../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
3 channel input
Require gradient = False for the first several layers of ResNet
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/27 22:01:19 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/27 22:01:19 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 22:01:19 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/27 22:01:20 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/27 22:01:20 d2.data.build]: [0mDistribution of instances among all 79 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 21744        |    bicycle    | 3806         |      car      | 39372        |
|  motorcycle   | 0            |   airplane    | 0            |      bus      | 0            |
|     train     | 0            |     truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant  | 0            |   stop sign   | 0            |
| parking meter | 0            |     bench     | 0            |     bird      | 0            |
|      cat      | 0            |      dog      | 0            |     horse     | 0            |
|     sheep     | 0            |      cow      | 0            |   elephant    | 0            |
|     bear      | 0            |     zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella    | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase    | 0            |    frisbee    | 0            |
|     skis      | 0            |   snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat  | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |   surfboard   | 0            | tennis racket | 0            |
|    bottle     | 0            |  wine glass   | 0            |      cup      | 0            |
|     fork      | 0            |     knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana     | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange     | 0            |   broccoli    | 0            |
|    carrot     | 0            |    hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake      | 0            |     chair     | 0            |
|     couch     | 0            | potted plant  | 0            |      bed      | 0            |
| dining table  | 0            |    toilet     | 0            |      tv       | 0            |
|    laptop     | 0            |     mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone   | 0            |   microwave   | 0            |
|     oven      | 0            |     bike      | 0            |    hydrant    | 0            |
|     motor     | 0            |     rider     | 0            |     light     | 0            |
|     sign      | 0            | motor vehicle | 0            |  human face   | 0            |
|  hair drier   | 0            |               |              |               |              |
|     total     | 64922        |               |              |               |              |[0m
[32m[04/27 22:01:20 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/27 22:01:20 d2.data.build]: [0mUsing training sampler TrainingSampler
-------- Changed the weights! ----------
============== The  0  *  1000  iterations ============
[32m[04/27 22:01:20 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/27 22:01:41 d2.utils.events]: [0m eta: 0:16:55  iter: 19  total_loss: 0.574  loss_cls: 0.179  loss_box_reg: 0.315  loss_rpn_cls: 0.010  loss_rpn_loc: 0.046  time: 1.0266  data_time: 0.0305  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:02:01 d2.utils.events]: [0m eta: 0:16:09  iter: 39  total_loss: 0.527  loss_cls: 0.170  loss_box_reg: 0.298  loss_rpn_cls: 0.007  loss_rpn_loc: 0.042  time: 1.0054  data_time: 0.0071  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:02:21 d2.utils.events]: [0m eta: 0:15:48  iter: 59  total_loss: 0.589  loss_cls: 0.182  loss_box_reg: 0.337  loss_rpn_cls: 0.013  loss_rpn_loc: 0.047  time: 1.0039  data_time: 0.0072  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:02:41 d2.utils.events]: [0m eta: 0:15:25  iter: 79  total_loss: 0.480  loss_cls: 0.150  loss_box_reg: 0.276  loss_rpn_cls: 0.008  loss_rpn_loc: 0.036  time: 1.0002  data_time: 0.0070  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:03:01 d2.utils.events]: [0m eta: 0:15:08  iter: 99  total_loss: 0.446  loss_cls: 0.139  loss_box_reg: 0.260  loss_rpn_cls: 0.007  loss_rpn_loc: 0.045  time: 1.0020  data_time: 0.0072  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:03:21 d2.utils.events]: [0m eta: 0:14:48  iter: 119  total_loss: 0.547  loss_cls: 0.175  loss_box_reg: 0.324  loss_rpn_cls: 0.012  loss_rpn_loc: 0.048  time: 1.0029  data_time: 0.0070  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:03:42 d2.utils.events]: [0m eta: 0:14:28  iter: 139  total_loss: 0.519  loss_cls: 0.168  loss_box_reg: 0.290  loss_rpn_cls: 0.009  loss_rpn_loc: 0.042  time: 1.0041  data_time: 0.0071  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:04:02 d2.utils.events]: [0m eta: 0:14:08  iter: 159  total_loss: 0.548  loss_cls: 0.168  loss_box_reg: 0.330  loss_rpn_cls: 0.010  loss_rpn_loc: 0.046  time: 1.0060  data_time: 0.0072  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:04:22 d2.utils.events]: [0m eta: 0:13:48  iter: 179  total_loss: 0.593  loss_cls: 0.185  loss_box_reg: 0.336  loss_rpn_cls: 0.009  loss_rpn_loc: 0.054  time: 1.0053  data_time: 0.0072  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:04:43 d2.utils.events]: [0m eta: 0:13:29  iter: 199  total_loss: 0.521  loss_cls: 0.171  loss_box_reg: 0.310  loss_rpn_cls: 0.007  loss_rpn_loc: 0.036  time: 1.0072  data_time: 0.0071  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:05:04 d2.utils.events]: [0m eta: 0:13:10  iter: 219  total_loss: 0.533  loss_cls: 0.174  loss_box_reg: 0.303  loss_rpn_cls: 0.011  loss_rpn_loc: 0.049  time: 1.0109  data_time: 0.0073  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:05:24 d2.utils.events]: [0m eta: 0:12:50  iter: 239  total_loss: 0.608  loss_cls: 0.193  loss_box_reg: 0.340  loss_rpn_cls: 0.014  loss_rpn_loc: 0.053  time: 1.0121  data_time: 0.0075  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:05:44 d2.utils.events]: [0m eta: 0:12:29  iter: 259  total_loss: 0.626  loss_cls: 0.187  loss_box_reg: 0.360  loss_rpn_cls: 0.009  loss_rpn_loc: 0.051  time: 1.0108  data_time: 0.0072  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:06:05 d2.utils.events]: [0m eta: 0:12:10  iter: 279  total_loss: 0.547  loss_cls: 0.174  loss_box_reg: 0.317  loss_rpn_cls: 0.008  loss_rpn_loc: 0.046  time: 1.0118  data_time: 0.0073  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:06:25 d2.utils.events]: [0m eta: 0:11:52  iter: 299  total_loss: 0.633  loss_cls: 0.202  loss_box_reg: 0.348  loss_rpn_cls: 0.011  loss_rpn_loc: 0.045  time: 1.0135  data_time: 0.0074  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:06:45 d2.utils.events]: [0m eta: 0:11:30  iter: 319  total_loss: 0.617  loss_cls: 0.184  loss_box_reg: 0.360  loss_rpn_cls: 0.010  loss_rpn_loc: 0.055  time: 1.0126  data_time: 0.0073  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:07:06 d2.utils.events]: [0m eta: 0:11:10  iter: 339  total_loss: 0.527  loss_cls: 0.169  loss_box_reg: 0.308  loss_rpn_cls: 0.010  loss_rpn_loc: 0.041  time: 1.0126  data_time: 0.0072  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:07:26 d2.utils.events]: [0m eta: 0:10:50  iter: 359  total_loss: 0.604  loss_cls: 0.182  loss_box_reg: 0.346  loss_rpn_cls: 0.010  loss_rpn_loc: 0.055  time: 1.0130  data_time: 0.0074  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:07:47 d2.utils.events]: [0m eta: 0:10:30  iter: 379  total_loss: 0.617  loss_cls: 0.192  loss_box_reg: 0.353  loss_rpn_cls: 0.010  loss_rpn_loc: 0.061  time: 1.0141  data_time: 0.0075  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:08:07 d2.utils.events]: [0m eta: 0:10:10  iter: 399  total_loss: 0.556  loss_cls: 0.186  loss_box_reg: 0.321  loss_rpn_cls: 0.011  loss_rpn_loc: 0.053  time: 1.0145  data_time: 0.0073  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:08:28 d2.utils.events]: [0m eta: 0:09:49  iter: 419  total_loss: 0.467  loss_cls: 0.143  loss_box_reg: 0.275  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 1.0149  data_time: 0.0072  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:08:48 d2.utils.events]: [0m eta: 0:09:28  iter: 439  total_loss: 0.601  loss_cls: 0.184  loss_box_reg: 0.330  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0143  data_time: 0.0071  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:09:09 d2.utils.events]: [0m eta: 0:09:08  iter: 459  total_loss: 0.619  loss_cls: 0.187  loss_box_reg: 0.366  loss_rpn_cls: 0.009  loss_rpn_loc: 0.063  time: 1.0153  data_time: 0.0076  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:09:30 d2.utils.events]: [0m eta: 0:08:49  iter: 479  total_loss: 0.522  loss_cls: 0.164  loss_box_reg: 0.295  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 1.0160  data_time: 0.0075  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:09:50 d2.utils.events]: [0m eta: 0:08:28  iter: 499  total_loss: 0.535  loss_cls: 0.174  loss_box_reg: 0.305  loss_rpn_cls: 0.007  loss_rpn_loc: 0.043  time: 1.0158  data_time: 0.0072  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:10:10 d2.utils.events]: [0m eta: 0:08:08  iter: 519  total_loss: 0.638  loss_cls: 0.197  loss_box_reg: 0.328  loss_rpn_cls: 0.015  loss_rpn_loc: 0.058  time: 1.0158  data_time: 0.0074  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:10:31 d2.utils.events]: [0m eta: 0:07:48  iter: 539  total_loss: 0.519  loss_cls: 0.162  loss_box_reg: 0.291  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 1.0157  data_time: 0.0074  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:10:52 d2.utils.events]: [0m eta: 0:07:28  iter: 559  total_loss: 0.552  loss_cls: 0.184  loss_box_reg: 0.311  loss_rpn_cls: 0.013  loss_rpn_loc: 0.051  time: 1.0173  data_time: 0.0075  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:11:12 d2.utils.events]: [0m eta: 0:07:08  iter: 579  total_loss: 0.617  loss_cls: 0.192  loss_box_reg: 0.342  loss_rpn_cls: 0.012  loss_rpn_loc: 0.053  time: 1.0168  data_time: 0.0073  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:11:33 d2.utils.events]: [0m eta: 0:06:48  iter: 599  total_loss: 0.530  loss_cls: 0.169  loss_box_reg: 0.309  loss_rpn_cls: 0.007  loss_rpn_loc: 0.037  time: 1.0173  data_time: 0.0074  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:11:53 d2.utils.events]: [0m eta: 0:06:27  iter: 619  total_loss: 0.548  loss_cls: 0.175  loss_box_reg: 0.324  loss_rpn_cls: 0.016  loss_rpn_loc: 0.044  time: 1.0172  data_time: 0.0071  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:12:13 d2.utils.events]: [0m eta: 0:06:07  iter: 639  total_loss: 0.546  loss_cls: 0.177  loss_box_reg: 0.311  loss_rpn_cls: 0.010  loss_rpn_loc: 0.042  time: 1.0171  data_time: 0.0073  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:12:33 d2.utils.events]: [0m eta: 0:05:47  iter: 659  total_loss: 0.551  loss_cls: 0.177  loss_box_reg: 0.318  loss_rpn_cls: 0.009  loss_rpn_loc: 0.046  time: 1.0165  data_time: 0.0080  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:12:54 d2.utils.events]: [0m eta: 0:05:26  iter: 679  total_loss: 0.561  loss_cls: 0.177  loss_box_reg: 0.326  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 1.0166  data_time: 0.0074  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:13:15 d2.utils.events]: [0m eta: 0:05:07  iter: 699  total_loss: 0.583  loss_cls: 0.184  loss_box_reg: 0.326  loss_rpn_cls: 0.009  loss_rpn_loc: 0.050  time: 1.0174  data_time: 0.0074  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:13:35 d2.utils.events]: [0m eta: 0:04:46  iter: 719  total_loss: 0.624  loss_cls: 0.191  loss_box_reg: 0.341  loss_rpn_cls: 0.011  loss_rpn_loc: 0.073  time: 1.0172  data_time: 0.0075  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:13:55 d2.utils.events]: [0m eta: 0:04:26  iter: 739  total_loss: 0.562  loss_cls: 0.175  loss_box_reg: 0.320  loss_rpn_cls: 0.009  loss_rpn_loc: 0.052  time: 1.0173  data_time: 0.0073  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:14:16 d2.utils.events]: [0m eta: 0:04:06  iter: 759  total_loss: 0.521  loss_cls: 0.170  loss_box_reg: 0.296  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0177  data_time: 0.0075  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:14:37 d2.utils.events]: [0m eta: 0:03:46  iter: 779  total_loss: 0.572  loss_cls: 0.171  loss_box_reg: 0.312  loss_rpn_cls: 0.015  loss_rpn_loc: 0.045  time: 1.0185  data_time: 0.0074  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:14:58 d2.utils.events]: [0m eta: 0:03:26  iter: 799  total_loss: 0.562  loss_cls: 0.183  loss_box_reg: 0.316  loss_rpn_cls: 0.009  loss_rpn_loc: 0.046  time: 1.0190  data_time: 0.0074  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:15:19 d2.utils.events]: [0m eta: 0:03:05  iter: 819  total_loss: 0.552  loss_cls: 0.164  loss_box_reg: 0.327  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 1.0196  data_time: 0.0074  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:15:39 d2.utils.events]: [0m eta: 0:02:45  iter: 839  total_loss: 0.525  loss_cls: 0.161  loss_box_reg: 0.299  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 1.0199  data_time: 0.0075  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:16:00 d2.utils.events]: [0m eta: 0:02:24  iter: 859  total_loss: 0.591  loss_cls: 0.191  loss_box_reg: 0.336  loss_rpn_cls: 0.008  loss_rpn_loc: 0.051  time: 1.0199  data_time: 0.0074  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:16:21 d2.utils.events]: [0m eta: 0:02:04  iter: 879  total_loss: 0.586  loss_cls: 0.185  loss_box_reg: 0.339  loss_rpn_cls: 0.010  loss_rpn_loc: 0.054  time: 1.0203  data_time: 0.0074  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:16:42 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.621  loss_cls: 0.196  loss_box_reg: 0.338  loss_rpn_cls: 0.012  loss_rpn_loc: 0.063  time: 1.0208  data_time: 0.0076  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:17:02 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.557  loss_cls: 0.171  loss_box_reg: 0.304  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0207  data_time: 0.0076  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:17:22 d2.utils.events]: [0m eta: 0:01:02  iter: 939  total_loss: 0.556  loss_cls: 0.180  loss_box_reg: 0.321  loss_rpn_cls: 0.010  loss_rpn_loc: 0.039  time: 1.0200  data_time: 0.0072  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:17:42 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.551  loss_cls: 0.179  loss_box_reg: 0.319  loss_rpn_cls: 0.012  loss_rpn_loc: 0.044  time: 1.0202  data_time: 0.0075  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:18:03 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.531  loss_cls: 0.180  loss_box_reg: 0.311  loss_rpn_cls: 0.010  loss_rpn_loc: 0.036  time: 1.0205  data_time: 0.0074  lr: 0.000500  max_mem: 5394M
[5m[31mWARNING[0m [32m[04/27 22:18:24 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 22:18:24 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/27 22:18:25 d2.data.build]: [0mDistribution of instances among all 80 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 5406         |    bicycle    | 420          |      car      | 5008         |
|  motorcycle   | 0            |   airplane    | 0            |      bus      | 0            |
|     train     | 0            |     truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant  | 0            |   stop sign   | 0            |
| parking meter | 0            |     bench     | 0            |     bird      | 0            |
|      cat      | 0            |      dog      | 0            |     horse     | 0            |
|     sheep     | 0            |      cow      | 0            |   elephant    | 0            |
|     bear      | 0            |     zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella    | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase    | 0            |    frisbee    | 0            |
|     skis      | 0            |   snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat  | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |   surfboard   | 0            | tennis racket | 0            |
|    bottle     | 0            |  wine glass   | 0            |      cup      | 0            |
|     fork      | 0            |     knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana     | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange     | 0            |   broccoli    | 0            |
|    carrot     | 0            |    hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake      | 0            |     chair     | 0            |
|     couch     | 0            | potted plant  | 0            |      bed      | 0            |
| dining table  | 0            |    toilet     | 0            |      tv       | 0            |
|    laptop     | 0            |     mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone   | 0            |   microwave   | 0            |
|     oven      | 0            |     bike      | 0            |    hydrant    | 0            |
|     motor     | 0            |     rider     | 0            |     light     | 0            |
|     sign      | 0            | motor vehicle | 0            |  human face   | 0            |
|  hair drier   | 0            | license plate | 0            |               |              |
|     total     | 10834        |               |              |               |              |[0m
[5m[31mWARNING[0m [32m[04/27 22:18:25 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/27 22:18:25 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.625  loss_cls: 0.203  loss_box_reg: 0.347  loss_rpn_cls: 0.009  loss_rpn_loc: 0.062  time: 1.0206  data_time: 0.0076  lr: 0.000500  max_mem: 5394M
[32m[04/27 22:18:25 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:16:58 (1.0216 s / it)
[32m[04/27 22:18:25 d2.engine.hooks]: [0mTotal training time: 0:17:01 (0:00:03 on hooks)
[5m[31mWARNING[0m [32m[04/27 22:18:26 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 22:18:26 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/27 22:18:26 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/27 22:18:28 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1138 s / img. ETA=0:16:01
[32m[04/27 22:18:33 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1136 s / img. ETA=0:15:57
[32m[04/27 22:18:38 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1135 s / img. ETA=0:15:51
[32m[04/27 22:18:43 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1136 s / img. ETA=0:15:46
[32m[04/27 22:18:48 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1136 s / img. ETA=0:15:41
[32m[04/27 22:18:53 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1137 s / img. ETA=0:15:37
[32m[04/27 22:18:58 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1137 s / img. ETA=0:15:32
[32m[04/27 22:19:03 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1137 s / img. ETA=0:15:27
[32m[04/27 22:19:08 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1138 s / img. ETA=0:15:22
[32m[04/27 22:19:13 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1138 s / img. ETA=0:15:17
[32m[04/27 22:19:19 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1138 s / img. ETA=0:15:13
[32m[04/27 22:19:24 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1138 s / img. ETA=0:15:08
[32m[04/27 22:19:29 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1139 s / img. ETA=0:15:03
[32m[04/27 22:19:34 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1139 s / img. ETA=0:14:58
[32m[04/27 22:19:39 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1139 s / img. ETA=0:14:53
[32m[04/27 22:19:44 d2.evaluation.evaluator]: [0mInference done 671/8355. 0.1139 s / img. ETA=0:14:48
[32m[04/27 22:19:49 d2.evaluation.evaluator]: [0mInference done 714/8355. 0.1140 s / img. ETA=0:14:44
[32m[04/27 22:19:54 d2.evaluation.evaluator]: [0mInference done 758/8355. 0.1140 s / img. ETA=0:14:38
[32m[04/27 22:19:59 d2.evaluation.evaluator]: [0mInference done 801/8355. 0.1141 s / img. ETA=0:14:34
[32m[04/27 22:20:04 d2.evaluation.evaluator]: [0mInference done 845/8355. 0.1141 s / img. ETA=0:14:29
[32m[04/27 22:20:09 d2.evaluation.evaluator]: [0mInference done 889/8355. 0.1141 s / img. ETA=0:14:24
[32m[04/27 22:20:14 d2.evaluation.evaluator]: [0mInference done 932/8355. 0.1141 s / img. ETA=0:14:19
[32m[04/27 22:20:20 d2.evaluation.evaluator]: [0mInference done 976/8355. 0.1141 s / img. ETA=0:14:14
[32m[04/27 22:20:25 d2.evaluation.evaluator]: [0mInference done 1020/8355. 0.1141 s / img. ETA=0:14:09
[32m[04/27 22:20:30 d2.evaluation.evaluator]: [0mInference done 1064/8355. 0.1141 s / img. ETA=0:14:04
[32m[04/27 22:20:35 d2.evaluation.evaluator]: [0mInference done 1108/8355. 0.1141 s / img. ETA=0:13:59
[32m[04/27 22:20:40 d2.evaluation.evaluator]: [0mInference done 1152/8355. 0.1141 s / img. ETA=0:13:54
[32m[04/27 22:20:45 d2.evaluation.evaluator]: [0mInference done 1196/8355. 0.1141 s / img. ETA=0:13:49
[32m[04/27 22:20:50 d2.evaluation.evaluator]: [0mInference done 1239/8355. 0.1142 s / img. ETA=0:13:44
[32m[04/27 22:20:55 d2.evaluation.evaluator]: [0mInference done 1283/8355. 0.1141 s / img. ETA=0:13:39
[32m[04/27 22:21:00 d2.evaluation.evaluator]: [0mInference done 1327/8355. 0.1141 s / img. ETA=0:13:34
[32m[04/27 22:21:05 d2.evaluation.evaluator]: [0mInference done 1371/8355. 0.1141 s / img. ETA=0:13:29
[32m[04/27 22:21:10 d2.evaluation.evaluator]: [0mInference done 1415/8355. 0.1141 s / img. ETA=0:13:23
[32m[04/27 22:21:15 d2.evaluation.evaluator]: [0mInference done 1459/8355. 0.1141 s / img. ETA=0:13:18
[32m[04/27 22:21:20 d2.evaluation.evaluator]: [0mInference done 1502/8355. 0.1141 s / img. ETA=0:13:13
[32m[04/27 22:21:26 d2.evaluation.evaluator]: [0mInference done 1545/8355. 0.1142 s / img. ETA=0:13:09
[32m[04/27 22:21:31 d2.evaluation.evaluator]: [0mInference done 1588/8355. 0.1142 s / img. ETA=0:13:04
[32m[04/27 22:21:36 d2.evaluation.evaluator]: [0mInference done 1631/8355. 0.1142 s / img. ETA=0:12:59
[32m[04/27 22:21:41 d2.evaluation.evaluator]: [0mInference done 1674/8355. 0.1143 s / img. ETA=0:12:54
[32m[04/27 22:21:46 d2.evaluation.evaluator]: [0mInference done 1717/8355. 0.1143 s / img. ETA=0:12:50
[32m[04/27 22:21:51 d2.evaluation.evaluator]: [0mInference done 1760/8355. 0.1143 s / img. ETA=0:12:45
[32m[04/27 22:21:56 d2.evaluation.evaluator]: [0mInference done 1803/8355. 0.1144 s / img. ETA=0:12:40
[32m[04/27 22:22:01 d2.evaluation.evaluator]: [0mInference done 1846/8355. 0.1144 s / img. ETA=0:12:36
[32m[04/27 22:22:06 d2.evaluation.evaluator]: [0mInference done 1889/8355. 0.1144 s / img. ETA=0:12:31
[32m[04/27 22:22:11 d2.evaluation.evaluator]: [0mInference done 1932/8355. 0.1144 s / img. ETA=0:12:26
[32m[04/27 22:22:16 d2.evaluation.evaluator]: [0mInference done 1975/8355. 0.1144 s / img. ETA=0:12:21
[32m[04/27 22:22:21 d2.evaluation.evaluator]: [0mInference done 2018/8355. 0.1145 s / img. ETA=0:12:16
[32m[04/27 22:22:26 d2.evaluation.evaluator]: [0mInference done 2061/8355. 0.1145 s / img. ETA=0:12:11
[32m[04/27 22:22:31 d2.evaluation.evaluator]: [0mInference done 2105/8355. 0.1145 s / img. ETA=0:12:06
[32m[04/27 22:22:36 d2.evaluation.evaluator]: [0mInference done 2149/8355. 0.1145 s / img. ETA=0:12:01
[32m[04/27 22:22:41 d2.evaluation.evaluator]: [0mInference done 2192/8355. 0.1145 s / img. ETA=0:11:56
[32m[04/27 22:22:46 d2.evaluation.evaluator]: [0mInference done 2235/8355. 0.1145 s / img. ETA=0:11:51
[32m[04/27 22:22:51 d2.evaluation.evaluator]: [0mInference done 2278/8355. 0.1145 s / img. ETA=0:11:46
[32m[04/27 22:22:56 d2.evaluation.evaluator]: [0mInference done 2321/8355. 0.1145 s / img. ETA=0:11:41
[32m[04/27 22:23:01 d2.evaluation.evaluator]: [0mInference done 2364/8355. 0.1146 s / img. ETA=0:11:36
[32m[04/27 22:23:06 d2.evaluation.evaluator]: [0mInference done 2407/8355. 0.1146 s / img. ETA=0:11:31
[32m[04/27 22:23:11 d2.evaluation.evaluator]: [0mInference done 2450/8355. 0.1146 s / img. ETA=0:11:26
[32m[04/27 22:23:17 d2.evaluation.evaluator]: [0mInference done 2494/8355. 0.1146 s / img. ETA=0:11:21
[32m[04/27 22:23:22 d2.evaluation.evaluator]: [0mInference done 2537/8355. 0.1146 s / img. ETA=0:11:16
[32m[04/27 22:23:27 d2.evaluation.evaluator]: [0mInference done 2580/8355. 0.1146 s / img. ETA=0:11:11
[32m[04/27 22:23:32 d2.evaluation.evaluator]: [0mInference done 2623/8355. 0.1146 s / img. ETA=0:11:06
[32m[04/27 22:23:37 d2.evaluation.evaluator]: [0mInference done 2666/8355. 0.1146 s / img. ETA=0:11:01
[32m[04/27 22:23:42 d2.evaluation.evaluator]: [0mInference done 2709/8355. 0.1146 s / img. ETA=0:10:56
[32m[04/27 22:23:47 d2.evaluation.evaluator]: [0mInference done 2752/8355. 0.1146 s / img. ETA=0:10:51
[32m[04/27 22:23:52 d2.evaluation.evaluator]: [0mInference done 2794/8355. 0.1146 s / img. ETA=0:10:47
[32m[04/27 22:23:57 d2.evaluation.evaluator]: [0mInference done 2837/8355. 0.1146 s / img. ETA=0:10:42
[32m[04/27 22:24:02 d2.evaluation.evaluator]: [0mInference done 2880/8355. 0.1147 s / img. ETA=0:10:37
[32m[04/27 22:24:07 d2.evaluation.evaluator]: [0mInference done 2923/8355. 0.1147 s / img. ETA=0:10:32
[32m[04/27 22:24:12 d2.evaluation.evaluator]: [0mInference done 2966/8355. 0.1147 s / img. ETA=0:10:27
[32m[04/27 22:24:17 d2.evaluation.evaluator]: [0mInference done 3009/8355. 0.1147 s / img. ETA=0:10:22
[32m[04/27 22:24:22 d2.evaluation.evaluator]: [0mInference done 3052/8355. 0.1147 s / img. ETA=0:10:17
[32m[04/27 22:24:27 d2.evaluation.evaluator]: [0mInference done 3095/8355. 0.1147 s / img. ETA=0:10:12
[32m[04/27 22:24:32 d2.evaluation.evaluator]: [0mInference done 3138/8355. 0.1147 s / img. ETA=0:10:07
[32m[04/27 22:24:37 d2.evaluation.evaluator]: [0mInference done 3182/8355. 0.1147 s / img. ETA=0:10:02
[32m[04/27 22:24:42 d2.evaluation.evaluator]: [0mInference done 3226/8355. 0.1147 s / img. ETA=0:09:57
[32m[04/27 22:24:47 d2.evaluation.evaluator]: [0mInference done 3269/8355. 0.1147 s / img. ETA=0:09:52
[32m[04/27 22:24:52 d2.evaluation.evaluator]: [0mInference done 3312/8355. 0.1147 s / img. ETA=0:09:47
[32m[04/27 22:24:57 d2.evaluation.evaluator]: [0mInference done 3355/8355. 0.1147 s / img. ETA=0:09:42
[32m[04/27 22:25:02 d2.evaluation.evaluator]: [0mInference done 3398/8355. 0.1147 s / img. ETA=0:09:37
[32m[04/27 22:25:07 d2.evaluation.evaluator]: [0mInference done 3442/8355. 0.1147 s / img. ETA=0:09:32
[32m[04/27 22:25:12 d2.evaluation.evaluator]: [0mInference done 3486/8355. 0.1147 s / img. ETA=0:09:27
[32m[04/27 22:25:17 d2.evaluation.evaluator]: [0mInference done 3529/8355. 0.1147 s / img. ETA=0:09:22
[32m[04/27 22:25:22 d2.evaluation.evaluator]: [0mInference done 3572/8355. 0.1147 s / img. ETA=0:09:17
[32m[04/27 22:25:28 d2.evaluation.evaluator]: [0mInference done 3615/8355. 0.1147 s / img. ETA=0:09:12
[32m[04/27 22:25:33 d2.evaluation.evaluator]: [0mInference done 3658/8355. 0.1147 s / img. ETA=0:09:07
[32m[04/27 22:25:38 d2.evaluation.evaluator]: [0mInference done 3702/8355. 0.1147 s / img. ETA=0:09:01
[32m[04/27 22:25:43 d2.evaluation.evaluator]: [0mInference done 3745/8355. 0.1147 s / img. ETA=0:08:56
[32m[04/27 22:25:48 d2.evaluation.evaluator]: [0mInference done 3788/8355. 0.1147 s / img. ETA=0:08:51
[32m[04/27 22:25:53 d2.evaluation.evaluator]: [0mInference done 3831/8355. 0.1147 s / img. ETA=0:08:47
[32m[04/27 22:25:58 d2.evaluation.evaluator]: [0mInference done 3875/8355. 0.1147 s / img. ETA=0:08:41
[32m[04/27 22:26:03 d2.evaluation.evaluator]: [0mInference done 3918/8355. 0.1147 s / img. ETA=0:08:36
[32m[04/27 22:26:08 d2.evaluation.evaluator]: [0mInference done 3962/8355. 0.1147 s / img. ETA=0:08:31
[32m[04/27 22:26:13 d2.evaluation.evaluator]: [0mInference done 4006/8355. 0.1147 s / img. ETA=0:08:26
[32m[04/27 22:26:18 d2.evaluation.evaluator]: [0mInference done 4049/8355. 0.1147 s / img. ETA=0:08:21
[32m[04/27 22:26:23 d2.evaluation.evaluator]: [0mInference done 4092/8355. 0.1147 s / img. ETA=0:08:16
[32m[04/27 22:26:28 d2.evaluation.evaluator]: [0mInference done 4135/8355. 0.1147 s / img. ETA=0:08:11
[32m[04/27 22:26:33 d2.evaluation.evaluator]: [0mInference done 4178/8355. 0.1147 s / img. ETA=0:08:06
[32m[04/27 22:26:38 d2.evaluation.evaluator]: [0mInference done 4221/8355. 0.1147 s / img. ETA=0:08:01
[32m[04/27 22:26:43 d2.evaluation.evaluator]: [0mInference done 4265/8355. 0.1147 s / img. ETA=0:07:56
[32m[04/27 22:26:48 d2.evaluation.evaluator]: [0mInference done 4308/8355. 0.1147 s / img. ETA=0:07:51
[32m[04/27 22:26:53 d2.evaluation.evaluator]: [0mInference done 4351/8355. 0.1147 s / img. ETA=0:07:46
[32m[04/27 22:26:58 d2.evaluation.evaluator]: [0mInference done 4394/8355. 0.1147 s / img. ETA=0:07:41
[32m[04/27 22:27:03 d2.evaluation.evaluator]: [0mInference done 4437/8355. 0.1147 s / img. ETA=0:07:36
[32m[04/27 22:27:09 d2.evaluation.evaluator]: [0mInference done 4481/8355. 0.1147 s / img. ETA=0:07:31
[32m[04/27 22:27:14 d2.evaluation.evaluator]: [0mInference done 4524/8355. 0.1147 s / img. ETA=0:07:26
[32m[04/27 22:27:19 d2.evaluation.evaluator]: [0mInference done 4567/8355. 0.1147 s / img. ETA=0:07:21
[32m[04/27 22:27:24 d2.evaluation.evaluator]: [0mInference done 4610/8355. 0.1147 s / img. ETA=0:07:16
[32m[04/27 22:27:29 d2.evaluation.evaluator]: [0mInference done 4653/8355. 0.1147 s / img. ETA=0:07:11
[32m[04/27 22:27:34 d2.evaluation.evaluator]: [0mInference done 4696/8355. 0.1147 s / img. ETA=0:07:06
[32m[04/27 22:27:39 d2.evaluation.evaluator]: [0mInference done 4739/8355. 0.1148 s / img. ETA=0:07:01
[32m[04/27 22:27:44 d2.evaluation.evaluator]: [0mInference done 4782/8355. 0.1148 s / img. ETA=0:06:56
[32m[04/27 22:27:49 d2.evaluation.evaluator]: [0mInference done 4825/8355. 0.1148 s / img. ETA=0:06:51
[32m[04/27 22:27:54 d2.evaluation.evaluator]: [0mInference done 4868/8355. 0.1148 s / img. ETA=0:06:46
[32m[04/27 22:27:59 d2.evaluation.evaluator]: [0mInference done 4912/8355. 0.1148 s / img. ETA=0:06:41
[32m[04/27 22:28:04 d2.evaluation.evaluator]: [0mInference done 4955/8355. 0.1148 s / img. ETA=0:06:36
[32m[04/27 22:28:09 d2.evaluation.evaluator]: [0mInference done 4998/8355. 0.1148 s / img. ETA=0:06:31
[32m[04/27 22:28:14 d2.evaluation.evaluator]: [0mInference done 5041/8355. 0.1148 s / img. ETA=0:06:26
[32m[04/27 22:28:19 d2.evaluation.evaluator]: [0mInference done 5084/8355. 0.1148 s / img. ETA=0:06:21
[32m[04/27 22:28:24 d2.evaluation.evaluator]: [0mInference done 5127/8355. 0.1148 s / img. ETA=0:06:16
[32m[04/27 22:28:29 d2.evaluation.evaluator]: [0mInference done 5170/8355. 0.1148 s / img. ETA=0:06:11
[32m[04/27 22:28:34 d2.evaluation.evaluator]: [0mInference done 5213/8355. 0.1148 s / img. ETA=0:06:06
[32m[04/27 22:28:39 d2.evaluation.evaluator]: [0mInference done 5255/8355. 0.1148 s / img. ETA=0:06:01
[32m[04/27 22:28:44 d2.evaluation.evaluator]: [0mInference done 5299/8355. 0.1148 s / img. ETA=0:05:56
[32m[04/27 22:28:49 d2.evaluation.evaluator]: [0mInference done 5342/8355. 0.1148 s / img. ETA=0:05:51
[32m[04/27 22:28:54 d2.evaluation.evaluator]: [0mInference done 5385/8355. 0.1148 s / img. ETA=0:05:46
[32m[04/27 22:28:59 d2.evaluation.evaluator]: [0mInference done 5428/8355. 0.1148 s / img. ETA=0:05:41
[32m[04/27 22:29:04 d2.evaluation.evaluator]: [0mInference done 5471/8355. 0.1148 s / img. ETA=0:05:36
[32m[04/27 22:29:09 d2.evaluation.evaluator]: [0mInference done 5514/8355. 0.1148 s / img. ETA=0:05:31
[32m[04/27 22:29:14 d2.evaluation.evaluator]: [0mInference done 5557/8355. 0.1148 s / img. ETA=0:05:26
[32m[04/27 22:29:20 d2.evaluation.evaluator]: [0mInference done 5601/8355. 0.1148 s / img. ETA=0:05:21
[32m[04/27 22:29:25 d2.evaluation.evaluator]: [0mInference done 5644/8355. 0.1148 s / img. ETA=0:05:16
[32m[04/27 22:29:30 d2.evaluation.evaluator]: [0mInference done 5687/8355. 0.1148 s / img. ETA=0:05:11
[32m[04/27 22:29:35 d2.evaluation.evaluator]: [0mInference done 5730/8355. 0.1148 s / img. ETA=0:05:06
[32m[04/27 22:29:40 d2.evaluation.evaluator]: [0mInference done 5773/8355. 0.1148 s / img. ETA=0:05:01
[32m[04/27 22:29:45 d2.evaluation.evaluator]: [0mInference done 5816/8355. 0.1149 s / img. ETA=0:04:56
[32m[04/27 22:29:50 d2.evaluation.evaluator]: [0mInference done 5859/8355. 0.1149 s / img. ETA=0:04:51
[32m[04/27 22:29:55 d2.evaluation.evaluator]: [0mInference done 5902/8355. 0.1149 s / img. ETA=0:04:46
[32m[04/27 22:30:00 d2.evaluation.evaluator]: [0mInference done 5945/8355. 0.1149 s / img. ETA=0:04:41
[32m[04/27 22:30:05 d2.evaluation.evaluator]: [0mInference done 5988/8355. 0.1149 s / img. ETA=0:04:36
[32m[04/27 22:30:10 d2.evaluation.evaluator]: [0mInference done 6030/8355. 0.1149 s / img. ETA=0:04:31
[32m[04/27 22:30:15 d2.evaluation.evaluator]: [0mInference done 6073/8355. 0.1149 s / img. ETA=0:04:26
[32m[04/27 22:30:20 d2.evaluation.evaluator]: [0mInference done 6116/8355. 0.1149 s / img. ETA=0:04:21
[32m[04/27 22:30:25 d2.evaluation.evaluator]: [0mInference done 6158/8355. 0.1149 s / img. ETA=0:04:16
[32m[04/27 22:30:30 d2.evaluation.evaluator]: [0mInference done 6201/8355. 0.1149 s / img. ETA=0:04:11
[32m[04/27 22:30:35 d2.evaluation.evaluator]: [0mInference done 6244/8355. 0.1150 s / img. ETA=0:04:06
[32m[04/27 22:30:40 d2.evaluation.evaluator]: [0mInference done 6287/8355. 0.1150 s / img. ETA=0:04:01
[32m[04/27 22:30:45 d2.evaluation.evaluator]: [0mInference done 6330/8355. 0.1150 s / img. ETA=0:03:56
[32m[04/27 22:30:51 d2.evaluation.evaluator]: [0mInference done 6373/8355. 0.1150 s / img. ETA=0:03:51
[32m[04/27 22:30:56 d2.evaluation.evaluator]: [0mInference done 6416/8355. 0.1150 s / img. ETA=0:03:46
[32m[04/27 22:31:01 d2.evaluation.evaluator]: [0mInference done 6459/8355. 0.1150 s / img. ETA=0:03:41
[32m[04/27 22:31:06 d2.evaluation.evaluator]: [0mInference done 6502/8355. 0.1150 s / img. ETA=0:03:36
[32m[04/27 22:31:11 d2.evaluation.evaluator]: [0mInference done 6546/8355. 0.1150 s / img. ETA=0:03:31
[32m[04/27 22:31:16 d2.evaluation.evaluator]: [0mInference done 6589/8355. 0.1150 s / img. ETA=0:03:26
[32m[04/27 22:31:21 d2.evaluation.evaluator]: [0mInference done 6632/8355. 0.1150 s / img. ETA=0:03:21
[32m[04/27 22:31:26 d2.evaluation.evaluator]: [0mInference done 6675/8355. 0.1150 s / img. ETA=0:03:16
[32m[04/27 22:31:31 d2.evaluation.evaluator]: [0mInference done 6718/8355. 0.1150 s / img. ETA=0:03:11
[32m[04/27 22:31:36 d2.evaluation.evaluator]: [0mInference done 6761/8355. 0.1150 s / img. ETA=0:03:06
[32m[04/27 22:31:41 d2.evaluation.evaluator]: [0mInference done 6804/8355. 0.1150 s / img. ETA=0:03:01
[32m[04/27 22:31:46 d2.evaluation.evaluator]: [0mInference done 6847/8355. 0.1150 s / img. ETA=0:02:56
[32m[04/27 22:31:51 d2.evaluation.evaluator]: [0mInference done 6890/8355. 0.1150 s / img. ETA=0:02:51
[32m[04/27 22:31:56 d2.evaluation.evaluator]: [0mInference done 6933/8355. 0.1150 s / img. ETA=0:02:46
[32m[04/27 22:32:01 d2.evaluation.evaluator]: [0mInference done 6976/8355. 0.1150 s / img. ETA=0:02:41
[32m[04/27 22:32:06 d2.evaluation.evaluator]: [0mInference done 7019/8355. 0.1150 s / img. ETA=0:02:36
[32m[04/27 22:32:11 d2.evaluation.evaluator]: [0mInference done 7062/8355. 0.1150 s / img. ETA=0:02:30
[32m[04/27 22:32:16 d2.evaluation.evaluator]: [0mInference done 7105/8355. 0.1150 s / img. ETA=0:02:25
[32m[04/27 22:32:21 d2.evaluation.evaluator]: [0mInference done 7148/8355. 0.1150 s / img. ETA=0:02:20
[32m[04/27 22:32:26 d2.evaluation.evaluator]: [0mInference done 7191/8355. 0.1150 s / img. ETA=0:02:15
[32m[04/27 22:32:31 d2.evaluation.evaluator]: [0mInference done 7233/8355. 0.1151 s / img. ETA=0:02:11
[32m[04/27 22:32:37 d2.evaluation.evaluator]: [0mInference done 7276/8355. 0.1151 s / img. ETA=0:02:06
[32m[04/27 22:32:42 d2.evaluation.evaluator]: [0mInference done 7319/8355. 0.1151 s / img. ETA=0:02:01
[32m[04/27 22:32:47 d2.evaluation.evaluator]: [0mInference done 7362/8355. 0.1151 s / img. ETA=0:01:56
[32m[04/27 22:32:52 d2.evaluation.evaluator]: [0mInference done 7405/8355. 0.1151 s / img. ETA=0:01:51
[32m[04/27 22:32:57 d2.evaluation.evaluator]: [0mInference done 7448/8355. 0.1151 s / img. ETA=0:01:45
[32m[04/27 22:33:02 d2.evaluation.evaluator]: [0mInference done 7491/8355. 0.1151 s / img. ETA=0:01:40
[32m[04/27 22:33:07 d2.evaluation.evaluator]: [0mInference done 7534/8355. 0.1151 s / img. ETA=0:01:35
[32m[04/27 22:33:12 d2.evaluation.evaluator]: [0mInference done 7577/8355. 0.1151 s / img. ETA=0:01:30
[32m[04/27 22:33:17 d2.evaluation.evaluator]: [0mInference done 7620/8355. 0.1151 s / img. ETA=0:01:25
[32m[04/27 22:33:22 d2.evaluation.evaluator]: [0mInference done 7663/8355. 0.1151 s / img. ETA=0:01:20
[32m[04/27 22:33:27 d2.evaluation.evaluator]: [0mInference done 7706/8355. 0.1151 s / img. ETA=0:01:15
[32m[04/27 22:33:32 d2.evaluation.evaluator]: [0mInference done 7749/8355. 0.1151 s / img. ETA=0:01:10
[32m[04/27 22:33:37 d2.evaluation.evaluator]: [0mInference done 7792/8355. 0.1151 s / img. ETA=0:01:05
[32m[04/27 22:33:42 d2.evaluation.evaluator]: [0mInference done 7835/8355. 0.1151 s / img. ETA=0:01:00
[32m[04/27 22:33:47 d2.evaluation.evaluator]: [0mInference done 7878/8355. 0.1151 s / img. ETA=0:00:55
[32m[04/27 22:33:53 d2.evaluation.evaluator]: [0mInference done 7921/8355. 0.1151 s / img. ETA=0:00:50
[32m[04/27 22:33:58 d2.evaluation.evaluator]: [0mInference done 7964/8355. 0.1151 s / img. ETA=0:00:45
[32m[04/27 22:34:03 d2.evaluation.evaluator]: [0mInference done 8007/8355. 0.1151 s / img. ETA=0:00:40
[32m[04/27 22:34:08 d2.evaluation.evaluator]: [0mInference done 8050/8355. 0.1151 s / img. ETA=0:00:35
[32m[04/27 22:34:13 d2.evaluation.evaluator]: [0mInference done 8093/8355. 0.1152 s / img. ETA=0:00:30
[32m[04/27 22:34:18 d2.evaluation.evaluator]: [0mInference done 8136/8355. 0.1151 s / img. ETA=0:00:25
[32m[04/27 22:34:23 d2.evaluation.evaluator]: [0mInference done 8179/8355. 0.1151 s / img. ETA=0:00:20
[32m[04/27 22:34:28 d2.evaluation.evaluator]: [0mInference done 8222/8355. 0.1151 s / img. ETA=0:00:15
[32m[04/27 22:34:33 d2.evaluation.evaluator]: [0mInference done 8265/8355. 0.1152 s / img. ETA=0:00:10
[32m[04/27 22:34:38 d2.evaluation.evaluator]: [0mInference done 8308/8355. 0.1152 s / img. ETA=0:00:05
[32m[04/27 22:34:43 d2.evaluation.evaluator]: [0mInference done 8351/8355. 0.1152 s / img. ETA=0:00:00
[32m[04/27 22:34:43 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:16.417792 (0.116936 s / img per device, on 1 devices)
[32m[04/27 22:34:43 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:01 (0.115164 s / img per device, on 1 devices)
[32m[04/27 22:34:44 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/27 22:34:44 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/27 22:34:44 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.45s).
Accumulating evaluation results...
DONE (t=2.20s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.791
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.428
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.330
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.580
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.699
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.173
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.494
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.508
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.408
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.646
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.751
[32m[04/27 22:35:06 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.387 | 79.078 | 42.843 | 32.959 | 58.017 | 69.875 |
[32m[04/27 22:35:06 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 43.477 | bicycle       | 34.946 | car            | 54.740 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/27 22:35:06 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 22:35:06 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/27 22:35:06 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/27 22:35:08 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1148 s / img. ETA=0:02:24
[32m[04/27 22:35:13 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1145 s / img. ETA=0:02:19
[32m[04/27 22:35:18 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1145 s / img. ETA=0:02:14
[32m[04/27 22:35:23 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1145 s / img. ETA=0:02:09
[32m[04/27 22:35:28 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1146 s / img. ETA=0:02:05
[32m[04/27 22:35:33 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1146 s / img. ETA=0:02:00
[32m[04/27 22:35:38 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1147 s / img. ETA=0:01:55
[32m[04/27 22:35:43 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1146 s / img. ETA=0:01:50
[32m[04/27 22:35:48 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1146 s / img. ETA=0:01:45
[32m[04/27 22:35:53 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1146 s / img. ETA=0:01:40
[32m[04/27 22:35:58 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1146 s / img. ETA=0:01:35
[32m[04/27 22:36:03 d2.evaluation.evaluator]: [0mInference done 485/1257. 0.1146 s / img. ETA=0:01:29
[32m[04/27 22:36:08 d2.evaluation.evaluator]: [0mInference done 528/1257. 0.1146 s / img. ETA=0:01:24
[32m[04/27 22:36:13 d2.evaluation.evaluator]: [0mInference done 571/1257. 0.1147 s / img. ETA=0:01:19
[32m[04/27 22:36:18 d2.evaluation.evaluator]: [0mInference done 614/1257. 0.1147 s / img. ETA=0:01:14
[32m[04/27 22:36:23 d2.evaluation.evaluator]: [0mInference done 657/1257. 0.1147 s / img. ETA=0:01:09
[32m[04/27 22:36:28 d2.evaluation.evaluator]: [0mInference done 700/1257. 0.1147 s / img. ETA=0:01:04
[32m[04/27 22:36:33 d2.evaluation.evaluator]: [0mInference done 743/1257. 0.1147 s / img. ETA=0:00:59
[32m[04/27 22:36:38 d2.evaluation.evaluator]: [0mInference done 787/1257. 0.1147 s / img. ETA=0:00:54
[32m[04/27 22:36:43 d2.evaluation.evaluator]: [0mInference done 830/1257. 0.1147 s / img. ETA=0:00:49
[32m[04/27 22:36:48 d2.evaluation.evaluator]: [0mInference done 873/1257. 0.1148 s / img. ETA=0:00:44
[32m[04/27 22:36:53 d2.evaluation.evaluator]: [0mInference done 916/1257. 0.1148 s / img. ETA=0:00:39
[32m[04/27 22:36:58 d2.evaluation.evaluator]: [0mInference done 959/1257. 0.1148 s / img. ETA=0:00:34
[32m[04/27 22:37:03 d2.evaluation.evaluator]: [0mInference done 1002/1257. 0.1148 s / img. ETA=0:00:29
[32m[04/27 22:37:08 d2.evaluation.evaluator]: [0mInference done 1045/1257. 0.1148 s / img. ETA=0:00:24
[32m[04/27 22:37:14 d2.evaluation.evaluator]: [0mInference done 1088/1257. 0.1148 s / img. ETA=0:00:19
[32m[04/27 22:37:19 d2.evaluation.evaluator]: [0mInference done 1131/1257. 0.1149 s / img. ETA=0:00:14
[32m[04/27 22:37:24 d2.evaluation.evaluator]: [0mInference done 1174/1257. 0.1149 s / img. ETA=0:00:09
[32m[04/27 22:37:29 d2.evaluation.evaluator]: [0mInference done 1217/1257. 0.1150 s / img. ETA=0:00:04
[32m[04/27 22:37:33 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.336282 (0.116882 s / img per device, on 1 devices)
[32m[04/27 22:37:33 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115017 s / img per device, on 1 devices)
[32m[04/27 22:37:34 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/27 22:37:34 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/27 22:37:34 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.21s).
Accumulating evaluation results...
DONE (t=0.36s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.791
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.394
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.312
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.490
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.495
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.403
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.559
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.682
[32m[04/27 22:37:37 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.600 | 79.068 | 39.438 | 31.229 | 49.050 | 59.829 |
[32m[04/27 22:37:37 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 43.712 | bicycle       | 27.451 | car            | 56.638 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  1  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/27 22:37:38 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/27 22:37:38 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 22:37:38 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/27 22:37:39 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/27 22:37:39 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/27 22:37:39 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/27 22:37:39 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/27 22:38:00 d2.utils.events]: [0m eta: 0:17:06  iter: 19  total_loss: 0.570  loss_cls: 0.197  loss_box_reg: 0.331  loss_rpn_cls: 0.010  loss_rpn_loc: 0.043  time: 1.0355  data_time: 0.0174  lr: 0.000100  max_mem: 5406M
[32m[04/27 22:38:21 d2.utils.events]: [0m eta: 0:16:50  iter: 39  total_loss: 0.517  loss_cls: 0.158  loss_box_reg: 0.298  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0394  data_time: 0.0075  lr: 0.000200  max_mem: 5406M
[32m[04/27 22:38:41 d2.utils.events]: [0m eta: 0:16:27  iter: 59  total_loss: 0.630  loss_cls: 0.192  loss_box_reg: 0.332  loss_rpn_cls: 0.010  loss_rpn_loc: 0.046  time: 1.0328  data_time: 0.0079  lr: 0.000300  max_mem: 5406M
[32m[04/27 22:39:02 d2.utils.events]: [0m eta: 0:16:07  iter: 79  total_loss: 0.525  loss_cls: 0.157  loss_box_reg: 0.304  loss_rpn_cls: 0.010  loss_rpn_loc: 0.055  time: 1.0341  data_time: 0.0073  lr: 0.000400  max_mem: 5406M
[32m[04/27 22:39:22 d2.utils.events]: [0m eta: 0:15:41  iter: 99  total_loss: 0.541  loss_cls: 0.154  loss_box_reg: 0.306  loss_rpn_cls: 0.008  loss_rpn_loc: 0.060  time: 1.0278  data_time: 0.0072  lr: 0.000500  max_mem: 5406M
[32m[04/27 22:39:42 d2.utils.events]: [0m eta: 0:15:16  iter: 119  total_loss: 0.574  loss_cls: 0.181  loss_box_reg: 0.333  loss_rpn_cls: 0.008  loss_rpn_loc: 0.043  time: 1.0236  data_time: 0.0073  lr: 0.000599  max_mem: 5406M
[32m[04/27 22:40:03 d2.utils.events]: [0m eta: 0:14:57  iter: 139  total_loss: 0.528  loss_cls: 0.155  loss_box_reg: 0.308  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 1.0238  data_time: 0.0076  lr: 0.000699  max_mem: 5406M
[32m[04/27 22:40:23 d2.utils.events]: [0m eta: 0:14:26  iter: 159  total_loss: 0.543  loss_cls: 0.171  loss_box_reg: 0.322  loss_rpn_cls: 0.010  loss_rpn_loc: 0.042  time: 1.0207  data_time: 0.0073  lr: 0.000799  max_mem: 5406M
[32m[04/27 22:40:43 d2.utils.events]: [0m eta: 0:14:06  iter: 179  total_loss: 0.562  loss_cls: 0.170  loss_box_reg: 0.306  loss_rpn_cls: 0.010  loss_rpn_loc: 0.043  time: 1.0211  data_time: 0.0072  lr: 0.000899  max_mem: 5406M
[32m[04/27 22:41:03 d2.utils.events]: [0m eta: 0:13:44  iter: 199  total_loss: 0.570  loss_cls: 0.179  loss_box_reg: 0.323  loss_rpn_cls: 0.012  loss_rpn_loc: 0.057  time: 1.0200  data_time: 0.0076  lr: 0.000999  max_mem: 5406M
[32m[04/27 22:41:24 d2.utils.events]: [0m eta: 0:13:24  iter: 219  total_loss: 0.582  loss_cls: 0.188  loss_box_reg: 0.345  loss_rpn_cls: 0.011  loss_rpn_loc: 0.053  time: 1.0214  data_time: 0.0075  lr: 0.001099  max_mem: 5406M
[32m[04/27 22:41:45 d2.utils.events]: [0m eta: 0:13:05  iter: 239  total_loss: 0.528  loss_cls: 0.170  loss_box_reg: 0.321  loss_rpn_cls: 0.009  loss_rpn_loc: 0.041  time: 1.0233  data_time: 0.0075  lr: 0.001199  max_mem: 5406M
[32m[04/27 22:42:06 d2.utils.events]: [0m eta: 0:12:45  iter: 259  total_loss: 0.568  loss_cls: 0.180  loss_box_reg: 0.318  loss_rpn_cls: 0.011  loss_rpn_loc: 0.054  time: 1.0246  data_time: 0.0076  lr: 0.001299  max_mem: 5406M
[32m[04/27 22:42:26 d2.utils.events]: [0m eta: 0:12:25  iter: 279  total_loss: 0.508  loss_cls: 0.161  loss_box_reg: 0.304  loss_rpn_cls: 0.007  loss_rpn_loc: 0.054  time: 1.0241  data_time: 0.0074  lr: 0.001399  max_mem: 5406M
[32m[04/27 22:42:48 d2.utils.events]: [0m eta: 0:12:08  iter: 299  total_loss: 0.528  loss_cls: 0.169  loss_box_reg: 0.310  loss_rpn_cls: 0.009  loss_rpn_loc: 0.040  time: 1.0262  data_time: 0.0077  lr: 0.001499  max_mem: 5406M
[32m[04/27 22:43:08 d2.utils.events]: [0m eta: 0:11:44  iter: 319  total_loss: 0.576  loss_cls: 0.176  loss_box_reg: 0.330  loss_rpn_cls: 0.009  loss_rpn_loc: 0.062  time: 1.0255  data_time: 0.0075  lr: 0.001598  max_mem: 5406M
[32m[04/27 22:43:29 d2.utils.events]: [0m eta: 0:11:29  iter: 339  total_loss: 0.570  loss_cls: 0.176  loss_box_reg: 0.323  loss_rpn_cls: 0.007  loss_rpn_loc: 0.060  time: 1.0280  data_time: 0.0076  lr: 0.001698  max_mem: 5406M
[32m[04/27 22:43:50 d2.utils.events]: [0m eta: 0:11:09  iter: 359  total_loss: 0.548  loss_cls: 0.178  loss_box_reg: 0.310  loss_rpn_cls: 0.011  loss_rpn_loc: 0.042  time: 1.0289  data_time: 0.0081  lr: 0.001798  max_mem: 5406M
[32m[04/27 22:44:10 d2.utils.events]: [0m eta: 0:10:47  iter: 379  total_loss: 0.603  loss_cls: 0.178  loss_box_reg: 0.347  loss_rpn_cls: 0.009  loss_rpn_loc: 0.060  time: 1.0277  data_time: 0.0075  lr: 0.001898  max_mem: 5406M
[32m[04/27 22:44:31 d2.utils.events]: [0m eta: 0:10:28  iter: 399  total_loss: 0.581  loss_cls: 0.175  loss_box_reg: 0.314  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0289  data_time: 0.0076  lr: 0.001998  max_mem: 5406M
[32m[04/27 22:44:52 d2.utils.events]: [0m eta: 0:10:05  iter: 419  total_loss: 0.587  loss_cls: 0.190  loss_box_reg: 0.325  loss_rpn_cls: 0.014  loss_rpn_loc: 0.052  time: 1.0276  data_time: 0.0074  lr: 0.002098  max_mem: 5406M
[32m[04/27 22:45:12 d2.utils.events]: [0m eta: 0:09:44  iter: 439  total_loss: 0.586  loss_cls: 0.190  loss_box_reg: 0.321  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0277  data_time: 0.0079  lr: 0.002198  max_mem: 5406M
[32m[04/27 22:45:33 d2.utils.events]: [0m eta: 0:09:22  iter: 459  total_loss: 0.645  loss_cls: 0.199  loss_box_reg: 0.355  loss_rpn_cls: 0.015  loss_rpn_loc: 0.057  time: 1.0272  data_time: 0.0081  lr: 0.002298  max_mem: 5406M
[32m[04/27 22:45:54 d2.utils.events]: [0m eta: 0:09:02  iter: 479  total_loss: 0.640  loss_cls: 0.205  loss_box_reg: 0.332  loss_rpn_cls: 0.012  loss_rpn_loc: 0.053  time: 1.0280  data_time: 0.0075  lr: 0.002398  max_mem: 5406M
[32m[04/27 22:46:14 d2.utils.events]: [0m eta: 0:08:39  iter: 499  total_loss: 0.619  loss_cls: 0.209  loss_box_reg: 0.351  loss_rpn_cls: 0.012  loss_rpn_loc: 0.044  time: 1.0272  data_time: 0.0074  lr: 0.002498  max_mem: 5406M
[32m[04/27 22:46:35 d2.utils.events]: [0m eta: 0:08:19  iter: 519  total_loss: 0.603  loss_cls: 0.197  loss_box_reg: 0.344  loss_rpn_cls: 0.014  loss_rpn_loc: 0.054  time: 1.0276  data_time: 0.0073  lr: 0.002597  max_mem: 5406M
[32m[04/27 22:46:55 d2.utils.events]: [0m eta: 0:07:58  iter: 539  total_loss: 0.529  loss_cls: 0.166  loss_box_reg: 0.305  loss_rpn_cls: 0.012  loss_rpn_loc: 0.040  time: 1.0275  data_time: 0.0075  lr: 0.002697  max_mem: 5406M
[32m[04/27 22:47:16 d2.utils.events]: [0m eta: 0:07:37  iter: 559  total_loss: 0.627  loss_cls: 0.196  loss_box_reg: 0.348  loss_rpn_cls: 0.016  loss_rpn_loc: 0.056  time: 1.0273  data_time: 0.0080  lr: 0.002797  max_mem: 5406M
[32m[04/27 22:47:36 d2.utils.events]: [0m eta: 0:07:15  iter: 579  total_loss: 0.582  loss_cls: 0.167  loss_box_reg: 0.322  loss_rpn_cls: 0.012  loss_rpn_loc: 0.044  time: 1.0272  data_time: 0.0076  lr: 0.002897  max_mem: 5406M
[32m[04/27 22:47:56 d2.utils.events]: [0m eta: 0:06:54  iter: 599  total_loss: 0.540  loss_cls: 0.167  loss_box_reg: 0.320  loss_rpn_cls: 0.011  loss_rpn_loc: 0.044  time: 1.0261  data_time: 0.0074  lr: 0.002997  max_mem: 5406M
[32m[04/27 22:48:17 d2.utils.events]: [0m eta: 0:06:34  iter: 619  total_loss: 0.633  loss_cls: 0.204  loss_box_reg: 0.364  loss_rpn_cls: 0.016  loss_rpn_loc: 0.051  time: 1.0269  data_time: 0.0074  lr: 0.003097  max_mem: 5406M
[32m[04/27 22:48:38 d2.utils.events]: [0m eta: 0:06:13  iter: 639  total_loss: 0.589  loss_cls: 0.186  loss_box_reg: 0.320  loss_rpn_cls: 0.016  loss_rpn_loc: 0.046  time: 1.0268  data_time: 0.0073  lr: 0.003197  max_mem: 5406M
[32m[04/27 22:48:58 d2.utils.events]: [0m eta: 0:05:52  iter: 659  total_loss: 0.567  loss_cls: 0.172  loss_box_reg: 0.336  loss_rpn_cls: 0.012  loss_rpn_loc: 0.048  time: 1.0263  data_time: 0.0072  lr: 0.003297  max_mem: 5406M
[32m[04/27 22:49:19 d2.utils.events]: [0m eta: 0:05:31  iter: 679  total_loss: 0.608  loss_cls: 0.185  loss_box_reg: 0.350  loss_rpn_cls: 0.011  loss_rpn_loc: 0.052  time: 1.0263  data_time: 0.0081  lr: 0.003397  max_mem: 5406M
[32m[04/27 22:49:39 d2.utils.events]: [0m eta: 0:05:10  iter: 699  total_loss: 0.620  loss_cls: 0.204  loss_box_reg: 0.354  loss_rpn_cls: 0.012  loss_rpn_loc: 0.047  time: 1.0258  data_time: 0.0076  lr: 0.003497  max_mem: 5406M
[32m[04/27 22:49:59 d2.utils.events]: [0m eta: 0:04:50  iter: 719  total_loss: 0.604  loss_cls: 0.193  loss_box_reg: 0.356  loss_rpn_cls: 0.007  loss_rpn_loc: 0.052  time: 1.0256  data_time: 0.0075  lr: 0.003596  max_mem: 5406M
[32m[04/27 22:50:20 d2.utils.events]: [0m eta: 0:04:29  iter: 739  total_loss: 0.558  loss_cls: 0.188  loss_box_reg: 0.312  loss_rpn_cls: 0.010  loss_rpn_loc: 0.045  time: 1.0257  data_time: 0.0075  lr: 0.003696  max_mem: 5406M
[32m[04/27 22:50:41 d2.utils.events]: [0m eta: 0:04:08  iter: 759  total_loss: 0.634  loss_cls: 0.193  loss_box_reg: 0.371  loss_rpn_cls: 0.013  loss_rpn_loc: 0.052  time: 1.0260  data_time: 0.0075  lr: 0.003796  max_mem: 5406M
[32m[04/27 22:51:01 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.634  loss_cls: 0.200  loss_box_reg: 0.364  loss_rpn_cls: 0.012  loss_rpn_loc: 0.055  time: 1.0264  data_time: 0.0075  lr: 0.003896  max_mem: 5406M
[32m[04/27 22:51:22 d2.utils.events]: [0m eta: 0:03:27  iter: 799  total_loss: 0.629  loss_cls: 0.209  loss_box_reg: 0.347  loss_rpn_cls: 0.016  loss_rpn_loc: 0.056  time: 1.0266  data_time: 0.0076  lr: 0.003996  max_mem: 5406M
[32m[04/27 22:51:43 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.568  loss_cls: 0.186  loss_box_reg: 0.307  loss_rpn_cls: 0.013  loss_rpn_loc: 0.050  time: 1.0272  data_time: 0.0075  lr: 0.004096  max_mem: 5406M
[32m[04/27 22:52:03 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.615  loss_cls: 0.199  loss_box_reg: 0.350  loss_rpn_cls: 0.012  loss_rpn_loc: 0.046  time: 1.0266  data_time: 0.0074  lr: 0.004196  max_mem: 5406M
[32m[04/27 22:52:24 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.617  loss_cls: 0.188  loss_box_reg: 0.345  loss_rpn_cls: 0.012  loss_rpn_loc: 0.061  time: 1.0265  data_time: 0.0075  lr: 0.004296  max_mem: 5406M
[32m[04/27 22:52:45 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.655  loss_cls: 0.204  loss_box_reg: 0.365  loss_rpn_cls: 0.016  loss_rpn_loc: 0.066  time: 1.0268  data_time: 0.0074  lr: 0.004396  max_mem: 5406M
[32m[04/27 22:53:06 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.601  loss_cls: 0.204  loss_box_reg: 0.327  loss_rpn_cls: 0.014  loss_rpn_loc: 0.054  time: 1.0274  data_time: 0.0076  lr: 0.004496  max_mem: 5406M
[32m[04/27 22:53:26 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.587  loss_cls: 0.186  loss_box_reg: 0.338  loss_rpn_cls: 0.013  loss_rpn_loc: 0.065  time: 1.0273  data_time: 0.0081  lr: 0.004595  max_mem: 5406M
[32m[04/27 22:53:47 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.657  loss_cls: 0.209  loss_box_reg: 0.343  loss_rpn_cls: 0.017  loss_rpn_loc: 0.062  time: 1.0272  data_time: 0.0075  lr: 0.004695  max_mem: 5406M
[32m[04/27 22:54:07 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.591  loss_cls: 0.178  loss_box_reg: 0.348  loss_rpn_cls: 0.018  loss_rpn_loc: 0.051  time: 1.0271  data_time: 0.0075  lr: 0.004795  max_mem: 5406M
[32m[04/27 22:54:27 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.680  loss_cls: 0.205  loss_box_reg: 0.369  loss_rpn_cls: 0.016  loss_rpn_loc: 0.067  time: 1.0266  data_time: 0.0074  lr: 0.004895  max_mem: 5406M
[5m[31mWARNING[0m [32m[04/27 22:54:50 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 22:54:50 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/27 22:54:50 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/27 22:54:50 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.652  loss_cls: 0.203  loss_box_reg: 0.366  loss_rpn_cls: 0.015  loss_rpn_loc: 0.049  time: 1.0264  data_time: 0.0079  lr: 0.004995  max_mem: 5406M
[32m[04/27 22:54:51 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:04 (1.0274 s / it)
[32m[04/27 22:54:51 d2.engine.hooks]: [0mTotal training time: 0:17:09 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/27 22:54:52 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 22:54:52 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/27 22:54:53 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/27 22:54:54 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1143 s / img. ETA=0:16:06
[32m[04/27 22:54:59 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1139 s / img. ETA=0:15:59
[32m[04/27 22:55:04 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1138 s / img. ETA=0:15:54
[32m[04/27 22:55:09 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1139 s / img. ETA=0:15:49
[32m[04/27 22:55:14 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1138 s / img. ETA=0:15:44
[32m[04/27 22:55:19 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1139 s / img. ETA=0:15:39
[32m[04/27 22:55:24 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1139 s / img. ETA=0:15:34
[32m[04/27 22:55:30 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1139 s / img. ETA=0:15:29
[32m[04/27 22:55:35 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1139 s / img. ETA=0:15:24
[32m[04/27 22:55:40 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1140 s / img. ETA=0:15:19
[32m[04/27 22:55:45 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1140 s / img. ETA=0:15:14
[32m[04/27 22:55:50 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1140 s / img. ETA=0:15:09
[32m[04/27 22:55:55 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1139 s / img. ETA=0:15:04
[32m[04/27 22:56:00 d2.evaluation.evaluator]: [0mInference done 582/8355. 0.1140 s / img. ETA=0:14:59
[32m[04/27 22:56:05 d2.evaluation.evaluator]: [0mInference done 625/8355. 0.1141 s / img. ETA=0:14:55
[32m[04/27 22:56:10 d2.evaluation.evaluator]: [0mInference done 668/8355. 0.1141 s / img. ETA=0:14:50
[32m[04/27 22:56:15 d2.evaluation.evaluator]: [0mInference done 711/8355. 0.1141 s / img. ETA=0:14:45
[32m[04/27 22:56:20 d2.evaluation.evaluator]: [0mInference done 754/8355. 0.1142 s / img. ETA=0:14:41
[32m[04/27 22:56:25 d2.evaluation.evaluator]: [0mInference done 797/8355. 0.1143 s / img. ETA=0:14:37
[32m[04/27 22:56:30 d2.evaluation.evaluator]: [0mInference done 841/8355. 0.1143 s / img. ETA=0:14:32
[32m[04/27 22:56:35 d2.evaluation.evaluator]: [0mInference done 884/8355. 0.1143 s / img. ETA=0:14:27
[32m[04/27 22:56:40 d2.evaluation.evaluator]: [0mInference done 927/8355. 0.1144 s / img. ETA=0:14:22
[32m[04/27 22:56:45 d2.evaluation.evaluator]: [0mInference done 971/8355. 0.1144 s / img. ETA=0:14:17
[32m[04/27 22:56:51 d2.evaluation.evaluator]: [0mInference done 1015/8355. 0.1144 s / img. ETA=0:14:12
[32m[04/27 22:56:56 d2.evaluation.evaluator]: [0mInference done 1058/8355. 0.1144 s / img. ETA=0:14:07
[32m[04/27 22:57:01 d2.evaluation.evaluator]: [0mInference done 1102/8355. 0.1144 s / img. ETA=0:14:02
[32m[04/27 22:57:06 d2.evaluation.evaluator]: [0mInference done 1146/8355. 0.1144 s / img. ETA=0:13:57
[32m[04/27 22:57:11 d2.evaluation.evaluator]: [0mInference done 1190/8355. 0.1144 s / img. ETA=0:13:52
[32m[04/27 22:57:16 d2.evaluation.evaluator]: [0mInference done 1233/8355. 0.1144 s / img. ETA=0:13:47
[32m[04/27 22:57:21 d2.evaluation.evaluator]: [0mInference done 1277/8355. 0.1144 s / img. ETA=0:13:42
[32m[04/27 22:57:26 d2.evaluation.evaluator]: [0mInference done 1321/8355. 0.1144 s / img. ETA=0:13:36
[32m[04/27 22:57:31 d2.evaluation.evaluator]: [0mInference done 1364/8355. 0.1144 s / img. ETA=0:13:31
[32m[04/27 22:57:36 d2.evaluation.evaluator]: [0mInference done 1408/8355. 0.1144 s / img. ETA=0:13:26
[32m[04/27 22:57:41 d2.evaluation.evaluator]: [0mInference done 1451/8355. 0.1144 s / img. ETA=0:13:21
[32m[04/27 22:57:46 d2.evaluation.evaluator]: [0mInference done 1494/8355. 0.1144 s / img. ETA=0:13:17
[32m[04/27 22:57:51 d2.evaluation.evaluator]: [0mInference done 1537/8355. 0.1145 s / img. ETA=0:13:12
[32m[04/27 22:57:56 d2.evaluation.evaluator]: [0mInference done 1580/8355. 0.1145 s / img. ETA=0:13:07
[32m[04/27 22:58:01 d2.evaluation.evaluator]: [0mInference done 1623/8355. 0.1146 s / img. ETA=0:13:03
[32m[04/27 22:58:07 d2.evaluation.evaluator]: [0mInference done 1666/8355. 0.1146 s / img. ETA=0:12:58
[32m[04/27 22:58:12 d2.evaluation.evaluator]: [0mInference done 1708/8355. 0.1147 s / img. ETA=0:12:53
[32m[04/27 22:58:17 d2.evaluation.evaluator]: [0mInference done 1751/8355. 0.1147 s / img. ETA=0:12:49
[32m[04/27 22:58:22 d2.evaluation.evaluator]: [0mInference done 1794/8355. 0.1147 s / img. ETA=0:12:44
[32m[04/27 22:58:27 d2.evaluation.evaluator]: [0mInference done 1837/8355. 0.1148 s / img. ETA=0:12:39
[32m[04/27 22:58:32 d2.evaluation.evaluator]: [0mInference done 1880/8355. 0.1148 s / img. ETA=0:12:34
[32m[04/27 22:58:37 d2.evaluation.evaluator]: [0mInference done 1923/8355. 0.1148 s / img. ETA=0:12:29
[32m[04/27 22:58:42 d2.evaluation.evaluator]: [0mInference done 1965/8355. 0.1149 s / img. ETA=0:12:25
[32m[04/27 22:58:47 d2.evaluation.evaluator]: [0mInference done 2008/8355. 0.1149 s / img. ETA=0:12:20
[32m[04/27 22:58:52 d2.evaluation.evaluator]: [0mInference done 2051/8355. 0.1149 s / img. ETA=0:12:15
[32m[04/27 22:58:57 d2.evaluation.evaluator]: [0mInference done 2094/8355. 0.1149 s / img. ETA=0:12:10
[32m[04/27 22:59:02 d2.evaluation.evaluator]: [0mInference done 2137/8355. 0.1149 s / img. ETA=0:12:05
[32m[04/27 22:59:07 d2.evaluation.evaluator]: [0mInference done 2180/8355. 0.1149 s / img. ETA=0:12:00
[32m[04/27 22:59:12 d2.evaluation.evaluator]: [0mInference done 2223/8355. 0.1149 s / img. ETA=0:11:55
[32m[04/27 22:59:17 d2.evaluation.evaluator]: [0mInference done 2266/8355. 0.1149 s / img. ETA=0:11:50
[32m[04/27 22:59:22 d2.evaluation.evaluator]: [0mInference done 2309/8355. 0.1149 s / img. ETA=0:11:45
[32m[04/27 22:59:27 d2.evaluation.evaluator]: [0mInference done 2352/8355. 0.1150 s / img. ETA=0:11:40
[32m[04/27 22:59:32 d2.evaluation.evaluator]: [0mInference done 2395/8355. 0.1150 s / img. ETA=0:11:35
[32m[04/27 22:59:37 d2.evaluation.evaluator]: [0mInference done 2438/8355. 0.1150 s / img. ETA=0:11:30
[32m[04/27 22:59:42 d2.evaluation.evaluator]: [0mInference done 2481/8355. 0.1150 s / img. ETA=0:11:25
[32m[04/27 22:59:47 d2.evaluation.evaluator]: [0mInference done 2524/8355. 0.1150 s / img. ETA=0:11:20
[32m[04/27 22:59:52 d2.evaluation.evaluator]: [0mInference done 2566/8355. 0.1150 s / img. ETA=0:11:16
[32m[04/27 22:59:57 d2.evaluation.evaluator]: [0mInference done 2609/8355. 0.1150 s / img. ETA=0:11:11
[32m[04/27 23:00:02 d2.evaluation.evaluator]: [0mInference done 2652/8355. 0.1150 s / img. ETA=0:11:06
[32m[04/27 23:00:08 d2.evaluation.evaluator]: [0mInference done 2695/8355. 0.1150 s / img. ETA=0:11:01
[32m[04/27 23:00:13 d2.evaluation.evaluator]: [0mInference done 2738/8355. 0.1150 s / img. ETA=0:10:56
[32m[04/27 23:00:18 d2.evaluation.evaluator]: [0mInference done 2780/8355. 0.1151 s / img. ETA=0:10:51
[32m[04/27 23:00:23 d2.evaluation.evaluator]: [0mInference done 2823/8355. 0.1151 s / img. ETA=0:10:46
[32m[04/27 23:00:28 d2.evaluation.evaluator]: [0mInference done 2866/8355. 0.1151 s / img. ETA=0:10:41
[32m[04/27 23:00:33 d2.evaluation.evaluator]: [0mInference done 2909/8355. 0.1151 s / img. ETA=0:10:36
[32m[04/27 23:00:38 d2.evaluation.evaluator]: [0mInference done 2952/8355. 0.1151 s / img. ETA=0:10:31
[32m[04/27 23:00:43 d2.evaluation.evaluator]: [0mInference done 2995/8355. 0.1151 s / img. ETA=0:10:26
[32m[04/27 23:00:48 d2.evaluation.evaluator]: [0mInference done 3038/8355. 0.1151 s / img. ETA=0:10:21
[32m[04/27 23:00:53 d2.evaluation.evaluator]: [0mInference done 3081/8355. 0.1151 s / img. ETA=0:10:16
[32m[04/27 23:00:58 d2.evaluation.evaluator]: [0mInference done 3124/8355. 0.1151 s / img. ETA=0:10:11
[32m[04/27 23:01:03 d2.evaluation.evaluator]: [0mInference done 3168/8355. 0.1151 s / img. ETA=0:10:06
[32m[04/27 23:01:08 d2.evaluation.evaluator]: [0mInference done 3212/8355. 0.1151 s / img. ETA=0:10:01
[32m[04/27 23:01:13 d2.evaluation.evaluator]: [0mInference done 3255/8355. 0.1151 s / img. ETA=0:09:56
[32m[04/27 23:01:18 d2.evaluation.evaluator]: [0mInference done 3298/8355. 0.1151 s / img. ETA=0:09:51
[32m[04/27 23:01:23 d2.evaluation.evaluator]: [0mInference done 3341/8355. 0.1151 s / img. ETA=0:09:46
[32m[04/27 23:01:28 d2.evaluation.evaluator]: [0mInference done 3384/8355. 0.1151 s / img. ETA=0:09:41
[32m[04/27 23:01:33 d2.evaluation.evaluator]: [0mInference done 3427/8355. 0.1151 s / img. ETA=0:09:36
[32m[04/27 23:01:38 d2.evaluation.evaluator]: [0mInference done 3470/8355. 0.1151 s / img. ETA=0:09:31
[32m[04/27 23:01:43 d2.evaluation.evaluator]: [0mInference done 3513/8355. 0.1151 s / img. ETA=0:09:26
[32m[04/27 23:01:48 d2.evaluation.evaluator]: [0mInference done 3556/8355. 0.1151 s / img. ETA=0:09:21
[32m[04/27 23:01:53 d2.evaluation.evaluator]: [0mInference done 3599/8355. 0.1151 s / img. ETA=0:09:15
[32m[04/27 23:01:58 d2.evaluation.evaluator]: [0mInference done 3642/8355. 0.1151 s / img. ETA=0:09:10
[32m[04/27 23:02:03 d2.evaluation.evaluator]: [0mInference done 3685/8355. 0.1151 s / img. ETA=0:09:05
[32m[04/27 23:02:09 d2.evaluation.evaluator]: [0mInference done 3728/8355. 0.1151 s / img. ETA=0:09:00
[32m[04/27 23:02:14 d2.evaluation.evaluator]: [0mInference done 3771/8355. 0.1151 s / img. ETA=0:08:55
[32m[04/27 23:02:19 d2.evaluation.evaluator]: [0mInference done 3814/8355. 0.1151 s / img. ETA=0:08:50
[32m[04/27 23:02:24 d2.evaluation.evaluator]: [0mInference done 3857/8355. 0.1151 s / img. ETA=0:08:45
[32m[04/27 23:02:29 d2.evaluation.evaluator]: [0mInference done 3901/8355. 0.1151 s / img. ETA=0:08:40
[32m[04/27 23:02:34 d2.evaluation.evaluator]: [0mInference done 3944/8355. 0.1151 s / img. ETA=0:08:35
[32m[04/27 23:02:39 d2.evaluation.evaluator]: [0mInference done 3987/8355. 0.1151 s / img. ETA=0:08:30
[32m[04/27 23:02:44 d2.evaluation.evaluator]: [0mInference done 4030/8355. 0.1151 s / img. ETA=0:08:25
[32m[04/27 23:02:49 d2.evaluation.evaluator]: [0mInference done 4073/8355. 0.1151 s / img. ETA=0:08:20
[32m[04/27 23:02:54 d2.evaluation.evaluator]: [0mInference done 4116/8355. 0.1151 s / img. ETA=0:08:15
[32m[04/27 23:02:59 d2.evaluation.evaluator]: [0mInference done 4159/8355. 0.1152 s / img. ETA=0:08:10
[32m[04/27 23:03:04 d2.evaluation.evaluator]: [0mInference done 4202/8355. 0.1152 s / img. ETA=0:08:05
[32m[04/27 23:03:09 d2.evaluation.evaluator]: [0mInference done 4245/8355. 0.1152 s / img. ETA=0:08:00
[32m[04/27 23:03:14 d2.evaluation.evaluator]: [0mInference done 4288/8355. 0.1152 s / img. ETA=0:07:55
[32m[04/27 23:03:19 d2.evaluation.evaluator]: [0mInference done 4331/8355. 0.1152 s / img. ETA=0:07:50
[32m[04/27 23:03:24 d2.evaluation.evaluator]: [0mInference done 4375/8355. 0.1151 s / img. ETA=0:07:45
[32m[04/27 23:03:29 d2.evaluation.evaluator]: [0mInference done 4418/8355. 0.1152 s / img. ETA=0:07:40
[32m[04/27 23:03:34 d2.evaluation.evaluator]: [0mInference done 4461/8355. 0.1152 s / img. ETA=0:07:35
[32m[04/27 23:03:39 d2.evaluation.evaluator]: [0mInference done 4504/8355. 0.1152 s / img. ETA=0:07:30
[32m[04/27 23:03:44 d2.evaluation.evaluator]: [0mInference done 4547/8355. 0.1152 s / img. ETA=0:07:25
[32m[04/27 23:03:50 d2.evaluation.evaluator]: [0mInference done 4590/8355. 0.1152 s / img. ETA=0:07:20
[32m[04/27 23:03:55 d2.evaluation.evaluator]: [0mInference done 4633/8355. 0.1152 s / img. ETA=0:07:15
[32m[04/27 23:04:00 d2.evaluation.evaluator]: [0mInference done 4676/8355. 0.1152 s / img. ETA=0:07:10
[32m[04/27 23:04:05 d2.evaluation.evaluator]: [0mInference done 4719/8355. 0.1152 s / img. ETA=0:07:05
[32m[04/27 23:04:10 d2.evaluation.evaluator]: [0mInference done 4762/8355. 0.1152 s / img. ETA=0:07:00
[32m[04/27 23:04:15 d2.evaluation.evaluator]: [0mInference done 4805/8355. 0.1152 s / img. ETA=0:06:55
[32m[04/27 23:04:20 d2.evaluation.evaluator]: [0mInference done 4848/8355. 0.1152 s / img. ETA=0:06:50
[32m[04/27 23:04:25 d2.evaluation.evaluator]: [0mInference done 4891/8355. 0.1152 s / img. ETA=0:06:45
[32m[04/27 23:04:30 d2.evaluation.evaluator]: [0mInference done 4934/8355. 0.1152 s / img. ETA=0:06:40
[32m[04/27 23:04:35 d2.evaluation.evaluator]: [0mInference done 4977/8355. 0.1152 s / img. ETA=0:06:35
[32m[04/27 23:04:40 d2.evaluation.evaluator]: [0mInference done 5020/8355. 0.1152 s / img. ETA=0:06:30
[32m[04/27 23:04:45 d2.evaluation.evaluator]: [0mInference done 5063/8355. 0.1152 s / img. ETA=0:06:25
[32m[04/27 23:04:50 d2.evaluation.evaluator]: [0mInference done 5106/8355. 0.1152 s / img. ETA=0:06:20
[32m[04/27 23:04:55 d2.evaluation.evaluator]: [0mInference done 5149/8355. 0.1152 s / img. ETA=0:06:15
[32m[04/27 23:05:00 d2.evaluation.evaluator]: [0mInference done 5192/8355. 0.1152 s / img. ETA=0:06:10
[32m[04/27 23:05:05 d2.evaluation.evaluator]: [0mInference done 5235/8355. 0.1152 s / img. ETA=0:06:05
[32m[04/27 23:05:10 d2.evaluation.evaluator]: [0mInference done 5278/8355. 0.1152 s / img. ETA=0:05:59
[32m[04/27 23:05:15 d2.evaluation.evaluator]: [0mInference done 5321/8355. 0.1152 s / img. ETA=0:05:54
[32m[04/27 23:05:20 d2.evaluation.evaluator]: [0mInference done 5364/8355. 0.1152 s / img. ETA=0:05:49
[32m[04/27 23:05:25 d2.evaluation.evaluator]: [0mInference done 5407/8355. 0.1152 s / img. ETA=0:05:44
[32m[04/27 23:05:30 d2.evaluation.evaluator]: [0mInference done 5450/8355. 0.1152 s / img. ETA=0:05:39
[32m[04/27 23:05:35 d2.evaluation.evaluator]: [0mInference done 5493/8355. 0.1152 s / img. ETA=0:05:34
[32m[04/27 23:05:40 d2.evaluation.evaluator]: [0mInference done 5536/8355. 0.1152 s / img. ETA=0:05:29
[32m[04/27 23:05:45 d2.evaluation.evaluator]: [0mInference done 5579/8355. 0.1152 s / img. ETA=0:05:24
[32m[04/27 23:05:50 d2.evaluation.evaluator]: [0mInference done 5622/8355. 0.1152 s / img. ETA=0:05:19
[32m[04/27 23:05:55 d2.evaluation.evaluator]: [0mInference done 5665/8355. 0.1152 s / img. ETA=0:05:14
[32m[04/27 23:06:01 d2.evaluation.evaluator]: [0mInference done 5708/8355. 0.1152 s / img. ETA=0:05:09
[32m[04/27 23:06:06 d2.evaluation.evaluator]: [0mInference done 5751/8355. 0.1152 s / img. ETA=0:05:04
[32m[04/27 23:06:11 d2.evaluation.evaluator]: [0mInference done 5794/8355. 0.1152 s / img. ETA=0:04:59
[32m[04/27 23:06:16 d2.evaluation.evaluator]: [0mInference done 5837/8355. 0.1152 s / img. ETA=0:04:54
[32m[04/27 23:06:21 d2.evaluation.evaluator]: [0mInference done 5879/8355. 0.1152 s / img. ETA=0:04:49
[32m[04/27 23:06:26 d2.evaluation.evaluator]: [0mInference done 5922/8355. 0.1153 s / img. ETA=0:04:44
[32m[04/27 23:06:31 d2.evaluation.evaluator]: [0mInference done 5965/8355. 0.1153 s / img. ETA=0:04:39
[32m[04/27 23:06:36 d2.evaluation.evaluator]: [0mInference done 6008/8355. 0.1153 s / img. ETA=0:04:34
[32m[04/27 23:06:41 d2.evaluation.evaluator]: [0mInference done 6051/8355. 0.1153 s / img. ETA=0:04:29
[32m[04/27 23:06:46 d2.evaluation.evaluator]: [0mInference done 6094/8355. 0.1153 s / img. ETA=0:04:24
[32m[04/27 23:06:51 d2.evaluation.evaluator]: [0mInference done 6137/8355. 0.1153 s / img. ETA=0:04:19
[32m[04/27 23:06:56 d2.evaluation.evaluator]: [0mInference done 6180/8355. 0.1153 s / img. ETA=0:04:14
[32m[04/27 23:07:01 d2.evaluation.evaluator]: [0mInference done 6222/8355. 0.1153 s / img. ETA=0:04:09
[32m[04/27 23:07:06 d2.evaluation.evaluator]: [0mInference done 6265/8355. 0.1153 s / img. ETA=0:04:04
[32m[04/27 23:07:11 d2.evaluation.evaluator]: [0mInference done 6308/8355. 0.1153 s / img. ETA=0:03:59
[32m[04/27 23:07:16 d2.evaluation.evaluator]: [0mInference done 6351/8355. 0.1153 s / img. ETA=0:03:54
[32m[04/27 23:07:22 d2.evaluation.evaluator]: [0mInference done 6394/8355. 0.1153 s / img. ETA=0:03:49
[32m[04/27 23:07:27 d2.evaluation.evaluator]: [0mInference done 6437/8355. 0.1153 s / img. ETA=0:03:44
[32m[04/27 23:07:32 d2.evaluation.evaluator]: [0mInference done 6480/8355. 0.1153 s / img. ETA=0:03:39
[32m[04/27 23:07:37 d2.evaluation.evaluator]: [0mInference done 6523/8355. 0.1153 s / img. ETA=0:03:34
[32m[04/27 23:07:42 d2.evaluation.evaluator]: [0mInference done 6567/8355. 0.1153 s / img. ETA=0:03:29
[32m[04/27 23:07:47 d2.evaluation.evaluator]: [0mInference done 6610/8355. 0.1153 s / img. ETA=0:03:24
[32m[04/27 23:07:52 d2.evaluation.evaluator]: [0mInference done 6654/8355. 0.1153 s / img. ETA=0:03:19
[32m[04/27 23:07:57 d2.evaluation.evaluator]: [0mInference done 6697/8355. 0.1153 s / img. ETA=0:03:14
[32m[04/27 23:08:02 d2.evaluation.evaluator]: [0mInference done 6741/8355. 0.1153 s / img. ETA=0:03:09
[32m[04/27 23:08:07 d2.evaluation.evaluator]: [0mInference done 6785/8355. 0.1153 s / img. ETA=0:03:03
[32m[04/27 23:08:12 d2.evaluation.evaluator]: [0mInference done 6828/8355. 0.1153 s / img. ETA=0:02:58
[32m[04/27 23:08:17 d2.evaluation.evaluator]: [0mInference done 6871/8355. 0.1153 s / img. ETA=0:02:53
[32m[04/27 23:08:22 d2.evaluation.evaluator]: [0mInference done 6914/8355. 0.1153 s / img. ETA=0:02:48
[32m[04/27 23:08:27 d2.evaluation.evaluator]: [0mInference done 6957/8355. 0.1153 s / img. ETA=0:02:43
[32m[04/27 23:08:32 d2.evaluation.evaluator]: [0mInference done 7000/8355. 0.1153 s / img. ETA=0:02:38
[32m[04/27 23:08:37 d2.evaluation.evaluator]: [0mInference done 7043/8355. 0.1153 s / img. ETA=0:02:33
[32m[04/27 23:08:43 d2.evaluation.evaluator]: [0mInference done 7086/8355. 0.1153 s / img. ETA=0:02:28
[32m[04/27 23:08:48 d2.evaluation.evaluator]: [0mInference done 7129/8355. 0.1153 s / img. ETA=0:02:23
[32m[04/27 23:08:53 d2.evaluation.evaluator]: [0mInference done 7171/8355. 0.1154 s / img. ETA=0:02:18
[32m[04/27 23:08:58 d2.evaluation.evaluator]: [0mInference done 7214/8355. 0.1154 s / img. ETA=0:02:13
[32m[04/27 23:09:03 d2.evaluation.evaluator]: [0mInference done 7257/8355. 0.1154 s / img. ETA=0:02:08
[32m[04/27 23:09:08 d2.evaluation.evaluator]: [0mInference done 7300/8355. 0.1154 s / img. ETA=0:02:03
[32m[04/27 23:09:13 d2.evaluation.evaluator]: [0mInference done 7343/8355. 0.1154 s / img. ETA=0:01:58
[32m[04/27 23:09:18 d2.evaluation.evaluator]: [0mInference done 7386/8355. 0.1154 s / img. ETA=0:01:53
[32m[04/27 23:09:23 d2.evaluation.evaluator]: [0mInference done 7429/8355. 0.1154 s / img. ETA=0:01:48
[32m[04/27 23:09:28 d2.evaluation.evaluator]: [0mInference done 7472/8355. 0.1154 s / img. ETA=0:01:43
[32m[04/27 23:09:33 d2.evaluation.evaluator]: [0mInference done 7515/8355. 0.1154 s / img. ETA=0:01:38
[32m[04/27 23:09:38 d2.evaluation.evaluator]: [0mInference done 7558/8355. 0.1154 s / img. ETA=0:01:33
[32m[04/27 23:09:43 d2.evaluation.evaluator]: [0mInference done 7601/8355. 0.1154 s / img. ETA=0:01:28
[32m[04/27 23:09:48 d2.evaluation.evaluator]: [0mInference done 7644/8355. 0.1154 s / img. ETA=0:01:23
[32m[04/27 23:09:53 d2.evaluation.evaluator]: [0mInference done 7687/8355. 0.1154 s / img. ETA=0:01:18
[32m[04/27 23:09:59 d2.evaluation.evaluator]: [0mInference done 7730/8355. 0.1154 s / img. ETA=0:01:13
[32m[04/27 23:10:04 d2.evaluation.evaluator]: [0mInference done 7773/8355. 0.1154 s / img. ETA=0:01:08
[32m[04/27 23:10:09 d2.evaluation.evaluator]: [0mInference done 7816/8355. 0.1154 s / img. ETA=0:01:03
[32m[04/27 23:10:14 d2.evaluation.evaluator]: [0mInference done 7859/8355. 0.1154 s / img. ETA=0:00:58
[32m[04/27 23:10:19 d2.evaluation.evaluator]: [0mInference done 7902/8355. 0.1154 s / img. ETA=0:00:53
[32m[04/27 23:10:24 d2.evaluation.evaluator]: [0mInference done 7945/8355. 0.1154 s / img. ETA=0:00:48
[32m[04/27 23:10:29 d2.evaluation.evaluator]: [0mInference done 7988/8355. 0.1154 s / img. ETA=0:00:43
[32m[04/27 23:10:34 d2.evaluation.evaluator]: [0mInference done 8031/8355. 0.1154 s / img. ETA=0:00:37
[32m[04/27 23:10:39 d2.evaluation.evaluator]: [0mInference done 8074/8355. 0.1154 s / img. ETA=0:00:32
[32m[04/27 23:10:44 d2.evaluation.evaluator]: [0mInference done 8118/8355. 0.1154 s / img. ETA=0:00:27
[32m[04/27 23:10:49 d2.evaluation.evaluator]: [0mInference done 8161/8355. 0.1154 s / img. ETA=0:00:22
[32m[04/27 23:10:54 d2.evaluation.evaluator]: [0mInference done 8204/8355. 0.1154 s / img. ETA=0:00:17
[32m[04/27 23:10:59 d2.evaluation.evaluator]: [0mInference done 8247/8355. 0.1154 s / img. ETA=0:00:12
[32m[04/27 23:11:04 d2.evaluation.evaluator]: [0mInference done 8290/8355. 0.1154 s / img. ETA=0:00:07
[32m[04/27 23:11:09 d2.evaluation.evaluator]: [0mInference done 8333/8355. 0.1154 s / img. ETA=0:00:02
[32m[04/27 23:11:12 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:18.659480 (0.117205 s / img per device, on 1 devices)
[32m[04/27 23:11:12 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:03 (0.115428 s / img per device, on 1 devices)
[32m[04/27 23:11:12 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/27 23:11:12 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/27 23:11:12 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.43s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.68s).
Accumulating evaluation results...
DONE (t=2.24s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.416
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.762
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.399
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.316
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.540
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.159
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.469
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.396
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.695
[32m[04/27 23:11:36 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.587 | 76.234 | 39.938 | 31.551 | 54.032 | 64.237 |
[32m[04/27 23:11:36 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 43.448 | bicycle       | 29.198 | car            | 52.116 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/27 23:11:36 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 23:11:36 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/27 23:11:36 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/27 23:11:38 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1144 s / img. ETA=0:02:24
[32m[04/27 23:11:43 d2.evaluation.evaluator]: [0mInference done 55/1257. 0.1144 s / img. ETA=0:02:19
[32m[04/27 23:11:48 d2.evaluation.evaluator]: [0mInference done 99/1257. 0.1145 s / img. ETA=0:02:14
[32m[04/27 23:11:53 d2.evaluation.evaluator]: [0mInference done 143/1257. 0.1144 s / img. ETA=0:02:09
[32m[04/27 23:11:58 d2.evaluation.evaluator]: [0mInference done 186/1257. 0.1145 s / img. ETA=0:02:04
[32m[04/27 23:12:03 d2.evaluation.evaluator]: [0mInference done 230/1257. 0.1145 s / img. ETA=0:01:59
[32m[04/27 23:12:08 d2.evaluation.evaluator]: [0mInference done 273/1257. 0.1146 s / img. ETA=0:01:54
[32m[04/27 23:12:13 d2.evaluation.evaluator]: [0mInference done 317/1257. 0.1146 s / img. ETA=0:01:49
[32m[04/27 23:12:19 d2.evaluation.evaluator]: [0mInference done 361/1257. 0.1146 s / img. ETA=0:01:44
[32m[04/27 23:12:24 d2.evaluation.evaluator]: [0mInference done 405/1257. 0.1146 s / img. ETA=0:01:39
[32m[04/27 23:12:29 d2.evaluation.evaluator]: [0mInference done 449/1257. 0.1145 s / img. ETA=0:01:33
[32m[04/27 23:12:34 d2.evaluation.evaluator]: [0mInference done 493/1257. 0.1145 s / img. ETA=0:01:28
[32m[04/27 23:12:39 d2.evaluation.evaluator]: [0mInference done 536/1257. 0.1145 s / img. ETA=0:01:23
[32m[04/27 23:12:44 d2.evaluation.evaluator]: [0mInference done 579/1257. 0.1146 s / img. ETA=0:01:18
[32m[04/27 23:12:49 d2.evaluation.evaluator]: [0mInference done 622/1257. 0.1146 s / img. ETA=0:01:13
[32m[04/27 23:12:54 d2.evaluation.evaluator]: [0mInference done 665/1257. 0.1146 s / img. ETA=0:01:08
[32m[04/27 23:12:59 d2.evaluation.evaluator]: [0mInference done 708/1257. 0.1146 s / img. ETA=0:01:03
[32m[04/27 23:13:04 d2.evaluation.evaluator]: [0mInference done 751/1257. 0.1146 s / img. ETA=0:00:58
[32m[04/27 23:13:09 d2.evaluation.evaluator]: [0mInference done 795/1257. 0.1146 s / img. ETA=0:00:53
[32m[04/27 23:13:14 d2.evaluation.evaluator]: [0mInference done 838/1257. 0.1146 s / img. ETA=0:00:48
[32m[04/27 23:13:19 d2.evaluation.evaluator]: [0mInference done 881/1257. 0.1147 s / img. ETA=0:00:43
[32m[04/27 23:13:24 d2.evaluation.evaluator]: [0mInference done 924/1257. 0.1147 s / img. ETA=0:00:38
[32m[04/27 23:13:29 d2.evaluation.evaluator]: [0mInference done 967/1257. 0.1147 s / img. ETA=0:00:33
[32m[04/27 23:13:34 d2.evaluation.evaluator]: [0mInference done 1010/1257. 0.1147 s / img. ETA=0:00:28
[32m[04/27 23:13:39 d2.evaluation.evaluator]: [0mInference done 1053/1257. 0.1147 s / img. ETA=0:00:23
[32m[04/27 23:13:44 d2.evaluation.evaluator]: [0mInference done 1096/1257. 0.1147 s / img. ETA=0:00:18
[32m[04/27 23:13:49 d2.evaluation.evaluator]: [0mInference done 1139/1257. 0.1148 s / img. ETA=0:00:13
[32m[04/27 23:13:54 d2.evaluation.evaluator]: [0mInference done 1182/1257. 0.1148 s / img. ETA=0:00:08
[32m[04/27 23:13:59 d2.evaluation.evaluator]: [0mInference done 1225/1257. 0.1148 s / img. ETA=0:00:03
[32m[04/27 23:14:03 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:25.956555 (0.116579 s / img per device, on 1 devices)
[32m[04/27 23:14:03 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:23 (0.114825 s / img per device, on 1 devices)
[32m[04/27 23:14:03 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/27 23:14:03 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/27 23:14:03 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.94s).
Accumulating evaluation results...
DONE (t=0.38s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.400
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.755
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.365
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.305
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.461
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.520
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.472
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.403
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.566
[32m[04/27 23:14:07 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.966 | 75.464 | 36.455 | 30.492 | 46.085 | 51.972 |
[32m[04/27 23:14:07 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 43.202 | bicycle       | 22.160 | car            | 54.536 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  2  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/27 23:14:07 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/27 23:14:08 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 23:14:08 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/27 23:14:08 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/27 23:14:08 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/27 23:14:08 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/27 23:14:08 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/27 23:14:29 d2.utils.events]: [0m eta: 0:17:15  iter: 19  total_loss: 0.575  loss_cls: 0.192  loss_box_reg: 0.326  loss_rpn_cls: 0.015  loss_rpn_loc: 0.051  time: 1.0302  data_time: 0.0176  lr: 0.000100  max_mem: 5406M
[32m[04/27 23:14:49 d2.utils.events]: [0m eta: 0:16:45  iter: 39  total_loss: 0.526  loss_cls: 0.182  loss_box_reg: 0.307  loss_rpn_cls: 0.013  loss_rpn_loc: 0.043  time: 1.0282  data_time: 0.0075  lr: 0.000200  max_mem: 5406M
[32m[04/27 23:15:10 d2.utils.events]: [0m eta: 0:16:15  iter: 59  total_loss: 0.516  loss_cls: 0.153  loss_box_reg: 0.291  loss_rpn_cls: 0.012  loss_rpn_loc: 0.049  time: 1.0239  data_time: 0.0076  lr: 0.000300  max_mem: 5406M
[32m[04/27 23:15:30 d2.utils.events]: [0m eta: 0:15:41  iter: 79  total_loss: 0.629  loss_cls: 0.204  loss_box_reg: 0.358  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0190  data_time: 0.0076  lr: 0.000400  max_mem: 5406M
[32m[04/27 23:15:51 d2.utils.events]: [0m eta: 0:15:26  iter: 99  total_loss: 0.566  loss_cls: 0.172  loss_box_reg: 0.306  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0223  data_time: 0.0078  lr: 0.000500  max_mem: 5406M
[32m[04/27 23:16:12 d2.utils.events]: [0m eta: 0:15:11  iter: 119  total_loss: 0.615  loss_cls: 0.188  loss_box_reg: 0.353  loss_rpn_cls: 0.013  loss_rpn_loc: 0.047  time: 1.0252  data_time: 0.0081  lr: 0.000599  max_mem: 5406M
[32m[04/27 23:16:32 d2.utils.events]: [0m eta: 0:14:43  iter: 139  total_loss: 0.624  loss_cls: 0.200  loss_box_reg: 0.346  loss_rpn_cls: 0.012  loss_rpn_loc: 0.059  time: 1.0220  data_time: 0.0075  lr: 0.000699  max_mem: 5406M
[32m[04/27 23:16:53 d2.utils.events]: [0m eta: 0:14:23  iter: 159  total_loss: 0.583  loss_cls: 0.194  loss_box_reg: 0.323  loss_rpn_cls: 0.016  loss_rpn_loc: 0.050  time: 1.0241  data_time: 0.0075  lr: 0.000799  max_mem: 5406M
[32m[04/27 23:17:14 d2.utils.events]: [0m eta: 0:14:10  iter: 179  total_loss: 0.585  loss_cls: 0.188  loss_box_reg: 0.337  loss_rpn_cls: 0.013  loss_rpn_loc: 0.049  time: 1.0275  data_time: 0.0076  lr: 0.000899  max_mem: 5406M
[32m[04/27 23:17:34 d2.utils.events]: [0m eta: 0:13:49  iter: 199  total_loss: 0.531  loss_cls: 0.161  loss_box_reg: 0.309  loss_rpn_cls: 0.012  loss_rpn_loc: 0.043  time: 1.0277  data_time: 0.0075  lr: 0.000999  max_mem: 5406M
[32m[04/27 23:17:55 d2.utils.events]: [0m eta: 0:13:31  iter: 219  total_loss: 0.621  loss_cls: 0.200  loss_box_reg: 0.348  loss_rpn_cls: 0.012  loss_rpn_loc: 0.054  time: 1.0282  data_time: 0.0075  lr: 0.001099  max_mem: 5406M
[32m[04/27 23:18:15 d2.utils.events]: [0m eta: 0:13:07  iter: 239  total_loss: 0.491  loss_cls: 0.166  loss_box_reg: 0.277  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0261  data_time: 0.0081  lr: 0.001199  max_mem: 5406M
[32m[04/27 23:18:35 d2.utils.events]: [0m eta: 0:12:41  iter: 259  total_loss: 0.607  loss_cls: 0.187  loss_box_reg: 0.345  loss_rpn_cls: 0.010  loss_rpn_loc: 0.065  time: 1.0247  data_time: 0.0074  lr: 0.001299  max_mem: 5406M
[32m[04/27 23:18:56 d2.utils.events]: [0m eta: 0:12:25  iter: 279  total_loss: 0.542  loss_cls: 0.182  loss_box_reg: 0.318  loss_rpn_cls: 0.011  loss_rpn_loc: 0.046  time: 1.0258  data_time: 0.0077  lr: 0.001399  max_mem: 5406M
[32m[04/27 23:19:17 d2.utils.events]: [0m eta: 0:12:04  iter: 299  total_loss: 0.584  loss_cls: 0.193  loss_box_reg: 0.314  loss_rpn_cls: 0.009  loss_rpn_loc: 0.047  time: 1.0263  data_time: 0.0076  lr: 0.001499  max_mem: 5406M
[32m[04/27 23:19:37 d2.utils.events]: [0m eta: 0:11:44  iter: 319  total_loss: 0.557  loss_cls: 0.164  loss_box_reg: 0.309  loss_rpn_cls: 0.010  loss_rpn_loc: 0.044  time: 1.0259  data_time: 0.0074  lr: 0.001598  max_mem: 5406M
[32m[04/27 23:19:57 d2.utils.events]: [0m eta: 0:11:22  iter: 339  total_loss: 0.644  loss_cls: 0.199  loss_box_reg: 0.355  loss_rpn_cls: 0.016  loss_rpn_loc: 0.064  time: 1.0245  data_time: 0.0075  lr: 0.001698  max_mem: 5406M
[32m[04/27 23:20:18 d2.utils.events]: [0m eta: 0:11:01  iter: 359  total_loss: 0.588  loss_cls: 0.189  loss_box_reg: 0.334  loss_rpn_cls: 0.009  loss_rpn_loc: 0.050  time: 1.0245  data_time: 0.0077  lr: 0.001798  max_mem: 5406M
[32m[04/27 23:20:39 d2.utils.events]: [0m eta: 0:10:41  iter: 379  total_loss: 0.526  loss_cls: 0.166  loss_box_reg: 0.297  loss_rpn_cls: 0.011  loss_rpn_loc: 0.043  time: 1.0251  data_time: 0.0075  lr: 0.001898  max_mem: 5406M
[32m[04/27 23:21:00 d2.utils.events]: [0m eta: 0:10:21  iter: 399  total_loss: 0.559  loss_cls: 0.185  loss_box_reg: 0.334  loss_rpn_cls: 0.011  loss_rpn_loc: 0.036  time: 1.0260  data_time: 0.0077  lr: 0.001998  max_mem: 5406M
[32m[04/27 23:21:20 d2.utils.events]: [0m eta: 0:10:01  iter: 419  total_loss: 0.633  loss_cls: 0.196  loss_box_reg: 0.365  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 1.0261  data_time: 0.0075  lr: 0.002098  max_mem: 5406M
[32m[04/27 23:21:41 d2.utils.events]: [0m eta: 0:09:41  iter: 439  total_loss: 0.585  loss_cls: 0.188  loss_box_reg: 0.363  loss_rpn_cls: 0.013  loss_rpn_loc: 0.043  time: 1.0264  data_time: 0.0076  lr: 0.002198  max_mem: 5406M
[32m[04/27 23:22:02 d2.utils.events]: [0m eta: 0:09:22  iter: 459  total_loss: 0.618  loss_cls: 0.201  loss_box_reg: 0.336  loss_rpn_cls: 0.012  loss_rpn_loc: 0.060  time: 1.0281  data_time: 0.0083  lr: 0.002298  max_mem: 5406M
[32m[04/27 23:22:24 d2.utils.events]: [0m eta: 0:09:04  iter: 479  total_loss: 0.602  loss_cls: 0.188  loss_box_reg: 0.339  loss_rpn_cls: 0.011  loss_rpn_loc: 0.055  time: 1.0303  data_time: 0.0077  lr: 0.002398  max_mem: 5406M
[32m[04/27 23:22:45 d2.utils.events]: [0m eta: 0:08:42  iter: 499  total_loss: 0.561  loss_cls: 0.193  loss_box_reg: 0.334  loss_rpn_cls: 0.014  loss_rpn_loc: 0.040  time: 1.0304  data_time: 0.0073  lr: 0.002498  max_mem: 5406M
[32m[04/27 23:23:05 d2.utils.events]: [0m eta: 0:08:21  iter: 519  total_loss: 0.597  loss_cls: 0.179  loss_box_reg: 0.337  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 1.0299  data_time: 0.0074  lr: 0.002597  max_mem: 5406M
[32m[04/27 23:23:25 d2.utils.events]: [0m eta: 0:07:59  iter: 539  total_loss: 0.576  loss_cls: 0.175  loss_box_reg: 0.339  loss_rpn_cls: 0.010  loss_rpn_loc: 0.040  time: 1.0294  data_time: 0.0075  lr: 0.002697  max_mem: 5406M
[32m[04/27 23:23:46 d2.utils.events]: [0m eta: 0:07:38  iter: 559  total_loss: 0.523  loss_cls: 0.163  loss_box_reg: 0.302  loss_rpn_cls: 0.015  loss_rpn_loc: 0.045  time: 1.0292  data_time: 0.0077  lr: 0.002797  max_mem: 5406M
[32m[04/27 23:24:07 d2.utils.events]: [0m eta: 0:07:18  iter: 579  total_loss: 0.655  loss_cls: 0.211  loss_box_reg: 0.379  loss_rpn_cls: 0.013  loss_rpn_loc: 0.060  time: 1.0300  data_time: 0.0077  lr: 0.002897  max_mem: 5406M
[32m[04/27 23:24:27 d2.utils.events]: [0m eta: 0:06:56  iter: 599  total_loss: 0.621  loss_cls: 0.196  loss_box_reg: 0.344  loss_rpn_cls: 0.017  loss_rpn_loc: 0.060  time: 1.0290  data_time: 0.0074  lr: 0.002997  max_mem: 5406M
[32m[04/27 23:24:48 d2.utils.events]: [0m eta: 0:06:35  iter: 619  total_loss: 0.638  loss_cls: 0.194  loss_box_reg: 0.378  loss_rpn_cls: 0.013  loss_rpn_loc: 0.051  time: 1.0289  data_time: 0.0077  lr: 0.003097  max_mem: 5406M
[32m[04/27 23:25:08 d2.utils.events]: [0m eta: 0:06:15  iter: 639  total_loss: 0.611  loss_cls: 0.184  loss_box_reg: 0.348  loss_rpn_cls: 0.012  loss_rpn_loc: 0.051  time: 1.0286  data_time: 0.0075  lr: 0.003197  max_mem: 5406M
[32m[04/27 23:25:28 d2.utils.events]: [0m eta: 0:05:53  iter: 659  total_loss: 0.578  loss_cls: 0.180  loss_box_reg: 0.314  loss_rpn_cls: 0.008  loss_rpn_loc: 0.051  time: 1.0280  data_time: 0.0073  lr: 0.003297  max_mem: 5406M
[32m[04/27 23:25:49 d2.utils.events]: [0m eta: 0:05:32  iter: 679  total_loss: 0.497  loss_cls: 0.153  loss_box_reg: 0.289  loss_rpn_cls: 0.009  loss_rpn_loc: 0.046  time: 1.0281  data_time: 0.0076  lr: 0.003397  max_mem: 5406M
[32m[04/27 23:26:10 d2.utils.events]: [0m eta: 0:05:12  iter: 699  total_loss: 0.579  loss_cls: 0.191  loss_box_reg: 0.321  loss_rpn_cls: 0.012  loss_rpn_loc: 0.058  time: 1.0285  data_time: 0.0077  lr: 0.003497  max_mem: 5406M
[32m[04/27 23:26:31 d2.utils.events]: [0m eta: 0:04:51  iter: 719  total_loss: 0.587  loss_cls: 0.187  loss_box_reg: 0.336  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 1.0284  data_time: 0.0076  lr: 0.003596  max_mem: 5406M
[32m[04/27 23:26:51 d2.utils.events]: [0m eta: 0:04:31  iter: 739  total_loss: 0.599  loss_cls: 0.187  loss_box_reg: 0.344  loss_rpn_cls: 0.013  loss_rpn_loc: 0.061  time: 1.0285  data_time: 0.0075  lr: 0.003696  max_mem: 5406M
[32m[04/27 23:27:12 d2.utils.events]: [0m eta: 0:04:10  iter: 759  total_loss: 0.499  loss_cls: 0.160  loss_box_reg: 0.286  loss_rpn_cls: 0.011  loss_rpn_loc: 0.051  time: 1.0289  data_time: 0.0074  lr: 0.003796  max_mem: 5406M
[32m[04/27 23:27:33 d2.utils.events]: [0m eta: 0:03:49  iter: 779  total_loss: 0.639  loss_cls: 0.198  loss_box_reg: 0.351  loss_rpn_cls: 0.014  loss_rpn_loc: 0.059  time: 1.0288  data_time: 0.0076  lr: 0.003896  max_mem: 5406M
[32m[04/27 23:27:53 d2.utils.events]: [0m eta: 0:03:28  iter: 799  total_loss: 0.564  loss_cls: 0.182  loss_box_reg: 0.311  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0286  data_time: 0.0074  lr: 0.003996  max_mem: 5406M
[32m[04/27 23:28:14 d2.utils.events]: [0m eta: 0:03:08  iter: 819  total_loss: 0.575  loss_cls: 0.181  loss_box_reg: 0.342  loss_rpn_cls: 0.011  loss_rpn_loc: 0.043  time: 1.0292  data_time: 0.0074  lr: 0.004096  max_mem: 5406M
[32m[04/27 23:28:35 d2.utils.events]: [0m eta: 0:02:47  iter: 839  total_loss: 0.547  loss_cls: 0.164  loss_box_reg: 0.304  loss_rpn_cls: 0.012  loss_rpn_loc: 0.046  time: 1.0296  data_time: 0.0078  lr: 0.004196  max_mem: 5406M
[32m[04/27 23:28:56 d2.utils.events]: [0m eta: 0:02:26  iter: 859  total_loss: 0.555  loss_cls: 0.167  loss_box_reg: 0.336  loss_rpn_cls: 0.013  loss_rpn_loc: 0.051  time: 1.0296  data_time: 0.0075  lr: 0.004296  max_mem: 5406M
[32m[04/27 23:29:17 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.610  loss_cls: 0.201  loss_box_reg: 0.367  loss_rpn_cls: 0.018  loss_rpn_loc: 0.054  time: 1.0295  data_time: 0.0081  lr: 0.004396  max_mem: 5406M
[32m[04/27 23:29:37 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.651  loss_cls: 0.201  loss_box_reg: 0.357  loss_rpn_cls: 0.013  loss_rpn_loc: 0.072  time: 1.0295  data_time: 0.0082  lr: 0.004496  max_mem: 5406M
[32m[04/27 23:29:58 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.659  loss_cls: 0.202  loss_box_reg: 0.370  loss_rpn_cls: 0.014  loss_rpn_loc: 0.057  time: 1.0296  data_time: 0.0074  lr: 0.004595  max_mem: 5406M
[32m[04/27 23:30:19 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.628  loss_cls: 0.205  loss_box_reg: 0.353  loss_rpn_cls: 0.014  loss_rpn_loc: 0.061  time: 1.0298  data_time: 0.0076  lr: 0.004695  max_mem: 5406M
[32m[04/27 23:30:39 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.612  loss_cls: 0.191  loss_box_reg: 0.343  loss_rpn_cls: 0.012  loss_rpn_loc: 0.058  time: 1.0299  data_time: 0.0076  lr: 0.004795  max_mem: 5406M
[32m[04/27 23:31:00 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.688  loss_cls: 0.211  loss_box_reg: 0.371  loss_rpn_cls: 0.018  loss_rpn_loc: 0.067  time: 1.0299  data_time: 0.0073  lr: 0.004895  max_mem: 5406M
[5m[31mWARNING[0m [32m[04/27 23:31:23 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 23:31:23 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/27 23:31:23 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/27 23:31:23 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.581  loss_cls: 0.172  loss_box_reg: 0.322  loss_rpn_cls: 0.014  loss_rpn_loc: 0.054  time: 1.0302  data_time: 0.0082  lr: 0.004995  max_mem: 5406M
[32m[04/27 23:31:24 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:08 (1.0312 s / it)
[32m[04/27 23:31:24 d2.engine.hooks]: [0mTotal training time: 0:17:13 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/27 23:31:25 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 23:31:25 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/27 23:31:26 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/27 23:31:27 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1147 s / img. ETA=0:16:08
[32m[04/27 23:31:32 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1142 s / img. ETA=0:16:01
[32m[04/27 23:31:37 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1140 s / img. ETA=0:15:55
[32m[04/27 23:31:42 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1140 s / img. ETA=0:15:49
[32m[04/27 23:31:47 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1139 s / img. ETA=0:15:44
[32m[04/27 23:31:53 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1140 s / img. ETA=0:15:39
[32m[04/27 23:31:58 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1140 s / img. ETA=0:15:34
[32m[04/27 23:32:03 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1140 s / img. ETA=0:15:29
[32m[04/27 23:32:08 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1140 s / img. ETA=0:15:24
[32m[04/27 23:32:13 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1140 s / img. ETA=0:15:19
[32m[04/27 23:32:18 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1140 s / img. ETA=0:15:14
[32m[04/27 23:32:23 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1140 s / img. ETA=0:15:09
[32m[04/27 23:32:28 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1139 s / img. ETA=0:15:04
[32m[04/27 23:32:33 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1139 s / img. ETA=0:14:58
[32m[04/27 23:32:38 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1139 s / img. ETA=0:14:53
[32m[04/27 23:32:43 d2.evaluation.evaluator]: [0mInference done 670/8355. 0.1140 s / img. ETA=0:14:49
[32m[04/27 23:32:48 d2.evaluation.evaluator]: [0mInference done 713/8355. 0.1140 s / img. ETA=0:14:44
[32m[04/27 23:32:53 d2.evaluation.evaluator]: [0mInference done 756/8355. 0.1141 s / img. ETA=0:14:40
[32m[04/27 23:32:58 d2.evaluation.evaluator]: [0mInference done 799/8355. 0.1141 s / img. ETA=0:14:35
[32m[04/27 23:33:03 d2.evaluation.evaluator]: [0mInference done 842/8355. 0.1142 s / img. ETA=0:14:31
[32m[04/27 23:33:08 d2.evaluation.evaluator]: [0mInference done 885/8355. 0.1143 s / img. ETA=0:14:26
[32m[04/27 23:33:13 d2.evaluation.evaluator]: [0mInference done 928/8355. 0.1143 s / img. ETA=0:14:21
[32m[04/27 23:33:18 d2.evaluation.evaluator]: [0mInference done 971/8355. 0.1143 s / img. ETA=0:14:16
[32m[04/27 23:33:23 d2.evaluation.evaluator]: [0mInference done 1014/8355. 0.1143 s / img. ETA=0:14:12
[32m[04/27 23:33:29 d2.evaluation.evaluator]: [0mInference done 1057/8355. 0.1144 s / img. ETA=0:14:07
[32m[04/27 23:33:34 d2.evaluation.evaluator]: [0mInference done 1100/8355. 0.1144 s / img. ETA=0:14:02
[32m[04/27 23:33:39 d2.evaluation.evaluator]: [0mInference done 1143/8355. 0.1144 s / img. ETA=0:13:57
[32m[04/27 23:33:44 d2.evaluation.evaluator]: [0mInference done 1187/8355. 0.1144 s / img. ETA=0:13:52
[32m[04/27 23:33:49 d2.evaluation.evaluator]: [0mInference done 1231/8355. 0.1144 s / img. ETA=0:13:47
[32m[04/27 23:33:54 d2.evaluation.evaluator]: [0mInference done 1275/8355. 0.1144 s / img. ETA=0:13:42
[32m[04/27 23:33:59 d2.evaluation.evaluator]: [0mInference done 1319/8355. 0.1144 s / img. ETA=0:13:37
[32m[04/27 23:34:04 d2.evaluation.evaluator]: [0mInference done 1363/8355. 0.1144 s / img. ETA=0:13:32
[32m[04/27 23:34:09 d2.evaluation.evaluator]: [0mInference done 1406/8355. 0.1144 s / img. ETA=0:13:27
[32m[04/27 23:34:14 d2.evaluation.evaluator]: [0mInference done 1449/8355. 0.1144 s / img. ETA=0:13:22
[32m[04/27 23:34:19 d2.evaluation.evaluator]: [0mInference done 1492/8355. 0.1145 s / img. ETA=0:13:17
[32m[04/27 23:34:24 d2.evaluation.evaluator]: [0mInference done 1535/8355. 0.1145 s / img. ETA=0:13:12
[32m[04/27 23:34:29 d2.evaluation.evaluator]: [0mInference done 1578/8355. 0.1145 s / img. ETA=0:13:08
[32m[04/27 23:34:34 d2.evaluation.evaluator]: [0mInference done 1621/8355. 0.1146 s / img. ETA=0:13:03
[32m[04/27 23:34:39 d2.evaluation.evaluator]: [0mInference done 1664/8355. 0.1146 s / img. ETA=0:12:58
[32m[04/27 23:34:44 d2.evaluation.evaluator]: [0mInference done 1707/8355. 0.1146 s / img. ETA=0:12:53
[32m[04/27 23:34:50 d2.evaluation.evaluator]: [0mInference done 1750/8355. 0.1147 s / img. ETA=0:12:49
[32m[04/27 23:34:55 d2.evaluation.evaluator]: [0mInference done 1792/8355. 0.1148 s / img. ETA=0:12:44
[32m[04/27 23:35:00 d2.evaluation.evaluator]: [0mInference done 1835/8355. 0.1148 s / img. ETA=0:12:39
[32m[04/27 23:35:05 d2.evaluation.evaluator]: [0mInference done 1878/8355. 0.1148 s / img. ETA=0:12:34
[32m[04/27 23:35:10 d2.evaluation.evaluator]: [0mInference done 1921/8355. 0.1148 s / img. ETA=0:12:29
[32m[04/27 23:35:15 d2.evaluation.evaluator]: [0mInference done 1963/8355. 0.1149 s / img. ETA=0:12:25
[32m[04/27 23:35:20 d2.evaluation.evaluator]: [0mInference done 2006/8355. 0.1149 s / img. ETA=0:12:20
[32m[04/27 23:35:25 d2.evaluation.evaluator]: [0mInference done 2049/8355. 0.1149 s / img. ETA=0:12:15
[32m[04/27 23:35:30 d2.evaluation.evaluator]: [0mInference done 2092/8355. 0.1149 s / img. ETA=0:12:10
[32m[04/27 23:35:35 d2.evaluation.evaluator]: [0mInference done 2135/8355. 0.1149 s / img. ETA=0:12:05
[32m[04/27 23:35:40 d2.evaluation.evaluator]: [0mInference done 2178/8355. 0.1149 s / img. ETA=0:12:00
[32m[04/27 23:35:45 d2.evaluation.evaluator]: [0mInference done 2221/8355. 0.1149 s / img. ETA=0:11:55
[32m[04/27 23:35:50 d2.evaluation.evaluator]: [0mInference done 2264/8355. 0.1149 s / img. ETA=0:11:50
[32m[04/27 23:35:55 d2.evaluation.evaluator]: [0mInference done 2307/8355. 0.1149 s / img. ETA=0:11:45
[32m[04/27 23:36:00 d2.evaluation.evaluator]: [0mInference done 2350/8355. 0.1150 s / img. ETA=0:11:40
[32m[04/27 23:36:05 d2.evaluation.evaluator]: [0mInference done 2393/8355. 0.1150 s / img. ETA=0:11:35
[32m[04/27 23:36:10 d2.evaluation.evaluator]: [0mInference done 2436/8355. 0.1150 s / img. ETA=0:11:30
[32m[04/27 23:36:15 d2.evaluation.evaluator]: [0mInference done 2479/8355. 0.1150 s / img. ETA=0:11:25
[32m[04/27 23:36:20 d2.evaluation.evaluator]: [0mInference done 2522/8355. 0.1150 s / img. ETA=0:11:20
[32m[04/27 23:36:25 d2.evaluation.evaluator]: [0mInference done 2565/8355. 0.1150 s / img. ETA=0:11:16
[32m[04/27 23:36:30 d2.evaluation.evaluator]: [0mInference done 2608/8355. 0.1150 s / img. ETA=0:11:11
[32m[04/27 23:36:35 d2.evaluation.evaluator]: [0mInference done 2651/8355. 0.1150 s / img. ETA=0:11:06
[32m[04/27 23:36:40 d2.evaluation.evaluator]: [0mInference done 2694/8355. 0.1150 s / img. ETA=0:11:01
[32m[04/27 23:36:45 d2.evaluation.evaluator]: [0mInference done 2737/8355. 0.1150 s / img. ETA=0:10:56
[32m[04/27 23:36:51 d2.evaluation.evaluator]: [0mInference done 2780/8355. 0.1150 s / img. ETA=0:10:51
[32m[04/27 23:36:56 d2.evaluation.evaluator]: [0mInference done 2823/8355. 0.1150 s / img. ETA=0:10:46
[32m[04/27 23:37:01 d2.evaluation.evaluator]: [0mInference done 2866/8355. 0.1151 s / img. ETA=0:10:41
[32m[04/27 23:37:06 d2.evaluation.evaluator]: [0mInference done 2909/8355. 0.1151 s / img. ETA=0:10:36
[32m[04/27 23:37:11 d2.evaluation.evaluator]: [0mInference done 2952/8355. 0.1151 s / img. ETA=0:10:31
[32m[04/27 23:37:16 d2.evaluation.evaluator]: [0mInference done 2995/8355. 0.1151 s / img. ETA=0:10:26
[32m[04/27 23:37:21 d2.evaluation.evaluator]: [0mInference done 3038/8355. 0.1151 s / img. ETA=0:10:21
[32m[04/27 23:37:26 d2.evaluation.evaluator]: [0mInference done 3081/8355. 0.1151 s / img. ETA=0:10:16
[32m[04/27 23:37:31 d2.evaluation.evaluator]: [0mInference done 3124/8355. 0.1151 s / img. ETA=0:10:11
[32m[04/27 23:37:36 d2.evaluation.evaluator]: [0mInference done 3167/8355. 0.1151 s / img. ETA=0:10:06
[32m[04/27 23:37:41 d2.evaluation.evaluator]: [0mInference done 3210/8355. 0.1151 s / img. ETA=0:10:01
[32m[04/27 23:37:46 d2.evaluation.evaluator]: [0mInference done 3253/8355. 0.1151 s / img. ETA=0:09:56
[32m[04/27 23:37:51 d2.evaluation.evaluator]: [0mInference done 3297/8355. 0.1151 s / img. ETA=0:09:51
[32m[04/27 23:37:56 d2.evaluation.evaluator]: [0mInference done 3340/8355. 0.1151 s / img. ETA=0:09:46
[32m[04/27 23:38:01 d2.evaluation.evaluator]: [0mInference done 3383/8355. 0.1151 s / img. ETA=0:09:40
[32m[04/27 23:38:06 d2.evaluation.evaluator]: [0mInference done 3426/8355. 0.1151 s / img. ETA=0:09:35
[32m[04/27 23:38:11 d2.evaluation.evaluator]: [0mInference done 3469/8355. 0.1151 s / img. ETA=0:09:30
[32m[04/27 23:38:16 d2.evaluation.evaluator]: [0mInference done 3512/8355. 0.1151 s / img. ETA=0:09:25
[32m[04/27 23:38:21 d2.evaluation.evaluator]: [0mInference done 3555/8355. 0.1151 s / img. ETA=0:09:20
[32m[04/27 23:38:26 d2.evaluation.evaluator]: [0mInference done 3598/8355. 0.1151 s / img. ETA=0:09:15
[32m[04/27 23:38:31 d2.evaluation.evaluator]: [0mInference done 3641/8355. 0.1151 s / img. ETA=0:09:10
[32m[04/27 23:38:36 d2.evaluation.evaluator]: [0mInference done 3684/8355. 0.1151 s / img. ETA=0:09:05
[32m[04/27 23:38:41 d2.evaluation.evaluator]: [0mInference done 3728/8355. 0.1151 s / img. ETA=0:09:00
[32m[04/27 23:38:46 d2.evaluation.evaluator]: [0mInference done 3771/8355. 0.1151 s / img. ETA=0:08:55
[32m[04/27 23:38:51 d2.evaluation.evaluator]: [0mInference done 3814/8355. 0.1151 s / img. ETA=0:08:50
[32m[04/27 23:38:57 d2.evaluation.evaluator]: [0mInference done 3857/8355. 0.1151 s / img. ETA=0:08:45
[32m[04/27 23:39:02 d2.evaluation.evaluator]: [0mInference done 3900/8355. 0.1151 s / img. ETA=0:08:40
[32m[04/27 23:39:07 d2.evaluation.evaluator]: [0mInference done 3943/8355. 0.1151 s / img. ETA=0:08:35
[32m[04/27 23:39:12 d2.evaluation.evaluator]: [0mInference done 3986/8355. 0.1151 s / img. ETA=0:08:30
[32m[04/27 23:39:17 d2.evaluation.evaluator]: [0mInference done 4029/8355. 0.1151 s / img. ETA=0:08:25
[32m[04/27 23:39:22 d2.evaluation.evaluator]: [0mInference done 4072/8355. 0.1151 s / img. ETA=0:08:20
[32m[04/27 23:39:27 d2.evaluation.evaluator]: [0mInference done 4115/8355. 0.1151 s / img. ETA=0:08:15
[32m[04/27 23:39:32 d2.evaluation.evaluator]: [0mInference done 4158/8355. 0.1151 s / img. ETA=0:08:10
[32m[04/27 23:39:37 d2.evaluation.evaluator]: [0mInference done 4201/8355. 0.1151 s / img. ETA=0:08:05
[32m[04/27 23:39:42 d2.evaluation.evaluator]: [0mInference done 4244/8355. 0.1151 s / img. ETA=0:08:00
[32m[04/27 23:39:47 d2.evaluation.evaluator]: [0mInference done 4288/8355. 0.1151 s / img. ETA=0:07:55
[32m[04/27 23:39:52 d2.evaluation.evaluator]: [0mInference done 4331/8355. 0.1151 s / img. ETA=0:07:50
[32m[04/27 23:39:57 d2.evaluation.evaluator]: [0mInference done 4374/8355. 0.1151 s / img. ETA=0:07:45
[32m[04/27 23:40:02 d2.evaluation.evaluator]: [0mInference done 4417/8355. 0.1151 s / img. ETA=0:07:40
[32m[04/27 23:40:07 d2.evaluation.evaluator]: [0mInference done 4460/8355. 0.1151 s / img. ETA=0:07:35
[32m[04/27 23:40:12 d2.evaluation.evaluator]: [0mInference done 4503/8355. 0.1151 s / img. ETA=0:07:30
[32m[04/27 23:40:17 d2.evaluation.evaluator]: [0mInference done 4546/8355. 0.1151 s / img. ETA=0:07:25
[32m[04/27 23:40:22 d2.evaluation.evaluator]: [0mInference done 4589/8355. 0.1151 s / img. ETA=0:07:20
[32m[04/27 23:40:27 d2.evaluation.evaluator]: [0mInference done 4632/8355. 0.1152 s / img. ETA=0:07:15
[32m[04/27 23:40:32 d2.evaluation.evaluator]: [0mInference done 4675/8355. 0.1152 s / img. ETA=0:07:10
[32m[04/27 23:40:37 d2.evaluation.evaluator]: [0mInference done 4718/8355. 0.1151 s / img. ETA=0:07:05
[32m[04/27 23:40:42 d2.evaluation.evaluator]: [0mInference done 4761/8355. 0.1152 s / img. ETA=0:07:00
[32m[04/27 23:40:47 d2.evaluation.evaluator]: [0mInference done 4804/8355. 0.1152 s / img. ETA=0:06:55
[32m[04/27 23:40:53 d2.evaluation.evaluator]: [0mInference done 4847/8355. 0.1152 s / img. ETA=0:06:50
[32m[04/27 23:40:58 d2.evaluation.evaluator]: [0mInference done 4890/8355. 0.1152 s / img. ETA=0:06:45
[32m[04/27 23:41:03 d2.evaluation.evaluator]: [0mInference done 4933/8355. 0.1152 s / img. ETA=0:06:40
[32m[04/27 23:41:08 d2.evaluation.evaluator]: [0mInference done 4976/8355. 0.1152 s / img. ETA=0:06:35
[32m[04/27 23:41:13 d2.evaluation.evaluator]: [0mInference done 5019/8355. 0.1152 s / img. ETA=0:06:30
[32m[04/27 23:41:18 d2.evaluation.evaluator]: [0mInference done 5062/8355. 0.1152 s / img. ETA=0:06:25
[32m[04/27 23:41:23 d2.evaluation.evaluator]: [0mInference done 5105/8355. 0.1152 s / img. ETA=0:06:20
[32m[04/27 23:41:28 d2.evaluation.evaluator]: [0mInference done 5148/8355. 0.1152 s / img. ETA=0:06:15
[32m[04/27 23:41:33 d2.evaluation.evaluator]: [0mInference done 5191/8355. 0.1152 s / img. ETA=0:06:09
[32m[04/27 23:41:38 d2.evaluation.evaluator]: [0mInference done 5234/8355. 0.1152 s / img. ETA=0:06:04
[32m[04/27 23:41:43 d2.evaluation.evaluator]: [0mInference done 5277/8355. 0.1152 s / img. ETA=0:05:59
[32m[04/27 23:41:48 d2.evaluation.evaluator]: [0mInference done 5317/8355. 0.1152 s / img. ETA=0:05:55
[32m[04/27 23:41:53 d2.evaluation.evaluator]: [0mInference done 5360/8355. 0.1152 s / img. ETA=0:05:50
[32m[04/27 23:41:58 d2.evaluation.evaluator]: [0mInference done 5403/8355. 0.1152 s / img. ETA=0:05:45
[32m[04/27 23:42:03 d2.evaluation.evaluator]: [0mInference done 5446/8355. 0.1152 s / img. ETA=0:05:40
[32m[04/27 23:42:08 d2.evaluation.evaluator]: [0mInference done 5488/8355. 0.1153 s / img. ETA=0:05:35
[32m[04/27 23:42:13 d2.evaluation.evaluator]: [0mInference done 5531/8355. 0.1153 s / img. ETA=0:05:30
[32m[04/27 23:42:18 d2.evaluation.evaluator]: [0mInference done 5574/8355. 0.1153 s / img. ETA=0:05:25
[32m[04/27 23:42:23 d2.evaluation.evaluator]: [0mInference done 5617/8355. 0.1153 s / img. ETA=0:05:20
[32m[04/27 23:42:28 d2.evaluation.evaluator]: [0mInference done 5660/8355. 0.1153 s / img. ETA=0:05:15
[32m[04/27 23:42:33 d2.evaluation.evaluator]: [0mInference done 5703/8355. 0.1153 s / img. ETA=0:05:10
[32m[04/27 23:42:38 d2.evaluation.evaluator]: [0mInference done 5746/8355. 0.1153 s / img. ETA=0:05:05
[32m[04/27 23:42:43 d2.evaluation.evaluator]: [0mInference done 5789/8355. 0.1153 s / img. ETA=0:05:00
[32m[04/27 23:42:48 d2.evaluation.evaluator]: [0mInference done 5832/8355. 0.1153 s / img. ETA=0:04:55
[32m[04/27 23:42:53 d2.evaluation.evaluator]: [0mInference done 5875/8355. 0.1153 s / img. ETA=0:04:50
[32m[04/27 23:42:59 d2.evaluation.evaluator]: [0mInference done 5918/8355. 0.1153 s / img. ETA=0:04:45
[32m[04/27 23:43:04 d2.evaluation.evaluator]: [0mInference done 5961/8355. 0.1153 s / img. ETA=0:04:40
[32m[04/27 23:43:09 d2.evaluation.evaluator]: [0mInference done 6004/8355. 0.1153 s / img. ETA=0:04:35
[32m[04/27 23:43:14 d2.evaluation.evaluator]: [0mInference done 6047/8355. 0.1153 s / img. ETA=0:04:30
[32m[04/27 23:43:19 d2.evaluation.evaluator]: [0mInference done 6090/8355. 0.1153 s / img. ETA=0:04:25
[32m[04/27 23:43:24 d2.evaluation.evaluator]: [0mInference done 6133/8355. 0.1153 s / img. ETA=0:04:20
[32m[04/27 23:43:29 d2.evaluation.evaluator]: [0mInference done 6176/8355. 0.1153 s / img. ETA=0:04:15
[32m[04/27 23:43:34 d2.evaluation.evaluator]: [0mInference done 6219/8355. 0.1154 s / img. ETA=0:04:10
[32m[04/27 23:43:39 d2.evaluation.evaluator]: [0mInference done 6262/8355. 0.1154 s / img. ETA=0:04:05
[32m[04/27 23:43:44 d2.evaluation.evaluator]: [0mInference done 6305/8355. 0.1154 s / img. ETA=0:04:00
[32m[04/27 23:43:49 d2.evaluation.evaluator]: [0mInference done 6348/8355. 0.1154 s / img. ETA=0:03:55
[32m[04/27 23:43:54 d2.evaluation.evaluator]: [0mInference done 6391/8355. 0.1154 s / img. ETA=0:03:50
[32m[04/27 23:44:00 d2.evaluation.evaluator]: [0mInference done 6434/8355. 0.1154 s / img. ETA=0:03:45
[32m[04/27 23:44:05 d2.evaluation.evaluator]: [0mInference done 6477/8355. 0.1154 s / img. ETA=0:03:40
[32m[04/27 23:44:10 d2.evaluation.evaluator]: [0mInference done 6520/8355. 0.1154 s / img. ETA=0:03:34
[32m[04/27 23:44:15 d2.evaluation.evaluator]: [0mInference done 6564/8355. 0.1154 s / img. ETA=0:03:29
[32m[04/27 23:44:20 d2.evaluation.evaluator]: [0mInference done 6607/8355. 0.1154 s / img. ETA=0:03:24
[32m[04/27 23:44:25 d2.evaluation.evaluator]: [0mInference done 6650/8355. 0.1154 s / img. ETA=0:03:19
[32m[04/27 23:44:30 d2.evaluation.evaluator]: [0mInference done 6694/8355. 0.1154 s / img. ETA=0:03:14
[32m[04/27 23:44:35 d2.evaluation.evaluator]: [0mInference done 6737/8355. 0.1154 s / img. ETA=0:03:09
[32m[04/27 23:44:40 d2.evaluation.evaluator]: [0mInference done 6780/8355. 0.1154 s / img. ETA=0:03:04
[32m[04/27 23:44:45 d2.evaluation.evaluator]: [0mInference done 6823/8355. 0.1154 s / img. ETA=0:02:59
[32m[04/27 23:44:50 d2.evaluation.evaluator]: [0mInference done 6866/8355. 0.1154 s / img. ETA=0:02:54
[32m[04/27 23:44:55 d2.evaluation.evaluator]: [0mInference done 6909/8355. 0.1154 s / img. ETA=0:02:49
[32m[04/27 23:45:00 d2.evaluation.evaluator]: [0mInference done 6952/8355. 0.1154 s / img. ETA=0:02:44
[32m[04/27 23:45:05 d2.evaluation.evaluator]: [0mInference done 6995/8355. 0.1154 s / img. ETA=0:02:39
[32m[04/27 23:45:10 d2.evaluation.evaluator]: [0mInference done 7038/8355. 0.1154 s / img. ETA=0:02:34
[32m[04/27 23:45:15 d2.evaluation.evaluator]: [0mInference done 7081/8355. 0.1154 s / img. ETA=0:02:29
[32m[04/27 23:45:20 d2.evaluation.evaluator]: [0mInference done 7123/8355. 0.1154 s / img. ETA=0:02:24
[32m[04/27 23:45:25 d2.evaluation.evaluator]: [0mInference done 7166/8355. 0.1154 s / img. ETA=0:02:19
[32m[04/27 23:45:30 d2.evaluation.evaluator]: [0mInference done 7208/8355. 0.1154 s / img. ETA=0:02:14
[32m[04/27 23:45:36 d2.evaluation.evaluator]: [0mInference done 7251/8355. 0.1154 s / img. ETA=0:02:09
[32m[04/27 23:45:41 d2.evaluation.evaluator]: [0mInference done 7294/8355. 0.1154 s / img. ETA=0:02:04
[32m[04/27 23:45:46 d2.evaluation.evaluator]: [0mInference done 7337/8355. 0.1154 s / img. ETA=0:01:59
[32m[04/27 23:45:51 d2.evaluation.evaluator]: [0mInference done 7380/8355. 0.1154 s / img. ETA=0:01:54
[32m[04/27 23:45:56 d2.evaluation.evaluator]: [0mInference done 7423/8355. 0.1154 s / img. ETA=0:01:49
[32m[04/27 23:46:01 d2.evaluation.evaluator]: [0mInference done 7466/8355. 0.1155 s / img. ETA=0:01:44
[32m[04/27 23:46:06 d2.evaluation.evaluator]: [0mInference done 7509/8355. 0.1155 s / img. ETA=0:01:39
[32m[04/27 23:46:11 d2.evaluation.evaluator]: [0mInference done 7552/8355. 0.1155 s / img. ETA=0:01:34
[32m[04/27 23:46:16 d2.evaluation.evaluator]: [0mInference done 7595/8355. 0.1155 s / img. ETA=0:01:29
[32m[04/27 23:46:21 d2.evaluation.evaluator]: [0mInference done 7638/8355. 0.1155 s / img. ETA=0:01:24
[32m[04/27 23:46:26 d2.evaluation.evaluator]: [0mInference done 7681/8355. 0.1155 s / img. ETA=0:01:19
[32m[04/27 23:46:31 d2.evaluation.evaluator]: [0mInference done 7724/8355. 0.1155 s / img. ETA=0:01:13
[32m[04/27 23:46:36 d2.evaluation.evaluator]: [0mInference done 7767/8355. 0.1155 s / img. ETA=0:01:08
[32m[04/27 23:46:42 d2.evaluation.evaluator]: [0mInference done 7810/8355. 0.1155 s / img. ETA=0:01:03
[32m[04/27 23:46:47 d2.evaluation.evaluator]: [0mInference done 7852/8355. 0.1155 s / img. ETA=0:00:58
[32m[04/27 23:46:52 d2.evaluation.evaluator]: [0mInference done 7895/8355. 0.1155 s / img. ETA=0:00:53
[32m[04/27 23:46:57 d2.evaluation.evaluator]: [0mInference done 7938/8355. 0.1155 s / img. ETA=0:00:48
[32m[04/27 23:47:02 d2.evaluation.evaluator]: [0mInference done 7981/8355. 0.1155 s / img. ETA=0:00:43
[32m[04/27 23:47:07 d2.evaluation.evaluator]: [0mInference done 8024/8355. 0.1155 s / img. ETA=0:00:38
[32m[04/27 23:47:12 d2.evaluation.evaluator]: [0mInference done 8067/8355. 0.1155 s / img. ETA=0:00:33
[32m[04/27 23:47:17 d2.evaluation.evaluator]: [0mInference done 8111/8355. 0.1155 s / img. ETA=0:00:28
[32m[04/27 23:47:22 d2.evaluation.evaluator]: [0mInference done 8154/8355. 0.1155 s / img. ETA=0:00:23
[32m[04/27 23:47:27 d2.evaluation.evaluator]: [0mInference done 8198/8355. 0.1155 s / img. ETA=0:00:18
[32m[04/27 23:47:32 d2.evaluation.evaluator]: [0mInference done 8241/8355. 0.1155 s / img. ETA=0:00:13
[32m[04/27 23:47:37 d2.evaluation.evaluator]: [0mInference done 8284/8355. 0.1155 s / img. ETA=0:00:08
[32m[04/27 23:47:42 d2.evaluation.evaluator]: [0mInference done 8327/8355. 0.1155 s / img. ETA=0:00:03
[32m[04/27 23:47:46 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:19.356705 (0.117288 s / img per device, on 1 devices)
[32m[04/27 23:47:46 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:04 (0.115515 s / img per device, on 1 devices)
[32m[04/27 23:47:46 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/27 23:47:46 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/27 23:47:46 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.84s).
Accumulating evaluation results...
DONE (t=2.29s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.791
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.401
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.323
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.559
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.164
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.483
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.502
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.406
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.718
[32m[04/27 23:48:10 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.884 | 79.105 | 40.072 | 32.269 | 55.930 | 66.365 |
[32m[04/27 23:48:10 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 42.175 | bicycle       | 32.943 | car            | 53.534 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/27 23:48:10 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 23:48:10 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/27 23:48:10 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/27 23:48:12 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1148 s / img. ETA=0:02:24
[32m[04/27 23:48:17 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1147 s / img. ETA=0:02:19
[32m[04/27 23:48:22 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1147 s / img. ETA=0:02:15
[32m[04/27 23:48:27 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1147 s / img. ETA=0:02:10
[32m[04/27 23:48:32 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1149 s / img. ETA=0:02:05
[32m[04/27 23:48:37 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1148 s / img. ETA=0:02:00
[32m[04/27 23:48:42 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1149 s / img. ETA=0:01:55
[32m[04/27 23:48:47 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1149 s / img. ETA=0:01:50
[32m[04/27 23:48:52 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1149 s / img. ETA=0:01:45
[32m[04/27 23:48:57 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1149 s / img. ETA=0:01:40
[32m[04/27 23:49:02 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1149 s / img. ETA=0:01:35
[32m[04/27 23:49:07 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1149 s / img. ETA=0:01:30
[32m[04/27 23:49:12 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1149 s / img. ETA=0:01:25
[32m[04/27 23:49:17 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1149 s / img. ETA=0:01:20
[32m[04/27 23:49:22 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1149 s / img. ETA=0:01:15
[32m[04/27 23:49:27 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1149 s / img. ETA=0:01:10
[32m[04/27 23:49:32 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1149 s / img. ETA=0:01:05
[32m[04/27 23:49:37 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1149 s / img. ETA=0:01:00
[32m[04/27 23:49:42 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1149 s / img. ETA=0:00:55
[32m[04/27 23:49:47 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1150 s / img. ETA=0:00:50
[32m[04/27 23:49:52 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1150 s / img. ETA=0:00:45
[32m[04/27 23:49:57 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1150 s / img. ETA=0:00:40
[32m[04/27 23:50:02 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1151 s / img. ETA=0:00:35
[32m[04/27 23:50:07 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1151 s / img. ETA=0:00:30
[32m[04/27 23:50:12 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1151 s / img. ETA=0:00:25
[32m[04/27 23:50:17 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1151 s / img. ETA=0:00:19
[32m[04/27 23:50:22 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1152 s / img. ETA=0:00:14
[32m[04/27 23:50:27 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1152 s / img. ETA=0:00:09
[32m[04/27 23:50:32 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1152 s / img. ETA=0:00:04
[32m[04/27 23:50:37 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.506976 (0.117018 s / img per device, on 1 devices)
[32m[04/27 23:50:37 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115256 s / img per device, on 1 devices)
[32m[04/27 23:50:37 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/27 23:50:37 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/27 23:50:37 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.41s).
Accumulating evaluation results...
DONE (t=0.39s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.406
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.774
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.366
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.478
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.486
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.402
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.554
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621
[32m[04/27 23:50:41 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.586 | 77.442 | 36.565 | 29.953 | 47.777 | 53.336 |
[32m[04/27 23:50:41 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 41.086 | bicycle       | 25.279 | car            | 55.391 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  3  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/27 23:50:42 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/27 23:50:42 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 23:50:42 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/27 23:50:43 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/27 23:50:43 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/27 23:50:43 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/27 23:50:43 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/27 23:51:03 d2.utils.events]: [0m eta: 0:16:08  iter: 19  total_loss: 0.696  loss_cls: 0.206  loss_box_reg: 0.405  loss_rpn_cls: 0.013  loss_rpn_loc: 0.065  time: 0.9967  data_time: 0.0175  lr: 0.000100  max_mem: 5406M
[32m[04/27 23:51:23 d2.utils.events]: [0m eta: 0:16:09  iter: 39  total_loss: 0.585  loss_cls: 0.179  loss_box_reg: 0.332  loss_rpn_cls: 0.012  loss_rpn_loc: 0.048  time: 1.0060  data_time: 0.0074  lr: 0.000200  max_mem: 5406M
[32m[04/27 23:51:44 d2.utils.events]: [0m eta: 0:15:52  iter: 59  total_loss: 0.511  loss_cls: 0.169  loss_box_reg: 0.297  loss_rpn_cls: 0.011  loss_rpn_loc: 0.037  time: 1.0098  data_time: 0.0074  lr: 0.000300  max_mem: 5406M
[32m[04/27 23:52:05 d2.utils.events]: [0m eta: 0:15:40  iter: 79  total_loss: 0.562  loss_cls: 0.164  loss_box_reg: 0.301  loss_rpn_cls: 0.013  loss_rpn_loc: 0.042  time: 1.0193  data_time: 0.0076  lr: 0.000400  max_mem: 5406M
[32m[04/27 23:52:25 d2.utils.events]: [0m eta: 0:15:16  iter: 99  total_loss: 0.558  loss_cls: 0.178  loss_box_reg: 0.311  loss_rpn_cls: 0.012  loss_rpn_loc: 0.044  time: 1.0176  data_time: 0.0077  lr: 0.000500  max_mem: 5406M
[32m[04/27 23:52:45 d2.utils.events]: [0m eta: 0:14:54  iter: 119  total_loss: 0.586  loss_cls: 0.175  loss_box_reg: 0.309  loss_rpn_cls: 0.014  loss_rpn_loc: 0.050  time: 1.0172  data_time: 0.0074  lr: 0.000599  max_mem: 5406M
[32m[04/27 23:53:06 d2.utils.events]: [0m eta: 0:14:36  iter: 139  total_loss: 0.531  loss_cls: 0.170  loss_box_reg: 0.309  loss_rpn_cls: 0.013  loss_rpn_loc: 0.043  time: 1.0169  data_time: 0.0073  lr: 0.000699  max_mem: 5406M
[32m[04/27 23:53:26 d2.utils.events]: [0m eta: 0:14:16  iter: 159  total_loss: 0.583  loss_cls: 0.186  loss_box_reg: 0.312  loss_rpn_cls: 0.012  loss_rpn_loc: 0.054  time: 1.0173  data_time: 0.0074  lr: 0.000799  max_mem: 5406M
[32m[04/27 23:53:47 d2.utils.events]: [0m eta: 0:13:59  iter: 179  total_loss: 0.585  loss_cls: 0.174  loss_box_reg: 0.326  loss_rpn_cls: 0.012  loss_rpn_loc: 0.055  time: 1.0205  data_time: 0.0075  lr: 0.000899  max_mem: 5406M
[32m[04/27 23:54:08 d2.utils.events]: [0m eta: 0:13:37  iter: 199  total_loss: 0.591  loss_cls: 0.181  loss_box_reg: 0.326  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 1.0206  data_time: 0.0074  lr: 0.000999  max_mem: 5406M
[32m[04/27 23:54:28 d2.utils.events]: [0m eta: 0:13:15  iter: 219  total_loss: 0.499  loss_cls: 0.154  loss_box_reg: 0.307  loss_rpn_cls: 0.010  loss_rpn_loc: 0.048  time: 1.0193  data_time: 0.0078  lr: 0.001099  max_mem: 5406M
[32m[04/27 23:54:48 d2.utils.events]: [0m eta: 0:12:55  iter: 239  total_loss: 0.592  loss_cls: 0.179  loss_box_reg: 0.337  loss_rpn_cls: 0.012  loss_rpn_loc: 0.043  time: 1.0196  data_time: 0.0076  lr: 0.001199  max_mem: 5406M
[32m[04/27 23:55:09 d2.utils.events]: [0m eta: 0:12:35  iter: 259  total_loss: 0.591  loss_cls: 0.175  loss_box_reg: 0.328  loss_rpn_cls: 0.011  loss_rpn_loc: 0.051  time: 1.0197  data_time: 0.0073  lr: 0.001299  max_mem: 5406M
[32m[04/27 23:55:30 d2.utils.events]: [0m eta: 0:12:15  iter: 279  total_loss: 0.517  loss_cls: 0.170  loss_box_reg: 0.288  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0209  data_time: 0.0075  lr: 0.001399  max_mem: 5406M
[32m[04/27 23:55:50 d2.utils.events]: [0m eta: 0:11:56  iter: 299  total_loss: 0.630  loss_cls: 0.202  loss_box_reg: 0.347  loss_rpn_cls: 0.011  loss_rpn_loc: 0.067  time: 1.0221  data_time: 0.0072  lr: 0.001499  max_mem: 5406M
[32m[04/27 23:56:11 d2.utils.events]: [0m eta: 0:11:38  iter: 319  total_loss: 0.560  loss_cls: 0.177  loss_box_reg: 0.316  loss_rpn_cls: 0.010  loss_rpn_loc: 0.057  time: 1.0234  data_time: 0.0075  lr: 0.001598  max_mem: 5406M
[32m[04/27 23:56:32 d2.utils.events]: [0m eta: 0:11:17  iter: 339  total_loss: 0.603  loss_cls: 0.183  loss_box_reg: 0.344  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 1.0242  data_time: 0.0076  lr: 0.001698  max_mem: 5406M
[32m[04/27 23:56:52 d2.utils.events]: [0m eta: 0:10:57  iter: 359  total_loss: 0.583  loss_cls: 0.181  loss_box_reg: 0.330  loss_rpn_cls: 0.009  loss_rpn_loc: 0.062  time: 1.0230  data_time: 0.0076  lr: 0.001798  max_mem: 5406M
[32m[04/27 23:57:13 d2.utils.events]: [0m eta: 0:10:37  iter: 379  total_loss: 0.552  loss_cls: 0.162  loss_box_reg: 0.328  loss_rpn_cls: 0.007  loss_rpn_loc: 0.053  time: 1.0230  data_time: 0.0081  lr: 0.001898  max_mem: 5406M
[32m[04/27 23:57:34 d2.utils.events]: [0m eta: 0:10:17  iter: 399  total_loss: 0.560  loss_cls: 0.178  loss_box_reg: 0.319  loss_rpn_cls: 0.009  loss_rpn_loc: 0.062  time: 1.0239  data_time: 0.0076  lr: 0.001998  max_mem: 5406M
[32m[04/27 23:57:54 d2.utils.events]: [0m eta: 0:09:57  iter: 419  total_loss: 0.512  loss_cls: 0.158  loss_box_reg: 0.280  loss_rpn_cls: 0.009  loss_rpn_loc: 0.037  time: 1.0244  data_time: 0.0076  lr: 0.002098  max_mem: 5406M
[32m[04/27 23:58:16 d2.utils.events]: [0m eta: 0:09:37  iter: 439  total_loss: 0.644  loss_cls: 0.195  loss_box_reg: 0.365  loss_rpn_cls: 0.010  loss_rpn_loc: 0.057  time: 1.0266  data_time: 0.0075  lr: 0.002198  max_mem: 5406M
[32m[04/27 23:58:37 d2.utils.events]: [0m eta: 0:09:18  iter: 459  total_loss: 0.539  loss_cls: 0.175  loss_box_reg: 0.316  loss_rpn_cls: 0.007  loss_rpn_loc: 0.041  time: 1.0278  data_time: 0.0077  lr: 0.002298  max_mem: 5406M
[32m[04/27 23:58:58 d2.utils.events]: [0m eta: 0:08:58  iter: 479  total_loss: 0.546  loss_cls: 0.173  loss_box_reg: 0.300  loss_rpn_cls: 0.009  loss_rpn_loc: 0.048  time: 1.0282  data_time: 0.0075  lr: 0.002398  max_mem: 5406M
[32m[04/27 23:59:18 d2.utils.events]: [0m eta: 0:08:37  iter: 499  total_loss: 0.505  loss_cls: 0.151  loss_box_reg: 0.303  loss_rpn_cls: 0.009  loss_rpn_loc: 0.050  time: 1.0270  data_time: 0.0073  lr: 0.002498  max_mem: 5406M
[32m[04/27 23:59:38 d2.utils.events]: [0m eta: 0:08:15  iter: 519  total_loss: 0.501  loss_cls: 0.160  loss_box_reg: 0.284  loss_rpn_cls: 0.008  loss_rpn_loc: 0.042  time: 1.0258  data_time: 0.0074  lr: 0.002597  max_mem: 5406M
[32m[04/27 23:59:58 d2.utils.events]: [0m eta: 0:07:54  iter: 539  total_loss: 0.573  loss_cls: 0.178  loss_box_reg: 0.318  loss_rpn_cls: 0.013  loss_rpn_loc: 0.049  time: 1.0258  data_time: 0.0076  lr: 0.002697  max_mem: 5406M
[32m[04/28 00:00:19 d2.utils.events]: [0m eta: 0:07:33  iter: 559  total_loss: 0.610  loss_cls: 0.192  loss_box_reg: 0.351  loss_rpn_cls: 0.010  loss_rpn_loc: 0.057  time: 1.0258  data_time: 0.0072  lr: 0.002797  max_mem: 5406M
[32m[04/28 00:00:39 d2.utils.events]: [0m eta: 0:07:13  iter: 579  total_loss: 0.519  loss_cls: 0.174  loss_box_reg: 0.284  loss_rpn_cls: 0.008  loss_rpn_loc: 0.045  time: 1.0250  data_time: 0.0074  lr: 0.002897  max_mem: 5406M
[32m[04/28 00:00:59 d2.utils.events]: [0m eta: 0:06:52  iter: 599  total_loss: 0.597  loss_cls: 0.177  loss_box_reg: 0.329  loss_rpn_cls: 0.010  loss_rpn_loc: 0.058  time: 1.0242  data_time: 0.0082  lr: 0.002997  max_mem: 5406M
[32m[04/28 00:01:20 d2.utils.events]: [0m eta: 0:06:31  iter: 619  total_loss: 0.656  loss_cls: 0.209  loss_box_reg: 0.371  loss_rpn_cls: 0.011  loss_rpn_loc: 0.070  time: 1.0242  data_time: 0.0074  lr: 0.003097  max_mem: 5406M
[32m[04/28 00:01:40 d2.utils.events]: [0m eta: 0:06:11  iter: 639  total_loss: 0.564  loss_cls: 0.189  loss_box_reg: 0.337  loss_rpn_cls: 0.012  loss_rpn_loc: 0.056  time: 1.0245  data_time: 0.0075  lr: 0.003197  max_mem: 5406M
[32m[04/28 00:02:01 d2.utils.events]: [0m eta: 0:05:50  iter: 659  total_loss: 0.526  loss_cls: 0.170  loss_box_reg: 0.296  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 1.0250  data_time: 0.0073  lr: 0.003297  max_mem: 5406M
[32m[04/28 00:02:22 d2.utils.events]: [0m eta: 0:05:30  iter: 679  total_loss: 0.547  loss_cls: 0.166  loss_box_reg: 0.314  loss_rpn_cls: 0.012  loss_rpn_loc: 0.047  time: 1.0252  data_time: 0.0080  lr: 0.003397  max_mem: 5406M
[32m[04/28 00:02:42 d2.utils.events]: [0m eta: 0:05:09  iter: 699  total_loss: 0.626  loss_cls: 0.191  loss_box_reg: 0.344  loss_rpn_cls: 0.010  loss_rpn_loc: 0.048  time: 1.0249  data_time: 0.0081  lr: 0.003497  max_mem: 5406M
[32m[04/28 00:03:02 d2.utils.events]: [0m eta: 0:04:49  iter: 719  total_loss: 0.628  loss_cls: 0.200  loss_box_reg: 0.357  loss_rpn_cls: 0.012  loss_rpn_loc: 0.052  time: 1.0244  data_time: 0.0075  lr: 0.003596  max_mem: 5406M
[32m[04/28 00:03:23 d2.utils.events]: [0m eta: 0:04:28  iter: 739  total_loss: 0.503  loss_cls: 0.161  loss_box_reg: 0.307  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0243  data_time: 0.0076  lr: 0.003696  max_mem: 5406M
[32m[04/28 00:03:43 d2.utils.events]: [0m eta: 0:04:07  iter: 759  total_loss: 0.582  loss_cls: 0.183  loss_box_reg: 0.321  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 1.0242  data_time: 0.0081  lr: 0.003796  max_mem: 5406M
[32m[04/28 00:04:04 d2.utils.events]: [0m eta: 0:03:47  iter: 779  total_loss: 0.621  loss_cls: 0.197  loss_box_reg: 0.343  loss_rpn_cls: 0.012  loss_rpn_loc: 0.058  time: 1.0243  data_time: 0.0074  lr: 0.003896  max_mem: 5406M
[32m[04/28 00:04:24 d2.utils.events]: [0m eta: 0:03:26  iter: 799  total_loss: 0.510  loss_cls: 0.163  loss_box_reg: 0.284  loss_rpn_cls: 0.009  loss_rpn_loc: 0.041  time: 1.0238  data_time: 0.0072  lr: 0.003996  max_mem: 5406M
[32m[04/28 00:04:45 d2.utils.events]: [0m eta: 0:03:06  iter: 819  total_loss: 0.531  loss_cls: 0.163  loss_box_reg: 0.300  loss_rpn_cls: 0.010  loss_rpn_loc: 0.042  time: 1.0245  data_time: 0.0074  lr: 0.004096  max_mem: 5406M
[32m[04/28 00:05:05 d2.utils.events]: [0m eta: 0:02:45  iter: 839  total_loss: 0.625  loss_cls: 0.202  loss_box_reg: 0.342  loss_rpn_cls: 0.009  loss_rpn_loc: 0.051  time: 1.0238  data_time: 0.0075  lr: 0.004196  max_mem: 5406M
[32m[04/28 00:05:26 d2.utils.events]: [0m eta: 0:02:24  iter: 859  total_loss: 0.524  loss_cls: 0.172  loss_box_reg: 0.292  loss_rpn_cls: 0.012  loss_rpn_loc: 0.038  time: 1.0240  data_time: 0.0076  lr: 0.004296  max_mem: 5406M
[32m[04/28 00:05:46 d2.utils.events]: [0m eta: 0:02:04  iter: 879  total_loss: 0.635  loss_cls: 0.193  loss_box_reg: 0.352  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 1.0235  data_time: 0.0081  lr: 0.004396  max_mem: 5406M
[32m[04/28 00:06:06 d2.utils.events]: [0m eta: 0:01:43  iter: 899  total_loss: 0.541  loss_cls: 0.180  loss_box_reg: 0.314  loss_rpn_cls: 0.011  loss_rpn_loc: 0.044  time: 1.0233  data_time: 0.0073  lr: 0.004496  max_mem: 5406M
[32m[04/28 00:06:26 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.670  loss_cls: 0.206  loss_box_reg: 0.362  loss_rpn_cls: 0.013  loss_rpn_loc: 0.068  time: 1.0227  data_time: 0.0077  lr: 0.004595  max_mem: 5406M
[32m[04/28 00:06:47 d2.utils.events]: [0m eta: 0:01:02  iter: 939  total_loss: 0.604  loss_cls: 0.185  loss_box_reg: 0.340  loss_rpn_cls: 0.014  loss_rpn_loc: 0.063  time: 1.0227  data_time: 0.0074  lr: 0.004695  max_mem: 5406M
[32m[04/28 00:07:07 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.646  loss_cls: 0.194  loss_box_reg: 0.323  loss_rpn_cls: 0.023  loss_rpn_loc: 0.067  time: 1.0223  data_time: 0.0077  lr: 0.004795  max_mem: 5406M
[32m[04/28 00:07:27 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.547  loss_cls: 0.169  loss_box_reg: 0.322  loss_rpn_cls: 0.015  loss_rpn_loc: 0.051  time: 1.0219  data_time: 0.0074  lr: 0.004895  max_mem: 5406M
[5m[31mWARNING[0m [32m[04/28 00:07:50 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 00:07:50 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 00:07:50 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 00:07:50 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.624  loss_cls: 0.205  loss_box_reg: 0.335  loss_rpn_cls: 0.015  loss_rpn_loc: 0.053  time: 1.0220  data_time: 0.0075  lr: 0.004995  max_mem: 5406M
[32m[04/28 00:07:51 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:16:59 (1.0230 s / it)
[32m[04/28 00:07:51 d2.engine.hooks]: [0mTotal training time: 0:17:05 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 00:07:52 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 00:07:52 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 00:07:52 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 00:07:54 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1144 s / img. ETA=0:16:06
[32m[04/28 00:07:59 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1140 s / img. ETA=0:16:00
[32m[04/28 00:08:04 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1138 s / img. ETA=0:15:53
[32m[04/28 00:08:09 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1138 s / img. ETA=0:15:48
[32m[04/28 00:08:14 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1138 s / img. ETA=0:15:43
[32m[04/28 00:08:19 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1138 s / img. ETA=0:15:38
[32m[04/28 00:08:24 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1139 s / img. ETA=0:15:33
[32m[04/28 00:08:29 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1139 s / img. ETA=0:15:29
[32m[04/28 00:08:34 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1139 s / img. ETA=0:15:24
[32m[04/28 00:08:39 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1140 s / img. ETA=0:15:19
[32m[04/28 00:08:45 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1140 s / img. ETA=0:15:14
[32m[04/28 00:08:50 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1139 s / img. ETA=0:15:08
[32m[04/28 00:08:55 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1139 s / img. ETA=0:15:03
[32m[04/28 00:09:00 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1139 s / img. ETA=0:14:58
[32m[04/28 00:09:05 d2.evaluation.evaluator]: [0mInference done 626/8355. 0.1140 s / img. ETA=0:14:54
[32m[04/28 00:09:10 d2.evaluation.evaluator]: [0mInference done 670/8355. 0.1140 s / img. ETA=0:14:49
[32m[04/28 00:09:15 d2.evaluation.evaluator]: [0mInference done 714/8355. 0.1140 s / img. ETA=0:14:44
[32m[04/28 00:09:20 d2.evaluation.evaluator]: [0mInference done 757/8355. 0.1140 s / img. ETA=0:14:39
[32m[04/28 00:09:25 d2.evaluation.evaluator]: [0mInference done 800/8355. 0.1141 s / img. ETA=0:14:34
[32m[04/28 00:09:30 d2.evaluation.evaluator]: [0mInference done 844/8355. 0.1141 s / img. ETA=0:14:29
[32m[04/28 00:09:35 d2.evaluation.evaluator]: [0mInference done 888/8355. 0.1141 s / img. ETA=0:14:24
[32m[04/28 00:09:40 d2.evaluation.evaluator]: [0mInference done 932/8355. 0.1141 s / img. ETA=0:14:19
[32m[04/28 00:09:45 d2.evaluation.evaluator]: [0mInference done 976/8355. 0.1141 s / img. ETA=0:14:14
[32m[04/28 00:09:50 d2.evaluation.evaluator]: [0mInference done 1019/8355. 0.1142 s / img. ETA=0:14:10
[32m[04/28 00:09:56 d2.evaluation.evaluator]: [0mInference done 1063/8355. 0.1142 s / img. ETA=0:14:05
[32m[04/28 00:10:01 d2.evaluation.evaluator]: [0mInference done 1107/8355. 0.1142 s / img. ETA=0:13:59
[32m[04/28 00:10:06 d2.evaluation.evaluator]: [0mInference done 1151/8355. 0.1141 s / img. ETA=0:13:54
[32m[04/28 00:10:11 d2.evaluation.evaluator]: [0mInference done 1195/8355. 0.1142 s / img. ETA=0:13:49
[32m[04/28 00:10:16 d2.evaluation.evaluator]: [0mInference done 1239/8355. 0.1142 s / img. ETA=0:13:44
[32m[04/28 00:10:21 d2.evaluation.evaluator]: [0mInference done 1283/8355. 0.1141 s / img. ETA=0:13:39
[32m[04/28 00:10:26 d2.evaluation.evaluator]: [0mInference done 1327/8355. 0.1141 s / img. ETA=0:13:34
[32m[04/28 00:10:31 d2.evaluation.evaluator]: [0mInference done 1371/8355. 0.1141 s / img. ETA=0:13:29
[32m[04/28 00:10:36 d2.evaluation.evaluator]: [0mInference done 1415/8355. 0.1141 s / img. ETA=0:13:24
[32m[04/28 00:10:41 d2.evaluation.evaluator]: [0mInference done 1458/8355. 0.1141 s / img. ETA=0:13:19
[32m[04/28 00:10:46 d2.evaluation.evaluator]: [0mInference done 1501/8355. 0.1142 s / img. ETA=0:13:14
[32m[04/28 00:10:51 d2.evaluation.evaluator]: [0mInference done 1544/8355. 0.1142 s / img. ETA=0:13:09
[32m[04/28 00:10:57 d2.evaluation.evaluator]: [0mInference done 1587/8355. 0.1143 s / img. ETA=0:13:05
[32m[04/28 00:11:02 d2.evaluation.evaluator]: [0mInference done 1630/8355. 0.1143 s / img. ETA=0:13:00
[32m[04/28 00:11:07 d2.evaluation.evaluator]: [0mInference done 1673/8355. 0.1144 s / img. ETA=0:12:55
[32m[04/28 00:11:12 d2.evaluation.evaluator]: [0mInference done 1716/8355. 0.1144 s / img. ETA=0:12:51
[32m[04/28 00:11:17 d2.evaluation.evaluator]: [0mInference done 1759/8355. 0.1145 s / img. ETA=0:12:46
[32m[04/28 00:11:22 d2.evaluation.evaluator]: [0mInference done 1802/8355. 0.1145 s / img. ETA=0:12:41
[32m[04/28 00:11:27 d2.evaluation.evaluator]: [0mInference done 1845/8355. 0.1145 s / img. ETA=0:12:36
[32m[04/28 00:11:32 d2.evaluation.evaluator]: [0mInference done 1888/8355. 0.1146 s / img. ETA=0:12:32
[32m[04/28 00:11:37 d2.evaluation.evaluator]: [0mInference done 1931/8355. 0.1146 s / img. ETA=0:12:27
[32m[04/28 00:11:42 d2.evaluation.evaluator]: [0mInference done 1974/8355. 0.1146 s / img. ETA=0:12:22
[32m[04/28 00:11:47 d2.evaluation.evaluator]: [0mInference done 2017/8355. 0.1146 s / img. ETA=0:12:17
[32m[04/28 00:11:52 d2.evaluation.evaluator]: [0mInference done 2060/8355. 0.1146 s / img. ETA=0:12:12
[32m[04/28 00:11:57 d2.evaluation.evaluator]: [0mInference done 2103/8355. 0.1146 s / img. ETA=0:12:07
[32m[04/28 00:12:02 d2.evaluation.evaluator]: [0mInference done 2146/8355. 0.1146 s / img. ETA=0:12:02
[32m[04/28 00:12:07 d2.evaluation.evaluator]: [0mInference done 2189/8355. 0.1146 s / img. ETA=0:11:57
[32m[04/28 00:12:12 d2.evaluation.evaluator]: [0mInference done 2232/8355. 0.1147 s / img. ETA=0:11:52
[32m[04/28 00:12:17 d2.evaluation.evaluator]: [0mInference done 2275/8355. 0.1147 s / img. ETA=0:11:48
[32m[04/28 00:12:22 d2.evaluation.evaluator]: [0mInference done 2318/8355. 0.1147 s / img. ETA=0:11:43
[32m[04/28 00:12:27 d2.evaluation.evaluator]: [0mInference done 2361/8355. 0.1147 s / img. ETA=0:11:38
[32m[04/28 00:12:32 d2.evaluation.evaluator]: [0mInference done 2404/8355. 0.1147 s / img. ETA=0:11:33
[32m[04/28 00:12:37 d2.evaluation.evaluator]: [0mInference done 2447/8355. 0.1147 s / img. ETA=0:11:28
[32m[04/28 00:12:43 d2.evaluation.evaluator]: [0mInference done 2490/8355. 0.1147 s / img. ETA=0:11:23
[32m[04/28 00:12:48 d2.evaluation.evaluator]: [0mInference done 2533/8355. 0.1148 s / img. ETA=0:11:18
[32m[04/28 00:12:53 d2.evaluation.evaluator]: [0mInference done 2576/8355. 0.1148 s / img. ETA=0:11:13
[32m[04/28 00:12:58 d2.evaluation.evaluator]: [0mInference done 2619/8355. 0.1148 s / img. ETA=0:11:08
[32m[04/28 00:13:03 d2.evaluation.evaluator]: [0mInference done 2662/8355. 0.1148 s / img. ETA=0:11:03
[32m[04/28 00:13:08 d2.evaluation.evaluator]: [0mInference done 2705/8355. 0.1148 s / img. ETA=0:10:58
[32m[04/28 00:13:13 d2.evaluation.evaluator]: [0mInference done 2748/8355. 0.1148 s / img. ETA=0:10:53
[32m[04/28 00:13:18 d2.evaluation.evaluator]: [0mInference done 2791/8355. 0.1148 s / img. ETA=0:10:48
[32m[04/28 00:13:23 d2.evaluation.evaluator]: [0mInference done 2834/8355. 0.1148 s / img. ETA=0:10:43
[32m[04/28 00:13:28 d2.evaluation.evaluator]: [0mInference done 2877/8355. 0.1149 s / img. ETA=0:10:38
[32m[04/28 00:13:33 d2.evaluation.evaluator]: [0mInference done 2920/8355. 0.1148 s / img. ETA=0:10:33
[32m[04/28 00:13:38 d2.evaluation.evaluator]: [0mInference done 2963/8355. 0.1149 s / img. ETA=0:10:29
[32m[04/28 00:13:43 d2.evaluation.evaluator]: [0mInference done 3006/8355. 0.1149 s / img. ETA=0:10:24
[32m[04/28 00:13:48 d2.evaluation.evaluator]: [0mInference done 3049/8355. 0.1149 s / img. ETA=0:10:19
[32m[04/28 00:13:53 d2.evaluation.evaluator]: [0mInference done 3092/8355. 0.1149 s / img. ETA=0:10:14
[32m[04/28 00:13:58 d2.evaluation.evaluator]: [0mInference done 3135/8355. 0.1149 s / img. ETA=0:10:09
[32m[04/28 00:14:03 d2.evaluation.evaluator]: [0mInference done 3179/8355. 0.1149 s / img. ETA=0:10:03
[32m[04/28 00:14:08 d2.evaluation.evaluator]: [0mInference done 3223/8355. 0.1148 s / img. ETA=0:09:58
[32m[04/28 00:14:13 d2.evaluation.evaluator]: [0mInference done 3266/8355. 0.1149 s / img. ETA=0:09:53
[32m[04/28 00:14:18 d2.evaluation.evaluator]: [0mInference done 3310/8355. 0.1148 s / img. ETA=0:09:48
[32m[04/28 00:14:23 d2.evaluation.evaluator]: [0mInference done 3353/8355. 0.1148 s / img. ETA=0:09:43
[32m[04/28 00:14:29 d2.evaluation.evaluator]: [0mInference done 3396/8355. 0.1148 s / img. ETA=0:09:38
[32m[04/28 00:14:34 d2.evaluation.evaluator]: [0mInference done 3439/8355. 0.1148 s / img. ETA=0:09:33
[32m[04/28 00:14:39 d2.evaluation.evaluator]: [0mInference done 3482/8355. 0.1148 s / img. ETA=0:09:28
[32m[04/28 00:14:44 d2.evaluation.evaluator]: [0mInference done 3525/8355. 0.1149 s / img. ETA=0:09:23
[32m[04/28 00:14:49 d2.evaluation.evaluator]: [0mInference done 3568/8355. 0.1149 s / img. ETA=0:09:18
[32m[04/28 00:14:54 d2.evaluation.evaluator]: [0mInference done 3611/8355. 0.1149 s / img. ETA=0:09:13
[32m[04/28 00:14:59 d2.evaluation.evaluator]: [0mInference done 3654/8355. 0.1149 s / img. ETA=0:09:08
[32m[04/28 00:15:04 d2.evaluation.evaluator]: [0mInference done 3698/8355. 0.1148 s / img. ETA=0:09:03
[32m[04/28 00:15:09 d2.evaluation.evaluator]: [0mInference done 3741/8355. 0.1148 s / img. ETA=0:08:58
[32m[04/28 00:15:14 d2.evaluation.evaluator]: [0mInference done 3784/8355. 0.1148 s / img. ETA=0:08:53
[32m[04/28 00:15:19 d2.evaluation.evaluator]: [0mInference done 3827/8355. 0.1149 s / img. ETA=0:08:48
[32m[04/28 00:15:24 d2.evaluation.evaluator]: [0mInference done 3870/8355. 0.1149 s / img. ETA=0:08:43
[32m[04/28 00:15:29 d2.evaluation.evaluator]: [0mInference done 3914/8355. 0.1149 s / img. ETA=0:08:38
[32m[04/28 00:15:34 d2.evaluation.evaluator]: [0mInference done 3957/8355. 0.1149 s / img. ETA=0:08:33
[32m[04/28 00:15:39 d2.evaluation.evaluator]: [0mInference done 4000/8355. 0.1149 s / img. ETA=0:08:28
[32m[04/28 00:15:44 d2.evaluation.evaluator]: [0mInference done 4043/8355. 0.1149 s / img. ETA=0:08:23
[32m[04/28 00:15:49 d2.evaluation.evaluator]: [0mInference done 4087/8355. 0.1149 s / img. ETA=0:08:17
[32m[04/28 00:15:54 d2.evaluation.evaluator]: [0mInference done 4130/8355. 0.1149 s / img. ETA=0:08:12
[32m[04/28 00:15:59 d2.evaluation.evaluator]: [0mInference done 4173/8355. 0.1149 s / img. ETA=0:08:07
[32m[04/28 00:16:04 d2.evaluation.evaluator]: [0mInference done 4216/8355. 0.1149 s / img. ETA=0:08:02
[32m[04/28 00:16:09 d2.evaluation.evaluator]: [0mInference done 4260/8355. 0.1149 s / img. ETA=0:07:57
[32m[04/28 00:16:14 d2.evaluation.evaluator]: [0mInference done 4303/8355. 0.1149 s / img. ETA=0:07:52
[32m[04/28 00:16:20 d2.evaluation.evaluator]: [0mInference done 4347/8355. 0.1149 s / img. ETA=0:07:47
[32m[04/28 00:16:25 d2.evaluation.evaluator]: [0mInference done 4390/8355. 0.1149 s / img. ETA=0:07:42
[32m[04/28 00:16:30 d2.evaluation.evaluator]: [0mInference done 4433/8355. 0.1149 s / img. ETA=0:07:37
[32m[04/28 00:16:35 d2.evaluation.evaluator]: [0mInference done 4476/8355. 0.1149 s / img. ETA=0:07:32
[32m[04/28 00:16:40 d2.evaluation.evaluator]: [0mInference done 4519/8355. 0.1149 s / img. ETA=0:07:27
[32m[04/28 00:16:45 d2.evaluation.evaluator]: [0mInference done 4562/8355. 0.1149 s / img. ETA=0:07:22
[32m[04/28 00:16:50 d2.evaluation.evaluator]: [0mInference done 4605/8355. 0.1149 s / img. ETA=0:07:17
[32m[04/28 00:16:55 d2.evaluation.evaluator]: [0mInference done 4648/8355. 0.1149 s / img. ETA=0:07:12
[32m[04/28 00:17:00 d2.evaluation.evaluator]: [0mInference done 4691/8355. 0.1149 s / img. ETA=0:07:07
[32m[04/28 00:17:05 d2.evaluation.evaluator]: [0mInference done 4734/8355. 0.1149 s / img. ETA=0:07:02
[32m[04/28 00:17:10 d2.evaluation.evaluator]: [0mInference done 4777/8355. 0.1149 s / img. ETA=0:06:57
[32m[04/28 00:17:15 d2.evaluation.evaluator]: [0mInference done 4820/8355. 0.1149 s / img. ETA=0:06:52
[32m[04/28 00:17:20 d2.evaluation.evaluator]: [0mInference done 4863/8355. 0.1149 s / img. ETA=0:06:47
[32m[04/28 00:17:25 d2.evaluation.evaluator]: [0mInference done 4906/8355. 0.1149 s / img. ETA=0:06:42
[32m[04/28 00:17:30 d2.evaluation.evaluator]: [0mInference done 4949/8355. 0.1149 s / img. ETA=0:06:37
[32m[04/28 00:17:35 d2.evaluation.evaluator]: [0mInference done 4993/8355. 0.1149 s / img. ETA=0:06:32
[32m[04/28 00:17:40 d2.evaluation.evaluator]: [0mInference done 5036/8355. 0.1149 s / img. ETA=0:06:27
[32m[04/28 00:17:45 d2.evaluation.evaluator]: [0mInference done 5079/8355. 0.1149 s / img. ETA=0:06:22
[32m[04/28 00:17:50 d2.evaluation.evaluator]: [0mInference done 5122/8355. 0.1149 s / img. ETA=0:06:17
[32m[04/28 00:17:55 d2.evaluation.evaluator]: [0mInference done 5165/8355. 0.1149 s / img. ETA=0:06:12
[32m[04/28 00:18:00 d2.evaluation.evaluator]: [0mInference done 5208/8355. 0.1149 s / img. ETA=0:06:07
[32m[04/28 00:18:05 d2.evaluation.evaluator]: [0mInference done 5251/8355. 0.1149 s / img. ETA=0:06:02
[32m[04/28 00:18:10 d2.evaluation.evaluator]: [0mInference done 5294/8355. 0.1150 s / img. ETA=0:05:57
[32m[04/28 00:18:16 d2.evaluation.evaluator]: [0mInference done 5337/8355. 0.1150 s / img. ETA=0:05:52
[32m[04/28 00:18:21 d2.evaluation.evaluator]: [0mInference done 5380/8355. 0.1150 s / img. ETA=0:05:47
[32m[04/28 00:18:26 d2.evaluation.evaluator]: [0mInference done 5423/8355. 0.1150 s / img. ETA=0:05:42
[32m[04/28 00:18:31 d2.evaluation.evaluator]: [0mInference done 5466/8355. 0.1150 s / img. ETA=0:05:37
[32m[04/28 00:18:36 d2.evaluation.evaluator]: [0mInference done 5509/8355. 0.1150 s / img. ETA=0:05:32
[32m[04/28 00:18:41 d2.evaluation.evaluator]: [0mInference done 5553/8355. 0.1150 s / img. ETA=0:05:27
[32m[04/28 00:18:46 d2.evaluation.evaluator]: [0mInference done 5596/8355. 0.1150 s / img. ETA=0:05:22
[32m[04/28 00:18:51 d2.evaluation.evaluator]: [0mInference done 5639/8355. 0.1150 s / img. ETA=0:05:17
[32m[04/28 00:18:56 d2.evaluation.evaluator]: [0mInference done 5682/8355. 0.1150 s / img. ETA=0:05:12
[32m[04/28 00:19:01 d2.evaluation.evaluator]: [0mInference done 5725/8355. 0.1150 s / img. ETA=0:05:07
[32m[04/28 00:19:06 d2.evaluation.evaluator]: [0mInference done 5768/8355. 0.1150 s / img. ETA=0:05:02
[32m[04/28 00:19:11 d2.evaluation.evaluator]: [0mInference done 5811/8355. 0.1150 s / img. ETA=0:04:57
[32m[04/28 00:19:16 d2.evaluation.evaluator]: [0mInference done 5854/8355. 0.1150 s / img. ETA=0:04:52
[32m[04/28 00:19:21 d2.evaluation.evaluator]: [0mInference done 5897/8355. 0.1150 s / img. ETA=0:04:47
[32m[04/28 00:19:27 d2.evaluation.evaluator]: [0mInference done 5940/8355. 0.1151 s / img. ETA=0:04:42
[32m[04/28 00:19:32 d2.evaluation.evaluator]: [0mInference done 5983/8355. 0.1151 s / img. ETA=0:04:37
[32m[04/28 00:19:37 d2.evaluation.evaluator]: [0mInference done 6025/8355. 0.1151 s / img. ETA=0:04:32
[32m[04/28 00:19:42 d2.evaluation.evaluator]: [0mInference done 6068/8355. 0.1151 s / img. ETA=0:04:27
[32m[04/28 00:19:47 d2.evaluation.evaluator]: [0mInference done 6111/8355. 0.1151 s / img. ETA=0:04:22
[32m[04/28 00:19:52 d2.evaluation.evaluator]: [0mInference done 6154/8355. 0.1151 s / img. ETA=0:04:17
[32m[04/28 00:19:57 d2.evaluation.evaluator]: [0mInference done 6197/8355. 0.1151 s / img. ETA=0:04:12
[32m[04/28 00:20:02 d2.evaluation.evaluator]: [0mInference done 6240/8355. 0.1151 s / img. ETA=0:04:07
[32m[04/28 00:20:07 d2.evaluation.evaluator]: [0mInference done 6283/8355. 0.1151 s / img. ETA=0:04:02
[32m[04/28 00:20:12 d2.evaluation.evaluator]: [0mInference done 6325/8355. 0.1152 s / img. ETA=0:03:57
[32m[04/28 00:20:17 d2.evaluation.evaluator]: [0mInference done 6368/8355. 0.1152 s / img. ETA=0:03:52
[32m[04/28 00:20:22 d2.evaluation.evaluator]: [0mInference done 6411/8355. 0.1152 s / img. ETA=0:03:47
[32m[04/28 00:20:27 d2.evaluation.evaluator]: [0mInference done 6453/8355. 0.1152 s / img. ETA=0:03:42
[32m[04/28 00:20:32 d2.evaluation.evaluator]: [0mInference done 6496/8355. 0.1152 s / img. ETA=0:03:37
[32m[04/28 00:20:37 d2.evaluation.evaluator]: [0mInference done 6539/8355. 0.1152 s / img. ETA=0:03:32
[32m[04/28 00:20:42 d2.evaluation.evaluator]: [0mInference done 6582/8355. 0.1152 s / img. ETA=0:03:27
[32m[04/28 00:20:47 d2.evaluation.evaluator]: [0mInference done 6625/8355. 0.1152 s / img. ETA=0:03:22
[32m[04/28 00:20:53 d2.evaluation.evaluator]: [0mInference done 6669/8355. 0.1152 s / img. ETA=0:03:17
[32m[04/28 00:20:58 d2.evaluation.evaluator]: [0mInference done 6713/8355. 0.1152 s / img. ETA=0:03:12
[32m[04/28 00:21:03 d2.evaluation.evaluator]: [0mInference done 6757/8355. 0.1152 s / img. ETA=0:03:06
[32m[04/28 00:21:08 d2.evaluation.evaluator]: [0mInference done 6801/8355. 0.1152 s / img. ETA=0:03:01
[32m[04/28 00:21:13 d2.evaluation.evaluator]: [0mInference done 6844/8355. 0.1152 s / img. ETA=0:02:56
[32m[04/28 00:21:18 d2.evaluation.evaluator]: [0mInference done 6887/8355. 0.1152 s / img. ETA=0:02:51
[32m[04/28 00:21:23 d2.evaluation.evaluator]: [0mInference done 6930/8355. 0.1152 s / img. ETA=0:02:46
[32m[04/28 00:21:28 d2.evaluation.evaluator]: [0mInference done 6973/8355. 0.1152 s / img. ETA=0:02:41
[32m[04/28 00:21:33 d2.evaluation.evaluator]: [0mInference done 7016/8355. 0.1152 s / img. ETA=0:02:36
[32m[04/28 00:21:38 d2.evaluation.evaluator]: [0mInference done 7059/8355. 0.1152 s / img. ETA=0:02:31
[32m[04/28 00:21:43 d2.evaluation.evaluator]: [0mInference done 7101/8355. 0.1152 s / img. ETA=0:02:26
[32m[04/28 00:21:48 d2.evaluation.evaluator]: [0mInference done 7144/8355. 0.1152 s / img. ETA=0:02:21
[32m[04/28 00:21:53 d2.evaluation.evaluator]: [0mInference done 7187/8355. 0.1152 s / img. ETA=0:02:16
[32m[04/28 00:21:58 d2.evaluation.evaluator]: [0mInference done 7230/8355. 0.1152 s / img. ETA=0:02:11
[32m[04/28 00:22:03 d2.evaluation.evaluator]: [0mInference done 7273/8355. 0.1152 s / img. ETA=0:02:06
[32m[04/28 00:22:08 d2.evaluation.evaluator]: [0mInference done 7315/8355. 0.1152 s / img. ETA=0:02:01
[32m[04/28 00:22:13 d2.evaluation.evaluator]: [0mInference done 7357/8355. 0.1152 s / img. ETA=0:01:56
[32m[04/28 00:22:19 d2.evaluation.evaluator]: [0mInference done 7400/8355. 0.1152 s / img. ETA=0:01:51
[32m[04/28 00:22:24 d2.evaluation.evaluator]: [0mInference done 7442/8355. 0.1153 s / img. ETA=0:01:46
[32m[04/28 00:22:29 d2.evaluation.evaluator]: [0mInference done 7485/8355. 0.1153 s / img. ETA=0:01:41
[32m[04/28 00:22:34 d2.evaluation.evaluator]: [0mInference done 7528/8355. 0.1153 s / img. ETA=0:01:36
[32m[04/28 00:22:39 d2.evaluation.evaluator]: [0mInference done 7571/8355. 0.1153 s / img. ETA=0:01:31
[32m[04/28 00:22:44 d2.evaluation.evaluator]: [0mInference done 7614/8355. 0.1153 s / img. ETA=0:01:26
[32m[04/28 00:22:49 d2.evaluation.evaluator]: [0mInference done 7657/8355. 0.1153 s / img. ETA=0:01:21
[32m[04/28 00:22:54 d2.evaluation.evaluator]: [0mInference done 7700/8355. 0.1153 s / img. ETA=0:01:16
[32m[04/28 00:22:59 d2.evaluation.evaluator]: [0mInference done 7743/8355. 0.1153 s / img. ETA=0:01:11
[32m[04/28 00:23:04 d2.evaluation.evaluator]: [0mInference done 7785/8355. 0.1153 s / img. ETA=0:01:06
[32m[04/28 00:23:09 d2.evaluation.evaluator]: [0mInference done 7828/8355. 0.1153 s / img. ETA=0:01:01
[32m[04/28 00:23:14 d2.evaluation.evaluator]: [0mInference done 7871/8355. 0.1153 s / img. ETA=0:00:56
[32m[04/28 00:23:19 d2.evaluation.evaluator]: [0mInference done 7914/8355. 0.1153 s / img. ETA=0:00:51
[32m[04/28 00:23:24 d2.evaluation.evaluator]: [0mInference done 7957/8355. 0.1153 s / img. ETA=0:00:46
[32m[04/28 00:23:29 d2.evaluation.evaluator]: [0mInference done 8000/8355. 0.1153 s / img. ETA=0:00:41
[32m[04/28 00:23:34 d2.evaluation.evaluator]: [0mInference done 8043/8355. 0.1153 s / img. ETA=0:00:36
[32m[04/28 00:23:40 d2.evaluation.evaluator]: [0mInference done 8087/8355. 0.1153 s / img. ETA=0:00:31
[32m[04/28 00:23:45 d2.evaluation.evaluator]: [0mInference done 8131/8355. 0.1153 s / img. ETA=0:00:26
[32m[04/28 00:23:50 d2.evaluation.evaluator]: [0mInference done 8174/8355. 0.1153 s / img. ETA=0:00:21
[32m[04/28 00:23:55 d2.evaluation.evaluator]: [0mInference done 8217/8355. 0.1153 s / img. ETA=0:00:16
[32m[04/28 00:24:00 d2.evaluation.evaluator]: [0mInference done 8260/8355. 0.1153 s / img. ETA=0:00:11
[32m[04/28 00:24:05 d2.evaluation.evaluator]: [0mInference done 8303/8355. 0.1153 s / img. ETA=0:00:06
[32m[04/28 00:24:10 d2.evaluation.evaluator]: [0mInference done 8346/8355. 0.1153 s / img. ETA=0:00:01
[32m[04/28 00:24:11 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:18.233973 (0.117154 s / img per device, on 1 devices)
[32m[04/28 00:24:11 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:02 (0.115323 s / img per device, on 1 devices)
[32m[04/28 00:24:12 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 00:24:12 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 00:24:12 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.64s).
Accumulating evaluation results...
DONE (t=2.29s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.780
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.396
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.323
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.544
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.166
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.477
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.405
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.711
[32m[04/28 00:24:35 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.992 | 77.970 | 39.621 | 32.261 | 54.357 | 66.966 |
[32m[04/28 00:24:35 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 43.179 | bicycle       | 32.480 | car            | 50.318 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 00:24:36 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 00:24:36 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 00:24:36 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 00:24:38 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1150 s / img. ETA=0:02:25
[32m[04/28 00:24:43 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1147 s / img. ETA=0:02:20
[32m[04/28 00:24:48 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1147 s / img. ETA=0:02:15
[32m[04/28 00:24:53 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1147 s / img. ETA=0:02:10
[32m[04/28 00:24:58 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1148 s / img. ETA=0:02:05
[32m[04/28 00:25:03 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1148 s / img. ETA=0:02:00
[32m[04/28 00:25:08 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1149 s / img. ETA=0:01:55
[32m[04/28 00:25:13 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1148 s / img. ETA=0:01:50
[32m[04/28 00:25:18 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1148 s / img. ETA=0:01:45
[32m[04/28 00:25:23 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1149 s / img. ETA=0:01:40
[32m[04/28 00:25:28 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1149 s / img. ETA=0:01:35
[32m[04/28 00:25:33 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1149 s / img. ETA=0:01:30
[32m[04/28 00:25:38 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1149 s / img. ETA=0:01:25
[32m[04/28 00:25:43 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1150 s / img. ETA=0:01:20
[32m[04/28 00:25:48 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1150 s / img. ETA=0:01:15
[32m[04/28 00:25:53 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1150 s / img. ETA=0:01:10
[32m[04/28 00:25:58 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1151 s / img. ETA=0:01:05
[32m[04/28 00:26:03 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1151 s / img. ETA=0:01:00
[32m[04/28 00:26:09 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1151 s / img. ETA=0:00:55
[32m[04/28 00:26:14 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1151 s / img. ETA=0:00:50
[32m[04/28 00:26:19 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1152 s / img. ETA=0:00:45
[32m[04/28 00:26:24 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1152 s / img. ETA=0:00:40
[32m[04/28 00:26:29 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1152 s / img. ETA=0:00:35
[32m[04/28 00:26:34 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1152 s / img. ETA=0:00:30
[32m[04/28 00:26:39 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1153 s / img. ETA=0:00:25
[32m[04/28 00:26:44 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1153 s / img. ETA=0:00:20
[32m[04/28 00:26:49 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1153 s / img. ETA=0:00:14
[32m[04/28 00:26:54 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1154 s / img. ETA=0:00:09
[32m[04/28 00:26:59 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1154 s / img. ETA=0:00:04
[32m[04/28 00:27:04 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.759863 (0.117220 s / img per device, on 1 devices)
[32m[04/28 00:27:04 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115366 s / img per device, on 1 devices)
[32m[04/28 00:27:04 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 00:27:04 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 00:27:04 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.27s).
Accumulating evaluation results...
DONE (t=0.40s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.739
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.330
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.443
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.566
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.179
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.454
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.370
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.512
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652
[32m[04/28 00:27:08 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 37.736 | 73.910 | 33.030 | 27.466 | 44.276 | 56.623 |
[32m[04/28 00:27:08 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 40.885 | bicycle       | 21.169 | car            | 51.154 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  4  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 00:27:09 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 00:27:09 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 00:27:10 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 00:27:10 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 00:27:10 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 00:27:10 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 00:27:11 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 00:27:33 d2.utils.events]: [0m eta: 0:17:20  iter: 19  total_loss: 0.631  loss_cls: 0.200  loss_box_reg: 0.357  loss_rpn_cls: 0.014  loss_rpn_loc: 0.053  time: 1.0446  data_time: 0.0390  lr: 0.000100  max_mem: 5406M
[32m[04/28 00:27:54 d2.utils.events]: [0m eta: 0:16:55  iter: 39  total_loss: 0.593  loss_cls: 0.192  loss_box_reg: 0.338  loss_rpn_cls: 0.013  loss_rpn_loc: 0.062  time: 1.0322  data_time: 0.0073  lr: 0.000200  max_mem: 5406M
[32m[04/28 00:28:14 d2.utils.events]: [0m eta: 0:16:30  iter: 59  total_loss: 0.523  loss_cls: 0.174  loss_box_reg: 0.290  loss_rpn_cls: 0.010  loss_rpn_loc: 0.040  time: 1.0325  data_time: 0.0072  lr: 0.000300  max_mem: 5406M
[32m[04/28 00:28:35 d2.utils.events]: [0m eta: 0:16:10  iter: 79  total_loss: 0.511  loss_cls: 0.172  loss_box_reg: 0.295  loss_rpn_cls: 0.009  loss_rpn_loc: 0.041  time: 1.0322  data_time: 0.0073  lr: 0.000400  max_mem: 5406M
[32m[04/28 00:28:56 d2.utils.events]: [0m eta: 0:15:54  iter: 99  total_loss: 0.525  loss_cls: 0.172  loss_box_reg: 0.299  loss_rpn_cls: 0.011  loss_rpn_loc: 0.052  time: 1.0370  data_time: 0.0075  lr: 0.000500  max_mem: 5406M
[32m[04/28 00:29:17 d2.utils.events]: [0m eta: 0:15:34  iter: 119  total_loss: 0.592  loss_cls: 0.182  loss_box_reg: 0.337  loss_rpn_cls: 0.012  loss_rpn_loc: 0.053  time: 1.0391  data_time: 0.0074  lr: 0.000599  max_mem: 5406M
[32m[04/28 00:29:39 d2.utils.events]: [0m eta: 0:15:15  iter: 139  total_loss: 0.509  loss_cls: 0.158  loss_box_reg: 0.288  loss_rpn_cls: 0.011  loss_rpn_loc: 0.043  time: 1.0418  data_time: 0.0078  lr: 0.000699  max_mem: 5406M
[32m[04/28 00:30:00 d2.utils.events]: [0m eta: 0:14:53  iter: 159  total_loss: 0.567  loss_cls: 0.182  loss_box_reg: 0.302  loss_rpn_cls: 0.012  loss_rpn_loc: 0.059  time: 1.0424  data_time: 0.0072  lr: 0.000799  max_mem: 5406M
[32m[04/28 00:30:20 d2.utils.events]: [0m eta: 0:14:32  iter: 179  total_loss: 0.556  loss_cls: 0.186  loss_box_reg: 0.320  loss_rpn_cls: 0.012  loss_rpn_loc: 0.046  time: 1.0419  data_time: 0.0070  lr: 0.000899  max_mem: 5406M
[32m[04/28 00:30:41 d2.utils.events]: [0m eta: 0:14:11  iter: 199  total_loss: 0.579  loss_cls: 0.177  loss_box_reg: 0.329  loss_rpn_cls: 0.015  loss_rpn_loc: 0.041  time: 1.0425  data_time: 0.0078  lr: 0.000999  max_mem: 5406M
[32m[04/28 00:31:03 d2.utils.events]: [0m eta: 0:13:51  iter: 219  total_loss: 0.480  loss_cls: 0.154  loss_box_reg: 0.300  loss_rpn_cls: 0.010  loss_rpn_loc: 0.039  time: 1.0445  data_time: 0.0075  lr: 0.001099  max_mem: 5406M
[32m[04/28 00:31:24 d2.utils.events]: [0m eta: 0:13:30  iter: 239  total_loss: 0.526  loss_cls: 0.166  loss_box_reg: 0.306  loss_rpn_cls: 0.009  loss_rpn_loc: 0.046  time: 1.0448  data_time: 0.0079  lr: 0.001199  max_mem: 5406M
[32m[04/28 00:31:44 d2.utils.events]: [0m eta: 0:13:06  iter: 259  total_loss: 0.485  loss_cls: 0.145  loss_box_reg: 0.279  loss_rpn_cls: 0.007  loss_rpn_loc: 0.040  time: 1.0418  data_time: 0.0074  lr: 0.001299  max_mem: 5406M
[32m[04/28 00:32:04 d2.utils.events]: [0m eta: 0:12:44  iter: 279  total_loss: 0.553  loss_cls: 0.174  loss_box_reg: 0.319  loss_rpn_cls: 0.010  loss_rpn_loc: 0.043  time: 1.0394  data_time: 0.0073  lr: 0.001399  max_mem: 5406M
[32m[04/28 00:32:24 d2.utils.events]: [0m eta: 0:12:21  iter: 299  total_loss: 0.598  loss_cls: 0.190  loss_box_reg: 0.344  loss_rpn_cls: 0.014  loss_rpn_loc: 0.053  time: 1.0372  data_time: 0.0073  lr: 0.001499  max_mem: 5406M
[32m[04/28 00:32:45 d2.utils.events]: [0m eta: 0:11:58  iter: 319  total_loss: 0.525  loss_cls: 0.169  loss_box_reg: 0.307  loss_rpn_cls: 0.009  loss_rpn_loc: 0.036  time: 1.0366  data_time: 0.0074  lr: 0.001598  max_mem: 5406M
[32m[04/28 00:33:06 d2.utils.events]: [0m eta: 0:11:35  iter: 339  total_loss: 0.520  loss_cls: 0.169  loss_box_reg: 0.291  loss_rpn_cls: 0.009  loss_rpn_loc: 0.039  time: 1.0363  data_time: 0.0076  lr: 0.001698  max_mem: 5406M
[32m[04/28 00:33:27 d2.utils.events]: [0m eta: 0:11:14  iter: 359  total_loss: 0.608  loss_cls: 0.200  loss_box_reg: 0.363  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0371  data_time: 0.0078  lr: 0.001798  max_mem: 5406M
[32m[04/28 00:33:47 d2.utils.events]: [0m eta: 0:10:53  iter: 379  total_loss: 0.594  loss_cls: 0.180  loss_box_reg: 0.333  loss_rpn_cls: 0.011  loss_rpn_loc: 0.053  time: 1.0365  data_time: 0.0080  lr: 0.001898  max_mem: 5406M
[32m[04/28 00:34:07 d2.utils.events]: [0m eta: 0:10:30  iter: 399  total_loss: 0.539  loss_cls: 0.165  loss_box_reg: 0.323  loss_rpn_cls: 0.011  loss_rpn_loc: 0.043  time: 1.0340  data_time: 0.0073  lr: 0.001998  max_mem: 5406M
[32m[04/28 00:34:28 d2.utils.events]: [0m eta: 0:10:09  iter: 419  total_loss: 0.612  loss_cls: 0.187  loss_box_reg: 0.355  loss_rpn_cls: 0.014  loss_rpn_loc: 0.052  time: 1.0340  data_time: 0.0074  lr: 0.002098  max_mem: 5406M
[32m[04/28 00:34:48 d2.utils.events]: [0m eta: 0:09:48  iter: 439  total_loss: 0.582  loss_cls: 0.185  loss_box_reg: 0.336  loss_rpn_cls: 0.011  loss_rpn_loc: 0.049  time: 1.0330  data_time: 0.0073  lr: 0.002198  max_mem: 5406M
[32m[04/28 00:35:09 d2.utils.events]: [0m eta: 0:09:27  iter: 459  total_loss: 0.556  loss_cls: 0.168  loss_box_reg: 0.308  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 1.0328  data_time: 0.0080  lr: 0.002298  max_mem: 5406M
[32m[04/28 00:35:30 d2.utils.events]: [0m eta: 0:09:06  iter: 479  total_loss: 0.588  loss_cls: 0.184  loss_box_reg: 0.347  loss_rpn_cls: 0.011  loss_rpn_loc: 0.051  time: 1.0333  data_time: 0.0076  lr: 0.002398  max_mem: 5406M
[32m[04/28 00:35:50 d2.utils.events]: [0m eta: 0:08:45  iter: 499  total_loss: 0.512  loss_cls: 0.160  loss_box_reg: 0.291  loss_rpn_cls: 0.013  loss_rpn_loc: 0.055  time: 1.0326  data_time: 0.0073  lr: 0.002498  max_mem: 5406M
