../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
3 channel input
Require gradient = False for the first several layers of ResNet
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 01:34:17 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 01:34:17 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 01:34:17 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 01:34:18 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 01:34:18 d2.data.build]: [0mDistribution of instances among all 79 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 21744        |    bicycle    | 3806         |      car      | 39372        |
|  motorcycle   | 0            |   airplane    | 0            |      bus      | 0            |
|     train     | 0            |     truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant  | 0            |   stop sign   | 0            |
| parking meter | 0            |     bench     | 0            |     bird      | 0            |
|      cat      | 0            |      dog      | 0            |     horse     | 0            |
|     sheep     | 0            |      cow      | 0            |   elephant    | 0            |
|     bear      | 0            |     zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella    | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase    | 0            |    frisbee    | 0            |
|     skis      | 0            |   snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat  | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |   surfboard   | 0            | tennis racket | 0            |
|    bottle     | 0            |  wine glass   | 0            |      cup      | 0            |
|     fork      | 0            |     knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana     | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange     | 0            |   broccoli    | 0            |
|    carrot     | 0            |    hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake      | 0            |     chair     | 0            |
|     couch     | 0            | potted plant  | 0            |      bed      | 0            |
| dining table  | 0            |    toilet     | 0            |      tv       | 0            |
|    laptop     | 0            |     mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone   | 0            |   microwave   | 0            |
|     oven      | 0            |     bike      | 0            |    hydrant    | 0            |
|     motor     | 0            |     rider     | 0            |     light     | 0            |
|     sign      | 0            | motor vehicle | 0            |  human face   | 0            |
|  hair drier   | 0            |               |              |               |              |
|     total     | 64922        |               |              |               |              |[0m
[32m[04/28 01:34:18 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 01:34:18 d2.data.build]: [0mUsing training sampler TrainingSampler
-------- Changed the weights! ----------
============== The  0  *  1000  iterations ============
[32m[04/28 01:34:20 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 01:34:42 d2.utils.events]: [0m eta: 0:16:49  iter: 19  total_loss: 0.589  loss_cls: 0.182  loss_box_reg: 0.322  loss_rpn_cls: 0.012  loss_rpn_loc: 0.057  time: 1.0215  data_time: 0.0439  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:35:02 d2.utils.events]: [0m eta: 0:16:13  iter: 39  total_loss: 0.632  loss_cls: 0.210  loss_box_reg: 0.344  loss_rpn_cls: 0.012  loss_rpn_loc: 0.058  time: 1.0102  data_time: 0.0069  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:35:23 d2.utils.events]: [0m eta: 0:16:09  iter: 59  total_loss: 0.528  loss_cls: 0.162  loss_box_reg: 0.310  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0178  data_time: 0.0067  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:35:43 d2.utils.events]: [0m eta: 0:15:34  iter: 79  total_loss: 0.591  loss_cls: 0.184  loss_box_reg: 0.345  loss_rpn_cls: 0.013  loss_rpn_loc: 0.054  time: 1.0149  data_time: 0.0069  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:36:04 d2.utils.events]: [0m eta: 0:15:16  iter: 99  total_loss: 0.562  loss_cls: 0.179  loss_box_reg: 0.318  loss_rpn_cls: 0.013  loss_rpn_loc: 0.053  time: 1.0157  data_time: 0.0070  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:36:24 d2.utils.events]: [0m eta: 0:14:53  iter: 119  total_loss: 0.556  loss_cls: 0.169  loss_box_reg: 0.326  loss_rpn_cls: 0.011  loss_rpn_loc: 0.045  time: 1.0106  data_time: 0.0072  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:36:44 d2.utils.events]: [0m eta: 0:14:33  iter: 139  total_loss: 0.643  loss_cls: 0.188  loss_box_reg: 0.355  loss_rpn_cls: 0.012  loss_rpn_loc: 0.052  time: 1.0115  data_time: 0.0067  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:37:05 d2.utils.events]: [0m eta: 0:14:13  iter: 159  total_loss: 0.527  loss_cls: 0.156  loss_box_reg: 0.291  loss_rpn_cls: 0.009  loss_rpn_loc: 0.041  time: 1.0136  data_time: 0.0069  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:37:25 d2.utils.events]: [0m eta: 0:13:53  iter: 179  total_loss: 0.579  loss_cls: 0.180  loss_box_reg: 0.326  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0130  data_time: 0.0072  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:37:46 d2.utils.events]: [0m eta: 0:13:37  iter: 199  total_loss: 0.524  loss_cls: 0.176  loss_box_reg: 0.310  loss_rpn_cls: 0.008  loss_rpn_loc: 0.041  time: 1.0154  data_time: 0.0069  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:38:06 d2.utils.events]: [0m eta: 0:13:23  iter: 219  total_loss: 0.565  loss_cls: 0.180  loss_box_reg: 0.320  loss_rpn_cls: 0.009  loss_rpn_loc: 0.046  time: 1.0165  data_time: 0.0070  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:38:27 d2.utils.events]: [0m eta: 0:12:58  iter: 239  total_loss: 0.598  loss_cls: 0.182  loss_box_reg: 0.334  loss_rpn_cls: 0.012  loss_rpn_loc: 0.053  time: 1.0167  data_time: 0.0076  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:38:47 d2.utils.events]: [0m eta: 0:12:39  iter: 259  total_loss: 0.575  loss_cls: 0.178  loss_box_reg: 0.306  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0176  data_time: 0.0070  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:39:07 d2.utils.events]: [0m eta: 0:12:15  iter: 279  total_loss: 0.578  loss_cls: 0.180  loss_box_reg: 0.328  loss_rpn_cls: 0.010  loss_rpn_loc: 0.053  time: 1.0158  data_time: 0.0067  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:39:27 d2.utils.events]: [0m eta: 0:11:53  iter: 299  total_loss: 0.576  loss_cls: 0.185  loss_box_reg: 0.327  loss_rpn_cls: 0.010  loss_rpn_loc: 0.053  time: 1.0150  data_time: 0.0068  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:39:47 d2.utils.events]: [0m eta: 0:11:31  iter: 319  total_loss: 0.531  loss_cls: 0.158  loss_box_reg: 0.306  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 1.0139  data_time: 0.0070  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:40:08 d2.utils.events]: [0m eta: 0:11:10  iter: 339  total_loss: 0.497  loss_cls: 0.161  loss_box_reg: 0.292  loss_rpn_cls: 0.009  loss_rpn_loc: 0.037  time: 1.0137  data_time: 0.0068  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:40:27 d2.utils.events]: [0m eta: 0:10:50  iter: 359  total_loss: 0.635  loss_cls: 0.188  loss_box_reg: 0.373  loss_rpn_cls: 0.010  loss_rpn_loc: 0.052  time: 1.0121  data_time: 0.0073  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:40:48 d2.utils.events]: [0m eta: 0:10:30  iter: 379  total_loss: 0.495  loss_cls: 0.167  loss_box_reg: 0.293  loss_rpn_cls: 0.012  loss_rpn_loc: 0.045  time: 1.0135  data_time: 0.0069  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:41:09 d2.utils.events]: [0m eta: 0:10:10  iter: 399  total_loss: 0.571  loss_cls: 0.181  loss_box_reg: 0.338  loss_rpn_cls: 0.010  loss_rpn_loc: 0.049  time: 1.0140  data_time: 0.0070  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:41:29 d2.utils.events]: [0m eta: 0:09:49  iter: 419  total_loss: 0.575  loss_cls: 0.179  loss_box_reg: 0.339  loss_rpn_cls: 0.007  loss_rpn_loc: 0.058  time: 1.0131  data_time: 0.0066  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:41:49 d2.utils.events]: [0m eta: 0:09:29  iter: 439  total_loss: 0.546  loss_cls: 0.185  loss_box_reg: 0.312  loss_rpn_cls: 0.010  loss_rpn_loc: 0.044  time: 1.0123  data_time: 0.0069  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:42:09 d2.utils.events]: [0m eta: 0:09:09  iter: 459  total_loss: 0.552  loss_cls: 0.167  loss_box_reg: 0.314  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0130  data_time: 0.0066  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:42:30 d2.utils.events]: [0m eta: 0:08:50  iter: 479  total_loss: 0.606  loss_cls: 0.180  loss_box_reg: 0.340  loss_rpn_cls: 0.009  loss_rpn_loc: 0.050  time: 1.0144  data_time: 0.0071  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:42:51 d2.utils.events]: [0m eta: 0:08:29  iter: 499  total_loss: 0.496  loss_cls: 0.156  loss_box_reg: 0.294  loss_rpn_cls: 0.008  loss_rpn_loc: 0.038  time: 1.0149  data_time: 0.0070  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:43:11 d2.utils.events]: [0m eta: 0:08:10  iter: 519  total_loss: 0.567  loss_cls: 0.162  loss_box_reg: 0.303  loss_rpn_cls: 0.012  loss_rpn_loc: 0.059  time: 1.0157  data_time: 0.0067  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:43:32 d2.utils.events]: [0m eta: 0:07:49  iter: 539  total_loss: 0.634  loss_cls: 0.194  loss_box_reg: 0.368  loss_rpn_cls: 0.010  loss_rpn_loc: 0.059  time: 1.0159  data_time: 0.0067  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:43:53 d2.utils.events]: [0m eta: 0:07:29  iter: 559  total_loss: 0.594  loss_cls: 0.179  loss_box_reg: 0.338  loss_rpn_cls: 0.010  loss_rpn_loc: 0.052  time: 1.0163  data_time: 0.0069  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:44:13 d2.utils.events]: [0m eta: 0:07:09  iter: 579  total_loss: 0.594  loss_cls: 0.177  loss_box_reg: 0.336  loss_rpn_cls: 0.013  loss_rpn_loc: 0.057  time: 1.0169  data_time: 0.0069  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:44:33 d2.utils.events]: [0m eta: 0:06:48  iter: 599  total_loss: 0.510  loss_cls: 0.158  loss_box_reg: 0.314  loss_rpn_cls: 0.012  loss_rpn_loc: 0.044  time: 1.0165  data_time: 0.0069  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:44:54 d2.utils.events]: [0m eta: 0:06:28  iter: 619  total_loss: 0.561  loss_cls: 0.177  loss_box_reg: 0.333  loss_rpn_cls: 0.012  loss_rpn_loc: 0.042  time: 1.0163  data_time: 0.0069  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:45:14 d2.utils.events]: [0m eta: 0:06:07  iter: 639  total_loss: 0.496  loss_cls: 0.168  loss_box_reg: 0.291  loss_rpn_cls: 0.010  loss_rpn_loc: 0.033  time: 1.0169  data_time: 0.0071  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:45:35 d2.utils.events]: [0m eta: 0:05:47  iter: 659  total_loss: 0.553  loss_cls: 0.169  loss_box_reg: 0.316  loss_rpn_cls: 0.008  loss_rpn_loc: 0.048  time: 1.0175  data_time: 0.0070  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:45:56 d2.utils.events]: [0m eta: 0:05:27  iter: 679  total_loss: 0.619  loss_cls: 0.202  loss_box_reg: 0.361  loss_rpn_cls: 0.012  loss_rpn_loc: 0.049  time: 1.0182  data_time: 0.0068  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:46:16 d2.utils.events]: [0m eta: 0:05:07  iter: 699  total_loss: 0.561  loss_cls: 0.167  loss_box_reg: 0.319  loss_rpn_cls: 0.010  loss_rpn_loc: 0.062  time: 1.0182  data_time: 0.0070  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:46:37 d2.utils.events]: [0m eta: 0:04:46  iter: 719  total_loss: 0.540  loss_cls: 0.164  loss_box_reg: 0.309  loss_rpn_cls: 0.010  loss_rpn_loc: 0.049  time: 1.0180  data_time: 0.0068  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:46:57 d2.utils.events]: [0m eta: 0:04:26  iter: 739  total_loss: 0.578  loss_cls: 0.179  loss_box_reg: 0.335  loss_rpn_cls: 0.012  loss_rpn_loc: 0.043  time: 1.0176  data_time: 0.0072  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:47:18 d2.utils.events]: [0m eta: 0:04:05  iter: 759  total_loss: 0.506  loss_cls: 0.157  loss_box_reg: 0.294  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 1.0182  data_time: 0.0069  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:47:38 d2.utils.events]: [0m eta: 0:03:45  iter: 779  total_loss: 0.543  loss_cls: 0.176  loss_box_reg: 0.323  loss_rpn_cls: 0.009  loss_rpn_loc: 0.036  time: 1.0183  data_time: 0.0071  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:47:58 d2.utils.events]: [0m eta: 0:03:24  iter: 799  total_loss: 0.569  loss_cls: 0.179  loss_box_reg: 0.311  loss_rpn_cls: 0.010  loss_rpn_loc: 0.045  time: 1.0174  data_time: 0.0069  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:48:19 d2.utils.events]: [0m eta: 0:03:04  iter: 819  total_loss: 0.650  loss_cls: 0.200  loss_box_reg: 0.367  loss_rpn_cls: 0.012  loss_rpn_loc: 0.064  time: 1.0177  data_time: 0.0068  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:48:39 d2.utils.events]: [0m eta: 0:02:43  iter: 839  total_loss: 0.543  loss_cls: 0.188  loss_box_reg: 0.301  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0171  data_time: 0.0068  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:48:59 d2.utils.events]: [0m eta: 0:02:23  iter: 859  total_loss: 0.560  loss_cls: 0.175  loss_box_reg: 0.339  loss_rpn_cls: 0.010  loss_rpn_loc: 0.043  time: 1.0172  data_time: 0.0070  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:49:20 d2.utils.events]: [0m eta: 0:02:03  iter: 879  total_loss: 0.576  loss_cls: 0.185  loss_box_reg: 0.341  loss_rpn_cls: 0.013  loss_rpn_loc: 0.048  time: 1.0175  data_time: 0.0069  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:49:40 d2.utils.events]: [0m eta: 0:01:42  iter: 899  total_loss: 0.602  loss_cls: 0.182  loss_box_reg: 0.347  loss_rpn_cls: 0.011  loss_rpn_loc: 0.056  time: 1.0174  data_time: 0.0067  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:50:00 d2.utils.events]: [0m eta: 0:01:22  iter: 919  total_loss: 0.565  loss_cls: 0.176  loss_box_reg: 0.346  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0175  data_time: 0.0067  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:50:21 d2.utils.events]: [0m eta: 0:01:02  iter: 939  total_loss: 0.604  loss_cls: 0.185  loss_box_reg: 0.324  loss_rpn_cls: 0.010  loss_rpn_loc: 0.038  time: 1.0178  data_time: 0.0075  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:50:41 d2.utils.events]: [0m eta: 0:00:41  iter: 959  total_loss: 0.576  loss_cls: 0.168  loss_box_reg: 0.332  loss_rpn_cls: 0.011  loss_rpn_loc: 0.052  time: 1.0174  data_time: 0.0069  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:51:02 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.499  loss_cls: 0.157  loss_box_reg: 0.284  loss_rpn_cls: 0.008  loss_rpn_loc: 0.052  time: 1.0180  data_time: 0.0069  lr: 0.000500  max_mem: 5394M
[5m[31mWARNING[0m [32m[04/28 01:51:25 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 01:51:25 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 01:51:25 d2.data.build]: [0mDistribution of instances among all 80 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 5406         |    bicycle    | 420          |      car      | 5008         |
|  motorcycle   | 0            |   airplane    | 0            |      bus      | 0            |
|     train     | 0            |     truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant  | 0            |   stop sign   | 0            |
| parking meter | 0            |     bench     | 0            |     bird      | 0            |
|      cat      | 0            |      dog      | 0            |     horse     | 0            |
|     sheep     | 0            |      cow      | 0            |   elephant    | 0            |
|     bear      | 0            |     zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella    | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase    | 0            |    frisbee    | 0            |
|     skis      | 0            |   snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat  | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |   surfboard   | 0            | tennis racket | 0            |
|    bottle     | 0            |  wine glass   | 0            |      cup      | 0            |
|     fork      | 0            |     knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana     | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange     | 0            |   broccoli    | 0            |
|    carrot     | 0            |    hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake      | 0            |     chair     | 0            |
|     couch     | 0            | potted plant  | 0            |      bed      | 0            |
| dining table  | 0            |    toilet     | 0            |      tv       | 0            |
|    laptop     | 0            |     mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone   | 0            |   microwave   | 0            |
|     oven      | 0            |     bike      | 0            |    hydrant    | 0            |
|     motor     | 0            |     rider     | 0            |     light     | 0            |
|     sign      | 0            | motor vehicle | 0            |  human face   | 0            |
|  hair drier   | 0            | license plate | 0            |               |              |
|     total     | 10834        |               |              |               |              |[0m
[5m[31mWARNING[0m [32m[04/28 01:51:25 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 01:51:25 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.609  loss_cls: 0.198  loss_box_reg: 0.360  loss_rpn_cls: 0.013  loss_rpn_loc: 0.060  time: 1.0180  data_time: 0.0074  lr: 0.000500  max_mem: 5394M
[32m[04/28 01:51:26 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:16:56 (1.0191 s / it)
[32m[04/28 01:51:26 d2.engine.hooks]: [0mTotal training time: 0:17:01 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 01:51:27 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 01:51:27 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 01:51:28 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 01:51:29 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1138 s / img. ETA=0:16:00
[32m[04/28 01:51:34 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1135 s / img. ETA=0:15:55
[32m[04/28 01:51:39 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1134 s / img. ETA=0:15:49
[32m[04/28 01:51:44 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1134 s / img. ETA=0:15:44
[32m[04/28 01:51:49 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1135 s / img. ETA=0:15:40
[32m[04/28 01:51:54 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1135 s / img. ETA=0:15:35
[32m[04/28 01:52:00 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1135 s / img. ETA=0:15:30
[32m[04/28 01:52:05 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1136 s / img. ETA=0:15:25
[32m[04/28 01:52:10 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1136 s / img. ETA=0:15:20
[32m[04/28 01:52:15 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1136 s / img. ETA=0:15:15
[32m[04/28 01:52:20 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1136 s / img. ETA=0:15:10
[32m[04/28 01:52:25 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1135 s / img. ETA=0:15:04
[32m[04/28 01:52:30 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1135 s / img. ETA=0:14:59
[32m[04/28 01:52:35 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1135 s / img. ETA=0:14:54
[32m[04/28 01:52:40 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1135 s / img. ETA=0:14:49
[32m[04/28 01:52:45 d2.evaluation.evaluator]: [0mInference done 671/8355. 0.1135 s / img. ETA=0:14:44
[32m[04/28 01:52:50 d2.evaluation.evaluator]: [0mInference done 715/8355. 0.1135 s / img. ETA=0:14:39
[32m[04/28 01:52:55 d2.evaluation.evaluator]: [0mInference done 759/8355. 0.1135 s / img. ETA=0:14:34
[32m[04/28 01:53:00 d2.evaluation.evaluator]: [0mInference done 803/8355. 0.1135 s / img. ETA=0:14:29
[32m[04/28 01:53:05 d2.evaluation.evaluator]: [0mInference done 847/8355. 0.1135 s / img. ETA=0:14:24
[32m[04/28 01:53:10 d2.evaluation.evaluator]: [0mInference done 890/8355. 0.1136 s / img. ETA=0:14:20
[32m[04/28 01:53:15 d2.evaluation.evaluator]: [0mInference done 934/8355. 0.1136 s / img. ETA=0:14:15
[32m[04/28 01:53:21 d2.evaluation.evaluator]: [0mInference done 978/8355. 0.1136 s / img. ETA=0:14:10
[32m[04/28 01:53:26 d2.evaluation.evaluator]: [0mInference done 1022/8355. 0.1136 s / img. ETA=0:14:05
[32m[04/28 01:53:31 d2.evaluation.evaluator]: [0mInference done 1066/8355. 0.1136 s / img. ETA=0:14:00
[32m[04/28 01:53:36 d2.evaluation.evaluator]: [0mInference done 1110/8355. 0.1137 s / img. ETA=0:13:55
[32m[04/28 01:53:41 d2.evaluation.evaluator]: [0mInference done 1154/8355. 0.1137 s / img. ETA=0:13:50
[32m[04/28 01:53:46 d2.evaluation.evaluator]: [0mInference done 1198/8355. 0.1137 s / img. ETA=0:13:45
[32m[04/28 01:53:51 d2.evaluation.evaluator]: [0mInference done 1242/8355. 0.1137 s / img. ETA=0:13:40
[32m[04/28 01:53:56 d2.evaluation.evaluator]: [0mInference done 1286/8355. 0.1137 s / img. ETA=0:13:35
[32m[04/28 01:54:01 d2.evaluation.evaluator]: [0mInference done 1330/8355. 0.1137 s / img. ETA=0:13:30
[32m[04/28 01:54:06 d2.evaluation.evaluator]: [0mInference done 1374/8355. 0.1137 s / img. ETA=0:13:24
[32m[04/28 01:54:11 d2.evaluation.evaluator]: [0mInference done 1418/8355. 0.1137 s / img. ETA=0:13:19
[32m[04/28 01:54:16 d2.evaluation.evaluator]: [0mInference done 1462/8355. 0.1137 s / img. ETA=0:13:14
[32m[04/28 01:54:21 d2.evaluation.evaluator]: [0mInference done 1505/8355. 0.1137 s / img. ETA=0:13:10
[32m[04/28 01:54:26 d2.evaluation.evaluator]: [0mInference done 1548/8355. 0.1138 s / img. ETA=0:13:05
[32m[04/28 01:54:31 d2.evaluation.evaluator]: [0mInference done 1591/8355. 0.1138 s / img. ETA=0:13:00
[32m[04/28 01:54:37 d2.evaluation.evaluator]: [0mInference done 1634/8355. 0.1138 s / img. ETA=0:12:56
[32m[04/28 01:54:42 d2.evaluation.evaluator]: [0mInference done 1677/8355. 0.1139 s / img. ETA=0:12:51
[32m[04/28 01:54:47 d2.evaluation.evaluator]: [0mInference done 1720/8355. 0.1139 s / img. ETA=0:12:46
[32m[04/28 01:54:52 d2.evaluation.evaluator]: [0mInference done 1763/8355. 0.1139 s / img. ETA=0:12:41
[32m[04/28 01:54:57 d2.evaluation.evaluator]: [0mInference done 1806/8355. 0.1139 s / img. ETA=0:12:36
[32m[04/28 01:55:02 d2.evaluation.evaluator]: [0mInference done 1849/8355. 0.1140 s / img. ETA=0:12:32
[32m[04/28 01:55:07 d2.evaluation.evaluator]: [0mInference done 1892/8355. 0.1140 s / img. ETA=0:12:27
[32m[04/28 01:55:12 d2.evaluation.evaluator]: [0mInference done 1936/8355. 0.1140 s / img. ETA=0:12:22
[32m[04/28 01:55:17 d2.evaluation.evaluator]: [0mInference done 1979/8355. 0.1141 s / img. ETA=0:12:17
[32m[04/28 01:55:22 d2.evaluation.evaluator]: [0mInference done 2023/8355. 0.1141 s / img. ETA=0:12:12
[32m[04/28 01:55:27 d2.evaluation.evaluator]: [0mInference done 2066/8355. 0.1141 s / img. ETA=0:12:07
[32m[04/28 01:55:32 d2.evaluation.evaluator]: [0mInference done 2110/8355. 0.1141 s / img. ETA=0:12:02
[32m[04/28 01:55:37 d2.evaluation.evaluator]: [0mInference done 2154/8355. 0.1141 s / img. ETA=0:11:57
[32m[04/28 01:55:42 d2.evaluation.evaluator]: [0mInference done 2197/8355. 0.1141 s / img. ETA=0:11:52
[32m[04/28 01:55:47 d2.evaluation.evaluator]: [0mInference done 2240/8355. 0.1141 s / img. ETA=0:11:47
[32m[04/28 01:55:52 d2.evaluation.evaluator]: [0mInference done 2283/8355. 0.1141 s / img. ETA=0:11:43
[32m[04/28 01:55:57 d2.evaluation.evaluator]: [0mInference done 2327/8355. 0.1141 s / img. ETA=0:11:37
[32m[04/28 01:56:02 d2.evaluation.evaluator]: [0mInference done 2370/8355. 0.1142 s / img. ETA=0:11:33
[32m[04/28 01:56:07 d2.evaluation.evaluator]: [0mInference done 2413/8355. 0.1142 s / img. ETA=0:11:28
[32m[04/28 01:56:12 d2.evaluation.evaluator]: [0mInference done 2456/8355. 0.1142 s / img. ETA=0:11:23
[32m[04/28 01:56:17 d2.evaluation.evaluator]: [0mInference done 2500/8355. 0.1142 s / img. ETA=0:11:18
[32m[04/28 01:56:23 d2.evaluation.evaluator]: [0mInference done 2544/8355. 0.1142 s / img. ETA=0:11:13
[32m[04/28 01:56:28 d2.evaluation.evaluator]: [0mInference done 2587/8355. 0.1142 s / img. ETA=0:11:08
[32m[04/28 01:56:33 d2.evaluation.evaluator]: [0mInference done 2631/8355. 0.1142 s / img. ETA=0:11:03
[32m[04/28 01:56:38 d2.evaluation.evaluator]: [0mInference done 2674/8355. 0.1142 s / img. ETA=0:10:58
[32m[04/28 01:56:43 d2.evaluation.evaluator]: [0mInference done 2717/8355. 0.1142 s / img. ETA=0:10:53
[32m[04/28 01:56:48 d2.evaluation.evaluator]: [0mInference done 2760/8355. 0.1142 s / img. ETA=0:10:48
[32m[04/28 01:56:53 d2.evaluation.evaluator]: [0mInference done 2803/8355. 0.1143 s / img. ETA=0:10:43
[32m[04/28 01:56:58 d2.evaluation.evaluator]: [0mInference done 2846/8355. 0.1143 s / img. ETA=0:10:38
[32m[04/28 01:57:03 d2.evaluation.evaluator]: [0mInference done 2890/8355. 0.1143 s / img. ETA=0:10:33
[32m[04/28 01:57:08 d2.evaluation.evaluator]: [0mInference done 2933/8355. 0.1143 s / img. ETA=0:10:28
[32m[04/28 01:57:13 d2.evaluation.evaluator]: [0mInference done 2977/8355. 0.1143 s / img. ETA=0:10:23
[32m[04/28 01:57:18 d2.evaluation.evaluator]: [0mInference done 3020/8355. 0.1143 s / img. ETA=0:10:18
[32m[04/28 01:57:23 d2.evaluation.evaluator]: [0mInference done 3064/8355. 0.1143 s / img. ETA=0:10:13
[32m[04/28 01:57:28 d2.evaluation.evaluator]: [0mInference done 3107/8355. 0.1143 s / img. ETA=0:10:08
[32m[04/28 01:57:33 d2.evaluation.evaluator]: [0mInference done 3151/8355. 0.1143 s / img. ETA=0:10:03
[32m[04/28 01:57:38 d2.evaluation.evaluator]: [0mInference done 3195/8355. 0.1143 s / img. ETA=0:09:58
[32m[04/28 01:57:43 d2.evaluation.evaluator]: [0mInference done 3238/8355. 0.1143 s / img. ETA=0:09:53
[32m[04/28 01:57:48 d2.evaluation.evaluator]: [0mInference done 3282/8355. 0.1143 s / img. ETA=0:09:48
[32m[04/28 01:57:54 d2.evaluation.evaluator]: [0mInference done 3326/8355. 0.1143 s / img. ETA=0:09:43
[32m[04/28 01:57:59 d2.evaluation.evaluator]: [0mInference done 3370/8355. 0.1143 s / img. ETA=0:09:38
[32m[04/28 01:58:04 d2.evaluation.evaluator]: [0mInference done 3414/8355. 0.1143 s / img. ETA=0:09:32
[32m[04/28 01:58:09 d2.evaluation.evaluator]: [0mInference done 3458/8355. 0.1143 s / img. ETA=0:09:27
[32m[04/28 01:58:14 d2.evaluation.evaluator]: [0mInference done 3502/8355. 0.1143 s / img. ETA=0:09:22
[32m[04/28 01:58:19 d2.evaluation.evaluator]: [0mInference done 3546/8355. 0.1143 s / img. ETA=0:09:17
[32m[04/28 01:58:24 d2.evaluation.evaluator]: [0mInference done 3589/8355. 0.1143 s / img. ETA=0:09:12
[32m[04/28 01:58:29 d2.evaluation.evaluator]: [0mInference done 3633/8355. 0.1143 s / img. ETA=0:09:07
[32m[04/28 01:58:34 d2.evaluation.evaluator]: [0mInference done 3677/8355. 0.1143 s / img. ETA=0:09:02
[32m[04/28 01:58:39 d2.evaluation.evaluator]: [0mInference done 3720/8355. 0.1143 s / img. ETA=0:08:57
[32m[04/28 01:58:44 d2.evaluation.evaluator]: [0mInference done 3764/8355. 0.1143 s / img. ETA=0:08:52
[32m[04/28 01:58:49 d2.evaluation.evaluator]: [0mInference done 3808/8355. 0.1143 s / img. ETA=0:08:47
[32m[04/28 01:58:55 d2.evaluation.evaluator]: [0mInference done 3851/8355. 0.1143 s / img. ETA=0:08:42
[32m[04/28 01:59:00 d2.evaluation.evaluator]: [0mInference done 3895/8355. 0.1143 s / img. ETA=0:08:37
[32m[04/28 01:59:05 d2.evaluation.evaluator]: [0mInference done 3939/8355. 0.1143 s / img. ETA=0:08:32
[32m[04/28 01:59:10 d2.evaluation.evaluator]: [0mInference done 3982/8355. 0.1143 s / img. ETA=0:08:27
[32m[04/28 01:59:15 d2.evaluation.evaluator]: [0mInference done 4025/8355. 0.1143 s / img. ETA=0:08:22
[32m[04/28 01:59:20 d2.evaluation.evaluator]: [0mInference done 4068/8355. 0.1143 s / img. ETA=0:08:17
[32m[04/28 01:59:25 d2.evaluation.evaluator]: [0mInference done 4111/8355. 0.1143 s / img. ETA=0:08:12
[32m[04/28 01:59:30 d2.evaluation.evaluator]: [0mInference done 4155/8355. 0.1143 s / img. ETA=0:08:07
[32m[04/28 01:59:35 d2.evaluation.evaluator]: [0mInference done 4199/8355. 0.1143 s / img. ETA=0:08:02
[32m[04/28 01:59:40 d2.evaluation.evaluator]: [0mInference done 4243/8355. 0.1143 s / img. ETA=0:07:56
[32m[04/28 01:59:45 d2.evaluation.evaluator]: [0mInference done 4287/8355. 0.1143 s / img. ETA=0:07:51
[32m[04/28 01:59:50 d2.evaluation.evaluator]: [0mInference done 4330/8355. 0.1143 s / img. ETA=0:07:46
[32m[04/28 01:59:55 d2.evaluation.evaluator]: [0mInference done 4374/8355. 0.1143 s / img. ETA=0:07:41
[32m[04/28 02:00:00 d2.evaluation.evaluator]: [0mInference done 4418/8355. 0.1143 s / img. ETA=0:07:36
[32m[04/28 02:00:05 d2.evaluation.evaluator]: [0mInference done 4462/8355. 0.1143 s / img. ETA=0:07:31
[32m[04/28 02:00:11 d2.evaluation.evaluator]: [0mInference done 4506/8355. 0.1143 s / img. ETA=0:07:26
[32m[04/28 02:00:16 d2.evaluation.evaluator]: [0mInference done 4549/8355. 0.1144 s / img. ETA=0:07:21
[32m[04/28 02:00:21 d2.evaluation.evaluator]: [0mInference done 4593/8355. 0.1144 s / img. ETA=0:07:16
[32m[04/28 02:00:26 d2.evaluation.evaluator]: [0mInference done 4636/8355. 0.1144 s / img. ETA=0:07:11
[32m[04/28 02:00:31 d2.evaluation.evaluator]: [0mInference done 4680/8355. 0.1144 s / img. ETA=0:07:06
[32m[04/28 02:00:36 d2.evaluation.evaluator]: [0mInference done 4724/8355. 0.1144 s / img. ETA=0:07:01
[32m[04/28 02:00:41 d2.evaluation.evaluator]: [0mInference done 4768/8355. 0.1144 s / img. ETA=0:06:56
[32m[04/28 02:00:46 d2.evaluation.evaluator]: [0mInference done 4811/8355. 0.1144 s / img. ETA=0:06:51
[32m[04/28 02:00:51 d2.evaluation.evaluator]: [0mInference done 4854/8355. 0.1144 s / img. ETA=0:06:46
[32m[04/28 02:00:56 d2.evaluation.evaluator]: [0mInference done 4897/8355. 0.1144 s / img. ETA=0:06:41
[32m[04/28 02:01:01 d2.evaluation.evaluator]: [0mInference done 4941/8355. 0.1144 s / img. ETA=0:06:36
[32m[04/28 02:01:06 d2.evaluation.evaluator]: [0mInference done 4984/8355. 0.1144 s / img. ETA=0:06:31
[32m[04/28 02:01:11 d2.evaluation.evaluator]: [0mInference done 5028/8355. 0.1144 s / img. ETA=0:06:26
[32m[04/28 02:01:16 d2.evaluation.evaluator]: [0mInference done 5072/8355. 0.1144 s / img. ETA=0:06:20
[32m[04/28 02:01:21 d2.evaluation.evaluator]: [0mInference done 5115/8355. 0.1144 s / img. ETA=0:06:15
[32m[04/28 02:01:26 d2.evaluation.evaluator]: [0mInference done 5158/8355. 0.1144 s / img. ETA=0:06:11
[32m[04/28 02:01:31 d2.evaluation.evaluator]: [0mInference done 5201/8355. 0.1144 s / img. ETA=0:06:06
[32m[04/28 02:01:37 d2.evaluation.evaluator]: [0mInference done 5245/8355. 0.1144 s / img. ETA=0:06:00
[32m[04/28 02:01:42 d2.evaluation.evaluator]: [0mInference done 5289/8355. 0.1144 s / img. ETA=0:05:55
[32m[04/28 02:01:47 d2.evaluation.evaluator]: [0mInference done 5333/8355. 0.1144 s / img. ETA=0:05:50
[32m[04/28 02:01:52 d2.evaluation.evaluator]: [0mInference done 5376/8355. 0.1144 s / img. ETA=0:05:45
[32m[04/28 02:01:57 d2.evaluation.evaluator]: [0mInference done 5419/8355. 0.1144 s / img. ETA=0:05:40
[32m[04/28 02:02:02 d2.evaluation.evaluator]: [0mInference done 5462/8355. 0.1144 s / img. ETA=0:05:35
[32m[04/28 02:02:07 d2.evaluation.evaluator]: [0mInference done 5506/8355. 0.1144 s / img. ETA=0:05:30
[32m[04/28 02:02:12 d2.evaluation.evaluator]: [0mInference done 5549/8355. 0.1144 s / img. ETA=0:05:25
[32m[04/28 02:02:17 d2.evaluation.evaluator]: [0mInference done 5593/8355. 0.1144 s / img. ETA=0:05:20
[32m[04/28 02:02:22 d2.evaluation.evaluator]: [0mInference done 5636/8355. 0.1144 s / img. ETA=0:05:15
[32m[04/28 02:02:27 d2.evaluation.evaluator]: [0mInference done 5679/8355. 0.1145 s / img. ETA=0:05:10
[32m[04/28 02:02:32 d2.evaluation.evaluator]: [0mInference done 5723/8355. 0.1144 s / img. ETA=0:05:05
[32m[04/28 02:02:37 d2.evaluation.evaluator]: [0mInference done 5766/8355. 0.1145 s / img. ETA=0:05:00
[32m[04/28 02:02:42 d2.evaluation.evaluator]: [0mInference done 5809/8355. 0.1145 s / img. ETA=0:04:55
[32m[04/28 02:02:47 d2.evaluation.evaluator]: [0mInference done 5852/8355. 0.1145 s / img. ETA=0:04:50
[32m[04/28 02:02:53 d2.evaluation.evaluator]: [0mInference done 5895/8355. 0.1145 s / img. ETA=0:04:45
[32m[04/28 02:02:58 d2.evaluation.evaluator]: [0mInference done 5938/8355. 0.1145 s / img. ETA=0:04:40
[32m[04/28 02:03:03 d2.evaluation.evaluator]: [0mInference done 5981/8355. 0.1145 s / img. ETA=0:04:35
[32m[04/28 02:03:08 d2.evaluation.evaluator]: [0mInference done 6024/8355. 0.1145 s / img. ETA=0:04:30
[32m[04/28 02:03:13 d2.evaluation.evaluator]: [0mInference done 6067/8355. 0.1145 s / img. ETA=0:04:25
[32m[04/28 02:03:18 d2.evaluation.evaluator]: [0mInference done 6110/8355. 0.1145 s / img. ETA=0:04:20
[32m[04/28 02:03:23 d2.evaluation.evaluator]: [0mInference done 6153/8355. 0.1145 s / img. ETA=0:04:15
[32m[04/28 02:03:28 d2.evaluation.evaluator]: [0mInference done 6196/8355. 0.1145 s / img. ETA=0:04:10
[32m[04/28 02:03:33 d2.evaluation.evaluator]: [0mInference done 6239/8355. 0.1146 s / img. ETA=0:04:05
[32m[04/28 02:03:38 d2.evaluation.evaluator]: [0mInference done 6282/8355. 0.1146 s / img. ETA=0:04:00
[32m[04/28 02:03:43 d2.evaluation.evaluator]: [0mInference done 6325/8355. 0.1146 s / img. ETA=0:03:55
[32m[04/28 02:03:48 d2.evaluation.evaluator]: [0mInference done 6368/8355. 0.1146 s / img. ETA=0:03:50
[32m[04/28 02:03:53 d2.evaluation.evaluator]: [0mInference done 6411/8355. 0.1146 s / img. ETA=0:03:46
[32m[04/28 02:03:58 d2.evaluation.evaluator]: [0mInference done 6454/8355. 0.1146 s / img. ETA=0:03:41
[32m[04/28 02:04:03 d2.evaluation.evaluator]: [0mInference done 6498/8355. 0.1146 s / img. ETA=0:03:35
[32m[04/28 02:04:08 d2.evaluation.evaluator]: [0mInference done 6541/8355. 0.1146 s / img. ETA=0:03:30
[32m[04/28 02:04:13 d2.evaluation.evaluator]: [0mInference done 6584/8355. 0.1146 s / img. ETA=0:03:25
[32m[04/28 02:04:18 d2.evaluation.evaluator]: [0mInference done 6627/8355. 0.1146 s / img. ETA=0:03:20
[32m[04/28 02:04:23 d2.evaluation.evaluator]: [0mInference done 6671/8355. 0.1146 s / img. ETA=0:03:15
[32m[04/28 02:04:29 d2.evaluation.evaluator]: [0mInference done 6715/8355. 0.1146 s / img. ETA=0:03:10
[32m[04/28 02:04:34 d2.evaluation.evaluator]: [0mInference done 6759/8355. 0.1146 s / img. ETA=0:03:05
[32m[04/28 02:04:39 d2.evaluation.evaluator]: [0mInference done 6803/8355. 0.1146 s / img. ETA=0:03:00
[32m[04/28 02:04:44 d2.evaluation.evaluator]: [0mInference done 6846/8355. 0.1146 s / img. ETA=0:02:55
[32m[04/28 02:04:49 d2.evaluation.evaluator]: [0mInference done 6889/8355. 0.1146 s / img. ETA=0:02:50
[32m[04/28 02:04:54 d2.evaluation.evaluator]: [0mInference done 6933/8355. 0.1146 s / img. ETA=0:02:45
[32m[04/28 02:04:59 d2.evaluation.evaluator]: [0mInference done 6976/8355. 0.1146 s / img. ETA=0:02:40
[32m[04/28 02:05:04 d2.evaluation.evaluator]: [0mInference done 7019/8355. 0.1146 s / img. ETA=0:02:35
[32m[04/28 02:05:09 d2.evaluation.evaluator]: [0mInference done 7062/8355. 0.1146 s / img. ETA=0:02:30
[32m[04/28 02:05:14 d2.evaluation.evaluator]: [0mInference done 7105/8355. 0.1146 s / img. ETA=0:02:25
[32m[04/28 02:05:19 d2.evaluation.evaluator]: [0mInference done 7148/8355. 0.1146 s / img. ETA=0:02:20
[32m[04/28 02:05:24 d2.evaluation.evaluator]: [0mInference done 7191/8355. 0.1146 s / img. ETA=0:02:15
[32m[04/28 02:05:29 d2.evaluation.evaluator]: [0mInference done 7233/8355. 0.1146 s / img. ETA=0:02:10
[32m[04/28 02:05:34 d2.evaluation.evaluator]: [0mInference done 7276/8355. 0.1147 s / img. ETA=0:02:05
[32m[04/28 02:05:39 d2.evaluation.evaluator]: [0mInference done 7319/8355. 0.1147 s / img. ETA=0:02:00
[32m[04/28 02:05:44 d2.evaluation.evaluator]: [0mInference done 7362/8355. 0.1147 s / img. ETA=0:01:55
[32m[04/28 02:05:49 d2.evaluation.evaluator]: [0mInference done 7405/8355. 0.1147 s / img. ETA=0:01:50
[32m[04/28 02:05:54 d2.evaluation.evaluator]: [0mInference done 7448/8355. 0.1147 s / img. ETA=0:01:45
[32m[04/28 02:06:00 d2.evaluation.evaluator]: [0mInference done 7491/8355. 0.1147 s / img. ETA=0:01:40
[32m[04/28 02:06:05 d2.evaluation.evaluator]: [0mInference done 7534/8355. 0.1147 s / img. ETA=0:01:35
[32m[04/28 02:06:10 d2.evaluation.evaluator]: [0mInference done 7577/8355. 0.1147 s / img. ETA=0:01:30
[32m[04/28 02:06:15 d2.evaluation.evaluator]: [0mInference done 7620/8355. 0.1147 s / img. ETA=0:01:25
[32m[04/28 02:06:20 d2.evaluation.evaluator]: [0mInference done 7663/8355. 0.1147 s / img. ETA=0:01:20
[32m[04/28 02:06:25 d2.evaluation.evaluator]: [0mInference done 7706/8355. 0.1147 s / img. ETA=0:01:15
[32m[04/28 02:06:30 d2.evaluation.evaluator]: [0mInference done 7749/8355. 0.1147 s / img. ETA=0:01:10
[32m[04/28 02:06:35 d2.evaluation.evaluator]: [0mInference done 7792/8355. 0.1147 s / img. ETA=0:01:05
[32m[04/28 02:06:40 d2.evaluation.evaluator]: [0mInference done 7835/8355. 0.1147 s / img. ETA=0:01:00
[32m[04/28 02:06:45 d2.evaluation.evaluator]: [0mInference done 7878/8355. 0.1147 s / img. ETA=0:00:55
[32m[04/28 02:06:50 d2.evaluation.evaluator]: [0mInference done 7921/8355. 0.1147 s / img. ETA=0:00:50
[32m[04/28 02:06:55 d2.evaluation.evaluator]: [0mInference done 7964/8355. 0.1147 s / img. ETA=0:00:45
[32m[04/28 02:07:00 d2.evaluation.evaluator]: [0mInference done 8007/8355. 0.1147 s / img. ETA=0:00:40
[32m[04/28 02:07:05 d2.evaluation.evaluator]: [0mInference done 8051/8355. 0.1147 s / img. ETA=0:00:35
[32m[04/28 02:07:10 d2.evaluation.evaluator]: [0mInference done 8094/8355. 0.1148 s / img. ETA=0:00:30
[32m[04/28 02:07:15 d2.evaluation.evaluator]: [0mInference done 8137/8355. 0.1148 s / img. ETA=0:00:25
[32m[04/28 02:07:20 d2.evaluation.evaluator]: [0mInference done 8181/8355. 0.1148 s / img. ETA=0:00:20
[32m[04/28 02:07:25 d2.evaluation.evaluator]: [0mInference done 8224/8355. 0.1148 s / img. ETA=0:00:15
[32m[04/28 02:07:30 d2.evaluation.evaluator]: [0mInference done 8267/8355. 0.1148 s / img. ETA=0:00:10
[32m[04/28 02:07:35 d2.evaluation.evaluator]: [0mInference done 8310/8355. 0.1148 s / img. ETA=0:00:05
[32m[04/28 02:07:40 d2.evaluation.evaluator]: [0mInference done 8353/8355. 0.1148 s / img. ETA=0:00:00
[32m[04/28 02:07:41 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:12.255565 (0.116438 s / img per device, on 1 devices)
[32m[04/28 02:07:41 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:15:58 (0.114762 s / img per device, on 1 devices)
[32m[04/28 02:07:41 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 02:07:41 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 02:07:41 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.03s).
Accumulating evaluation results...
DONE (t=2.24s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.807
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.428
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.335
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.582
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.693
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.173
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.497
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.515
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.419
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.645
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.743
[32m[04/28 02:08:04 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.733 | 80.689 | 42.788 | 33.513 | 58.235 | 69.313 |
[32m[04/28 02:08:04 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 44.958 | bicycle       | 34.925 | car            | 54.316 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 02:08:05 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 02:08:05 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 02:08:05 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 02:08:06 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1148 s / img. ETA=0:02:24
[32m[04/28 02:08:11 d2.evaluation.evaluator]: [0mInference done 55/1257. 0.1144 s / img. ETA=0:02:19
[32m[04/28 02:08:16 d2.evaluation.evaluator]: [0mInference done 99/1257. 0.1145 s / img. ETA=0:02:14
[32m[04/28 02:08:22 d2.evaluation.evaluator]: [0mInference done 143/1257. 0.1144 s / img. ETA=0:02:09
[32m[04/28 02:08:27 d2.evaluation.evaluator]: [0mInference done 187/1257. 0.1144 s / img. ETA=0:02:04
[32m[04/28 02:08:32 d2.evaluation.evaluator]: [0mInference done 231/1257. 0.1143 s / img. ETA=0:01:58
[32m[04/28 02:08:37 d2.evaluation.evaluator]: [0mInference done 274/1257. 0.1144 s / img. ETA=0:01:54
[32m[04/28 02:08:42 d2.evaluation.evaluator]: [0mInference done 318/1257. 0.1144 s / img. ETA=0:01:48
[32m[04/28 02:08:47 d2.evaluation.evaluator]: [0mInference done 362/1257. 0.1143 s / img. ETA=0:01:43
[32m[04/28 02:08:52 d2.evaluation.evaluator]: [0mInference done 406/1257. 0.1143 s / img. ETA=0:01:38
[32m[04/28 02:08:57 d2.evaluation.evaluator]: [0mInference done 450/1257. 0.1143 s / img. ETA=0:01:33
[32m[04/28 02:09:02 d2.evaluation.evaluator]: [0mInference done 494/1257. 0.1143 s / img. ETA=0:01:28
[32m[04/28 02:09:07 d2.evaluation.evaluator]: [0mInference done 537/1257. 0.1143 s / img. ETA=0:01:23
[32m[04/28 02:09:12 d2.evaluation.evaluator]: [0mInference done 580/1257. 0.1144 s / img. ETA=0:01:18
[32m[04/28 02:09:17 d2.evaluation.evaluator]: [0mInference done 624/1257. 0.1144 s / img. ETA=0:01:13
[32m[04/28 02:09:22 d2.evaluation.evaluator]: [0mInference done 667/1257. 0.1144 s / img. ETA=0:01:08
[32m[04/28 02:09:27 d2.evaluation.evaluator]: [0mInference done 710/1257. 0.1144 s / img. ETA=0:01:03
[32m[04/28 02:09:32 d2.evaluation.evaluator]: [0mInference done 754/1257. 0.1144 s / img. ETA=0:00:58
[32m[04/28 02:09:38 d2.evaluation.evaluator]: [0mInference done 798/1257. 0.1144 s / img. ETA=0:00:53
[32m[04/28 02:09:43 d2.evaluation.evaluator]: [0mInference done 841/1257. 0.1145 s / img. ETA=0:00:48
[32m[04/28 02:09:48 d2.evaluation.evaluator]: [0mInference done 884/1257. 0.1145 s / img. ETA=0:00:43
[32m[04/28 02:09:53 d2.evaluation.evaluator]: [0mInference done 928/1257. 0.1145 s / img. ETA=0:00:38
[32m[04/28 02:09:58 d2.evaluation.evaluator]: [0mInference done 972/1257. 0.1145 s / img. ETA=0:00:33
[32m[04/28 02:10:03 d2.evaluation.evaluator]: [0mInference done 1015/1257. 0.1145 s / img. ETA=0:00:28
[32m[04/28 02:10:08 d2.evaluation.evaluator]: [0mInference done 1058/1257. 0.1145 s / img. ETA=0:00:23
[32m[04/28 02:10:13 d2.evaluation.evaluator]: [0mInference done 1101/1257. 0.1145 s / img. ETA=0:00:18
[32m[04/28 02:10:18 d2.evaluation.evaluator]: [0mInference done 1144/1257. 0.1146 s / img. ETA=0:00:13
[32m[04/28 02:10:23 d2.evaluation.evaluator]: [0mInference done 1187/1257. 0.1146 s / img. ETA=0:00:08
[32m[04/28 02:10:28 d2.evaluation.evaluator]: [0mInference done 1230/1257. 0.1146 s / img. ETA=0:00:03
[32m[04/28 02:10:31 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:25.595142 (0.116290 s / img per device, on 1 devices)
[32m[04/28 02:10:31 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:23 (0.114605 s / img per device, on 1 devices)
[32m[04/28 02:10:31 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 02:10:31 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 02:10:31 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.31s).
Accumulating evaluation results...
DONE (t=0.38s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.414
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.783
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.371
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.291
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.486
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.192
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.484
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.388
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.555
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.679
[32m[04/28 02:10:35 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.438 | 78.272 | 37.104 | 29.107 | 48.635 | 61.556 |
[32m[04/28 02:10:35 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 44.409 | bicycle       | 24.803 | car            | 55.102 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  1  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 02:10:36 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 02:10:36 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 02:10:36 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 02:10:36 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 02:10:37 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 02:10:37 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 02:10:37 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 02:10:57 d2.utils.events]: [0m eta: 0:16:29  iter: 19  total_loss: 0.539  loss_cls: 0.166  loss_box_reg: 0.325  loss_rpn_cls: 0.012  loss_rpn_loc: 0.044  time: 1.0066  data_time: 0.0207  lr: 0.000100  max_mem: 5394M
[32m[04/28 02:11:17 d2.utils.events]: [0m eta: 0:16:30  iter: 39  total_loss: 0.599  loss_cls: 0.184  loss_box_reg: 0.341  loss_rpn_cls: 0.010  loss_rpn_loc: 0.057  time: 1.0189  data_time: 0.0073  lr: 0.000200  max_mem: 5394M
[32m[04/28 02:11:38 d2.utils.events]: [0m eta: 0:16:01  iter: 59  total_loss: 0.547  loss_cls: 0.174  loss_box_reg: 0.312  loss_rpn_cls: 0.010  loss_rpn_loc: 0.051  time: 1.0212  data_time: 0.0072  lr: 0.000300  max_mem: 5394M
[32m[04/28 02:11:59 d2.utils.events]: [0m eta: 0:15:55  iter: 79  total_loss: 0.587  loss_cls: 0.180  loss_box_reg: 0.332  loss_rpn_cls: 0.009  loss_rpn_loc: 0.051  time: 1.0264  data_time: 0.0074  lr: 0.000400  max_mem: 5394M
[32m[04/28 02:12:19 d2.utils.events]: [0m eta: 0:15:22  iter: 99  total_loss: 0.519  loss_cls: 0.168  loss_box_reg: 0.302  loss_rpn_cls: 0.012  loss_rpn_loc: 0.048  time: 1.0234  data_time: 0.0076  lr: 0.000500  max_mem: 5394M
[32m[04/28 02:12:40 d2.utils.events]: [0m eta: 0:15:07  iter: 119  total_loss: 0.571  loss_cls: 0.172  loss_box_reg: 0.340  loss_rpn_cls: 0.009  loss_rpn_loc: 0.053  time: 1.0269  data_time: 0.0075  lr: 0.000599  max_mem: 5394M
[32m[04/28 02:13:00 d2.utils.events]: [0m eta: 0:14:42  iter: 139  total_loss: 0.589  loss_cls: 0.204  loss_box_reg: 0.341  loss_rpn_cls: 0.010  loss_rpn_loc: 0.048  time: 1.0234  data_time: 0.0073  lr: 0.000699  max_mem: 5394M
[32m[04/28 02:13:21 d2.utils.events]: [0m eta: 0:14:24  iter: 159  total_loss: 0.576  loss_cls: 0.181  loss_box_reg: 0.330  loss_rpn_cls: 0.011  loss_rpn_loc: 0.044  time: 1.0233  data_time: 0.0075  lr: 0.000799  max_mem: 5394M
[32m[04/28 02:13:41 d2.utils.events]: [0m eta: 0:14:03  iter: 179  total_loss: 0.526  loss_cls: 0.159  loss_box_reg: 0.307  loss_rpn_cls: 0.009  loss_rpn_loc: 0.042  time: 1.0244  data_time: 0.0074  lr: 0.000899  max_mem: 5394M
[32m[04/28 02:14:02 d2.utils.events]: [0m eta: 0:13:45  iter: 199  total_loss: 0.604  loss_cls: 0.186  loss_box_reg: 0.341  loss_rpn_cls: 0.009  loss_rpn_loc: 0.052  time: 1.0266  data_time: 0.0075  lr: 0.000999  max_mem: 5394M
[32m[04/28 02:14:23 d2.utils.events]: [0m eta: 0:13:32  iter: 219  total_loss: 0.576  loss_cls: 0.185  loss_box_reg: 0.336  loss_rpn_cls: 0.009  loss_rpn_loc: 0.046  time: 1.0290  data_time: 0.0076  lr: 0.001099  max_mem: 5394M
[32m[04/28 02:14:44 d2.utils.events]: [0m eta: 0:13:12  iter: 239  total_loss: 0.579  loss_cls: 0.182  loss_box_reg: 0.358  loss_rpn_cls: 0.014  loss_rpn_loc: 0.043  time: 1.0305  data_time: 0.0076  lr: 0.001199  max_mem: 5394M
[32m[04/28 02:15:06 d2.utils.events]: [0m eta: 0:12:52  iter: 259  total_loss: 0.557  loss_cls: 0.170  loss_box_reg: 0.308  loss_rpn_cls: 0.008  loss_rpn_loc: 0.051  time: 1.0322  data_time: 0.0074  lr: 0.001299  max_mem: 5394M
[32m[04/28 02:15:26 d2.utils.events]: [0m eta: 0:12:32  iter: 279  total_loss: 0.610  loss_cls: 0.194  loss_box_reg: 0.344  loss_rpn_cls: 0.012  loss_rpn_loc: 0.057  time: 1.0328  data_time: 0.0076  lr: 0.001399  max_mem: 5394M
[32m[04/28 02:15:47 d2.utils.events]: [0m eta: 0:12:11  iter: 299  total_loss: 0.646  loss_cls: 0.193  loss_box_reg: 0.347  loss_rpn_cls: 0.010  loss_rpn_loc: 0.049  time: 1.0332  data_time: 0.0077  lr: 0.001499  max_mem: 5394M
[32m[04/28 02:16:08 d2.utils.events]: [0m eta: 0:11:51  iter: 319  total_loss: 0.587  loss_cls: 0.186  loss_box_reg: 0.351  loss_rpn_cls: 0.010  loss_rpn_loc: 0.049  time: 1.0333  data_time: 0.0076  lr: 0.001598  max_mem: 5394M
[32m[04/28 02:16:28 d2.utils.events]: [0m eta: 0:11:25  iter: 339  total_loss: 0.569  loss_cls: 0.173  loss_box_reg: 0.327  loss_rpn_cls: 0.010  loss_rpn_loc: 0.053  time: 1.0298  data_time: 0.0074  lr: 0.001698  max_mem: 5394M
[32m[04/28 02:16:48 d2.utils.events]: [0m eta: 0:11:04  iter: 359  total_loss: 0.563  loss_cls: 0.177  loss_box_reg: 0.322  loss_rpn_cls: 0.009  loss_rpn_loc: 0.041  time: 1.0290  data_time: 0.0079  lr: 0.001798  max_mem: 5394M
[32m[04/28 02:17:09 d2.utils.events]: [0m eta: 0:10:45  iter: 379  total_loss: 0.568  loss_cls: 0.182  loss_box_reg: 0.327  loss_rpn_cls: 0.009  loss_rpn_loc: 0.042  time: 1.0289  data_time: 0.0076  lr: 0.001898  max_mem: 5394M
[32m[04/28 02:17:29 d2.utils.events]: [0m eta: 0:10:23  iter: 399  total_loss: 0.574  loss_cls: 0.185  loss_box_reg: 0.316  loss_rpn_cls: 0.009  loss_rpn_loc: 0.053  time: 1.0289  data_time: 0.0076  lr: 0.001998  max_mem: 5394M
[32m[04/28 02:17:50 d2.utils.events]: [0m eta: 0:10:01  iter: 419  total_loss: 0.651  loss_cls: 0.205  loss_box_reg: 0.369  loss_rpn_cls: 0.010  loss_rpn_loc: 0.052  time: 1.0287  data_time: 0.0074  lr: 0.002098  max_mem: 5394M
[32m[04/28 02:18:10 d2.utils.events]: [0m eta: 0:09:41  iter: 439  total_loss: 0.542  loss_cls: 0.164  loss_box_reg: 0.308  loss_rpn_cls: 0.010  loss_rpn_loc: 0.049  time: 1.0287  data_time: 0.0076  lr: 0.002198  max_mem: 5394M
[32m[04/28 02:18:31 d2.utils.events]: [0m eta: 0:09:19  iter: 459  total_loss: 0.625  loss_cls: 0.197  loss_box_reg: 0.323  loss_rpn_cls: 0.016  loss_rpn_loc: 0.062  time: 1.0281  data_time: 0.0075  lr: 0.002298  max_mem: 5394M
[32m[04/28 02:18:52 d2.utils.events]: [0m eta: 0:08:58  iter: 479  total_loss: 0.571  loss_cls: 0.183  loss_box_reg: 0.325  loss_rpn_cls: 0.011  loss_rpn_loc: 0.046  time: 1.0286  data_time: 0.0075  lr: 0.002398  max_mem: 5394M
[32m[04/28 02:19:12 d2.utils.events]: [0m eta: 0:08:38  iter: 499  total_loss: 0.642  loss_cls: 0.209  loss_box_reg: 0.365  loss_rpn_cls: 0.013  loss_rpn_loc: 0.066  time: 1.0287  data_time: 0.0077  lr: 0.002498  max_mem: 5394M
[32m[04/28 02:19:33 d2.utils.events]: [0m eta: 0:08:17  iter: 519  total_loss: 0.555  loss_cls: 0.168  loss_box_reg: 0.341  loss_rpn_cls: 0.011  loss_rpn_loc: 0.055  time: 1.0290  data_time: 0.0076  lr: 0.002597  max_mem: 5394M
[32m[04/28 02:19:54 d2.utils.events]: [0m eta: 0:07:57  iter: 539  total_loss: 0.648  loss_cls: 0.203  loss_box_reg: 0.367  loss_rpn_cls: 0.015  loss_rpn_loc: 0.047  time: 1.0294  data_time: 0.0075  lr: 0.002697  max_mem: 5394M
[32m[04/28 02:20:14 d2.utils.events]: [0m eta: 0:07:36  iter: 559  total_loss: 0.541  loss_cls: 0.174  loss_box_reg: 0.314  loss_rpn_cls: 0.010  loss_rpn_loc: 0.043  time: 1.0293  data_time: 0.0076  lr: 0.002797  max_mem: 5394M
[32m[04/28 02:20:35 d2.utils.events]: [0m eta: 0:07:15  iter: 579  total_loss: 0.544  loss_cls: 0.165  loss_box_reg: 0.313  loss_rpn_cls: 0.011  loss_rpn_loc: 0.060  time: 1.0287  data_time: 0.0074  lr: 0.002897  max_mem: 5394M
[32m[04/28 02:20:56 d2.utils.events]: [0m eta: 0:06:55  iter: 599  total_loss: 0.534  loss_cls: 0.192  loss_box_reg: 0.309  loss_rpn_cls: 0.015  loss_rpn_loc: 0.048  time: 1.0292  data_time: 0.0076  lr: 0.002997  max_mem: 5394M
[32m[04/28 02:21:16 d2.utils.events]: [0m eta: 0:06:33  iter: 619  total_loss: 0.595  loss_cls: 0.182  loss_box_reg: 0.327  loss_rpn_cls: 0.015  loss_rpn_loc: 0.050  time: 1.0285  data_time: 0.0075  lr: 0.003097  max_mem: 5394M
[32m[04/28 02:21:36 d2.utils.events]: [0m eta: 0:06:13  iter: 639  total_loss: 0.567  loss_cls: 0.180  loss_box_reg: 0.309  loss_rpn_cls: 0.013  loss_rpn_loc: 0.041  time: 1.0284  data_time: 0.0079  lr: 0.003197  max_mem: 5394M
[32m[04/28 02:21:57 d2.utils.events]: [0m eta: 0:05:51  iter: 659  total_loss: 0.645  loss_cls: 0.195  loss_box_reg: 0.357  loss_rpn_cls: 0.016  loss_rpn_loc: 0.050  time: 1.0277  data_time: 0.0074  lr: 0.003297  max_mem: 5394M
[32m[04/28 02:22:17 d2.utils.events]: [0m eta: 0:05:31  iter: 679  total_loss: 0.610  loss_cls: 0.212  loss_box_reg: 0.344  loss_rpn_cls: 0.012  loss_rpn_loc: 0.052  time: 1.0273  data_time: 0.0076  lr: 0.003397  max_mem: 5394M
[32m[04/28 02:22:37 d2.utils.events]: [0m eta: 0:05:10  iter: 699  total_loss: 0.600  loss_cls: 0.189  loss_box_reg: 0.337  loss_rpn_cls: 0.012  loss_rpn_loc: 0.062  time: 1.0270  data_time: 0.0075  lr: 0.003497  max_mem: 5394M
[32m[04/28 02:22:58 d2.utils.events]: [0m eta: 0:04:50  iter: 719  total_loss: 0.655  loss_cls: 0.211  loss_box_reg: 0.331  loss_rpn_cls: 0.017  loss_rpn_loc: 0.062  time: 1.0274  data_time: 0.0076  lr: 0.003596  max_mem: 5394M
[32m[04/28 02:23:18 d2.utils.events]: [0m eta: 0:04:29  iter: 739  total_loss: 0.633  loss_cls: 0.190  loss_box_reg: 0.363  loss_rpn_cls: 0.010  loss_rpn_loc: 0.051  time: 1.0269  data_time: 0.0073  lr: 0.003696  max_mem: 5394M
[32m[04/28 02:23:39 d2.utils.events]: [0m eta: 0:04:08  iter: 759  total_loss: 0.600  loss_cls: 0.202  loss_box_reg: 0.334  loss_rpn_cls: 0.013  loss_rpn_loc: 0.057  time: 1.0266  data_time: 0.0075  lr: 0.003796  max_mem: 5394M
[32m[04/28 02:23:59 d2.utils.events]: [0m eta: 0:03:47  iter: 779  total_loss: 0.599  loss_cls: 0.191  loss_box_reg: 0.341  loss_rpn_cls: 0.013  loss_rpn_loc: 0.058  time: 1.0261  data_time: 0.0074  lr: 0.003896  max_mem: 5394M
[32m[04/28 02:24:20 d2.utils.events]: [0m eta: 0:03:27  iter: 799  total_loss: 0.604  loss_cls: 0.190  loss_box_reg: 0.355  loss_rpn_cls: 0.009  loss_rpn_loc: 0.051  time: 1.0266  data_time: 0.0076  lr: 0.003996  max_mem: 5394M
[32m[04/28 02:24:40 d2.utils.events]: [0m eta: 0:03:06  iter: 819  total_loss: 0.678  loss_cls: 0.207  loss_box_reg: 0.384  loss_rpn_cls: 0.016  loss_rpn_loc: 0.060  time: 1.0266  data_time: 0.0076  lr: 0.004096  max_mem: 5394M
[32m[04/28 02:25:01 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.553  loss_cls: 0.180  loss_box_reg: 0.309  loss_rpn_cls: 0.012  loss_rpn_loc: 0.045  time: 1.0264  data_time: 0.0074  lr: 0.004196  max_mem: 5394M
[32m[04/28 02:25:22 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.596  loss_cls: 0.186  loss_box_reg: 0.339  loss_rpn_cls: 0.011  loss_rpn_loc: 0.044  time: 1.0266  data_time: 0.0077  lr: 0.004296  max_mem: 5394M
[32m[04/28 02:25:42 d2.utils.events]: [0m eta: 0:02:04  iter: 879  total_loss: 0.601  loss_cls: 0.189  loss_box_reg: 0.336  loss_rpn_cls: 0.015  loss_rpn_loc: 0.054  time: 1.0265  data_time: 0.0076  lr: 0.004396  max_mem: 5394M
[32m[04/28 02:26:03 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.604  loss_cls: 0.180  loss_box_reg: 0.355  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0267  data_time: 0.0076  lr: 0.004496  max_mem: 5394M
[32m[04/28 02:26:23 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.630  loss_cls: 0.214  loss_box_reg: 0.365  loss_rpn_cls: 0.012  loss_rpn_loc: 0.047  time: 1.0264  data_time: 0.0075  lr: 0.004595  max_mem: 5394M
[32m[04/28 02:26:44 d2.utils.events]: [0m eta: 0:01:02  iter: 939  total_loss: 0.615  loss_cls: 0.202  loss_box_reg: 0.356  loss_rpn_cls: 0.016  loss_rpn_loc: 0.056  time: 1.0264  data_time: 0.0074  lr: 0.004695  max_mem: 5394M
[32m[04/28 02:27:04 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.680  loss_cls: 0.207  loss_box_reg: 0.370  loss_rpn_cls: 0.011  loss_rpn_loc: 0.065  time: 1.0262  data_time: 0.0073  lr: 0.004795  max_mem: 5394M
[32m[04/28 02:27:25 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.613  loss_cls: 0.215  loss_box_reg: 0.336  loss_rpn_cls: 0.013  loss_rpn_loc: 0.054  time: 1.0260  data_time: 0.0074  lr: 0.004895  max_mem: 5394M
[5m[31mWARNING[0m [32m[04/28 02:27:48 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 02:27:48 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 02:27:48 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 02:27:48 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.644  loss_cls: 0.199  loss_box_reg: 0.354  loss_rpn_cls: 0.015  loss_rpn_loc: 0.050  time: 1.0262  data_time: 0.0074  lr: 0.004995  max_mem: 5394M
[32m[04/28 02:27:48 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:04 (1.0273 s / it)
[32m[04/28 02:27:48 d2.engine.hooks]: [0mTotal training time: 0:17:09 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 02:27:50 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 02:27:50 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 02:27:50 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 02:27:52 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1141 s / img. ETA=0:16:03
[32m[04/28 02:27:57 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1136 s / img. ETA=0:15:56
[32m[04/28 02:28:02 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1136 s / img. ETA=0:15:51
[32m[04/28 02:28:07 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1137 s / img. ETA=0:15:46
[32m[04/28 02:28:12 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1137 s / img. ETA=0:15:41
[32m[04/28 02:28:17 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1137 s / img. ETA=0:15:37
[32m[04/28 02:28:22 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1138 s / img. ETA=0:15:32
[32m[04/28 02:28:27 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1138 s / img. ETA=0:15:27
[32m[04/28 02:28:32 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1138 s / img. ETA=0:15:22
[32m[04/28 02:28:37 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1138 s / img. ETA=0:15:17
[32m[04/28 02:28:43 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1138 s / img. ETA=0:15:13
[32m[04/28 02:28:48 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1138 s / img. ETA=0:15:07
[32m[04/28 02:28:53 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1138 s / img. ETA=0:15:02
[32m[04/28 02:28:58 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1138 s / img. ETA=0:14:57
[32m[04/28 02:29:03 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1138 s / img. ETA=0:14:52
[32m[04/28 02:29:08 d2.evaluation.evaluator]: [0mInference done 671/8355. 0.1138 s / img. ETA=0:14:47
[32m[04/28 02:29:13 d2.evaluation.evaluator]: [0mInference done 715/8355. 0.1139 s / img. ETA=0:14:42
[32m[04/28 02:29:18 d2.evaluation.evaluator]: [0mInference done 759/8355. 0.1139 s / img. ETA=0:14:37
[32m[04/28 02:29:23 d2.evaluation.evaluator]: [0mInference done 802/8355. 0.1139 s / img. ETA=0:14:33
[32m[04/28 02:29:28 d2.evaluation.evaluator]: [0mInference done 846/8355. 0.1139 s / img. ETA=0:14:28
[32m[04/28 02:29:33 d2.evaluation.evaluator]: [0mInference done 889/8355. 0.1140 s / img. ETA=0:14:23
[32m[04/28 02:29:38 d2.evaluation.evaluator]: [0mInference done 932/8355. 0.1140 s / img. ETA=0:14:18
[32m[04/28 02:29:43 d2.evaluation.evaluator]: [0mInference done 976/8355. 0.1140 s / img. ETA=0:14:13
[32m[04/28 02:29:48 d2.evaluation.evaluator]: [0mInference done 1020/8355. 0.1140 s / img. ETA=0:14:08
[32m[04/28 02:29:53 d2.evaluation.evaluator]: [0mInference done 1063/8355. 0.1140 s / img. ETA=0:14:03
[32m[04/28 02:29:59 d2.evaluation.evaluator]: [0mInference done 1107/8355. 0.1140 s / img. ETA=0:13:58
[32m[04/28 02:30:04 d2.evaluation.evaluator]: [0mInference done 1151/8355. 0.1140 s / img. ETA=0:13:53
[32m[04/28 02:30:09 d2.evaluation.evaluator]: [0mInference done 1195/8355. 0.1140 s / img. ETA=0:13:48
[32m[04/28 02:30:14 d2.evaluation.evaluator]: [0mInference done 1239/8355. 0.1140 s / img. ETA=0:13:43
[32m[04/28 02:30:19 d2.evaluation.evaluator]: [0mInference done 1283/8355. 0.1140 s / img. ETA=0:13:38
[32m[04/28 02:30:24 d2.evaluation.evaluator]: [0mInference done 1327/8355. 0.1140 s / img. ETA=0:13:32
[32m[04/28 02:30:29 d2.evaluation.evaluator]: [0mInference done 1371/8355. 0.1140 s / img. ETA=0:13:27
[32m[04/28 02:30:34 d2.evaluation.evaluator]: [0mInference done 1415/8355. 0.1140 s / img. ETA=0:13:22
[32m[04/28 02:30:39 d2.evaluation.evaluator]: [0mInference done 1457/8355. 0.1141 s / img. ETA=0:13:19
[32m[04/28 02:30:44 d2.evaluation.evaluator]: [0mInference done 1500/8355. 0.1142 s / img. ETA=0:13:14
[32m[04/28 02:30:49 d2.evaluation.evaluator]: [0mInference done 1543/8355. 0.1142 s / img. ETA=0:13:09
[32m[04/28 02:30:54 d2.evaluation.evaluator]: [0mInference done 1586/8355. 0.1143 s / img. ETA=0:13:05
[32m[04/28 02:30:59 d2.evaluation.evaluator]: [0mInference done 1629/8355. 0.1143 s / img. ETA=0:13:00
[32m[04/28 02:31:05 d2.evaluation.evaluator]: [0mInference done 1672/8355. 0.1144 s / img. ETA=0:12:55
[32m[04/28 02:31:10 d2.evaluation.evaluator]: [0mInference done 1715/8355. 0.1144 s / img. ETA=0:12:50
[32m[04/28 02:31:15 d2.evaluation.evaluator]: [0mInference done 1758/8355. 0.1144 s / img. ETA=0:12:46
[32m[04/28 02:31:20 d2.evaluation.evaluator]: [0mInference done 1801/8355. 0.1145 s / img. ETA=0:12:41
[32m[04/28 02:31:25 d2.evaluation.evaluator]: [0mInference done 1844/8355. 0.1145 s / img. ETA=0:12:36
[32m[04/28 02:31:30 d2.evaluation.evaluator]: [0mInference done 1887/8355. 0.1145 s / img. ETA=0:12:31
[32m[04/28 02:31:35 d2.evaluation.evaluator]: [0mInference done 1930/8355. 0.1145 s / img. ETA=0:12:26
[32m[04/28 02:31:40 d2.evaluation.evaluator]: [0mInference done 1973/8355. 0.1146 s / img. ETA=0:12:22
[32m[04/28 02:31:45 d2.evaluation.evaluator]: [0mInference done 2016/8355. 0.1146 s / img. ETA=0:12:17
[32m[04/28 02:31:50 d2.evaluation.evaluator]: [0mInference done 2059/8355. 0.1146 s / img. ETA=0:12:12
[32m[04/28 02:31:55 d2.evaluation.evaluator]: [0mInference done 2102/8355. 0.1146 s / img. ETA=0:12:07
[32m[04/28 02:32:00 d2.evaluation.evaluator]: [0mInference done 2146/8355. 0.1146 s / img. ETA=0:12:02
[32m[04/28 02:32:05 d2.evaluation.evaluator]: [0mInference done 2189/8355. 0.1146 s / img. ETA=0:11:57
[32m[04/28 02:32:10 d2.evaluation.evaluator]: [0mInference done 2232/8355. 0.1146 s / img. ETA=0:11:52
[32m[04/28 02:32:15 d2.evaluation.evaluator]: [0mInference done 2275/8355. 0.1147 s / img. ETA=0:11:47
[32m[04/28 02:32:20 d2.evaluation.evaluator]: [0mInference done 2318/8355. 0.1147 s / img. ETA=0:11:42
[32m[04/28 02:32:25 d2.evaluation.evaluator]: [0mInference done 2361/8355. 0.1147 s / img. ETA=0:11:37
[32m[04/28 02:32:30 d2.evaluation.evaluator]: [0mInference done 2404/8355. 0.1147 s / img. ETA=0:11:32
[32m[04/28 02:32:35 d2.evaluation.evaluator]: [0mInference done 2446/8355. 0.1147 s / img. ETA=0:11:28
[32m[04/28 02:32:40 d2.evaluation.evaluator]: [0mInference done 2490/8355. 0.1147 s / img. ETA=0:11:23
[32m[04/28 02:32:46 d2.evaluation.evaluator]: [0mInference done 2533/8355. 0.1147 s / img. ETA=0:11:18
[32m[04/28 02:32:51 d2.evaluation.evaluator]: [0mInference done 2576/8355. 0.1147 s / img. ETA=0:11:13
[32m[04/28 02:32:56 d2.evaluation.evaluator]: [0mInference done 2619/8355. 0.1147 s / img. ETA=0:11:08
[32m[04/28 02:33:01 d2.evaluation.evaluator]: [0mInference done 2662/8355. 0.1148 s / img. ETA=0:11:03
[32m[04/28 02:33:06 d2.evaluation.evaluator]: [0mInference done 2705/8355. 0.1148 s / img. ETA=0:10:58
[32m[04/28 02:33:11 d2.evaluation.evaluator]: [0mInference done 2748/8355. 0.1148 s / img. ETA=0:10:53
[32m[04/28 02:33:16 d2.evaluation.evaluator]: [0mInference done 2791/8355. 0.1148 s / img. ETA=0:10:48
[32m[04/28 02:33:21 d2.evaluation.evaluator]: [0mInference done 2834/8355. 0.1148 s / img. ETA=0:10:43
[32m[04/28 02:33:26 d2.evaluation.evaluator]: [0mInference done 2877/8355. 0.1148 s / img. ETA=0:10:38
[32m[04/28 02:33:31 d2.evaluation.evaluator]: [0mInference done 2920/8355. 0.1148 s / img. ETA=0:10:33
[32m[04/28 02:33:36 d2.evaluation.evaluator]: [0mInference done 2963/8355. 0.1149 s / img. ETA=0:10:28
[32m[04/28 02:33:41 d2.evaluation.evaluator]: [0mInference done 3007/8355. 0.1148 s / img. ETA=0:10:23
[32m[04/28 02:33:46 d2.evaluation.evaluator]: [0mInference done 3050/8355. 0.1149 s / img. ETA=0:10:18
[32m[04/28 02:33:51 d2.evaluation.evaluator]: [0mInference done 3093/8355. 0.1149 s / img. ETA=0:10:13
[32m[04/28 02:33:56 d2.evaluation.evaluator]: [0mInference done 3136/8355. 0.1149 s / img. ETA=0:10:08
[32m[04/28 02:34:01 d2.evaluation.evaluator]: [0mInference done 3180/8355. 0.1149 s / img. ETA=0:10:03
[32m[04/28 02:34:06 d2.evaluation.evaluator]: [0mInference done 3224/8355. 0.1149 s / img. ETA=0:09:58
[32m[04/28 02:34:11 d2.evaluation.evaluator]: [0mInference done 3267/8355. 0.1149 s / img. ETA=0:09:53
[32m[04/28 02:34:17 d2.evaluation.evaluator]: [0mInference done 3311/8355. 0.1148 s / img. ETA=0:09:48
[32m[04/28 02:34:22 d2.evaluation.evaluator]: [0mInference done 3354/8355. 0.1148 s / img. ETA=0:09:43
[32m[04/28 02:34:27 d2.evaluation.evaluator]: [0mInference done 3397/8355. 0.1148 s / img. ETA=0:09:38
[32m[04/28 02:34:32 d2.evaluation.evaluator]: [0mInference done 3440/8355. 0.1148 s / img. ETA=0:09:33
[32m[04/28 02:34:37 d2.evaluation.evaluator]: [0mInference done 3483/8355. 0.1148 s / img. ETA=0:09:28
[32m[04/28 02:34:42 d2.evaluation.evaluator]: [0mInference done 3526/8355. 0.1148 s / img. ETA=0:09:23
[32m[04/28 02:34:47 d2.evaluation.evaluator]: [0mInference done 3570/8355. 0.1148 s / img. ETA=0:09:17
[32m[04/28 02:34:52 d2.evaluation.evaluator]: [0mInference done 3613/8355. 0.1148 s / img. ETA=0:09:12
[32m[04/28 02:34:57 d2.evaluation.evaluator]: [0mInference done 3656/8355. 0.1148 s / img. ETA=0:09:07
[32m[04/28 02:35:02 d2.evaluation.evaluator]: [0mInference done 3699/8355. 0.1148 s / img. ETA=0:09:02
[32m[04/28 02:35:07 d2.evaluation.evaluator]: [0mInference done 3742/8355. 0.1148 s / img. ETA=0:08:57
[32m[04/28 02:35:12 d2.evaluation.evaluator]: [0mInference done 3786/8355. 0.1148 s / img. ETA=0:08:52
[32m[04/28 02:35:17 d2.evaluation.evaluator]: [0mInference done 3829/8355. 0.1148 s / img. ETA=0:08:47
[32m[04/28 02:35:22 d2.evaluation.evaluator]: [0mInference done 3872/8355. 0.1148 s / img. ETA=0:08:42
[32m[04/28 02:35:27 d2.evaluation.evaluator]: [0mInference done 3916/8355. 0.1148 s / img. ETA=0:08:37
[32m[04/28 02:35:32 d2.evaluation.evaluator]: [0mInference done 3960/8355. 0.1148 s / img. ETA=0:08:32
[32m[04/28 02:35:37 d2.evaluation.evaluator]: [0mInference done 4003/8355. 0.1148 s / img. ETA=0:08:27
[32m[04/28 02:35:42 d2.evaluation.evaluator]: [0mInference done 4046/8355. 0.1148 s / img. ETA=0:08:22
[32m[04/28 02:35:47 d2.evaluation.evaluator]: [0mInference done 4089/8355. 0.1148 s / img. ETA=0:08:17
[32m[04/28 02:35:52 d2.evaluation.evaluator]: [0mInference done 4132/8355. 0.1149 s / img. ETA=0:08:12
[32m[04/28 02:35:57 d2.evaluation.evaluator]: [0mInference done 4175/8355. 0.1149 s / img. ETA=0:08:07
[32m[04/28 02:36:02 d2.evaluation.evaluator]: [0mInference done 4218/8355. 0.1149 s / img. ETA=0:08:02
[32m[04/28 02:36:07 d2.evaluation.evaluator]: [0mInference done 4262/8355. 0.1148 s / img. ETA=0:07:57
[32m[04/28 02:36:12 d2.evaluation.evaluator]: [0mInference done 4305/8355. 0.1148 s / img. ETA=0:07:52
[32m[04/28 02:36:17 d2.evaluation.evaluator]: [0mInference done 4348/8355. 0.1148 s / img. ETA=0:07:47
[32m[04/28 02:36:23 d2.evaluation.evaluator]: [0mInference done 4391/8355. 0.1149 s / img. ETA=0:07:42
[32m[04/28 02:36:28 d2.evaluation.evaluator]: [0mInference done 4434/8355. 0.1149 s / img. ETA=0:07:37
[32m[04/28 02:36:33 d2.evaluation.evaluator]: [0mInference done 4477/8355. 0.1149 s / img. ETA=0:07:32
[32m[04/28 02:36:38 d2.evaluation.evaluator]: [0mInference done 4519/8355. 0.1149 s / img. ETA=0:07:27
[32m[04/28 02:36:43 d2.evaluation.evaluator]: [0mInference done 4562/8355. 0.1149 s / img. ETA=0:07:22
[32m[04/28 02:36:48 d2.evaluation.evaluator]: [0mInference done 4605/8355. 0.1149 s / img. ETA=0:07:17
[32m[04/28 02:36:53 d2.evaluation.evaluator]: [0mInference done 4648/8355. 0.1149 s / img. ETA=0:07:12
[32m[04/28 02:36:58 d2.evaluation.evaluator]: [0mInference done 4691/8355. 0.1149 s / img. ETA=0:07:07
[32m[04/28 02:37:03 d2.evaluation.evaluator]: [0mInference done 4734/8355. 0.1149 s / img. ETA=0:07:02
[32m[04/28 02:37:08 d2.evaluation.evaluator]: [0mInference done 4777/8355. 0.1149 s / img. ETA=0:06:57
[32m[04/28 02:37:13 d2.evaluation.evaluator]: [0mInference done 4820/8355. 0.1149 s / img. ETA=0:06:52
[32m[04/28 02:37:18 d2.evaluation.evaluator]: [0mInference done 4863/8355. 0.1149 s / img. ETA=0:06:47
[32m[04/28 02:37:23 d2.evaluation.evaluator]: [0mInference done 4906/8355. 0.1149 s / img. ETA=0:06:42
[32m[04/28 02:37:28 d2.evaluation.evaluator]: [0mInference done 4949/8355. 0.1149 s / img. ETA=0:06:37
[32m[04/28 02:37:33 d2.evaluation.evaluator]: [0mInference done 4992/8355. 0.1149 s / img. ETA=0:06:32
[32m[04/28 02:37:38 d2.evaluation.evaluator]: [0mInference done 5035/8355. 0.1149 s / img. ETA=0:06:27
[32m[04/28 02:37:43 d2.evaluation.evaluator]: [0mInference done 5078/8355. 0.1149 s / img. ETA=0:06:22
[32m[04/28 02:37:48 d2.evaluation.evaluator]: [0mInference done 5121/8355. 0.1149 s / img. ETA=0:06:17
[32m[04/28 02:37:53 d2.evaluation.evaluator]: [0mInference done 5164/8355. 0.1149 s / img. ETA=0:06:12
[32m[04/28 02:37:58 d2.evaluation.evaluator]: [0mInference done 5207/8355. 0.1149 s / img. ETA=0:06:07
[32m[04/28 02:38:03 d2.evaluation.evaluator]: [0mInference done 5250/8355. 0.1149 s / img. ETA=0:06:02
[32m[04/28 02:38:08 d2.evaluation.evaluator]: [0mInference done 5293/8355. 0.1149 s / img. ETA=0:05:57
[32m[04/28 02:38:13 d2.evaluation.evaluator]: [0mInference done 5336/8355. 0.1149 s / img. ETA=0:05:52
[32m[04/28 02:38:18 d2.evaluation.evaluator]: [0mInference done 5379/8355. 0.1149 s / img. ETA=0:05:47
[32m[04/28 02:38:23 d2.evaluation.evaluator]: [0mInference done 5422/8355. 0.1149 s / img. ETA=0:05:42
[32m[04/28 02:38:28 d2.evaluation.evaluator]: [0mInference done 5465/8355. 0.1149 s / img. ETA=0:05:37
[32m[04/28 02:38:33 d2.evaluation.evaluator]: [0mInference done 5508/8355. 0.1149 s / img. ETA=0:05:32
[32m[04/28 02:38:39 d2.evaluation.evaluator]: [0mInference done 5552/8355. 0.1149 s / img. ETA=0:05:27
[32m[04/28 02:38:44 d2.evaluation.evaluator]: [0mInference done 5595/8355. 0.1149 s / img. ETA=0:05:22
[32m[04/28 02:38:49 d2.evaluation.evaluator]: [0mInference done 5638/8355. 0.1149 s / img. ETA=0:05:17
[32m[04/28 02:38:54 d2.evaluation.evaluator]: [0mInference done 5681/8355. 0.1149 s / img. ETA=0:05:12
[32m[04/28 02:38:59 d2.evaluation.evaluator]: [0mInference done 5724/8355. 0.1149 s / img. ETA=0:05:07
[32m[04/28 02:39:04 d2.evaluation.evaluator]: [0mInference done 5767/8355. 0.1149 s / img. ETA=0:05:02
[32m[04/28 02:39:09 d2.evaluation.evaluator]: [0mInference done 5810/8355. 0.1149 s / img. ETA=0:04:57
[32m[04/28 02:39:14 d2.evaluation.evaluator]: [0mInference done 5853/8355. 0.1150 s / img. ETA=0:04:52
[32m[04/28 02:39:19 d2.evaluation.evaluator]: [0mInference done 5896/8355. 0.1150 s / img. ETA=0:04:47
[32m[04/28 02:39:24 d2.evaluation.evaluator]: [0mInference done 5939/8355. 0.1150 s / img. ETA=0:04:42
[32m[04/28 02:39:29 d2.evaluation.evaluator]: [0mInference done 5982/8355. 0.1150 s / img. ETA=0:04:37
[32m[04/28 02:39:34 d2.evaluation.evaluator]: [0mInference done 6025/8355. 0.1150 s / img. ETA=0:04:32
[32m[04/28 02:39:39 d2.evaluation.evaluator]: [0mInference done 6068/8355. 0.1150 s / img. ETA=0:04:27
[32m[04/28 02:39:44 d2.evaluation.evaluator]: [0mInference done 6111/8355. 0.1150 s / img. ETA=0:04:22
[32m[04/28 02:39:49 d2.evaluation.evaluator]: [0mInference done 6154/8355. 0.1150 s / img. ETA=0:04:17
[32m[04/28 02:39:54 d2.evaluation.evaluator]: [0mInference done 6197/8355. 0.1150 s / img. ETA=0:04:12
[32m[04/28 02:40:00 d2.evaluation.evaluator]: [0mInference done 6240/8355. 0.1150 s / img. ETA=0:04:07
[32m[04/28 02:40:05 d2.evaluation.evaluator]: [0mInference done 6283/8355. 0.1151 s / img. ETA=0:04:02
[32m[04/28 02:40:10 d2.evaluation.evaluator]: [0mInference done 6325/8355. 0.1151 s / img. ETA=0:03:57
[32m[04/28 02:40:15 d2.evaluation.evaluator]: [0mInference done 6368/8355. 0.1151 s / img. ETA=0:03:52
[32m[04/28 02:40:20 d2.evaluation.evaluator]: [0mInference done 6411/8355. 0.1151 s / img. ETA=0:03:47
[32m[04/28 02:40:25 d2.evaluation.evaluator]: [0mInference done 6454/8355. 0.1151 s / img. ETA=0:03:42
[32m[04/28 02:40:30 d2.evaluation.evaluator]: [0mInference done 6497/8355. 0.1151 s / img. ETA=0:03:37
[32m[04/28 02:40:35 d2.evaluation.evaluator]: [0mInference done 6541/8355. 0.1151 s / img. ETA=0:03:31
[32m[04/28 02:40:40 d2.evaluation.evaluator]: [0mInference done 6584/8355. 0.1151 s / img. ETA=0:03:26
[32m[04/28 02:40:45 d2.evaluation.evaluator]: [0mInference done 6627/8355. 0.1151 s / img. ETA=0:03:21
[32m[04/28 02:40:50 d2.evaluation.evaluator]: [0mInference done 6671/8355. 0.1151 s / img. ETA=0:03:16
[32m[04/28 02:40:55 d2.evaluation.evaluator]: [0mInference done 6714/8355. 0.1151 s / img. ETA=0:03:11
[32m[04/28 02:41:00 d2.evaluation.evaluator]: [0mInference done 6757/8355. 0.1151 s / img. ETA=0:03:06
[32m[04/28 02:41:05 d2.evaluation.evaluator]: [0mInference done 6801/8355. 0.1151 s / img. ETA=0:03:01
[32m[04/28 02:41:10 d2.evaluation.evaluator]: [0mInference done 6845/8355. 0.1151 s / img. ETA=0:02:56
[32m[04/28 02:41:15 d2.evaluation.evaluator]: [0mInference done 6888/8355. 0.1151 s / img. ETA=0:02:51
[32m[04/28 02:41:21 d2.evaluation.evaluator]: [0mInference done 6932/8355. 0.1151 s / img. ETA=0:02:46
[32m[04/28 02:41:26 d2.evaluation.evaluator]: [0mInference done 6975/8355. 0.1151 s / img. ETA=0:02:41
[32m[04/28 02:41:31 d2.evaluation.evaluator]: [0mInference done 7018/8355. 0.1151 s / img. ETA=0:02:36
[32m[04/28 02:41:36 d2.evaluation.evaluator]: [0mInference done 7061/8355. 0.1151 s / img. ETA=0:02:31
[32m[04/28 02:41:41 d2.evaluation.evaluator]: [0mInference done 7104/8355. 0.1151 s / img. ETA=0:02:26
[32m[04/28 02:41:46 d2.evaluation.evaluator]: [0mInference done 7147/8355. 0.1151 s / img. ETA=0:02:21
[32m[04/28 02:41:51 d2.evaluation.evaluator]: [0mInference done 7189/8355. 0.1151 s / img. ETA=0:02:16
[32m[04/28 02:41:56 d2.evaluation.evaluator]: [0mInference done 7232/8355. 0.1151 s / img. ETA=0:02:11
[32m[04/28 02:42:01 d2.evaluation.evaluator]: [0mInference done 7275/8355. 0.1151 s / img. ETA=0:02:06
[32m[04/28 02:42:06 d2.evaluation.evaluator]: [0mInference done 7318/8355. 0.1151 s / img. ETA=0:02:01
[32m[04/28 02:42:11 d2.evaluation.evaluator]: [0mInference done 7360/8355. 0.1151 s / img. ETA=0:01:56
[32m[04/28 02:42:16 d2.evaluation.evaluator]: [0mInference done 7403/8355. 0.1151 s / img. ETA=0:01:51
[32m[04/28 02:42:21 d2.evaluation.evaluator]: [0mInference done 7446/8355. 0.1152 s / img. ETA=0:01:46
[32m[04/28 02:42:26 d2.evaluation.evaluator]: [0mInference done 7489/8355. 0.1152 s / img. ETA=0:01:41
[32m[04/28 02:42:31 d2.evaluation.evaluator]: [0mInference done 7532/8355. 0.1152 s / img. ETA=0:01:36
[32m[04/28 02:42:36 d2.evaluation.evaluator]: [0mInference done 7575/8355. 0.1152 s / img. ETA=0:01:31
[32m[04/28 02:42:41 d2.evaluation.evaluator]: [0mInference done 7618/8355. 0.1152 s / img. ETA=0:01:26
[32m[04/28 02:42:46 d2.evaluation.evaluator]: [0mInference done 7660/8355. 0.1152 s / img. ETA=0:01:21
[32m[04/28 02:42:52 d2.evaluation.evaluator]: [0mInference done 7703/8355. 0.1152 s / img. ETA=0:01:16
[32m[04/28 02:42:57 d2.evaluation.evaluator]: [0mInference done 7746/8355. 0.1152 s / img. ETA=0:01:11
[32m[04/28 02:43:02 d2.evaluation.evaluator]: [0mInference done 7789/8355. 0.1152 s / img. ETA=0:01:06
[32m[04/28 02:43:07 d2.evaluation.evaluator]: [0mInference done 7832/8355. 0.1152 s / img. ETA=0:01:01
[32m[04/28 02:43:12 d2.evaluation.evaluator]: [0mInference done 7875/8355. 0.1152 s / img. ETA=0:00:56
[32m[04/28 02:43:17 d2.evaluation.evaluator]: [0mInference done 7918/8355. 0.1152 s / img. ETA=0:00:51
[32m[04/28 02:43:22 d2.evaluation.evaluator]: [0mInference done 7961/8355. 0.1152 s / img. ETA=0:00:46
[32m[04/28 02:43:27 d2.evaluation.evaluator]: [0mInference done 8004/8355. 0.1152 s / img. ETA=0:00:41
[32m[04/28 02:43:32 d2.evaluation.evaluator]: [0mInference done 8048/8355. 0.1152 s / img. ETA=0:00:35
[32m[04/28 02:43:37 d2.evaluation.evaluator]: [0mInference done 8091/8355. 0.1152 s / img. ETA=0:00:30
[32m[04/28 02:43:42 d2.evaluation.evaluator]: [0mInference done 8135/8355. 0.1152 s / img. ETA=0:00:25
[32m[04/28 02:43:47 d2.evaluation.evaluator]: [0mInference done 8179/8355. 0.1152 s / img. ETA=0:00:20
[32m[04/28 02:43:52 d2.evaluation.evaluator]: [0mInference done 8222/8355. 0.1152 s / img. ETA=0:00:15
[32m[04/28 02:43:57 d2.evaluation.evaluator]: [0mInference done 8265/8355. 0.1152 s / img. ETA=0:00:10
[32m[04/28 02:44:02 d2.evaluation.evaluator]: [0mInference done 8308/8355. 0.1152 s / img. ETA=0:00:05
[32m[04/28 02:44:07 d2.evaluation.evaluator]: [0mInference done 8351/8355. 0.1152 s / img. ETA=0:00:00
[32m[04/28 02:44:08 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:16.921997 (0.116997 s / img per device, on 1 devices)
[32m[04/28 02:44:08 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:01 (0.115195 s / img per device, on 1 devices)
[32m[04/28 02:44:08 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 02:44:08 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 02:44:08 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=18.53s).
Accumulating evaluation results...
DONE (t=2.04s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.384
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.715
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.357
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.273
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.534
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.152
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.434
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.332
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.707
[32m[04/28 02:44:29 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 38.426 | 71.474 | 35.690 | 27.331 | 53.380 | 65.158 |
[32m[04/28 02:44:29 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 38.690 | bicycle       | 26.294 | car            | 50.294 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 02:44:29 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 02:44:29 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 02:44:30 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 02:44:31 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1152 s / img. ETA=0:02:25
[32m[04/28 02:44:36 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1148 s / img. ETA=0:02:20
[32m[04/28 02:44:41 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1149 s / img. ETA=0:02:15
[32m[04/28 02:44:46 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1149 s / img. ETA=0:02:10
[32m[04/28 02:44:51 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1149 s / img. ETA=0:02:05
[32m[04/28 02:44:56 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1149 s / img. ETA=0:02:00
[32m[04/28 02:45:01 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1149 s / img. ETA=0:01:55
[32m[04/28 02:45:06 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1149 s / img. ETA=0:01:50
[32m[04/28 02:45:11 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1149 s / img. ETA=0:01:45
[32m[04/28 02:45:16 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1149 s / img. ETA=0:01:40
[32m[04/28 02:45:21 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1149 s / img. ETA=0:01:35
[32m[04/28 02:45:26 d2.evaluation.evaluator]: [0mInference done 485/1257. 0.1148 s / img. ETA=0:01:29
[32m[04/28 02:45:31 d2.evaluation.evaluator]: [0mInference done 528/1257. 0.1148 s / img. ETA=0:01:24
[32m[04/28 02:45:36 d2.evaluation.evaluator]: [0mInference done 571/1257. 0.1149 s / img. ETA=0:01:19
[32m[04/28 02:45:41 d2.evaluation.evaluator]: [0mInference done 614/1257. 0.1149 s / img. ETA=0:01:14
[32m[04/28 02:45:47 d2.evaluation.evaluator]: [0mInference done 657/1257. 0.1149 s / img. ETA=0:01:09
[32m[04/28 02:45:52 d2.evaluation.evaluator]: [0mInference done 700/1257. 0.1149 s / img. ETA=0:01:04
[32m[04/28 02:45:57 d2.evaluation.evaluator]: [0mInference done 743/1257. 0.1149 s / img. ETA=0:00:59
[32m[04/28 02:46:02 d2.evaluation.evaluator]: [0mInference done 787/1257. 0.1149 s / img. ETA=0:00:54
[32m[04/28 02:46:07 d2.evaluation.evaluator]: [0mInference done 830/1257. 0.1149 s / img. ETA=0:00:49
[32m[04/28 02:46:12 d2.evaluation.evaluator]: [0mInference done 873/1257. 0.1149 s / img. ETA=0:00:44
[32m[04/28 02:46:17 d2.evaluation.evaluator]: [0mInference done 916/1257. 0.1150 s / img. ETA=0:00:39
[32m[04/28 02:46:22 d2.evaluation.evaluator]: [0mInference done 959/1257. 0.1150 s / img. ETA=0:00:34
[32m[04/28 02:46:27 d2.evaluation.evaluator]: [0mInference done 1002/1257. 0.1150 s / img. ETA=0:00:29
[32m[04/28 02:46:32 d2.evaluation.evaluator]: [0mInference done 1045/1257. 0.1151 s / img. ETA=0:00:24
[32m[04/28 02:46:37 d2.evaluation.evaluator]: [0mInference done 1088/1257. 0.1151 s / img. ETA=0:00:19
[32m[04/28 02:46:42 d2.evaluation.evaluator]: [0mInference done 1131/1257. 0.1151 s / img. ETA=0:00:14
[32m[04/28 02:46:47 d2.evaluation.evaluator]: [0mInference done 1174/1257. 0.1152 s / img. ETA=0:00:09
[32m[04/28 02:46:52 d2.evaluation.evaluator]: [0mInference done 1217/1257. 0.1152 s / img. ETA=0:00:04
[32m[04/28 02:46:57 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.400844 (0.116934 s / img per device, on 1 devices)
[32m[04/28 02:46:57 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115194 s / img per device, on 1 devices)
[32m[04/28 02:46:57 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 02:46:57 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 02:46:57 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.75s).
Accumulating evaluation results...
DONE (t=0.35s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.399
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.743
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.373
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.278
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.485
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.566
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.463
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.345
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.555
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.629
[32m[04/28 02:47:00 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.857 | 74.291 | 37.337 | 27.819 | 48.544 | 56.640 |
[32m[04/28 02:47:00 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 39.726 | bicycle       | 26.157 | car            | 53.689 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  2  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 02:47:01 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 02:47:01 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 02:47:01 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 02:47:02 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 02:47:02 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 02:47:02 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 02:47:02 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 02:47:23 d2.utils.events]: [0m eta: 0:17:07  iter: 19  total_loss: 0.651  loss_cls: 0.211  loss_box_reg: 0.347  loss_rpn_cls: 0.017  loss_rpn_loc: 0.068  time: 1.0310  data_time: 0.0190  lr: 0.000100  max_mem: 5394M
[32m[04/28 02:47:43 d2.utils.events]: [0m eta: 0:16:46  iter: 39  total_loss: 0.584  loss_cls: 0.187  loss_box_reg: 0.343  loss_rpn_cls: 0.012  loss_rpn_loc: 0.049  time: 1.0342  data_time: 0.0074  lr: 0.000200  max_mem: 5394M
[32m[04/28 02:48:05 d2.utils.events]: [0m eta: 0:16:28  iter: 59  total_loss: 0.587  loss_cls: 0.174  loss_box_reg: 0.339  loss_rpn_cls: 0.011  loss_rpn_loc: 0.052  time: 1.0414  data_time: 0.0074  lr: 0.000300  max_mem: 5394M
[32m[04/28 02:48:26 d2.utils.events]: [0m eta: 0:16:14  iter: 79  total_loss: 0.588  loss_cls: 0.183  loss_box_reg: 0.326  loss_rpn_cls: 0.009  loss_rpn_loc: 0.061  time: 1.0464  data_time: 0.0075  lr: 0.000400  max_mem: 5394M
[32m[04/28 02:48:47 d2.utils.events]: [0m eta: 0:15:57  iter: 99  total_loss: 0.602  loss_cls: 0.188  loss_box_reg: 0.347  loss_rpn_cls: 0.012  loss_rpn_loc: 0.054  time: 1.0479  data_time: 0.0075  lr: 0.000500  max_mem: 5394M
[32m[04/28 02:49:08 d2.utils.events]: [0m eta: 0:15:34  iter: 119  total_loss: 0.591  loss_cls: 0.196  loss_box_reg: 0.340  loss_rpn_cls: 0.014  loss_rpn_loc: 0.047  time: 1.0469  data_time: 0.0077  lr: 0.000599  max_mem: 5394M
[32m[04/28 02:49:29 d2.utils.events]: [0m eta: 0:15:15  iter: 139  total_loss: 0.513  loss_cls: 0.165  loss_box_reg: 0.295  loss_rpn_cls: 0.010  loss_rpn_loc: 0.049  time: 1.0453  data_time: 0.0081  lr: 0.000699  max_mem: 5394M
[32m[04/28 02:49:49 d2.utils.events]: [0m eta: 0:14:49  iter: 159  total_loss: 0.546  loss_cls: 0.191  loss_box_reg: 0.301  loss_rpn_cls: 0.012  loss_rpn_loc: 0.052  time: 1.0440  data_time: 0.0076  lr: 0.000799  max_mem: 5394M
[32m[04/28 02:50:10 d2.utils.events]: [0m eta: 0:14:27  iter: 179  total_loss: 0.545  loss_cls: 0.169  loss_box_reg: 0.311  loss_rpn_cls: 0.012  loss_rpn_loc: 0.056  time: 1.0410  data_time: 0.0076  lr: 0.000899  max_mem: 5394M
[32m[04/28 02:50:31 d2.utils.events]: [0m eta: 0:14:04  iter: 199  total_loss: 0.655  loss_cls: 0.215  loss_box_reg: 0.352  loss_rpn_cls: 0.013  loss_rpn_loc: 0.058  time: 1.0404  data_time: 0.0076  lr: 0.000999  max_mem: 5394M
[32m[04/28 02:50:51 d2.utils.events]: [0m eta: 0:13:41  iter: 219  total_loss: 0.597  loss_cls: 0.192  loss_box_reg: 0.338  loss_rpn_cls: 0.013  loss_rpn_loc: 0.048  time: 1.0377  data_time: 0.0078  lr: 0.001099  max_mem: 5394M
[32m[04/28 02:51:11 d2.utils.events]: [0m eta: 0:13:20  iter: 239  total_loss: 0.566  loss_cls: 0.181  loss_box_reg: 0.336  loss_rpn_cls: 0.009  loss_rpn_loc: 0.048  time: 1.0371  data_time: 0.0079  lr: 0.001199  max_mem: 5394M
[32m[04/28 02:51:32 d2.utils.events]: [0m eta: 0:12:58  iter: 259  total_loss: 0.593  loss_cls: 0.195  loss_box_reg: 0.307  loss_rpn_cls: 0.012  loss_rpn_loc: 0.058  time: 1.0356  data_time: 0.0076  lr: 0.001299  max_mem: 5394M
[32m[04/28 02:51:52 d2.utils.events]: [0m eta: 0:12:37  iter: 279  total_loss: 0.634  loss_cls: 0.202  loss_box_reg: 0.333  loss_rpn_cls: 0.010  loss_rpn_loc: 0.052  time: 1.0349  data_time: 0.0079  lr: 0.001399  max_mem: 5394M
[32m[04/28 02:52:13 d2.utils.events]: [0m eta: 0:12:16  iter: 299  total_loss: 0.572  loss_cls: 0.186  loss_box_reg: 0.326  loss_rpn_cls: 0.012  loss_rpn_loc: 0.044  time: 1.0345  data_time: 0.0076  lr: 0.001499  max_mem: 5394M
[32m[04/28 02:52:33 d2.utils.events]: [0m eta: 0:11:53  iter: 319  total_loss: 0.587  loss_cls: 0.192  loss_box_reg: 0.331  loss_rpn_cls: 0.013  loss_rpn_loc: 0.052  time: 1.0322  data_time: 0.0076  lr: 0.001598  max_mem: 5394M
[32m[04/28 02:52:54 d2.utils.events]: [0m eta: 0:11:32  iter: 339  total_loss: 0.594  loss_cls: 0.182  loss_box_reg: 0.343  loss_rpn_cls: 0.010  loss_rpn_loc: 0.042  time: 1.0316  data_time: 0.0081  lr: 0.001698  max_mem: 5394M
[32m[04/28 02:53:15 d2.utils.events]: [0m eta: 0:11:11  iter: 359  total_loss: 0.551  loss_cls: 0.179  loss_box_reg: 0.312  loss_rpn_cls: 0.008  loss_rpn_loc: 0.052  time: 1.0326  data_time: 0.0077  lr: 0.001798  max_mem: 5394M
[32m[04/28 02:53:35 d2.utils.events]: [0m eta: 0:10:50  iter: 379  total_loss: 0.485  loss_cls: 0.165  loss_box_reg: 0.283  loss_rpn_cls: 0.009  loss_rpn_loc: 0.038  time: 1.0324  data_time: 0.0082  lr: 0.001898  max_mem: 5394M
[32m[04/28 02:53:55 d2.utils.events]: [0m eta: 0:10:28  iter: 399  total_loss: 0.572  loss_cls: 0.191  loss_box_reg: 0.320  loss_rpn_cls: 0.013  loss_rpn_loc: 0.053  time: 1.0309  data_time: 0.0075  lr: 0.001998  max_mem: 5394M
[32m[04/28 02:54:16 d2.utils.events]: [0m eta: 0:10:08  iter: 419  total_loss: 0.519  loss_cls: 0.160  loss_box_reg: 0.307  loss_rpn_cls: 0.010  loss_rpn_loc: 0.037  time: 1.0312  data_time: 0.0075  lr: 0.002098  max_mem: 5394M
[32m[04/28 02:54:36 d2.utils.events]: [0m eta: 0:09:45  iter: 439  total_loss: 0.576  loss_cls: 0.180  loss_box_reg: 0.314  loss_rpn_cls: 0.012  loss_rpn_loc: 0.043  time: 1.0299  data_time: 0.0075  lr: 0.002198  max_mem: 5394M
[32m[04/28 02:54:57 d2.utils.events]: [0m eta: 0:09:23  iter: 459  total_loss: 0.581  loss_cls: 0.173  loss_box_reg: 0.323  loss_rpn_cls: 0.012  loss_rpn_loc: 0.055  time: 1.0297  data_time: 0.0075  lr: 0.002298  max_mem: 5394M
[32m[04/28 02:55:18 d2.utils.events]: [0m eta: 0:09:03  iter: 479  total_loss: 0.578  loss_cls: 0.191  loss_box_reg: 0.325  loss_rpn_cls: 0.010  loss_rpn_loc: 0.045  time: 1.0311  data_time: 0.0077  lr: 0.002398  max_mem: 5394M
[32m[04/28 02:55:39 d2.utils.events]: [0m eta: 0:08:42  iter: 499  total_loss: 0.541  loss_cls: 0.174  loss_box_reg: 0.304  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0307  data_time: 0.0075  lr: 0.002498  max_mem: 5394M
[32m[04/28 02:55:59 d2.utils.events]: [0m eta: 0:08:21  iter: 519  total_loss: 0.545  loss_cls: 0.182  loss_box_reg: 0.316  loss_rpn_cls: 0.014  loss_rpn_loc: 0.050  time: 1.0307  data_time: 0.0075  lr: 0.002597  max_mem: 5394M
[32m[04/28 02:56:20 d2.utils.events]: [0m eta: 0:08:01  iter: 539  total_loss: 0.543  loss_cls: 0.164  loss_box_reg: 0.318  loss_rpn_cls: 0.008  loss_rpn_loc: 0.049  time: 1.0318  data_time: 0.0076  lr: 0.002697  max_mem: 5394M
[32m[04/28 02:56:41 d2.utils.events]: [0m eta: 0:07:39  iter: 559  total_loss: 0.538  loss_cls: 0.173  loss_box_reg: 0.303  loss_rpn_cls: 0.011  loss_rpn_loc: 0.043  time: 1.0310  data_time: 0.0076  lr: 0.002797  max_mem: 5394M
[32m[04/28 02:57:01 d2.utils.events]: [0m eta: 0:07:19  iter: 579  total_loss: 0.555  loss_cls: 0.173  loss_box_reg: 0.308  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0310  data_time: 0.0075  lr: 0.002897  max_mem: 5394M
[32m[04/28 02:57:22 d2.utils.events]: [0m eta: 0:06:58  iter: 599  total_loss: 0.657  loss_cls: 0.207  loss_box_reg: 0.370  loss_rpn_cls: 0.013  loss_rpn_loc: 0.059  time: 1.0313  data_time: 0.0081  lr: 0.002997  max_mem: 5394M
[32m[04/28 02:57:43 d2.utils.events]: [0m eta: 0:06:37  iter: 619  total_loss: 0.563  loss_cls: 0.174  loss_box_reg: 0.329  loss_rpn_cls: 0.014  loss_rpn_loc: 0.039  time: 1.0309  data_time: 0.0080  lr: 0.003097  max_mem: 5394M
[32m[04/28 02:58:03 d2.utils.events]: [0m eta: 0:06:16  iter: 639  total_loss: 0.672  loss_cls: 0.194  loss_box_reg: 0.379  loss_rpn_cls: 0.015  loss_rpn_loc: 0.073  time: 1.0306  data_time: 0.0074  lr: 0.003197  max_mem: 5394M
[32m[04/28 02:58:23 d2.utils.events]: [0m eta: 0:05:55  iter: 659  total_loss: 0.568  loss_cls: 0.185  loss_box_reg: 0.326  loss_rpn_cls: 0.014  loss_rpn_loc: 0.049  time: 1.0300  data_time: 0.0077  lr: 0.003297  max_mem: 5394M
[32m[04/28 02:58:44 d2.utils.events]: [0m eta: 0:05:34  iter: 679  total_loss: 0.559  loss_cls: 0.183  loss_box_reg: 0.320  loss_rpn_cls: 0.011  loss_rpn_loc: 0.050  time: 1.0301  data_time: 0.0077  lr: 0.003397  max_mem: 5394M
[32m[04/28 02:59:05 d2.utils.events]: [0m eta: 0:05:13  iter: 699  total_loss: 0.599  loss_cls: 0.186  loss_box_reg: 0.348  loss_rpn_cls: 0.011  loss_rpn_loc: 0.051  time: 1.0301  data_time: 0.0075  lr: 0.003497  max_mem: 5394M
[32m[04/28 02:59:26 d2.utils.events]: [0m eta: 0:04:52  iter: 719  total_loss: 0.562  loss_cls: 0.179  loss_box_reg: 0.322  loss_rpn_cls: 0.009  loss_rpn_loc: 0.059  time: 1.0302  data_time: 0.0074  lr: 0.003596  max_mem: 5394M
[32m[04/28 02:59:47 d2.utils.events]: [0m eta: 0:04:32  iter: 739  total_loss: 0.613  loss_cls: 0.195  loss_box_reg: 0.353  loss_rpn_cls: 0.012  loss_rpn_loc: 0.042  time: 1.0310  data_time: 0.0078  lr: 0.003696  max_mem: 5394M
[32m[04/28 03:00:07 d2.utils.events]: [0m eta: 0:04:11  iter: 759  total_loss: 0.681  loss_cls: 0.220  loss_box_reg: 0.380  loss_rpn_cls: 0.014  loss_rpn_loc: 0.058  time: 1.0305  data_time: 0.0074  lr: 0.003796  max_mem: 5394M
[32m[04/28 03:00:28 d2.utils.events]: [0m eta: 0:03:50  iter: 779  total_loss: 0.580  loss_cls: 0.183  loss_box_reg: 0.311  loss_rpn_cls: 0.015  loss_rpn_loc: 0.051  time: 1.0305  data_time: 0.0076  lr: 0.003896  max_mem: 5394M
[32m[04/28 03:00:48 d2.utils.events]: [0m eta: 0:03:29  iter: 799  total_loss: 0.556  loss_cls: 0.169  loss_box_reg: 0.307  loss_rpn_cls: 0.016  loss_rpn_loc: 0.045  time: 1.0301  data_time: 0.0080  lr: 0.003996  max_mem: 5394M
[32m[04/28 03:01:09 d2.utils.events]: [0m eta: 0:03:08  iter: 819  total_loss: 0.536  loss_cls: 0.165  loss_box_reg: 0.302  loss_rpn_cls: 0.013  loss_rpn_loc: 0.044  time: 1.0303  data_time: 0.0077  lr: 0.004096  max_mem: 5394M
[32m[04/28 03:01:30 d2.utils.events]: [0m eta: 0:02:48  iter: 839  total_loss: 0.575  loss_cls: 0.183  loss_box_reg: 0.332  loss_rpn_cls: 0.013  loss_rpn_loc: 0.061  time: 1.0310  data_time: 0.0077  lr: 0.004196  max_mem: 5394M
[32m[04/28 03:01:50 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.570  loss_cls: 0.170  loss_box_reg: 0.329  loss_rpn_cls: 0.013  loss_rpn_loc: 0.061  time: 1.0304  data_time: 0.0077  lr: 0.004296  max_mem: 5394M
[32m[04/28 03:02:10 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.593  loss_cls: 0.180  loss_box_reg: 0.337  loss_rpn_cls: 0.014  loss_rpn_loc: 0.059  time: 1.0295  data_time: 0.0075  lr: 0.004396  max_mem: 5394M
[32m[04/28 03:02:31 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.621  loss_cls: 0.204  loss_box_reg: 0.376  loss_rpn_cls: 0.013  loss_rpn_loc: 0.049  time: 1.0300  data_time: 0.0080  lr: 0.004496  max_mem: 5394M
[32m[04/28 03:02:52 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.621  loss_cls: 0.204  loss_box_reg: 0.340  loss_rpn_cls: 0.015  loss_rpn_loc: 0.057  time: 1.0296  data_time: 0.0082  lr: 0.004595  max_mem: 5394M
[32m[04/28 03:03:12 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.671  loss_cls: 0.200  loss_box_reg: 0.370  loss_rpn_cls: 0.013  loss_rpn_loc: 0.052  time: 1.0295  data_time: 0.0077  lr: 0.004695  max_mem: 5394M
[32m[04/28 03:03:33 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.611  loss_cls: 0.196  loss_box_reg: 0.341  loss_rpn_cls: 0.013  loss_rpn_loc: 0.058  time: 1.0296  data_time: 0.0077  lr: 0.004795  max_mem: 5394M
[32m[04/28 03:03:54 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.551  loss_cls: 0.169  loss_box_reg: 0.325  loss_rpn_cls: 0.010  loss_rpn_loc: 0.048  time: 1.0297  data_time: 0.0077  lr: 0.004895  max_mem: 5394M
[5m[31mWARNING[0m [32m[04/28 03:04:17 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 03:04:17 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 03:04:17 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 03:04:17 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.573  loss_cls: 0.181  loss_box_reg: 0.328  loss_rpn_cls: 0.011  loss_rpn_loc: 0.052  time: 1.0300  data_time: 0.0075  lr: 0.004995  max_mem: 5394M
[32m[04/28 03:04:17 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:07 (1.0310 s / it)
[32m[04/28 03:04:17 d2.engine.hooks]: [0mTotal training time: 0:17:13 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 03:04:19 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 03:04:19 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 03:04:20 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 03:04:21 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1137 s / img. ETA=0:16:00
[32m[04/28 03:04:26 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1138 s / img. ETA=0:15:57
[32m[04/28 03:04:31 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1137 s / img. ETA=0:15:51
[32m[04/28 03:04:36 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1137 s / img. ETA=0:15:47
[32m[04/28 03:04:41 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1137 s / img. ETA=0:15:42
[32m[04/28 03:04:46 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1137 s / img. ETA=0:15:37
[32m[04/28 03:04:51 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1138 s / img. ETA=0:15:32
[32m[04/28 03:04:57 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1138 s / img. ETA=0:15:27
[32m[04/28 03:05:02 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1138 s / img. ETA=0:15:23
[32m[04/28 03:05:07 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1138 s / img. ETA=0:15:18
[32m[04/28 03:05:12 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1138 s / img. ETA=0:15:13
[32m[04/28 03:05:17 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1138 s / img. ETA=0:15:07
[32m[04/28 03:05:22 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1137 s / img. ETA=0:15:02
[32m[04/28 03:05:27 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1137 s / img. ETA=0:14:57
[32m[04/28 03:05:32 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1137 s / img. ETA=0:14:52
[32m[04/28 03:05:37 d2.evaluation.evaluator]: [0mInference done 670/8355. 0.1138 s / img. ETA=0:14:47
[32m[04/28 03:05:42 d2.evaluation.evaluator]: [0mInference done 714/8355. 0.1139 s / img. ETA=0:14:43
[32m[04/28 03:05:47 d2.evaluation.evaluator]: [0mInference done 758/8355. 0.1139 s / img. ETA=0:14:38
[32m[04/28 03:05:52 d2.evaluation.evaluator]: [0mInference done 801/8355. 0.1140 s / img. ETA=0:14:33
[32m[04/28 03:05:57 d2.evaluation.evaluator]: [0mInference done 845/8355. 0.1140 s / img. ETA=0:14:28
[32m[04/28 03:06:02 d2.evaluation.evaluator]: [0mInference done 888/8355. 0.1140 s / img. ETA=0:14:24
[32m[04/28 03:06:08 d2.evaluation.evaluator]: [0mInference done 932/8355. 0.1140 s / img. ETA=0:14:19
[32m[04/28 03:06:13 d2.evaluation.evaluator]: [0mInference done 976/8355. 0.1140 s / img. ETA=0:14:14
[32m[04/28 03:06:18 d2.evaluation.evaluator]: [0mInference done 1019/8355. 0.1140 s / img. ETA=0:14:09
[32m[04/28 03:06:23 d2.evaluation.evaluator]: [0mInference done 1063/8355. 0.1140 s / img. ETA=0:14:04
[32m[04/28 03:06:28 d2.evaluation.evaluator]: [0mInference done 1107/8355. 0.1141 s / img. ETA=0:13:59
[32m[04/28 03:06:33 d2.evaluation.evaluator]: [0mInference done 1151/8355. 0.1140 s / img. ETA=0:13:53
[32m[04/28 03:06:38 d2.evaluation.evaluator]: [0mInference done 1194/8355. 0.1141 s / img. ETA=0:13:49
[32m[04/28 03:06:43 d2.evaluation.evaluator]: [0mInference done 1238/8355. 0.1140 s / img. ETA=0:13:43
[32m[04/28 03:06:48 d2.evaluation.evaluator]: [0mInference done 1282/8355. 0.1140 s / img. ETA=0:13:38
[32m[04/28 03:06:53 d2.evaluation.evaluator]: [0mInference done 1326/8355. 0.1140 s / img. ETA=0:13:33
[32m[04/28 03:06:58 d2.evaluation.evaluator]: [0mInference done 1370/8355. 0.1140 s / img. ETA=0:13:28
[32m[04/28 03:07:03 d2.evaluation.evaluator]: [0mInference done 1414/8355. 0.1140 s / img. ETA=0:13:23
[32m[04/28 03:07:08 d2.evaluation.evaluator]: [0mInference done 1458/8355. 0.1140 s / img. ETA=0:13:18
[32m[04/28 03:07:13 d2.evaluation.evaluator]: [0mInference done 1501/8355. 0.1140 s / img. ETA=0:13:13
[32m[04/28 03:07:18 d2.evaluation.evaluator]: [0mInference done 1544/8355. 0.1141 s / img. ETA=0:13:08
[32m[04/28 03:07:23 d2.evaluation.evaluator]: [0mInference done 1587/8355. 0.1141 s / img. ETA=0:13:03
[32m[04/28 03:07:29 d2.evaluation.evaluator]: [0mInference done 1630/8355. 0.1141 s / img. ETA=0:12:59
[32m[04/28 03:07:34 d2.evaluation.evaluator]: [0mInference done 1673/8355. 0.1142 s / img. ETA=0:12:54
[32m[04/28 03:07:39 d2.evaluation.evaluator]: [0mInference done 1716/8355. 0.1142 s / img. ETA=0:12:49
[32m[04/28 03:07:44 d2.evaluation.evaluator]: [0mInference done 1759/8355. 0.1142 s / img. ETA=0:12:44
[32m[04/28 03:07:49 d2.evaluation.evaluator]: [0mInference done 1802/8355. 0.1142 s / img. ETA=0:12:40
[32m[04/28 03:07:54 d2.evaluation.evaluator]: [0mInference done 1845/8355. 0.1143 s / img. ETA=0:12:35
[32m[04/28 03:07:59 d2.evaluation.evaluator]: [0mInference done 1888/8355. 0.1143 s / img. ETA=0:12:30
[32m[04/28 03:08:04 d2.evaluation.evaluator]: [0mInference done 1931/8355. 0.1143 s / img. ETA=0:12:25
[32m[04/28 03:08:09 d2.evaluation.evaluator]: [0mInference done 1974/8355. 0.1143 s / img. ETA=0:12:20
[32m[04/28 03:08:14 d2.evaluation.evaluator]: [0mInference done 2017/8355. 0.1143 s / img. ETA=0:12:15
[32m[04/28 03:08:19 d2.evaluation.evaluator]: [0mInference done 2060/8355. 0.1144 s / img. ETA=0:12:10
[32m[04/28 03:08:24 d2.evaluation.evaluator]: [0mInference done 2103/8355. 0.1144 s / img. ETA=0:12:05
[32m[04/28 03:08:29 d2.evaluation.evaluator]: [0mInference done 2146/8355. 0.1144 s / img. ETA=0:12:01
[32m[04/28 03:08:34 d2.evaluation.evaluator]: [0mInference done 2189/8355. 0.1144 s / img. ETA=0:11:56
[32m[04/28 03:08:39 d2.evaluation.evaluator]: [0mInference done 2232/8355. 0.1144 s / img. ETA=0:11:51
[32m[04/28 03:08:44 d2.evaluation.evaluator]: [0mInference done 2275/8355. 0.1144 s / img. ETA=0:11:46
[32m[04/28 03:08:49 d2.evaluation.evaluator]: [0mInference done 2318/8355. 0.1145 s / img. ETA=0:11:41
[32m[04/28 03:08:54 d2.evaluation.evaluator]: [0mInference done 2361/8355. 0.1145 s / img. ETA=0:11:36
[32m[04/28 03:08:59 d2.evaluation.evaluator]: [0mInference done 2404/8355. 0.1145 s / img. ETA=0:11:31
[32m[04/28 03:09:04 d2.evaluation.evaluator]: [0mInference done 2447/8355. 0.1145 s / img. ETA=0:11:26
[32m[04/28 03:09:09 d2.evaluation.evaluator]: [0mInference done 2490/8355. 0.1145 s / img. ETA=0:11:21
[32m[04/28 03:09:14 d2.evaluation.evaluator]: [0mInference done 2533/8355. 0.1145 s / img. ETA=0:11:16
[32m[04/28 03:09:19 d2.evaluation.evaluator]: [0mInference done 2576/8355. 0.1145 s / img. ETA=0:11:12
[32m[04/28 03:09:24 d2.evaluation.evaluator]: [0mInference done 2619/8355. 0.1145 s / img. ETA=0:11:07
[32m[04/28 03:09:29 d2.evaluation.evaluator]: [0mInference done 2662/8355. 0.1146 s / img. ETA=0:11:02
[32m[04/28 03:09:34 d2.evaluation.evaluator]: [0mInference done 2705/8355. 0.1146 s / img. ETA=0:10:57
[32m[04/28 03:09:39 d2.evaluation.evaluator]: [0mInference done 2748/8355. 0.1146 s / img. ETA=0:10:52
[32m[04/28 03:09:44 d2.evaluation.evaluator]: [0mInference done 2792/8355. 0.1146 s / img. ETA=0:10:47
[32m[04/28 03:09:49 d2.evaluation.evaluator]: [0mInference done 2835/8355. 0.1146 s / img. ETA=0:10:42
[32m[04/28 03:09:54 d2.evaluation.evaluator]: [0mInference done 2878/8355. 0.1146 s / img. ETA=0:10:37
[32m[04/28 03:10:00 d2.evaluation.evaluator]: [0mInference done 2921/8355. 0.1146 s / img. ETA=0:10:32
[32m[04/28 03:10:05 d2.evaluation.evaluator]: [0mInference done 2964/8355. 0.1146 s / img. ETA=0:10:27
[32m[04/28 03:10:10 d2.evaluation.evaluator]: [0mInference done 3007/8355. 0.1146 s / img. ETA=0:10:22
[32m[04/28 03:10:15 d2.evaluation.evaluator]: [0mInference done 3051/8355. 0.1146 s / img. ETA=0:10:17
[32m[04/28 03:10:20 d2.evaluation.evaluator]: [0mInference done 3094/8355. 0.1146 s / img. ETA=0:10:12
[32m[04/28 03:10:25 d2.evaluation.evaluator]: [0mInference done 3137/8355. 0.1146 s / img. ETA=0:10:07
[32m[04/28 03:10:30 d2.evaluation.evaluator]: [0mInference done 3181/8355. 0.1146 s / img. ETA=0:10:02
[32m[04/28 03:10:35 d2.evaluation.evaluator]: [0mInference done 3225/8355. 0.1146 s / img. ETA=0:09:56
[32m[04/28 03:10:40 d2.evaluation.evaluator]: [0mInference done 3268/8355. 0.1146 s / img. ETA=0:09:51
[32m[04/28 03:10:45 d2.evaluation.evaluator]: [0mInference done 3312/8355. 0.1146 s / img. ETA=0:09:46
[32m[04/28 03:10:50 d2.evaluation.evaluator]: [0mInference done 3356/8355. 0.1146 s / img. ETA=0:09:41
[32m[04/28 03:10:55 d2.evaluation.evaluator]: [0mInference done 3400/8355. 0.1146 s / img. ETA=0:09:36
[32m[04/28 03:11:00 d2.evaluation.evaluator]: [0mInference done 3443/8355. 0.1146 s / img. ETA=0:09:31
[32m[04/28 03:11:05 d2.evaluation.evaluator]: [0mInference done 3486/8355. 0.1146 s / img. ETA=0:09:26
[32m[04/28 03:11:10 d2.evaluation.evaluator]: [0mInference done 3529/8355. 0.1146 s / img. ETA=0:09:21
[32m[04/28 03:11:15 d2.evaluation.evaluator]: [0mInference done 3572/8355. 0.1146 s / img. ETA=0:09:16
[32m[04/28 03:11:20 d2.evaluation.evaluator]: [0mInference done 3615/8355. 0.1146 s / img. ETA=0:09:11
[32m[04/28 03:11:25 d2.evaluation.evaluator]: [0mInference done 3658/8355. 0.1146 s / img. ETA=0:09:06
[32m[04/28 03:11:30 d2.evaluation.evaluator]: [0mInference done 3701/8355. 0.1146 s / img. ETA=0:09:01
[32m[04/28 03:11:35 d2.evaluation.evaluator]: [0mInference done 3744/8355. 0.1146 s / img. ETA=0:08:56
[32m[04/28 03:11:41 d2.evaluation.evaluator]: [0mInference done 3788/8355. 0.1146 s / img. ETA=0:08:51
[32m[04/28 03:11:46 d2.evaluation.evaluator]: [0mInference done 3831/8355. 0.1146 s / img. ETA=0:08:46
[32m[04/28 03:11:51 d2.evaluation.evaluator]: [0mInference done 3874/8355. 0.1146 s / img. ETA=0:08:41
[32m[04/28 03:11:56 d2.evaluation.evaluator]: [0mInference done 3918/8355. 0.1146 s / img. ETA=0:08:36
[32m[04/28 03:12:01 d2.evaluation.evaluator]: [0mInference done 3961/8355. 0.1146 s / img. ETA=0:08:31
[32m[04/28 03:12:06 d2.evaluation.evaluator]: [0mInference done 4004/8355. 0.1146 s / img. ETA=0:08:26
[32m[04/28 03:12:11 d2.evaluation.evaluator]: [0mInference done 4047/8355. 0.1146 s / img. ETA=0:08:21
[32m[04/28 03:12:16 d2.evaluation.evaluator]: [0mInference done 4090/8355. 0.1146 s / img. ETA=0:08:16
[32m[04/28 03:12:21 d2.evaluation.evaluator]: [0mInference done 4133/8355. 0.1146 s / img. ETA=0:08:11
[32m[04/28 03:12:26 d2.evaluation.evaluator]: [0mInference done 4176/8355. 0.1147 s / img. ETA=0:08:06
[32m[04/28 03:12:31 d2.evaluation.evaluator]: [0mInference done 4219/8355. 0.1147 s / img. ETA=0:08:01
[32m[04/28 03:12:36 d2.evaluation.evaluator]: [0mInference done 4263/8355. 0.1147 s / img. ETA=0:07:56
[32m[04/28 03:12:41 d2.evaluation.evaluator]: [0mInference done 4306/8355. 0.1147 s / img. ETA=0:07:51
[32m[04/28 03:12:46 d2.evaluation.evaluator]: [0mInference done 4349/8355. 0.1147 s / img. ETA=0:07:46
[32m[04/28 03:12:51 d2.evaluation.evaluator]: [0mInference done 4392/8355. 0.1147 s / img. ETA=0:07:41
[32m[04/28 03:12:56 d2.evaluation.evaluator]: [0mInference done 4435/8355. 0.1147 s / img. ETA=0:07:36
[32m[04/28 03:13:01 d2.evaluation.evaluator]: [0mInference done 4478/8355. 0.1147 s / img. ETA=0:07:31
[32m[04/28 03:13:06 d2.evaluation.evaluator]: [0mInference done 4521/8355. 0.1147 s / img. ETA=0:07:26
[32m[04/28 03:13:11 d2.evaluation.evaluator]: [0mInference done 4564/8355. 0.1147 s / img. ETA=0:07:21
[32m[04/28 03:13:16 d2.evaluation.evaluator]: [0mInference done 4607/8355. 0.1147 s / img. ETA=0:07:16
[32m[04/28 03:13:21 d2.evaluation.evaluator]: [0mInference done 4650/8355. 0.1147 s / img. ETA=0:07:11
[32m[04/28 03:13:26 d2.evaluation.evaluator]: [0mInference done 4693/8355. 0.1147 s / img. ETA=0:07:06
[32m[04/28 03:13:31 d2.evaluation.evaluator]: [0mInference done 4734/8355. 0.1147 s / img. ETA=0:07:01
[32m[04/28 03:13:36 d2.evaluation.evaluator]: [0mInference done 4778/8355. 0.1147 s / img. ETA=0:06:56
[32m[04/28 03:13:41 d2.evaluation.evaluator]: [0mInference done 4822/8355. 0.1147 s / img. ETA=0:06:51
[32m[04/28 03:13:46 d2.evaluation.evaluator]: [0mInference done 4865/8355. 0.1147 s / img. ETA=0:06:46
[32m[04/28 03:13:52 d2.evaluation.evaluator]: [0mInference done 4908/8355. 0.1147 s / img. ETA=0:06:41
[32m[04/28 03:13:57 d2.evaluation.evaluator]: [0mInference done 4951/8355. 0.1147 s / img. ETA=0:06:36
[32m[04/28 03:14:02 d2.evaluation.evaluator]: [0mInference done 4995/8355. 0.1147 s / img. ETA=0:06:31
[32m[04/28 03:14:07 d2.evaluation.evaluator]: [0mInference done 5039/8355. 0.1147 s / img. ETA=0:06:26
[32m[04/28 03:14:12 d2.evaluation.evaluator]: [0mInference done 5083/8355. 0.1147 s / img. ETA=0:06:21
[32m[04/28 03:14:17 d2.evaluation.evaluator]: [0mInference done 5126/8355. 0.1148 s / img. ETA=0:06:16
[32m[04/28 03:14:22 d2.evaluation.evaluator]: [0mInference done 5169/8355. 0.1148 s / img. ETA=0:06:11
[32m[04/28 03:14:27 d2.evaluation.evaluator]: [0mInference done 5212/8355. 0.1148 s / img. ETA=0:06:06
[32m[04/28 03:14:32 d2.evaluation.evaluator]: [0mInference done 5255/8355. 0.1148 s / img. ETA=0:06:01
[32m[04/28 03:14:37 d2.evaluation.evaluator]: [0mInference done 5298/8355. 0.1148 s / img. ETA=0:05:56
[32m[04/28 03:14:42 d2.evaluation.evaluator]: [0mInference done 5341/8355. 0.1148 s / img. ETA=0:05:51
[32m[04/28 03:14:47 d2.evaluation.evaluator]: [0mInference done 5384/8355. 0.1148 s / img. ETA=0:05:46
[32m[04/28 03:14:52 d2.evaluation.evaluator]: [0mInference done 5427/8355. 0.1148 s / img. ETA=0:05:41
[32m[04/28 03:14:57 d2.evaluation.evaluator]: [0mInference done 5470/8355. 0.1148 s / img. ETA=0:05:36
[32m[04/28 03:15:02 d2.evaluation.evaluator]: [0mInference done 5513/8355. 0.1148 s / img. ETA=0:05:31
[32m[04/28 03:15:07 d2.evaluation.evaluator]: [0mInference done 5556/8355. 0.1148 s / img. ETA=0:05:26
[32m[04/28 03:15:12 d2.evaluation.evaluator]: [0mInference done 5600/8355. 0.1148 s / img. ETA=0:05:21
[32m[04/28 03:15:17 d2.evaluation.evaluator]: [0mInference done 5643/8355. 0.1148 s / img. ETA=0:05:16
[32m[04/28 03:15:22 d2.evaluation.evaluator]: [0mInference done 5686/8355. 0.1148 s / img. ETA=0:05:11
[32m[04/28 03:15:27 d2.evaluation.evaluator]: [0mInference done 5729/8355. 0.1148 s / img. ETA=0:05:06
[32m[04/28 03:15:32 d2.evaluation.evaluator]: [0mInference done 5772/8355. 0.1148 s / img. ETA=0:05:01
[32m[04/28 03:15:37 d2.evaluation.evaluator]: [0mInference done 5815/8355. 0.1148 s / img. ETA=0:04:56
[32m[04/28 03:15:42 d2.evaluation.evaluator]: [0mInference done 5858/8355. 0.1148 s / img. ETA=0:04:51
[32m[04/28 03:15:48 d2.evaluation.evaluator]: [0mInference done 5901/8355. 0.1148 s / img. ETA=0:04:46
[32m[04/28 03:15:53 d2.evaluation.evaluator]: [0mInference done 5944/8355. 0.1148 s / img. ETA=0:04:41
[32m[04/28 03:15:58 d2.evaluation.evaluator]: [0mInference done 5987/8355. 0.1148 s / img. ETA=0:04:36
[32m[04/28 03:16:03 d2.evaluation.evaluator]: [0mInference done 6030/8355. 0.1148 s / img. ETA=0:04:31
[32m[04/28 03:16:08 d2.evaluation.evaluator]: [0mInference done 6073/8355. 0.1148 s / img. ETA=0:04:26
[32m[04/28 03:16:13 d2.evaluation.evaluator]: [0mInference done 6116/8355. 0.1148 s / img. ETA=0:04:21
[32m[04/28 03:16:18 d2.evaluation.evaluator]: [0mInference done 6159/8355. 0.1148 s / img. ETA=0:04:16
[32m[04/28 03:16:23 d2.evaluation.evaluator]: [0mInference done 6202/8355. 0.1148 s / img. ETA=0:04:11
[32m[04/28 03:16:28 d2.evaluation.evaluator]: [0mInference done 6245/8355. 0.1148 s / img. ETA=0:04:06
[32m[04/28 03:16:33 d2.evaluation.evaluator]: [0mInference done 6288/8355. 0.1148 s / img. ETA=0:04:01
[32m[04/28 03:16:38 d2.evaluation.evaluator]: [0mInference done 6330/8355. 0.1149 s / img. ETA=0:03:56
[32m[04/28 03:16:43 d2.evaluation.evaluator]: [0mInference done 6373/8355. 0.1149 s / img. ETA=0:03:51
[32m[04/28 03:16:48 d2.evaluation.evaluator]: [0mInference done 6416/8355. 0.1149 s / img. ETA=0:03:46
[32m[04/28 03:16:53 d2.evaluation.evaluator]: [0mInference done 6459/8355. 0.1149 s / img. ETA=0:03:41
[32m[04/28 03:16:58 d2.evaluation.evaluator]: [0mInference done 6502/8355. 0.1149 s / img. ETA=0:03:36
[32m[04/28 03:17:03 d2.evaluation.evaluator]: [0mInference done 6546/8355. 0.1149 s / img. ETA=0:03:31
[32m[04/28 03:17:08 d2.evaluation.evaluator]: [0mInference done 6589/8355. 0.1149 s / img. ETA=0:03:25
[32m[04/28 03:17:13 d2.evaluation.evaluator]: [0mInference done 6632/8355. 0.1149 s / img. ETA=0:03:20
[32m[04/28 03:17:18 d2.evaluation.evaluator]: [0mInference done 6675/8355. 0.1149 s / img. ETA=0:03:15
[32m[04/28 03:17:23 d2.evaluation.evaluator]: [0mInference done 6718/8355. 0.1149 s / img. ETA=0:03:10
[32m[04/28 03:17:28 d2.evaluation.evaluator]: [0mInference done 6762/8355. 0.1149 s / img. ETA=0:03:05
[32m[04/28 03:17:33 d2.evaluation.evaluator]: [0mInference done 6806/8355. 0.1149 s / img. ETA=0:03:00
[32m[04/28 03:17:39 d2.evaluation.evaluator]: [0mInference done 6849/8355. 0.1149 s / img. ETA=0:02:55
[32m[04/28 03:17:44 d2.evaluation.evaluator]: [0mInference done 6892/8355. 0.1149 s / img. ETA=0:02:50
[32m[04/28 03:17:49 d2.evaluation.evaluator]: [0mInference done 6935/8355. 0.1149 s / img. ETA=0:02:45
[32m[04/28 03:17:54 d2.evaluation.evaluator]: [0mInference done 6978/8355. 0.1149 s / img. ETA=0:02:40
[32m[04/28 03:17:59 d2.evaluation.evaluator]: [0mInference done 7021/8355. 0.1149 s / img. ETA=0:02:35
[32m[04/28 03:18:04 d2.evaluation.evaluator]: [0mInference done 7064/8355. 0.1149 s / img. ETA=0:02:30
[32m[04/28 03:18:09 d2.evaluation.evaluator]: [0mInference done 7107/8355. 0.1149 s / img. ETA=0:02:25
[32m[04/28 03:18:14 d2.evaluation.evaluator]: [0mInference done 7150/8355. 0.1149 s / img. ETA=0:02:20
[32m[04/28 03:18:19 d2.evaluation.evaluator]: [0mInference done 7193/8355. 0.1149 s / img. ETA=0:02:15
[32m[04/28 03:18:24 d2.evaluation.evaluator]: [0mInference done 7236/8355. 0.1149 s / img. ETA=0:02:10
[32m[04/28 03:18:29 d2.evaluation.evaluator]: [0mInference done 7279/8355. 0.1149 s / img. ETA=0:02:05
[32m[04/28 03:18:34 d2.evaluation.evaluator]: [0mInference done 7322/8355. 0.1149 s / img. ETA=0:02:00
[32m[04/28 03:18:39 d2.evaluation.evaluator]: [0mInference done 7364/8355. 0.1149 s / img. ETA=0:01:55
[32m[04/28 03:18:44 d2.evaluation.evaluator]: [0mInference done 7407/8355. 0.1149 s / img. ETA=0:01:50
[32m[04/28 03:18:49 d2.evaluation.evaluator]: [0mInference done 7450/8355. 0.1149 s / img. ETA=0:01:45
[32m[04/28 03:18:54 d2.evaluation.evaluator]: [0mInference done 7493/8355. 0.1149 s / img. ETA=0:01:40
[32m[04/28 03:18:59 d2.evaluation.evaluator]: [0mInference done 7536/8355. 0.1149 s / img. ETA=0:01:35
[32m[04/28 03:19:04 d2.evaluation.evaluator]: [0mInference done 7579/8355. 0.1149 s / img. ETA=0:01:30
[32m[04/28 03:19:09 d2.evaluation.evaluator]: [0mInference done 7622/8355. 0.1149 s / img. ETA=0:01:25
[32m[04/28 03:19:14 d2.evaluation.evaluator]: [0mInference done 7665/8355. 0.1149 s / img. ETA=0:01:20
[32m[04/28 03:19:19 d2.evaluation.evaluator]: [0mInference done 7708/8355. 0.1149 s / img. ETA=0:01:15
[32m[04/28 03:19:24 d2.evaluation.evaluator]: [0mInference done 7751/8355. 0.1149 s / img. ETA=0:01:10
[32m[04/28 03:19:29 d2.evaluation.evaluator]: [0mInference done 7794/8355. 0.1149 s / img. ETA=0:01:05
[32m[04/28 03:19:34 d2.evaluation.evaluator]: [0mInference done 7837/8355. 0.1149 s / img. ETA=0:01:00
[32m[04/28 03:19:40 d2.evaluation.evaluator]: [0mInference done 7880/8355. 0.1149 s / img. ETA=0:00:55
[32m[04/28 03:19:45 d2.evaluation.evaluator]: [0mInference done 7923/8355. 0.1149 s / img. ETA=0:00:50
[32m[04/28 03:19:50 d2.evaluation.evaluator]: [0mInference done 7966/8355. 0.1149 s / img. ETA=0:00:45
[32m[04/28 03:19:55 d2.evaluation.evaluator]: [0mInference done 8009/8355. 0.1149 s / img. ETA=0:00:40
[32m[04/28 03:20:00 d2.evaluation.evaluator]: [0mInference done 8053/8355. 0.1149 s / img. ETA=0:00:35
[32m[04/28 03:20:05 d2.evaluation.evaluator]: [0mInference done 8097/8355. 0.1149 s / img. ETA=0:00:30
[32m[04/28 03:20:10 d2.evaluation.evaluator]: [0mInference done 8140/8355. 0.1149 s / img. ETA=0:00:25
[32m[04/28 03:20:15 d2.evaluation.evaluator]: [0mInference done 8183/8355. 0.1149 s / img. ETA=0:00:20
[32m[04/28 03:20:20 d2.evaluation.evaluator]: [0mInference done 8226/8355. 0.1149 s / img. ETA=0:00:15
[32m[04/28 03:20:25 d2.evaluation.evaluator]: [0mInference done 8269/8355. 0.1149 s / img. ETA=0:00:10
[32m[04/28 03:20:30 d2.evaluation.evaluator]: [0mInference done 8312/8355. 0.1149 s / img. ETA=0:00:05
[32m[04/28 03:20:35 d2.evaluation.evaluator]: [0mInference done 8355/8355. 0.1149 s / img. ETA=0:00:00
[32m[04/28 03:20:35 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:14.753080 (0.116737 s / img per device, on 1 devices)
[32m[04/28 03:20:35 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:15:59 (0.114939 s / img per device, on 1 devices)
[32m[04/28 03:20:35 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 03:20:35 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 03:20:36 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.78s).
Accumulating evaluation results...
DONE (t=2.16s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.414
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.768
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.387
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.307
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.545
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.467
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.483
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.392
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716
[32m[04/28 03:20:58 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.428 | 76.838 | 38.652 | 30.663 | 54.488 | 66.586 |
[32m[04/28 03:20:58 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 41.952 | bicycle       | 29.504 | car            | 52.830 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 03:20:58 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 03:20:58 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 03:20:58 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 03:20:59 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1148 s / img. ETA=0:02:24
[32m[04/28 03:21:04 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1146 s / img. ETA=0:02:19
[32m[04/28 03:21:09 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1146 s / img. ETA=0:02:14
[32m[04/28 03:21:15 d2.evaluation.evaluator]: [0mInference done 141/1257. 0.1145 s / img. ETA=0:02:09
[32m[04/28 03:21:20 d2.evaluation.evaluator]: [0mInference done 184/1257. 0.1145 s / img. ETA=0:02:04
[32m[04/28 03:21:25 d2.evaluation.evaluator]: [0mInference done 228/1257. 0.1145 s / img. ETA=0:01:59
[32m[04/28 03:21:30 d2.evaluation.evaluator]: [0mInference done 271/1257. 0.1146 s / img. ETA=0:01:54
[32m[04/28 03:21:35 d2.evaluation.evaluator]: [0mInference done 315/1257. 0.1145 s / img. ETA=0:01:49
[32m[04/28 03:21:40 d2.evaluation.evaluator]: [0mInference done 359/1257. 0.1145 s / img. ETA=0:01:44
[32m[04/28 03:21:45 d2.evaluation.evaluator]: [0mInference done 403/1257. 0.1145 s / img. ETA=0:01:39
[32m[04/28 03:21:50 d2.evaluation.evaluator]: [0mInference done 447/1257. 0.1145 s / img. ETA=0:01:34
[32m[04/28 03:21:55 d2.evaluation.evaluator]: [0mInference done 491/1257. 0.1145 s / img. ETA=0:01:29
[32m[04/28 03:22:00 d2.evaluation.evaluator]: [0mInference done 534/1257. 0.1145 s / img. ETA=0:01:24
[32m[04/28 03:22:05 d2.evaluation.evaluator]: [0mInference done 577/1257. 0.1145 s / img. ETA=0:01:19
[32m[04/28 03:22:10 d2.evaluation.evaluator]: [0mInference done 620/1257. 0.1145 s / img. ETA=0:01:14
[32m[04/28 03:22:15 d2.evaluation.evaluator]: [0mInference done 663/1257. 0.1145 s / img. ETA=0:01:09
[32m[04/28 03:22:20 d2.evaluation.evaluator]: [0mInference done 706/1257. 0.1145 s / img. ETA=0:01:04
[32m[04/28 03:22:25 d2.evaluation.evaluator]: [0mInference done 750/1257. 0.1145 s / img. ETA=0:00:58
[32m[04/28 03:22:30 d2.evaluation.evaluator]: [0mInference done 793/1257. 0.1145 s / img. ETA=0:00:53
[32m[04/28 03:22:35 d2.evaluation.evaluator]: [0mInference done 836/1257. 0.1146 s / img. ETA=0:00:48
[32m[04/28 03:22:40 d2.evaluation.evaluator]: [0mInference done 879/1257. 0.1146 s / img. ETA=0:00:43
[32m[04/28 03:22:46 d2.evaluation.evaluator]: [0mInference done 922/1257. 0.1147 s / img. ETA=0:00:39
[32m[04/28 03:22:51 d2.evaluation.evaluator]: [0mInference done 965/1257. 0.1147 s / img. ETA=0:00:34
[32m[04/28 03:22:56 d2.evaluation.evaluator]: [0mInference done 1008/1257. 0.1147 s / img. ETA=0:00:29
[32m[04/28 03:23:01 d2.evaluation.evaluator]: [0mInference done 1051/1257. 0.1147 s / img. ETA=0:00:24
[32m[04/28 03:23:06 d2.evaluation.evaluator]: [0mInference done 1094/1257. 0.1147 s / img. ETA=0:00:18
[32m[04/28 03:23:11 d2.evaluation.evaluator]: [0mInference done 1137/1257. 0.1148 s / img. ETA=0:00:13
[32m[04/28 03:23:16 d2.evaluation.evaluator]: [0mInference done 1180/1257. 0.1148 s / img. ETA=0:00:08
[32m[04/28 03:23:21 d2.evaluation.evaluator]: [0mInference done 1223/1257. 0.1148 s / img. ETA=0:00:03
[32m[04/28 03:23:25 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:25.994010 (0.116609 s / img per device, on 1 devices)
[32m[04/28 03:23:25 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:23 (0.114808 s / img per device, on 1 devices)
[32m[04/28 03:23:25 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 03:23:25 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 03:23:25 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.28s).
Accumulating evaluation results...
DONE (t=0.37s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.378
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.725
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.329
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.272
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.443
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.537
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.173
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.448
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.508
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.591
[32m[04/28 03:23:29 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 37.782 | 72.527 | 32.855 | 27.161 | 44.339 | 53.694 |
[32m[04/28 03:23:29 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 41.542 | bicycle       | 17.314 | car            | 54.490 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  3  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 03:23:29 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 03:23:30 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 03:23:30 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 03:23:30 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 03:23:30 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 03:23:30 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 03:23:30 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 03:23:51 d2.utils.events]: [0m eta: 0:17:07  iter: 19  total_loss: 0.537  loss_cls: 0.168  loss_box_reg: 0.309  loss_rpn_cls: 0.013  loss_rpn_loc: 0.048  time: 1.0227  data_time: 0.0213  lr: 0.000100  max_mem: 5394M
[32m[04/28 03:24:11 d2.utils.events]: [0m eta: 0:16:40  iter: 39  total_loss: 0.543  loss_cls: 0.181  loss_box_reg: 0.296  loss_rpn_cls: 0.013  loss_rpn_loc: 0.052  time: 1.0250  data_time: 0.0075  lr: 0.000200  max_mem: 5394M
[32m[04/28 03:24:32 d2.utils.events]: [0m eta: 0:16:26  iter: 59  total_loss: 0.591  loss_cls: 0.189  loss_box_reg: 0.326  loss_rpn_cls: 0.014  loss_rpn_loc: 0.050  time: 1.0303  data_time: 0.0081  lr: 0.000300  max_mem: 5394M
[32m[04/28 03:24:53 d2.utils.events]: [0m eta: 0:16:03  iter: 79  total_loss: 0.586  loss_cls: 0.190  loss_box_reg: 0.326  loss_rpn_cls: 0.012  loss_rpn_loc: 0.045  time: 1.0305  data_time: 0.0074  lr: 0.000400  max_mem: 5394M
[32m[04/28 03:25:14 d2.utils.events]: [0m eta: 0:15:45  iter: 99  total_loss: 0.573  loss_cls: 0.195  loss_box_reg: 0.329  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0325  data_time: 0.0076  lr: 0.000500  max_mem: 5394M
[32m[04/28 03:25:34 d2.utils.events]: [0m eta: 0:15:19  iter: 119  total_loss: 0.585  loss_cls: 0.177  loss_box_reg: 0.323  loss_rpn_cls: 0.011  loss_rpn_loc: 0.044  time: 1.0276  data_time: 0.0075  lr: 0.000599  max_mem: 5394M
[32m[04/28 03:25:54 d2.utils.events]: [0m eta: 0:14:57  iter: 139  total_loss: 0.603  loss_cls: 0.202  loss_box_reg: 0.345  loss_rpn_cls: 0.012  loss_rpn_loc: 0.058  time: 1.0249  data_time: 0.0080  lr: 0.000699  max_mem: 5394M
[32m[04/28 03:26:15 d2.utils.events]: [0m eta: 0:14:38  iter: 159  total_loss: 0.570  loss_cls: 0.180  loss_box_reg: 0.327  loss_rpn_cls: 0.010  loss_rpn_loc: 0.041  time: 1.0262  data_time: 0.0078  lr: 0.000799  max_mem: 5394M
[32m[04/28 03:26:36 d2.utils.events]: [0m eta: 0:14:17  iter: 179  total_loss: 0.581  loss_cls: 0.175  loss_box_reg: 0.341  loss_rpn_cls: 0.013  loss_rpn_loc: 0.042  time: 1.0281  data_time: 0.0077  lr: 0.000899  max_mem: 5394M
[32m[04/28 03:26:57 d2.utils.events]: [0m eta: 0:13:57  iter: 199  total_loss: 0.510  loss_cls: 0.161  loss_box_reg: 0.296  loss_rpn_cls: 0.011  loss_rpn_loc: 0.044  time: 1.0296  data_time: 0.0077  lr: 0.000999  max_mem: 5394M
[32m[04/28 03:27:17 d2.utils.events]: [0m eta: 0:13:36  iter: 219  total_loss: 0.532  loss_cls: 0.171  loss_box_reg: 0.307  loss_rpn_cls: 0.009  loss_rpn_loc: 0.047  time: 1.0298  data_time: 0.0082  lr: 0.001099  max_mem: 5394M
[32m[04/28 03:27:38 d2.utils.events]: [0m eta: 0:13:16  iter: 239  total_loss: 0.563  loss_cls: 0.171  loss_box_reg: 0.321  loss_rpn_cls: 0.011  loss_rpn_loc: 0.051  time: 1.0308  data_time: 0.0077  lr: 0.001199  max_mem: 5394M
[32m[04/28 03:27:58 d2.utils.events]: [0m eta: 0:12:54  iter: 259  total_loss: 0.557  loss_cls: 0.172  loss_box_reg: 0.310  loss_rpn_cls: 0.012  loss_rpn_loc: 0.059  time: 1.0293  data_time: 0.0077  lr: 0.001299  max_mem: 5394M
[32m[04/28 03:28:19 d2.utils.events]: [0m eta: 0:12:33  iter: 279  total_loss: 0.624  loss_cls: 0.187  loss_box_reg: 0.365  loss_rpn_cls: 0.011  loss_rpn_loc: 0.053  time: 1.0280  data_time: 0.0077  lr: 0.001399  max_mem: 5394M
[32m[04/28 03:28:39 d2.utils.events]: [0m eta: 0:12:09  iter: 299  total_loss: 0.593  loss_cls: 0.187  loss_box_reg: 0.345  loss_rpn_cls: 0.010  loss_rpn_loc: 0.052  time: 1.0253  data_time: 0.0076  lr: 0.001499  max_mem: 5394M
[32m[04/28 03:28:59 d2.utils.events]: [0m eta: 0:11:46  iter: 319  total_loss: 0.562  loss_cls: 0.169  loss_box_reg: 0.321  loss_rpn_cls: 0.009  loss_rpn_loc: 0.051  time: 1.0245  data_time: 0.0076  lr: 0.001598  max_mem: 5394M
[32m[04/28 03:29:20 d2.utils.events]: [0m eta: 0:11:26  iter: 339  total_loss: 0.574  loss_cls: 0.191  loss_box_reg: 0.334  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 1.0253  data_time: 0.0079  lr: 0.001698  max_mem: 5394M
[32m[04/28 03:29:40 d2.utils.events]: [0m eta: 0:11:05  iter: 359  total_loss: 0.603  loss_cls: 0.210  loss_box_reg: 0.327  loss_rpn_cls: 0.011  loss_rpn_loc: 0.043  time: 1.0248  data_time: 0.0074  lr: 0.001798  max_mem: 5394M
[32m[04/28 03:30:00 d2.utils.events]: [0m eta: 0:10:41  iter: 379  total_loss: 0.526  loss_cls: 0.164  loss_box_reg: 0.305  loss_rpn_cls: 0.009  loss_rpn_loc: 0.041  time: 1.0229  data_time: 0.0074  lr: 0.001898  max_mem: 5394M
[32m[04/28 03:30:21 d2.utils.events]: [0m eta: 0:10:22  iter: 399  total_loss: 0.542  loss_cls: 0.172  loss_box_reg: 0.315  loss_rpn_cls: 0.010  loss_rpn_loc: 0.044  time: 1.0241  data_time: 0.0075  lr: 0.001998  max_mem: 5394M
[32m[04/28 03:30:41 d2.utils.events]: [0m eta: 0:10:00  iter: 419  total_loss: 0.600  loss_cls: 0.196  loss_box_reg: 0.323  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 1.0236  data_time: 0.0078  lr: 0.002098  max_mem: 5394M
[32m[04/28 03:31:01 d2.utils.events]: [0m eta: 0:09:37  iter: 439  total_loss: 0.518  loss_cls: 0.161  loss_box_reg: 0.292  loss_rpn_cls: 0.009  loss_rpn_loc: 0.041  time: 1.0227  data_time: 0.0075  lr: 0.002198  max_mem: 5394M
[32m[04/28 03:31:22 d2.utils.events]: [0m eta: 0:09:18  iter: 459  total_loss: 0.532  loss_cls: 0.180  loss_box_reg: 0.300  loss_rpn_cls: 0.009  loss_rpn_loc: 0.041  time: 1.0239  data_time: 0.0076  lr: 0.002298  max_mem: 5394M
[32m[04/28 03:31:43 d2.utils.events]: [0m eta: 0:08:57  iter: 479  total_loss: 0.575  loss_cls: 0.189  loss_box_reg: 0.318  loss_rpn_cls: 0.013  loss_rpn_loc: 0.058  time: 1.0236  data_time: 0.0075  lr: 0.002398  max_mem: 5394M
[32m[04/28 03:32:04 d2.utils.events]: [0m eta: 0:08:37  iter: 499  total_loss: 0.513  loss_cls: 0.158  loss_box_reg: 0.305  loss_rpn_cls: 0.009  loss_rpn_loc: 0.041  time: 1.0244  data_time: 0.0075  lr: 0.002498  max_mem: 5394M
[32m[04/28 03:32:24 d2.utils.events]: [0m eta: 0:08:15  iter: 519  total_loss: 0.546  loss_cls: 0.172  loss_box_reg: 0.314  loss_rpn_cls: 0.012  loss_rpn_loc: 0.042  time: 1.0237  data_time: 0.0075  lr: 0.002597  max_mem: 5394M
[32m[04/28 03:32:44 d2.utils.events]: [0m eta: 0:07:54  iter: 539  total_loss: 0.511  loss_cls: 0.166  loss_box_reg: 0.271  loss_rpn_cls: 0.010  loss_rpn_loc: 0.044  time: 1.0231  data_time: 0.0074  lr: 0.002697  max_mem: 5394M
[32m[04/28 03:33:05 d2.utils.events]: [0m eta: 0:07:34  iter: 559  total_loss: 0.640  loss_cls: 0.197  loss_box_reg: 0.356  loss_rpn_cls: 0.013  loss_rpn_loc: 0.053  time: 1.0243  data_time: 0.0079  lr: 0.002797  max_mem: 5394M
[32m[04/28 03:33:26 d2.utils.events]: [0m eta: 0:07:14  iter: 579  total_loss: 0.594  loss_cls: 0.191  loss_box_reg: 0.334  loss_rpn_cls: 0.010  loss_rpn_loc: 0.040  time: 1.0242  data_time: 0.0078  lr: 0.002897  max_mem: 5394M
[32m[04/28 03:33:46 d2.utils.events]: [0m eta: 0:06:53  iter: 599  total_loss: 0.697  loss_cls: 0.212  loss_box_reg: 0.376  loss_rpn_cls: 0.015  loss_rpn_loc: 0.076  time: 1.0237  data_time: 0.0082  lr: 0.002997  max_mem: 5394M
[32m[04/28 03:34:07 d2.utils.events]: [0m eta: 0:06:33  iter: 619  total_loss: 0.566  loss_cls: 0.173  loss_box_reg: 0.339  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0246  data_time: 0.0078  lr: 0.003097  max_mem: 5394M
[32m[04/28 03:34:27 d2.utils.events]: [0m eta: 0:06:12  iter: 639  total_loss: 0.600  loss_cls: 0.174  loss_box_reg: 0.331  loss_rpn_cls: 0.011  loss_rpn_loc: 0.057  time: 1.0242  data_time: 0.0076  lr: 0.003197  max_mem: 5394M
[32m[04/28 03:34:48 d2.utils.events]: [0m eta: 0:05:51  iter: 659  total_loss: 0.655  loss_cls: 0.197  loss_box_reg: 0.367  loss_rpn_cls: 0.011  loss_rpn_loc: 0.045  time: 1.0244  data_time: 0.0077  lr: 0.003297  max_mem: 5394M
[32m[04/28 03:35:09 d2.utils.events]: [0m eta: 0:05:31  iter: 679  total_loss: 0.528  loss_cls: 0.168  loss_box_reg: 0.303  loss_rpn_cls: 0.010  loss_rpn_loc: 0.049  time: 1.0247  data_time: 0.0076  lr: 0.003397  max_mem: 5394M
[32m[04/28 03:35:29 d2.utils.events]: [0m eta: 0:05:10  iter: 699  total_loss: 0.626  loss_cls: 0.202  loss_box_reg: 0.373  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0247  data_time: 0.0082  lr: 0.003497  max_mem: 5394M
[32m[04/28 03:35:50 d2.utils.events]: [0m eta: 0:04:50  iter: 719  total_loss: 0.589  loss_cls: 0.183  loss_box_reg: 0.337  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0248  data_time: 0.0074  lr: 0.003596  max_mem: 5394M
[32m[04/28 03:36:10 d2.utils.events]: [0m eta: 0:04:29  iter: 739  total_loss: 0.564  loss_cls: 0.177  loss_box_reg: 0.305  loss_rpn_cls: 0.011  loss_rpn_loc: 0.056  time: 1.0248  data_time: 0.0074  lr: 0.003696  max_mem: 5394M
[32m[04/28 03:36:31 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.583  loss_cls: 0.181  loss_box_reg: 0.336  loss_rpn_cls: 0.011  loss_rpn_loc: 0.049  time: 1.0251  data_time: 0.0075  lr: 0.003796  max_mem: 5394M
[32m[04/28 03:36:51 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.558  loss_cls: 0.184  loss_box_reg: 0.322  loss_rpn_cls: 0.013  loss_rpn_loc: 0.042  time: 1.0247  data_time: 0.0076  lr: 0.003896  max_mem: 5394M
[32m[04/28 03:37:12 d2.utils.events]: [0m eta: 0:03:27  iter: 799  total_loss: 0.631  loss_cls: 0.199  loss_box_reg: 0.347  loss_rpn_cls: 0.011  loss_rpn_loc: 0.052  time: 1.0246  data_time: 0.0077  lr: 0.003996  max_mem: 5394M
[32m[04/28 03:37:32 d2.utils.events]: [0m eta: 0:03:06  iter: 819  total_loss: 0.611  loss_cls: 0.192  loss_box_reg: 0.328  loss_rpn_cls: 0.010  loss_rpn_loc: 0.059  time: 1.0242  data_time: 0.0083  lr: 0.004096  max_mem: 5394M
[32m[04/28 03:37:53 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.586  loss_cls: 0.192  loss_box_reg: 0.338  loss_rpn_cls: 0.008  loss_rpn_loc: 0.057  time: 1.0249  data_time: 0.0083  lr: 0.004196  max_mem: 5394M
[32m[04/28 03:38:14 d2.utils.events]: [0m eta: 0:02:26  iter: 859  total_loss: 0.621  loss_cls: 0.203  loss_box_reg: 0.342  loss_rpn_cls: 0.008  loss_rpn_loc: 0.051  time: 1.0253  data_time: 0.0075  lr: 0.004296  max_mem: 5394M
[32m[04/28 03:38:34 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.650  loss_cls: 0.188  loss_box_reg: 0.348  loss_rpn_cls: 0.013  loss_rpn_loc: 0.054  time: 1.0250  data_time: 0.0075  lr: 0.004396  max_mem: 5394M
[32m[04/28 03:38:55 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.608  loss_cls: 0.188  loss_box_reg: 0.353  loss_rpn_cls: 0.013  loss_rpn_loc: 0.052  time: 1.0254  data_time: 0.0074  lr: 0.004496  max_mem: 5394M
[32m[04/28 03:39:16 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.601  loss_cls: 0.181  loss_box_reg: 0.330  loss_rpn_cls: 0.012  loss_rpn_loc: 0.051  time: 1.0251  data_time: 0.0073  lr: 0.004595  max_mem: 5394M
[32m[04/28 03:39:36 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.617  loss_cls: 0.193  loss_box_reg: 0.340  loss_rpn_cls: 0.016  loss_rpn_loc: 0.057  time: 1.0251  data_time: 0.0073  lr: 0.004695  max_mem: 5394M
[32m[04/28 03:39:57 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.611  loss_cls: 0.188  loss_box_reg: 0.357  loss_rpn_cls: 0.010  loss_rpn_loc: 0.055  time: 1.0255  data_time: 0.0073  lr: 0.004795  max_mem: 5394M
[32m[04/28 03:40:18 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.525  loss_cls: 0.166  loss_box_reg: 0.298  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 1.0256  data_time: 0.0074  lr: 0.004895  max_mem: 5394M
[5m[31mWARNING[0m [32m[04/28 03:40:41 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 03:40:41 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 03:40:41 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 03:40:41 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.633  loss_cls: 0.192  loss_box_reg: 0.361  loss_rpn_cls: 0.014  loss_rpn_loc: 0.052  time: 1.0258  data_time: 0.0075  lr: 0.004995  max_mem: 5394M
[32m[04/28 03:40:41 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:03 (1.0268 s / it)
[32m[04/28 03:40:41 d2.engine.hooks]: [0mTotal training time: 0:17:09 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 03:40:43 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 03:40:43 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 03:40:44 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 03:40:45 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1140 s / img. ETA=0:16:02
[32m[04/28 03:40:50 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1138 s / img. ETA=0:15:57
[32m[04/28 03:40:55 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1136 s / img. ETA=0:15:51
[32m[04/28 03:41:00 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1136 s / img. ETA=0:15:46
[32m[04/28 03:41:05 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1136 s / img. ETA=0:15:41
[32m[04/28 03:41:11 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1136 s / img. ETA=0:15:36
[32m[04/28 03:41:16 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1137 s / img. ETA=0:15:31
[32m[04/28 03:41:21 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1137 s / img. ETA=0:15:27
[32m[04/28 03:41:26 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1137 s / img. ETA=0:15:22
[32m[04/28 03:41:31 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1138 s / img. ETA=0:15:17
[32m[04/28 03:41:36 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1138 s / img. ETA=0:15:12
[32m[04/28 03:41:41 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1138 s / img. ETA=0:15:07
[32m[04/28 03:41:46 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1138 s / img. ETA=0:15:02
[32m[04/28 03:41:51 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1138 s / img. ETA=0:14:57
[32m[04/28 03:41:56 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1138 s / img. ETA=0:14:52
[32m[04/28 03:42:01 d2.evaluation.evaluator]: [0mInference done 671/8355. 0.1138 s / img. ETA=0:14:47
[32m[04/28 03:42:06 d2.evaluation.evaluator]: [0mInference done 714/8355. 0.1139 s / img. ETA=0:14:43
[32m[04/28 03:42:12 d2.evaluation.evaluator]: [0mInference done 758/8355. 0.1139 s / img. ETA=0:14:38
[32m[04/28 03:42:17 d2.evaluation.evaluator]: [0mInference done 802/8355. 0.1140 s / img. ETA=0:14:33
[32m[04/28 03:42:22 d2.evaluation.evaluator]: [0mInference done 845/8355. 0.1140 s / img. ETA=0:14:28
[32m[04/28 03:42:27 d2.evaluation.evaluator]: [0mInference done 889/8355. 0.1140 s / img. ETA=0:14:23
[32m[04/28 03:42:32 d2.evaluation.evaluator]: [0mInference done 933/8355. 0.1140 s / img. ETA=0:14:18
[32m[04/28 03:42:37 d2.evaluation.evaluator]: [0mInference done 977/8355. 0.1140 s / img. ETA=0:14:13
[32m[04/28 03:42:42 d2.evaluation.evaluator]: [0mInference done 1021/8355. 0.1140 s / img. ETA=0:14:08
[32m[04/28 03:42:47 d2.evaluation.evaluator]: [0mInference done 1065/8355. 0.1140 s / img. ETA=0:14:03
[32m[04/28 03:42:52 d2.evaluation.evaluator]: [0mInference done 1109/8355. 0.1141 s / img. ETA=0:13:58
[32m[04/28 03:42:57 d2.evaluation.evaluator]: [0mInference done 1153/8355. 0.1141 s / img. ETA=0:13:53
[32m[04/28 03:43:02 d2.evaluation.evaluator]: [0mInference done 1197/8355. 0.1141 s / img. ETA=0:13:48
[32m[04/28 03:43:07 d2.evaluation.evaluator]: [0mInference done 1241/8355. 0.1140 s / img. ETA=0:13:43
[32m[04/28 03:43:13 d2.evaluation.evaluator]: [0mInference done 1285/8355. 0.1140 s / img. ETA=0:13:37
[32m[04/28 03:43:18 d2.evaluation.evaluator]: [0mInference done 1329/8355. 0.1140 s / img. ETA=0:13:32
[32m[04/28 03:43:23 d2.evaluation.evaluator]: [0mInference done 1373/8355. 0.1140 s / img. ETA=0:13:27
[32m[04/28 03:43:28 d2.evaluation.evaluator]: [0mInference done 1417/8355. 0.1140 s / img. ETA=0:13:22
[32m[04/28 03:43:33 d2.evaluation.evaluator]: [0mInference done 1461/8355. 0.1140 s / img. ETA=0:13:17
[32m[04/28 03:43:38 d2.evaluation.evaluator]: [0mInference done 1504/8355. 0.1141 s / img. ETA=0:13:13
[32m[04/28 03:43:43 d2.evaluation.evaluator]: [0mInference done 1547/8355. 0.1142 s / img. ETA=0:13:08
[32m[04/28 03:43:48 d2.evaluation.evaluator]: [0mInference done 1590/8355. 0.1142 s / img. ETA=0:13:03
[32m[04/28 03:43:53 d2.evaluation.evaluator]: [0mInference done 1633/8355. 0.1142 s / img. ETA=0:12:59
[32m[04/28 03:43:58 d2.evaluation.evaluator]: [0mInference done 1676/8355. 0.1143 s / img. ETA=0:12:54
[32m[04/28 03:44:03 d2.evaluation.evaluator]: [0mInference done 1719/8355. 0.1143 s / img. ETA=0:12:49
[32m[04/28 03:44:08 d2.evaluation.evaluator]: [0mInference done 1762/8355. 0.1143 s / img. ETA=0:12:45
[32m[04/28 03:44:13 d2.evaluation.evaluator]: [0mInference done 1805/8355. 0.1144 s / img. ETA=0:12:40
[32m[04/28 03:44:18 d2.evaluation.evaluator]: [0mInference done 1848/8355. 0.1144 s / img. ETA=0:12:35
[32m[04/28 03:44:24 d2.evaluation.evaluator]: [0mInference done 1891/8355. 0.1144 s / img. ETA=0:12:30
[32m[04/28 03:44:29 d2.evaluation.evaluator]: [0mInference done 1934/8355. 0.1144 s / img. ETA=0:12:25
[32m[04/28 03:44:34 d2.evaluation.evaluator]: [0mInference done 1977/8355. 0.1145 s / img. ETA=0:12:21
[32m[04/28 03:44:39 d2.evaluation.evaluator]: [0mInference done 2020/8355. 0.1145 s / img. ETA=0:12:16
[32m[04/28 03:44:44 d2.evaluation.evaluator]: [0mInference done 2063/8355. 0.1145 s / img. ETA=0:12:11
[32m[04/28 03:44:49 d2.evaluation.evaluator]: [0mInference done 2106/8355. 0.1145 s / img. ETA=0:12:06
[32m[04/28 03:44:54 d2.evaluation.evaluator]: [0mInference done 2150/8355. 0.1145 s / img. ETA=0:12:01
[32m[04/28 03:44:59 d2.evaluation.evaluator]: [0mInference done 2193/8355. 0.1145 s / img. ETA=0:11:56
[32m[04/28 03:45:04 d2.evaluation.evaluator]: [0mInference done 2236/8355. 0.1145 s / img. ETA=0:11:51
[32m[04/28 03:45:09 d2.evaluation.evaluator]: [0mInference done 2279/8355. 0.1146 s / img. ETA=0:11:46
[32m[04/28 03:45:14 d2.evaluation.evaluator]: [0mInference done 2322/8355. 0.1146 s / img. ETA=0:11:41
[32m[04/28 03:45:19 d2.evaluation.evaluator]: [0mInference done 2364/8355. 0.1146 s / img. ETA=0:11:37
[32m[04/28 03:45:24 d2.evaluation.evaluator]: [0mInference done 2407/8355. 0.1146 s / img. ETA=0:11:32
[32m[04/28 03:45:29 d2.evaluation.evaluator]: [0mInference done 2450/8355. 0.1146 s / img. ETA=0:11:27
[32m[04/28 03:45:34 d2.evaluation.evaluator]: [0mInference done 2493/8355. 0.1147 s / img. ETA=0:11:22
[32m[04/28 03:45:39 d2.evaluation.evaluator]: [0mInference done 2536/8355. 0.1147 s / img. ETA=0:11:17
[32m[04/28 03:45:44 d2.evaluation.evaluator]: [0mInference done 2579/8355. 0.1147 s / img. ETA=0:11:12
[32m[04/28 03:45:49 d2.evaluation.evaluator]: [0mInference done 2622/8355. 0.1147 s / img. ETA=0:11:07
[32m[04/28 03:45:54 d2.evaluation.evaluator]: [0mInference done 2665/8355. 0.1147 s / img. ETA=0:11:02
[32m[04/28 03:45:59 d2.evaluation.evaluator]: [0mInference done 2708/8355. 0.1147 s / img. ETA=0:10:57
[32m[04/28 03:46:04 d2.evaluation.evaluator]: [0mInference done 2751/8355. 0.1147 s / img. ETA=0:10:52
[32m[04/28 03:46:09 d2.evaluation.evaluator]: [0mInference done 2794/8355. 0.1147 s / img. ETA=0:10:47
[32m[04/28 03:46:14 d2.evaluation.evaluator]: [0mInference done 2837/8355. 0.1147 s / img. ETA=0:10:42
[32m[04/28 03:46:19 d2.evaluation.evaluator]: [0mInference done 2880/8355. 0.1148 s / img. ETA=0:10:37
[32m[04/28 03:46:24 d2.evaluation.evaluator]: [0mInference done 2923/8355. 0.1148 s / img. ETA=0:10:32
[32m[04/28 03:46:30 d2.evaluation.evaluator]: [0mInference done 2966/8355. 0.1148 s / img. ETA=0:10:27
[32m[04/28 03:46:35 d2.evaluation.evaluator]: [0mInference done 3009/8355. 0.1148 s / img. ETA=0:10:22
[32m[04/28 03:46:40 d2.evaluation.evaluator]: [0mInference done 3052/8355. 0.1148 s / img. ETA=0:10:17
[32m[04/28 03:46:45 d2.evaluation.evaluator]: [0mInference done 3095/8355. 0.1148 s / img. ETA=0:10:12
[32m[04/28 03:46:50 d2.evaluation.evaluator]: [0mInference done 3138/8355. 0.1148 s / img. ETA=0:10:07
[32m[04/28 03:46:55 d2.evaluation.evaluator]: [0mInference done 3182/8355. 0.1148 s / img. ETA=0:10:02
[32m[04/28 03:47:00 d2.evaluation.evaluator]: [0mInference done 3226/8355. 0.1148 s / img. ETA=0:09:57
[32m[04/28 03:47:05 d2.evaluation.evaluator]: [0mInference done 3269/8355. 0.1148 s / img. ETA=0:09:52
[32m[04/28 03:47:10 d2.evaluation.evaluator]: [0mInference done 3312/8355. 0.1148 s / img. ETA=0:09:47
[32m[04/28 03:47:15 d2.evaluation.evaluator]: [0mInference done 3355/8355. 0.1148 s / img. ETA=0:09:42
[32m[04/28 03:47:20 d2.evaluation.evaluator]: [0mInference done 3398/8355. 0.1148 s / img. ETA=0:09:37
[32m[04/28 03:47:25 d2.evaluation.evaluator]: [0mInference done 3441/8355. 0.1148 s / img. ETA=0:09:32
[32m[04/28 03:47:30 d2.evaluation.evaluator]: [0mInference done 3484/8355. 0.1148 s / img. ETA=0:09:27
[32m[04/28 03:47:35 d2.evaluation.evaluator]: [0mInference done 3528/8355. 0.1148 s / img. ETA=0:09:22
[32m[04/28 03:47:40 d2.evaluation.evaluator]: [0mInference done 3572/8355. 0.1148 s / img. ETA=0:09:17
[32m[04/28 03:47:45 d2.evaluation.evaluator]: [0mInference done 3615/8355. 0.1148 s / img. ETA=0:09:12
[32m[04/28 03:47:50 d2.evaluation.evaluator]: [0mInference done 3658/8355. 0.1148 s / img. ETA=0:09:07
[32m[04/28 03:47:55 d2.evaluation.evaluator]: [0mInference done 3702/8355. 0.1148 s / img. ETA=0:09:02
[32m[04/28 03:48:00 d2.evaluation.evaluator]: [0mInference done 3745/8355. 0.1148 s / img. ETA=0:08:57
[32m[04/28 03:48:05 d2.evaluation.evaluator]: [0mInference done 3788/8355. 0.1148 s / img. ETA=0:08:52
[32m[04/28 03:48:10 d2.evaluation.evaluator]: [0mInference done 3831/8355. 0.1148 s / img. ETA=0:08:47
[32m[04/28 03:48:15 d2.evaluation.evaluator]: [0mInference done 3874/8355. 0.1148 s / img. ETA=0:08:42
[32m[04/28 03:48:20 d2.evaluation.evaluator]: [0mInference done 3918/8355. 0.1148 s / img. ETA=0:08:37
[32m[04/28 03:48:26 d2.evaluation.evaluator]: [0mInference done 3962/8355. 0.1148 s / img. ETA=0:08:31
[32m[04/28 03:48:31 d2.evaluation.evaluator]: [0mInference done 4005/8355. 0.1148 s / img. ETA=0:08:26
[32m[04/28 03:48:36 d2.evaluation.evaluator]: [0mInference done 4048/8355. 0.1148 s / img. ETA=0:08:21
[32m[04/28 03:48:41 d2.evaluation.evaluator]: [0mInference done 4091/8355. 0.1148 s / img. ETA=0:08:16
[32m[04/28 03:48:46 d2.evaluation.evaluator]: [0mInference done 4134/8355. 0.1148 s / img. ETA=0:08:11
[32m[04/28 03:48:51 d2.evaluation.evaluator]: [0mInference done 4177/8355. 0.1148 s / img. ETA=0:08:06
[32m[04/28 03:48:56 d2.evaluation.evaluator]: [0mInference done 4220/8355. 0.1148 s / img. ETA=0:08:01
[32m[04/28 03:49:01 d2.evaluation.evaluator]: [0mInference done 4264/8355. 0.1148 s / img. ETA=0:07:56
[32m[04/28 03:49:06 d2.evaluation.evaluator]: [0mInference done 4308/8355. 0.1148 s / img. ETA=0:07:51
[32m[04/28 03:49:11 d2.evaluation.evaluator]: [0mInference done 4351/8355. 0.1148 s / img. ETA=0:07:46
[32m[04/28 03:49:16 d2.evaluation.evaluator]: [0mInference done 4394/8355. 0.1148 s / img. ETA=0:07:41
[32m[04/28 03:49:21 d2.evaluation.evaluator]: [0mInference done 4437/8355. 0.1148 s / img. ETA=0:07:36
[32m[04/28 03:49:26 d2.evaluation.evaluator]: [0mInference done 4480/8355. 0.1148 s / img. ETA=0:07:31
[32m[04/28 03:49:31 d2.evaluation.evaluator]: [0mInference done 4523/8355. 0.1148 s / img. ETA=0:07:26
[32m[04/28 03:49:36 d2.evaluation.evaluator]: [0mInference done 4566/8355. 0.1148 s / img. ETA=0:07:21
[32m[04/28 03:49:41 d2.evaluation.evaluator]: [0mInference done 4609/8355. 0.1148 s / img. ETA=0:07:16
[32m[04/28 03:49:46 d2.evaluation.evaluator]: [0mInference done 4652/8355. 0.1148 s / img. ETA=0:07:11
[32m[04/28 03:49:51 d2.evaluation.evaluator]: [0mInference done 4695/8355. 0.1148 s / img. ETA=0:07:06
[32m[04/28 03:49:56 d2.evaluation.evaluator]: [0mInference done 4738/8355. 0.1148 s / img. ETA=0:07:01
[32m[04/28 03:50:01 d2.evaluation.evaluator]: [0mInference done 4781/8355. 0.1148 s / img. ETA=0:06:56
[32m[04/28 03:50:06 d2.evaluation.evaluator]: [0mInference done 4824/8355. 0.1148 s / img. ETA=0:06:51
[32m[04/28 03:50:11 d2.evaluation.evaluator]: [0mInference done 4867/8355. 0.1148 s / img. ETA=0:06:46
[32m[04/28 03:50:16 d2.evaluation.evaluator]: [0mInference done 4910/8355. 0.1148 s / img. ETA=0:06:41
[32m[04/28 03:50:21 d2.evaluation.evaluator]: [0mInference done 4953/8355. 0.1148 s / img. ETA=0:06:36
[32m[04/28 03:50:26 d2.evaluation.evaluator]: [0mInference done 4996/8355. 0.1148 s / img. ETA=0:06:31
[32m[04/28 03:50:31 d2.evaluation.evaluator]: [0mInference done 5039/8355. 0.1148 s / img. ETA=0:06:26
[32m[04/28 03:50:36 d2.evaluation.evaluator]: [0mInference done 5082/8355. 0.1148 s / img. ETA=0:06:21
[32m[04/28 03:50:41 d2.evaluation.evaluator]: [0mInference done 5124/8355. 0.1149 s / img. ETA=0:06:16
[32m[04/28 03:50:47 d2.evaluation.evaluator]: [0mInference done 5167/8355. 0.1149 s / img. ETA=0:06:11
[32m[04/28 03:50:52 d2.evaluation.evaluator]: [0mInference done 5210/8355. 0.1149 s / img. ETA=0:06:06
[32m[04/28 03:50:57 d2.evaluation.evaluator]: [0mInference done 5253/8355. 0.1149 s / img. ETA=0:06:01
[32m[04/28 03:51:02 d2.evaluation.evaluator]: [0mInference done 5296/8355. 0.1149 s / img. ETA=0:05:56
[32m[04/28 03:51:07 d2.evaluation.evaluator]: [0mInference done 5339/8355. 0.1149 s / img. ETA=0:05:51
[32m[04/28 03:51:12 d2.evaluation.evaluator]: [0mInference done 5382/8355. 0.1149 s / img. ETA=0:05:46
[32m[04/28 03:51:17 d2.evaluation.evaluator]: [0mInference done 5425/8355. 0.1149 s / img. ETA=0:05:41
[32m[04/28 03:51:22 d2.evaluation.evaluator]: [0mInference done 5468/8355. 0.1149 s / img. ETA=0:05:36
[32m[04/28 03:51:27 d2.evaluation.evaluator]: [0mInference done 5511/8355. 0.1149 s / img. ETA=0:05:31
[32m[04/28 03:51:32 d2.evaluation.evaluator]: [0mInference done 5555/8355. 0.1149 s / img. ETA=0:05:26
[32m[04/28 03:51:37 d2.evaluation.evaluator]: [0mInference done 5598/8355. 0.1149 s / img. ETA=0:05:21
[32m[04/28 03:51:42 d2.evaluation.evaluator]: [0mInference done 5641/8355. 0.1149 s / img. ETA=0:05:16
[32m[04/28 03:51:47 d2.evaluation.evaluator]: [0mInference done 5684/8355. 0.1149 s / img. ETA=0:05:11
[32m[04/28 03:51:52 d2.evaluation.evaluator]: [0mInference done 5727/8355. 0.1149 s / img. ETA=0:05:06
[32m[04/28 03:51:57 d2.evaluation.evaluator]: [0mInference done 5770/8355. 0.1149 s / img. ETA=0:05:01
[32m[04/28 03:52:02 d2.evaluation.evaluator]: [0mInference done 5813/8355. 0.1149 s / img. ETA=0:04:56
[32m[04/28 03:52:07 d2.evaluation.evaluator]: [0mInference done 5856/8355. 0.1149 s / img. ETA=0:04:51
[32m[04/28 03:52:12 d2.evaluation.evaluator]: [0mInference done 5899/8355. 0.1149 s / img. ETA=0:04:46
[32m[04/28 03:52:17 d2.evaluation.evaluator]: [0mInference done 5942/8355. 0.1149 s / img. ETA=0:04:41
[32m[04/28 03:52:22 d2.evaluation.evaluator]: [0mInference done 5985/8355. 0.1149 s / img. ETA=0:04:36
[32m[04/28 03:52:27 d2.evaluation.evaluator]: [0mInference done 6028/8355. 0.1149 s / img. ETA=0:04:31
[32m[04/28 03:52:32 d2.evaluation.evaluator]: [0mInference done 6071/8355. 0.1149 s / img. ETA=0:04:26
[32m[04/28 03:52:38 d2.evaluation.evaluator]: [0mInference done 6114/8355. 0.1149 s / img. ETA=0:04:21
[32m[04/28 03:52:43 d2.evaluation.evaluator]: [0mInference done 6157/8355. 0.1150 s / img. ETA=0:04:16
[32m[04/28 03:52:48 d2.evaluation.evaluator]: [0mInference done 6200/8355. 0.1150 s / img. ETA=0:04:11
[32m[04/28 03:52:53 d2.evaluation.evaluator]: [0mInference done 6243/8355. 0.1150 s / img. ETA=0:04:06
[32m[04/28 03:52:58 d2.evaluation.evaluator]: [0mInference done 6286/8355. 0.1150 s / img. ETA=0:04:01
[32m[04/28 03:53:03 d2.evaluation.evaluator]: [0mInference done 6329/8355. 0.1150 s / img. ETA=0:03:56
[32m[04/28 03:53:08 d2.evaluation.evaluator]: [0mInference done 6372/8355. 0.1150 s / img. ETA=0:03:51
[32m[04/28 03:53:13 d2.evaluation.evaluator]: [0mInference done 6415/8355. 0.1150 s / img. ETA=0:03:46
[32m[04/28 03:53:18 d2.evaluation.evaluator]: [0mInference done 6458/8355. 0.1150 s / img. ETA=0:03:41
[32m[04/28 03:53:23 d2.evaluation.evaluator]: [0mInference done 6501/8355. 0.1150 s / img. ETA=0:03:36
[32m[04/28 03:53:28 d2.evaluation.evaluator]: [0mInference done 6545/8355. 0.1150 s / img. ETA=0:03:31
[32m[04/28 03:53:33 d2.evaluation.evaluator]: [0mInference done 6588/8355. 0.1150 s / img. ETA=0:03:26
[32m[04/28 03:53:38 d2.evaluation.evaluator]: [0mInference done 6631/8355. 0.1150 s / img. ETA=0:03:21
[32m[04/28 03:53:43 d2.evaluation.evaluator]: [0mInference done 6674/8355. 0.1150 s / img. ETA=0:03:16
[32m[04/28 03:53:48 d2.evaluation.evaluator]: [0mInference done 6718/8355. 0.1150 s / img. ETA=0:03:11
[32m[04/28 03:53:53 d2.evaluation.evaluator]: [0mInference done 6761/8355. 0.1150 s / img. ETA=0:03:06
[32m[04/28 03:53:58 d2.evaluation.evaluator]: [0mInference done 6804/8355. 0.1150 s / img. ETA=0:03:01
[32m[04/28 03:54:03 d2.evaluation.evaluator]: [0mInference done 6847/8355. 0.1150 s / img. ETA=0:02:56
[32m[04/28 03:54:09 d2.evaluation.evaluator]: [0mInference done 6891/8355. 0.1150 s / img. ETA=0:02:50
[32m[04/28 03:54:14 d2.evaluation.evaluator]: [0mInference done 6934/8355. 0.1150 s / img. ETA=0:02:45
[32m[04/28 03:54:19 d2.evaluation.evaluator]: [0mInference done 6977/8355. 0.1150 s / img. ETA=0:02:40
[32m[04/28 03:54:24 d2.evaluation.evaluator]: [0mInference done 7020/8355. 0.1150 s / img. ETA=0:02:35
[32m[04/28 03:54:29 d2.evaluation.evaluator]: [0mInference done 7063/8355. 0.1150 s / img. ETA=0:02:30
[32m[04/28 03:54:34 d2.evaluation.evaluator]: [0mInference done 7106/8355. 0.1150 s / img. ETA=0:02:25
[32m[04/28 03:54:39 d2.evaluation.evaluator]: [0mInference done 7149/8355. 0.1150 s / img. ETA=0:02:20
[32m[04/28 03:54:44 d2.evaluation.evaluator]: [0mInference done 7192/8355. 0.1150 s / img. ETA=0:02:15
[32m[04/28 03:54:49 d2.evaluation.evaluator]: [0mInference done 7234/8355. 0.1150 s / img. ETA=0:02:10
[32m[04/28 03:54:54 d2.evaluation.evaluator]: [0mInference done 7277/8355. 0.1150 s / img. ETA=0:02:05
[32m[04/28 03:54:59 d2.evaluation.evaluator]: [0mInference done 7320/8355. 0.1150 s / img. ETA=0:02:00
[32m[04/28 03:55:04 d2.evaluation.evaluator]: [0mInference done 7363/8355. 0.1150 s / img. ETA=0:01:55
[32m[04/28 03:55:09 d2.evaluation.evaluator]: [0mInference done 7406/8355. 0.1151 s / img. ETA=0:01:50
[32m[04/28 03:55:14 d2.evaluation.evaluator]: [0mInference done 7449/8355. 0.1151 s / img. ETA=0:01:45
[32m[04/28 03:55:19 d2.evaluation.evaluator]: [0mInference done 7491/8355. 0.1151 s / img. ETA=0:01:40
[32m[04/28 03:55:24 d2.evaluation.evaluator]: [0mInference done 7534/8355. 0.1151 s / img. ETA=0:01:35
[32m[04/28 03:55:29 d2.evaluation.evaluator]: [0mInference done 7577/8355. 0.1151 s / img. ETA=0:01:30
[32m[04/28 03:55:34 d2.evaluation.evaluator]: [0mInference done 7620/8355. 0.1151 s / img. ETA=0:01:25
[32m[04/28 03:55:39 d2.evaluation.evaluator]: [0mInference done 7663/8355. 0.1151 s / img. ETA=0:01:20
[32m[04/28 03:55:45 d2.evaluation.evaluator]: [0mInference done 7706/8355. 0.1151 s / img. ETA=0:01:15
[32m[04/28 03:55:50 d2.evaluation.evaluator]: [0mInference done 7749/8355. 0.1151 s / img. ETA=0:01:10
[32m[04/28 03:55:55 d2.evaluation.evaluator]: [0mInference done 7792/8355. 0.1151 s / img. ETA=0:01:05
[32m[04/28 03:56:00 d2.evaluation.evaluator]: [0mInference done 7835/8355. 0.1151 s / img. ETA=0:01:00
[32m[04/28 03:56:05 d2.evaluation.evaluator]: [0mInference done 7878/8355. 0.1151 s / img. ETA=0:00:55
[32m[04/28 03:56:10 d2.evaluation.evaluator]: [0mInference done 7921/8355. 0.1151 s / img. ETA=0:00:50
[32m[04/28 03:56:15 d2.evaluation.evaluator]: [0mInference done 7964/8355. 0.1151 s / img. ETA=0:00:45
[32m[04/28 03:56:20 d2.evaluation.evaluator]: [0mInference done 8007/8355. 0.1151 s / img. ETA=0:00:40
[32m[04/28 03:56:25 d2.evaluation.evaluator]: [0mInference done 8051/8355. 0.1151 s / img. ETA=0:00:35
[32m[04/28 03:56:30 d2.evaluation.evaluator]: [0mInference done 8095/8355. 0.1151 s / img. ETA=0:00:30
[32m[04/28 03:56:35 d2.evaluation.evaluator]: [0mInference done 8138/8355. 0.1151 s / img. ETA=0:00:25
[32m[04/28 03:56:40 d2.evaluation.evaluator]: [0mInference done 8181/8355. 0.1151 s / img. ETA=0:00:20
[32m[04/28 03:56:45 d2.evaluation.evaluator]: [0mInference done 8224/8355. 0.1151 s / img. ETA=0:00:15
[32m[04/28 03:56:50 d2.evaluation.evaluator]: [0mInference done 8267/8355. 0.1151 s / img. ETA=0:00:10
[32m[04/28 03:56:55 d2.evaluation.evaluator]: [0mInference done 8310/8355. 0.1151 s / img. ETA=0:00:05
[32m[04/28 03:57:00 d2.evaluation.evaluator]: [0mInference done 8353/8355. 0.1151 s / img. ETA=0:00:00
[32m[04/28 03:57:01 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:16.116043 (0.116900 s / img per device, on 1 devices)
[32m[04/28 03:57:01 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:01 (0.115104 s / img per device, on 1 devices)
[32m[04/28 03:57:01 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 03:57:01 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 03:57:01 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.43s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.83s).
Accumulating evaluation results...
DONE (t=2.32s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.432
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.806
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.404
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.339
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.545
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.167
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.497
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.516
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.434
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.699
[32m[04/28 03:57:25 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.216 | 80.582 | 40.379 | 33.898 | 54.485 | 65.084 |
[32m[04/28 03:57:25 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 44.890 | bicycle       | 32.002 | car            | 52.757 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 03:57:25 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 03:57:25 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 03:57:25 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 03:57:27 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1149 s / img. ETA=0:02:25
[32m[04/28 03:57:32 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1146 s / img. ETA=0:02:19
[32m[04/28 03:57:37 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1146 s / img. ETA=0:02:15
[32m[04/28 03:57:42 d2.evaluation.evaluator]: [0mInference done 141/1257. 0.1145 s / img. ETA=0:02:09
[32m[04/28 03:57:47 d2.evaluation.evaluator]: [0mInference done 184/1257. 0.1146 s / img. ETA=0:02:04
[32m[04/28 03:57:52 d2.evaluation.evaluator]: [0mInference done 227/1257. 0.1146 s / img. ETA=0:01:59
[32m[04/28 03:57:57 d2.evaluation.evaluator]: [0mInference done 270/1257. 0.1147 s / img. ETA=0:01:54
[32m[04/28 03:58:02 d2.evaluation.evaluator]: [0mInference done 313/1257. 0.1147 s / img. ETA=0:01:49
[32m[04/28 03:58:07 d2.evaluation.evaluator]: [0mInference done 356/1257. 0.1147 s / img. ETA=0:01:44
[32m[04/28 03:58:12 d2.evaluation.evaluator]: [0mInference done 399/1257. 0.1147 s / img. ETA=0:01:39
[32m[04/28 03:58:17 d2.evaluation.evaluator]: [0mInference done 442/1257. 0.1146 s / img. ETA=0:01:34
[32m[04/28 03:58:22 d2.evaluation.evaluator]: [0mInference done 486/1257. 0.1146 s / img. ETA=0:01:29
[32m[04/28 03:58:27 d2.evaluation.evaluator]: [0mInference done 529/1257. 0.1147 s / img. ETA=0:01:24
[32m[04/28 03:58:32 d2.evaluation.evaluator]: [0mInference done 572/1257. 0.1147 s / img. ETA=0:01:19
[32m[04/28 03:58:37 d2.evaluation.evaluator]: [0mInference done 615/1257. 0.1147 s / img. ETA=0:01:14
[32m[04/28 03:58:42 d2.evaluation.evaluator]: [0mInference done 658/1257. 0.1147 s / img. ETA=0:01:09
[32m[04/28 03:58:47 d2.evaluation.evaluator]: [0mInference done 701/1257. 0.1147 s / img. ETA=0:01:04
[32m[04/28 03:58:52 d2.evaluation.evaluator]: [0mInference done 744/1257. 0.1147 s / img. ETA=0:00:59
[32m[04/28 03:58:57 d2.evaluation.evaluator]: [0mInference done 787/1257. 0.1147 s / img. ETA=0:00:54
[32m[04/28 03:59:02 d2.evaluation.evaluator]: [0mInference done 830/1257. 0.1147 s / img. ETA=0:00:49
[32m[04/28 03:59:07 d2.evaluation.evaluator]: [0mInference done 873/1257. 0.1148 s / img. ETA=0:00:44
[32m[04/28 03:59:12 d2.evaluation.evaluator]: [0mInference done 916/1257. 0.1148 s / img. ETA=0:00:39
[32m[04/28 03:59:17 d2.evaluation.evaluator]: [0mInference done 959/1257. 0.1148 s / img. ETA=0:00:34
[32m[04/28 03:59:22 d2.evaluation.evaluator]: [0mInference done 1002/1257. 0.1149 s / img. ETA=0:00:29
[32m[04/28 03:59:27 d2.evaluation.evaluator]: [0mInference done 1045/1257. 0.1149 s / img. ETA=0:00:24
[32m[04/28 03:59:32 d2.evaluation.evaluator]: [0mInference done 1088/1257. 0.1149 s / img. ETA=0:00:19
[32m[04/28 03:59:37 d2.evaluation.evaluator]: [0mInference done 1130/1257. 0.1150 s / img. ETA=0:00:14
[32m[04/28 03:59:42 d2.evaluation.evaluator]: [0mInference done 1173/1257. 0.1150 s / img. ETA=0:00:09
[32m[04/28 03:59:47 d2.evaluation.evaluator]: [0mInference done 1216/1257. 0.1151 s / img. ETA=0:00:04
[32m[04/28 03:59:52 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.342300 (0.116887 s / img per device, on 1 devices)
[32m[04/28 03:59:52 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115076 s / img per device, on 1 devices)
[32m[04/28 03:59:52 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 03:59:52 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 03:59:52 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.98s).
Accumulating evaluation results...
DONE (t=0.40s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.748
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.344
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.296
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.439
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.550
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.184
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.478
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.426
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.514
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602
[32m[04/28 03:59:56 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 38.695 | 74.791 | 34.415 | 29.579 | 43.882 | 55.033 |
[32m[04/28 03:59:56 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 43.380 | bicycle       | 19.923 | car            | 52.782 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  4  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 03:59:57 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 03:59:57 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 03:59:57 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 03:59:57 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 03:59:58 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 03:59:58 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 03:59:58 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 04:00:18 d2.utils.events]: [0m eta: 0:16:27  iter: 19  total_loss: 0.572  loss_cls: 0.176  loss_box_reg: 0.321  loss_rpn_cls: 0.012  loss_rpn_loc: 0.062  time: 1.0133  data_time: 0.0203  lr: 0.000100  max_mem: 5394M
[32m[04/28 04:00:38 d2.utils.events]: [0m eta: 0:16:07  iter: 39  total_loss: 0.623  loss_cls: 0.188  loss_box_reg: 0.353  loss_rpn_cls: 0.014  loss_rpn_loc: 0.054  time: 1.0109  data_time: 0.0074  lr: 0.000200  max_mem: 5394M
[32m[04/28 04:00:59 d2.utils.events]: [0m eta: 0:15:52  iter: 59  total_loss: 0.553  loss_cls: 0.169  loss_box_reg: 0.311  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0150  data_time: 0.0074  lr: 0.000300  max_mem: 5394M
[32m[04/28 04:01:19 d2.utils.events]: [0m eta: 0:15:36  iter: 79  total_loss: 0.634  loss_cls: 0.200  loss_box_reg: 0.353  loss_rpn_cls: 0.017  loss_rpn_loc: 0.056  time: 1.0180  data_time: 0.0075  lr: 0.000400  max_mem: 5394M
[32m[04/28 04:01:40 d2.utils.events]: [0m eta: 0:15:19  iter: 99  total_loss: 0.516  loss_cls: 0.159  loss_box_reg: 0.303  loss_rpn_cls: 0.011  loss_rpn_loc: 0.042  time: 1.0199  data_time: 0.0074  lr: 0.000500  max_mem: 5394M
[32m[04/28 04:02:01 d2.utils.events]: [0m eta: 0:15:06  iter: 119  total_loss: 0.607  loss_cls: 0.193  loss_box_reg: 0.342  loss_rpn_cls: 0.010  loss_rpn_loc: 0.048  time: 1.0220  data_time: 0.0075  lr: 0.000599  max_mem: 5394M
[32m[04/28 04:02:21 d2.utils.events]: [0m eta: 0:14:43  iter: 139  total_loss: 0.572  loss_cls: 0.174  loss_box_reg: 0.323  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 1.0224  data_time: 0.0077  lr: 0.000699  max_mem: 5394M
[32m[04/28 04:02:42 d2.utils.events]: [0m eta: 0:14:24  iter: 159  total_loss: 0.638  loss_cls: 0.191  loss_box_reg: 0.371  loss_rpn_cls: 0.011  loss_rpn_loc: 0.045  time: 1.0229  data_time: 0.0076  lr: 0.000799  max_mem: 5394M
[32m[04/28 04:03:03 d2.utils.events]: [0m eta: 0:14:11  iter: 179  total_loss: 0.459  loss_cls: 0.143  loss_box_reg: 0.260  loss_rpn_cls: 0.009  loss_rpn_loc: 0.047  time: 1.0247  data_time: 0.0077  lr: 0.000899  max_mem: 5394M
[32m[04/28 04:03:24 d2.utils.events]: [0m eta: 0:13:54  iter: 199  total_loss: 0.536  loss_cls: 0.169  loss_box_reg: 0.309  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 1.0268  data_time: 0.0076  lr: 0.000999  max_mem: 5394M
[32m[04/28 04:03:44 d2.utils.events]: [0m eta: 0:13:33  iter: 219  total_loss: 0.504  loss_cls: 0.152  loss_box_reg: 0.293  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 1.0274  data_time: 0.0075  lr: 0.001099  max_mem: 5394M
[32m[04/28 04:04:04 d2.utils.events]: [0m eta: 0:13:10  iter: 239  total_loss: 0.514  loss_cls: 0.167  loss_box_reg: 0.302  loss_rpn_cls: 0.009  loss_rpn_loc: 0.048  time: 1.0238  data_time: 0.0075  lr: 0.001199  max_mem: 5394M
[32m[04/28 04:04:25 d2.utils.events]: [0m eta: 0:12:49  iter: 259  total_loss: 0.573  loss_cls: 0.175  loss_box_reg: 0.340  loss_rpn_cls: 0.010  loss_rpn_loc: 0.051  time: 1.0255  data_time: 0.0076  lr: 0.001299  max_mem: 5394M
[32m[04/28 04:04:45 d2.utils.events]: [0m eta: 0:12:27  iter: 279  total_loss: 0.636  loss_cls: 0.200  loss_box_reg: 0.360  loss_rpn_cls: 0.010  loss_rpn_loc: 0.053  time: 1.0238  data_time: 0.0074  lr: 0.001399  max_mem: 5394M
[32m[04/28 04:05:06 d2.utils.events]: [0m eta: 0:12:07  iter: 299  total_loss: 0.536  loss_cls: 0.160  loss_box_reg: 0.298  loss_rpn_cls: 0.009  loss_rpn_loc: 0.050  time: 1.0248  data_time: 0.0076  lr: 0.001499  max_mem: 5394M
[32m[04/28 04:05:27 d2.utils.events]: [0m eta: 0:11:47  iter: 319  total_loss: 0.548  loss_cls: 0.165  loss_box_reg: 0.325  loss_rpn_cls: 0.009  loss_rpn_loc: 0.047  time: 1.0255  data_time: 0.0076  lr: 0.001598  max_mem: 5394M
[32m[04/28 04:05:47 d2.utils.events]: [0m eta: 0:11:27  iter: 339  total_loss: 0.545  loss_cls: 0.172  loss_box_reg: 0.307  loss_rpn_cls: 0.008  loss_rpn_loc: 0.052  time: 1.0254  data_time: 0.0080  lr: 0.001698  max_mem: 5394M
[32m[04/28 04:06:08 d2.utils.events]: [0m eta: 0:11:06  iter: 359  total_loss: 0.648  loss_cls: 0.203  loss_box_reg: 0.372  loss_rpn_cls: 0.012  loss_rpn_loc: 0.054  time: 1.0264  data_time: 0.0075  lr: 0.001798  max_mem: 5394M
[32m[04/28 04:06:29 d2.utils.events]: [0m eta: 0:10:46  iter: 379  total_loss: 0.587  loss_cls: 0.194  loss_box_reg: 0.318  loss_rpn_cls: 0.013  loss_rpn_loc: 0.051  time: 1.0270  data_time: 0.0077  lr: 0.001898  max_mem: 5394M
[32m[04/28 04:06:50 d2.utils.events]: [0m eta: 0:10:25  iter: 399  total_loss: 0.628  loss_cls: 0.195  loss_box_reg: 0.342  loss_rpn_cls: 0.008  loss_rpn_loc: 0.048  time: 1.0277  data_time: 0.0076  lr: 0.001998  max_mem: 5394M
[32m[04/28 04:07:10 d2.utils.events]: [0m eta: 0:10:03  iter: 419  total_loss: 0.572  loss_cls: 0.173  loss_box_reg: 0.319  loss_rpn_cls: 0.011  loss_rpn_loc: 0.057  time: 1.0273  data_time: 0.0083  lr: 0.002098  max_mem: 5394M
[32m[04/28 04:07:31 d2.utils.events]: [0m eta: 0:09:42  iter: 439  total_loss: 0.505  loss_cls: 0.157  loss_box_reg: 0.282  loss_rpn_cls: 0.008  loss_rpn_loc: 0.046  time: 1.0277  data_time: 0.0073  lr: 0.002198  max_mem: 5394M
[32m[04/28 04:07:51 d2.utils.events]: [0m eta: 0:09:21  iter: 459  total_loss: 0.564  loss_cls: 0.181  loss_box_reg: 0.293  loss_rpn_cls: 0.010  loss_rpn_loc: 0.046  time: 1.0269  data_time: 0.0077  lr: 0.002298  max_mem: 5394M
[32m[04/28 04:08:12 d2.utils.events]: [0m eta: 0:09:00  iter: 479  total_loss: 0.506  loss_cls: 0.159  loss_box_reg: 0.286  loss_rpn_cls: 0.011  loss_rpn_loc: 0.037  time: 1.0271  data_time: 0.0076  lr: 0.002398  max_mem: 5394M
[32m[04/28 04:08:32 d2.utils.events]: [0m eta: 0:08:38  iter: 499  total_loss: 0.570  loss_cls: 0.169  loss_box_reg: 0.330  loss_rpn_cls: 0.011  loss_rpn_loc: 0.053  time: 1.0258  data_time: 0.0077  lr: 0.002498  max_mem: 5394M
[32m[04/28 04:08:53 d2.utils.events]: [0m eta: 0:08:18  iter: 519  total_loss: 0.535  loss_cls: 0.165  loss_box_reg: 0.308  loss_rpn_cls: 0.011  loss_rpn_loc: 0.044  time: 1.0263  data_time: 0.0075  lr: 0.002597  max_mem: 5394M
[32m[04/28 04:09:13 d2.utils.events]: [0m eta: 0:07:57  iter: 539  total_loss: 0.512  loss_cls: 0.166  loss_box_reg: 0.299  loss_rpn_cls: 0.008  loss_rpn_loc: 0.042  time: 1.0266  data_time: 0.0074  lr: 0.002697  max_mem: 5394M
[32m[04/28 04:09:34 d2.utils.events]: [0m eta: 0:07:37  iter: 559  total_loss: 0.594  loss_cls: 0.199  loss_box_reg: 0.326  loss_rpn_cls: 0.012  loss_rpn_loc: 0.055  time: 1.0271  data_time: 0.0076  lr: 0.002797  max_mem: 5394M
[32m[04/28 04:09:55 d2.utils.events]: [0m eta: 0:07:16  iter: 579  total_loss: 0.541  loss_cls: 0.168  loss_box_reg: 0.305  loss_rpn_cls: 0.010  loss_rpn_loc: 0.048  time: 1.0275  data_time: 0.0075  lr: 0.002897  max_mem: 5394M
[32m[04/28 04:10:16 d2.utils.events]: [0m eta: 0:06:56  iter: 599  total_loss: 0.567  loss_cls: 0.183  loss_box_reg: 0.318  loss_rpn_cls: 0.008  loss_rpn_loc: 0.061  time: 1.0278  data_time: 0.0075  lr: 0.002997  max_mem: 5394M
[32m[04/28 04:10:37 d2.utils.events]: [0m eta: 0:06:35  iter: 619  total_loss: 0.553  loss_cls: 0.187  loss_box_reg: 0.335  loss_rpn_cls: 0.014  loss_rpn_loc: 0.062  time: 1.0284  data_time: 0.0074  lr: 0.003097  max_mem: 5394M
[32m[04/28 04:10:58 d2.utils.events]: [0m eta: 0:06:14  iter: 639  total_loss: 0.543  loss_cls: 0.178  loss_box_reg: 0.318  loss_rpn_cls: 0.012  loss_rpn_loc: 0.047  time: 1.0288  data_time: 0.0074  lr: 0.003197  max_mem: 5394M
[32m[04/28 04:11:19 d2.utils.events]: [0m eta: 0:05:54  iter: 659  total_loss: 0.584  loss_cls: 0.180  loss_box_reg: 0.334  loss_rpn_cls: 0.013  loss_rpn_loc: 0.057  time: 1.0291  data_time: 0.0076  lr: 0.003297  max_mem: 5394M
[32m[04/28 04:11:39 d2.utils.events]: [0m eta: 0:05:33  iter: 679  total_loss: 0.635  loss_cls: 0.198  loss_box_reg: 0.365  loss_rpn_cls: 0.015  loss_rpn_loc: 0.050  time: 1.0289  data_time: 0.0076  lr: 0.003397  max_mem: 5394M
[32m[04/28 04:12:00 d2.utils.events]: [0m eta: 0:05:12  iter: 699  total_loss: 0.531  loss_cls: 0.162  loss_box_reg: 0.315  loss_rpn_cls: 0.009  loss_rpn_loc: 0.050  time: 1.0288  data_time: 0.0078  lr: 0.003497  max_mem: 5394M
[32m[04/28 04:12:20 d2.utils.events]: [0m eta: 0:04:51  iter: 719  total_loss: 0.578  loss_cls: 0.170  loss_box_reg: 0.319  loss_rpn_cls: 0.013  loss_rpn_loc: 0.058  time: 1.0284  data_time: 0.0075  lr: 0.003596  max_mem: 5394M
[32m[04/28 04:12:40 d2.utils.events]: [0m eta: 0:04:30  iter: 739  total_loss: 0.627  loss_cls: 0.182  loss_box_reg: 0.346  loss_rpn_cls: 0.014  loss_rpn_loc: 0.057  time: 1.0280  data_time: 0.0077  lr: 0.003696  max_mem: 5394M
[32m[04/28 04:13:00 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.595  loss_cls: 0.180  loss_box_reg: 0.349  loss_rpn_cls: 0.012  loss_rpn_loc: 0.047  time: 1.0274  data_time: 0.0074  lr: 0.003796  max_mem: 5394M
[32m[04/28 04:13:21 d2.utils.events]: [0m eta: 0:03:49  iter: 779  total_loss: 0.534  loss_cls: 0.155  loss_box_reg: 0.308  loss_rpn_cls: 0.013  loss_rpn_loc: 0.052  time: 1.0271  data_time: 0.0075  lr: 0.003896  max_mem: 5394M
[32m[04/28 04:13:41 d2.utils.events]: [0m eta: 0:03:28  iter: 799  total_loss: 0.522  loss_cls: 0.163  loss_box_reg: 0.316  loss_rpn_cls: 0.012  loss_rpn_loc: 0.049  time: 1.0267  data_time: 0.0076  lr: 0.003996  max_mem: 5394M
[32m[04/28 04:14:02 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.608  loss_cls: 0.194  loss_box_reg: 0.351  loss_rpn_cls: 0.010  loss_rpn_loc: 0.043  time: 1.0274  data_time: 0.0078  lr: 0.004096  max_mem: 5394M
[32m[04/28 04:14:23 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.522  loss_cls: 0.173  loss_box_reg: 0.313  loss_rpn_cls: 0.009  loss_rpn_loc: 0.048  time: 1.0272  data_time: 0.0075  lr: 0.004196  max_mem: 5394M
[32m[04/28 04:14:43 d2.utils.events]: [0m eta: 0:02:26  iter: 859  total_loss: 0.611  loss_cls: 0.199  loss_box_reg: 0.341  loss_rpn_cls: 0.011  loss_rpn_loc: 0.055  time: 1.0271  data_time: 0.0075  lr: 0.004296  max_mem: 5394M
[32m[04/28 04:15:03 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.569  loss_cls: 0.180  loss_box_reg: 0.328  loss_rpn_cls: 0.009  loss_rpn_loc: 0.053  time: 1.0262  data_time: 0.0074  lr: 0.004396  max_mem: 5394M
[32m[04/28 04:15:23 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.634  loss_cls: 0.190  loss_box_reg: 0.347  loss_rpn_cls: 0.012  loss_rpn_loc: 0.054  time: 1.0260  data_time: 0.0074  lr: 0.004496  max_mem: 5394M
[32m[04/28 04:15:44 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.570  loss_cls: 0.176  loss_box_reg: 0.321  loss_rpn_cls: 0.013  loss_rpn_loc: 0.058  time: 1.0261  data_time: 0.0082  lr: 0.004595  max_mem: 5394M
[32m[04/28 04:16:05 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.481  loss_cls: 0.152  loss_box_reg: 0.281  loss_rpn_cls: 0.011  loss_rpn_loc: 0.044  time: 1.0262  data_time: 0.0077  lr: 0.004695  max_mem: 5394M
[32m[04/28 04:16:26 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.576  loss_cls: 0.177  loss_box_reg: 0.325  loss_rpn_cls: 0.011  loss_rpn_loc: 0.060  time: 1.0268  data_time: 0.0075  lr: 0.004795  max_mem: 5394M
[32m[04/28 04:16:46 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.600  loss_cls: 0.187  loss_box_reg: 0.352  loss_rpn_cls: 0.013  loss_rpn_loc: 0.065  time: 1.0268  data_time: 0.0072  lr: 0.004895  max_mem: 5394M
[5m[31mWARNING[0m [32m[04/28 04:17:09 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 04:17:09 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 04:17:09 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 04:17:09 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.558  loss_cls: 0.177  loss_box_reg: 0.312  loss_rpn_cls: 0.015  loss_rpn_loc: 0.056  time: 1.0265  data_time: 0.0077  lr: 0.004995  max_mem: 5394M
[32m[04/28 04:17:10 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:04 (1.0275 s / it)
[32m[04/28 04:17:10 d2.engine.hooks]: [0mTotal training time: 0:17:09 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 04:17:11 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 04:17:11 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 04:17:11 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 04:17:13 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1139 s / img. ETA=0:16:01
[32m[04/28 04:17:18 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1137 s / img. ETA=0:15:57
[32m[04/28 04:17:23 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1137 s / img. ETA=0:15:51
[32m[04/28 04:17:28 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1137 s / img. ETA=0:15:47
[32m[04/28 04:17:33 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1137 s / img. ETA=0:15:42
[32m[04/28 04:17:38 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1137 s / img. ETA=0:15:37
[32m[04/28 04:17:43 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1138 s / img. ETA=0:15:32
[32m[04/28 04:17:48 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1138 s / img. ETA=0:15:27
[32m[04/28 04:17:53 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1138 s / img. ETA=0:15:22
[32m[04/28 04:17:59 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1138 s / img. ETA=0:15:18
[32m[04/28 04:18:04 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1139 s / img. ETA=0:15:13
[32m[04/28 04:18:09 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1138 s / img. ETA=0:15:07
[32m[04/28 04:18:14 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1139 s / img. ETA=0:15:03
[32m[04/28 04:18:19 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1139 s / img. ETA=0:14:58
[32m[04/28 04:18:24 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1139 s / img. ETA=0:14:53
[32m[04/28 04:18:29 d2.evaluation.evaluator]: [0mInference done 671/8355. 0.1140 s / img. ETA=0:14:48
[32m[04/28 04:18:34 d2.evaluation.evaluator]: [0mInference done 715/8355. 0.1140 s / img. ETA=0:14:43
[32m[04/28 04:18:39 d2.evaluation.evaluator]: [0mInference done 758/8355. 0.1140 s / img. ETA=0:14:38
[32m[04/28 04:18:44 d2.evaluation.evaluator]: [0mInference done 801/8355. 0.1141 s / img. ETA=0:14:34
[32m[04/28 04:18:49 d2.evaluation.evaluator]: [0mInference done 845/8355. 0.1140 s / img. ETA=0:14:29
[32m[04/28 04:18:54 d2.evaluation.evaluator]: [0mInference done 888/8355. 0.1141 s / img. ETA=0:14:24
[32m[04/28 04:18:59 d2.evaluation.evaluator]: [0mInference done 931/8355. 0.1141 s / img. ETA=0:14:19
[32m[04/28 04:19:04 d2.evaluation.evaluator]: [0mInference done 975/8355. 0.1141 s / img. ETA=0:14:14
[32m[04/28 04:19:09 d2.evaluation.evaluator]: [0mInference done 1018/8355. 0.1142 s / img. ETA=0:14:10
[32m[04/28 04:19:15 d2.evaluation.evaluator]: [0mInference done 1062/8355. 0.1142 s / img. ETA=0:14:04
[32m[04/28 04:19:20 d2.evaluation.evaluator]: [0mInference done 1106/8355. 0.1142 s / img. ETA=0:13:59
[32m[04/28 04:19:25 d2.evaluation.evaluator]: [0mInference done 1150/8355. 0.1141 s / img. ETA=0:13:54
[32m[04/28 04:19:30 d2.evaluation.evaluator]: [0mInference done 1194/8355. 0.1141 s / img. ETA=0:13:49
[32m[04/28 04:19:35 d2.evaluation.evaluator]: [0mInference done 1238/8355. 0.1141 s / img. ETA=0:13:44
[32m[04/28 04:19:40 d2.evaluation.evaluator]: [0mInference done 1282/8355. 0.1141 s / img. ETA=0:13:39
[32m[04/28 04:19:45 d2.evaluation.evaluator]: [0mInference done 1326/8355. 0.1141 s / img. ETA=0:13:34
[32m[04/28 04:19:50 d2.evaluation.evaluator]: [0mInference done 1369/8355. 0.1141 s / img. ETA=0:13:29
[32m[04/28 04:19:55 d2.evaluation.evaluator]: [0mInference done 1413/8355. 0.1141 s / img. ETA=0:13:24
[32m[04/28 04:20:00 d2.evaluation.evaluator]: [0mInference done 1456/8355. 0.1142 s / img. ETA=0:13:19
[32m[04/28 04:20:05 d2.evaluation.evaluator]: [0mInference done 1499/8355. 0.1142 s / img. ETA=0:13:14
[32m[04/28 04:20:10 d2.evaluation.evaluator]: [0mInference done 1542/8355. 0.1142 s / img. ETA=0:13:10
[32m[04/28 04:20:15 d2.evaluation.evaluator]: [0mInference done 1585/8355. 0.1143 s / img. ETA=0:13:05
[32m[04/28 04:20:20 d2.evaluation.evaluator]: [0mInference done 1628/8355. 0.1143 s / img. ETA=0:13:00
[32m[04/28 04:20:25 d2.evaluation.evaluator]: [0mInference done 1671/8355. 0.1144 s / img. ETA=0:12:55
[32m[04/28 04:20:31 d2.evaluation.evaluator]: [0mInference done 1714/8355. 0.1144 s / img. ETA=0:12:51
[32m[04/28 04:20:36 d2.evaluation.evaluator]: [0mInference done 1757/8355. 0.1144 s / img. ETA=0:12:46
[32m[04/28 04:20:41 d2.evaluation.evaluator]: [0mInference done 1800/8355. 0.1144 s / img. ETA=0:12:41
[32m[04/28 04:20:46 d2.evaluation.evaluator]: [0mInference done 1843/8355. 0.1145 s / img. ETA=0:12:36
[32m[04/28 04:20:51 d2.evaluation.evaluator]: [0mInference done 1886/8355. 0.1145 s / img. ETA=0:12:32
[32m[04/28 04:20:56 d2.evaluation.evaluator]: [0mInference done 1929/8355. 0.1145 s / img. ETA=0:12:27
[32m[04/28 04:21:01 d2.evaluation.evaluator]: [0mInference done 1972/8355. 0.1145 s / img. ETA=0:12:22
[32m[04/28 04:21:06 d2.evaluation.evaluator]: [0mInference done 2015/8355. 0.1145 s / img. ETA=0:12:17
[32m[04/28 04:21:11 d2.evaluation.evaluator]: [0mInference done 2058/8355. 0.1146 s / img. ETA=0:12:12
[32m[04/28 04:21:16 d2.evaluation.evaluator]: [0mInference done 2101/8355. 0.1146 s / img. ETA=0:12:07
[32m[04/28 04:21:21 d2.evaluation.evaluator]: [0mInference done 2145/8355. 0.1146 s / img. ETA=0:12:02
[32m[04/28 04:21:26 d2.evaluation.evaluator]: [0mInference done 2188/8355. 0.1146 s / img. ETA=0:11:57
[32m[04/28 04:21:31 d2.evaluation.evaluator]: [0mInference done 2231/8355. 0.1146 s / img. ETA=0:11:52
[32m[04/28 04:21:36 d2.evaluation.evaluator]: [0mInference done 2274/8355. 0.1146 s / img. ETA=0:11:47
[32m[04/28 04:21:41 d2.evaluation.evaluator]: [0mInference done 2317/8355. 0.1146 s / img. ETA=0:11:42
[32m[04/28 04:21:46 d2.evaluation.evaluator]: [0mInference done 2360/8355. 0.1146 s / img. ETA=0:11:37
[32m[04/28 04:21:51 d2.evaluation.evaluator]: [0mInference done 2403/8355. 0.1146 s / img. ETA=0:11:32
[32m[04/28 04:21:56 d2.evaluation.evaluator]: [0mInference done 2446/8355. 0.1147 s / img. ETA=0:11:27
[32m[04/28 04:22:01 d2.evaluation.evaluator]: [0mInference done 2489/8355. 0.1147 s / img. ETA=0:11:22
[32m[04/28 04:22:06 d2.evaluation.evaluator]: [0mInference done 2532/8355. 0.1147 s / img. ETA=0:11:18
[32m[04/28 04:22:11 d2.evaluation.evaluator]: [0mInference done 2575/8355. 0.1147 s / img. ETA=0:11:13
[32m[04/28 04:22:16 d2.evaluation.evaluator]: [0mInference done 2618/8355. 0.1147 s / img. ETA=0:11:08
[32m[04/28 04:22:21 d2.evaluation.evaluator]: [0mInference done 2661/8355. 0.1147 s / img. ETA=0:11:03
[32m[04/28 04:22:26 d2.evaluation.evaluator]: [0mInference done 2704/8355. 0.1147 s / img. ETA=0:10:58
[32m[04/28 04:22:31 d2.evaluation.evaluator]: [0mInference done 2747/8355. 0.1147 s / img. ETA=0:10:53
[32m[04/28 04:22:36 d2.evaluation.evaluator]: [0mInference done 2790/8355. 0.1147 s / img. ETA=0:10:48
[32m[04/28 04:22:42 d2.evaluation.evaluator]: [0mInference done 2833/8355. 0.1147 s / img. ETA=0:10:43
[32m[04/28 04:22:47 d2.evaluation.evaluator]: [0mInference done 2876/8355. 0.1147 s / img. ETA=0:10:38
[32m[04/28 04:22:52 d2.evaluation.evaluator]: [0mInference done 2920/8355. 0.1147 s / img. ETA=0:10:33
[32m[04/28 04:22:57 d2.evaluation.evaluator]: [0mInference done 2963/8355. 0.1147 s / img. ETA=0:10:28
[32m[04/28 04:23:02 d2.evaluation.evaluator]: [0mInference done 3006/8355. 0.1147 s / img. ETA=0:10:23
[32m[04/28 04:23:07 d2.evaluation.evaluator]: [0mInference done 3049/8355. 0.1147 s / img. ETA=0:10:18
[32m[04/28 04:23:12 d2.evaluation.evaluator]: [0mInference done 3092/8355. 0.1147 s / img. ETA=0:10:13
[32m[04/28 04:23:17 d2.evaluation.evaluator]: [0mInference done 3135/8355. 0.1147 s / img. ETA=0:10:08
[32m[04/28 04:23:22 d2.evaluation.evaluator]: [0mInference done 3179/8355. 0.1147 s / img. ETA=0:10:02
[32m[04/28 04:23:27 d2.evaluation.evaluator]: [0mInference done 3223/8355. 0.1147 s / img. ETA=0:09:57
[32m[04/28 04:23:32 d2.evaluation.evaluator]: [0mInference done 3266/8355. 0.1147 s / img. ETA=0:09:52
[32m[04/28 04:23:37 d2.evaluation.evaluator]: [0mInference done 3310/8355. 0.1147 s / img. ETA=0:09:47
[32m[04/28 04:23:42 d2.evaluation.evaluator]: [0mInference done 3354/8355. 0.1147 s / img. ETA=0:09:42
[32m[04/28 04:23:47 d2.evaluation.evaluator]: [0mInference done 3398/8355. 0.1147 s / img. ETA=0:09:37
[32m[04/28 04:23:52 d2.evaluation.evaluator]: [0mInference done 3442/8355. 0.1147 s / img. ETA=0:09:32
[32m[04/28 04:23:57 d2.evaluation.evaluator]: [0mInference done 3485/8355. 0.1147 s / img. ETA=0:09:27
[32m[04/28 04:24:02 d2.evaluation.evaluator]: [0mInference done 3529/8355. 0.1147 s / img. ETA=0:09:21
[32m[04/28 04:24:08 d2.evaluation.evaluator]: [0mInference done 3573/8355. 0.1147 s / img. ETA=0:09:16
[32m[04/28 04:24:13 d2.evaluation.evaluator]: [0mInference done 3617/8355. 0.1147 s / img. ETA=0:09:11
[32m[04/28 04:24:18 d2.evaluation.evaluator]: [0mInference done 3661/8355. 0.1147 s / img. ETA=0:09:06
[32m[04/28 04:24:23 d2.evaluation.evaluator]: [0mInference done 3705/8355. 0.1147 s / img. ETA=0:09:01
[32m[04/28 04:24:28 d2.evaluation.evaluator]: [0mInference done 3749/8355. 0.1147 s / img. ETA=0:08:56
[32m[04/28 04:24:33 d2.evaluation.evaluator]: [0mInference done 3793/8355. 0.1147 s / img. ETA=0:08:51
[32m[04/28 04:24:38 d2.evaluation.evaluator]: [0mInference done 3836/8355. 0.1147 s / img. ETA=0:08:46
[32m[04/28 04:24:43 d2.evaluation.evaluator]: [0mInference done 3880/8355. 0.1147 s / img. ETA=0:08:40
[32m[04/28 04:24:48 d2.evaluation.evaluator]: [0mInference done 3924/8355. 0.1146 s / img. ETA=0:08:35
[32m[04/28 04:24:53 d2.evaluation.evaluator]: [0mInference done 3968/8355. 0.1146 s / img. ETA=0:08:30
[32m[04/28 04:24:58 d2.evaluation.evaluator]: [0mInference done 4011/8355. 0.1146 s / img. ETA=0:08:25
[32m[04/28 04:25:03 d2.evaluation.evaluator]: [0mInference done 4054/8355. 0.1146 s / img. ETA=0:08:20
[32m[04/28 04:25:08 d2.evaluation.evaluator]: [0mInference done 4097/8355. 0.1146 s / img. ETA=0:08:15
[32m[04/28 04:25:13 d2.evaluation.evaluator]: [0mInference done 4140/8355. 0.1146 s / img. ETA=0:08:10
[32m[04/28 04:25:18 d2.evaluation.evaluator]: [0mInference done 4183/8355. 0.1147 s / img. ETA=0:08:05
[32m[04/28 04:25:24 d2.evaluation.evaluator]: [0mInference done 4227/8355. 0.1146 s / img. ETA=0:08:00
[32m[04/28 04:25:29 d2.evaluation.evaluator]: [0mInference done 4271/8355. 0.1146 s / img. ETA=0:07:55
[32m[04/28 04:25:34 d2.evaluation.evaluator]: [0mInference done 4314/8355. 0.1146 s / img. ETA=0:07:50
[32m[04/28 04:25:39 d2.evaluation.evaluator]: [0mInference done 4358/8355. 0.1146 s / img. ETA=0:07:45
[32m[04/28 04:25:44 d2.evaluation.evaluator]: [0mInference done 4401/8355. 0.1146 s / img. ETA=0:07:40
[32m[04/28 04:25:49 d2.evaluation.evaluator]: [0mInference done 4444/8355. 0.1146 s / img. ETA=0:07:35
[32m[04/28 04:25:54 d2.evaluation.evaluator]: [0mInference done 4488/8355. 0.1146 s / img. ETA=0:07:30
[32m[04/28 04:25:59 d2.evaluation.evaluator]: [0mInference done 4531/8355. 0.1146 s / img. ETA=0:07:25
[32m[04/28 04:26:04 d2.evaluation.evaluator]: [0mInference done 4574/8355. 0.1147 s / img. ETA=0:07:20
[32m[04/28 04:26:09 d2.evaluation.evaluator]: [0mInference done 4617/8355. 0.1147 s / img. ETA=0:07:15
[32m[04/28 04:26:14 d2.evaluation.evaluator]: [0mInference done 4660/8355. 0.1147 s / img. ETA=0:07:10
[32m[04/28 04:26:19 d2.evaluation.evaluator]: [0mInference done 4703/8355. 0.1147 s / img. ETA=0:07:05
[32m[04/28 04:26:24 d2.evaluation.evaluator]: [0mInference done 4746/8355. 0.1147 s / img. ETA=0:07:00
[32m[04/28 04:26:29 d2.evaluation.evaluator]: [0mInference done 4789/8355. 0.1147 s / img. ETA=0:06:55
[32m[04/28 04:26:34 d2.evaluation.evaluator]: [0mInference done 4832/8355. 0.1147 s / img. ETA=0:06:50
[32m[04/28 04:26:39 d2.evaluation.evaluator]: [0mInference done 4875/8355. 0.1147 s / img. ETA=0:06:45
[32m[04/28 04:26:44 d2.evaluation.evaluator]: [0mInference done 4918/8355. 0.1147 s / img. ETA=0:06:40
[32m[04/28 04:26:49 d2.evaluation.evaluator]: [0mInference done 4961/8355. 0.1147 s / img. ETA=0:06:35
[32m[04/28 04:26:54 d2.evaluation.evaluator]: [0mInference done 5004/8355. 0.1147 s / img. ETA=0:06:30
[32m[04/28 04:26:59 d2.evaluation.evaluator]: [0mInference done 5047/8355. 0.1147 s / img. ETA=0:06:25
[32m[04/28 04:27:04 d2.evaluation.evaluator]: [0mInference done 5090/8355. 0.1147 s / img. ETA=0:06:20
[32m[04/28 04:27:09 d2.evaluation.evaluator]: [0mInference done 5133/8355. 0.1147 s / img. ETA=0:06:15
[32m[04/28 04:27:14 d2.evaluation.evaluator]: [0mInference done 5176/8355. 0.1147 s / img. ETA=0:06:10
[32m[04/28 04:27:19 d2.evaluation.evaluator]: [0mInference done 5219/8355. 0.1147 s / img. ETA=0:06:05
[32m[04/28 04:27:24 d2.evaluation.evaluator]: [0mInference done 5262/8355. 0.1147 s / img. ETA=0:06:00
[32m[04/28 04:27:29 d2.evaluation.evaluator]: [0mInference done 5305/8355. 0.1147 s / img. ETA=0:05:55
[32m[04/28 04:27:34 d2.evaluation.evaluator]: [0mInference done 5348/8355. 0.1147 s / img. ETA=0:05:50
[32m[04/28 04:27:40 d2.evaluation.evaluator]: [0mInference done 5391/8355. 0.1147 s / img. ETA=0:05:45
[32m[04/28 04:27:45 d2.evaluation.evaluator]: [0mInference done 5434/8355. 0.1147 s / img. ETA=0:05:40
[32m[04/28 04:27:50 d2.evaluation.evaluator]: [0mInference done 5477/8355. 0.1147 s / img. ETA=0:05:35
[32m[04/28 04:27:55 d2.evaluation.evaluator]: [0mInference done 5520/8355. 0.1147 s / img. ETA=0:05:30
[32m[04/28 04:28:00 d2.evaluation.evaluator]: [0mInference done 5564/8355. 0.1147 s / img. ETA=0:05:25
[32m[04/28 04:28:05 d2.evaluation.evaluator]: [0mInference done 5607/8355. 0.1147 s / img. ETA=0:05:20
[32m[04/28 04:28:10 d2.evaluation.evaluator]: [0mInference done 5650/8355. 0.1147 s / img. ETA=0:05:15
[32m[04/28 04:28:15 d2.evaluation.evaluator]: [0mInference done 5693/8355. 0.1147 s / img. ETA=0:05:10
[32m[04/28 04:28:20 d2.evaluation.evaluator]: [0mInference done 5736/8355. 0.1147 s / img. ETA=0:05:05
[32m[04/28 04:28:25 d2.evaluation.evaluator]: [0mInference done 5779/8355. 0.1147 s / img. ETA=0:05:00
[32m[04/28 04:28:30 d2.evaluation.evaluator]: [0mInference done 5822/8355. 0.1147 s / img. ETA=0:04:55
[32m[04/28 04:28:35 d2.evaluation.evaluator]: [0mInference done 5864/8355. 0.1148 s / img. ETA=0:04:50
[32m[04/28 04:28:40 d2.evaluation.evaluator]: [0mInference done 5907/8355. 0.1148 s / img. ETA=0:04:45
[32m[04/28 04:28:45 d2.evaluation.evaluator]: [0mInference done 5950/8355. 0.1148 s / img. ETA=0:04:40
[32m[04/28 04:28:50 d2.evaluation.evaluator]: [0mInference done 5993/8355. 0.1148 s / img. ETA=0:04:35
[32m[04/28 04:28:55 d2.evaluation.evaluator]: [0mInference done 6036/8355. 0.1148 s / img. ETA=0:04:30
[32m[04/28 04:29:00 d2.evaluation.evaluator]: [0mInference done 6079/8355. 0.1148 s / img. ETA=0:04:25
[32m[04/28 04:29:05 d2.evaluation.evaluator]: [0mInference done 6122/8355. 0.1148 s / img. ETA=0:04:20
[32m[04/28 04:29:11 d2.evaluation.evaluator]: [0mInference done 6165/8355. 0.1148 s / img. ETA=0:04:15
[32m[04/28 04:29:16 d2.evaluation.evaluator]: [0mInference done 6208/8355. 0.1149 s / img. ETA=0:04:10
[32m[04/28 04:29:21 d2.evaluation.evaluator]: [0mInference done 6251/8355. 0.1149 s / img. ETA=0:04:05
[32m[04/28 04:29:26 d2.evaluation.evaluator]: [0mInference done 6293/8355. 0.1149 s / img. ETA=0:04:00
[32m[04/28 04:29:31 d2.evaluation.evaluator]: [0mInference done 6336/8355. 0.1149 s / img. ETA=0:03:55
[32m[04/28 04:29:36 d2.evaluation.evaluator]: [0mInference done 6379/8355. 0.1149 s / img. ETA=0:03:50
[32m[04/28 04:29:41 d2.evaluation.evaluator]: [0mInference done 6422/8355. 0.1149 s / img. ETA=0:03:45
[32m[04/28 04:29:46 d2.evaluation.evaluator]: [0mInference done 6465/8355. 0.1149 s / img. ETA=0:03:40
[32m[04/28 04:29:51 d2.evaluation.evaluator]: [0mInference done 6508/8355. 0.1149 s / img. ETA=0:03:35
[32m[04/28 04:29:56 d2.evaluation.evaluator]: [0mInference done 6551/8355. 0.1149 s / img. ETA=0:03:30
[32m[04/28 04:30:01 d2.evaluation.evaluator]: [0mInference done 6594/8355. 0.1149 s / img. ETA=0:03:25
[32m[04/28 04:30:06 d2.evaluation.evaluator]: [0mInference done 6637/8355. 0.1149 s / img. ETA=0:03:20
[32m[04/28 04:30:11 d2.evaluation.evaluator]: [0mInference done 6681/8355. 0.1149 s / img. ETA=0:03:15
[32m[04/28 04:30:16 d2.evaluation.evaluator]: [0mInference done 6724/8355. 0.1149 s / img. ETA=0:03:10
[32m[04/28 04:30:21 d2.evaluation.evaluator]: [0mInference done 6767/8355. 0.1149 s / img. ETA=0:03:05
[32m[04/28 04:30:26 d2.evaluation.evaluator]: [0mInference done 6810/8355. 0.1149 s / img. ETA=0:03:00
[32m[04/28 04:30:31 d2.evaluation.evaluator]: [0mInference done 6853/8355. 0.1149 s / img. ETA=0:02:55
[32m[04/28 04:30:36 d2.evaluation.evaluator]: [0mInference done 6896/8355. 0.1149 s / img. ETA=0:02:50
[32m[04/28 04:30:41 d2.evaluation.evaluator]: [0mInference done 6939/8355. 0.1149 s / img. ETA=0:02:45
[32m[04/28 04:30:47 d2.evaluation.evaluator]: [0mInference done 6982/8355. 0.1149 s / img. ETA=0:02:40
[32m[04/28 04:30:52 d2.evaluation.evaluator]: [0mInference done 7025/8355. 0.1149 s / img. ETA=0:02:35
[32m[04/28 04:30:57 d2.evaluation.evaluator]: [0mInference done 7068/8355. 0.1149 s / img. ETA=0:02:30
[32m[04/28 04:31:02 d2.evaluation.evaluator]: [0mInference done 7110/8355. 0.1150 s / img. ETA=0:02:25
[32m[04/28 04:31:07 d2.evaluation.evaluator]: [0mInference done 7152/8355. 0.1150 s / img. ETA=0:02:20
[32m[04/28 04:31:12 d2.evaluation.evaluator]: [0mInference done 7195/8355. 0.1150 s / img. ETA=0:02:15
[32m[04/28 04:31:17 d2.evaluation.evaluator]: [0mInference done 7238/8355. 0.1150 s / img. ETA=0:02:10
[32m[04/28 04:31:22 d2.evaluation.evaluator]: [0mInference done 7281/8355. 0.1150 s / img. ETA=0:02:05
[32m[04/28 04:31:27 d2.evaluation.evaluator]: [0mInference done 7324/8355. 0.1150 s / img. ETA=0:02:00
[32m[04/28 04:31:32 d2.evaluation.evaluator]: [0mInference done 7367/8355. 0.1150 s / img. ETA=0:01:55
[32m[04/28 04:31:37 d2.evaluation.evaluator]: [0mInference done 7410/8355. 0.1150 s / img. ETA=0:01:50
[32m[04/28 04:31:42 d2.evaluation.evaluator]: [0mInference done 7452/8355. 0.1150 s / img. ETA=0:01:45
[32m[04/28 04:31:47 d2.evaluation.evaluator]: [0mInference done 7495/8355. 0.1151 s / img. ETA=0:01:40
[32m[04/28 04:31:52 d2.evaluation.evaluator]: [0mInference done 7538/8355. 0.1151 s / img. ETA=0:01:35
[32m[04/28 04:31:57 d2.evaluation.evaluator]: [0mInference done 7581/8355. 0.1151 s / img. ETA=0:01:30
[32m[04/28 04:32:03 d2.evaluation.evaluator]: [0mInference done 7624/8355. 0.1151 s / img. ETA=0:01:25
[32m[04/28 04:32:08 d2.evaluation.evaluator]: [0mInference done 7667/8355. 0.1151 s / img. ETA=0:01:20
[32m[04/28 04:32:13 d2.evaluation.evaluator]: [0mInference done 7710/8355. 0.1151 s / img. ETA=0:01:15
[32m[04/28 04:32:18 d2.evaluation.evaluator]: [0mInference done 7753/8355. 0.1151 s / img. ETA=0:01:10
[32m[04/28 04:32:23 d2.evaluation.evaluator]: [0mInference done 7796/8355. 0.1151 s / img. ETA=0:01:05
[32m[04/28 04:32:28 d2.evaluation.evaluator]: [0mInference done 7839/8355. 0.1151 s / img. ETA=0:01:00
[32m[04/28 04:32:33 d2.evaluation.evaluator]: [0mInference done 7882/8355. 0.1151 s / img. ETA=0:00:55
[32m[04/28 04:32:38 d2.evaluation.evaluator]: [0mInference done 7925/8355. 0.1151 s / img. ETA=0:00:50
[32m[04/28 04:32:43 d2.evaluation.evaluator]: [0mInference done 7968/8355. 0.1151 s / img. ETA=0:00:45
[32m[04/28 04:32:48 d2.evaluation.evaluator]: [0mInference done 8011/8355. 0.1151 s / img. ETA=0:00:40
[32m[04/28 04:32:53 d2.evaluation.evaluator]: [0mInference done 8054/8355. 0.1151 s / img. ETA=0:00:35
[32m[04/28 04:32:58 d2.evaluation.evaluator]: [0mInference done 8097/8355. 0.1151 s / img. ETA=0:00:30
[32m[04/28 04:33:03 d2.evaluation.evaluator]: [0mInference done 8140/8355. 0.1151 s / img. ETA=0:00:25
[32m[04/28 04:33:08 d2.evaluation.evaluator]: [0mInference done 8183/8355. 0.1151 s / img. ETA=0:00:20
[32m[04/28 04:33:13 d2.evaluation.evaluator]: [0mInference done 8226/8355. 0.1151 s / img. ETA=0:00:15
[32m[04/28 04:33:18 d2.evaluation.evaluator]: [0mInference done 8269/8355. 0.1151 s / img. ETA=0:00:10
[32m[04/28 04:33:24 d2.evaluation.evaluator]: [0mInference done 8312/8355. 0.1151 s / img. ETA=0:00:05
[32m[04/28 04:33:29 d2.evaluation.evaluator]: [0mInference done 8355/8355. 0.1151 s / img. ETA=0:00:00
[32m[04/28 04:33:29 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:16.496445 (0.116946 s / img per device, on 1 devices)
[32m[04/28 04:33:29 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:01 (0.115141 s / img per device, on 1 devices)
[32m[04/28 04:33:29 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 04:33:29 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 04:33:29 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.98s).
Accumulating evaluation results...
DONE (t=2.22s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.434
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.778
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.423
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.323
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.565
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.694
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.168
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.481
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.393
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.743
[32m[04/28 04:33:52 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.368 | 77.774 | 42.254 | 32.338 | 56.530 | 69.442 |
[32m[04/28 04:33:52 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 44.193 | bicycle       | 33.150 | car            | 52.762 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 04:33:52 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 04:33:52 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 04:33:52 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 04:33:54 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1147 s / img. ETA=0:02:25
[32m[04/28 04:33:59 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1147 s / img. ETA=0:02:20
[32m[04/28 04:34:04 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1147 s / img. ETA=0:02:15
[32m[04/28 04:34:09 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1147 s / img. ETA=0:02:10
[32m[04/28 04:34:14 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1147 s / img. ETA=0:02:05
[32m[04/28 04:34:19 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1147 s / img. ETA=0:02:00
[32m[04/28 04:34:24 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1148 s / img. ETA=0:01:55
[32m[04/28 04:34:29 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1148 s / img. ETA=0:01:50
[32m[04/28 04:34:34 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1148 s / img. ETA=0:01:45
[32m[04/28 04:34:39 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1148 s / img. ETA=0:01:40
[32m[04/28 04:34:44 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1147 s / img. ETA=0:01:35
[32m[04/28 04:34:49 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1147 s / img. ETA=0:01:30
[32m[04/28 04:34:54 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1147 s / img. ETA=0:01:25
[32m[04/28 04:34:59 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1148 s / img. ETA=0:01:20
[32m[04/28 04:35:04 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1148 s / img. ETA=0:01:15
[32m[04/28 04:35:09 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1148 s / img. ETA=0:01:10
[32m[04/28 04:35:14 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1148 s / img. ETA=0:01:05
[32m[04/28 04:35:19 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1148 s / img. ETA=0:01:00
[32m[04/28 04:35:24 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1148 s / img. ETA=0:00:55
[32m[04/28 04:35:29 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1149 s / img. ETA=0:00:50
[32m[04/28 04:35:34 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1149 s / img. ETA=0:00:45
[32m[04/28 04:35:39 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1149 s / img. ETA=0:00:40
[32m[04/28 04:35:44 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1150 s / img. ETA=0:00:35
[32m[04/28 04:35:49 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1151 s / img. ETA=0:00:30
[32m[04/28 04:35:54 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1151 s / img. ETA=0:00:25
[32m[04/28 04:35:59 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1151 s / img. ETA=0:00:20
[32m[04/28 04:36:04 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1151 s / img. ETA=0:00:14
[32m[04/28 04:36:09 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1152 s / img. ETA=0:00:09
[32m[04/28 04:36:15 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1152 s / img. ETA=0:00:04
[32m[04/28 04:36:20 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.600363 (0.117093 s / img per device, on 1 devices)
[32m[04/28 04:36:20 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115191 s / img per device, on 1 devices)
[32m[04/28 04:36:20 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 04:36:20 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 04:36:20 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.04s).
Accumulating evaluation results...
DONE (t=0.66s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.403
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.749
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.389
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.290
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.572
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.186
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.465
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.373
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.534
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.635
[32m[04/28 04:36:23 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.305 | 74.907 | 38.868 | 28.970 | 46.896 | 57.173 |
[32m[04/28 04:36:23 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 44.003 | bicycle       | 23.110 | car            | 53.801 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  5  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 04:36:24 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 04:36:24 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 04:36:24 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 04:36:25 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 04:36:25 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 04:36:25 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 04:36:25 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 04:36:46 d2.utils.events]: [0m eta: 0:17:00  iter: 19  total_loss: 0.582  loss_cls: 0.181  loss_box_reg: 0.329  loss_rpn_cls: 0.014  loss_rpn_loc: 0.059  time: 1.0221  data_time: 0.0248  lr: 0.000100  max_mem: 5394M
[32m[04/28 04:37:06 d2.utils.events]: [0m eta: 0:16:16  iter: 39  total_loss: 0.538  loss_cls: 0.175  loss_box_reg: 0.333  loss_rpn_cls: 0.010  loss_rpn_loc: 0.049  time: 1.0134  data_time: 0.0079  lr: 0.000200  max_mem: 5394M
[32m[04/28 04:37:27 d2.utils.events]: [0m eta: 0:16:07  iter: 59  total_loss: 0.585  loss_cls: 0.194  loss_box_reg: 0.313  loss_rpn_cls: 0.014  loss_rpn_loc: 0.056  time: 1.0217  data_time: 0.0080  lr: 0.000300  max_mem: 5394M
[32m[04/28 04:37:48 d2.utils.events]: [0m eta: 0:15:53  iter: 79  total_loss: 0.566  loss_cls: 0.181  loss_box_reg: 0.337  loss_rpn_cls: 0.012  loss_rpn_loc: 0.044  time: 1.0274  data_time: 0.0081  lr: 0.000400  max_mem: 5394M
[32m[04/28 04:38:09 d2.utils.events]: [0m eta: 0:15:39  iter: 99  total_loss: 0.533  loss_cls: 0.170  loss_box_reg: 0.306  loss_rpn_cls: 0.010  loss_rpn_loc: 0.049  time: 1.0303  data_time: 0.0078  lr: 0.000500  max_mem: 5394M
[32m[04/28 04:38:29 d2.utils.events]: [0m eta: 0:15:10  iter: 119  total_loss: 0.541  loss_cls: 0.164  loss_box_reg: 0.322  loss_rpn_cls: 0.011  loss_rpn_loc: 0.042  time: 1.0268  data_time: 0.0079  lr: 0.000599  max_mem: 5394M
[32m[04/28 04:38:50 d2.utils.events]: [0m eta: 0:14:51  iter: 139  total_loss: 0.520  loss_cls: 0.163  loss_box_reg: 0.292  loss_rpn_cls: 0.009  loss_rpn_loc: 0.040  time: 1.0289  data_time: 0.0078  lr: 0.000699  max_mem: 5394M
[32m[04/28 04:39:10 d2.utils.events]: [0m eta: 0:14:36  iter: 159  total_loss: 0.487  loss_cls: 0.154  loss_box_reg: 0.279  loss_rpn_cls: 0.007  loss_rpn_loc: 0.041  time: 1.0302  data_time: 0.0078  lr: 0.000799  max_mem: 5394M
[32m[04/28 04:39:31 d2.utils.events]: [0m eta: 0:14:18  iter: 179  total_loss: 0.464  loss_cls: 0.144  loss_box_reg: 0.283  loss_rpn_cls: 0.006  loss_rpn_loc: 0.036  time: 1.0314  data_time: 0.0079  lr: 0.000899  max_mem: 5394M
[32m[04/28 04:39:52 d2.utils.events]: [0m eta: 0:13:57  iter: 199  total_loss: 0.453  loss_cls: 0.145  loss_box_reg: 0.276  loss_rpn_cls: 0.009  loss_rpn_loc: 0.039  time: 1.0324  data_time: 0.0079  lr: 0.000999  max_mem: 5394M
[32m[04/28 04:40:13 d2.utils.events]: [0m eta: 0:13:38  iter: 219  total_loss: 0.514  loss_cls: 0.160  loss_box_reg: 0.298  loss_rpn_cls: 0.008  loss_rpn_loc: 0.048  time: 1.0328  data_time: 0.0078  lr: 0.001099  max_mem: 5394M
[32m[04/28 04:40:34 d2.utils.events]: [0m eta: 0:13:17  iter: 239  total_loss: 0.534  loss_cls: 0.172  loss_box_reg: 0.311  loss_rpn_cls: 0.009  loss_rpn_loc: 0.042  time: 1.0340  data_time: 0.0076  lr: 0.001199  max_mem: 5394M
[32m[04/28 04:40:55 d2.utils.events]: [0m eta: 0:12:56  iter: 259  total_loss: 0.504  loss_cls: 0.141  loss_box_reg: 0.299  loss_rpn_cls: 0.008  loss_rpn_loc: 0.047  time: 1.0338  data_time: 0.0075  lr: 0.001299  max_mem: 5394M
[32m[04/28 04:41:15 d2.utils.events]: [0m eta: 0:12:33  iter: 279  total_loss: 0.563  loss_cls: 0.178  loss_box_reg: 0.321  loss_rpn_cls: 0.012  loss_rpn_loc: 0.052  time: 1.0325  data_time: 0.0077  lr: 0.001399  max_mem: 5394M
[32m[04/28 04:41:35 d2.utils.events]: [0m eta: 0:12:07  iter: 299  total_loss: 0.557  loss_cls: 0.177  loss_box_reg: 0.322  loss_rpn_cls: 0.010  loss_rpn_loc: 0.052  time: 1.0302  data_time: 0.0075  lr: 0.001499  max_mem: 5394M
[32m[04/28 04:41:56 d2.utils.events]: [0m eta: 0:11:45  iter: 319  total_loss: 0.588  loss_cls: 0.200  loss_box_reg: 0.334  loss_rpn_cls: 0.010  loss_rpn_loc: 0.052  time: 1.0298  data_time: 0.0080  lr: 0.001598  max_mem: 5394M
[32m[04/28 04:42:16 d2.utils.events]: [0m eta: 0:11:23  iter: 339  total_loss: 0.598  loss_cls: 0.192  loss_box_reg: 0.346  loss_rpn_cls: 0.008  loss_rpn_loc: 0.051  time: 1.0288  data_time: 0.0078  lr: 0.001698  max_mem: 5394M
[32m[04/28 04:42:36 d2.utils.events]: [0m eta: 0:11:01  iter: 359  total_loss: 0.513  loss_cls: 0.162  loss_box_reg: 0.290  loss_rpn_cls: 0.008  loss_rpn_loc: 0.049  time: 1.0265  data_time: 0.0075  lr: 0.001798  max_mem: 5394M
[32m[04/28 04:42:57 d2.utils.events]: [0m eta: 0:10:42  iter: 379  total_loss: 0.637  loss_cls: 0.187  loss_box_reg: 0.351  loss_rpn_cls: 0.011  loss_rpn_loc: 0.064  time: 1.0278  data_time: 0.0077  lr: 0.001898  max_mem: 5394M
[32m[04/28 04:43:17 d2.utils.events]: [0m eta: 0:10:22  iter: 399  total_loss: 0.508  loss_cls: 0.161  loss_box_reg: 0.288  loss_rpn_cls: 0.007  loss_rpn_loc: 0.051  time: 1.0277  data_time: 0.0077  lr: 0.001998  max_mem: 5394M
[32m[04/28 04:43:38 d2.utils.events]: [0m eta: 0:10:00  iter: 419  total_loss: 0.577  loss_cls: 0.186  loss_box_reg: 0.340  loss_rpn_cls: 0.010  loss_rpn_loc: 0.054  time: 1.0271  data_time: 0.0077  lr: 0.002098  max_mem: 5394M
[32m[04/28 04:43:58 d2.utils.events]: [0m eta: 0:09:39  iter: 439  total_loss: 0.579  loss_cls: 0.180  loss_box_reg: 0.331  loss_rpn_cls: 0.010  loss_rpn_loc: 0.049  time: 1.0268  data_time: 0.0078  lr: 0.002198  max_mem: 5394M
[32m[04/28 04:44:19 d2.utils.events]: [0m eta: 0:09:18  iter: 459  total_loss: 0.545  loss_cls: 0.174  loss_box_reg: 0.306  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0268  data_time: 0.0075  lr: 0.002298  max_mem: 5394M
[32m[04/28 04:44:40 d2.utils.events]: [0m eta: 0:08:59  iter: 479  total_loss: 0.546  loss_cls: 0.177  loss_box_reg: 0.318  loss_rpn_cls: 0.007  loss_rpn_loc: 0.045  time: 1.0281  data_time: 0.0073  lr: 0.002398  max_mem: 5394M
[32m[04/28 04:45:01 d2.utils.events]: [0m eta: 0:08:38  iter: 499  total_loss: 0.495  loss_cls: 0.155  loss_box_reg: 0.278  loss_rpn_cls: 0.011  loss_rpn_loc: 0.042  time: 1.0281  data_time: 0.0075  lr: 0.002498  max_mem: 5394M
[32m[04/28 04:45:22 d2.utils.events]: [0m eta: 0:08:18  iter: 519  total_loss: 0.603  loss_cls: 0.182  loss_box_reg: 0.322  loss_rpn_cls: 0.010  loss_rpn_loc: 0.063  time: 1.0288  data_time: 0.0079  lr: 0.002597  max_mem: 5394M
[32m[04/28 04:45:42 d2.utils.events]: [0m eta: 0:07:57  iter: 539  total_loss: 0.575  loss_cls: 0.183  loss_box_reg: 0.319  loss_rpn_cls: 0.010  loss_rpn_loc: 0.054  time: 1.0279  data_time: 0.0078  lr: 0.002697  max_mem: 5394M
[32m[04/28 04:46:02 d2.utils.events]: [0m eta: 0:07:36  iter: 559  total_loss: 0.554  loss_cls: 0.175  loss_box_reg: 0.323  loss_rpn_cls: 0.009  loss_rpn_loc: 0.043  time: 1.0281  data_time: 0.0079  lr: 0.002797  max_mem: 5394M
[32m[04/28 04:46:23 d2.utils.events]: [0m eta: 0:07:15  iter: 579  total_loss: 0.566  loss_cls: 0.168  loss_box_reg: 0.320  loss_rpn_cls: 0.012  loss_rpn_loc: 0.054  time: 1.0283  data_time: 0.0077  lr: 0.002897  max_mem: 5394M
[32m[04/28 04:46:43 d2.utils.events]: [0m eta: 0:06:55  iter: 599  total_loss: 0.534  loss_cls: 0.169  loss_box_reg: 0.309  loss_rpn_cls: 0.008  loss_rpn_loc: 0.053  time: 1.0271  data_time: 0.0076  lr: 0.002997  max_mem: 5394M
[32m[04/28 04:47:04 d2.utils.events]: [0m eta: 0:06:34  iter: 619  total_loss: 0.551  loss_cls: 0.160  loss_box_reg: 0.315  loss_rpn_cls: 0.007  loss_rpn_loc: 0.054  time: 1.0272  data_time: 0.0078  lr: 0.003097  max_mem: 5394M
[32m[04/28 04:47:24 d2.utils.events]: [0m eta: 0:06:13  iter: 639  total_loss: 0.548  loss_cls: 0.170  loss_box_reg: 0.323  loss_rpn_cls: 0.007  loss_rpn_loc: 0.051  time: 1.0269  data_time: 0.0076  lr: 0.003197  max_mem: 5394M
[32m[04/28 04:47:45 d2.utils.events]: [0m eta: 0:05:52  iter: 659  total_loss: 0.476  loss_cls: 0.153  loss_box_reg: 0.279  loss_rpn_cls: 0.009  loss_rpn_loc: 0.037  time: 1.0271  data_time: 0.0075  lr: 0.003297  max_mem: 5394M
[32m[04/28 04:48:06 d2.utils.events]: [0m eta: 0:05:32  iter: 679  total_loss: 0.554  loss_cls: 0.169  loss_box_reg: 0.325  loss_rpn_cls: 0.008  loss_rpn_loc: 0.048  time: 1.0276  data_time: 0.0077  lr: 0.003397  max_mem: 5394M
[32m[04/28 04:48:27 d2.utils.events]: [0m eta: 0:05:11  iter: 699  total_loss: 0.581  loss_cls: 0.166  loss_box_reg: 0.339  loss_rpn_cls: 0.008  loss_rpn_loc: 0.056  time: 1.0281  data_time: 0.0078  lr: 0.003497  max_mem: 5394M
[32m[04/28 04:48:47 d2.utils.events]: [0m eta: 0:04:51  iter: 719  total_loss: 0.621  loss_cls: 0.200  loss_box_reg: 0.332  loss_rpn_cls: 0.009  loss_rpn_loc: 0.060  time: 1.0281  data_time: 0.0078  lr: 0.003596  max_mem: 5394M
[32m[04/28 04:49:08 d2.utils.events]: [0m eta: 0:04:30  iter: 739  total_loss: 0.547  loss_cls: 0.166  loss_box_reg: 0.318  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 1.0283  data_time: 0.0075  lr: 0.003696  max_mem: 5394M
[32m[04/28 04:49:29 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.554  loss_cls: 0.179  loss_box_reg: 0.309  loss_rpn_cls: 0.012  loss_rpn_loc: 0.042  time: 1.0282  data_time: 0.0075  lr: 0.003796  max_mem: 5394M
[32m[04/28 04:49:49 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.547  loss_cls: 0.177  loss_box_reg: 0.302  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 1.0280  data_time: 0.0076  lr: 0.003896  max_mem: 5394M
[32m[04/28 04:50:10 d2.utils.events]: [0m eta: 0:03:28  iter: 799  total_loss: 0.514  loss_cls: 0.168  loss_box_reg: 0.307  loss_rpn_cls: 0.010  loss_rpn_loc: 0.048  time: 1.0283  data_time: 0.0076  lr: 0.003996  max_mem: 5394M
[32m[04/28 04:50:31 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.544  loss_cls: 0.167  loss_box_reg: 0.328  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 1.0286  data_time: 0.0078  lr: 0.004096  max_mem: 5394M
[32m[04/28 04:50:52 d2.utils.events]: [0m eta: 0:02:47  iter: 839  total_loss: 0.603  loss_cls: 0.186  loss_box_reg: 0.347  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 1.0290  data_time: 0.0080  lr: 0.004196  max_mem: 5394M
[32m[04/28 04:51:13 d2.utils.events]: [0m eta: 0:02:26  iter: 859  total_loss: 0.644  loss_cls: 0.209  loss_box_reg: 0.364  loss_rpn_cls: 0.013  loss_rpn_loc: 0.062  time: 1.0293  data_time: 0.0076  lr: 0.004296  max_mem: 5394M
[32m[04/28 04:51:33 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.547  loss_cls: 0.169  loss_box_reg: 0.289  loss_rpn_cls: 0.009  loss_rpn_loc: 0.048  time: 1.0294  data_time: 0.0081  lr: 0.004396  max_mem: 5394M
[32m[04/28 04:51:53 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.609  loss_cls: 0.193  loss_box_reg: 0.346  loss_rpn_cls: 0.009  loss_rpn_loc: 0.056  time: 1.0288  data_time: 0.0078  lr: 0.004496  max_mem: 5394M
[32m[04/28 04:52:14 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.575  loss_cls: 0.185  loss_box_reg: 0.331  loss_rpn_cls: 0.015  loss_rpn_loc: 0.050  time: 1.0287  data_time: 0.0076  lr: 0.004595  max_mem: 5394M
[32m[04/28 04:52:35 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.609  loss_cls: 0.187  loss_box_reg: 0.351  loss_rpn_cls: 0.009  loss_rpn_loc: 0.050  time: 1.0288  data_time: 0.0078  lr: 0.004695  max_mem: 5394M
[32m[04/28 04:52:55 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.580  loss_cls: 0.169  loss_box_reg: 0.337  loss_rpn_cls: 0.012  loss_rpn_loc: 0.063  time: 1.0287  data_time: 0.0080  lr: 0.004795  max_mem: 5394M
[32m[04/28 04:53:16 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.629  loss_cls: 0.207  loss_box_reg: 0.343  loss_rpn_cls: 0.013  loss_rpn_loc: 0.047  time: 1.0286  data_time: 0.0075  lr: 0.004895  max_mem: 5394M
[5m[31mWARNING[0m [32m[04/28 04:53:39 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 04:53:39 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 04:53:39 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 04:53:39 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.685  loss_cls: 0.217  loss_box_reg: 0.356  loss_rpn_cls: 0.013  loss_rpn_loc: 0.076  time: 1.0286  data_time: 0.0078  lr: 0.004995  max_mem: 5394M
[32m[04/28 04:53:39 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:06 (1.0297 s / it)
[32m[04/28 04:53:39 d2.engine.hooks]: [0mTotal training time: 0:17:12 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 04:53:41 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 04:53:41 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 04:53:41 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 04:53:42 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1151 s / img. ETA=0:16:11
[32m[04/28 04:53:47 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1146 s / img. ETA=0:16:04
[32m[04/28 04:53:53 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1146 s / img. ETA=0:15:59
[32m[04/28 04:53:58 d2.evaluation.evaluator]: [0mInference done 142/8355. 0.1146 s / img. ETA=0:15:54
[32m[04/28 04:54:03 d2.evaluation.evaluator]: [0mInference done 185/8355. 0.1147 s / img. ETA=0:15:50
[32m[04/28 04:54:08 d2.evaluation.evaluator]: [0mInference done 228/8355. 0.1147 s / img. ETA=0:15:46
[32m[04/28 04:54:13 d2.evaluation.evaluator]: [0mInference done 271/8355. 0.1148 s / img. ETA=0:15:41
[32m[04/28 04:54:18 d2.evaluation.evaluator]: [0mInference done 314/8355. 0.1148 s / img. ETA=0:15:36
[32m[04/28 04:54:23 d2.evaluation.evaluator]: [0mInference done 357/8355. 0.1148 s / img. ETA=0:15:31
[32m[04/28 04:54:28 d2.evaluation.evaluator]: [0mInference done 400/8355. 0.1149 s / img. ETA=0:15:27
[32m[04/28 04:54:33 d2.evaluation.evaluator]: [0mInference done 443/8355. 0.1149 s / img. ETA=0:15:22
[32m[04/28 04:54:38 d2.evaluation.evaluator]: [0mInference done 486/8355. 0.1149 s / img. ETA=0:15:17
[32m[04/28 04:54:43 d2.evaluation.evaluator]: [0mInference done 530/8355. 0.1148 s / img. ETA=0:15:12
[32m[04/28 04:54:48 d2.evaluation.evaluator]: [0mInference done 573/8355. 0.1149 s / img. ETA=0:15:07
[32m[04/28 04:54:53 d2.evaluation.evaluator]: [0mInference done 616/8355. 0.1149 s / img. ETA=0:15:02
[32m[04/28 04:54:58 d2.evaluation.evaluator]: [0mInference done 659/8355. 0.1149 s / img. ETA=0:14:57
[32m[04/28 04:55:03 d2.evaluation.evaluator]: [0mInference done 702/8355. 0.1150 s / img. ETA=0:14:53
[32m[04/28 04:55:08 d2.evaluation.evaluator]: [0mInference done 745/8355. 0.1150 s / img. ETA=0:14:48
[32m[04/28 04:55:13 d2.evaluation.evaluator]: [0mInference done 788/8355. 0.1150 s / img. ETA=0:14:43
[32m[04/28 04:55:18 d2.evaluation.evaluator]: [0mInference done 831/8355. 0.1151 s / img. ETA=0:14:39
[32m[04/28 04:55:23 d2.evaluation.evaluator]: [0mInference done 874/8355. 0.1151 s / img. ETA=0:14:34
[32m[04/28 04:55:28 d2.evaluation.evaluator]: [0mInference done 917/8355. 0.1152 s / img. ETA=0:14:29
[32m[04/28 04:55:33 d2.evaluation.evaluator]: [0mInference done 960/8355. 0.1152 s / img. ETA=0:14:25
[32m[04/28 04:55:38 d2.evaluation.evaluator]: [0mInference done 1003/8355. 0.1152 s / img. ETA=0:14:20
[32m[04/28 04:55:43 d2.evaluation.evaluator]: [0mInference done 1046/8355. 0.1152 s / img. ETA=0:14:14
[32m[04/28 04:55:48 d2.evaluation.evaluator]: [0mInference done 1089/8355. 0.1152 s / img. ETA=0:14:09
[32m[04/28 04:55:54 d2.evaluation.evaluator]: [0mInference done 1132/8355. 0.1152 s / img. ETA=0:14:04
[32m[04/28 04:55:59 d2.evaluation.evaluator]: [0mInference done 1175/8355. 0.1152 s / img. ETA=0:13:59
[32m[04/28 04:56:04 d2.evaluation.evaluator]: [0mInference done 1218/8355. 0.1152 s / img. ETA=0:13:54
[32m[04/28 04:56:09 d2.evaluation.evaluator]: [0mInference done 1261/8355. 0.1152 s / img. ETA=0:13:49
[32m[04/28 04:56:14 d2.evaluation.evaluator]: [0mInference done 1304/8355. 0.1152 s / img. ETA=0:13:44
[32m[04/28 04:56:19 d2.evaluation.evaluator]: [0mInference done 1347/8355. 0.1152 s / img. ETA=0:13:39
[32m[04/28 04:56:24 d2.evaluation.evaluator]: [0mInference done 1390/8355. 0.1152 s / img. ETA=0:13:34
[32m[04/28 04:56:29 d2.evaluation.evaluator]: [0mInference done 1433/8355. 0.1152 s / img. ETA=0:13:29
[32m[04/28 04:56:34 d2.evaluation.evaluator]: [0mInference done 1476/8355. 0.1152 s / img. ETA=0:13:24
[32m[04/28 04:56:39 d2.evaluation.evaluator]: [0mInference done 1519/8355. 0.1152 s / img. ETA=0:13:19
[32m[04/28 04:56:44 d2.evaluation.evaluator]: [0mInference done 1561/8355. 0.1153 s / img. ETA=0:13:15
[32m[04/28 04:56:49 d2.evaluation.evaluator]: [0mInference done 1604/8355. 0.1153 s / img. ETA=0:13:10
[32m[04/28 04:56:54 d2.evaluation.evaluator]: [0mInference done 1646/8355. 0.1153 s / img. ETA=0:13:05
[32m[04/28 04:56:59 d2.evaluation.evaluator]: [0mInference done 1689/8355. 0.1154 s / img. ETA=0:13:00
[32m[04/28 04:57:04 d2.evaluation.evaluator]: [0mInference done 1732/8355. 0.1154 s / img. ETA=0:12:56
[32m[04/28 04:57:09 d2.evaluation.evaluator]: [0mInference done 1775/8355. 0.1154 s / img. ETA=0:12:51
[32m[04/28 04:57:14 d2.evaluation.evaluator]: [0mInference done 1817/8355. 0.1155 s / img. ETA=0:12:46
[32m[04/28 04:57:19 d2.evaluation.evaluator]: [0mInference done 1860/8355. 0.1155 s / img. ETA=0:12:41
[32m[04/28 04:57:24 d2.evaluation.evaluator]: [0mInference done 1903/8355. 0.1155 s / img. ETA=0:12:36
[32m[04/28 04:57:29 d2.evaluation.evaluator]: [0mInference done 1946/8355. 0.1155 s / img. ETA=0:12:31
[32m[04/28 04:57:34 d2.evaluation.evaluator]: [0mInference done 1989/8355. 0.1155 s / img. ETA=0:12:26
[32m[04/28 04:57:40 d2.evaluation.evaluator]: [0mInference done 2032/8355. 0.1155 s / img. ETA=0:12:21
[32m[04/28 04:57:45 d2.evaluation.evaluator]: [0mInference done 2075/8355. 0.1155 s / img. ETA=0:12:16
[32m[04/28 04:57:50 d2.evaluation.evaluator]: [0mInference done 2118/8355. 0.1156 s / img. ETA=0:12:12
[32m[04/28 04:57:55 d2.evaluation.evaluator]: [0mInference done 2161/8355. 0.1156 s / img. ETA=0:12:06
[32m[04/28 04:58:00 d2.evaluation.evaluator]: [0mInference done 2202/8355. 0.1157 s / img. ETA=0:12:02
[32m[04/28 04:58:05 d2.evaluation.evaluator]: [0mInference done 2245/8355. 0.1157 s / img. ETA=0:11:58
[32m[04/28 04:58:10 d2.evaluation.evaluator]: [0mInference done 2288/8355. 0.1157 s / img. ETA=0:11:53
[32m[04/28 04:58:15 d2.evaluation.evaluator]: [0mInference done 2331/8355. 0.1157 s / img. ETA=0:11:48
[32m[04/28 04:58:20 d2.evaluation.evaluator]: [0mInference done 2374/8355. 0.1157 s / img. ETA=0:11:42
[32m[04/28 04:58:25 d2.evaluation.evaluator]: [0mInference done 2417/8355. 0.1157 s / img. ETA=0:11:37
[32m[04/28 04:58:30 d2.evaluation.evaluator]: [0mInference done 2460/8355. 0.1157 s / img. ETA=0:11:32
[32m[04/28 04:58:35 d2.evaluation.evaluator]: [0mInference done 2503/8355. 0.1157 s / img. ETA=0:11:27
[32m[04/28 04:58:40 d2.evaluation.evaluator]: [0mInference done 2546/8355. 0.1157 s / img. ETA=0:11:22
[32m[04/28 04:58:45 d2.evaluation.evaluator]: [0mInference done 2589/8355. 0.1157 s / img. ETA=0:11:17
[32m[04/28 04:58:51 d2.evaluation.evaluator]: [0mInference done 2632/8355. 0.1158 s / img. ETA=0:11:12
[32m[04/28 04:58:56 d2.evaluation.evaluator]: [0mInference done 2675/8355. 0.1158 s / img. ETA=0:11:07
[32m[04/28 04:59:01 d2.evaluation.evaluator]: [0mInference done 2718/8355. 0.1158 s / img. ETA=0:11:02
[32m[04/28 04:59:06 d2.evaluation.evaluator]: [0mInference done 2761/8355. 0.1158 s / img. ETA=0:10:57
[32m[04/28 04:59:11 d2.evaluation.evaluator]: [0mInference done 2804/8355. 0.1158 s / img. ETA=0:10:52
[32m[04/28 04:59:16 d2.evaluation.evaluator]: [0mInference done 2847/8355. 0.1158 s / img. ETA=0:10:47
[32m[04/28 04:59:21 d2.evaluation.evaluator]: [0mInference done 2890/8355. 0.1158 s / img. ETA=0:10:42
[32m[04/28 04:59:26 d2.evaluation.evaluator]: [0mInference done 2933/8355. 0.1158 s / img. ETA=0:10:37
[32m[04/28 04:59:31 d2.evaluation.evaluator]: [0mInference done 2976/8355. 0.1158 s / img. ETA=0:10:32
[32m[04/28 04:59:36 d2.evaluation.evaluator]: [0mInference done 3019/8355. 0.1158 s / img. ETA=0:10:27
[32m[04/28 04:59:41 d2.evaluation.evaluator]: [0mInference done 3062/8355. 0.1158 s / img. ETA=0:10:22
[32m[04/28 04:59:46 d2.evaluation.evaluator]: [0mInference done 3105/8355. 0.1158 s / img. ETA=0:10:17
[32m[04/28 04:59:51 d2.evaluation.evaluator]: [0mInference done 3148/8355. 0.1158 s / img. ETA=0:10:12
[32m[04/28 04:59:56 d2.evaluation.evaluator]: [0mInference done 3191/8355. 0.1158 s / img. ETA=0:10:07
[32m[04/28 05:00:01 d2.evaluation.evaluator]: [0mInference done 3234/8355. 0.1158 s / img. ETA=0:10:02
[32m[04/28 05:00:06 d2.evaluation.evaluator]: [0mInference done 3277/8355. 0.1158 s / img. ETA=0:09:57
[32m[04/28 05:00:11 d2.evaluation.evaluator]: [0mInference done 3320/8355. 0.1158 s / img. ETA=0:09:52
[32m[04/28 05:00:16 d2.evaluation.evaluator]: [0mInference done 3363/8355. 0.1158 s / img. ETA=0:09:46
[32m[04/28 05:00:22 d2.evaluation.evaluator]: [0mInference done 3406/8355. 0.1157 s / img. ETA=0:09:41
[32m[04/28 05:00:27 d2.evaluation.evaluator]: [0mInference done 3449/8355. 0.1157 s / img. ETA=0:09:36
[32m[04/28 05:00:32 d2.evaluation.evaluator]: [0mInference done 3492/8355. 0.1157 s / img. ETA=0:09:31
[32m[04/28 05:00:37 d2.evaluation.evaluator]: [0mInference done 3535/8355. 0.1158 s / img. ETA=0:09:26
[32m[04/28 05:00:42 d2.evaluation.evaluator]: [0mInference done 3578/8355. 0.1157 s / img. ETA=0:09:21
[32m[04/28 05:00:47 d2.evaluation.evaluator]: [0mInference done 3621/8355. 0.1157 s / img. ETA=0:09:16
[32m[04/28 05:00:52 d2.evaluation.evaluator]: [0mInference done 3664/8355. 0.1157 s / img. ETA=0:09:11
[32m[04/28 05:00:57 d2.evaluation.evaluator]: [0mInference done 3707/8355. 0.1157 s / img. ETA=0:09:06
[32m[04/28 05:01:02 d2.evaluation.evaluator]: [0mInference done 3750/8355. 0.1157 s / img. ETA=0:09:01
[32m[04/28 05:01:07 d2.evaluation.evaluator]: [0mInference done 3793/8355. 0.1157 s / img. ETA=0:08:56
[32m[04/28 05:01:12 d2.evaluation.evaluator]: [0mInference done 3836/8355. 0.1157 s / img. ETA=0:08:51
[32m[04/28 05:01:17 d2.evaluation.evaluator]: [0mInference done 3879/8355. 0.1157 s / img. ETA=0:08:46
[32m[04/28 05:01:22 d2.evaluation.evaluator]: [0mInference done 3922/8355. 0.1157 s / img. ETA=0:08:41
[32m[04/28 05:01:27 d2.evaluation.evaluator]: [0mInference done 3965/8355. 0.1157 s / img. ETA=0:08:36
[32m[04/28 05:01:32 d2.evaluation.evaluator]: [0mInference done 4008/8355. 0.1157 s / img. ETA=0:08:31
[32m[04/28 05:01:37 d2.evaluation.evaluator]: [0mInference done 4051/8355. 0.1157 s / img. ETA=0:08:25
[32m[04/28 05:01:42 d2.evaluation.evaluator]: [0mInference done 4094/8355. 0.1157 s / img. ETA=0:08:20
[32m[04/28 05:01:47 d2.evaluation.evaluator]: [0mInference done 4137/8355. 0.1157 s / img. ETA=0:08:15
[32m[04/28 05:01:53 d2.evaluation.evaluator]: [0mInference done 4180/8355. 0.1157 s / img. ETA=0:08:10
[32m[04/28 05:01:58 d2.evaluation.evaluator]: [0mInference done 4223/8355. 0.1157 s / img. ETA=0:08:05
[32m[04/28 05:02:03 d2.evaluation.evaluator]: [0mInference done 4266/8355. 0.1157 s / img. ETA=0:08:00
[32m[04/28 05:02:08 d2.evaluation.evaluator]: [0mInference done 4309/8355. 0.1157 s / img. ETA=0:07:55
[32m[04/28 05:02:13 d2.evaluation.evaluator]: [0mInference done 4352/8355. 0.1157 s / img. ETA=0:07:50
[32m[04/28 05:02:18 d2.evaluation.evaluator]: [0mInference done 4395/8355. 0.1157 s / img. ETA=0:07:45
[32m[04/28 05:02:23 d2.evaluation.evaluator]: [0mInference done 4438/8355. 0.1157 s / img. ETA=0:07:40
[32m[04/28 05:02:28 d2.evaluation.evaluator]: [0mInference done 4481/8355. 0.1157 s / img. ETA=0:07:35
[32m[04/28 05:02:33 d2.evaluation.evaluator]: [0mInference done 4524/8355. 0.1157 s / img. ETA=0:07:30
[32m[04/28 05:02:38 d2.evaluation.evaluator]: [0mInference done 4567/8355. 0.1157 s / img. ETA=0:07:25
[32m[04/28 05:02:43 d2.evaluation.evaluator]: [0mInference done 4610/8355. 0.1157 s / img. ETA=0:07:20
[32m[04/28 05:02:48 d2.evaluation.evaluator]: [0mInference done 4652/8355. 0.1157 s / img. ETA=0:07:15
[32m[04/28 05:02:53 d2.evaluation.evaluator]: [0mInference done 4695/8355. 0.1157 s / img. ETA=0:07:10
[32m[04/28 05:02:58 d2.evaluation.evaluator]: [0mInference done 4738/8355. 0.1157 s / img. ETA=0:07:05
[32m[04/28 05:03:03 d2.evaluation.evaluator]: [0mInference done 4781/8355. 0.1157 s / img. ETA=0:07:00
[32m[04/28 05:03:08 d2.evaluation.evaluator]: [0mInference done 4824/8355. 0.1158 s / img. ETA=0:06:55
[32m[04/28 05:03:13 d2.evaluation.evaluator]: [0mInference done 4867/8355. 0.1158 s / img. ETA=0:06:50
[32m[04/28 05:03:18 d2.evaluation.evaluator]: [0mInference done 4910/8355. 0.1158 s / img. ETA=0:06:45
[32m[04/28 05:03:24 d2.evaluation.evaluator]: [0mInference done 4953/8355. 0.1158 s / img. ETA=0:06:40
[32m[04/28 05:03:29 d2.evaluation.evaluator]: [0mInference done 4996/8355. 0.1158 s / img. ETA=0:06:34
[32m[04/28 05:03:34 d2.evaluation.evaluator]: [0mInference done 5039/8355. 0.1157 s / img. ETA=0:06:29
[32m[04/28 05:03:39 d2.evaluation.evaluator]: [0mInference done 5082/8355. 0.1158 s / img. ETA=0:06:24
[32m[04/28 05:03:44 d2.evaluation.evaluator]: [0mInference done 5124/8355. 0.1158 s / img. ETA=0:06:19
[32m[04/28 05:03:49 d2.evaluation.evaluator]: [0mInference done 5167/8355. 0.1158 s / img. ETA=0:06:14
[32m[04/28 05:03:54 d2.evaluation.evaluator]: [0mInference done 5210/8355. 0.1158 s / img. ETA=0:06:09
[32m[04/28 05:03:59 d2.evaluation.evaluator]: [0mInference done 5253/8355. 0.1158 s / img. ETA=0:06:04
[32m[04/28 05:04:04 d2.evaluation.evaluator]: [0mInference done 5296/8355. 0.1158 s / img. ETA=0:05:59
[32m[04/28 05:04:09 d2.evaluation.evaluator]: [0mInference done 5339/8355. 0.1158 s / img. ETA=0:05:54
[32m[04/28 05:04:14 d2.evaluation.evaluator]: [0mInference done 5382/8355. 0.1158 s / img. ETA=0:05:49
[32m[04/28 05:04:19 d2.evaluation.evaluator]: [0mInference done 5425/8355. 0.1158 s / img. ETA=0:05:44
[32m[04/28 05:04:24 d2.evaluation.evaluator]: [0mInference done 5468/8355. 0.1158 s / img. ETA=0:05:39
[32m[04/28 05:04:29 d2.evaluation.evaluator]: [0mInference done 5511/8355. 0.1158 s / img. ETA=0:05:34
[32m[04/28 05:04:34 d2.evaluation.evaluator]: [0mInference done 5554/8355. 0.1158 s / img. ETA=0:05:29
[32m[04/28 05:04:39 d2.evaluation.evaluator]: [0mInference done 5597/8355. 0.1158 s / img. ETA=0:05:24
[32m[04/28 05:04:44 d2.evaluation.evaluator]: [0mInference done 5640/8355. 0.1158 s / img. ETA=0:05:19
[32m[04/28 05:04:50 d2.evaluation.evaluator]: [0mInference done 5683/8355. 0.1158 s / img. ETA=0:05:14
[32m[04/28 05:04:55 d2.evaluation.evaluator]: [0mInference done 5726/8355. 0.1158 s / img. ETA=0:05:09
[32m[04/28 05:05:00 d2.evaluation.evaluator]: [0mInference done 5769/8355. 0.1158 s / img. ETA=0:05:04
[32m[04/28 05:05:05 d2.evaluation.evaluator]: [0mInference done 5812/8355. 0.1158 s / img. ETA=0:04:59
[32m[04/28 05:05:10 d2.evaluation.evaluator]: [0mInference done 5855/8355. 0.1158 s / img. ETA=0:04:54
[32m[04/28 05:05:15 d2.evaluation.evaluator]: [0mInference done 5897/8355. 0.1158 s / img. ETA=0:04:49
[32m[04/28 05:05:20 d2.evaluation.evaluator]: [0mInference done 5940/8355. 0.1158 s / img. ETA=0:04:44
[32m[04/28 05:05:25 d2.evaluation.evaluator]: [0mInference done 5983/8355. 0.1158 s / img. ETA=0:04:39
[32m[04/28 05:05:30 d2.evaluation.evaluator]: [0mInference done 6026/8355. 0.1158 s / img. ETA=0:04:34
[32m[04/28 05:05:35 d2.evaluation.evaluator]: [0mInference done 6069/8355. 0.1158 s / img. ETA=0:04:29
[32m[04/28 05:05:40 d2.evaluation.evaluator]: [0mInference done 6112/8355. 0.1159 s / img. ETA=0:04:23
[32m[04/28 05:05:45 d2.evaluation.evaluator]: [0mInference done 6154/8355. 0.1159 s / img. ETA=0:04:19
[32m[04/28 05:05:51 d2.evaluation.evaluator]: [0mInference done 6197/8355. 0.1159 s / img. ETA=0:04:14
[32m[04/28 05:05:56 d2.evaluation.evaluator]: [0mInference done 6239/8355. 0.1159 s / img. ETA=0:04:09
[32m[04/28 05:06:01 d2.evaluation.evaluator]: [0mInference done 6282/8355. 0.1159 s / img. ETA=0:04:04
[32m[04/28 05:06:06 d2.evaluation.evaluator]: [0mInference done 6324/8355. 0.1159 s / img. ETA=0:03:59
[32m[04/28 05:06:11 d2.evaluation.evaluator]: [0mInference done 6367/8355. 0.1159 s / img. ETA=0:03:54
[32m[04/28 05:06:16 d2.evaluation.evaluator]: [0mInference done 6410/8355. 0.1159 s / img. ETA=0:03:49
[32m[04/28 05:06:21 d2.evaluation.evaluator]: [0mInference done 6453/8355. 0.1159 s / img. ETA=0:03:43
[32m[04/28 05:06:26 d2.evaluation.evaluator]: [0mInference done 6496/8355. 0.1159 s / img. ETA=0:03:38
[32m[04/28 05:06:31 d2.evaluation.evaluator]: [0mInference done 6539/8355. 0.1159 s / img. ETA=0:03:33
[32m[04/28 05:06:36 d2.evaluation.evaluator]: [0mInference done 6582/8355. 0.1159 s / img. ETA=0:03:28
[32m[04/28 05:06:41 d2.evaluation.evaluator]: [0mInference done 6625/8355. 0.1159 s / img. ETA=0:03:23
[32m[04/28 05:06:46 d2.evaluation.evaluator]: [0mInference done 6668/8355. 0.1159 s / img. ETA=0:03:18
[32m[04/28 05:06:51 d2.evaluation.evaluator]: [0mInference done 6711/8355. 0.1159 s / img. ETA=0:03:13
[32m[04/28 05:06:56 d2.evaluation.evaluator]: [0mInference done 6754/8355. 0.1159 s / img. ETA=0:03:08
[32m[04/28 05:07:01 d2.evaluation.evaluator]: [0mInference done 6797/8355. 0.1159 s / img. ETA=0:03:03
[32m[04/28 05:07:06 d2.evaluation.evaluator]: [0mInference done 6840/8355. 0.1159 s / img. ETA=0:02:58
[32m[04/28 05:07:11 d2.evaluation.evaluator]: [0mInference done 6883/8355. 0.1159 s / img. ETA=0:02:53
[32m[04/28 05:07:16 d2.evaluation.evaluator]: [0mInference done 6926/8355. 0.1159 s / img. ETA=0:02:48
[32m[04/28 05:07:21 d2.evaluation.evaluator]: [0mInference done 6969/8355. 0.1159 s / img. ETA=0:02:43
[32m[04/28 05:07:26 d2.evaluation.evaluator]: [0mInference done 7012/8355. 0.1159 s / img. ETA=0:02:38
[32m[04/28 05:07:31 d2.evaluation.evaluator]: [0mInference done 7055/8355. 0.1159 s / img. ETA=0:02:33
[32m[04/28 05:07:37 d2.evaluation.evaluator]: [0mInference done 7098/8355. 0.1159 s / img. ETA=0:02:27
[32m[04/28 05:07:42 d2.evaluation.evaluator]: [0mInference done 7141/8355. 0.1159 s / img. ETA=0:02:22
[32m[04/28 05:07:47 d2.evaluation.evaluator]: [0mInference done 7184/8355. 0.1159 s / img. ETA=0:02:17
[32m[04/28 05:07:52 d2.evaluation.evaluator]: [0mInference done 7227/8355. 0.1159 s / img. ETA=0:02:12
[32m[04/28 05:07:57 d2.evaluation.evaluator]: [0mInference done 7269/8355. 0.1159 s / img. ETA=0:02:07
[32m[04/28 05:08:02 d2.evaluation.evaluator]: [0mInference done 7312/8355. 0.1159 s / img. ETA=0:02:02
[32m[04/28 05:08:07 d2.evaluation.evaluator]: [0mInference done 7355/8355. 0.1159 s / img. ETA=0:01:57
[32m[04/28 05:08:12 d2.evaluation.evaluator]: [0mInference done 7398/8355. 0.1159 s / img. ETA=0:01:52
[32m[04/28 05:08:17 d2.evaluation.evaluator]: [0mInference done 7440/8355. 0.1159 s / img. ETA=0:01:47
[32m[04/28 05:08:22 d2.evaluation.evaluator]: [0mInference done 7483/8355. 0.1159 s / img. ETA=0:01:42
[32m[04/28 05:08:27 d2.evaluation.evaluator]: [0mInference done 7526/8355. 0.1159 s / img. ETA=0:01:37
[32m[04/28 05:08:32 d2.evaluation.evaluator]: [0mInference done 7569/8355. 0.1159 s / img. ETA=0:01:32
[32m[04/28 05:08:37 d2.evaluation.evaluator]: [0mInference done 7612/8355. 0.1159 s / img. ETA=0:01:27
[32m[04/28 05:08:43 d2.evaluation.evaluator]: [0mInference done 7655/8355. 0.1159 s / img. ETA=0:01:22
[32m[04/28 05:08:48 d2.evaluation.evaluator]: [0mInference done 7698/8355. 0.1159 s / img. ETA=0:01:17
[32m[04/28 05:08:53 d2.evaluation.evaluator]: [0mInference done 7741/8355. 0.1159 s / img. ETA=0:01:12
[32m[04/28 05:08:58 d2.evaluation.evaluator]: [0mInference done 7784/8355. 0.1159 s / img. ETA=0:01:07
[32m[04/28 05:09:03 d2.evaluation.evaluator]: [0mInference done 7826/8355. 0.1159 s / img. ETA=0:01:02
[32m[04/28 05:09:08 d2.evaluation.evaluator]: [0mInference done 7869/8355. 0.1159 s / img. ETA=0:00:57
[32m[04/28 05:09:13 d2.evaluation.evaluator]: [0mInference done 7911/8355. 0.1159 s / img. ETA=0:00:52
[32m[04/28 05:09:18 d2.evaluation.evaluator]: [0mInference done 7954/8355. 0.1159 s / img. ETA=0:00:47
[32m[04/28 05:09:23 d2.evaluation.evaluator]: [0mInference done 7997/8355. 0.1159 s / img. ETA=0:00:42
[32m[04/28 05:09:28 d2.evaluation.evaluator]: [0mInference done 8040/8355. 0.1159 s / img. ETA=0:00:37
[32m[04/28 05:09:33 d2.evaluation.evaluator]: [0mInference done 8083/8355. 0.1159 s / img. ETA=0:00:32
[32m[04/28 05:09:38 d2.evaluation.evaluator]: [0mInference done 8126/8355. 0.1159 s / img. ETA=0:00:26
[32m[04/28 05:09:43 d2.evaluation.evaluator]: [0mInference done 8169/8355. 0.1159 s / img. ETA=0:00:21
[32m[04/28 05:09:48 d2.evaluation.evaluator]: [0mInference done 8212/8355. 0.1159 s / img. ETA=0:00:16
[32m[04/28 05:09:53 d2.evaluation.evaluator]: [0mInference done 8255/8355. 0.1159 s / img. ETA=0:00:11
[32m[04/28 05:09:58 d2.evaluation.evaluator]: [0mInference done 8297/8355. 0.1159 s / img. ETA=0:00:06
[32m[04/28 05:10:03 d2.evaluation.evaluator]: [0mInference done 8340/8355. 0.1159 s / img. ETA=0:00:01
[32m[04/28 05:10:05 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:23.444959 (0.117778 s / img per device, on 1 devices)
[32m[04/28 05:10:05 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:07 (0.115928 s / img per device, on 1 devices)
[32m[04/28 05:10:05 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 05:10:05 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 05:10:06 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.05s).
Accumulating evaluation results...
DONE (t=2.13s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.418
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.775
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.391
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.326
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.162
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.474
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.405
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.595
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.663
[32m[04/28 05:10:27 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.785 | 77.520 | 39.076 | 32.645 | 52.439 | 62.557 |
[32m[04/28 05:10:27 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 42.773 | bicycle       | 29.612 | car            | 52.969 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 05:10:27 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 05:10:27 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 05:10:27 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 05:10:29 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1145 s / img. ETA=0:02:24
[32m[04/28 05:10:34 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1148 s / img. ETA=0:02:20
[32m[04/28 05:10:39 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1149 s / img. ETA=0:02:15
[32m[04/28 05:10:44 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1149 s / img. ETA=0:02:10
[32m[04/28 05:10:49 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1149 s / img. ETA=0:02:05
[32m[04/28 05:10:54 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1148 s / img. ETA=0:02:00
[32m[04/28 05:10:59 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1149 s / img. ETA=0:01:55
[32m[04/28 05:11:04 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1149 s / img. ETA=0:01:50
[32m[04/28 05:11:09 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1149 s / img. ETA=0:01:45
[32m[04/28 05:11:14 d2.evaluation.evaluator]: [0mInference done 396/1257. 0.1155 s / img. ETA=0:01:41
[32m[04/28 05:11:19 d2.evaluation.evaluator]: [0mInference done 439/1257. 0.1154 s / img. ETA=0:01:35
[32m[04/28 05:11:24 d2.evaluation.evaluator]: [0mInference done 482/1257. 0.1154 s / img. ETA=0:01:30
[32m[04/28 05:11:29 d2.evaluation.evaluator]: [0mInference done 525/1257. 0.1153 s / img. ETA=0:01:25
[32m[04/28 05:11:34 d2.evaluation.evaluator]: [0mInference done 568/1257. 0.1153 s / img. ETA=0:01:20
[32m[04/28 05:11:39 d2.evaluation.evaluator]: [0mInference done 611/1257. 0.1153 s / img. ETA=0:01:15
[32m[04/28 05:11:44 d2.evaluation.evaluator]: [0mInference done 654/1257. 0.1153 s / img. ETA=0:01:10
[32m[04/28 05:11:49 d2.evaluation.evaluator]: [0mInference done 697/1257. 0.1153 s / img. ETA=0:01:05
[32m[04/28 05:11:54 d2.evaluation.evaluator]: [0mInference done 740/1257. 0.1153 s / img. ETA=0:01:00
[32m[04/28 05:11:59 d2.evaluation.evaluator]: [0mInference done 783/1257. 0.1152 s / img. ETA=0:00:55
[32m[04/28 05:12:04 d2.evaluation.evaluator]: [0mInference done 826/1257. 0.1153 s / img. ETA=0:00:50
[32m[04/28 05:12:09 d2.evaluation.evaluator]: [0mInference done 869/1257. 0.1153 s / img. ETA=0:00:45
[32m[04/28 05:12:14 d2.evaluation.evaluator]: [0mInference done 912/1257. 0.1153 s / img. ETA=0:00:40
[32m[04/28 05:12:19 d2.evaluation.evaluator]: [0mInference done 955/1257. 0.1153 s / img. ETA=0:00:35
[32m[04/28 05:12:25 d2.evaluation.evaluator]: [0mInference done 998/1257. 0.1153 s / img. ETA=0:00:30
[32m[04/28 05:12:30 d2.evaluation.evaluator]: [0mInference done 1041/1257. 0.1153 s / img. ETA=0:00:25
[32m[04/28 05:12:35 d2.evaluation.evaluator]: [0mInference done 1084/1257. 0.1153 s / img. ETA=0:00:20
[32m[04/28 05:12:40 d2.evaluation.evaluator]: [0mInference done 1127/1257. 0.1153 s / img. ETA=0:00:15
[32m[04/28 05:12:45 d2.evaluation.evaluator]: [0mInference done 1170/1257. 0.1154 s / img. ETA=0:00:10
[32m[04/28 05:12:50 d2.evaluation.evaluator]: [0mInference done 1213/1257. 0.1154 s / img. ETA=0:00:05
[32m[04/28 05:12:55 d2.evaluation.evaluator]: [0mInference done 1256/1257. 0.1154 s / img. ETA=0:00:00
[32m[04/28 05:12:55 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.830407 (0.117277 s / img per device, on 1 devices)
[32m[04/28 05:12:55 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115359 s / img per device, on 1 devices)
[32m[04/28 05:12:55 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 05:12:55 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 05:12:55 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.94s).
Accumulating evaluation results...
DONE (t=0.37s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.711
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.319
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.277
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.483
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.164
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.437
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.442
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.378
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.480
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.524
[32m[04/28 05:12:58 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 36.421 | 71.063 | 31.882 | 27.738 | 41.193 | 48.314 |
[32m[04/28 05:12:58 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 39.506 | bicycle       | 14.333 | car            | 55.424 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  6  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 05:12:59 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 05:13:00 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 05:13:00 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 05:13:00 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 05:13:00 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 05:13:00 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 05:13:00 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 05:13:21 d2.utils.events]: [0m eta: 0:16:49  iter: 19  total_loss: 0.617  loss_cls: 0.182  loss_box_reg: 0.355  loss_rpn_cls: 0.011  loss_rpn_loc: 0.070  time: 1.0294  data_time: 0.0189  lr: 0.000100  max_mem: 5394M
[32m[04/28 05:13:42 d2.utils.events]: [0m eta: 0:16:48  iter: 39  total_loss: 0.578  loss_cls: 0.181  loss_box_reg: 0.323  loss_rpn_cls: 0.011  loss_rpn_loc: 0.053  time: 1.0383  data_time: 0.0078  lr: 0.000200  max_mem: 5394M
[32m[04/28 05:14:02 d2.utils.events]: [0m eta: 0:16:24  iter: 59  total_loss: 0.529  loss_cls: 0.164  loss_box_reg: 0.287  loss_rpn_cls: 0.011  loss_rpn_loc: 0.054  time: 1.0329  data_time: 0.0076  lr: 0.000300  max_mem: 5394M
[32m[04/28 05:14:23 d2.utils.events]: [0m eta: 0:16:00  iter: 79  total_loss: 0.491  loss_cls: 0.164  loss_box_reg: 0.288  loss_rpn_cls: 0.012  loss_rpn_loc: 0.041  time: 1.0259  data_time: 0.0075  lr: 0.000400  max_mem: 5394M
[32m[04/28 05:14:44 d2.utils.events]: [0m eta: 0:15:44  iter: 99  total_loss: 0.619  loss_cls: 0.182  loss_box_reg: 0.347  loss_rpn_cls: 0.012  loss_rpn_loc: 0.054  time: 1.0333  data_time: 0.0076  lr: 0.000500  max_mem: 5394M
[32m[04/28 05:15:04 d2.utils.events]: [0m eta: 0:15:13  iter: 119  total_loss: 0.571  loss_cls: 0.165  loss_box_reg: 0.313  loss_rpn_cls: 0.009  loss_rpn_loc: 0.058  time: 1.0253  data_time: 0.0075  lr: 0.000599  max_mem: 5394M
[32m[04/28 05:15:25 d2.utils.events]: [0m eta: 0:14:55  iter: 139  total_loss: 0.590  loss_cls: 0.176  loss_box_reg: 0.336  loss_rpn_cls: 0.010  loss_rpn_loc: 0.049  time: 1.0286  data_time: 0.0078  lr: 0.000699  max_mem: 5394M
[32m[04/28 05:15:45 d2.utils.events]: [0m eta: 0:14:30  iter: 159  total_loss: 0.547  loss_cls: 0.169  loss_box_reg: 0.304  loss_rpn_cls: 0.011  loss_rpn_loc: 0.045  time: 1.0259  data_time: 0.0082  lr: 0.000799  max_mem: 5394M
[32m[04/28 05:16:05 d2.utils.events]: [0m eta: 0:14:08  iter: 179  total_loss: 0.557  loss_cls: 0.171  loss_box_reg: 0.332  loss_rpn_cls: 0.009  loss_rpn_loc: 0.047  time: 1.0240  data_time: 0.0077  lr: 0.000899  max_mem: 5394M
[32m[04/28 05:16:25 d2.utils.events]: [0m eta: 0:13:41  iter: 199  total_loss: 0.551  loss_cls: 0.171  loss_box_reg: 0.340  loss_rpn_cls: 0.008  loss_rpn_loc: 0.042  time: 1.0227  data_time: 0.0080  lr: 0.000999  max_mem: 5394M
[32m[04/28 05:16:46 d2.utils.events]: [0m eta: 0:13:20  iter: 219  total_loss: 0.509  loss_cls: 0.171  loss_box_reg: 0.289  loss_rpn_cls: 0.010  loss_rpn_loc: 0.041  time: 1.0220  data_time: 0.0078  lr: 0.001099  max_mem: 5394M
[32m[04/28 05:17:07 d2.utils.events]: [0m eta: 0:13:02  iter: 239  total_loss: 0.608  loss_cls: 0.197  loss_box_reg: 0.334  loss_rpn_cls: 0.009  loss_rpn_loc: 0.057  time: 1.0239  data_time: 0.0076  lr: 0.001199  max_mem: 5394M
[32m[04/28 05:17:27 d2.utils.events]: [0m eta: 0:12:45  iter: 259  total_loss: 0.494  loss_cls: 0.154  loss_box_reg: 0.301  loss_rpn_cls: 0.008  loss_rpn_loc: 0.033  time: 1.0250  data_time: 0.0076  lr: 0.001299  max_mem: 5394M
[32m[04/28 05:17:48 d2.utils.events]: [0m eta: 0:12:24  iter: 279  total_loss: 0.578  loss_cls: 0.177  loss_box_reg: 0.327  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 1.0251  data_time: 0.0076  lr: 0.001399  max_mem: 5394M
[32m[04/28 05:18:08 d2.utils.events]: [0m eta: 0:11:59  iter: 299  total_loss: 0.557  loss_cls: 0.173  loss_box_reg: 0.305  loss_rpn_cls: 0.008  loss_rpn_loc: 0.058  time: 1.0233  data_time: 0.0073  lr: 0.001499  max_mem: 5394M
[32m[04/28 05:18:28 d2.utils.events]: [0m eta: 0:11:34  iter: 319  total_loss: 0.508  loss_cls: 0.163  loss_box_reg: 0.284  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 1.0218  data_time: 0.0077  lr: 0.001598  max_mem: 5394M
[32m[04/28 05:18:49 d2.utils.events]: [0m eta: 0:11:17  iter: 339  total_loss: 0.512  loss_cls: 0.163  loss_box_reg: 0.298  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 1.0240  data_time: 0.0078  lr: 0.001698  max_mem: 5394M
[32m[04/28 05:19:10 d2.utils.events]: [0m eta: 0:10:58  iter: 359  total_loss: 0.531  loss_cls: 0.153  loss_box_reg: 0.325  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 1.0249  data_time: 0.0076  lr: 0.001798  max_mem: 5394M
[32m[04/28 05:19:31 d2.utils.events]: [0m eta: 0:10:38  iter: 379  total_loss: 0.598  loss_cls: 0.193  loss_box_reg: 0.336  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0266  data_time: 0.0077  lr: 0.001898  max_mem: 5394M
[32m[04/28 05:19:52 d2.utils.events]: [0m eta: 0:10:16  iter: 399  total_loss: 0.491  loss_cls: 0.151  loss_box_reg: 0.273  loss_rpn_cls: 0.008  loss_rpn_loc: 0.057  time: 1.0257  data_time: 0.0081  lr: 0.001998  max_mem: 5394M
[32m[04/28 05:20:13 d2.utils.events]: [0m eta: 0:09:58  iter: 419  total_loss: 0.579  loss_cls: 0.175  loss_box_reg: 0.334  loss_rpn_cls: 0.011  loss_rpn_loc: 0.049  time: 1.0266  data_time: 0.0077  lr: 0.002098  max_mem: 5394M
[32m[04/28 05:20:33 d2.utils.events]: [0m eta: 0:09:36  iter: 439  total_loss: 0.518  loss_cls: 0.161  loss_box_reg: 0.308  loss_rpn_cls: 0.008  loss_rpn_loc: 0.048  time: 1.0261  data_time: 0.0076  lr: 0.002198  max_mem: 5394M
[32m[04/28 05:20:53 d2.utils.events]: [0m eta: 0:09:15  iter: 459  total_loss: 0.576  loss_cls: 0.177  loss_box_reg: 0.322  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0251  data_time: 0.0073  lr: 0.002298  max_mem: 5394M
[32m[04/28 05:21:14 d2.utils.events]: [0m eta: 0:08:54  iter: 479  total_loss: 0.515  loss_cls: 0.162  loss_box_reg: 0.283  loss_rpn_cls: 0.008  loss_rpn_loc: 0.048  time: 1.0250  data_time: 0.0076  lr: 0.002398  max_mem: 5394M
[32m[04/28 05:21:34 d2.utils.events]: [0m eta: 0:08:34  iter: 499  total_loss: 0.543  loss_cls: 0.175  loss_box_reg: 0.303  loss_rpn_cls: 0.011  loss_rpn_loc: 0.043  time: 1.0257  data_time: 0.0076  lr: 0.002498  max_mem: 5394M
[32m[04/28 05:21:55 d2.utils.events]: [0m eta: 0:08:14  iter: 519  total_loss: 0.496  loss_cls: 0.159  loss_box_reg: 0.281  loss_rpn_cls: 0.006  loss_rpn_loc: 0.044  time: 1.0263  data_time: 0.0077  lr: 0.002597  max_mem: 5394M
[32m[04/28 05:22:15 d2.utils.events]: [0m eta: 0:07:53  iter: 539  total_loss: 0.493  loss_cls: 0.158  loss_box_reg: 0.289  loss_rpn_cls: 0.010  loss_rpn_loc: 0.039  time: 1.0255  data_time: 0.0076  lr: 0.002697  max_mem: 5394M
[32m[04/28 05:22:36 d2.utils.events]: [0m eta: 0:07:32  iter: 559  total_loss: 0.584  loss_cls: 0.178  loss_box_reg: 0.325  loss_rpn_cls: 0.009  loss_rpn_loc: 0.046  time: 1.0250  data_time: 0.0074  lr: 0.002797  max_mem: 5394M
[32m[04/28 05:22:57 d2.utils.events]: [0m eta: 0:07:12  iter: 579  total_loss: 0.557  loss_cls: 0.171  loss_box_reg: 0.321  loss_rpn_cls: 0.012  loss_rpn_loc: 0.043  time: 1.0255  data_time: 0.0082  lr: 0.002897  max_mem: 5394M
[32m[04/28 05:23:18 d2.utils.events]: [0m eta: 0:06:52  iter: 599  total_loss: 0.622  loss_cls: 0.197  loss_box_reg: 0.332  loss_rpn_cls: 0.012  loss_rpn_loc: 0.053  time: 1.0263  data_time: 0.0076  lr: 0.002997  max_mem: 5394M
[32m[04/28 05:23:38 d2.utils.events]: [0m eta: 0:06:31  iter: 619  total_loss: 0.556  loss_cls: 0.171  loss_box_reg: 0.318  loss_rpn_cls: 0.009  loss_rpn_loc: 0.048  time: 1.0256  data_time: 0.0074  lr: 0.003097  max_mem: 5394M
[32m[04/28 05:23:58 d2.utils.events]: [0m eta: 0:06:10  iter: 639  total_loss: 0.658  loss_cls: 0.203  loss_box_reg: 0.371  loss_rpn_cls: 0.011  loss_rpn_loc: 0.053  time: 1.0250  data_time: 0.0078  lr: 0.003197  max_mem: 5394M
[32m[04/28 05:24:19 d2.utils.events]: [0m eta: 0:05:50  iter: 659  total_loss: 0.635  loss_cls: 0.184  loss_box_reg: 0.348  loss_rpn_cls: 0.011  loss_rpn_loc: 0.060  time: 1.0253  data_time: 0.0079  lr: 0.003297  max_mem: 5394M
[32m[04/28 05:24:40 d2.utils.events]: [0m eta: 0:05:30  iter: 679  total_loss: 0.487  loss_cls: 0.151  loss_box_reg: 0.270  loss_rpn_cls: 0.009  loss_rpn_loc: 0.052  time: 1.0258  data_time: 0.0078  lr: 0.003397  max_mem: 5394M
[32m[04/28 05:25:00 d2.utils.events]: [0m eta: 0:05:10  iter: 699  total_loss: 0.479  loss_cls: 0.161  loss_box_reg: 0.277  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 1.0259  data_time: 0.0078  lr: 0.003497  max_mem: 5394M
[32m[04/28 05:25:21 d2.utils.events]: [0m eta: 0:04:49  iter: 719  total_loss: 0.581  loss_cls: 0.187  loss_box_reg: 0.323  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0260  data_time: 0.0082  lr: 0.003596  max_mem: 5394M
[32m[04/28 05:25:41 d2.utils.events]: [0m eta: 0:04:28  iter: 739  total_loss: 0.519  loss_cls: 0.154  loss_box_reg: 0.305  loss_rpn_cls: 0.008  loss_rpn_loc: 0.060  time: 1.0255  data_time: 0.0075  lr: 0.003696  max_mem: 5394M
[32m[04/28 05:26:02 d2.utils.events]: [0m eta: 0:04:07  iter: 759  total_loss: 0.590  loss_cls: 0.182  loss_box_reg: 0.332  loss_rpn_cls: 0.008  loss_rpn_loc: 0.053  time: 1.0257  data_time: 0.0075  lr: 0.003796  max_mem: 5394M
[32m[04/28 05:26:22 d2.utils.events]: [0m eta: 0:03:47  iter: 779  total_loss: 0.585  loss_cls: 0.184  loss_box_reg: 0.333  loss_rpn_cls: 0.009  loss_rpn_loc: 0.048  time: 1.0252  data_time: 0.0077  lr: 0.003896  max_mem: 5394M
[32m[04/28 05:26:43 d2.utils.events]: [0m eta: 0:03:26  iter: 799  total_loss: 0.552  loss_cls: 0.166  loss_box_reg: 0.305  loss_rpn_cls: 0.008  loss_rpn_loc: 0.043  time: 1.0259  data_time: 0.0078  lr: 0.003996  max_mem: 5394M
[32m[04/28 05:27:04 d2.utils.events]: [0m eta: 0:03:06  iter: 819  total_loss: 0.602  loss_cls: 0.183  loss_box_reg: 0.351  loss_rpn_cls: 0.009  loss_rpn_loc: 0.048  time: 1.0263  data_time: 0.0078  lr: 0.004096  max_mem: 5394M
[32m[04/28 05:27:25 d2.utils.events]: [0m eta: 0:02:45  iter: 839  total_loss: 0.632  loss_cls: 0.191  loss_box_reg: 0.364  loss_rpn_cls: 0.010  loss_rpn_loc: 0.054  time: 1.0264  data_time: 0.0075  lr: 0.004196  max_mem: 5394M
[32m[04/28 05:27:45 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.586  loss_cls: 0.179  loss_box_reg: 0.321  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0266  data_time: 0.0076  lr: 0.004296  max_mem: 5394M
[32m[04/28 05:28:06 d2.utils.events]: [0m eta: 0:02:04  iter: 879  total_loss: 0.609  loss_cls: 0.184  loss_box_reg: 0.366  loss_rpn_cls: 0.008  loss_rpn_loc: 0.047  time: 1.0265  data_time: 0.0077  lr: 0.004396  max_mem: 5394M
[32m[04/28 05:28:27 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.597  loss_cls: 0.188  loss_box_reg: 0.334  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 1.0267  data_time: 0.0075  lr: 0.004496  max_mem: 5394M
[32m[04/28 05:28:47 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.559  loss_cls: 0.171  loss_box_reg: 0.330  loss_rpn_cls: 0.016  loss_rpn_loc: 0.046  time: 1.0260  data_time: 0.0078  lr: 0.004595  max_mem: 5394M
[32m[04/28 05:29:07 d2.utils.events]: [0m eta: 0:01:02  iter: 939  total_loss: 0.588  loss_cls: 0.188  loss_box_reg: 0.344  loss_rpn_cls: 0.014  loss_rpn_loc: 0.065  time: 1.0261  data_time: 0.0076  lr: 0.004695  max_mem: 5394M
[32m[04/28 05:29:28 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.508  loss_cls: 0.155  loss_box_reg: 0.312  loss_rpn_cls: 0.011  loss_rpn_loc: 0.045  time: 1.0267  data_time: 0.0076  lr: 0.004795  max_mem: 5394M
[32m[04/28 05:29:49 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.560  loss_cls: 0.175  loss_box_reg: 0.317  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 1.0265  data_time: 0.0082  lr: 0.004895  max_mem: 5394M
[5m[31mWARNING[0m [32m[04/28 05:30:12 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 05:30:12 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 05:30:12 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 05:30:12 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.538  loss_cls: 0.174  loss_box_reg: 0.322  loss_rpn_cls: 0.009  loss_rpn_loc: 0.046  time: 1.0261  data_time: 0.0075  lr: 0.004995  max_mem: 5394M
[32m[04/28 05:30:12 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:04 (1.0272 s / it)
[32m[04/28 05:30:12 d2.engine.hooks]: [0mTotal training time: 0:17:09 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 05:30:13 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 05:30:13 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 05:30:14 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 05:30:15 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1142 s / img. ETA=0:16:04
[32m[04/28 05:30:20 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1143 s / img. ETA=0:16:03
[32m[04/28 05:30:25 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1141 s / img. ETA=0:15:55
[32m[04/28 05:30:30 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1140 s / img. ETA=0:15:50
[32m[04/28 05:30:35 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1140 s / img. ETA=0:15:45
[32m[04/28 05:30:41 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1140 s / img. ETA=0:15:40
[32m[04/28 05:30:46 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1140 s / img. ETA=0:15:35
[32m[04/28 05:30:51 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1140 s / img. ETA=0:15:30
[32m[04/28 05:30:56 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1140 s / img. ETA=0:15:25
[32m[04/28 05:31:01 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1141 s / img. ETA=0:15:20
[32m[04/28 05:31:06 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1141 s / img. ETA=0:15:15
[32m[04/28 05:31:11 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1140 s / img. ETA=0:15:10
[32m[04/28 05:31:16 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1140 s / img. ETA=0:15:04
[32m[04/28 05:31:21 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1141 s / img. ETA=0:15:00
[32m[04/28 05:31:26 d2.evaluation.evaluator]: [0mInference done 626/8355. 0.1141 s / img. ETA=0:14:55
[32m[04/28 05:31:31 d2.evaluation.evaluator]: [0mInference done 669/8355. 0.1142 s / img. ETA=0:14:51
[32m[04/28 05:31:36 d2.evaluation.evaluator]: [0mInference done 713/8355. 0.1142 s / img. ETA=0:14:45
[32m[04/28 05:31:42 d2.evaluation.evaluator]: [0mInference done 757/8355. 0.1142 s / img. ETA=0:14:41
[32m[04/28 05:31:47 d2.evaluation.evaluator]: [0mInference done 800/8355. 0.1142 s / img. ETA=0:14:36
[32m[04/28 05:31:52 d2.evaluation.evaluator]: [0mInference done 844/8355. 0.1142 s / img. ETA=0:14:31
[32m[04/28 05:31:57 d2.evaluation.evaluator]: [0mInference done 887/8355. 0.1143 s / img. ETA=0:14:26
[32m[04/28 05:32:02 d2.evaluation.evaluator]: [0mInference done 930/8355. 0.1144 s / img. ETA=0:14:22
[32m[04/28 05:32:07 d2.evaluation.evaluator]: [0mInference done 974/8355. 0.1143 s / img. ETA=0:14:17
[32m[04/28 05:32:12 d2.evaluation.evaluator]: [0mInference done 1017/8355. 0.1144 s / img. ETA=0:14:12
[32m[04/28 05:32:17 d2.evaluation.evaluator]: [0mInference done 1061/8355. 0.1144 s / img. ETA=0:14:07
[32m[04/28 05:32:22 d2.evaluation.evaluator]: [0mInference done 1105/8355. 0.1144 s / img. ETA=0:14:02
[32m[04/28 05:32:27 d2.evaluation.evaluator]: [0mInference done 1149/8355. 0.1144 s / img. ETA=0:13:56
[32m[04/28 05:32:32 d2.evaluation.evaluator]: [0mInference done 1193/8355. 0.1144 s / img. ETA=0:13:51
[32m[04/28 05:32:37 d2.evaluation.evaluator]: [0mInference done 1237/8355. 0.1143 s / img. ETA=0:13:46
[32m[04/28 05:32:42 d2.evaluation.evaluator]: [0mInference done 1281/8355. 0.1143 s / img. ETA=0:13:41
[32m[04/28 05:32:48 d2.evaluation.evaluator]: [0mInference done 1325/8355. 0.1143 s / img. ETA=0:13:35
[32m[04/28 05:32:53 d2.evaluation.evaluator]: [0mInference done 1369/8355. 0.1143 s / img. ETA=0:13:30
[32m[04/28 05:32:58 d2.evaluation.evaluator]: [0mInference done 1412/8355. 0.1143 s / img. ETA=0:13:25
[32m[04/28 05:33:03 d2.evaluation.evaluator]: [0mInference done 1456/8355. 0.1143 s / img. ETA=0:13:20
[32m[04/28 05:33:08 d2.evaluation.evaluator]: [0mInference done 1499/8355. 0.1144 s / img. ETA=0:13:16
[32m[04/28 05:33:13 d2.evaluation.evaluator]: [0mInference done 1542/8355. 0.1144 s / img. ETA=0:13:11
[32m[04/28 05:33:18 d2.evaluation.evaluator]: [0mInference done 1585/8355. 0.1144 s / img. ETA=0:13:06
[32m[04/28 05:33:23 d2.evaluation.evaluator]: [0mInference done 1628/8355. 0.1145 s / img. ETA=0:13:01
[32m[04/28 05:33:28 d2.evaluation.evaluator]: [0mInference done 1670/8355. 0.1145 s / img. ETA=0:12:57
[32m[04/28 05:33:33 d2.evaluation.evaluator]: [0mInference done 1713/8355. 0.1146 s / img. ETA=0:12:52
[32m[04/28 05:33:38 d2.evaluation.evaluator]: [0mInference done 1756/8355. 0.1146 s / img. ETA=0:12:47
[32m[04/28 05:33:43 d2.evaluation.evaluator]: [0mInference done 1799/8355. 0.1146 s / img. ETA=0:12:43
[32m[04/28 05:33:48 d2.evaluation.evaluator]: [0mInference done 1842/8355. 0.1147 s / img. ETA=0:12:38
[32m[04/28 05:33:53 d2.evaluation.evaluator]: [0mInference done 1885/8355. 0.1147 s / img. ETA=0:12:33
[32m[04/28 05:33:58 d2.evaluation.evaluator]: [0mInference done 1928/8355. 0.1147 s / img. ETA=0:12:28
[32m[04/28 05:34:03 d2.evaluation.evaluator]: [0mInference done 1971/8355. 0.1148 s / img. ETA=0:12:23
[32m[04/28 05:34:09 d2.evaluation.evaluator]: [0mInference done 2014/8355. 0.1148 s / img. ETA=0:12:19
[32m[04/28 05:34:14 d2.evaluation.evaluator]: [0mInference done 2057/8355. 0.1148 s / img. ETA=0:12:14
[32m[04/28 05:34:19 d2.evaluation.evaluator]: [0mInference done 2100/8355. 0.1148 s / img. ETA=0:12:09
[32m[04/28 05:34:24 d2.evaluation.evaluator]: [0mInference done 2143/8355. 0.1148 s / img. ETA=0:12:04
[32m[04/28 05:34:29 d2.evaluation.evaluator]: [0mInference done 2186/8355. 0.1148 s / img. ETA=0:11:59
[32m[04/28 05:34:34 d2.evaluation.evaluator]: [0mInference done 2229/8355. 0.1148 s / img. ETA=0:11:54
[32m[04/28 05:34:39 d2.evaluation.evaluator]: [0mInference done 2272/8355. 0.1148 s / img. ETA=0:11:49
[32m[04/28 05:34:44 d2.evaluation.evaluator]: [0mInference done 2315/8355. 0.1148 s / img. ETA=0:11:44
[32m[04/28 05:34:49 d2.evaluation.evaluator]: [0mInference done 2358/8355. 0.1148 s / img. ETA=0:11:39
[32m[04/28 05:34:54 d2.evaluation.evaluator]: [0mInference done 2401/8355. 0.1148 s / img. ETA=0:11:34
[32m[04/28 05:34:59 d2.evaluation.evaluator]: [0mInference done 2444/8355. 0.1149 s / img. ETA=0:11:29
[32m[04/28 05:35:04 d2.evaluation.evaluator]: [0mInference done 2487/8355. 0.1149 s / img. ETA=0:11:24
[32m[04/28 05:35:09 d2.evaluation.evaluator]: [0mInference done 2530/8355. 0.1149 s / img. ETA=0:11:19
[32m[04/28 05:35:14 d2.evaluation.evaluator]: [0mInference done 2573/8355. 0.1149 s / img. ETA=0:11:14
[32m[04/28 05:35:19 d2.evaluation.evaluator]: [0mInference done 2616/8355. 0.1149 s / img. ETA=0:11:09
[32m[04/28 05:35:24 d2.evaluation.evaluator]: [0mInference done 2658/8355. 0.1149 s / img. ETA=0:11:04
[32m[04/28 05:35:29 d2.evaluation.evaluator]: [0mInference done 2701/8355. 0.1149 s / img. ETA=0:10:59
[32m[04/28 05:35:34 d2.evaluation.evaluator]: [0mInference done 2744/8355. 0.1149 s / img. ETA=0:10:55
[32m[04/28 05:35:39 d2.evaluation.evaluator]: [0mInference done 2787/8355. 0.1149 s / img. ETA=0:10:50
[32m[04/28 05:35:44 d2.evaluation.evaluator]: [0mInference done 2830/8355. 0.1149 s / img. ETA=0:10:45
[32m[04/28 05:35:49 d2.evaluation.evaluator]: [0mInference done 2873/8355. 0.1150 s / img. ETA=0:10:40
[32m[04/28 05:35:54 d2.evaluation.evaluator]: [0mInference done 2916/8355. 0.1150 s / img. ETA=0:10:35
[32m[04/28 05:35:59 d2.evaluation.evaluator]: [0mInference done 2959/8355. 0.1150 s / img. ETA=0:10:30
[32m[04/28 05:36:05 d2.evaluation.evaluator]: [0mInference done 3002/8355. 0.1150 s / img. ETA=0:10:25
[32m[04/28 05:36:10 d2.evaluation.evaluator]: [0mInference done 3046/8355. 0.1150 s / img. ETA=0:10:20
[32m[04/28 05:36:15 d2.evaluation.evaluator]: [0mInference done 3089/8355. 0.1150 s / img. ETA=0:10:15
[32m[04/28 05:36:20 d2.evaluation.evaluator]: [0mInference done 3133/8355. 0.1150 s / img. ETA=0:10:09
[32m[04/28 05:36:25 d2.evaluation.evaluator]: [0mInference done 3177/8355. 0.1150 s / img. ETA=0:10:04
[32m[04/28 05:36:30 d2.evaluation.evaluator]: [0mInference done 3221/8355. 0.1150 s / img. ETA=0:09:59
[32m[04/28 05:36:35 d2.evaluation.evaluator]: [0mInference done 3264/8355. 0.1149 s / img. ETA=0:09:54
[32m[04/28 05:36:40 d2.evaluation.evaluator]: [0mInference done 3308/8355. 0.1149 s / img. ETA=0:09:49
[32m[04/28 05:36:45 d2.evaluation.evaluator]: [0mInference done 3352/8355. 0.1149 s / img. ETA=0:09:43
[32m[04/28 05:36:50 d2.evaluation.evaluator]: [0mInference done 3395/8355. 0.1149 s / img. ETA=0:09:38
[32m[04/28 05:36:55 d2.evaluation.evaluator]: [0mInference done 3439/8355. 0.1149 s / img. ETA=0:09:33
[32m[04/28 05:37:00 d2.evaluation.evaluator]: [0mInference done 3482/8355. 0.1149 s / img. ETA=0:09:28
[32m[04/28 05:37:05 d2.evaluation.evaluator]: [0mInference done 3525/8355. 0.1149 s / img. ETA=0:09:23
[32m[04/28 05:37:10 d2.evaluation.evaluator]: [0mInference done 3568/8355. 0.1149 s / img. ETA=0:09:18
[32m[04/28 05:37:15 d2.evaluation.evaluator]: [0mInference done 3611/8355. 0.1149 s / img. ETA=0:09:13
[32m[04/28 05:37:20 d2.evaluation.evaluator]: [0mInference done 3654/8355. 0.1149 s / img. ETA=0:09:08
[32m[04/28 05:37:25 d2.evaluation.evaluator]: [0mInference done 3697/8355. 0.1149 s / img. ETA=0:09:03
[32m[04/28 05:37:30 d2.evaluation.evaluator]: [0mInference done 3740/8355. 0.1149 s / img. ETA=0:08:58
[32m[04/28 05:37:35 d2.evaluation.evaluator]: [0mInference done 3784/8355. 0.1149 s / img. ETA=0:08:53
[32m[04/28 05:37:40 d2.evaluation.evaluator]: [0mInference done 3827/8355. 0.1149 s / img. ETA=0:08:48
[32m[04/28 05:37:45 d2.evaluation.evaluator]: [0mInference done 3870/8355. 0.1149 s / img. ETA=0:08:43
[32m[04/28 05:37:51 d2.evaluation.evaluator]: [0mInference done 3914/8355. 0.1149 s / img. ETA=0:08:38
[32m[04/28 05:37:56 d2.evaluation.evaluator]: [0mInference done 3958/8355. 0.1149 s / img. ETA=0:08:33
[32m[04/28 05:38:01 d2.evaluation.evaluator]: [0mInference done 4002/8355. 0.1149 s / img. ETA=0:08:27
[32m[04/28 05:38:06 d2.evaluation.evaluator]: [0mInference done 4045/8355. 0.1149 s / img. ETA=0:08:22
[32m[04/28 05:38:11 d2.evaluation.evaluator]: [0mInference done 4088/8355. 0.1149 s / img. ETA=0:08:17
[32m[04/28 05:38:16 d2.evaluation.evaluator]: [0mInference done 4131/8355. 0.1149 s / img. ETA=0:08:13
[32m[04/28 05:38:21 d2.evaluation.evaluator]: [0mInference done 4174/8355. 0.1149 s / img. ETA=0:08:07
[32m[04/28 05:38:26 d2.evaluation.evaluator]: [0mInference done 4217/8355. 0.1149 s / img. ETA=0:08:02
[32m[04/28 05:38:31 d2.evaluation.evaluator]: [0mInference done 4260/8355. 0.1149 s / img. ETA=0:07:57
[32m[04/28 05:38:36 d2.evaluation.evaluator]: [0mInference done 4303/8355. 0.1149 s / img. ETA=0:07:52
[32m[04/28 05:38:41 d2.evaluation.evaluator]: [0mInference done 4346/8355. 0.1149 s / img. ETA=0:07:47
[32m[04/28 05:38:46 d2.evaluation.evaluator]: [0mInference done 4389/8355. 0.1149 s / img. ETA=0:07:42
[32m[04/28 05:38:51 d2.evaluation.evaluator]: [0mInference done 4432/8355. 0.1149 s / img. ETA=0:07:37
[32m[04/28 05:38:56 d2.evaluation.evaluator]: [0mInference done 4475/8355. 0.1149 s / img. ETA=0:07:32
[32m[04/28 05:39:01 d2.evaluation.evaluator]: [0mInference done 4518/8355. 0.1149 s / img. ETA=0:07:27
[32m[04/28 05:39:06 d2.evaluation.evaluator]: [0mInference done 4561/8355. 0.1149 s / img. ETA=0:07:22
[32m[04/28 05:39:11 d2.evaluation.evaluator]: [0mInference done 4604/8355. 0.1149 s / img. ETA=0:07:17
[32m[04/28 05:39:16 d2.evaluation.evaluator]: [0mInference done 4647/8355. 0.1149 s / img. ETA=0:07:12
[32m[04/28 05:39:21 d2.evaluation.evaluator]: [0mInference done 4691/8355. 0.1149 s / img. ETA=0:07:07
[32m[04/28 05:39:26 d2.evaluation.evaluator]: [0mInference done 4735/8355. 0.1149 s / img. ETA=0:07:02
[32m[04/28 05:39:31 d2.evaluation.evaluator]: [0mInference done 4778/8355. 0.1149 s / img. ETA=0:06:57
[32m[04/28 05:39:37 d2.evaluation.evaluator]: [0mInference done 4821/8355. 0.1149 s / img. ETA=0:06:52
[32m[04/28 05:39:42 d2.evaluation.evaluator]: [0mInference done 4864/8355. 0.1149 s / img. ETA=0:06:47
[32m[04/28 05:39:47 d2.evaluation.evaluator]: [0mInference done 4908/8355. 0.1149 s / img. ETA=0:06:42
[32m[04/28 05:39:52 d2.evaluation.evaluator]: [0mInference done 4951/8355. 0.1149 s / img. ETA=0:06:37
[32m[04/28 05:39:57 d2.evaluation.evaluator]: [0mInference done 4995/8355. 0.1149 s / img. ETA=0:06:32
[32m[04/28 05:40:02 d2.evaluation.evaluator]: [0mInference done 5038/8355. 0.1149 s / img. ETA=0:06:27
[32m[04/28 05:40:07 d2.evaluation.evaluator]: [0mInference done 5081/8355. 0.1149 s / img. ETA=0:06:22
[32m[04/28 05:40:12 d2.evaluation.evaluator]: [0mInference done 5124/8355. 0.1149 s / img. ETA=0:06:17
[32m[04/28 05:40:17 d2.evaluation.evaluator]: [0mInference done 5167/8355. 0.1149 s / img. ETA=0:06:12
[32m[04/28 05:40:22 d2.evaluation.evaluator]: [0mInference done 5210/8355. 0.1149 s / img. ETA=0:06:07
[32m[04/28 05:40:27 d2.evaluation.evaluator]: [0mInference done 5253/8355. 0.1149 s / img. ETA=0:06:02
[32m[04/28 05:40:32 d2.evaluation.evaluator]: [0mInference done 5296/8355. 0.1149 s / img. ETA=0:05:57
[32m[04/28 05:40:37 d2.evaluation.evaluator]: [0mInference done 5339/8355. 0.1149 s / img. ETA=0:05:52
[32m[04/28 05:40:42 d2.evaluation.evaluator]: [0mInference done 5382/8355. 0.1149 s / img. ETA=0:05:46
[32m[04/28 05:40:47 d2.evaluation.evaluator]: [0mInference done 5425/8355. 0.1149 s / img. ETA=0:05:41
[32m[04/28 05:40:52 d2.evaluation.evaluator]: [0mInference done 5468/8355. 0.1149 s / img. ETA=0:05:36
[32m[04/28 05:40:57 d2.evaluation.evaluator]: [0mInference done 5511/8355. 0.1149 s / img. ETA=0:05:31
[32m[04/28 05:41:02 d2.evaluation.evaluator]: [0mInference done 5555/8355. 0.1149 s / img. ETA=0:05:26
[32m[04/28 05:41:07 d2.evaluation.evaluator]: [0mInference done 5599/8355. 0.1149 s / img. ETA=0:05:21
[32m[04/28 05:41:12 d2.evaluation.evaluator]: [0mInference done 5642/8355. 0.1149 s / img. ETA=0:05:16
[32m[04/28 05:41:17 d2.evaluation.evaluator]: [0mInference done 5685/8355. 0.1149 s / img. ETA=0:05:11
[32m[04/28 05:41:22 d2.evaluation.evaluator]: [0mInference done 5728/8355. 0.1149 s / img. ETA=0:05:06
[32m[04/28 05:41:27 d2.evaluation.evaluator]: [0mInference done 5771/8355. 0.1149 s / img. ETA=0:05:01
[32m[04/28 05:41:32 d2.evaluation.evaluator]: [0mInference done 5814/8355. 0.1149 s / img. ETA=0:04:56
[32m[04/28 05:41:37 d2.evaluation.evaluator]: [0mInference done 5857/8355. 0.1149 s / img. ETA=0:04:51
[32m[04/28 05:41:42 d2.evaluation.evaluator]: [0mInference done 5900/8355. 0.1149 s / img. ETA=0:04:46
[32m[04/28 05:41:47 d2.evaluation.evaluator]: [0mInference done 5943/8355. 0.1149 s / img. ETA=0:04:41
[32m[04/28 05:41:53 d2.evaluation.evaluator]: [0mInference done 5986/8355. 0.1149 s / img. ETA=0:04:36
[32m[04/28 05:41:58 d2.evaluation.evaluator]: [0mInference done 6029/8355. 0.1149 s / img. ETA=0:04:31
[32m[04/28 05:42:03 d2.evaluation.evaluator]: [0mInference done 6072/8355. 0.1149 s / img. ETA=0:04:26
[32m[04/28 05:42:08 d2.evaluation.evaluator]: [0mInference done 6115/8355. 0.1149 s / img. ETA=0:04:21
[32m[04/28 05:42:13 d2.evaluation.evaluator]: [0mInference done 6158/8355. 0.1149 s / img. ETA=0:04:16
[32m[04/28 05:42:18 d2.evaluation.evaluator]: [0mInference done 6201/8355. 0.1149 s / img. ETA=0:04:11
[32m[04/28 05:42:23 d2.evaluation.evaluator]: [0mInference done 6244/8355. 0.1149 s / img. ETA=0:04:06
[32m[04/28 05:42:28 d2.evaluation.evaluator]: [0mInference done 6287/8355. 0.1149 s / img. ETA=0:04:01
[32m[04/28 05:42:33 d2.evaluation.evaluator]: [0mInference done 6330/8355. 0.1150 s / img. ETA=0:03:56
[32m[04/28 05:42:38 d2.evaluation.evaluator]: [0mInference done 6373/8355. 0.1150 s / img. ETA=0:03:51
[32m[04/28 05:42:43 d2.evaluation.evaluator]: [0mInference done 6416/8355. 0.1150 s / img. ETA=0:03:46
[32m[04/28 05:42:48 d2.evaluation.evaluator]: [0mInference done 6459/8355. 0.1150 s / img. ETA=0:03:41
[32m[04/28 05:42:53 d2.evaluation.evaluator]: [0mInference done 6502/8355. 0.1150 s / img. ETA=0:03:36
[32m[04/28 05:42:58 d2.evaluation.evaluator]: [0mInference done 6546/8355. 0.1150 s / img. ETA=0:03:31
[32m[04/28 05:43:03 d2.evaluation.evaluator]: [0mInference done 6589/8355. 0.1150 s / img. ETA=0:03:26
[32m[04/28 05:43:08 d2.evaluation.evaluator]: [0mInference done 6632/8355. 0.1150 s / img. ETA=0:03:21
[32m[04/28 05:43:13 d2.evaluation.evaluator]: [0mInference done 6675/8355. 0.1150 s / img. ETA=0:03:16
[32m[04/28 05:43:19 d2.evaluation.evaluator]: [0mInference done 6719/8355. 0.1149 s / img. ETA=0:03:11
[32m[04/28 05:43:24 d2.evaluation.evaluator]: [0mInference done 6762/8355. 0.1149 s / img. ETA=0:03:06
[32m[04/28 05:43:29 d2.evaluation.evaluator]: [0mInference done 6805/8355. 0.1149 s / img. ETA=0:03:01
[32m[04/28 05:43:34 d2.evaluation.evaluator]: [0mInference done 6848/8355. 0.1149 s / img. ETA=0:02:56
[32m[04/28 05:43:39 d2.evaluation.evaluator]: [0mInference done 6892/8355. 0.1149 s / img. ETA=0:02:50
[32m[04/28 05:43:44 d2.evaluation.evaluator]: [0mInference done 6935/8355. 0.1149 s / img. ETA=0:02:45
[32m[04/28 05:43:49 d2.evaluation.evaluator]: [0mInference done 6978/8355. 0.1149 s / img. ETA=0:02:40
[32m[04/28 05:43:54 d2.evaluation.evaluator]: [0mInference done 7021/8355. 0.1149 s / img. ETA=0:02:35
[32m[04/28 05:43:59 d2.evaluation.evaluator]: [0mInference done 7064/8355. 0.1149 s / img. ETA=0:02:30
[32m[04/28 05:44:04 d2.evaluation.evaluator]: [0mInference done 7107/8355. 0.1150 s / img. ETA=0:02:25
[32m[04/28 05:44:09 d2.evaluation.evaluator]: [0mInference done 7150/8355. 0.1150 s / img. ETA=0:02:20
[32m[04/28 05:44:14 d2.evaluation.evaluator]: [0mInference done 7192/8355. 0.1150 s / img. ETA=0:02:15
[32m[04/28 05:44:19 d2.evaluation.evaluator]: [0mInference done 7235/8355. 0.1150 s / img. ETA=0:02:10
[32m[04/28 05:44:24 d2.evaluation.evaluator]: [0mInference done 7278/8355. 0.1150 s / img. ETA=0:02:05
[32m[04/28 05:44:29 d2.evaluation.evaluator]: [0mInference done 7321/8355. 0.1150 s / img. ETA=0:02:00
[32m[04/28 05:44:34 d2.evaluation.evaluator]: [0mInference done 7364/8355. 0.1150 s / img. ETA=0:01:55
[32m[04/28 05:44:39 d2.evaluation.evaluator]: [0mInference done 7407/8355. 0.1150 s / img. ETA=0:01:50
[32m[04/28 05:44:44 d2.evaluation.evaluator]: [0mInference done 7449/8355. 0.1150 s / img. ETA=0:01:45
[32m[04/28 05:44:49 d2.evaluation.evaluator]: [0mInference done 7492/8355. 0.1150 s / img. ETA=0:01:40
[32m[04/28 05:44:54 d2.evaluation.evaluator]: [0mInference done 7535/8355. 0.1150 s / img. ETA=0:01:35
[32m[04/28 05:44:59 d2.evaluation.evaluator]: [0mInference done 7578/8355. 0.1150 s / img. ETA=0:01:30
[32m[04/28 05:45:04 d2.evaluation.evaluator]: [0mInference done 7621/8355. 0.1150 s / img. ETA=0:01:25
[32m[04/28 05:45:10 d2.evaluation.evaluator]: [0mInference done 7664/8355. 0.1150 s / img. ETA=0:01:20
[32m[04/28 05:45:15 d2.evaluation.evaluator]: [0mInference done 7707/8355. 0.1150 s / img. ETA=0:01:15
[32m[04/28 05:45:20 d2.evaluation.evaluator]: [0mInference done 7750/8355. 0.1150 s / img. ETA=0:01:10
[32m[04/28 05:45:25 d2.evaluation.evaluator]: [0mInference done 7793/8355. 0.1150 s / img. ETA=0:01:05
[32m[04/28 05:45:30 d2.evaluation.evaluator]: [0mInference done 7836/8355. 0.1150 s / img. ETA=0:01:00
[32m[04/28 05:45:35 d2.evaluation.evaluator]: [0mInference done 7876/8355. 0.1151 s / img. ETA=0:00:56
[32m[04/28 05:45:40 d2.evaluation.evaluator]: [0mInference done 7919/8355. 0.1151 s / img. ETA=0:00:50
[32m[04/28 05:45:45 d2.evaluation.evaluator]: [0mInference done 7962/8355. 0.1151 s / img. ETA=0:00:45
[32m[04/28 05:45:50 d2.evaluation.evaluator]: [0mInference done 8005/8355. 0.1151 s / img. ETA=0:00:40
[32m[04/28 05:45:55 d2.evaluation.evaluator]: [0mInference done 8048/8355. 0.1151 s / img. ETA=0:00:35
[32m[04/28 05:46:00 d2.evaluation.evaluator]: [0mInference done 8091/8355. 0.1151 s / img. ETA=0:00:30
[32m[04/28 05:46:05 d2.evaluation.evaluator]: [0mInference done 8135/8355. 0.1151 s / img. ETA=0:00:25
[32m[04/28 05:46:10 d2.evaluation.evaluator]: [0mInference done 8179/8355. 0.1151 s / img. ETA=0:00:20
[32m[04/28 05:46:15 d2.evaluation.evaluator]: [0mInference done 8222/8355. 0.1151 s / img. ETA=0:00:15
[32m[04/28 05:46:20 d2.evaluation.evaluator]: [0mInference done 8265/8355. 0.1151 s / img. ETA=0:00:10
[32m[04/28 05:46:25 d2.evaluation.evaluator]: [0mInference done 8308/8355. 0.1151 s / img. ETA=0:00:05
[32m[04/28 05:46:30 d2.evaluation.evaluator]: [0mInference done 8351/8355. 0.1151 s / img. ETA=0:00:00
[32m[04/28 05:46:31 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:16.630837 (0.116962 s / img per device, on 1 devices)
[32m[04/28 05:46:31 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:01 (0.115097 s / img per device, on 1 devices)
[32m[04/28 05:46:31 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 05:46:31 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 05:46:32 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.09s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=21.99s).
Accumulating evaluation results...
DONE (t=2.46s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.833
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.428
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.356
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.566
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.172
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.508
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.448
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729
[32m[04/28 05:46:56 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.325 | 83.279 | 42.824 | 35.642 | 56.600 | 68.827 |
[32m[04/28 05:46:56 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 45.806 | bicycle       | 35.184 | car            | 54.987 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 05:46:57 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 05:46:57 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 05:46:57 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 05:46:58 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1146 s / img. ETA=0:02:24
[32m[04/28 05:47:03 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1146 s / img. ETA=0:02:20
[32m[04/28 05:47:08 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1148 s / img. ETA=0:02:15
[32m[04/28 05:47:13 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1147 s / img. ETA=0:02:10
[32m[04/28 05:47:18 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1148 s / img. ETA=0:02:05
[32m[04/28 05:47:23 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1148 s / img. ETA=0:02:00
[32m[04/28 05:47:28 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1148 s / img. ETA=0:01:55
[32m[04/28 05:47:33 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1148 s / img. ETA=0:01:50
[32m[04/28 05:47:38 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1148 s / img. ETA=0:01:45
[32m[04/28 05:47:43 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1148 s / img. ETA=0:01:40
[32m[04/28 05:47:48 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1148 s / img. ETA=0:01:35
[32m[04/28 05:47:53 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1147 s / img. ETA=0:01:30
[32m[04/28 05:47:58 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1148 s / img. ETA=0:01:25
[32m[04/28 05:48:03 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1148 s / img. ETA=0:01:20
[32m[04/28 05:48:08 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1148 s / img. ETA=0:01:15
[32m[04/28 05:48:13 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1148 s / img. ETA=0:01:10
[32m[04/28 05:48:19 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1148 s / img. ETA=0:01:05
[32m[04/28 05:48:24 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1149 s / img. ETA=0:01:00
[32m[04/28 05:48:29 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1148 s / img. ETA=0:00:55
[32m[04/28 05:48:34 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1149 s / img. ETA=0:00:50
[32m[04/28 05:48:39 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1149 s / img. ETA=0:00:45
[32m[04/28 05:48:44 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1150 s / img. ETA=0:00:40
[32m[04/28 05:48:49 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1150 s / img. ETA=0:00:35
[32m[04/28 05:48:54 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1150 s / img. ETA=0:00:30
[32m[04/28 05:48:59 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1150 s / img. ETA=0:00:25
[32m[04/28 05:49:04 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1150 s / img. ETA=0:00:20
[32m[04/28 05:49:09 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1151 s / img. ETA=0:00:14
[32m[04/28 05:49:14 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1151 s / img. ETA=0:00:09
[32m[04/28 05:49:19 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1151 s / img. ETA=0:00:04
[32m[04/28 05:49:24 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.650439 (0.117133 s / img per device, on 1 devices)
[32m[04/28 05:49:24 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115136 s / img per device, on 1 devices)
[32m[04/28 05:49:24 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 05:49:24 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 05:49:24 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.46s).
Accumulating evaluation results...
DONE (t=0.44s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.408
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.773
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.374
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.313
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.464
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.529
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.487
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.426
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.537
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.574
[32m[04/28 05:49:28 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.846 | 77.270 | 37.385 | 31.275 | 46.438 | 52.893 |
[32m[04/28 05:49:28 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 44.986 | bicycle       | 22.569 | car            | 54.984 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  7  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 05:49:29 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 05:49:29 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 05:49:29 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 05:49:30 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 05:49:30 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 05:49:30 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 05:49:30 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 05:49:50 d2.utils.events]: [0m eta: 0:16:40  iter: 19  total_loss: 0.520  loss_cls: 0.162  loss_box_reg: 0.286  loss_rpn_cls: 0.011  loss_rpn_loc: 0.042  time: 1.0099  data_time: 0.0200  lr: 0.000100  max_mem: 5397M
[32m[04/28 05:50:10 d2.utils.events]: [0m eta: 0:15:59  iter: 39  total_loss: 0.556  loss_cls: 0.167  loss_box_reg: 0.317  loss_rpn_cls: 0.011  loss_rpn_loc: 0.058  time: 0.9962  data_time: 0.0078  lr: 0.000200  max_mem: 5397M
[32m[04/28 05:50:31 d2.utils.events]: [0m eta: 0:15:57  iter: 59  total_loss: 0.584  loss_cls: 0.173  loss_box_reg: 0.318  loss_rpn_cls: 0.009  loss_rpn_loc: 0.046  time: 1.0140  data_time: 0.0081  lr: 0.000300  max_mem: 5397M
[32m[04/28 05:50:52 d2.utils.events]: [0m eta: 0:15:46  iter: 79  total_loss: 0.525  loss_cls: 0.166  loss_box_reg: 0.321  loss_rpn_cls: 0.011  loss_rpn_loc: 0.035  time: 1.0215  data_time: 0.0086  lr: 0.000400  max_mem: 5397M
[32m[04/28 05:51:12 d2.utils.events]: [0m eta: 0:15:15  iter: 99  total_loss: 0.540  loss_cls: 0.171  loss_box_reg: 0.307  loss_rpn_cls: 0.012  loss_rpn_loc: 0.057  time: 1.0146  data_time: 0.0081  lr: 0.000500  max_mem: 5397M
[32m[04/28 05:51:32 d2.utils.events]: [0m eta: 0:15:00  iter: 119  total_loss: 0.579  loss_cls: 0.182  loss_box_reg: 0.335  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 1.0198  data_time: 0.0083  lr: 0.000599  max_mem: 5397M
[32m[04/28 05:51:53 d2.utils.events]: [0m eta: 0:14:42  iter: 139  total_loss: 0.580  loss_cls: 0.172  loss_box_reg: 0.337  loss_rpn_cls: 0.011  loss_rpn_loc: 0.051  time: 1.0206  data_time: 0.0081  lr: 0.000699  max_mem: 5397M
[32m[04/28 05:52:13 d2.utils.events]: [0m eta: 0:14:21  iter: 159  total_loss: 0.527  loss_cls: 0.159  loss_box_reg: 0.312  loss_rpn_cls: 0.010  loss_rpn_loc: 0.045  time: 1.0192  data_time: 0.0085  lr: 0.000799  max_mem: 5397M
[32m[04/28 05:52:33 d2.utils.events]: [0m eta: 0:13:58  iter: 179  total_loss: 0.583  loss_cls: 0.184  loss_box_reg: 0.342  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0177  data_time: 0.0083  lr: 0.000899  max_mem: 5397M
[32m[04/28 05:52:54 d2.utils.events]: [0m eta: 0:13:38  iter: 199  total_loss: 0.535  loss_cls: 0.162  loss_box_reg: 0.303  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 1.0179  data_time: 0.0081  lr: 0.000999  max_mem: 5397M
[32m[04/28 05:53:14 d2.utils.events]: [0m eta: 0:13:16  iter: 219  total_loss: 0.529  loss_cls: 0.165  loss_box_reg: 0.302  loss_rpn_cls: 0.011  loss_rpn_loc: 0.054  time: 1.0177  data_time: 0.0080  lr: 0.001099  max_mem: 5397M
[32m[04/28 05:53:35 d2.utils.events]: [0m eta: 0:12:58  iter: 239  total_loss: 0.470  loss_cls: 0.149  loss_box_reg: 0.283  loss_rpn_cls: 0.008  loss_rpn_loc: 0.035  time: 1.0185  data_time: 0.0082  lr: 0.001199  max_mem: 5397M
[32m[04/28 05:53:55 d2.utils.events]: [0m eta: 0:12:37  iter: 259  total_loss: 0.461  loss_cls: 0.146  loss_box_reg: 0.267  loss_rpn_cls: 0.009  loss_rpn_loc: 0.042  time: 1.0179  data_time: 0.0082  lr: 0.001299  max_mem: 5397M
[32m[04/28 05:54:16 d2.utils.events]: [0m eta: 0:12:19  iter: 279  total_loss: 0.596  loss_cls: 0.181  loss_box_reg: 0.345  loss_rpn_cls: 0.008  loss_rpn_loc: 0.058  time: 1.0198  data_time: 0.0080  lr: 0.001399  max_mem: 5397M
[32m[04/28 05:54:37 d2.utils.events]: [0m eta: 0:11:59  iter: 299  total_loss: 0.561  loss_cls: 0.185  loss_box_reg: 0.322  loss_rpn_cls: 0.009  loss_rpn_loc: 0.048  time: 1.0209  data_time: 0.0082  lr: 0.001499  max_mem: 5397M
[32m[04/28 05:54:57 d2.utils.events]: [0m eta: 0:11:39  iter: 319  total_loss: 0.549  loss_cls: 0.163  loss_box_reg: 0.317  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0209  data_time: 0.0080  lr: 0.001598  max_mem: 5397M
[32m[04/28 05:55:17 d2.utils.events]: [0m eta: 0:11:17  iter: 339  total_loss: 0.530  loss_cls: 0.152  loss_box_reg: 0.313  loss_rpn_cls: 0.007  loss_rpn_loc: 0.049  time: 1.0197  data_time: 0.0075  lr: 0.001698  max_mem: 5397M
[32m[04/28 05:55:38 d2.utils.events]: [0m eta: 0:10:57  iter: 359  total_loss: 0.618  loss_cls: 0.189  loss_box_reg: 0.351  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 1.0203  data_time: 0.0080  lr: 0.001798  max_mem: 5397M
[32m[04/28 05:55:58 d2.utils.events]: [0m eta: 0:10:36  iter: 379  total_loss: 0.500  loss_cls: 0.155  loss_box_reg: 0.290  loss_rpn_cls: 0.009  loss_rpn_loc: 0.043  time: 1.0197  data_time: 0.0080  lr: 0.001898  max_mem: 5397M
[32m[04/28 05:56:19 d2.utils.events]: [0m eta: 0:10:16  iter: 399  total_loss: 0.543  loss_cls: 0.168  loss_box_reg: 0.325  loss_rpn_cls: 0.010  loss_rpn_loc: 0.051  time: 1.0204  data_time: 0.0081  lr: 0.001998  max_mem: 5397M
[32m[04/28 05:56:40 d2.utils.events]: [0m eta: 0:09:55  iter: 419  total_loss: 0.444  loss_cls: 0.136  loss_box_reg: 0.251  loss_rpn_cls: 0.009  loss_rpn_loc: 0.033  time: 1.0206  data_time: 0.0077  lr: 0.002098  max_mem: 5397M
[32m[04/28 05:57:00 d2.utils.events]: [0m eta: 0:09:35  iter: 439  total_loss: 0.557  loss_cls: 0.170  loss_box_reg: 0.320  loss_rpn_cls: 0.007  loss_rpn_loc: 0.043  time: 1.0214  data_time: 0.0081  lr: 0.002198  max_mem: 5397M
[32m[04/28 05:57:22 d2.utils.events]: [0m eta: 0:09:16  iter: 459  total_loss: 0.548  loss_cls: 0.172  loss_box_reg: 0.315  loss_rpn_cls: 0.010  loss_rpn_loc: 0.058  time: 1.0229  data_time: 0.0078  lr: 0.002298  max_mem: 5397M
[32m[04/28 05:57:42 d2.utils.events]: [0m eta: 0:08:55  iter: 479  total_loss: 0.562  loss_cls: 0.175  loss_box_reg: 0.311  loss_rpn_cls: 0.008  loss_rpn_loc: 0.066  time: 1.0226  data_time: 0.0082  lr: 0.002398  max_mem: 5397M
[32m[04/28 05:58:03 d2.utils.events]: [0m eta: 0:08:35  iter: 499  total_loss: 0.527  loss_cls: 0.162  loss_box_reg: 0.306  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0237  data_time: 0.0079  lr: 0.002498  max_mem: 5397M
[32m[04/28 05:58:24 d2.utils.events]: [0m eta: 0:08:14  iter: 519  total_loss: 0.555  loss_cls: 0.161  loss_box_reg: 0.335  loss_rpn_cls: 0.008  loss_rpn_loc: 0.039  time: 1.0240  data_time: 0.0076  lr: 0.002597  max_mem: 5397M
[32m[04/28 05:58:44 d2.utils.events]: [0m eta: 0:07:54  iter: 539  total_loss: 0.547  loss_cls: 0.179  loss_box_reg: 0.321  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 1.0244  data_time: 0.0075  lr: 0.002697  max_mem: 5397M
[32m[04/28 05:59:05 d2.utils.events]: [0m eta: 0:07:34  iter: 559  total_loss: 0.465  loss_cls: 0.149  loss_box_reg: 0.276  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0248  data_time: 0.0079  lr: 0.002797  max_mem: 5397M
[32m[04/28 05:59:26 d2.utils.events]: [0m eta: 0:07:13  iter: 579  total_loss: 0.606  loss_cls: 0.185  loss_box_reg: 0.347  loss_rpn_cls: 0.009  loss_rpn_loc: 0.053  time: 1.0246  data_time: 0.0079  lr: 0.002897  max_mem: 5397M
[32m[04/28 05:59:47 d2.utils.events]: [0m eta: 0:06:53  iter: 599  total_loss: 0.532  loss_cls: 0.165  loss_box_reg: 0.292  loss_rpn_cls: 0.006  loss_rpn_loc: 0.051  time: 1.0257  data_time: 0.0080  lr: 0.002997  max_mem: 5397M
[32m[04/28 06:00:07 d2.utils.events]: [0m eta: 0:06:33  iter: 619  total_loss: 0.535  loss_cls: 0.168  loss_box_reg: 0.297  loss_rpn_cls: 0.013  loss_rpn_loc: 0.044  time: 1.0259  data_time: 0.0079  lr: 0.003097  max_mem: 5397M
[32m[04/28 06:00:28 d2.utils.events]: [0m eta: 0:06:13  iter: 639  total_loss: 0.610  loss_cls: 0.193  loss_box_reg: 0.327  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0264  data_time: 0.0079  lr: 0.003197  max_mem: 5397M
[32m[04/28 06:00:49 d2.utils.events]: [0m eta: 0:05:52  iter: 659  total_loss: 0.573  loss_cls: 0.183  loss_box_reg: 0.320  loss_rpn_cls: 0.012  loss_rpn_loc: 0.056  time: 1.0259  data_time: 0.0077  lr: 0.003297  max_mem: 5397M
[32m[04/28 06:01:09 d2.utils.events]: [0m eta: 0:05:31  iter: 679  total_loss: 0.522  loss_cls: 0.174  loss_box_reg: 0.294  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0262  data_time: 0.0076  lr: 0.003397  max_mem: 5397M
[32m[04/28 06:01:30 d2.utils.events]: [0m eta: 0:05:11  iter: 699  total_loss: 0.548  loss_cls: 0.176  loss_box_reg: 0.300  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 1.0267  data_time: 0.0078  lr: 0.003497  max_mem: 5397M
[32m[04/28 06:01:51 d2.utils.events]: [0m eta: 0:04:50  iter: 719  total_loss: 0.521  loss_cls: 0.166  loss_box_reg: 0.304  loss_rpn_cls: 0.005  loss_rpn_loc: 0.042  time: 1.0268  data_time: 0.0077  lr: 0.003596  max_mem: 5397M
[32m[04/28 06:02:12 d2.utils.events]: [0m eta: 0:04:29  iter: 739  total_loss: 0.594  loss_cls: 0.179  loss_box_reg: 0.346  loss_rpn_cls: 0.012  loss_rpn_loc: 0.057  time: 1.0269  data_time: 0.0076  lr: 0.003696  max_mem: 5397M
[32m[04/28 06:02:33 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.567  loss_cls: 0.175  loss_box_reg: 0.320  loss_rpn_cls: 0.008  loss_rpn_loc: 0.057  time: 1.0273  data_time: 0.0079  lr: 0.003796  max_mem: 5397M
[32m[04/28 06:02:53 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.530  loss_cls: 0.160  loss_box_reg: 0.314  loss_rpn_cls: 0.008  loss_rpn_loc: 0.039  time: 1.0277  data_time: 0.0080  lr: 0.003896  max_mem: 5397M
[32m[04/28 06:03:14 d2.utils.events]: [0m eta: 0:03:27  iter: 799  total_loss: 0.569  loss_cls: 0.167  loss_box_reg: 0.322  loss_rpn_cls: 0.012  loss_rpn_loc: 0.051  time: 1.0273  data_time: 0.0080  lr: 0.003996  max_mem: 5397M
[32m[04/28 06:03:34 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.545  loss_cls: 0.172  loss_box_reg: 0.330  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 1.0275  data_time: 0.0074  lr: 0.004096  max_mem: 5397M
[32m[04/28 06:03:55 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.552  loss_cls: 0.188  loss_box_reg: 0.313  loss_rpn_cls: 0.014  loss_rpn_loc: 0.056  time: 1.0274  data_time: 0.0078  lr: 0.004196  max_mem: 5397M
[32m[04/28 06:04:15 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.531  loss_cls: 0.160  loss_box_reg: 0.326  loss_rpn_cls: 0.009  loss_rpn_loc: 0.050  time: 1.0270  data_time: 0.0077  lr: 0.004296  max_mem: 5397M
[32m[04/28 06:04:36 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.581  loss_cls: 0.169  loss_box_reg: 0.320  loss_rpn_cls: 0.011  loss_rpn_loc: 0.073  time: 1.0268  data_time: 0.0075  lr: 0.004396  max_mem: 5397M
[32m[04/28 06:04:56 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.632  loss_cls: 0.194  loss_box_reg: 0.359  loss_rpn_cls: 0.011  loss_rpn_loc: 0.052  time: 1.0269  data_time: 0.0082  lr: 0.004496  max_mem: 5397M
[32m[04/28 06:05:17 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.522  loss_cls: 0.174  loss_box_reg: 0.310  loss_rpn_cls: 0.009  loss_rpn_loc: 0.039  time: 1.0269  data_time: 0.0078  lr: 0.004595  max_mem: 5397M
[32m[04/28 06:05:38 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.558  loss_cls: 0.165  loss_box_reg: 0.325  loss_rpn_cls: 0.011  loss_rpn_loc: 0.043  time: 1.0270  data_time: 0.0078  lr: 0.004695  max_mem: 5397M
[32m[04/28 06:05:58 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.688  loss_cls: 0.211  loss_box_reg: 0.377  loss_rpn_cls: 0.010  loss_rpn_loc: 0.069  time: 1.0266  data_time: 0.0085  lr: 0.004795  max_mem: 5397M
[32m[04/28 06:06:18 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.484  loss_cls: 0.145  loss_box_reg: 0.270  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0265  data_time: 0.0077  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 06:06:41 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 06:06:41 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 06:06:42 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 06:06:42 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.534  loss_cls: 0.158  loss_box_reg: 0.322  loss_rpn_cls: 0.013  loss_rpn_loc: 0.043  time: 1.0267  data_time: 0.0081  lr: 0.004995  max_mem: 5397M
[32m[04/28 06:06:42 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:04 (1.0277 s / it)
[32m[04/28 06:06:42 d2.engine.hooks]: [0mTotal training time: 0:17:10 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 06:06:43 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 06:06:43 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 06:06:44 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 06:06:45 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1138 s / img. ETA=0:16:01
[32m[04/28 06:06:50 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1139 s / img. ETA=0:15:58
[32m[04/28 06:06:55 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1137 s / img. ETA=0:15:52
[32m[04/28 06:07:00 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1137 s / img. ETA=0:15:47
[32m[04/28 06:07:06 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1138 s / img. ETA=0:15:42
[32m[04/28 06:07:11 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1139 s / img. ETA=0:15:38
[32m[04/28 06:07:16 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1139 s / img. ETA=0:15:33
[32m[04/28 06:07:21 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1139 s / img. ETA=0:15:28
[32m[04/28 06:07:26 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1139 s / img. ETA=0:15:23
[32m[04/28 06:07:31 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1140 s / img. ETA=0:15:19
[32m[04/28 06:07:36 d2.evaluation.evaluator]: [0mInference done 450/8355. 0.1141 s / img. ETA=0:15:15
[32m[04/28 06:07:41 d2.evaluation.evaluator]: [0mInference done 494/8355. 0.1140 s / img. ETA=0:15:09
[32m[04/28 06:07:46 d2.evaluation.evaluator]: [0mInference done 538/8355. 0.1140 s / img. ETA=0:15:04
[32m[04/28 06:07:51 d2.evaluation.evaluator]: [0mInference done 582/8355. 0.1140 s / img. ETA=0:14:59
[32m[04/28 06:07:56 d2.evaluation.evaluator]: [0mInference done 625/8355. 0.1141 s / img. ETA=0:14:54
[32m[04/28 06:08:01 d2.evaluation.evaluator]: [0mInference done 669/8355. 0.1141 s / img. ETA=0:14:50
[32m[04/28 06:08:07 d2.evaluation.evaluator]: [0mInference done 712/8355. 0.1142 s / img. ETA=0:14:45
[32m[04/28 06:08:12 d2.evaluation.evaluator]: [0mInference done 756/8355. 0.1142 s / img. ETA=0:14:40
[32m[04/28 06:08:17 d2.evaluation.evaluator]: [0mInference done 799/8355. 0.1142 s / img. ETA=0:14:35
[32m[04/28 06:08:22 d2.evaluation.evaluator]: [0mInference done 842/8355. 0.1142 s / img. ETA=0:14:31
[32m[04/28 06:08:27 d2.evaluation.evaluator]: [0mInference done 885/8355. 0.1143 s / img. ETA=0:14:26
[32m[04/28 06:08:32 d2.evaluation.evaluator]: [0mInference done 928/8355. 0.1144 s / img. ETA=0:14:22
[32m[04/28 06:08:37 d2.evaluation.evaluator]: [0mInference done 972/8355. 0.1144 s / img. ETA=0:14:16
[32m[04/28 06:08:42 d2.evaluation.evaluator]: [0mInference done 1015/8355. 0.1144 s / img. ETA=0:14:12
[32m[04/28 06:08:47 d2.evaluation.evaluator]: [0mInference done 1058/8355. 0.1144 s / img. ETA=0:14:07
[32m[04/28 06:08:52 d2.evaluation.evaluator]: [0mInference done 1101/8355. 0.1144 s / img. ETA=0:14:02
[32m[04/28 06:08:57 d2.evaluation.evaluator]: [0mInference done 1145/8355. 0.1144 s / img. ETA=0:13:57
[32m[04/28 06:09:02 d2.evaluation.evaluator]: [0mInference done 1188/8355. 0.1144 s / img. ETA=0:13:52
[32m[04/28 06:09:07 d2.evaluation.evaluator]: [0mInference done 1232/8355. 0.1144 s / img. ETA=0:13:47
[32m[04/28 06:09:12 d2.evaluation.evaluator]: [0mInference done 1276/8355. 0.1144 s / img. ETA=0:13:42
[32m[04/28 06:09:17 d2.evaluation.evaluator]: [0mInference done 1319/8355. 0.1144 s / img. ETA=0:13:37
[32m[04/28 06:09:22 d2.evaluation.evaluator]: [0mInference done 1362/8355. 0.1144 s / img. ETA=0:13:32
[32m[04/28 06:09:27 d2.evaluation.evaluator]: [0mInference done 1405/8355. 0.1144 s / img. ETA=0:13:27
[32m[04/28 06:09:32 d2.evaluation.evaluator]: [0mInference done 1448/8355. 0.1145 s / img. ETA=0:13:22
[32m[04/28 06:09:37 d2.evaluation.evaluator]: [0mInference done 1491/8355. 0.1145 s / img. ETA=0:13:17
[32m[04/28 06:09:42 d2.evaluation.evaluator]: [0mInference done 1534/8355. 0.1145 s / img. ETA=0:13:12
[32m[04/28 06:09:47 d2.evaluation.evaluator]: [0mInference done 1577/8355. 0.1145 s / img. ETA=0:13:08
[32m[04/28 06:09:52 d2.evaluation.evaluator]: [0mInference done 1620/8355. 0.1146 s / img. ETA=0:13:03
[32m[04/28 06:09:57 d2.evaluation.evaluator]: [0mInference done 1663/8355. 0.1146 s / img. ETA=0:12:58
[32m[04/28 06:10:03 d2.evaluation.evaluator]: [0mInference done 1706/8355. 0.1146 s / img. ETA=0:12:53
[32m[04/28 06:10:08 d2.evaluation.evaluator]: [0mInference done 1749/8355. 0.1147 s / img. ETA=0:12:48
[32m[04/28 06:10:13 d2.evaluation.evaluator]: [0mInference done 1792/8355. 0.1147 s / img. ETA=0:12:44
[32m[04/28 06:10:18 d2.evaluation.evaluator]: [0mInference done 1835/8355. 0.1147 s / img. ETA=0:12:39
[32m[04/28 06:10:23 d2.evaluation.evaluator]: [0mInference done 1878/8355. 0.1147 s / img. ETA=0:12:34
[32m[04/28 06:10:28 d2.evaluation.evaluator]: [0mInference done 1921/8355. 0.1148 s / img. ETA=0:12:29
[32m[04/28 06:10:33 d2.evaluation.evaluator]: [0mInference done 1964/8355. 0.1148 s / img. ETA=0:12:24
[32m[04/28 06:10:38 d2.evaluation.evaluator]: [0mInference done 2007/8355. 0.1148 s / img. ETA=0:12:19
[32m[04/28 06:10:43 d2.evaluation.evaluator]: [0mInference done 2050/8355. 0.1148 s / img. ETA=0:12:15
[32m[04/28 06:10:48 d2.evaluation.evaluator]: [0mInference done 2093/8355. 0.1148 s / img. ETA=0:12:10
[32m[04/28 06:10:53 d2.evaluation.evaluator]: [0mInference done 2137/8355. 0.1148 s / img. ETA=0:12:04
[32m[04/28 06:10:58 d2.evaluation.evaluator]: [0mInference done 2180/8355. 0.1148 s / img. ETA=0:11:59
[32m[04/28 06:11:03 d2.evaluation.evaluator]: [0mInference done 2223/8355. 0.1148 s / img. ETA=0:11:55
[32m[04/28 06:11:08 d2.evaluation.evaluator]: [0mInference done 2266/8355. 0.1149 s / img. ETA=0:11:50
[32m[04/28 06:11:13 d2.evaluation.evaluator]: [0mInference done 2309/8355. 0.1149 s / img. ETA=0:11:45
[32m[04/28 06:11:18 d2.evaluation.evaluator]: [0mInference done 2352/8355. 0.1149 s / img. ETA=0:11:40
[32m[04/28 06:11:23 d2.evaluation.evaluator]: [0mInference done 2395/8355. 0.1149 s / img. ETA=0:11:35
[32m[04/28 06:11:28 d2.evaluation.evaluator]: [0mInference done 2438/8355. 0.1149 s / img. ETA=0:11:30
[32m[04/28 06:11:33 d2.evaluation.evaluator]: [0mInference done 2481/8355. 0.1149 s / img. ETA=0:11:25
[32m[04/28 06:11:39 d2.evaluation.evaluator]: [0mInference done 2524/8355. 0.1149 s / img. ETA=0:11:20
[32m[04/28 06:11:44 d2.evaluation.evaluator]: [0mInference done 2567/8355. 0.1149 s / img. ETA=0:11:15
[32m[04/28 06:11:49 d2.evaluation.evaluator]: [0mInference done 2610/8355. 0.1149 s / img. ETA=0:11:10
[32m[04/28 06:11:54 d2.evaluation.evaluator]: [0mInference done 2653/8355. 0.1149 s / img. ETA=0:11:05
[32m[04/28 06:11:59 d2.evaluation.evaluator]: [0mInference done 2696/8355. 0.1149 s / img. ETA=0:11:00
[32m[04/28 06:12:04 d2.evaluation.evaluator]: [0mInference done 2739/8355. 0.1150 s / img. ETA=0:10:55
[32m[04/28 06:12:09 d2.evaluation.evaluator]: [0mInference done 2782/8355. 0.1150 s / img. ETA=0:10:50
[32m[04/28 06:12:14 d2.evaluation.evaluator]: [0mInference done 2825/8355. 0.1150 s / img. ETA=0:10:45
[32m[04/28 06:12:19 d2.evaluation.evaluator]: [0mInference done 2868/8355. 0.1150 s / img. ETA=0:10:40
[32m[04/28 06:12:24 d2.evaluation.evaluator]: [0mInference done 2911/8355. 0.1150 s / img. ETA=0:10:35
[32m[04/28 06:12:29 d2.evaluation.evaluator]: [0mInference done 2954/8355. 0.1150 s / img. ETA=0:10:30
[32m[04/28 06:12:34 d2.evaluation.evaluator]: [0mInference done 2997/8355. 0.1150 s / img. ETA=0:10:25
[32m[04/28 06:12:39 d2.evaluation.evaluator]: [0mInference done 3040/8355. 0.1150 s / img. ETA=0:10:20
[32m[04/28 06:12:44 d2.evaluation.evaluator]: [0mInference done 3083/8355. 0.1150 s / img. ETA=0:10:15
[32m[04/28 06:12:49 d2.evaluation.evaluator]: [0mInference done 3126/8355. 0.1150 s / img. ETA=0:10:10
[32m[04/28 06:12:54 d2.evaluation.evaluator]: [0mInference done 3169/8355. 0.1150 s / img. ETA=0:10:05
[32m[04/28 06:12:59 d2.evaluation.evaluator]: [0mInference done 3212/8355. 0.1150 s / img. ETA=0:10:00
[32m[04/28 06:13:04 d2.evaluation.evaluator]: [0mInference done 3255/8355. 0.1150 s / img. ETA=0:09:55
[32m[04/28 06:13:09 d2.evaluation.evaluator]: [0mInference done 3299/8355. 0.1150 s / img. ETA=0:09:50
[32m[04/28 06:13:14 d2.evaluation.evaluator]: [0mInference done 3342/8355. 0.1150 s / img. ETA=0:09:45
[32m[04/28 06:13:19 d2.evaluation.evaluator]: [0mInference done 3385/8355. 0.1150 s / img. ETA=0:09:40
[32m[04/28 06:13:24 d2.evaluation.evaluator]: [0mInference done 3427/8355. 0.1150 s / img. ETA=0:09:35
[32m[04/28 06:13:29 d2.evaluation.evaluator]: [0mInference done 3471/8355. 0.1150 s / img. ETA=0:09:30
[32m[04/28 06:13:34 d2.evaluation.evaluator]: [0mInference done 3514/8355. 0.1150 s / img. ETA=0:09:25
[32m[04/28 06:13:39 d2.evaluation.evaluator]: [0mInference done 3557/8355. 0.1150 s / img. ETA=0:09:20
[32m[04/28 06:13:45 d2.evaluation.evaluator]: [0mInference done 3601/8355. 0.1150 s / img. ETA=0:09:15
[32m[04/28 06:13:50 d2.evaluation.evaluator]: [0mInference done 3645/8355. 0.1150 s / img. ETA=0:09:10
[32m[04/28 06:13:55 d2.evaluation.evaluator]: [0mInference done 3688/8355. 0.1150 s / img. ETA=0:09:05
[32m[04/28 06:14:00 d2.evaluation.evaluator]: [0mInference done 3731/8355. 0.1150 s / img. ETA=0:09:00
[32m[04/28 06:14:05 d2.evaluation.evaluator]: [0mInference done 3774/8355. 0.1150 s / img. ETA=0:08:55
[32m[04/28 06:14:10 d2.evaluation.evaluator]: [0mInference done 3817/8355. 0.1150 s / img. ETA=0:08:50
[32m[04/28 06:14:15 d2.evaluation.evaluator]: [0mInference done 3860/8355. 0.1150 s / img. ETA=0:08:45
[32m[04/28 06:14:20 d2.evaluation.evaluator]: [0mInference done 3903/8355. 0.1150 s / img. ETA=0:08:40
[32m[04/28 06:14:25 d2.evaluation.evaluator]: [0mInference done 3946/8355. 0.1150 s / img. ETA=0:08:35
[32m[04/28 06:14:30 d2.evaluation.evaluator]: [0mInference done 3989/8355. 0.1150 s / img. ETA=0:08:29
[32m[04/28 06:14:35 d2.evaluation.evaluator]: [0mInference done 4032/8355. 0.1150 s / img. ETA=0:08:24
[32m[04/28 06:14:40 d2.evaluation.evaluator]: [0mInference done 4074/8355. 0.1150 s / img. ETA=0:08:20
[32m[04/28 06:14:45 d2.evaluation.evaluator]: [0mInference done 4117/8355. 0.1151 s / img. ETA=0:08:15
[32m[04/28 06:14:50 d2.evaluation.evaluator]: [0mInference done 4160/8355. 0.1150 s / img. ETA=0:08:10
[32m[04/28 06:14:55 d2.evaluation.evaluator]: [0mInference done 4203/8355. 0.1150 s / img. ETA=0:08:05
[32m[04/28 06:15:00 d2.evaluation.evaluator]: [0mInference done 4247/8355. 0.1150 s / img. ETA=0:07:59
[32m[04/28 06:15:05 d2.evaluation.evaluator]: [0mInference done 4290/8355. 0.1150 s / img. ETA=0:07:54
[32m[04/28 06:15:10 d2.evaluation.evaluator]: [0mInference done 4332/8355. 0.1151 s / img. ETA=0:07:50
[32m[04/28 06:15:15 d2.evaluation.evaluator]: [0mInference done 4376/8355. 0.1151 s / img. ETA=0:07:44
[32m[04/28 06:15:20 d2.evaluation.evaluator]: [0mInference done 4419/8355. 0.1150 s / img. ETA=0:07:39
[32m[04/28 06:15:25 d2.evaluation.evaluator]: [0mInference done 4462/8355. 0.1150 s / img. ETA=0:07:34
[32m[04/28 06:15:30 d2.evaluation.evaluator]: [0mInference done 4505/8355. 0.1150 s / img. ETA=0:07:29
[32m[04/28 06:15:35 d2.evaluation.evaluator]: [0mInference done 4548/8355. 0.1150 s / img. ETA=0:07:24
[32m[04/28 06:15:40 d2.evaluation.evaluator]: [0mInference done 4591/8355. 0.1150 s / img. ETA=0:07:19
[32m[04/28 06:15:45 d2.evaluation.evaluator]: [0mInference done 4634/8355. 0.1150 s / img. ETA=0:07:14
[32m[04/28 06:15:50 d2.evaluation.evaluator]: [0mInference done 4677/8355. 0.1150 s / img. ETA=0:07:09
[32m[04/28 06:15:56 d2.evaluation.evaluator]: [0mInference done 4721/8355. 0.1150 s / img. ETA=0:07:04
[32m[04/28 06:16:01 d2.evaluation.evaluator]: [0mInference done 4764/8355. 0.1150 s / img. ETA=0:06:59
[32m[04/28 06:16:06 d2.evaluation.evaluator]: [0mInference done 4807/8355. 0.1150 s / img. ETA=0:06:54
[32m[04/28 06:16:11 d2.evaluation.evaluator]: [0mInference done 4850/8355. 0.1150 s / img. ETA=0:06:49
[32m[04/28 06:16:16 d2.evaluation.evaluator]: [0mInference done 4893/8355. 0.1150 s / img. ETA=0:06:44
[32m[04/28 06:16:21 d2.evaluation.evaluator]: [0mInference done 4935/8355. 0.1150 s / img. ETA=0:06:39
[32m[04/28 06:16:26 d2.evaluation.evaluator]: [0mInference done 4979/8355. 0.1150 s / img. ETA=0:06:34
[32m[04/28 06:16:31 d2.evaluation.evaluator]: [0mInference done 5022/8355. 0.1151 s / img. ETA=0:06:29
[32m[04/28 06:16:36 d2.evaluation.evaluator]: [0mInference done 5064/8355. 0.1151 s / img. ETA=0:06:24
[32m[04/28 06:16:41 d2.evaluation.evaluator]: [0mInference done 5107/8355. 0.1151 s / img. ETA=0:06:19
[32m[04/28 06:16:46 d2.evaluation.evaluator]: [0mInference done 5150/8355. 0.1151 s / img. ETA=0:06:14
[32m[04/28 06:16:51 d2.evaluation.evaluator]: [0mInference done 5193/8355. 0.1151 s / img. ETA=0:06:09
[32m[04/28 06:16:56 d2.evaluation.evaluator]: [0mInference done 5236/8355. 0.1151 s / img. ETA=0:06:04
[32m[04/28 06:17:01 d2.evaluation.evaluator]: [0mInference done 5280/8355. 0.1151 s / img. ETA=0:05:59
[32m[04/28 06:17:06 d2.evaluation.evaluator]: [0mInference done 5323/8355. 0.1151 s / img. ETA=0:05:54
[32m[04/28 06:17:11 d2.evaluation.evaluator]: [0mInference done 5366/8355. 0.1151 s / img. ETA=0:05:49
[32m[04/28 06:17:16 d2.evaluation.evaluator]: [0mInference done 5409/8355. 0.1151 s / img. ETA=0:05:44
[32m[04/28 06:17:21 d2.evaluation.evaluator]: [0mInference done 5452/8355. 0.1151 s / img. ETA=0:05:39
[32m[04/28 06:17:26 d2.evaluation.evaluator]: [0mInference done 5495/8355. 0.1151 s / img. ETA=0:05:34
[32m[04/28 06:17:31 d2.evaluation.evaluator]: [0mInference done 5537/8355. 0.1151 s / img. ETA=0:05:29
[32m[04/28 06:17:36 d2.evaluation.evaluator]: [0mInference done 5581/8355. 0.1151 s / img. ETA=0:05:24
[32m[04/28 06:17:41 d2.evaluation.evaluator]: [0mInference done 5624/8355. 0.1151 s / img. ETA=0:05:19
[32m[04/28 06:17:46 d2.evaluation.evaluator]: [0mInference done 5667/8355. 0.1151 s / img. ETA=0:05:14
[32m[04/28 06:17:51 d2.evaluation.evaluator]: [0mInference done 5710/8355. 0.1151 s / img. ETA=0:05:09
[32m[04/28 06:17:56 d2.evaluation.evaluator]: [0mInference done 5753/8355. 0.1151 s / img. ETA=0:05:04
[32m[04/28 06:18:01 d2.evaluation.evaluator]: [0mInference done 5796/8355. 0.1151 s / img. ETA=0:04:59
[32m[04/28 06:18:06 d2.evaluation.evaluator]: [0mInference done 5839/8355. 0.1151 s / img. ETA=0:04:54
[32m[04/28 06:18:12 d2.evaluation.evaluator]: [0mInference done 5882/8355. 0.1151 s / img. ETA=0:04:49
[32m[04/28 06:18:17 d2.evaluation.evaluator]: [0mInference done 5925/8355. 0.1151 s / img. ETA=0:04:44
[32m[04/28 06:18:22 d2.evaluation.evaluator]: [0mInference done 5968/8355. 0.1151 s / img. ETA=0:04:39
[32m[04/28 06:18:27 d2.evaluation.evaluator]: [0mInference done 6011/8355. 0.1151 s / img. ETA=0:04:34
[32m[04/28 06:18:32 d2.evaluation.evaluator]: [0mInference done 6054/8355. 0.1151 s / img. ETA=0:04:29
[32m[04/28 06:18:37 d2.evaluation.evaluator]: [0mInference done 6097/8355. 0.1151 s / img. ETA=0:04:24
[32m[04/28 06:18:42 d2.evaluation.evaluator]: [0mInference done 6140/8355. 0.1151 s / img. ETA=0:04:18
[32m[04/28 06:18:47 d2.evaluation.evaluator]: [0mInference done 6183/8355. 0.1151 s / img. ETA=0:04:13
[32m[04/28 06:18:52 d2.evaluation.evaluator]: [0mInference done 6226/8355. 0.1151 s / img. ETA=0:04:08
[32m[04/28 06:18:57 d2.evaluation.evaluator]: [0mInference done 6269/8355. 0.1151 s / img. ETA=0:04:03
[32m[04/28 06:19:02 d2.evaluation.evaluator]: [0mInference done 6312/8355. 0.1151 s / img. ETA=0:03:58
[32m[04/28 06:19:07 d2.evaluation.evaluator]: [0mInference done 6355/8355. 0.1151 s / img. ETA=0:03:53
[32m[04/28 06:19:12 d2.evaluation.evaluator]: [0mInference done 6398/8355. 0.1151 s / img. ETA=0:03:48
[32m[04/28 06:19:17 d2.evaluation.evaluator]: [0mInference done 6441/8355. 0.1151 s / img. ETA=0:03:43
[32m[04/28 06:19:22 d2.evaluation.evaluator]: [0mInference done 6484/8355. 0.1151 s / img. ETA=0:03:38
[32m[04/28 06:19:27 d2.evaluation.evaluator]: [0mInference done 6527/8355. 0.1151 s / img. ETA=0:03:33
[32m[04/28 06:19:32 d2.evaluation.evaluator]: [0mInference done 6570/8355. 0.1151 s / img. ETA=0:03:28
[32m[04/28 06:19:37 d2.evaluation.evaluator]: [0mInference done 6613/8355. 0.1151 s / img. ETA=0:03:23
[32m[04/28 06:19:42 d2.evaluation.evaluator]: [0mInference done 6656/8355. 0.1151 s / img. ETA=0:03:18
[32m[04/28 06:19:47 d2.evaluation.evaluator]: [0mInference done 6700/8355. 0.1151 s / img. ETA=0:03:13
[32m[04/28 06:19:52 d2.evaluation.evaluator]: [0mInference done 6743/8355. 0.1151 s / img. ETA=0:03:08
[32m[04/28 06:19:58 d2.evaluation.evaluator]: [0mInference done 6787/8355. 0.1151 s / img. ETA=0:03:03
[32m[04/28 06:20:03 d2.evaluation.evaluator]: [0mInference done 6831/8355. 0.1151 s / img. ETA=0:02:58
[32m[04/28 06:20:08 d2.evaluation.evaluator]: [0mInference done 6875/8355. 0.1151 s / img. ETA=0:02:53
[32m[04/28 06:20:13 d2.evaluation.evaluator]: [0mInference done 6918/8355. 0.1151 s / img. ETA=0:02:48
[32m[04/28 06:20:18 d2.evaluation.evaluator]: [0mInference done 6961/8355. 0.1151 s / img. ETA=0:02:42
[32m[04/28 06:20:23 d2.evaluation.evaluator]: [0mInference done 7004/8355. 0.1151 s / img. ETA=0:02:37
[32m[04/28 06:20:28 d2.evaluation.evaluator]: [0mInference done 7047/8355. 0.1151 s / img. ETA=0:02:32
[32m[04/28 06:20:33 d2.evaluation.evaluator]: [0mInference done 7090/8355. 0.1151 s / img. ETA=0:02:27
[32m[04/28 06:20:38 d2.evaluation.evaluator]: [0mInference done 7133/8355. 0.1151 s / img. ETA=0:02:22
[32m[04/28 06:20:43 d2.evaluation.evaluator]: [0mInference done 7176/8355. 0.1151 s / img. ETA=0:02:17
[32m[04/28 06:20:48 d2.evaluation.evaluator]: [0mInference done 7219/8355. 0.1151 s / img. ETA=0:02:12
[32m[04/28 06:20:53 d2.evaluation.evaluator]: [0mInference done 7262/8355. 0.1151 s / img. ETA=0:02:07
[32m[04/28 06:20:58 d2.evaluation.evaluator]: [0mInference done 7305/8355. 0.1151 s / img. ETA=0:02:02
[32m[04/28 06:21:03 d2.evaluation.evaluator]: [0mInference done 7348/8355. 0.1151 s / img. ETA=0:01:57
[32m[04/28 06:21:08 d2.evaluation.evaluator]: [0mInference done 7391/8355. 0.1151 s / img. ETA=0:01:52
[32m[04/28 06:21:13 d2.evaluation.evaluator]: [0mInference done 7434/8355. 0.1151 s / img. ETA=0:01:47
[32m[04/28 06:21:18 d2.evaluation.evaluator]: [0mInference done 7477/8355. 0.1151 s / img. ETA=0:01:42
[32m[04/28 06:21:23 d2.evaluation.evaluator]: [0mInference done 7520/8355. 0.1151 s / img. ETA=0:01:37
[32m[04/28 06:21:29 d2.evaluation.evaluator]: [0mInference done 7563/8355. 0.1151 s / img. ETA=0:01:32
[32m[04/28 06:21:34 d2.evaluation.evaluator]: [0mInference done 7606/8355. 0.1151 s / img. ETA=0:01:27
[32m[04/28 06:21:39 d2.evaluation.evaluator]: [0mInference done 7649/8355. 0.1151 s / img. ETA=0:01:22
[32m[04/28 06:21:44 d2.evaluation.evaluator]: [0mInference done 7692/8355. 0.1151 s / img. ETA=0:01:17
[32m[04/28 06:21:49 d2.evaluation.evaluator]: [0mInference done 7735/8355. 0.1151 s / img. ETA=0:01:12
[32m[04/28 06:21:54 d2.evaluation.evaluator]: [0mInference done 7778/8355. 0.1151 s / img. ETA=0:01:07
[32m[04/28 06:21:59 d2.evaluation.evaluator]: [0mInference done 7820/8355. 0.1151 s / img. ETA=0:01:02
[32m[04/28 06:22:04 d2.evaluation.evaluator]: [0mInference done 7863/8355. 0.1151 s / img. ETA=0:00:57
[32m[04/28 06:22:09 d2.evaluation.evaluator]: [0mInference done 7906/8355. 0.1151 s / img. ETA=0:00:52
[32m[04/28 06:22:14 d2.evaluation.evaluator]: [0mInference done 7949/8355. 0.1151 s / img. ETA=0:00:47
[32m[04/28 06:22:19 d2.evaluation.evaluator]: [0mInference done 7992/8355. 0.1152 s / img. ETA=0:00:42
[32m[04/28 06:22:24 d2.evaluation.evaluator]: [0mInference done 8036/8355. 0.1151 s / img. ETA=0:00:37
[32m[04/28 06:22:29 d2.evaluation.evaluator]: [0mInference done 8079/8355. 0.1151 s / img. ETA=0:00:32
[32m[04/28 06:22:34 d2.evaluation.evaluator]: [0mInference done 8123/8355. 0.1151 s / img. ETA=0:00:27
[32m[04/28 06:22:39 d2.evaluation.evaluator]: [0mInference done 8167/8355. 0.1151 s / img. ETA=0:00:21
[32m[04/28 06:22:44 d2.evaluation.evaluator]: [0mInference done 8210/8355. 0.1151 s / img. ETA=0:00:16
[32m[04/28 06:22:49 d2.evaluation.evaluator]: [0mInference done 8253/8355. 0.1151 s / img. ETA=0:00:11
[32m[04/28 06:22:54 d2.evaluation.evaluator]: [0mInference done 8296/8355. 0.1151 s / img. ETA=0:00:06
[32m[04/28 06:22:59 d2.evaluation.evaluator]: [0mInference done 8339/8355. 0.1151 s / img. ETA=0:00:01
[32m[04/28 06:23:01 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:16.630924 (0.116962 s / img per device, on 1 devices)
[32m[04/28 06:23:01 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:01 (0.115133 s / img per device, on 1 devices)
[32m[04/28 06:23:01 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 06:23:01 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 06:23:02 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.43s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.68s).
Accumulating evaluation results...
DONE (t=2.14s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.814
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.428
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.347
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.572
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.703
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.174
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.500
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.515
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.425
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.756
[32m[04/28 06:23:24 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.796 | 81.393 | 42.818 | 34.679 | 57.162 | 70.293 |
[32m[04/28 06:23:24 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 43.119 | bicycle       | 37.023 | car            | 54.247 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 06:23:24 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 06:23:24 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 06:23:24 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 06:23:26 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1142 s / img. ETA=0:02:24
[32m[04/28 06:23:31 d2.evaluation.evaluator]: [0mInference done 55/1257. 0.1139 s / img. ETA=0:02:19
[32m[04/28 06:23:36 d2.evaluation.evaluator]: [0mInference done 99/1257. 0.1142 s / img. ETA=0:02:14
[32m[04/28 06:23:41 d2.evaluation.evaluator]: [0mInference done 143/1257. 0.1142 s / img. ETA=0:02:09
[32m[04/28 06:23:46 d2.evaluation.evaluator]: [0mInference done 186/1257. 0.1143 s / img. ETA=0:02:04
[32m[04/28 06:23:51 d2.evaluation.evaluator]: [0mInference done 230/1257. 0.1143 s / img. ETA=0:01:59
[32m[04/28 06:23:56 d2.evaluation.evaluator]: [0mInference done 273/1257. 0.1144 s / img. ETA=0:01:54
[32m[04/28 06:24:01 d2.evaluation.evaluator]: [0mInference done 317/1257. 0.1144 s / img. ETA=0:01:49
[32m[04/28 06:24:07 d2.evaluation.evaluator]: [0mInference done 361/1257. 0.1144 s / img. ETA=0:01:44
[32m[04/28 06:24:12 d2.evaluation.evaluator]: [0mInference done 405/1257. 0.1144 s / img. ETA=0:01:38
[32m[04/28 06:24:17 d2.evaluation.evaluator]: [0mInference done 449/1257. 0.1144 s / img. ETA=0:01:33
[32m[04/28 06:24:22 d2.evaluation.evaluator]: [0mInference done 493/1257. 0.1144 s / img. ETA=0:01:28
[32m[04/28 06:24:27 d2.evaluation.evaluator]: [0mInference done 536/1257. 0.1144 s / img. ETA=0:01:23
[32m[04/28 06:24:32 d2.evaluation.evaluator]: [0mInference done 579/1257. 0.1144 s / img. ETA=0:01:18
[32m[04/28 06:24:37 d2.evaluation.evaluator]: [0mInference done 623/1257. 0.1144 s / img. ETA=0:01:13
[32m[04/28 06:24:42 d2.evaluation.evaluator]: [0mInference done 666/1257. 0.1144 s / img. ETA=0:01:08
[32m[04/28 06:24:47 d2.evaluation.evaluator]: [0mInference done 709/1257. 0.1144 s / img. ETA=0:01:03
[32m[04/28 06:24:52 d2.evaluation.evaluator]: [0mInference done 753/1257. 0.1144 s / img. ETA=0:00:58
[32m[04/28 06:24:57 d2.evaluation.evaluator]: [0mInference done 796/1257. 0.1144 s / img. ETA=0:00:53
[32m[04/28 06:25:02 d2.evaluation.evaluator]: [0mInference done 839/1257. 0.1145 s / img. ETA=0:00:48
[32m[04/28 06:25:07 d2.evaluation.evaluator]: [0mInference done 882/1257. 0.1145 s / img. ETA=0:00:43
[32m[04/28 06:25:12 d2.evaluation.evaluator]: [0mInference done 925/1257. 0.1145 s / img. ETA=0:00:38
[32m[04/28 06:25:17 d2.evaluation.evaluator]: [0mInference done 968/1257. 0.1145 s / img. ETA=0:00:33
[32m[04/28 06:25:22 d2.evaluation.evaluator]: [0mInference done 1011/1257. 0.1145 s / img. ETA=0:00:28
[32m[04/28 06:25:27 d2.evaluation.evaluator]: [0mInference done 1054/1257. 0.1145 s / img. ETA=0:00:23
[32m[04/28 06:25:32 d2.evaluation.evaluator]: [0mInference done 1097/1257. 0.1146 s / img. ETA=0:00:18
[32m[04/28 06:25:37 d2.evaluation.evaluator]: [0mInference done 1140/1257. 0.1146 s / img. ETA=0:00:13
[32m[04/28 06:25:42 d2.evaluation.evaluator]: [0mInference done 1183/1257. 0.1146 s / img. ETA=0:00:08
[32m[04/28 06:25:47 d2.evaluation.evaluator]: [0mInference done 1226/1257. 0.1146 s / img. ETA=0:00:03
[32m[04/28 06:25:51 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:25.896104 (0.116530 s / img per device, on 1 devices)
[32m[04/28 06:25:51 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:23 (0.114655 s / img per device, on 1 devices)
[32m[04/28 06:25:51 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 06:25:51 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 06:25:51 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.73s).
Accumulating evaluation results...
DONE (t=0.36s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.767
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.334
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.451
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.570
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.466
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.387
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.522
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.623
[32m[04/28 06:25:54 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.089 | 76.662 | 33.401 | 29.178 | 45.104 | 57.024 |
[32m[04/28 06:25:54 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 39.614 | bicycle       | 24.352 | car            | 53.301 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  8  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 06:25:55 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 06:25:55 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 06:25:55 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 06:25:56 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 06:25:56 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 06:25:56 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 06:25:56 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 06:26:17 d2.utils.events]: [0m eta: 0:16:53  iter: 19  total_loss: 0.568  loss_cls: 0.183  loss_box_reg: 0.331  loss_rpn_cls: 0.011  loss_rpn_loc: 0.057  time: 1.0238  data_time: 0.0220  lr: 0.000100  max_mem: 5397M
[32m[04/28 06:26:37 d2.utils.events]: [0m eta: 0:16:33  iter: 39  total_loss: 0.545  loss_cls: 0.166  loss_box_reg: 0.325  loss_rpn_cls: 0.008  loss_rpn_loc: 0.043  time: 1.0294  data_time: 0.0076  lr: 0.000200  max_mem: 5397M
[32m[04/28 06:26:58 d2.utils.events]: [0m eta: 0:16:23  iter: 59  total_loss: 0.534  loss_cls: 0.172  loss_box_reg: 0.311  loss_rpn_cls: 0.010  loss_rpn_loc: 0.043  time: 1.0369  data_time: 0.0078  lr: 0.000300  max_mem: 5397M
[32m[04/28 06:27:19 d2.utils.events]: [0m eta: 0:16:02  iter: 79  total_loss: 0.545  loss_cls: 0.174  loss_box_reg: 0.325  loss_rpn_cls: 0.010  loss_rpn_loc: 0.056  time: 1.0329  data_time: 0.0076  lr: 0.000400  max_mem: 5397M
[32m[04/28 06:27:39 d2.utils.events]: [0m eta: 0:15:35  iter: 99  total_loss: 0.609  loss_cls: 0.185  loss_box_reg: 0.346  loss_rpn_cls: 0.008  loss_rpn_loc: 0.060  time: 1.0277  data_time: 0.0078  lr: 0.000500  max_mem: 5397M
[32m[04/28 06:28:00 d2.utils.events]: [0m eta: 0:15:14  iter: 119  total_loss: 0.505  loss_cls: 0.161  loss_box_reg: 0.290  loss_rpn_cls: 0.008  loss_rpn_loc: 0.047  time: 1.0275  data_time: 0.0077  lr: 0.000599  max_mem: 5397M
[32m[04/28 06:28:20 d2.utils.events]: [0m eta: 0:14:51  iter: 139  total_loss: 0.496  loss_cls: 0.150  loss_box_reg: 0.286  loss_rpn_cls: 0.011  loss_rpn_loc: 0.043  time: 1.0277  data_time: 0.0076  lr: 0.000699  max_mem: 5397M
[32m[04/28 06:28:41 d2.utils.events]: [0m eta: 0:14:31  iter: 159  total_loss: 0.550  loss_cls: 0.166  loss_box_reg: 0.320  loss_rpn_cls: 0.015  loss_rpn_loc: 0.046  time: 1.0266  data_time: 0.0080  lr: 0.000799  max_mem: 5397M
[32m[04/28 06:29:02 d2.utils.events]: [0m eta: 0:14:13  iter: 179  total_loss: 0.558  loss_cls: 0.182  loss_box_reg: 0.330  loss_rpn_cls: 0.012  loss_rpn_loc: 0.055  time: 1.0284  data_time: 0.0086  lr: 0.000899  max_mem: 5397M
[32m[04/28 06:29:22 d2.utils.events]: [0m eta: 0:13:53  iter: 199  total_loss: 0.458  loss_cls: 0.133  loss_box_reg: 0.264  loss_rpn_cls: 0.008  loss_rpn_loc: 0.048  time: 1.0294  data_time: 0.0075  lr: 0.000999  max_mem: 5397M
[32m[04/28 06:29:43 d2.utils.events]: [0m eta: 0:13:31  iter: 219  total_loss: 0.488  loss_cls: 0.146  loss_box_reg: 0.284  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 1.0276  data_time: 0.0079  lr: 0.001099  max_mem: 5397M
[32m[04/28 06:30:04 d2.utils.events]: [0m eta: 0:13:12  iter: 239  total_loss: 0.493  loss_cls: 0.136  loss_box_reg: 0.279  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0299  data_time: 0.0077  lr: 0.001199  max_mem: 5397M
[32m[04/28 06:30:25 d2.utils.events]: [0m eta: 0:12:51  iter: 259  total_loss: 0.496  loss_cls: 0.136  loss_box_reg: 0.291  loss_rpn_cls: 0.011  loss_rpn_loc: 0.044  time: 1.0311  data_time: 0.0076  lr: 0.001299  max_mem: 5397M
[32m[04/28 06:30:46 d2.utils.events]: [0m eta: 0:12:34  iter: 279  total_loss: 0.615  loss_cls: 0.187  loss_box_reg: 0.347  loss_rpn_cls: 0.010  loss_rpn_loc: 0.062  time: 1.0325  data_time: 0.0076  lr: 0.001399  max_mem: 5397M
[32m[04/28 06:31:06 d2.utils.events]: [0m eta: 0:12:13  iter: 299  total_loss: 0.495  loss_cls: 0.169  loss_box_reg: 0.282  loss_rpn_cls: 0.009  loss_rpn_loc: 0.042  time: 1.0322  data_time: 0.0077  lr: 0.001499  max_mem: 5397M
[32m[04/28 06:31:27 d2.utils.events]: [0m eta: 0:11:50  iter: 319  total_loss: 0.561  loss_cls: 0.177  loss_box_reg: 0.313  loss_rpn_cls: 0.012  loss_rpn_loc: 0.053  time: 1.0316  data_time: 0.0075  lr: 0.001598  max_mem: 5397M
[32m[04/28 06:31:48 d2.utils.events]: [0m eta: 0:11:30  iter: 339  total_loss: 0.572  loss_cls: 0.163  loss_box_reg: 0.310  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 1.0317  data_time: 0.0077  lr: 0.001698  max_mem: 5397M
[32m[04/28 06:32:08 d2.utils.events]: [0m eta: 0:11:08  iter: 359  total_loss: 0.529  loss_cls: 0.168  loss_box_reg: 0.298  loss_rpn_cls: 0.011  loss_rpn_loc: 0.046  time: 1.0299  data_time: 0.0077  lr: 0.001798  max_mem: 5397M
[32m[04/28 06:32:28 d2.utils.events]: [0m eta: 0:10:46  iter: 379  total_loss: 0.549  loss_cls: 0.174  loss_box_reg: 0.318  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0298  data_time: 0.0074  lr: 0.001898  max_mem: 5397M
[32m[04/28 06:32:49 d2.utils.events]: [0m eta: 0:10:25  iter: 399  total_loss: 0.570  loss_cls: 0.171  loss_box_reg: 0.315  loss_rpn_cls: 0.010  loss_rpn_loc: 0.059  time: 1.0306  data_time: 0.0079  lr: 0.001998  max_mem: 5397M
[32m[04/28 06:33:10 d2.utils.events]: [0m eta: 0:10:05  iter: 419  total_loss: 0.469  loss_cls: 0.151  loss_box_reg: 0.272  loss_rpn_cls: 0.007  loss_rpn_loc: 0.049  time: 1.0298  data_time: 0.0077  lr: 0.002098  max_mem: 5397M
[32m[04/28 06:33:30 d2.utils.events]: [0m eta: 0:09:45  iter: 439  total_loss: 0.479  loss_cls: 0.159  loss_box_reg: 0.284  loss_rpn_cls: 0.011  loss_rpn_loc: 0.049  time: 1.0302  data_time: 0.0075  lr: 0.002198  max_mem: 5397M
[32m[04/28 06:33:51 d2.utils.events]: [0m eta: 0:09:23  iter: 459  total_loss: 0.553  loss_cls: 0.165  loss_box_reg: 0.332  loss_rpn_cls: 0.012  loss_rpn_loc: 0.041  time: 1.0298  data_time: 0.0075  lr: 0.002298  max_mem: 5397M
[32m[04/28 06:34:11 d2.utils.events]: [0m eta: 0:09:02  iter: 479  total_loss: 0.537  loss_cls: 0.164  loss_box_reg: 0.317  loss_rpn_cls: 0.009  loss_rpn_loc: 0.061  time: 1.0292  data_time: 0.0077  lr: 0.002398  max_mem: 5397M
[32m[04/28 06:34:32 d2.utils.events]: [0m eta: 0:08:41  iter: 499  total_loss: 0.514  loss_cls: 0.154  loss_box_reg: 0.294  loss_rpn_cls: 0.013  loss_rpn_loc: 0.048  time: 1.0293  data_time: 0.0077  lr: 0.002498  max_mem: 5397M
[32m[04/28 06:34:53 d2.utils.events]: [0m eta: 0:08:21  iter: 519  total_loss: 0.500  loss_cls: 0.168  loss_box_reg: 0.297  loss_rpn_cls: 0.008  loss_rpn_loc: 0.046  time: 1.0295  data_time: 0.0080  lr: 0.002597  max_mem: 5397M
[32m[04/28 06:35:13 d2.utils.events]: [0m eta: 0:07:59  iter: 539  total_loss: 0.541  loss_cls: 0.170  loss_box_reg: 0.308  loss_rpn_cls: 0.009  loss_rpn_loc: 0.042  time: 1.0294  data_time: 0.0075  lr: 0.002697  max_mem: 5397M
[32m[04/28 06:35:34 d2.utils.events]: [0m eta: 0:07:38  iter: 559  total_loss: 0.546  loss_cls: 0.165  loss_box_reg: 0.313  loss_rpn_cls: 0.010  loss_rpn_loc: 0.053  time: 1.0292  data_time: 0.0077  lr: 0.002797  max_mem: 5397M
[32m[04/28 06:35:54 d2.utils.events]: [0m eta: 0:07:18  iter: 579  total_loss: 0.536  loss_cls: 0.158  loss_box_reg: 0.313  loss_rpn_cls: 0.010  loss_rpn_loc: 0.045  time: 1.0288  data_time: 0.0076  lr: 0.002897  max_mem: 5397M
[32m[04/28 06:36:15 d2.utils.events]: [0m eta: 0:06:57  iter: 599  total_loss: 0.535  loss_cls: 0.157  loss_box_reg: 0.301  loss_rpn_cls: 0.008  loss_rpn_loc: 0.043  time: 1.0292  data_time: 0.0074  lr: 0.002997  max_mem: 5397M
[32m[04/28 06:36:36 d2.utils.events]: [0m eta: 0:06:36  iter: 619  total_loss: 0.555  loss_cls: 0.172  loss_box_reg: 0.324  loss_rpn_cls: 0.007  loss_rpn_loc: 0.045  time: 1.0292  data_time: 0.0076  lr: 0.003097  max_mem: 5397M
[32m[04/28 06:36:56 d2.utils.events]: [0m eta: 0:06:15  iter: 639  total_loss: 0.503  loss_cls: 0.166  loss_box_reg: 0.299  loss_rpn_cls: 0.008  loss_rpn_loc: 0.046  time: 1.0293  data_time: 0.0076  lr: 0.003197  max_mem: 5397M
[32m[04/28 06:37:17 d2.utils.events]: [0m eta: 0:05:55  iter: 659  total_loss: 0.460  loss_cls: 0.148  loss_box_reg: 0.283  loss_rpn_cls: 0.008  loss_rpn_loc: 0.038  time: 1.0295  data_time: 0.0078  lr: 0.003297  max_mem: 5397M
[32m[04/28 06:37:38 d2.utils.events]: [0m eta: 0:05:34  iter: 679  total_loss: 0.580  loss_cls: 0.180  loss_box_reg: 0.332  loss_rpn_cls: 0.006  loss_rpn_loc: 0.050  time: 1.0294  data_time: 0.0078  lr: 0.003397  max_mem: 5397M
[32m[04/28 06:37:59 d2.utils.events]: [0m eta: 0:05:13  iter: 699  total_loss: 0.579  loss_cls: 0.173  loss_box_reg: 0.322  loss_rpn_cls: 0.013  loss_rpn_loc: 0.043  time: 1.0298  data_time: 0.0078  lr: 0.003497  max_mem: 5397M
[32m[04/28 06:38:20 d2.utils.events]: [0m eta: 0:04:52  iter: 719  total_loss: 0.564  loss_cls: 0.179  loss_box_reg: 0.339  loss_rpn_cls: 0.010  loss_rpn_loc: 0.042  time: 1.0306  data_time: 0.0079  lr: 0.003596  max_mem: 5397M
[32m[04/28 06:38:41 d2.utils.events]: [0m eta: 0:04:32  iter: 739  total_loss: 0.578  loss_cls: 0.189  loss_box_reg: 0.336  loss_rpn_cls: 0.007  loss_rpn_loc: 0.060  time: 1.0313  data_time: 0.0077  lr: 0.003696  max_mem: 5397M
[32m[04/28 06:39:02 d2.utils.events]: [0m eta: 0:04:11  iter: 759  total_loss: 0.537  loss_cls: 0.164  loss_box_reg: 0.313  loss_rpn_cls: 0.007  loss_rpn_loc: 0.046  time: 1.0311  data_time: 0.0080  lr: 0.003796  max_mem: 5397M
[32m[04/28 06:39:23 d2.utils.events]: [0m eta: 0:03:50  iter: 779  total_loss: 0.560  loss_cls: 0.191  loss_box_reg: 0.317  loss_rpn_cls: 0.009  loss_rpn_loc: 0.047  time: 1.0315  data_time: 0.0077  lr: 0.003896  max_mem: 5397M
[32m[04/28 06:39:43 d2.utils.events]: [0m eta: 0:03:29  iter: 799  total_loss: 0.554  loss_cls: 0.178  loss_box_reg: 0.321  loss_rpn_cls: 0.008  loss_rpn_loc: 0.045  time: 1.0313  data_time: 0.0079  lr: 0.003996  max_mem: 5397M
[32m[04/28 06:40:04 d2.utils.events]: [0m eta: 0:03:08  iter: 819  total_loss: 0.497  loss_cls: 0.155  loss_box_reg: 0.287  loss_rpn_cls: 0.008  loss_rpn_loc: 0.045  time: 1.0315  data_time: 0.0076  lr: 0.004096  max_mem: 5397M
[32m[04/28 06:40:24 d2.utils.events]: [0m eta: 0:02:47  iter: 839  total_loss: 0.568  loss_cls: 0.174  loss_box_reg: 0.329  loss_rpn_cls: 0.010  loss_rpn_loc: 0.056  time: 1.0312  data_time: 0.0075  lr: 0.004196  max_mem: 5397M
[32m[04/28 06:40:45 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.541  loss_cls: 0.169  loss_box_reg: 0.305  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 1.0317  data_time: 0.0079  lr: 0.004296  max_mem: 5397M
[32m[04/28 06:41:06 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.546  loss_cls: 0.186  loss_box_reg: 0.328  loss_rpn_cls: 0.009  loss_rpn_loc: 0.047  time: 1.0321  data_time: 0.0079  lr: 0.004396  max_mem: 5397M
[32m[04/28 06:41:27 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.533  loss_cls: 0.162  loss_box_reg: 0.330  loss_rpn_cls: 0.009  loss_rpn_loc: 0.056  time: 1.0319  data_time: 0.0077  lr: 0.004496  max_mem: 5397M
[32m[04/28 06:41:48 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.529  loss_cls: 0.157  loss_box_reg: 0.295  loss_rpn_cls: 0.008  loss_rpn_loc: 0.045  time: 1.0318  data_time: 0.0075  lr: 0.004595  max_mem: 5397M
[32m[04/28 06:42:08 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.615  loss_cls: 0.200  loss_box_reg: 0.339  loss_rpn_cls: 0.011  loss_rpn_loc: 0.052  time: 1.0315  data_time: 0.0076  lr: 0.004695  max_mem: 5397M
[32m[04/28 06:42:29 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.617  loss_cls: 0.194  loss_box_reg: 0.342  loss_rpn_cls: 0.010  loss_rpn_loc: 0.042  time: 1.0318  data_time: 0.0076  lr: 0.004795  max_mem: 5397M
[32m[04/28 06:42:50 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.558  loss_cls: 0.172  loss_box_reg: 0.325  loss_rpn_cls: 0.009  loss_rpn_loc: 0.048  time: 1.0322  data_time: 0.0078  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 06:43:13 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 06:43:13 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 06:43:13 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 06:43:13 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.534  loss_cls: 0.168  loss_box_reg: 0.301  loss_rpn_cls: 0.011  loss_rpn_loc: 0.054  time: 1.0318  data_time: 0.0077  lr: 0.004995  max_mem: 5397M
[32m[04/28 06:43:13 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:09 (1.0328 s / it)
[32m[04/28 06:43:13 d2.engine.hooks]: [0mTotal training time: 0:17:15 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 06:43:15 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 06:43:15 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 06:43:15 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 06:43:16 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1138 s / img. ETA=0:16:01
[32m[04/28 06:43:21 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1136 s / img. ETA=0:15:56
[32m[04/28 06:43:26 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1136 s / img. ETA=0:15:51
[32m[04/28 06:43:31 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1135 s / img. ETA=0:15:46
[32m[04/28 06:43:37 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1135 s / img. ETA=0:15:40
[32m[04/28 06:43:42 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1135 s / img. ETA=0:15:35
[32m[04/28 06:43:47 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1136 s / img. ETA=0:15:31
[32m[04/28 06:43:52 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1136 s / img. ETA=0:15:26
[32m[04/28 06:43:57 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1136 s / img. ETA=0:15:21
[32m[04/28 06:44:02 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1137 s / img. ETA=0:15:16
[32m[04/28 06:44:07 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1137 s / img. ETA=0:15:12
[32m[04/28 06:44:12 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1137 s / img. ETA=0:15:06
[32m[04/28 06:44:17 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1136 s / img. ETA=0:15:01
[32m[04/28 06:44:22 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1137 s / img. ETA=0:14:56
[32m[04/28 06:44:27 d2.evaluation.evaluator]: [0mInference done 626/8355. 0.1138 s / img. ETA=0:14:52
[32m[04/28 06:44:32 d2.evaluation.evaluator]: [0mInference done 670/8355. 0.1138 s / img. ETA=0:14:47
[32m[04/28 06:44:37 d2.evaluation.evaluator]: [0mInference done 714/8355. 0.1138 s / img. ETA=0:14:42
[32m[04/28 06:44:43 d2.evaluation.evaluator]: [0mInference done 758/8355. 0.1138 s / img. ETA=0:14:37
[32m[04/28 06:44:48 d2.evaluation.evaluator]: [0mInference done 802/8355. 0.1138 s / img. ETA=0:14:32
[32m[04/28 06:44:53 d2.evaluation.evaluator]: [0mInference done 846/8355. 0.1138 s / img. ETA=0:14:27
[32m[04/28 06:44:58 d2.evaluation.evaluator]: [0mInference done 889/8355. 0.1139 s / img. ETA=0:14:23
[32m[04/28 06:45:03 d2.evaluation.evaluator]: [0mInference done 932/8355. 0.1139 s / img. ETA=0:14:18
[32m[04/28 06:45:08 d2.evaluation.evaluator]: [0mInference done 976/8355. 0.1139 s / img. ETA=0:14:13
[32m[04/28 06:45:13 d2.evaluation.evaluator]: [0mInference done 1019/8355. 0.1140 s / img. ETA=0:14:09
[32m[04/28 06:45:18 d2.evaluation.evaluator]: [0mInference done 1063/8355. 0.1140 s / img. ETA=0:14:04
[32m[04/28 06:45:23 d2.evaluation.evaluator]: [0mInference done 1107/8355. 0.1140 s / img. ETA=0:13:58
[32m[04/28 06:45:28 d2.evaluation.evaluator]: [0mInference done 1151/8355. 0.1140 s / img. ETA=0:13:53
[32m[04/28 06:45:33 d2.evaluation.evaluator]: [0mInference done 1195/8355. 0.1140 s / img. ETA=0:13:48
[32m[04/28 06:45:38 d2.evaluation.evaluator]: [0mInference done 1239/8355. 0.1140 s / img. ETA=0:13:43
[32m[04/28 06:45:43 d2.evaluation.evaluator]: [0mInference done 1283/8355. 0.1139 s / img. ETA=0:13:37
[32m[04/28 06:45:48 d2.evaluation.evaluator]: [0mInference done 1327/8355. 0.1139 s / img. ETA=0:13:32
[32m[04/28 06:45:54 d2.evaluation.evaluator]: [0mInference done 1371/8355. 0.1139 s / img. ETA=0:13:27
[32m[04/28 06:45:59 d2.evaluation.evaluator]: [0mInference done 1415/8355. 0.1139 s / img. ETA=0:13:22
[32m[04/28 06:46:04 d2.evaluation.evaluator]: [0mInference done 1459/8355. 0.1139 s / img. ETA=0:13:17
[32m[04/28 06:46:09 d2.evaluation.evaluator]: [0mInference done 1502/8355. 0.1140 s / img. ETA=0:13:12
[32m[04/28 06:46:14 d2.evaluation.evaluator]: [0mInference done 1545/8355. 0.1140 s / img. ETA=0:13:08
[32m[04/28 06:46:19 d2.evaluation.evaluator]: [0mInference done 1588/8355. 0.1141 s / img. ETA=0:13:03
[32m[04/28 06:46:24 d2.evaluation.evaluator]: [0mInference done 1631/8355. 0.1141 s / img. ETA=0:12:58
[32m[04/28 06:46:29 d2.evaluation.evaluator]: [0mInference done 1674/8355. 0.1141 s / img. ETA=0:12:54
[32m[04/28 06:46:34 d2.evaluation.evaluator]: [0mInference done 1717/8355. 0.1142 s / img. ETA=0:12:49
[32m[04/28 06:46:39 d2.evaluation.evaluator]: [0mInference done 1760/8355. 0.1142 s / img. ETA=0:12:44
[32m[04/28 06:46:44 d2.evaluation.evaluator]: [0mInference done 1803/8355. 0.1142 s / img. ETA=0:12:39
[32m[04/28 06:46:49 d2.evaluation.evaluator]: [0mInference done 1846/8355. 0.1142 s / img. ETA=0:12:35
[32m[04/28 06:46:54 d2.evaluation.evaluator]: [0mInference done 1889/8355. 0.1143 s / img. ETA=0:12:30
[32m[04/28 06:46:59 d2.evaluation.evaluator]: [0mInference done 1932/8355. 0.1143 s / img. ETA=0:12:25
[32m[04/28 06:47:04 d2.evaluation.evaluator]: [0mInference done 1975/8355. 0.1143 s / img. ETA=0:12:20
[32m[04/28 06:47:09 d2.evaluation.evaluator]: [0mInference done 2018/8355. 0.1143 s / img. ETA=0:12:15
[32m[04/28 06:47:14 d2.evaluation.evaluator]: [0mInference done 2061/8355. 0.1143 s / img. ETA=0:12:10
[32m[04/28 06:47:19 d2.evaluation.evaluator]: [0mInference done 2104/8355. 0.1143 s / img. ETA=0:12:05
[32m[04/28 06:47:24 d2.evaluation.evaluator]: [0mInference done 2147/8355. 0.1143 s / img. ETA=0:12:00
[32m[04/28 06:47:29 d2.evaluation.evaluator]: [0mInference done 2190/8355. 0.1144 s / img. ETA=0:11:55
[32m[04/28 06:47:34 d2.evaluation.evaluator]: [0mInference done 2232/8355. 0.1144 s / img. ETA=0:11:51
[32m[04/28 06:47:39 d2.evaluation.evaluator]: [0mInference done 2275/8355. 0.1144 s / img. ETA=0:11:46
[32m[04/28 06:47:44 d2.evaluation.evaluator]: [0mInference done 2318/8355. 0.1145 s / img. ETA=0:11:41
[32m[04/28 06:47:49 d2.evaluation.evaluator]: [0mInference done 2361/8355. 0.1145 s / img. ETA=0:11:36
[32m[04/28 06:47:54 d2.evaluation.evaluator]: [0mInference done 2402/8355. 0.1146 s / img. ETA=0:11:32
[32m[04/28 06:48:00 d2.evaluation.evaluator]: [0mInference done 2445/8355. 0.1146 s / img. ETA=0:11:27
[32m[04/28 06:48:05 d2.evaluation.evaluator]: [0mInference done 2488/8355. 0.1146 s / img. ETA=0:11:22
[32m[04/28 06:48:10 d2.evaluation.evaluator]: [0mInference done 2531/8355. 0.1146 s / img. ETA=0:11:17
[32m[04/28 06:48:15 d2.evaluation.evaluator]: [0mInference done 2574/8355. 0.1146 s / img. ETA=0:11:12
[32m[04/28 06:48:20 d2.evaluation.evaluator]: [0mInference done 2617/8355. 0.1146 s / img. ETA=0:11:08
[32m[04/28 06:48:25 d2.evaluation.evaluator]: [0mInference done 2660/8355. 0.1146 s / img. ETA=0:11:03
[32m[04/28 06:48:30 d2.evaluation.evaluator]: [0mInference done 2703/8355. 0.1147 s / img. ETA=0:10:58
[32m[04/28 06:48:35 d2.evaluation.evaluator]: [0mInference done 2746/8355. 0.1147 s / img. ETA=0:10:53
[32m[04/28 06:48:40 d2.evaluation.evaluator]: [0mInference done 2789/8355. 0.1147 s / img. ETA=0:10:48
[32m[04/28 06:48:45 d2.evaluation.evaluator]: [0mInference done 2832/8355. 0.1147 s / img. ETA=0:10:43
[32m[04/28 06:48:50 d2.evaluation.evaluator]: [0mInference done 2875/8355. 0.1147 s / img. ETA=0:10:38
[32m[04/28 06:48:55 d2.evaluation.evaluator]: [0mInference done 2918/8355. 0.1147 s / img. ETA=0:10:33
[32m[04/28 06:49:00 d2.evaluation.evaluator]: [0mInference done 2961/8355. 0.1147 s / img. ETA=0:10:28
[32m[04/28 06:49:05 d2.evaluation.evaluator]: [0mInference done 3004/8355. 0.1147 s / img. ETA=0:10:23
[32m[04/28 06:49:10 d2.evaluation.evaluator]: [0mInference done 3047/8355. 0.1147 s / img. ETA=0:10:18
[32m[04/28 06:49:15 d2.evaluation.evaluator]: [0mInference done 3090/8355. 0.1147 s / img. ETA=0:10:13
[32m[04/28 06:49:20 d2.evaluation.evaluator]: [0mInference done 3133/8355. 0.1147 s / img. ETA=0:10:08
[32m[04/28 06:49:25 d2.evaluation.evaluator]: [0mInference done 3176/8355. 0.1147 s / img. ETA=0:10:03
[32m[04/28 06:49:30 d2.evaluation.evaluator]: [0mInference done 3220/8355. 0.1147 s / img. ETA=0:09:58
[32m[04/28 06:49:35 d2.evaluation.evaluator]: [0mInference done 3264/8355. 0.1147 s / img. ETA=0:09:53
[32m[04/28 06:49:40 d2.evaluation.evaluator]: [0mInference done 3308/8355. 0.1147 s / img. ETA=0:09:47
[32m[04/28 06:49:45 d2.evaluation.evaluator]: [0mInference done 3352/8355. 0.1147 s / img. ETA=0:09:42
[32m[04/28 06:49:50 d2.evaluation.evaluator]: [0mInference done 3395/8355. 0.1147 s / img. ETA=0:09:37
[32m[04/28 06:49:56 d2.evaluation.evaluator]: [0mInference done 3438/8355. 0.1147 s / img. ETA=0:09:32
[32m[04/28 06:50:01 d2.evaluation.evaluator]: [0mInference done 3482/8355. 0.1147 s / img. ETA=0:09:27
[32m[04/28 06:50:06 d2.evaluation.evaluator]: [0mInference done 3525/8355. 0.1147 s / img. ETA=0:09:22
[32m[04/28 06:50:11 d2.evaluation.evaluator]: [0mInference done 3569/8355. 0.1147 s / img. ETA=0:09:17
[32m[04/28 06:50:16 d2.evaluation.evaluator]: [0mInference done 3612/8355. 0.1147 s / img. ETA=0:09:12
[32m[04/28 06:50:21 d2.evaluation.evaluator]: [0mInference done 3655/8355. 0.1147 s / img. ETA=0:09:07
[32m[04/28 06:50:26 d2.evaluation.evaluator]: [0mInference done 3698/8355. 0.1147 s / img. ETA=0:09:02
[32m[04/28 06:50:31 d2.evaluation.evaluator]: [0mInference done 3741/8355. 0.1147 s / img. ETA=0:08:57
[32m[04/28 06:50:36 d2.evaluation.evaluator]: [0mInference done 3785/8355. 0.1147 s / img. ETA=0:08:52
[32m[04/28 06:50:41 d2.evaluation.evaluator]: [0mInference done 3828/8355. 0.1147 s / img. ETA=0:08:47
[32m[04/28 06:50:46 d2.evaluation.evaluator]: [0mInference done 3871/8355. 0.1147 s / img. ETA=0:08:42
[32m[04/28 06:50:51 d2.evaluation.evaluator]: [0mInference done 3915/8355. 0.1147 s / img. ETA=0:08:37
[32m[04/28 06:50:56 d2.evaluation.evaluator]: [0mInference done 3959/8355. 0.1147 s / img. ETA=0:08:32
[32m[04/28 06:51:01 d2.evaluation.evaluator]: [0mInference done 4002/8355. 0.1147 s / img. ETA=0:08:27
[32m[04/28 06:51:06 d2.evaluation.evaluator]: [0mInference done 4045/8355. 0.1147 s / img. ETA=0:08:22
[32m[04/28 06:51:11 d2.evaluation.evaluator]: [0mInference done 4088/8355. 0.1147 s / img. ETA=0:08:17
[32m[04/28 06:51:16 d2.evaluation.evaluator]: [0mInference done 4131/8355. 0.1147 s / img. ETA=0:08:12
[32m[04/28 06:51:22 d2.evaluation.evaluator]: [0mInference done 4175/8355. 0.1147 s / img. ETA=0:08:07
[32m[04/28 06:51:27 d2.evaluation.evaluator]: [0mInference done 4218/8355. 0.1147 s / img. ETA=0:08:02
[32m[04/28 06:51:32 d2.evaluation.evaluator]: [0mInference done 4262/8355. 0.1147 s / img. ETA=0:07:57
[32m[04/28 06:51:37 d2.evaluation.evaluator]: [0mInference done 4306/8355. 0.1147 s / img. ETA=0:07:51
[32m[04/28 06:51:42 d2.evaluation.evaluator]: [0mInference done 4349/8355. 0.1147 s / img. ETA=0:07:46
[32m[04/28 06:51:47 d2.evaluation.evaluator]: [0mInference done 4393/8355. 0.1147 s / img. ETA=0:07:41
[32m[04/28 06:51:52 d2.evaluation.evaluator]: [0mInference done 4436/8355. 0.1147 s / img. ETA=0:07:36
[32m[04/28 06:51:57 d2.evaluation.evaluator]: [0mInference done 4480/8355. 0.1147 s / img. ETA=0:07:31
[32m[04/28 06:52:02 d2.evaluation.evaluator]: [0mInference done 4523/8355. 0.1147 s / img. ETA=0:07:26
[32m[04/28 06:52:07 d2.evaluation.evaluator]: [0mInference done 4566/8355. 0.1147 s / img. ETA=0:07:21
[32m[04/28 06:52:12 d2.evaluation.evaluator]: [0mInference done 4609/8355. 0.1147 s / img. ETA=0:07:16
[32m[04/28 06:52:17 d2.evaluation.evaluator]: [0mInference done 4652/8355. 0.1147 s / img. ETA=0:07:11
[32m[04/28 06:52:22 d2.evaluation.evaluator]: [0mInference done 4695/8355. 0.1147 s / img. ETA=0:07:06
[32m[04/28 06:52:27 d2.evaluation.evaluator]: [0mInference done 4738/8355. 0.1147 s / img. ETA=0:07:01
[32m[04/28 06:52:32 d2.evaluation.evaluator]: [0mInference done 4781/8355. 0.1147 s / img. ETA=0:06:56
[32m[04/28 06:52:37 d2.evaluation.evaluator]: [0mInference done 4824/8355. 0.1147 s / img. ETA=0:06:51
[32m[04/28 06:52:42 d2.evaluation.evaluator]: [0mInference done 4867/8355. 0.1148 s / img. ETA=0:06:46
[32m[04/28 06:52:47 d2.evaluation.evaluator]: [0mInference done 4910/8355. 0.1148 s / img. ETA=0:06:41
[32m[04/28 06:52:52 d2.evaluation.evaluator]: [0mInference done 4954/8355. 0.1147 s / img. ETA=0:06:36
[32m[04/28 06:52:58 d2.evaluation.evaluator]: [0mInference done 4997/8355. 0.1148 s / img. ETA=0:06:31
[32m[04/28 06:53:03 d2.evaluation.evaluator]: [0mInference done 5040/8355. 0.1148 s / img. ETA=0:06:26
[32m[04/28 06:53:08 d2.evaluation.evaluator]: [0mInference done 5083/8355. 0.1148 s / img. ETA=0:06:21
[32m[04/28 06:53:13 d2.evaluation.evaluator]: [0mInference done 5126/8355. 0.1148 s / img. ETA=0:06:16
[32m[04/28 06:53:18 d2.evaluation.evaluator]: [0mInference done 5169/8355. 0.1148 s / img. ETA=0:06:11
[32m[04/28 06:53:23 d2.evaluation.evaluator]: [0mInference done 5212/8355. 0.1148 s / img. ETA=0:06:06
[32m[04/28 06:53:28 d2.evaluation.evaluator]: [0mInference done 5256/8355. 0.1148 s / img. ETA=0:06:01
[32m[04/28 06:53:33 d2.evaluation.evaluator]: [0mInference done 5299/8355. 0.1148 s / img. ETA=0:05:56
[32m[04/28 06:53:38 d2.evaluation.evaluator]: [0mInference done 5342/8355. 0.1148 s / img. ETA=0:05:51
[32m[04/28 06:53:43 d2.evaluation.evaluator]: [0mInference done 5385/8355. 0.1148 s / img. ETA=0:05:46
[32m[04/28 06:53:48 d2.evaluation.evaluator]: [0mInference done 5428/8355. 0.1148 s / img. ETA=0:05:41
[32m[04/28 06:53:53 d2.evaluation.evaluator]: [0mInference done 5471/8355. 0.1148 s / img. ETA=0:05:36
[32m[04/28 06:53:58 d2.evaluation.evaluator]: [0mInference done 5514/8355. 0.1148 s / img. ETA=0:05:31
[32m[04/28 06:54:03 d2.evaluation.evaluator]: [0mInference done 5558/8355. 0.1148 s / img. ETA=0:05:26
[32m[04/28 06:54:08 d2.evaluation.evaluator]: [0mInference done 5601/8355. 0.1148 s / img. ETA=0:05:21
[32m[04/28 06:54:13 d2.evaluation.evaluator]: [0mInference done 5644/8355. 0.1148 s / img. ETA=0:05:16
[32m[04/28 06:54:18 d2.evaluation.evaluator]: [0mInference done 5687/8355. 0.1148 s / img. ETA=0:05:11
[32m[04/28 06:54:23 d2.evaluation.evaluator]: [0mInference done 5730/8355. 0.1148 s / img. ETA=0:05:06
[32m[04/28 06:54:28 d2.evaluation.evaluator]: [0mInference done 5773/8355. 0.1148 s / img. ETA=0:05:01
[32m[04/28 06:54:33 d2.evaluation.evaluator]: [0mInference done 5816/8355. 0.1148 s / img. ETA=0:04:56
[32m[04/28 06:54:38 d2.evaluation.evaluator]: [0mInference done 5859/8355. 0.1148 s / img. ETA=0:04:51
[32m[04/28 06:54:43 d2.evaluation.evaluator]: [0mInference done 5902/8355. 0.1148 s / img. ETA=0:04:46
[32m[04/28 06:54:48 d2.evaluation.evaluator]: [0mInference done 5945/8355. 0.1148 s / img. ETA=0:04:41
[32m[04/28 06:54:54 d2.evaluation.evaluator]: [0mInference done 5988/8355. 0.1148 s / img. ETA=0:04:36
[32m[04/28 06:54:59 d2.evaluation.evaluator]: [0mInference done 6031/8355. 0.1148 s / img. ETA=0:04:31
[32m[04/28 06:55:04 d2.evaluation.evaluator]: [0mInference done 6074/8355. 0.1148 s / img. ETA=0:04:26
[32m[04/28 06:55:09 d2.evaluation.evaluator]: [0mInference done 6117/8355. 0.1149 s / img. ETA=0:04:21
[32m[04/28 06:55:14 d2.evaluation.evaluator]: [0mInference done 6160/8355. 0.1149 s / img. ETA=0:04:16
[32m[04/28 06:55:19 d2.evaluation.evaluator]: [0mInference done 6203/8355. 0.1149 s / img. ETA=0:04:11
[32m[04/28 06:55:24 d2.evaluation.evaluator]: [0mInference done 6246/8355. 0.1149 s / img. ETA=0:04:06
[32m[04/28 06:55:29 d2.evaluation.evaluator]: [0mInference done 6289/8355. 0.1149 s / img. ETA=0:04:01
[32m[04/28 06:55:34 d2.evaluation.evaluator]: [0mInference done 6332/8355. 0.1149 s / img. ETA=0:03:56
[32m[04/28 06:55:39 d2.evaluation.evaluator]: [0mInference done 6375/8355. 0.1149 s / img. ETA=0:03:51
[32m[04/28 06:55:44 d2.evaluation.evaluator]: [0mInference done 6418/8355. 0.1149 s / img. ETA=0:03:46
[32m[04/28 06:55:49 d2.evaluation.evaluator]: [0mInference done 6461/8355. 0.1149 s / img. ETA=0:03:41
[32m[04/28 06:55:54 d2.evaluation.evaluator]: [0mInference done 6504/8355. 0.1149 s / img. ETA=0:03:36
[32m[04/28 06:55:59 d2.evaluation.evaluator]: [0mInference done 6547/8355. 0.1149 s / img. ETA=0:03:31
[32m[04/28 06:56:04 d2.evaluation.evaluator]: [0mInference done 6590/8355. 0.1149 s / img. ETA=0:03:26
[32m[04/28 06:56:09 d2.evaluation.evaluator]: [0mInference done 6633/8355. 0.1149 s / img. ETA=0:03:21
[32m[04/28 06:56:14 d2.evaluation.evaluator]: [0mInference done 6676/8355. 0.1149 s / img. ETA=0:03:16
[32m[04/28 06:56:19 d2.evaluation.evaluator]: [0mInference done 6720/8355. 0.1149 s / img. ETA=0:03:10
[32m[04/28 06:56:25 d2.evaluation.evaluator]: [0mInference done 6763/8355. 0.1149 s / img. ETA=0:03:05
[32m[04/28 06:56:30 d2.evaluation.evaluator]: [0mInference done 6807/8355. 0.1149 s / img. ETA=0:03:00
[32m[04/28 06:56:35 d2.evaluation.evaluator]: [0mInference done 6850/8355. 0.1149 s / img. ETA=0:02:55
[32m[04/28 06:56:40 d2.evaluation.evaluator]: [0mInference done 6893/8355. 0.1149 s / img. ETA=0:02:50
[32m[04/28 06:56:45 d2.evaluation.evaluator]: [0mInference done 6936/8355. 0.1149 s / img. ETA=0:02:45
[32m[04/28 06:56:50 d2.evaluation.evaluator]: [0mInference done 6979/8355. 0.1149 s / img. ETA=0:02:40
[32m[04/28 06:56:55 d2.evaluation.evaluator]: [0mInference done 7022/8355. 0.1149 s / img. ETA=0:02:35
[32m[04/28 06:57:00 d2.evaluation.evaluator]: [0mInference done 7065/8355. 0.1149 s / img. ETA=0:02:30
[32m[04/28 06:57:05 d2.evaluation.evaluator]: [0mInference done 7107/8355. 0.1149 s / img. ETA=0:02:25
[32m[04/28 06:57:10 d2.evaluation.evaluator]: [0mInference done 7150/8355. 0.1149 s / img. ETA=0:02:20
[32m[04/28 06:57:15 d2.evaluation.evaluator]: [0mInference done 7193/8355. 0.1150 s / img. ETA=0:02:15
[32m[04/28 06:57:20 d2.evaluation.evaluator]: [0mInference done 7236/8355. 0.1150 s / img. ETA=0:02:10
[32m[04/28 06:57:25 d2.evaluation.evaluator]: [0mInference done 7279/8355. 0.1150 s / img. ETA=0:02:05
[32m[04/28 06:57:30 d2.evaluation.evaluator]: [0mInference done 7322/8355. 0.1150 s / img. ETA=0:02:00
[32m[04/28 06:57:35 d2.evaluation.evaluator]: [0mInference done 7365/8355. 0.1150 s / img. ETA=0:01:55
[32m[04/28 06:57:40 d2.evaluation.evaluator]: [0mInference done 7408/8355. 0.1150 s / img. ETA=0:01:50
[32m[04/28 06:57:45 d2.evaluation.evaluator]: [0mInference done 7451/8355. 0.1150 s / img. ETA=0:01:45
[32m[04/28 06:57:50 d2.evaluation.evaluator]: [0mInference done 7494/8355. 0.1150 s / img. ETA=0:01:40
[32m[04/28 06:57:55 d2.evaluation.evaluator]: [0mInference done 7537/8355. 0.1150 s / img. ETA=0:01:35
[32m[04/28 06:58:01 d2.evaluation.evaluator]: [0mInference done 7580/8355. 0.1150 s / img. ETA=0:01:30
[32m[04/28 06:58:06 d2.evaluation.evaluator]: [0mInference done 7623/8355. 0.1150 s / img. ETA=0:01:25
[32m[04/28 06:58:11 d2.evaluation.evaluator]: [0mInference done 7666/8355. 0.1150 s / img. ETA=0:01:20
[32m[04/28 06:58:16 d2.evaluation.evaluator]: [0mInference done 7709/8355. 0.1150 s / img. ETA=0:01:15
[32m[04/28 06:58:21 d2.evaluation.evaluator]: [0mInference done 7752/8355. 0.1150 s / img. ETA=0:01:10
[32m[04/28 06:58:26 d2.evaluation.evaluator]: [0mInference done 7795/8355. 0.1150 s / img. ETA=0:01:05
[32m[04/28 06:58:31 d2.evaluation.evaluator]: [0mInference done 7838/8355. 0.1150 s / img. ETA=0:01:00
[32m[04/28 06:58:36 d2.evaluation.evaluator]: [0mInference done 7881/8355. 0.1150 s / img. ETA=0:00:55
[32m[04/28 06:58:41 d2.evaluation.evaluator]: [0mInference done 7924/8355. 0.1150 s / img. ETA=0:00:50
[32m[04/28 06:58:46 d2.evaluation.evaluator]: [0mInference done 7967/8355. 0.1150 s / img. ETA=0:00:45
[32m[04/28 06:58:51 d2.evaluation.evaluator]: [0mInference done 8010/8355. 0.1150 s / img. ETA=0:00:40
[32m[04/28 06:58:56 d2.evaluation.evaluator]: [0mInference done 8054/8355. 0.1150 s / img. ETA=0:00:35
[32m[04/28 06:59:01 d2.evaluation.evaluator]: [0mInference done 8097/8355. 0.1150 s / img. ETA=0:00:30
[32m[04/28 06:59:06 d2.evaluation.evaluator]: [0mInference done 8140/8355. 0.1150 s / img. ETA=0:00:25
[32m[04/28 06:59:11 d2.evaluation.evaluator]: [0mInference done 8184/8355. 0.1150 s / img. ETA=0:00:19
[32m[04/28 06:59:16 d2.evaluation.evaluator]: [0mInference done 8227/8355. 0.1150 s / img. ETA=0:00:14
[32m[04/28 06:59:21 d2.evaluation.evaluator]: [0mInference done 8270/8355. 0.1150 s / img. ETA=0:00:09
[32m[04/28 06:59:26 d2.evaluation.evaluator]: [0mInference done 8312/8355. 0.1150 s / img. ETA=0:00:05
[32m[04/28 06:59:31 d2.evaluation.evaluator]: [0mInference done 8355/8355. 0.1150 s / img. ETA=0:00:00
[32m[04/28 06:59:31 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:15.824083 (0.116865 s / img per device, on 1 devices)
[32m[04/28 06:59:31 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:00 (0.115023 s / img per device, on 1 devices)
[32m[04/28 06:59:32 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 06:59:32 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 06:59:32 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.43s).
Accumulating evaluation results...
DONE (t=2.27s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.827
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.430
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.352
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.576
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.173
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.512
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.531
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.442
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.750
[32m[04/28 06:59:55 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.121 | 82.739 | 42.978 | 35.226 | 57.638 | 70.620 |
[32m[04/28 06:59:55 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 45.057 | bicycle       | 35.884 | car            | 54.423 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 06:59:55 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 06:59:55 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 06:59:55 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 06:59:57 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1145 s / img. ETA=0:02:24
[32m[04/28 07:00:02 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1144 s / img. ETA=0:02:19
[32m[04/28 07:00:07 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1146 s / img. ETA=0:02:15
[32m[04/28 07:00:12 d2.evaluation.evaluator]: [0mInference done 141/1257. 0.1145 s / img. ETA=0:02:09
[32m[04/28 07:00:17 d2.evaluation.evaluator]: [0mInference done 184/1257. 0.1146 s / img. ETA=0:02:04
[32m[04/28 07:00:22 d2.evaluation.evaluator]: [0mInference done 227/1257. 0.1145 s / img. ETA=0:01:59
[32m[04/28 07:00:27 d2.evaluation.evaluator]: [0mInference done 270/1257. 0.1146 s / img. ETA=0:01:54
[32m[04/28 07:00:32 d2.evaluation.evaluator]: [0mInference done 314/1257. 0.1146 s / img. ETA=0:01:49
[32m[04/28 07:00:37 d2.evaluation.evaluator]: [0mInference done 357/1257. 0.1146 s / img. ETA=0:01:44
[32m[04/28 07:00:42 d2.evaluation.evaluator]: [0mInference done 400/1257. 0.1146 s / img. ETA=0:01:39
[32m[04/28 07:00:47 d2.evaluation.evaluator]: [0mInference done 443/1257. 0.1146 s / img. ETA=0:01:34
[32m[04/28 07:00:52 d2.evaluation.evaluator]: [0mInference done 486/1257. 0.1146 s / img. ETA=0:01:29
[32m[04/28 07:00:57 d2.evaluation.evaluator]: [0mInference done 529/1257. 0.1146 s / img. ETA=0:01:24
[32m[04/28 07:01:02 d2.evaluation.evaluator]: [0mInference done 572/1257. 0.1146 s / img. ETA=0:01:19
[32m[04/28 07:01:07 d2.evaluation.evaluator]: [0mInference done 615/1257. 0.1146 s / img. ETA=0:01:14
[32m[04/28 07:01:12 d2.evaluation.evaluator]: [0mInference done 658/1257. 0.1146 s / img. ETA=0:01:09
[32m[04/28 07:01:17 d2.evaluation.evaluator]: [0mInference done 701/1257. 0.1146 s / img. ETA=0:01:04
[32m[04/28 07:01:22 d2.evaluation.evaluator]: [0mInference done 744/1257. 0.1146 s / img. ETA=0:00:59
[32m[04/28 07:01:27 d2.evaluation.evaluator]: [0mInference done 787/1257. 0.1146 s / img. ETA=0:00:54
[32m[04/28 07:01:32 d2.evaluation.evaluator]: [0mInference done 830/1257. 0.1147 s / img. ETA=0:00:49
[32m[04/28 07:01:37 d2.evaluation.evaluator]: [0mInference done 873/1257. 0.1147 s / img. ETA=0:00:44
[32m[04/28 07:01:42 d2.evaluation.evaluator]: [0mInference done 916/1257. 0.1147 s / img. ETA=0:00:39
[32m[04/28 07:01:47 d2.evaluation.evaluator]: [0mInference done 959/1257. 0.1147 s / img. ETA=0:00:34
[32m[04/28 07:01:52 d2.evaluation.evaluator]: [0mInference done 1002/1257. 0.1148 s / img. ETA=0:00:29
[32m[04/28 07:01:58 d2.evaluation.evaluator]: [0mInference done 1045/1257. 0.1148 s / img. ETA=0:00:24
[32m[04/28 07:02:03 d2.evaluation.evaluator]: [0mInference done 1088/1257. 0.1148 s / img. ETA=0:00:19
[32m[04/28 07:02:08 d2.evaluation.evaluator]: [0mInference done 1131/1257. 0.1148 s / img. ETA=0:00:14
[32m[04/28 07:02:13 d2.evaluation.evaluator]: [0mInference done 1173/1257. 0.1149 s / img. ETA=0:00:09
[32m[04/28 07:02:18 d2.evaluation.evaluator]: [0mInference done 1216/1257. 0.1149 s / img. ETA=0:00:04
[32m[04/28 07:02:22 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.272015 (0.116831 s / img per device, on 1 devices)
[32m[04/28 07:02:22 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:23 (0.114925 s / img per device, on 1 devices)
[32m[04/28 07:02:23 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 07:02:23 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 07:02:23 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.22s).
Accumulating evaluation results...
DONE (t=0.40s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.747
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.371
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.301
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.462
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.561
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.493
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.500
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.430
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.615
[32m[04/28 07:02:26 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.598 | 74.673 | 37.093 | 30.119 | 46.173 | 56.128 |
[32m[04/28 07:02:26 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 45.094 | bicycle       | 18.320 | car            | 55.380 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  9  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 07:02:27 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 07:02:27 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 07:02:27 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 07:02:28 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 07:02:28 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 07:02:28 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 07:02:28 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 07:02:48 d2.utils.events]: [0m eta: 0:16:38  iter: 19  total_loss: 0.505  loss_cls: 0.150  loss_box_reg: 0.294  loss_rpn_cls: 0.012  loss_rpn_loc: 0.048  time: 1.0048  data_time: 0.0194  lr: 0.000100  max_mem: 5397M
[32m[04/28 07:03:09 d2.utils.events]: [0m eta: 0:16:17  iter: 39  total_loss: 0.487  loss_cls: 0.147  loss_box_reg: 0.286  loss_rpn_cls: 0.012  loss_rpn_loc: 0.051  time: 1.0080  data_time: 0.0077  lr: 0.000200  max_mem: 5397M
[32m[04/28 07:03:29 d2.utils.events]: [0m eta: 0:15:55  iter: 59  total_loss: 0.506  loss_cls: 0.167  loss_box_reg: 0.285  loss_rpn_cls: 0.010  loss_rpn_loc: 0.036  time: 1.0121  data_time: 0.0075  lr: 0.000300  max_mem: 5397M
[32m[04/28 07:03:50 d2.utils.events]: [0m eta: 0:15:42  iter: 79  total_loss: 0.547  loss_cls: 0.172  loss_box_reg: 0.322  loss_rpn_cls: 0.009  loss_rpn_loc: 0.046  time: 1.0243  data_time: 0.0078  lr: 0.000400  max_mem: 5397M
[32m[04/28 07:04:10 d2.utils.events]: [0m eta: 0:15:18  iter: 99  total_loss: 0.479  loss_cls: 0.155  loss_box_reg: 0.287  loss_rpn_cls: 0.007  loss_rpn_loc: 0.037  time: 1.0211  data_time: 0.0076  lr: 0.000500  max_mem: 5397M
[32m[04/28 07:04:31 d2.utils.events]: [0m eta: 0:14:57  iter: 119  total_loss: 0.514  loss_cls: 0.157  loss_box_reg: 0.309  loss_rpn_cls: 0.009  loss_rpn_loc: 0.035  time: 1.0203  data_time: 0.0075  lr: 0.000599  max_mem: 5397M
[32m[04/28 07:04:51 d2.utils.events]: [0m eta: 0:14:37  iter: 139  total_loss: 0.588  loss_cls: 0.171  loss_box_reg: 0.335  loss_rpn_cls: 0.011  loss_rpn_loc: 0.051  time: 1.0202  data_time: 0.0076  lr: 0.000699  max_mem: 5397M
[32m[04/28 07:05:12 d2.utils.events]: [0m eta: 0:14:17  iter: 159  total_loss: 0.506  loss_cls: 0.160  loss_box_reg: 0.263  loss_rpn_cls: 0.008  loss_rpn_loc: 0.039  time: 1.0206  data_time: 0.0080  lr: 0.000799  max_mem: 5397M
[32m[04/28 07:05:32 d2.utils.events]: [0m eta: 0:14:00  iter: 179  total_loss: 0.561  loss_cls: 0.177  loss_box_reg: 0.320  loss_rpn_cls: 0.010  loss_rpn_loc: 0.046  time: 1.0203  data_time: 0.0080  lr: 0.000899  max_mem: 5397M
[32m[04/28 07:05:53 d2.utils.events]: [0m eta: 0:13:38  iter: 199  total_loss: 0.513  loss_cls: 0.160  loss_box_reg: 0.301  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 1.0193  data_time: 0.0078  lr: 0.000999  max_mem: 5397M
[32m[04/28 07:06:13 d2.utils.events]: [0m eta: 0:13:19  iter: 219  total_loss: 0.527  loss_cls: 0.165  loss_box_reg: 0.309  loss_rpn_cls: 0.009  loss_rpn_loc: 0.046  time: 1.0209  data_time: 0.0083  lr: 0.001099  max_mem: 5397M
[32m[04/28 07:06:34 d2.utils.events]: [0m eta: 0:13:00  iter: 239  total_loss: 0.510  loss_cls: 0.160  loss_box_reg: 0.298  loss_rpn_cls: 0.010  loss_rpn_loc: 0.039  time: 1.0224  data_time: 0.0078  lr: 0.001199  max_mem: 5397M
[32m[04/28 07:06:55 d2.utils.events]: [0m eta: 0:12:40  iter: 259  total_loss: 0.471  loss_cls: 0.144  loss_box_reg: 0.275  loss_rpn_cls: 0.008  loss_rpn_loc: 0.039  time: 1.0234  data_time: 0.0078  lr: 0.001299  max_mem: 5397M
[32m[04/28 07:07:15 d2.utils.events]: [0m eta: 0:12:19  iter: 279  total_loss: 0.483  loss_cls: 0.144  loss_box_reg: 0.285  loss_rpn_cls: 0.011  loss_rpn_loc: 0.045  time: 1.0223  data_time: 0.0077  lr: 0.001399  max_mem: 5397M
[32m[04/28 07:07:36 d2.utils.events]: [0m eta: 0:12:00  iter: 299  total_loss: 0.483  loss_cls: 0.173  loss_box_reg: 0.267  loss_rpn_cls: 0.008  loss_rpn_loc: 0.041  time: 1.0240  data_time: 0.0078  lr: 0.001499  max_mem: 5397M
[32m[04/28 07:07:57 d2.utils.events]: [0m eta: 0:11:39  iter: 319  total_loss: 0.514  loss_cls: 0.166  loss_box_reg: 0.301  loss_rpn_cls: 0.008  loss_rpn_loc: 0.052  time: 1.0239  data_time: 0.0076  lr: 0.001598  max_mem: 5397M
[32m[04/28 07:08:18 d2.utils.events]: [0m eta: 0:11:19  iter: 339  total_loss: 0.599  loss_cls: 0.165  loss_box_reg: 0.334  loss_rpn_cls: 0.007  loss_rpn_loc: 0.057  time: 1.0250  data_time: 0.0078  lr: 0.001698  max_mem: 5397M
[32m[04/28 07:08:38 d2.utils.events]: [0m eta: 0:11:00  iter: 359  total_loss: 0.490  loss_cls: 0.151  loss_box_reg: 0.285  loss_rpn_cls: 0.005  loss_rpn_loc: 0.050  time: 1.0258  data_time: 0.0080  lr: 0.001798  max_mem: 5397M
[32m[04/28 07:08:59 d2.utils.events]: [0m eta: 0:10:41  iter: 379  total_loss: 0.504  loss_cls: 0.155  loss_box_reg: 0.295  loss_rpn_cls: 0.009  loss_rpn_loc: 0.042  time: 1.0257  data_time: 0.0076  lr: 0.001898  max_mem: 5397M
[32m[04/28 07:09:20 d2.utils.events]: [0m eta: 0:10:22  iter: 399  total_loss: 0.500  loss_cls: 0.150  loss_box_reg: 0.290  loss_rpn_cls: 0.009  loss_rpn_loc: 0.043  time: 1.0272  data_time: 0.0077  lr: 0.001998  max_mem: 5397M
[32m[04/28 07:09:41 d2.utils.events]: [0m eta: 0:10:02  iter: 419  total_loss: 0.523  loss_cls: 0.170  loss_box_reg: 0.307  loss_rpn_cls: 0.006  loss_rpn_loc: 0.050  time: 1.0283  data_time: 0.0079  lr: 0.002098  max_mem: 5397M
[32m[04/28 07:10:01 d2.utils.events]: [0m eta: 0:09:40  iter: 439  total_loss: 0.552  loss_cls: 0.159  loss_box_reg: 0.306  loss_rpn_cls: 0.009  loss_rpn_loc: 0.043  time: 1.0274  data_time: 0.0075  lr: 0.002198  max_mem: 5397M
[32m[04/28 07:10:22 d2.utils.events]: [0m eta: 0:09:19  iter: 459  total_loss: 0.554  loss_cls: 0.163  loss_box_reg: 0.336  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0272  data_time: 0.0079  lr: 0.002298  max_mem: 5397M
[32m[04/28 07:10:42 d2.utils.events]: [0m eta: 0:08:58  iter: 479  total_loss: 0.603  loss_cls: 0.176  loss_box_reg: 0.351  loss_rpn_cls: 0.007  loss_rpn_loc: 0.060  time: 1.0273  data_time: 0.0075  lr: 0.002398  max_mem: 5397M
[32m[04/28 07:11:03 d2.utils.events]: [0m eta: 0:08:35  iter: 499  total_loss: 0.559  loss_cls: 0.184  loss_box_reg: 0.326  loss_rpn_cls: 0.007  loss_rpn_loc: 0.054  time: 1.0264  data_time: 0.0078  lr: 0.002498  max_mem: 5397M
[32m[04/28 07:11:23 d2.utils.events]: [0m eta: 0:08:15  iter: 519  total_loss: 0.484  loss_cls: 0.149  loss_box_reg: 0.288  loss_rpn_cls: 0.011  loss_rpn_loc: 0.039  time: 1.0266  data_time: 0.0077  lr: 0.002597  max_mem: 5397M
[32m[04/28 07:11:43 d2.utils.events]: [0m eta: 0:07:54  iter: 539  total_loss: 0.602  loss_cls: 0.188  loss_box_reg: 0.347  loss_rpn_cls: 0.011  loss_rpn_loc: 0.056  time: 1.0257  data_time: 0.0076  lr: 0.002697  max_mem: 5397M
[32m[04/28 07:12:04 d2.utils.events]: [0m eta: 0:07:34  iter: 559  total_loss: 0.562  loss_cls: 0.171  loss_box_reg: 0.334  loss_rpn_cls: 0.011  loss_rpn_loc: 0.051  time: 1.0257  data_time: 0.0079  lr: 0.002797  max_mem: 5397M
[32m[04/28 07:12:25 d2.utils.events]: [0m eta: 0:07:13  iter: 579  total_loss: 0.571  loss_cls: 0.174  loss_box_reg: 0.330  loss_rpn_cls: 0.010  loss_rpn_loc: 0.053  time: 1.0259  data_time: 0.0078  lr: 0.002897  max_mem: 5397M
[32m[04/28 07:12:45 d2.utils.events]: [0m eta: 0:06:52  iter: 599  total_loss: 0.584  loss_cls: 0.181  loss_box_reg: 0.329  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 1.0260  data_time: 0.0078  lr: 0.002997  max_mem: 5397M
[32m[04/28 07:13:06 d2.utils.events]: [0m eta: 0:06:31  iter: 619  total_loss: 0.516  loss_cls: 0.160  loss_box_reg: 0.310  loss_rpn_cls: 0.007  loss_rpn_loc: 0.043  time: 1.0256  data_time: 0.0078  lr: 0.003097  max_mem: 5397M
[32m[04/28 07:13:26 d2.utils.events]: [0m eta: 0:06:11  iter: 639  total_loss: 0.557  loss_cls: 0.181  loss_box_reg: 0.319  loss_rpn_cls: 0.009  loss_rpn_loc: 0.051  time: 1.0258  data_time: 0.0075  lr: 0.003197  max_mem: 5397M
[32m[04/28 07:13:47 d2.utils.events]: [0m eta: 0:05:51  iter: 659  total_loss: 0.548  loss_cls: 0.165  loss_box_reg: 0.336  loss_rpn_cls: 0.007  loss_rpn_loc: 0.049  time: 1.0256  data_time: 0.0076  lr: 0.003297  max_mem: 5397M
[32m[04/28 07:14:07 d2.utils.events]: [0m eta: 0:05:30  iter: 679  total_loss: 0.531  loss_cls: 0.161  loss_box_reg: 0.321  loss_rpn_cls: 0.009  loss_rpn_loc: 0.041  time: 1.0257  data_time: 0.0078  lr: 0.003397  max_mem: 5397M
[32m[04/28 07:14:28 d2.utils.events]: [0m eta: 0:05:10  iter: 699  total_loss: 0.605  loss_cls: 0.171  loss_box_reg: 0.329  loss_rpn_cls: 0.011  loss_rpn_loc: 0.058  time: 1.0258  data_time: 0.0077  lr: 0.003497  max_mem: 5397M
[32m[04/28 07:14:48 d2.utils.events]: [0m eta: 0:04:49  iter: 719  total_loss: 0.553  loss_cls: 0.177  loss_box_reg: 0.324  loss_rpn_cls: 0.014  loss_rpn_loc: 0.047  time: 1.0253  data_time: 0.0076  lr: 0.003596  max_mem: 5397M
[32m[04/28 07:15:09 d2.utils.events]: [0m eta: 0:04:28  iter: 739  total_loss: 0.578  loss_cls: 0.181  loss_box_reg: 0.331  loss_rpn_cls: 0.009  loss_rpn_loc: 0.054  time: 1.0252  data_time: 0.0075  lr: 0.003696  max_mem: 5397M
[32m[04/28 07:15:29 d2.utils.events]: [0m eta: 0:04:07  iter: 759  total_loss: 0.512  loss_cls: 0.163  loss_box_reg: 0.294  loss_rpn_cls: 0.009  loss_rpn_loc: 0.038  time: 1.0250  data_time: 0.0076  lr: 0.003796  max_mem: 5397M
[32m[04/28 07:15:50 d2.utils.events]: [0m eta: 0:03:47  iter: 779  total_loss: 0.500  loss_cls: 0.153  loss_box_reg: 0.295  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0251  data_time: 0.0077  lr: 0.003896  max_mem: 5397M
[32m[04/28 07:16:09 d2.utils.events]: [0m eta: 0:03:26  iter: 799  total_loss: 0.519  loss_cls: 0.155  loss_box_reg: 0.301  loss_rpn_cls: 0.007  loss_rpn_loc: 0.054  time: 1.0239  data_time: 0.0078  lr: 0.003996  max_mem: 5397M
[32m[04/28 07:16:30 d2.utils.events]: [0m eta: 0:03:06  iter: 819  total_loss: 0.627  loss_cls: 0.191  loss_box_reg: 0.348  loss_rpn_cls: 0.011  loss_rpn_loc: 0.063  time: 1.0241  data_time: 0.0078  lr: 0.004096  max_mem: 5397M
[32m[04/28 07:16:50 d2.utils.events]: [0m eta: 0:02:45  iter: 839  total_loss: 0.578  loss_cls: 0.186  loss_box_reg: 0.324  loss_rpn_cls: 0.010  loss_rpn_loc: 0.052  time: 1.0239  data_time: 0.0075  lr: 0.004196  max_mem: 5397M
[32m[04/28 07:17:11 d2.utils.events]: [0m eta: 0:02:24  iter: 859  total_loss: 0.563  loss_cls: 0.176  loss_box_reg: 0.347  loss_rpn_cls: 0.008  loss_rpn_loc: 0.048  time: 1.0239  data_time: 0.0077  lr: 0.004296  max_mem: 5397M
[32m[04/28 07:17:32 d2.utils.events]: [0m eta: 0:02:04  iter: 879  total_loss: 0.561  loss_cls: 0.169  loss_box_reg: 0.302  loss_rpn_cls: 0.009  loss_rpn_loc: 0.050  time: 1.0241  data_time: 0.0077  lr: 0.004396  max_mem: 5397M
[32m[04/28 07:17:53 d2.utils.events]: [0m eta: 0:01:43  iter: 899  total_loss: 0.549  loss_cls: 0.167  loss_box_reg: 0.325  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0249  data_time: 0.0075  lr: 0.004496  max_mem: 5397M
[32m[04/28 07:18:13 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.515  loss_cls: 0.161  loss_box_reg: 0.284  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 1.0248  data_time: 0.0075  lr: 0.004595  max_mem: 5397M
[32m[04/28 07:18:34 d2.utils.events]: [0m eta: 0:01:02  iter: 939  total_loss: 0.538  loss_cls: 0.171  loss_box_reg: 0.312  loss_rpn_cls: 0.010  loss_rpn_loc: 0.049  time: 1.0249  data_time: 0.0076  lr: 0.004695  max_mem: 5397M
[32m[04/28 07:18:54 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.559  loss_cls: 0.177  loss_box_reg: 0.306  loss_rpn_cls: 0.010  loss_rpn_loc: 0.051  time: 1.0249  data_time: 0.0074  lr: 0.004795  max_mem: 5397M
[32m[04/28 07:19:15 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.547  loss_cls: 0.177  loss_box_reg: 0.300  loss_rpn_cls: 0.009  loss_rpn_loc: 0.052  time: 1.0250  data_time: 0.0079  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 07:19:38 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 07:19:38 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 07:19:38 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 07:19:38 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.589  loss_cls: 0.167  loss_box_reg: 0.347  loss_rpn_cls: 0.007  loss_rpn_loc: 0.057  time: 1.0252  data_time: 0.0076  lr: 0.004995  max_mem: 5397M
[32m[04/28 07:19:39 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:03 (1.0263 s / it)
[32m[04/28 07:19:39 d2.engine.hooks]: [0mTotal training time: 0:17:08 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 07:19:40 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 07:19:40 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 07:19:40 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 07:19:42 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1136 s / img. ETA=0:15:59
[32m[04/28 07:19:47 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1136 s / img. ETA=0:15:56
[32m[04/28 07:19:52 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1136 s / img. ETA=0:15:51
[32m[04/28 07:19:57 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1136 s / img. ETA=0:15:46
[32m[04/28 07:20:02 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1137 s / img. ETA=0:15:42
[32m[04/28 07:20:07 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1137 s / img. ETA=0:15:37
[32m[04/28 07:20:12 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1137 s / img. ETA=0:15:32
[32m[04/28 07:20:17 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1138 s / img. ETA=0:15:27
[32m[04/28 07:20:22 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1138 s / img. ETA=0:15:22
[32m[04/28 07:20:27 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1138 s / img. ETA=0:15:17
[32m[04/28 07:20:32 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1138 s / img. ETA=0:15:12
[32m[04/28 07:20:38 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1137 s / img. ETA=0:15:07
[32m[04/28 07:20:43 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1137 s / img. ETA=0:15:01
[32m[04/28 07:20:48 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1137 s / img. ETA=0:14:56
[32m[04/28 07:20:53 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1137 s / img. ETA=0:14:51
[32m[04/28 07:20:58 d2.evaluation.evaluator]: [0mInference done 671/8355. 0.1137 s / img. ETA=0:14:46
[32m[04/28 07:21:03 d2.evaluation.evaluator]: [0mInference done 715/8355. 0.1138 s / img. ETA=0:14:42
[32m[04/28 07:21:08 d2.evaluation.evaluator]: [0mInference done 759/8355. 0.1138 s / img. ETA=0:14:37
[32m[04/28 07:21:13 d2.evaluation.evaluator]: [0mInference done 803/8355. 0.1138 s / img. ETA=0:14:32
[32m[04/28 07:21:18 d2.evaluation.evaluator]: [0mInference done 847/8355. 0.1138 s / img. ETA=0:14:27
[32m[04/28 07:21:23 d2.evaluation.evaluator]: [0mInference done 891/8355. 0.1139 s / img. ETA=0:14:22
[32m[04/28 07:21:28 d2.evaluation.evaluator]: [0mInference done 934/8355. 0.1139 s / img. ETA=0:14:17
[32m[04/28 07:21:33 d2.evaluation.evaluator]: [0mInference done 977/8355. 0.1140 s / img. ETA=0:14:13
[32m[04/28 07:21:39 d2.evaluation.evaluator]: [0mInference done 1021/8355. 0.1140 s / img. ETA=0:14:08
[32m[04/28 07:21:44 d2.evaluation.evaluator]: [0mInference done 1065/8355. 0.1140 s / img. ETA=0:14:03
[32m[04/28 07:21:49 d2.evaluation.evaluator]: [0mInference done 1109/8355. 0.1140 s / img. ETA=0:13:58
[32m[04/28 07:21:54 d2.evaluation.evaluator]: [0mInference done 1153/8355. 0.1140 s / img. ETA=0:13:53
[32m[04/28 07:21:59 d2.evaluation.evaluator]: [0mInference done 1197/8355. 0.1140 s / img. ETA=0:13:48
[32m[04/28 07:22:04 d2.evaluation.evaluator]: [0mInference done 1240/8355. 0.1141 s / img. ETA=0:13:43
[32m[04/28 07:22:09 d2.evaluation.evaluator]: [0mInference done 1284/8355. 0.1141 s / img. ETA=0:13:38
[32m[04/28 07:22:14 d2.evaluation.evaluator]: [0mInference done 1328/8355. 0.1140 s / img. ETA=0:13:33
[32m[04/28 07:22:19 d2.evaluation.evaluator]: [0mInference done 1372/8355. 0.1140 s / img. ETA=0:13:28
[32m[04/28 07:22:24 d2.evaluation.evaluator]: [0mInference done 1416/8355. 0.1140 s / img. ETA=0:13:23
[32m[04/28 07:22:29 d2.evaluation.evaluator]: [0mInference done 1460/8355. 0.1140 s / img. ETA=0:13:18
[32m[04/28 07:22:34 d2.evaluation.evaluator]: [0mInference done 1503/8355. 0.1141 s / img. ETA=0:13:13
[32m[04/28 07:22:39 d2.evaluation.evaluator]: [0mInference done 1546/8355. 0.1141 s / img. ETA=0:13:08
[32m[04/28 07:22:44 d2.evaluation.evaluator]: [0mInference done 1589/8355. 0.1141 s / img. ETA=0:13:03
[32m[04/28 07:22:50 d2.evaluation.evaluator]: [0mInference done 1632/8355. 0.1142 s / img. ETA=0:12:59
[32m[04/28 07:22:55 d2.evaluation.evaluator]: [0mInference done 1675/8355. 0.1142 s / img. ETA=0:12:54
[32m[04/28 07:23:00 d2.evaluation.evaluator]: [0mInference done 1718/8355. 0.1142 s / img. ETA=0:12:49
[32m[04/28 07:23:05 d2.evaluation.evaluator]: [0mInference done 1761/8355. 0.1142 s / img. ETA=0:12:44
[32m[04/28 07:23:10 d2.evaluation.evaluator]: [0mInference done 1804/8355. 0.1143 s / img. ETA=0:12:39
[32m[04/28 07:23:15 d2.evaluation.evaluator]: [0mInference done 1847/8355. 0.1143 s / img. ETA=0:12:35
[32m[04/28 07:23:20 d2.evaluation.evaluator]: [0mInference done 1890/8355. 0.1143 s / img. ETA=0:12:30
[32m[04/28 07:23:25 d2.evaluation.evaluator]: [0mInference done 1933/8355. 0.1143 s / img. ETA=0:12:25
[32m[04/28 07:23:30 d2.evaluation.evaluator]: [0mInference done 1976/8355. 0.1144 s / img. ETA=0:12:20
[32m[04/28 07:23:35 d2.evaluation.evaluator]: [0mInference done 2019/8355. 0.1144 s / img. ETA=0:12:15
[32m[04/28 07:23:40 d2.evaluation.evaluator]: [0mInference done 2062/8355. 0.1144 s / img. ETA=0:12:10
[32m[04/28 07:23:45 d2.evaluation.evaluator]: [0mInference done 2105/8355. 0.1144 s / img. ETA=0:12:05
[32m[04/28 07:23:50 d2.evaluation.evaluator]: [0mInference done 2149/8355. 0.1144 s / img. ETA=0:12:00
[32m[04/28 07:23:55 d2.evaluation.evaluator]: [0mInference done 2192/8355. 0.1144 s / img. ETA=0:11:55
[32m[04/28 07:24:00 d2.evaluation.evaluator]: [0mInference done 2233/8355. 0.1146 s / img. ETA=0:11:52
[32m[04/28 07:24:05 d2.evaluation.evaluator]: [0mInference done 2276/8355. 0.1146 s / img. ETA=0:11:47
[32m[04/28 07:24:10 d2.evaluation.evaluator]: [0mInference done 2319/8355. 0.1146 s / img. ETA=0:11:42
[32m[04/28 07:24:15 d2.evaluation.evaluator]: [0mInference done 2363/8355. 0.1146 s / img. ETA=0:11:37
[32m[04/28 07:24:20 d2.evaluation.evaluator]: [0mInference done 2407/8355. 0.1146 s / img. ETA=0:11:31
[32m[04/28 07:24:25 d2.evaluation.evaluator]: [0mInference done 2450/8355. 0.1146 s / img. ETA=0:11:26
[32m[04/28 07:24:30 d2.evaluation.evaluator]: [0mInference done 2493/8355. 0.1146 s / img. ETA=0:11:22
[32m[04/28 07:24:35 d2.evaluation.evaluator]: [0mInference done 2536/8355. 0.1146 s / img. ETA=0:11:17
[32m[04/28 07:24:40 d2.evaluation.evaluator]: [0mInference done 2579/8355. 0.1146 s / img. ETA=0:11:12
[32m[04/28 07:24:46 d2.evaluation.evaluator]: [0mInference done 2622/8355. 0.1146 s / img. ETA=0:11:07
[32m[04/28 07:24:51 d2.evaluation.evaluator]: [0mInference done 2665/8355. 0.1146 s / img. ETA=0:11:02
[32m[04/28 07:24:56 d2.evaluation.evaluator]: [0mInference done 2708/8355. 0.1146 s / img. ETA=0:10:57
[32m[04/28 07:25:01 d2.evaluation.evaluator]: [0mInference done 2751/8355. 0.1146 s / img. ETA=0:10:52
[32m[04/28 07:25:06 d2.evaluation.evaluator]: [0mInference done 2794/8355. 0.1146 s / img. ETA=0:10:47
[32m[04/28 07:25:11 d2.evaluation.evaluator]: [0mInference done 2837/8355. 0.1146 s / img. ETA=0:10:42
[32m[04/28 07:25:16 d2.evaluation.evaluator]: [0mInference done 2880/8355. 0.1147 s / img. ETA=0:10:37
[32m[04/28 07:25:21 d2.evaluation.evaluator]: [0mInference done 2924/8355. 0.1147 s / img. ETA=0:10:32
[32m[04/28 07:25:26 d2.evaluation.evaluator]: [0mInference done 2967/8355. 0.1147 s / img. ETA=0:10:27
[32m[04/28 07:25:31 d2.evaluation.evaluator]: [0mInference done 3011/8355. 0.1147 s / img. ETA=0:10:22
[32m[04/28 07:25:36 d2.evaluation.evaluator]: [0mInference done 3054/8355. 0.1147 s / img. ETA=0:10:17
[32m[04/28 07:25:41 d2.evaluation.evaluator]: [0mInference done 3097/8355. 0.1147 s / img. ETA=0:10:12
[32m[04/28 07:25:46 d2.evaluation.evaluator]: [0mInference done 3140/8355. 0.1147 s / img. ETA=0:10:07
[32m[04/28 07:25:51 d2.evaluation.evaluator]: [0mInference done 3183/8355. 0.1147 s / img. ETA=0:10:02
[32m[04/28 07:25:56 d2.evaluation.evaluator]: [0mInference done 3226/8355. 0.1147 s / img. ETA=0:09:57
[32m[04/28 07:26:01 d2.evaluation.evaluator]: [0mInference done 3270/8355. 0.1147 s / img. ETA=0:09:52
[32m[04/28 07:26:06 d2.evaluation.evaluator]: [0mInference done 3314/8355. 0.1147 s / img. ETA=0:09:47
[32m[04/28 07:26:11 d2.evaluation.evaluator]: [0mInference done 3357/8355. 0.1147 s / img. ETA=0:09:42
[32m[04/28 07:26:16 d2.evaluation.evaluator]: [0mInference done 3401/8355. 0.1147 s / img. ETA=0:09:36
[32m[04/28 07:26:21 d2.evaluation.evaluator]: [0mInference done 3444/8355. 0.1147 s / img. ETA=0:09:31
[32m[04/28 07:26:26 d2.evaluation.evaluator]: [0mInference done 3487/8355. 0.1147 s / img. ETA=0:09:26
[32m[04/28 07:26:32 d2.evaluation.evaluator]: [0mInference done 3531/8355. 0.1147 s / img. ETA=0:09:21
[32m[04/28 07:26:37 d2.evaluation.evaluator]: [0mInference done 3575/8355. 0.1147 s / img. ETA=0:09:16
[32m[04/28 07:26:42 d2.evaluation.evaluator]: [0mInference done 3618/8355. 0.1147 s / img. ETA=0:09:11
[32m[04/28 07:26:47 d2.evaluation.evaluator]: [0mInference done 3661/8355. 0.1147 s / img. ETA=0:09:06
[32m[04/28 07:26:52 d2.evaluation.evaluator]: [0mInference done 3704/8355. 0.1147 s / img. ETA=0:09:01
[32m[04/28 07:26:57 d2.evaluation.evaluator]: [0mInference done 3748/8355. 0.1147 s / img. ETA=0:08:56
[32m[04/28 07:27:02 d2.evaluation.evaluator]: [0mInference done 3791/8355. 0.1147 s / img. ETA=0:08:51
[32m[04/28 07:27:07 d2.evaluation.evaluator]: [0mInference done 3834/8355. 0.1147 s / img. ETA=0:08:46
[32m[04/28 07:27:12 d2.evaluation.evaluator]: [0mInference done 3878/8355. 0.1147 s / img. ETA=0:08:41
[32m[04/28 07:27:17 d2.evaluation.evaluator]: [0mInference done 3922/8355. 0.1147 s / img. ETA=0:08:36
[32m[04/28 07:27:22 d2.evaluation.evaluator]: [0mInference done 3966/8355. 0.1147 s / img. ETA=0:08:31
[32m[04/28 07:27:27 d2.evaluation.evaluator]: [0mInference done 4009/8355. 0.1147 s / img. ETA=0:08:26
[32m[04/28 07:27:32 d2.evaluation.evaluator]: [0mInference done 4052/8355. 0.1147 s / img. ETA=0:08:21
[32m[04/28 07:27:37 d2.evaluation.evaluator]: [0mInference done 4095/8355. 0.1147 s / img. ETA=0:08:16
[32m[04/28 07:27:42 d2.evaluation.evaluator]: [0mInference done 4138/8355. 0.1147 s / img. ETA=0:08:11
[32m[04/28 07:27:48 d2.evaluation.evaluator]: [0mInference done 4182/8355. 0.1147 s / img. ETA=0:08:06
[32m[04/28 07:27:53 d2.evaluation.evaluator]: [0mInference done 4226/8355. 0.1147 s / img. ETA=0:08:00
[32m[04/28 07:27:58 d2.evaluation.evaluator]: [0mInference done 4269/8355. 0.1147 s / img. ETA=0:07:55
[32m[04/28 07:28:03 d2.evaluation.evaluator]: [0mInference done 4313/8355. 0.1147 s / img. ETA=0:07:50
[32m[04/28 07:28:08 d2.evaluation.evaluator]: [0mInference done 4356/8355. 0.1147 s / img. ETA=0:07:45
[32m[04/28 07:28:13 d2.evaluation.evaluator]: [0mInference done 4399/8355. 0.1147 s / img. ETA=0:07:40
[32m[04/28 07:28:18 d2.evaluation.evaluator]: [0mInference done 4443/8355. 0.1147 s / img. ETA=0:07:35
[32m[04/28 07:28:23 d2.evaluation.evaluator]: [0mInference done 4486/8355. 0.1147 s / img. ETA=0:07:30
[32m[04/28 07:28:28 d2.evaluation.evaluator]: [0mInference done 4529/8355. 0.1147 s / img. ETA=0:07:25
[32m[04/28 07:28:33 d2.evaluation.evaluator]: [0mInference done 4572/8355. 0.1147 s / img. ETA=0:07:20
[32m[04/28 07:28:38 d2.evaluation.evaluator]: [0mInference done 4615/8355. 0.1147 s / img. ETA=0:07:15
[32m[04/28 07:28:43 d2.evaluation.evaluator]: [0mInference done 4659/8355. 0.1147 s / img. ETA=0:07:10
[32m[04/28 07:28:48 d2.evaluation.evaluator]: [0mInference done 4702/8355. 0.1147 s / img. ETA=0:07:05
[32m[04/28 07:28:53 d2.evaluation.evaluator]: [0mInference done 4746/8355. 0.1147 s / img. ETA=0:07:00
[32m[04/28 07:28:58 d2.evaluation.evaluator]: [0mInference done 4789/8355. 0.1147 s / img. ETA=0:06:55
[32m[04/28 07:29:03 d2.evaluation.evaluator]: [0mInference done 4832/8355. 0.1147 s / img. ETA=0:06:50
[32m[04/28 07:29:08 d2.evaluation.evaluator]: [0mInference done 4876/8355. 0.1147 s / img. ETA=0:06:45
[32m[04/28 07:29:14 d2.evaluation.evaluator]: [0mInference done 4919/8355. 0.1147 s / img. ETA=0:06:40
[32m[04/28 07:29:19 d2.evaluation.evaluator]: [0mInference done 4963/8355. 0.1147 s / img. ETA=0:06:35
[32m[04/28 07:29:24 d2.evaluation.evaluator]: [0mInference done 5006/8355. 0.1147 s / img. ETA=0:06:30
[32m[04/28 07:29:29 d2.evaluation.evaluator]: [0mInference done 5049/8355. 0.1147 s / img. ETA=0:06:25
[32m[04/28 07:29:34 d2.evaluation.evaluator]: [0mInference done 5092/8355. 0.1147 s / img. ETA=0:06:20
[32m[04/28 07:29:39 d2.evaluation.evaluator]: [0mInference done 5135/8355. 0.1147 s / img. ETA=0:06:15
[32m[04/28 07:29:44 d2.evaluation.evaluator]: [0mInference done 5178/8355. 0.1147 s / img. ETA=0:06:10
[32m[04/28 07:29:49 d2.evaluation.evaluator]: [0mInference done 5221/8355. 0.1147 s / img. ETA=0:06:05
[32m[04/28 07:29:54 d2.evaluation.evaluator]: [0mInference done 5264/8355. 0.1147 s / img. ETA=0:06:00
[32m[04/28 07:29:59 d2.evaluation.evaluator]: [0mInference done 5307/8355. 0.1147 s / img. ETA=0:05:55
[32m[04/28 07:30:04 d2.evaluation.evaluator]: [0mInference done 5350/8355. 0.1147 s / img. ETA=0:05:50
[32m[04/28 07:30:09 d2.evaluation.evaluator]: [0mInference done 5393/8355. 0.1147 s / img. ETA=0:05:45
[32m[04/28 07:30:14 d2.evaluation.evaluator]: [0mInference done 5436/8355. 0.1147 s / img. ETA=0:05:40
[32m[04/28 07:30:19 d2.evaluation.evaluator]: [0mInference done 5479/8355. 0.1148 s / img. ETA=0:05:35
[32m[04/28 07:30:24 d2.evaluation.evaluator]: [0mInference done 5522/8355. 0.1148 s / img. ETA=0:05:30
[32m[04/28 07:30:29 d2.evaluation.evaluator]: [0mInference done 5565/8355. 0.1148 s / img. ETA=0:05:25
[32m[04/28 07:30:34 d2.evaluation.evaluator]: [0mInference done 5608/8355. 0.1147 s / img. ETA=0:05:20
[32m[04/28 07:30:39 d2.evaluation.evaluator]: [0mInference done 5651/8355. 0.1147 s / img. ETA=0:05:15
[32m[04/28 07:30:44 d2.evaluation.evaluator]: [0mInference done 5694/8355. 0.1147 s / img. ETA=0:05:10
[32m[04/28 07:30:49 d2.evaluation.evaluator]: [0mInference done 5737/8355. 0.1147 s / img. ETA=0:05:05
[32m[04/28 07:30:54 d2.evaluation.evaluator]: [0mInference done 5780/8355. 0.1148 s / img. ETA=0:05:00
[32m[04/28 07:30:59 d2.evaluation.evaluator]: [0mInference done 5823/8355. 0.1148 s / img. ETA=0:04:55
[32m[04/28 07:31:04 d2.evaluation.evaluator]: [0mInference done 5866/8355. 0.1148 s / img. ETA=0:04:50
[32m[04/28 07:31:09 d2.evaluation.evaluator]: [0mInference done 5909/8355. 0.1148 s / img. ETA=0:04:45
[32m[04/28 07:31:14 d2.evaluation.evaluator]: [0mInference done 5952/8355. 0.1148 s / img. ETA=0:04:40
[32m[04/28 07:31:19 d2.evaluation.evaluator]: [0mInference done 5995/8355. 0.1148 s / img. ETA=0:04:35
[32m[04/28 07:31:24 d2.evaluation.evaluator]: [0mInference done 6038/8355. 0.1148 s / img. ETA=0:04:30
[32m[04/28 07:31:30 d2.evaluation.evaluator]: [0mInference done 6081/8355. 0.1148 s / img. ETA=0:04:25
[32m[04/28 07:31:35 d2.evaluation.evaluator]: [0mInference done 6124/8355. 0.1148 s / img. ETA=0:04:20
[32m[04/28 07:31:40 d2.evaluation.evaluator]: [0mInference done 6167/8355. 0.1148 s / img. ETA=0:04:15
[32m[04/28 07:31:45 d2.evaluation.evaluator]: [0mInference done 6210/8355. 0.1148 s / img. ETA=0:04:10
[32m[04/28 07:31:50 d2.evaluation.evaluator]: [0mInference done 6253/8355. 0.1148 s / img. ETA=0:04:05
[32m[04/28 07:31:55 d2.evaluation.evaluator]: [0mInference done 6296/8355. 0.1148 s / img. ETA=0:04:00
[32m[04/28 07:32:00 d2.evaluation.evaluator]: [0mInference done 6339/8355. 0.1149 s / img. ETA=0:03:55
[32m[04/28 07:32:05 d2.evaluation.evaluator]: [0mInference done 6382/8355. 0.1149 s / img. ETA=0:03:50
[32m[04/28 07:32:10 d2.evaluation.evaluator]: [0mInference done 6425/8355. 0.1149 s / img. ETA=0:03:45
[32m[04/28 07:32:15 d2.evaluation.evaluator]: [0mInference done 6468/8355. 0.1149 s / img. ETA=0:03:40
[32m[04/28 07:32:20 d2.evaluation.evaluator]: [0mInference done 6512/8355. 0.1149 s / img. ETA=0:03:35
[32m[04/28 07:32:25 d2.evaluation.evaluator]: [0mInference done 6555/8355. 0.1149 s / img. ETA=0:03:29
[32m[04/28 07:32:30 d2.evaluation.evaluator]: [0mInference done 6598/8355. 0.1149 s / img. ETA=0:03:24
[32m[04/28 07:32:35 d2.evaluation.evaluator]: [0mInference done 6642/8355. 0.1149 s / img. ETA=0:03:19
[32m[04/28 07:32:40 d2.evaluation.evaluator]: [0mInference done 6686/8355. 0.1149 s / img. ETA=0:03:14
[32m[04/28 07:32:45 d2.evaluation.evaluator]: [0mInference done 6730/8355. 0.1148 s / img. ETA=0:03:09
[32m[04/28 07:32:50 d2.evaluation.evaluator]: [0mInference done 6773/8355. 0.1148 s / img. ETA=0:03:04
[32m[04/28 07:32:55 d2.evaluation.evaluator]: [0mInference done 6816/8355. 0.1148 s / img. ETA=0:02:59
[32m[04/28 07:33:01 d2.evaluation.evaluator]: [0mInference done 6859/8355. 0.1148 s / img. ETA=0:02:54
[32m[04/28 07:33:06 d2.evaluation.evaluator]: [0mInference done 6902/8355. 0.1148 s / img. ETA=0:02:49
[32m[04/28 07:33:11 d2.evaluation.evaluator]: [0mInference done 6945/8355. 0.1148 s / img. ETA=0:02:44
[32m[04/28 07:33:16 d2.evaluation.evaluator]: [0mInference done 6988/8355. 0.1149 s / img. ETA=0:02:39
[32m[04/28 07:33:21 d2.evaluation.evaluator]: [0mInference done 7031/8355. 0.1149 s / img. ETA=0:02:34
[32m[04/28 07:33:26 d2.evaluation.evaluator]: [0mInference done 7074/8355. 0.1149 s / img. ETA=0:02:29
[32m[04/28 07:33:31 d2.evaluation.evaluator]: [0mInference done 7117/8355. 0.1149 s / img. ETA=0:02:24
[32m[04/28 07:33:36 d2.evaluation.evaluator]: [0mInference done 7160/8355. 0.1149 s / img. ETA=0:02:19
[32m[04/28 07:33:41 d2.evaluation.evaluator]: [0mInference done 7203/8355. 0.1149 s / img. ETA=0:02:14
[32m[04/28 07:33:46 d2.evaluation.evaluator]: [0mInference done 7246/8355. 0.1149 s / img. ETA=0:02:09
[32m[04/28 07:33:51 d2.evaluation.evaluator]: [0mInference done 7289/8355. 0.1149 s / img. ETA=0:02:04
[32m[04/28 07:33:56 d2.evaluation.evaluator]: [0mInference done 7332/8355. 0.1149 s / img. ETA=0:01:59
[32m[04/28 07:34:01 d2.evaluation.evaluator]: [0mInference done 7375/8355. 0.1149 s / img. ETA=0:01:54
[32m[04/28 07:34:06 d2.evaluation.evaluator]: [0mInference done 7418/8355. 0.1149 s / img. ETA=0:01:49
[32m[04/28 07:34:11 d2.evaluation.evaluator]: [0mInference done 7461/8355. 0.1149 s / img. ETA=0:01:44
[32m[04/28 07:34:16 d2.evaluation.evaluator]: [0mInference done 7503/8355. 0.1149 s / img. ETA=0:01:39
[32m[04/28 07:34:21 d2.evaluation.evaluator]: [0mInference done 7546/8355. 0.1149 s / img. ETA=0:01:34
[32m[04/28 07:34:26 d2.evaluation.evaluator]: [0mInference done 7589/8355. 0.1149 s / img. ETA=0:01:29
[32m[04/28 07:34:31 d2.evaluation.evaluator]: [0mInference done 7632/8355. 0.1149 s / img. ETA=0:01:24
[32m[04/28 07:34:36 d2.evaluation.evaluator]: [0mInference done 7675/8355. 0.1149 s / img. ETA=0:01:19
[32m[04/28 07:34:41 d2.evaluation.evaluator]: [0mInference done 7718/8355. 0.1149 s / img. ETA=0:01:14
[32m[04/28 07:34:46 d2.evaluation.evaluator]: [0mInference done 7761/8355. 0.1149 s / img. ETA=0:01:09
[32m[04/28 07:34:51 d2.evaluation.evaluator]: [0mInference done 7804/8355. 0.1149 s / img. ETA=0:01:04
[32m[04/28 07:34:57 d2.evaluation.evaluator]: [0mInference done 7847/8355. 0.1149 s / img. ETA=0:00:59
[32m[04/28 07:35:02 d2.evaluation.evaluator]: [0mInference done 7890/8355. 0.1149 s / img. ETA=0:00:54
[32m[04/28 07:35:07 d2.evaluation.evaluator]: [0mInference done 7933/8355. 0.1149 s / img. ETA=0:00:49
[32m[04/28 07:35:12 d2.evaluation.evaluator]: [0mInference done 7976/8355. 0.1149 s / img. ETA=0:00:44
[32m[04/28 07:35:17 d2.evaluation.evaluator]: [0mInference done 8018/8355. 0.1150 s / img. ETA=0:00:39
[32m[04/28 07:35:22 d2.evaluation.evaluator]: [0mInference done 8062/8355. 0.1150 s / img. ETA=0:00:34
[32m[04/28 07:35:27 d2.evaluation.evaluator]: [0mInference done 8106/8355. 0.1149 s / img. ETA=0:00:29
[32m[04/28 07:35:32 d2.evaluation.evaluator]: [0mInference done 8149/8355. 0.1149 s / img. ETA=0:00:24
[32m[04/28 07:35:37 d2.evaluation.evaluator]: [0mInference done 8193/8355. 0.1149 s / img. ETA=0:00:18
[32m[04/28 07:35:42 d2.evaluation.evaluator]: [0mInference done 8236/8355. 0.1149 s / img. ETA=0:00:13
[32m[04/28 07:35:47 d2.evaluation.evaluator]: [0mInference done 8279/8355. 0.1149 s / img. ETA=0:00:08
[32m[04/28 07:35:52 d2.evaluation.evaluator]: [0mInference done 8322/8355. 0.1149 s / img. ETA=0:00:03
[32m[04/28 07:35:56 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:15.029782 (0.116770 s / img per device, on 1 devices)
[32m[04/28 07:35:56 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:15:59 (0.114950 s / img per device, on 1 devices)
[32m[04/28 07:35:56 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 07:35:56 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 07:35:57 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.51s).
Accumulating evaluation results...
DONE (t=2.13s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.818
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.435
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.341
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.581
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.175
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.499
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.417
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.760
[32m[04/28 07:36:18 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.181 | 81.785 | 43.492 | 34.063 | 58.130 | 71.621 |
[32m[04/28 07:36:18 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 44.662 | bicycle       | 36.826 | car            | 54.055 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 07:36:19 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 07:36:19 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 07:36:19 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 07:36:20 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1143 s / img. ETA=0:02:24
[32m[04/28 07:36:25 d2.evaluation.evaluator]: [0mInference done 55/1257. 0.1142 s / img. ETA=0:02:19
[32m[04/28 07:36:30 d2.evaluation.evaluator]: [0mInference done 98/1257. 0.1144 s / img. ETA=0:02:14
[32m[04/28 07:36:35 d2.evaluation.evaluator]: [0mInference done 142/1257. 0.1143 s / img. ETA=0:02:09
[32m[04/28 07:36:40 d2.evaluation.evaluator]: [0mInference done 185/1257. 0.1144 s / img. ETA=0:02:04
[32m[04/28 07:36:45 d2.evaluation.evaluator]: [0mInference done 229/1257. 0.1144 s / img. ETA=0:01:59
[32m[04/28 07:36:51 d2.evaluation.evaluator]: [0mInference done 272/1257. 0.1145 s / img. ETA=0:01:54
[32m[04/28 07:36:56 d2.evaluation.evaluator]: [0mInference done 316/1257. 0.1144 s / img. ETA=0:01:49
[32m[04/28 07:37:01 d2.evaluation.evaluator]: [0mInference done 360/1257. 0.1144 s / img. ETA=0:01:44
[32m[04/28 07:37:06 d2.evaluation.evaluator]: [0mInference done 404/1257. 0.1144 s / img. ETA=0:01:39
[32m[04/28 07:37:11 d2.evaluation.evaluator]: [0mInference done 448/1257. 0.1144 s / img. ETA=0:01:34
[32m[04/28 07:37:16 d2.evaluation.evaluator]: [0mInference done 492/1257. 0.1144 s / img. ETA=0:01:28
[32m[04/28 07:37:21 d2.evaluation.evaluator]: [0mInference done 535/1257. 0.1144 s / img. ETA=0:01:23
[32m[04/28 07:37:26 d2.evaluation.evaluator]: [0mInference done 578/1257. 0.1144 s / img. ETA=0:01:18
[32m[04/28 07:37:31 d2.evaluation.evaluator]: [0mInference done 622/1257. 0.1144 s / img. ETA=0:01:13
[32m[04/28 07:37:36 d2.evaluation.evaluator]: [0mInference done 665/1257. 0.1144 s / img. ETA=0:01:08
[32m[04/28 07:37:41 d2.evaluation.evaluator]: [0mInference done 708/1257. 0.1144 s / img. ETA=0:01:03
[32m[04/28 07:37:46 d2.evaluation.evaluator]: [0mInference done 751/1257. 0.1145 s / img. ETA=0:00:58
[32m[04/28 07:37:51 d2.evaluation.evaluator]: [0mInference done 794/1257. 0.1145 s / img. ETA=0:00:53
[32m[04/28 07:37:56 d2.evaluation.evaluator]: [0mInference done 837/1257. 0.1145 s / img. ETA=0:00:48
[32m[04/28 07:38:01 d2.evaluation.evaluator]: [0mInference done 880/1257. 0.1145 s / img. ETA=0:00:43
[32m[04/28 07:38:06 d2.evaluation.evaluator]: [0mInference done 923/1257. 0.1146 s / img. ETA=0:00:38
[32m[04/28 07:38:11 d2.evaluation.evaluator]: [0mInference done 966/1257. 0.1146 s / img. ETA=0:00:33
[32m[04/28 07:38:16 d2.evaluation.evaluator]: [0mInference done 1009/1257. 0.1146 s / img. ETA=0:00:28
[32m[04/28 07:38:21 d2.evaluation.evaluator]: [0mInference done 1052/1257. 0.1146 s / img. ETA=0:00:23
[32m[04/28 07:38:26 d2.evaluation.evaluator]: [0mInference done 1095/1257. 0.1146 s / img. ETA=0:00:18
[32m[04/28 07:38:31 d2.evaluation.evaluator]: [0mInference done 1138/1257. 0.1146 s / img. ETA=0:00:13
[32m[04/28 07:38:36 d2.evaluation.evaluator]: [0mInference done 1181/1257. 0.1147 s / img. ETA=0:00:08
[32m[04/28 07:38:41 d2.evaluation.evaluator]: [0mInference done 1224/1257. 0.1147 s / img. ETA=0:00:03
[32m[04/28 07:38:45 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:25.933361 (0.116560 s / img per device, on 1 devices)
[32m[04/28 07:38:45 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:23 (0.114709 s / img per device, on 1 devices)
[32m[04/28 07:38:45 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 07:38:45 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 07:38:45 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.24s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.88s).
Accumulating evaluation results...
DONE (t=0.36s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.770
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.325
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.276
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.457
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.545
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.191
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.458
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.370
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.584
[32m[04/28 07:38:49 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.064 | 77.037 | 32.536 | 27.558 | 45.743 | 54.517 |
[32m[04/28 07:38:49 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 38.515 | bicycle       | 25.862 | car            | 52.814 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  10  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 07:38:50 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 07:38:50 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 07:38:50 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 07:38:51 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 07:38:51 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 07:38:51 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 07:38:51 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 07:39:11 d2.utils.events]: [0m eta: 0:16:31  iter: 19  total_loss: 0.554  loss_cls: 0.167  loss_box_reg: 0.314  loss_rpn_cls: 0.010  loss_rpn_loc: 0.041  time: 1.0094  data_time: 0.0220  lr: 0.000100  max_mem: 5397M
[32m[04/28 07:39:32 d2.utils.events]: [0m eta: 0:16:28  iter: 39  total_loss: 0.542  loss_cls: 0.163  loss_box_reg: 0.327  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 1.0207  data_time: 0.0076  lr: 0.000200  max_mem: 5397M
[32m[04/28 07:39:52 d2.utils.events]: [0m eta: 0:16:07  iter: 59  total_loss: 0.581  loss_cls: 0.171  loss_box_reg: 0.342  loss_rpn_cls: 0.008  loss_rpn_loc: 0.059  time: 1.0166  data_time: 0.0079  lr: 0.000300  max_mem: 5397M
[32m[04/28 07:40:13 d2.utils.events]: [0m eta: 0:15:52  iter: 79  total_loss: 0.476  loss_cls: 0.154  loss_box_reg: 0.268  loss_rpn_cls: 0.009  loss_rpn_loc: 0.035  time: 1.0252  data_time: 0.0076  lr: 0.000400  max_mem: 5397M
[32m[04/28 07:40:34 d2.utils.events]: [0m eta: 0:15:31  iter: 99  total_loss: 0.520  loss_cls: 0.159  loss_box_reg: 0.300  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0262  data_time: 0.0077  lr: 0.000500  max_mem: 5397M
[32m[04/28 07:40:54 d2.utils.events]: [0m eta: 0:15:13  iter: 119  total_loss: 0.547  loss_cls: 0.173  loss_box_reg: 0.323  loss_rpn_cls: 0.010  loss_rpn_loc: 0.045  time: 1.0275  data_time: 0.0078  lr: 0.000599  max_mem: 5397M
[32m[04/28 07:41:14 d2.utils.events]: [0m eta: 0:14:48  iter: 139  total_loss: 0.538  loss_cls: 0.167  loss_box_reg: 0.312  loss_rpn_cls: 0.007  loss_rpn_loc: 0.052  time: 1.0237  data_time: 0.0076  lr: 0.000699  max_mem: 5397M
[32m[04/28 07:41:34 d2.utils.events]: [0m eta: 0:14:26  iter: 159  total_loss: 0.525  loss_cls: 0.154  loss_box_reg: 0.293  loss_rpn_cls: 0.008  loss_rpn_loc: 0.047  time: 1.0202  data_time: 0.0078  lr: 0.000799  max_mem: 5397M
[32m[04/28 07:41:55 d2.utils.events]: [0m eta: 0:14:05  iter: 179  total_loss: 0.484  loss_cls: 0.150  loss_box_reg: 0.265  loss_rpn_cls: 0.009  loss_rpn_loc: 0.052  time: 1.0210  data_time: 0.0079  lr: 0.000899  max_mem: 5397M
[32m[04/28 07:42:15 d2.utils.events]: [0m eta: 0:13:45  iter: 199  total_loss: 0.511  loss_cls: 0.152  loss_box_reg: 0.297  loss_rpn_cls: 0.008  loss_rpn_loc: 0.045  time: 1.0204  data_time: 0.0077  lr: 0.000999  max_mem: 5397M
[32m[04/28 07:42:36 d2.utils.events]: [0m eta: 0:13:24  iter: 219  total_loss: 0.604  loss_cls: 0.181  loss_box_reg: 0.332  loss_rpn_cls: 0.008  loss_rpn_loc: 0.058  time: 1.0209  data_time: 0.0077  lr: 0.001099  max_mem: 5397M
[32m[04/28 07:42:57 d2.utils.events]: [0m eta: 0:13:04  iter: 239  total_loss: 0.549  loss_cls: 0.165  loss_box_reg: 0.328  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0232  data_time: 0.0078  lr: 0.001199  max_mem: 5397M
[32m[04/28 07:43:17 d2.utils.events]: [0m eta: 0:12:44  iter: 259  total_loss: 0.529  loss_cls: 0.162  loss_box_reg: 0.318  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 1.0229  data_time: 0.0077  lr: 0.001299  max_mem: 5397M
[32m[04/28 07:43:38 d2.utils.events]: [0m eta: 0:12:23  iter: 279  total_loss: 0.482  loss_cls: 0.160  loss_box_reg: 0.285  loss_rpn_cls: 0.007  loss_rpn_loc: 0.052  time: 1.0222  data_time: 0.0076  lr: 0.001399  max_mem: 5397M
[32m[04/28 07:43:59 d2.utils.events]: [0m eta: 0:12:03  iter: 299  total_loss: 0.522  loss_cls: 0.158  loss_box_reg: 0.298  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0245  data_time: 0.0080  lr: 0.001499  max_mem: 5397M
[32m[04/28 07:44:20 d2.utils.events]: [0m eta: 0:11:44  iter: 319  total_loss: 0.570  loss_cls: 0.178  loss_box_reg: 0.319  loss_rpn_cls: 0.007  loss_rpn_loc: 0.056  time: 1.0252  data_time: 0.0076  lr: 0.001598  max_mem: 5397M
[32m[04/28 07:44:41 d2.utils.events]: [0m eta: 0:11:24  iter: 339  total_loss: 0.556  loss_cls: 0.179  loss_box_reg: 0.323  loss_rpn_cls: 0.009  loss_rpn_loc: 0.041  time: 1.0268  data_time: 0.0079  lr: 0.001698  max_mem: 5397M
[32m[04/28 07:45:02 d2.utils.events]: [0m eta: 0:11:04  iter: 359  total_loss: 0.495  loss_cls: 0.163  loss_box_reg: 0.307  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0278  data_time: 0.0076  lr: 0.001798  max_mem: 5397M
[32m[04/28 07:45:22 d2.utils.events]: [0m eta: 0:10:43  iter: 379  total_loss: 0.541  loss_cls: 0.158  loss_box_reg: 0.314  loss_rpn_cls: 0.007  loss_rpn_loc: 0.043  time: 1.0278  data_time: 0.0077  lr: 0.001898  max_mem: 5397M
[32m[04/28 07:45:43 d2.utils.events]: [0m eta: 0:10:23  iter: 399  total_loss: 0.602  loss_cls: 0.179  loss_box_reg: 0.346  loss_rpn_cls: 0.008  loss_rpn_loc: 0.055  time: 1.0286  data_time: 0.0077  lr: 0.001998  max_mem: 5397M
[32m[04/28 07:46:04 d2.utils.events]: [0m eta: 0:10:01  iter: 419  total_loss: 0.505  loss_cls: 0.160  loss_box_reg: 0.291  loss_rpn_cls: 0.008  loss_rpn_loc: 0.046  time: 1.0282  data_time: 0.0077  lr: 0.002098  max_mem: 5397M
[32m[04/28 07:46:24 d2.utils.events]: [0m eta: 0:09:41  iter: 439  total_loss: 0.555  loss_cls: 0.167  loss_box_reg: 0.314  loss_rpn_cls: 0.007  loss_rpn_loc: 0.046  time: 1.0282  data_time: 0.0079  lr: 0.002198  max_mem: 5397M
[32m[04/28 07:46:45 d2.utils.events]: [0m eta: 0:09:21  iter: 459  total_loss: 0.529  loss_cls: 0.165  loss_box_reg: 0.311  loss_rpn_cls: 0.009  loss_rpn_loc: 0.047  time: 1.0289  data_time: 0.0079  lr: 0.002298  max_mem: 5397M
[32m[04/28 07:47:06 d2.utils.events]: [0m eta: 0:09:00  iter: 479  total_loss: 0.535  loss_cls: 0.163  loss_box_reg: 0.301  loss_rpn_cls: 0.009  loss_rpn_loc: 0.052  time: 1.0296  data_time: 0.0076  lr: 0.002398  max_mem: 5397M
[32m[04/28 07:47:27 d2.utils.events]: [0m eta: 0:08:40  iter: 499  total_loss: 0.532  loss_cls: 0.155  loss_box_reg: 0.311  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 1.0296  data_time: 0.0077  lr: 0.002498  max_mem: 5397M
[32m[04/28 07:47:47 d2.utils.events]: [0m eta: 0:08:19  iter: 519  total_loss: 0.526  loss_cls: 0.160  loss_box_reg: 0.305  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0293  data_time: 0.0077  lr: 0.002597  max_mem: 5397M
[32m[04/28 07:48:08 d2.utils.events]: [0m eta: 0:07:58  iter: 539  total_loss: 0.512  loss_cls: 0.163  loss_box_reg: 0.305  loss_rpn_cls: 0.007  loss_rpn_loc: 0.049  time: 1.0291  data_time: 0.0077  lr: 0.002697  max_mem: 5397M
[32m[04/28 07:48:29 d2.utils.events]: [0m eta: 0:07:37  iter: 559  total_loss: 0.583  loss_cls: 0.176  loss_box_reg: 0.333  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0298  data_time: 0.0078  lr: 0.002797  max_mem: 5397M
[32m[04/28 07:48:50 d2.utils.events]: [0m eta: 0:07:17  iter: 579  total_loss: 0.533  loss_cls: 0.154  loss_box_reg: 0.305  loss_rpn_cls: 0.007  loss_rpn_loc: 0.052  time: 1.0302  data_time: 0.0079  lr: 0.002897  max_mem: 5397M
[32m[04/28 07:49:10 d2.utils.events]: [0m eta: 0:06:56  iter: 599  total_loss: 0.504  loss_cls: 0.165  loss_box_reg: 0.291  loss_rpn_cls: 0.007  loss_rpn_loc: 0.039  time: 1.0302  data_time: 0.0079  lr: 0.002997  max_mem: 5397M
[32m[04/28 07:49:31 d2.utils.events]: [0m eta: 0:06:35  iter: 619  total_loss: 0.521  loss_cls: 0.169  loss_box_reg: 0.295  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 1.0304  data_time: 0.0078  lr: 0.003097  max_mem: 5397M
[32m[04/28 07:49:52 d2.utils.events]: [0m eta: 0:06:15  iter: 639  total_loss: 0.530  loss_cls: 0.160  loss_box_reg: 0.292  loss_rpn_cls: 0.008  loss_rpn_loc: 0.052  time: 1.0303  data_time: 0.0077  lr: 0.003197  max_mem: 5397M
[32m[04/28 07:50:13 d2.utils.events]: [0m eta: 0:05:54  iter: 659  total_loss: 0.553  loss_cls: 0.175  loss_box_reg: 0.313  loss_rpn_cls: 0.006  loss_rpn_loc: 0.052  time: 1.0307  data_time: 0.0077  lr: 0.003297  max_mem: 5397M
[32m[04/28 07:50:34 d2.utils.events]: [0m eta: 0:05:33  iter: 679  total_loss: 0.544  loss_cls: 0.172  loss_box_reg: 0.312  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 1.0310  data_time: 0.0080  lr: 0.003397  max_mem: 5397M
[32m[04/28 07:50:54 d2.utils.events]: [0m eta: 0:05:12  iter: 699  total_loss: 0.541  loss_cls: 0.167  loss_box_reg: 0.315  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 1.0311  data_time: 0.0079  lr: 0.003497  max_mem: 5397M
[32m[04/28 07:51:15 d2.utils.events]: [0m eta: 0:04:52  iter: 719  total_loss: 0.593  loss_cls: 0.179  loss_box_reg: 0.310  loss_rpn_cls: 0.009  loss_rpn_loc: 0.050  time: 1.0312  data_time: 0.0081  lr: 0.003596  max_mem: 5397M
[32m[04/28 07:51:36 d2.utils.events]: [0m eta: 0:04:31  iter: 739  total_loss: 0.555  loss_cls: 0.178  loss_box_reg: 0.333  loss_rpn_cls: 0.010  loss_rpn_loc: 0.043  time: 1.0310  data_time: 0.0078  lr: 0.003696  max_mem: 5397M
[32m[04/28 07:51:57 d2.utils.events]: [0m eta: 0:04:11  iter: 759  total_loss: 0.581  loss_cls: 0.174  loss_box_reg: 0.342  loss_rpn_cls: 0.006  loss_rpn_loc: 0.055  time: 1.0316  data_time: 0.0075  lr: 0.003796  max_mem: 5397M
[32m[04/28 07:52:18 d2.utils.events]: [0m eta: 0:03:50  iter: 779  total_loss: 0.513  loss_cls: 0.144  loss_box_reg: 0.298  loss_rpn_cls: 0.009  loss_rpn_loc: 0.043  time: 1.0319  data_time: 0.0077  lr: 0.003896  max_mem: 5397M
[32m[04/28 07:52:39 d2.utils.events]: [0m eta: 0:03:29  iter: 799  total_loss: 0.489  loss_cls: 0.154  loss_box_reg: 0.279  loss_rpn_cls: 0.008  loss_rpn_loc: 0.045  time: 1.0322  data_time: 0.0078  lr: 0.003996  max_mem: 5397M
[32m[04/28 07:53:00 d2.utils.events]: [0m eta: 0:03:08  iter: 819  total_loss: 0.544  loss_cls: 0.162  loss_box_reg: 0.317  loss_rpn_cls: 0.010  loss_rpn_loc: 0.046  time: 1.0325  data_time: 0.0078  lr: 0.004096  max_mem: 5397M
[32m[04/28 07:53:20 d2.utils.events]: [0m eta: 0:02:47  iter: 839  total_loss: 0.561  loss_cls: 0.159  loss_box_reg: 0.313  loss_rpn_cls: 0.010  loss_rpn_loc: 0.053  time: 1.0320  data_time: 0.0078  lr: 0.004196  max_mem: 5397M
[32m[04/28 07:53:40 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.507  loss_cls: 0.151  loss_box_reg: 0.282  loss_rpn_cls: 0.010  loss_rpn_loc: 0.036  time: 1.0317  data_time: 0.0079  lr: 0.004296  max_mem: 5397M
[32m[04/28 07:54:01 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.545  loss_cls: 0.171  loss_box_reg: 0.325  loss_rpn_cls: 0.010  loss_rpn_loc: 0.045  time: 1.0314  data_time: 0.0076  lr: 0.004396  max_mem: 5397M
[32m[04/28 07:54:21 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.554  loss_cls: 0.172  loss_box_reg: 0.305  loss_rpn_cls: 0.012  loss_rpn_loc: 0.055  time: 1.0310  data_time: 0.0074  lr: 0.004496  max_mem: 5397M
[32m[04/28 07:54:42 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.561  loss_cls: 0.176  loss_box_reg: 0.328  loss_rpn_cls: 0.010  loss_rpn_loc: 0.062  time: 1.0315  data_time: 0.0077  lr: 0.004595  max_mem: 5397M
[32m[04/28 07:55:02 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.605  loss_cls: 0.181  loss_box_reg: 0.354  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 1.0308  data_time: 0.0078  lr: 0.004695  max_mem: 5397M
[32m[04/28 07:55:23 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.499  loss_cls: 0.156  loss_box_reg: 0.294  loss_rpn_cls: 0.009  loss_rpn_loc: 0.055  time: 1.0307  data_time: 0.0078  lr: 0.004795  max_mem: 5397M
[32m[04/28 07:55:43 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.558  loss_cls: 0.165  loss_box_reg: 0.316  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0304  data_time: 0.0077  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 07:56:06 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 07:56:06 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 07:56:06 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 07:56:06 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.532  loss_cls: 0.160  loss_box_reg: 0.311  loss_rpn_cls: 0.007  loss_rpn_loc: 0.045  time: 1.0302  data_time: 0.0076  lr: 0.004995  max_mem: 5397M
[32m[04/28 07:56:06 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:08 (1.0313 s / it)
[32m[04/28 07:56:06 d2.engine.hooks]: [0mTotal training time: 0:17:13 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 07:56:08 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 07:56:08 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 07:56:08 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 07:56:10 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1142 s / img. ETA=0:16:04
[32m[04/28 07:56:15 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1138 s / img. ETA=0:15:58
[32m[04/28 07:56:20 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1137 s / img. ETA=0:15:52
[32m[04/28 07:56:25 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1137 s / img. ETA=0:15:46
[32m[04/28 07:56:30 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1137 s / img. ETA=0:15:41
[32m[04/28 07:56:35 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1138 s / img. ETA=0:15:37
[32m[04/28 07:56:40 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1138 s / img. ETA=0:15:32
[32m[04/28 07:56:45 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1139 s / img. ETA=0:15:28
[32m[04/28 07:56:50 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1139 s / img. ETA=0:15:23
[32m[04/28 07:56:55 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1140 s / img. ETA=0:15:19
[32m[04/28 07:57:00 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1140 s / img. ETA=0:15:14
[32m[04/28 07:57:06 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1140 s / img. ETA=0:15:08
[32m[04/28 07:57:11 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1140 s / img. ETA=0:15:03
[32m[04/28 07:57:16 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1140 s / img. ETA=0:14:58
[32m[04/28 07:57:21 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1140 s / img. ETA=0:14:53
[32m[04/28 07:57:26 d2.evaluation.evaluator]: [0mInference done 670/8355. 0.1141 s / img. ETA=0:14:49
[32m[04/28 07:57:31 d2.evaluation.evaluator]: [0mInference done 714/8355. 0.1141 s / img. ETA=0:14:44
[32m[04/28 07:57:36 d2.evaluation.evaluator]: [0mInference done 758/8355. 0.1141 s / img. ETA=0:14:39
[32m[04/28 07:57:41 d2.evaluation.evaluator]: [0mInference done 801/8355. 0.1142 s / img. ETA=0:14:35
[32m[04/28 07:57:46 d2.evaluation.evaluator]: [0mInference done 845/8355. 0.1142 s / img. ETA=0:14:30
[32m[04/28 07:57:51 d2.evaluation.evaluator]: [0mInference done 888/8355. 0.1143 s / img. ETA=0:14:25
[32m[04/28 07:57:56 d2.evaluation.evaluator]: [0mInference done 932/8355. 0.1143 s / img. ETA=0:14:20
[32m[04/28 07:58:01 d2.evaluation.evaluator]: [0mInference done 976/8355. 0.1143 s / img. ETA=0:14:15
[32m[04/28 07:58:06 d2.evaluation.evaluator]: [0mInference done 1019/8355. 0.1143 s / img. ETA=0:14:10
[32m[04/28 07:58:12 d2.evaluation.evaluator]: [0mInference done 1063/8355. 0.1143 s / img. ETA=0:14:05
[32m[04/28 07:58:17 d2.evaluation.evaluator]: [0mInference done 1107/8355. 0.1143 s / img. ETA=0:14:00
[32m[04/28 07:58:22 d2.evaluation.evaluator]: [0mInference done 1151/8355. 0.1143 s / img. ETA=0:13:55
[32m[04/28 07:58:27 d2.evaluation.evaluator]: [0mInference done 1195/8355. 0.1143 s / img. ETA=0:13:50
[32m[04/28 07:58:32 d2.evaluation.evaluator]: [0mInference done 1239/8355. 0.1143 s / img. ETA=0:13:44
[32m[04/28 07:58:37 d2.evaluation.evaluator]: [0mInference done 1283/8355. 0.1143 s / img. ETA=0:13:39
[32m[04/28 07:58:42 d2.evaluation.evaluator]: [0mInference done 1327/8355. 0.1142 s / img. ETA=0:13:34
[32m[04/28 07:58:47 d2.evaluation.evaluator]: [0mInference done 1371/8355. 0.1142 s / img. ETA=0:13:29
[32m[04/28 07:58:52 d2.evaluation.evaluator]: [0mInference done 1415/8355. 0.1142 s / img. ETA=0:13:24
[32m[04/28 07:58:57 d2.evaluation.evaluator]: [0mInference done 1459/8355. 0.1142 s / img. ETA=0:13:19
[32m[04/28 07:59:02 d2.evaluation.evaluator]: [0mInference done 1501/8355. 0.1143 s / img. ETA=0:13:14
[32m[04/28 07:59:07 d2.evaluation.evaluator]: [0mInference done 1544/8355. 0.1143 s / img. ETA=0:13:10
[32m[04/28 07:59:13 d2.evaluation.evaluator]: [0mInference done 1587/8355. 0.1144 s / img. ETA=0:13:05
[32m[04/28 07:59:18 d2.evaluation.evaluator]: [0mInference done 1630/8355. 0.1144 s / img. ETA=0:13:00
[32m[04/28 07:59:23 d2.evaluation.evaluator]: [0mInference done 1673/8355. 0.1145 s / img. ETA=0:12:56
[32m[04/28 07:59:28 d2.evaluation.evaluator]: [0mInference done 1716/8355. 0.1145 s / img. ETA=0:12:51
[32m[04/28 07:59:33 d2.evaluation.evaluator]: [0mInference done 1759/8355. 0.1145 s / img. ETA=0:12:46
[32m[04/28 07:59:38 d2.evaluation.evaluator]: [0mInference done 1802/8355. 0.1146 s / img. ETA=0:12:41
[32m[04/28 07:59:43 d2.evaluation.evaluator]: [0mInference done 1845/8355. 0.1146 s / img. ETA=0:12:37
[32m[04/28 07:59:48 d2.evaluation.evaluator]: [0mInference done 1888/8355. 0.1146 s / img. ETA=0:12:32
[32m[04/28 07:59:53 d2.evaluation.evaluator]: [0mInference done 1931/8355. 0.1146 s / img. ETA=0:12:27
[32m[04/28 07:59:58 d2.evaluation.evaluator]: [0mInference done 1974/8355. 0.1147 s / img. ETA=0:12:22
[32m[04/28 08:00:03 d2.evaluation.evaluator]: [0mInference done 2017/8355. 0.1147 s / img. ETA=0:12:17
[32m[04/28 08:00:08 d2.evaluation.evaluator]: [0mInference done 2060/8355. 0.1147 s / img. ETA=0:12:12
[32m[04/28 08:00:13 d2.evaluation.evaluator]: [0mInference done 2103/8355. 0.1147 s / img. ETA=0:12:07
[32m[04/28 08:00:18 d2.evaluation.evaluator]: [0mInference done 2147/8355. 0.1147 s / img. ETA=0:12:02
[32m[04/28 08:00:23 d2.evaluation.evaluator]: [0mInference done 2190/8355. 0.1147 s / img. ETA=0:11:57
[32m[04/28 08:00:28 d2.evaluation.evaluator]: [0mInference done 2233/8355. 0.1147 s / img. ETA=0:11:52
[32m[04/28 08:00:33 d2.evaluation.evaluator]: [0mInference done 2276/8355. 0.1148 s / img. ETA=0:11:48
[32m[04/28 08:00:38 d2.evaluation.evaluator]: [0mInference done 2319/8355. 0.1148 s / img. ETA=0:11:43
[32m[04/28 08:00:44 d2.evaluation.evaluator]: [0mInference done 2362/8355. 0.1148 s / img. ETA=0:11:38
[32m[04/28 08:00:49 d2.evaluation.evaluator]: [0mInference done 2405/8355. 0.1148 s / img. ETA=0:11:33
[32m[04/28 08:00:54 d2.evaluation.evaluator]: [0mInference done 2448/8355. 0.1148 s / img. ETA=0:11:28
[32m[04/28 08:00:59 d2.evaluation.evaluator]: [0mInference done 2491/8355. 0.1148 s / img. ETA=0:11:23
[32m[04/28 08:01:04 d2.evaluation.evaluator]: [0mInference done 2534/8355. 0.1148 s / img. ETA=0:11:18
[32m[04/28 08:01:09 d2.evaluation.evaluator]: [0mInference done 2577/8355. 0.1148 s / img. ETA=0:11:13
[32m[04/28 08:01:14 d2.evaluation.evaluator]: [0mInference done 2620/8355. 0.1149 s / img. ETA=0:11:08
[32m[04/28 08:01:19 d2.evaluation.evaluator]: [0mInference done 2663/8355. 0.1149 s / img. ETA=0:11:03
[32m[04/28 08:01:24 d2.evaluation.evaluator]: [0mInference done 2706/8355. 0.1149 s / img. ETA=0:10:58
[32m[04/28 08:01:29 d2.evaluation.evaluator]: [0mInference done 2749/8355. 0.1149 s / img. ETA=0:10:53
[32m[04/28 08:01:34 d2.evaluation.evaluator]: [0mInference done 2792/8355. 0.1149 s / img. ETA=0:10:48
[32m[04/28 08:01:39 d2.evaluation.evaluator]: [0mInference done 2835/8355. 0.1149 s / img. ETA=0:10:43
[32m[04/28 08:01:44 d2.evaluation.evaluator]: [0mInference done 2878/8355. 0.1149 s / img. ETA=0:10:39
[32m[04/28 08:01:49 d2.evaluation.evaluator]: [0mInference done 2921/8355. 0.1149 s / img. ETA=0:10:34
[32m[04/28 08:01:54 d2.evaluation.evaluator]: [0mInference done 2964/8355. 0.1150 s / img. ETA=0:10:29
[32m[04/28 08:01:59 d2.evaluation.evaluator]: [0mInference done 3007/8355. 0.1150 s / img. ETA=0:10:24
[32m[04/28 08:02:04 d2.evaluation.evaluator]: [0mInference done 3050/8355. 0.1150 s / img. ETA=0:10:19
[32m[04/28 08:02:09 d2.evaluation.evaluator]: [0mInference done 3093/8355. 0.1150 s / img. ETA=0:10:14
[32m[04/28 08:02:14 d2.evaluation.evaluator]: [0mInference done 3136/8355. 0.1150 s / img. ETA=0:10:09
[32m[04/28 08:02:19 d2.evaluation.evaluator]: [0mInference done 3180/8355. 0.1149 s / img. ETA=0:10:03
[32m[04/28 08:02:24 d2.evaluation.evaluator]: [0mInference done 3223/8355. 0.1149 s / img. ETA=0:09:58
[32m[04/28 08:02:29 d2.evaluation.evaluator]: [0mInference done 3266/8355. 0.1150 s / img. ETA=0:09:53
[32m[04/28 08:02:35 d2.evaluation.evaluator]: [0mInference done 3310/8355. 0.1149 s / img. ETA=0:09:48
[32m[04/28 08:02:40 d2.evaluation.evaluator]: [0mInference done 3354/8355. 0.1149 s / img. ETA=0:09:43
[32m[04/28 08:02:45 d2.evaluation.evaluator]: [0mInference done 3397/8355. 0.1149 s / img. ETA=0:09:38
[32m[04/28 08:02:50 d2.evaluation.evaluator]: [0mInference done 3441/8355. 0.1149 s / img. ETA=0:09:33
[32m[04/28 08:02:55 d2.evaluation.evaluator]: [0mInference done 3484/8355. 0.1149 s / img. ETA=0:09:28
[32m[04/28 08:03:00 d2.evaluation.evaluator]: [0mInference done 3527/8355. 0.1149 s / img. ETA=0:09:23
[32m[04/28 08:03:05 d2.evaluation.evaluator]: [0mInference done 3571/8355. 0.1149 s / img. ETA=0:09:18
[32m[04/28 08:03:10 d2.evaluation.evaluator]: [0mInference done 3614/8355. 0.1149 s / img. ETA=0:09:13
[32m[04/28 08:03:15 d2.evaluation.evaluator]: [0mInference done 3657/8355. 0.1149 s / img. ETA=0:09:08
[32m[04/28 08:03:20 d2.evaluation.evaluator]: [0mInference done 3700/8355. 0.1149 s / img. ETA=0:09:03
[32m[04/28 08:03:25 d2.evaluation.evaluator]: [0mInference done 3743/8355. 0.1149 s / img. ETA=0:08:58
[32m[04/28 08:03:30 d2.evaluation.evaluator]: [0mInference done 3787/8355. 0.1149 s / img. ETA=0:08:52
[32m[04/28 08:03:35 d2.evaluation.evaluator]: [0mInference done 3830/8355. 0.1149 s / img. ETA=0:08:48
[32m[04/28 08:03:40 d2.evaluation.evaluator]: [0mInference done 3873/8355. 0.1149 s / img. ETA=0:08:43
[32m[04/28 08:03:45 d2.evaluation.evaluator]: [0mInference done 3916/8355. 0.1149 s / img. ETA=0:08:37
[32m[04/28 08:03:50 d2.evaluation.evaluator]: [0mInference done 3960/8355. 0.1149 s / img. ETA=0:08:32
[32m[04/28 08:03:55 d2.evaluation.evaluator]: [0mInference done 4003/8355. 0.1149 s / img. ETA=0:08:27
[32m[04/28 08:04:00 d2.evaluation.evaluator]: [0mInference done 4046/8355. 0.1149 s / img. ETA=0:08:22
[32m[04/28 08:04:06 d2.evaluation.evaluator]: [0mInference done 4089/8355. 0.1149 s / img. ETA=0:08:17
[32m[04/28 08:04:11 d2.evaluation.evaluator]: [0mInference done 4132/8355. 0.1149 s / img. ETA=0:08:12
[32m[04/28 08:04:16 d2.evaluation.evaluator]: [0mInference done 4175/8355. 0.1149 s / img. ETA=0:08:07
[32m[04/28 08:04:21 d2.evaluation.evaluator]: [0mInference done 4218/8355. 0.1149 s / img. ETA=0:08:02
[32m[04/28 08:04:26 d2.evaluation.evaluator]: [0mInference done 4262/8355. 0.1149 s / img. ETA=0:07:57
[32m[04/28 08:04:31 d2.evaluation.evaluator]: [0mInference done 4305/8355. 0.1149 s / img. ETA=0:07:52
[32m[04/28 08:04:36 d2.evaluation.evaluator]: [0mInference done 4348/8355. 0.1149 s / img. ETA=0:07:47
[32m[04/28 08:04:41 d2.evaluation.evaluator]: [0mInference done 4391/8355. 0.1149 s / img. ETA=0:07:42
[32m[04/28 08:04:46 d2.evaluation.evaluator]: [0mInference done 4434/8355. 0.1149 s / img. ETA=0:07:37
[32m[04/28 08:04:51 d2.evaluation.evaluator]: [0mInference done 4477/8355. 0.1149 s / img. ETA=0:07:32
[32m[04/28 08:04:56 d2.evaluation.evaluator]: [0mInference done 4520/8355. 0.1149 s / img. ETA=0:07:27
[32m[04/28 08:05:01 d2.evaluation.evaluator]: [0mInference done 4563/8355. 0.1149 s / img. ETA=0:07:22
[32m[04/28 08:05:06 d2.evaluation.evaluator]: [0mInference done 4606/8355. 0.1149 s / img. ETA=0:07:17
[32m[04/28 08:05:11 d2.evaluation.evaluator]: [0mInference done 4649/8355. 0.1150 s / img. ETA=0:07:12
[32m[04/28 08:05:16 d2.evaluation.evaluator]: [0mInference done 4692/8355. 0.1150 s / img. ETA=0:07:07
[32m[04/28 08:05:21 d2.evaluation.evaluator]: [0mInference done 4735/8355. 0.1150 s / img. ETA=0:07:02
[32m[04/28 08:05:26 d2.evaluation.evaluator]: [0mInference done 4778/8355. 0.1150 s / img. ETA=0:06:57
[32m[04/28 08:05:31 d2.evaluation.evaluator]: [0mInference done 4821/8355. 0.1150 s / img. ETA=0:06:52
[32m[04/28 08:05:36 d2.evaluation.evaluator]: [0mInference done 4864/8355. 0.1150 s / img. ETA=0:06:47
[32m[04/28 08:05:41 d2.evaluation.evaluator]: [0mInference done 4907/8355. 0.1150 s / img. ETA=0:06:42
[32m[04/28 08:05:46 d2.evaluation.evaluator]: [0mInference done 4950/8355. 0.1150 s / img. ETA=0:06:37
[32m[04/28 08:05:51 d2.evaluation.evaluator]: [0mInference done 4993/8355. 0.1150 s / img. ETA=0:06:32
[32m[04/28 08:05:56 d2.evaluation.evaluator]: [0mInference done 5036/8355. 0.1150 s / img. ETA=0:06:27
[32m[04/28 08:06:01 d2.evaluation.evaluator]: [0mInference done 5079/8355. 0.1150 s / img. ETA=0:06:22
[32m[04/28 08:06:06 d2.evaluation.evaluator]: [0mInference done 5122/8355. 0.1150 s / img. ETA=0:06:17
[32m[04/28 08:06:11 d2.evaluation.evaluator]: [0mInference done 5165/8355. 0.1150 s / img. ETA=0:06:12
[32m[04/28 08:06:16 d2.evaluation.evaluator]: [0mInference done 5208/8355. 0.1150 s / img. ETA=0:06:07
[32m[04/28 08:06:22 d2.evaluation.evaluator]: [0mInference done 5252/8355. 0.1150 s / img. ETA=0:06:02
[32m[04/28 08:06:27 d2.evaluation.evaluator]: [0mInference done 5295/8355. 0.1150 s / img. ETA=0:05:57
[32m[04/28 08:06:32 d2.evaluation.evaluator]: [0mInference done 5338/8355. 0.1150 s / img. ETA=0:05:52
[32m[04/28 08:06:37 d2.evaluation.evaluator]: [0mInference done 5381/8355. 0.1150 s / img. ETA=0:05:47
[32m[04/28 08:06:42 d2.evaluation.evaluator]: [0mInference done 5424/8355. 0.1150 s / img. ETA=0:05:42
[32m[04/28 08:06:47 d2.evaluation.evaluator]: [0mInference done 5467/8355. 0.1150 s / img. ETA=0:05:37
[32m[04/28 08:06:52 d2.evaluation.evaluator]: [0mInference done 5511/8355. 0.1150 s / img. ETA=0:05:32
[32m[04/28 08:06:57 d2.evaluation.evaluator]: [0mInference done 5554/8355. 0.1150 s / img. ETA=0:05:27
[32m[04/28 08:07:02 d2.evaluation.evaluator]: [0mInference done 5598/8355. 0.1150 s / img. ETA=0:05:21
[32m[04/28 08:07:07 d2.evaluation.evaluator]: [0mInference done 5642/8355. 0.1150 s / img. ETA=0:05:16
[32m[04/28 08:07:12 d2.evaluation.evaluator]: [0mInference done 5685/8355. 0.1150 s / img. ETA=0:05:11
[32m[04/28 08:07:17 d2.evaluation.evaluator]: [0mInference done 5729/8355. 0.1150 s / img. ETA=0:05:06
[32m[04/28 08:07:22 d2.evaluation.evaluator]: [0mInference done 5772/8355. 0.1150 s / img. ETA=0:05:01
[32m[04/28 08:07:27 d2.evaluation.evaluator]: [0mInference done 5815/8355. 0.1150 s / img. ETA=0:04:56
[32m[04/28 08:07:33 d2.evaluation.evaluator]: [0mInference done 5858/8355. 0.1150 s / img. ETA=0:04:51
[32m[04/28 08:07:38 d2.evaluation.evaluator]: [0mInference done 5901/8355. 0.1150 s / img. ETA=0:04:46
[32m[04/28 08:07:43 d2.evaluation.evaluator]: [0mInference done 5944/8355. 0.1150 s / img. ETA=0:04:41
[32m[04/28 08:07:48 d2.evaluation.evaluator]: [0mInference done 5987/8355. 0.1150 s / img. ETA=0:04:36
[32m[04/28 08:07:53 d2.evaluation.evaluator]: [0mInference done 6030/8355. 0.1150 s / img. ETA=0:04:31
[32m[04/28 08:07:58 d2.evaluation.evaluator]: [0mInference done 6073/8355. 0.1150 s / img. ETA=0:04:26
[32m[04/28 08:08:03 d2.evaluation.evaluator]: [0mInference done 6116/8355. 0.1150 s / img. ETA=0:04:21
[32m[04/28 08:08:08 d2.evaluation.evaluator]: [0mInference done 6159/8355. 0.1151 s / img. ETA=0:04:16
[32m[04/28 08:08:13 d2.evaluation.evaluator]: [0mInference done 6202/8355. 0.1151 s / img. ETA=0:04:11
[32m[04/28 08:08:18 d2.evaluation.evaluator]: [0mInference done 6245/8355. 0.1151 s / img. ETA=0:04:06
[32m[04/28 08:08:23 d2.evaluation.evaluator]: [0mInference done 6288/8355. 0.1151 s / img. ETA=0:04:01
[32m[04/28 08:08:28 d2.evaluation.evaluator]: [0mInference done 6330/8355. 0.1151 s / img. ETA=0:03:56
[32m[04/28 08:08:33 d2.evaluation.evaluator]: [0mInference done 6373/8355. 0.1151 s / img. ETA=0:03:51
[32m[04/28 08:08:38 d2.evaluation.evaluator]: [0mInference done 6415/8355. 0.1151 s / img. ETA=0:03:46
[32m[04/28 08:08:43 d2.evaluation.evaluator]: [0mInference done 6458/8355. 0.1151 s / img. ETA=0:03:41
[32m[04/28 08:08:48 d2.evaluation.evaluator]: [0mInference done 6501/8355. 0.1151 s / img. ETA=0:03:36
[32m[04/28 08:08:53 d2.evaluation.evaluator]: [0mInference done 6545/8355. 0.1151 s / img. ETA=0:03:31
[32m[04/28 08:08:58 d2.evaluation.evaluator]: [0mInference done 6588/8355. 0.1151 s / img. ETA=0:03:26
[32m[04/28 08:09:04 d2.evaluation.evaluator]: [0mInference done 6631/8355. 0.1151 s / img. ETA=0:03:21
[32m[04/28 08:09:09 d2.evaluation.evaluator]: [0mInference done 6674/8355. 0.1151 s / img. ETA=0:03:16
[32m[04/28 08:09:14 d2.evaluation.evaluator]: [0mInference done 6717/8355. 0.1151 s / img. ETA=0:03:11
[32m[04/28 08:09:19 d2.evaluation.evaluator]: [0mInference done 6761/8355. 0.1151 s / img. ETA=0:03:06
[32m[04/28 08:09:24 d2.evaluation.evaluator]: [0mInference done 6804/8355. 0.1151 s / img. ETA=0:03:01
[32m[04/28 08:09:29 d2.evaluation.evaluator]: [0mInference done 6847/8355. 0.1151 s / img. ETA=0:02:56
[32m[04/28 08:09:34 d2.evaluation.evaluator]: [0mInference done 6890/8355. 0.1151 s / img. ETA=0:02:51
[32m[04/28 08:09:39 d2.evaluation.evaluator]: [0mInference done 6933/8355. 0.1151 s / img. ETA=0:02:46
[32m[04/28 08:09:44 d2.evaluation.evaluator]: [0mInference done 6976/8355. 0.1151 s / img. ETA=0:02:41
[32m[04/28 08:09:49 d2.evaluation.evaluator]: [0mInference done 7019/8355. 0.1151 s / img. ETA=0:02:36
[32m[04/28 08:09:54 d2.evaluation.evaluator]: [0mInference done 7062/8355. 0.1151 s / img. ETA=0:02:31
[32m[04/28 08:09:59 d2.evaluation.evaluator]: [0mInference done 7105/8355. 0.1151 s / img. ETA=0:02:26
[32m[04/28 08:10:04 d2.evaluation.evaluator]: [0mInference done 7148/8355. 0.1151 s / img. ETA=0:02:21
[32m[04/28 08:10:09 d2.evaluation.evaluator]: [0mInference done 7191/8355. 0.1151 s / img. ETA=0:02:16
[32m[04/28 08:10:14 d2.evaluation.evaluator]: [0mInference done 7234/8355. 0.1151 s / img. ETA=0:02:11
[32m[04/28 08:10:19 d2.evaluation.evaluator]: [0mInference done 7277/8355. 0.1151 s / img. ETA=0:02:06
[32m[04/28 08:10:24 d2.evaluation.evaluator]: [0mInference done 7320/8355. 0.1151 s / img. ETA=0:02:01
[32m[04/28 08:10:29 d2.evaluation.evaluator]: [0mInference done 7362/8355. 0.1151 s / img. ETA=0:01:56
[32m[04/28 08:10:34 d2.evaluation.evaluator]: [0mInference done 7405/8355. 0.1151 s / img. ETA=0:01:51
[32m[04/28 08:10:40 d2.evaluation.evaluator]: [0mInference done 7448/8355. 0.1151 s / img. ETA=0:01:46
[32m[04/28 08:10:45 d2.evaluation.evaluator]: [0mInference done 7491/8355. 0.1152 s / img. ETA=0:01:41
[32m[04/28 08:10:50 d2.evaluation.evaluator]: [0mInference done 7534/8355. 0.1152 s / img. ETA=0:01:36
[32m[04/28 08:10:55 d2.evaluation.evaluator]: [0mInference done 7577/8355. 0.1152 s / img. ETA=0:01:31
[32m[04/28 08:11:00 d2.evaluation.evaluator]: [0mInference done 7620/8355. 0.1152 s / img. ETA=0:01:25
[32m[04/28 08:11:05 d2.evaluation.evaluator]: [0mInference done 7663/8355. 0.1152 s / img. ETA=0:01:20
[32m[04/28 08:11:10 d2.evaluation.evaluator]: [0mInference done 7706/8355. 0.1152 s / img. ETA=0:01:15
[32m[04/28 08:11:15 d2.evaluation.evaluator]: [0mInference done 7749/8355. 0.1152 s / img. ETA=0:01:10
[32m[04/28 08:11:20 d2.evaluation.evaluator]: [0mInference done 7792/8355. 0.1152 s / img. ETA=0:01:05
[32m[04/28 08:11:25 d2.evaluation.evaluator]: [0mInference done 7835/8355. 0.1152 s / img. ETA=0:01:00
[32m[04/28 08:11:30 d2.evaluation.evaluator]: [0mInference done 7878/8355. 0.1152 s / img. ETA=0:00:55
[32m[04/28 08:11:35 d2.evaluation.evaluator]: [0mInference done 7921/8355. 0.1152 s / img. ETA=0:00:50
[32m[04/28 08:11:40 d2.evaluation.evaluator]: [0mInference done 7964/8355. 0.1152 s / img. ETA=0:00:45
[32m[04/28 08:11:45 d2.evaluation.evaluator]: [0mInference done 8007/8355. 0.1152 s / img. ETA=0:00:40
[32m[04/28 08:11:50 d2.evaluation.evaluator]: [0mInference done 8050/8355. 0.1152 s / img. ETA=0:00:35
[32m[04/28 08:11:55 d2.evaluation.evaluator]: [0mInference done 8093/8355. 0.1152 s / img. ETA=0:00:30
[32m[04/28 08:12:00 d2.evaluation.evaluator]: [0mInference done 8137/8355. 0.1152 s / img. ETA=0:00:25
[32m[04/28 08:12:06 d2.evaluation.evaluator]: [0mInference done 8181/8355. 0.1152 s / img. ETA=0:00:20
[32m[04/28 08:12:11 d2.evaluation.evaluator]: [0mInference done 8224/8355. 0.1152 s / img. ETA=0:00:15
[32m[04/28 08:12:16 d2.evaluation.evaluator]: [0mInference done 8267/8355. 0.1152 s / img. ETA=0:00:10
[32m[04/28 08:12:21 d2.evaluation.evaluator]: [0mInference done 8310/8355. 0.1152 s / img. ETA=0:00:05
[32m[04/28 08:12:26 d2.evaluation.evaluator]: [0mInference done 8353/8355. 0.1152 s / img. ETA=0:00:00
[32m[04/28 08:12:26 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:17.071643 (0.117015 s / img per device, on 1 devices)
[32m[04/28 08:12:26 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:01 (0.115185 s / img per device, on 1 devices)
[32m[04/28 08:12:26 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 08:12:26 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 08:12:26 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.34s).
Accumulating evaluation results...
DONE (t=2.75s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.456
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.810
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.448
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.346
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.590
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.705
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.174
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.503
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.519
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.421
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.752
[32m[04/28 08:12:49 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.637 | 80.991 | 44.817 | 34.595 | 58.975 | 70.506 |
[32m[04/28 08:12:49 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 46.518 | bicycle       | 35.168 | car            | 55.224 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 08:12:49 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 08:12:49 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 08:12:49 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 08:12:51 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1148 s / img. ETA=0:02:24
[32m[04/28 08:12:56 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1146 s / img. ETA=0:02:20
[32m[04/28 08:13:01 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1147 s / img. ETA=0:02:15
[32m[04/28 08:13:06 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1147 s / img. ETA=0:02:10
[32m[04/28 08:13:11 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1148 s / img. ETA=0:02:05
[32m[04/28 08:13:16 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1148 s / img. ETA=0:02:00
[32m[04/28 08:13:21 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1149 s / img. ETA=0:01:55
[32m[04/28 08:13:26 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1149 s / img. ETA=0:01:50
[32m[04/28 08:13:31 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1149 s / img. ETA=0:01:45
[32m[04/28 08:13:36 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1149 s / img. ETA=0:01:40
[32m[04/28 08:13:41 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1148 s / img. ETA=0:01:35
[32m[04/28 08:13:46 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1148 s / img. ETA=0:01:30
[32m[04/28 08:13:51 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1148 s / img. ETA=0:01:25
[32m[04/28 08:13:56 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1149 s / img. ETA=0:01:20
[32m[04/28 08:14:01 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1149 s / img. ETA=0:01:15
[32m[04/28 08:14:06 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1149 s / img. ETA=0:01:10
[32m[04/28 08:14:11 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1149 s / img. ETA=0:01:05
[32m[04/28 08:14:16 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1149 s / img. ETA=0:01:00
[32m[04/28 08:14:21 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1149 s / img. ETA=0:00:55
[32m[04/28 08:14:26 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1149 s / img. ETA=0:00:50
[32m[04/28 08:14:31 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1150 s / img. ETA=0:00:45
[32m[04/28 08:14:36 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1150 s / img. ETA=0:00:40
[32m[04/28 08:14:41 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1150 s / img. ETA=0:00:35
[32m[04/28 08:14:46 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1150 s / img. ETA=0:00:30
[32m[04/28 08:14:51 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1150 s / img. ETA=0:00:25
[32m[04/28 08:14:56 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1150 s / img. ETA=0:00:19
[32m[04/28 08:15:01 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1151 s / img. ETA=0:00:14
[32m[04/28 08:15:06 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1151 s / img. ETA=0:00:09
[32m[04/28 08:15:11 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1151 s / img. ETA=0:00:04
[32m[04/28 08:15:16 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.501992 (0.117014 s / img per device, on 1 devices)
[32m[04/28 08:15:16 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115138 s / img per device, on 1 devices)
[32m[04/28 08:15:16 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 08:15:16 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 08:15:16 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.70s).
Accumulating evaluation results...
DONE (t=0.36s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.417
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.771
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.395
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.313
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.484
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.550
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.486
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.399
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.556
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.605
[32m[04/28 08:15:20 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.733 | 77.088 | 39.528 | 31.296 | 48.360 | 54.971 |
[32m[04/28 08:15:20 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 44.394 | bicycle       | 26.529 | car            | 54.275 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  11  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 08:15:20 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 08:15:21 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 08:15:21 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 08:15:21 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 08:15:21 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 08:15:21 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 08:15:21 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 08:15:42 d2.utils.events]: [0m eta: 0:17:31  iter: 19  total_loss: 0.482  loss_cls: 0.146  loss_box_reg: 0.280  loss_rpn_cls: 0.009  loss_rpn_loc: 0.043  time: 1.0456  data_time: 0.0195  lr: 0.000100  max_mem: 5397M
[32m[04/28 08:16:03 d2.utils.events]: [0m eta: 0:16:53  iter: 39  total_loss: 0.558  loss_cls: 0.185  loss_box_reg: 0.313  loss_rpn_cls: 0.010  loss_rpn_loc: 0.051  time: 1.0361  data_time: 0.0076  lr: 0.000200  max_mem: 5397M
[32m[04/28 08:16:23 d2.utils.events]: [0m eta: 0:16:22  iter: 59  total_loss: 0.521  loss_cls: 0.155  loss_box_reg: 0.299  loss_rpn_cls: 0.009  loss_rpn_loc: 0.052  time: 1.0328  data_time: 0.0075  lr: 0.000300  max_mem: 5397M
[32m[04/28 08:16:44 d2.utils.events]: [0m eta: 0:15:53  iter: 79  total_loss: 0.565  loss_cls: 0.174  loss_box_reg: 0.340  loss_rpn_cls: 0.009  loss_rpn_loc: 0.054  time: 1.0276  data_time: 0.0077  lr: 0.000400  max_mem: 5397M
[32m[04/28 08:17:04 d2.utils.events]: [0m eta: 0:15:32  iter: 99  total_loss: 0.536  loss_cls: 0.172  loss_box_reg: 0.304  loss_rpn_cls: 0.008  loss_rpn_loc: 0.039  time: 1.0281  data_time: 0.0079  lr: 0.000500  max_mem: 5397M
[32m[04/28 08:17:24 d2.utils.events]: [0m eta: 0:15:01  iter: 119  total_loss: 0.519  loss_cls: 0.161  loss_box_reg: 0.303  loss_rpn_cls: 0.005  loss_rpn_loc: 0.047  time: 1.0231  data_time: 0.0077  lr: 0.000599  max_mem: 5397M
[32m[04/28 08:17:45 d2.utils.events]: [0m eta: 0:14:42  iter: 139  total_loss: 0.546  loss_cls: 0.168  loss_box_reg: 0.311  loss_rpn_cls: 0.009  loss_rpn_loc: 0.052  time: 1.0235  data_time: 0.0078  lr: 0.000699  max_mem: 5397M
[32m[04/28 08:18:05 d2.utils.events]: [0m eta: 0:14:25  iter: 159  total_loss: 0.477  loss_cls: 0.147  loss_box_reg: 0.285  loss_rpn_cls: 0.008  loss_rpn_loc: 0.046  time: 1.0236  data_time: 0.0079  lr: 0.000799  max_mem: 5397M
[32m[04/28 08:18:26 d2.utils.events]: [0m eta: 0:14:03  iter: 179  total_loss: 0.464  loss_cls: 0.146  loss_box_reg: 0.265  loss_rpn_cls: 0.008  loss_rpn_loc: 0.040  time: 1.0230  data_time: 0.0074  lr: 0.000899  max_mem: 5397M
[32m[04/28 08:18:47 d2.utils.events]: [0m eta: 0:13:50  iter: 199  total_loss: 0.522  loss_cls: 0.171  loss_box_reg: 0.308  loss_rpn_cls: 0.009  loss_rpn_loc: 0.042  time: 1.0264  data_time: 0.0077  lr: 0.000999  max_mem: 5397M
[32m[04/28 08:19:07 d2.utils.events]: [0m eta: 0:13:25  iter: 219  total_loss: 0.590  loss_cls: 0.188  loss_box_reg: 0.338  loss_rpn_cls: 0.008  loss_rpn_loc: 0.055  time: 1.0255  data_time: 0.0079  lr: 0.001099  max_mem: 5397M
[32m[04/28 08:19:29 d2.utils.events]: [0m eta: 0:13:09  iter: 239  total_loss: 0.544  loss_cls: 0.169  loss_box_reg: 0.306  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 1.0275  data_time: 0.0078  lr: 0.001199  max_mem: 5397M
[32m[04/28 08:19:49 d2.utils.events]: [0m eta: 0:12:48  iter: 259  total_loss: 0.517  loss_cls: 0.159  loss_box_reg: 0.311  loss_rpn_cls: 0.009  loss_rpn_loc: 0.048  time: 1.0274  data_time: 0.0075  lr: 0.001299  max_mem: 5397M
[32m[04/28 08:20:10 d2.utils.events]: [0m eta: 0:12:27  iter: 279  total_loss: 0.606  loss_cls: 0.187  loss_box_reg: 0.320  loss_rpn_cls: 0.008  loss_rpn_loc: 0.056  time: 1.0269  data_time: 0.0076  lr: 0.001399  max_mem: 5397M
[32m[04/28 08:20:30 d2.utils.events]: [0m eta: 0:12:06  iter: 299  total_loss: 0.449  loss_cls: 0.144  loss_box_reg: 0.259  loss_rpn_cls: 0.006  loss_rpn_loc: 0.039  time: 1.0275  data_time: 0.0077  lr: 0.001499  max_mem: 5397M
[32m[04/28 08:20:51 d2.utils.events]: [0m eta: 0:11:46  iter: 319  total_loss: 0.550  loss_cls: 0.183  loss_box_reg: 0.325  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 1.0277  data_time: 0.0079  lr: 0.001598  max_mem: 5397M
[32m[04/28 08:21:12 d2.utils.events]: [0m eta: 0:11:26  iter: 339  total_loss: 0.491  loss_cls: 0.152  loss_box_reg: 0.291  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0285  data_time: 0.0079  lr: 0.001698  max_mem: 5397M
[32m[04/28 08:21:33 d2.utils.events]: [0m eta: 0:11:06  iter: 359  total_loss: 0.561  loss_cls: 0.166  loss_box_reg: 0.316  loss_rpn_cls: 0.009  loss_rpn_loc: 0.054  time: 1.0288  data_time: 0.0081  lr: 0.001798  max_mem: 5397M
[32m[04/28 08:21:53 d2.utils.events]: [0m eta: 0:10:44  iter: 379  total_loss: 0.531  loss_cls: 0.156  loss_box_reg: 0.324  loss_rpn_cls: 0.005  loss_rpn_loc: 0.046  time: 1.0283  data_time: 0.0077  lr: 0.001898  max_mem: 5397M
[32m[04/28 08:22:13 d2.utils.events]: [0m eta: 0:10:23  iter: 399  total_loss: 0.512  loss_cls: 0.175  loss_box_reg: 0.293  loss_rpn_cls: 0.005  loss_rpn_loc: 0.042  time: 1.0277  data_time: 0.0076  lr: 0.001998  max_mem: 5397M
[32m[04/28 08:22:34 d2.utils.events]: [0m eta: 0:10:01  iter: 419  total_loss: 0.514  loss_cls: 0.167  loss_box_reg: 0.282  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0268  data_time: 0.0076  lr: 0.002098  max_mem: 5397M
[32m[04/28 08:22:54 d2.utils.events]: [0m eta: 0:09:38  iter: 439  total_loss: 0.536  loss_cls: 0.181  loss_box_reg: 0.307  loss_rpn_cls: 0.012  loss_rpn_loc: 0.048  time: 1.0253  data_time: 0.0076  lr: 0.002198  max_mem: 5397M
[32m[04/28 08:23:14 d2.utils.events]: [0m eta: 0:09:17  iter: 459  total_loss: 0.485  loss_cls: 0.147  loss_box_reg: 0.288  loss_rpn_cls: 0.007  loss_rpn_loc: 0.039  time: 1.0245  data_time: 0.0076  lr: 0.002298  max_mem: 5397M
[32m[04/28 08:23:34 d2.utils.events]: [0m eta: 0:08:56  iter: 479  total_loss: 0.547  loss_cls: 0.169  loss_box_reg: 0.303  loss_rpn_cls: 0.008  loss_rpn_loc: 0.054  time: 1.0241  data_time: 0.0077  lr: 0.002398  max_mem: 5397M
[32m[04/28 08:23:55 d2.utils.events]: [0m eta: 0:08:36  iter: 499  total_loss: 0.520  loss_cls: 0.172  loss_box_reg: 0.303  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 1.0249  data_time: 0.0078  lr: 0.002498  max_mem: 5397M
[32m[04/28 08:24:16 d2.utils.events]: [0m eta: 0:08:16  iter: 519  total_loss: 0.614  loss_cls: 0.192  loss_box_reg: 0.346  loss_rpn_cls: 0.010  loss_rpn_loc: 0.059  time: 1.0252  data_time: 0.0076  lr: 0.002597  max_mem: 5397M
[32m[04/28 08:24:36 d2.utils.events]: [0m eta: 0:07:56  iter: 539  total_loss: 0.470  loss_cls: 0.143  loss_box_reg: 0.284  loss_rpn_cls: 0.007  loss_rpn_loc: 0.035  time: 1.0250  data_time: 0.0077  lr: 0.002697  max_mem: 5397M
[32m[04/28 08:24:57 d2.utils.events]: [0m eta: 0:07:35  iter: 559  total_loss: 0.597  loss_cls: 0.178  loss_box_reg: 0.315  loss_rpn_cls: 0.007  loss_rpn_loc: 0.055  time: 1.0253  data_time: 0.0078  lr: 0.002797  max_mem: 5397M
[32m[04/28 08:25:17 d2.utils.events]: [0m eta: 0:07:14  iter: 579  total_loss: 0.567  loss_cls: 0.183  loss_box_reg: 0.312  loss_rpn_cls: 0.008  loss_rpn_loc: 0.048  time: 1.0249  data_time: 0.0077  lr: 0.002897  max_mem: 5397M
[32m[04/28 08:25:38 d2.utils.events]: [0m eta: 0:06:54  iter: 599  total_loss: 0.564  loss_cls: 0.180  loss_box_reg: 0.321  loss_rpn_cls: 0.006  loss_rpn_loc: 0.052  time: 1.0257  data_time: 0.0083  lr: 0.002997  max_mem: 5397M
[32m[04/28 08:25:59 d2.utils.events]: [0m eta: 0:06:33  iter: 619  total_loss: 0.545  loss_cls: 0.177  loss_box_reg: 0.306  loss_rpn_cls: 0.009  loss_rpn_loc: 0.046  time: 1.0260  data_time: 0.0077  lr: 0.003097  max_mem: 5397M
[32m[04/28 08:26:20 d2.utils.events]: [0m eta: 0:06:13  iter: 639  total_loss: 0.557  loss_cls: 0.181  loss_box_reg: 0.317  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 1.0260  data_time: 0.0078  lr: 0.003197  max_mem: 5397M
[32m[04/28 08:26:40 d2.utils.events]: [0m eta: 0:05:52  iter: 659  total_loss: 0.484  loss_cls: 0.147  loss_box_reg: 0.287  loss_rpn_cls: 0.008  loss_rpn_loc: 0.037  time: 1.0255  data_time: 0.0078  lr: 0.003297  max_mem: 5397M
[32m[04/28 08:27:01 d2.utils.events]: [0m eta: 0:05:31  iter: 679  total_loss: 0.571  loss_cls: 0.175  loss_box_reg: 0.340  loss_rpn_cls: 0.010  loss_rpn_loc: 0.044  time: 1.0259  data_time: 0.0078  lr: 0.003397  max_mem: 5397M
[32m[04/28 08:27:21 d2.utils.events]: [0m eta: 0:05:11  iter: 699  total_loss: 0.522  loss_cls: 0.164  loss_box_reg: 0.309  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 1.0254  data_time: 0.0079  lr: 0.003497  max_mem: 5397M
[32m[04/28 08:27:42 d2.utils.events]: [0m eta: 0:04:50  iter: 719  total_loss: 0.555  loss_cls: 0.176  loss_box_reg: 0.307  loss_rpn_cls: 0.007  loss_rpn_loc: 0.056  time: 1.0257  data_time: 0.0076  lr: 0.003596  max_mem: 5397M
[32m[04/28 08:28:02 d2.utils.events]: [0m eta: 0:04:29  iter: 739  total_loss: 0.527  loss_cls: 0.167  loss_box_reg: 0.293  loss_rpn_cls: 0.009  loss_rpn_loc: 0.042  time: 1.0255  data_time: 0.0075  lr: 0.003696  max_mem: 5397M
[32m[04/28 08:28:22 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.442  loss_cls: 0.136  loss_box_reg: 0.246  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 1.0252  data_time: 0.0077  lr: 0.003796  max_mem: 5397M
[32m[04/28 08:28:43 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.567  loss_cls: 0.172  loss_box_reg: 0.311  loss_rpn_cls: 0.010  loss_rpn_loc: 0.045  time: 1.0253  data_time: 0.0074  lr: 0.003896  max_mem: 5397M
[32m[04/28 08:29:03 d2.utils.events]: [0m eta: 0:03:27  iter: 799  total_loss: 0.498  loss_cls: 0.157  loss_box_reg: 0.274  loss_rpn_cls: 0.010  loss_rpn_loc: 0.049  time: 1.0244  data_time: 0.0074  lr: 0.003996  max_mem: 5397M
[32m[04/28 08:29:23 d2.utils.events]: [0m eta: 0:03:06  iter: 819  total_loss: 0.562  loss_cls: 0.172  loss_box_reg: 0.324  loss_rpn_cls: 0.006  loss_rpn_loc: 0.055  time: 1.0244  data_time: 0.0076  lr: 0.004096  max_mem: 5397M
[32m[04/28 08:29:44 d2.utils.events]: [0m eta: 0:02:45  iter: 839  total_loss: 0.581  loss_cls: 0.174  loss_box_reg: 0.346  loss_rpn_cls: 0.010  loss_rpn_loc: 0.046  time: 1.0242  data_time: 0.0076  lr: 0.004196  max_mem: 5397M
[32m[04/28 08:30:04 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.503  loss_cls: 0.157  loss_box_reg: 0.283  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0244  data_time: 0.0077  lr: 0.004296  max_mem: 5397M
[32m[04/28 08:30:25 d2.utils.events]: [0m eta: 0:02:04  iter: 879  total_loss: 0.540  loss_cls: 0.165  loss_box_reg: 0.312  loss_rpn_cls: 0.008  loss_rpn_loc: 0.048  time: 1.0245  data_time: 0.0075  lr: 0.004396  max_mem: 5397M
[32m[04/28 08:30:46 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.570  loss_cls: 0.180  loss_box_reg: 0.334  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0251  data_time: 0.0076  lr: 0.004496  max_mem: 5397M
[32m[04/28 08:31:07 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.536  loss_cls: 0.168  loss_box_reg: 0.298  loss_rpn_cls: 0.007  loss_rpn_loc: 0.059  time: 1.0259  data_time: 0.0076  lr: 0.004595  max_mem: 5397M
[32m[04/28 08:31:29 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.487  loss_cls: 0.151  loss_box_reg: 0.296  loss_rpn_cls: 0.007  loss_rpn_loc: 0.043  time: 1.0267  data_time: 0.0077  lr: 0.004695  max_mem: 5397M
[32m[04/28 08:31:49 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.489  loss_cls: 0.151  loss_box_reg: 0.268  loss_rpn_cls: 0.008  loss_rpn_loc: 0.047  time: 1.0266  data_time: 0.0076  lr: 0.004795  max_mem: 5397M
[32m[04/28 08:32:10 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.598  loss_cls: 0.189  loss_box_reg: 0.337  loss_rpn_cls: 0.014  loss_rpn_loc: 0.049  time: 1.0264  data_time: 0.0078  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 08:32:33 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 08:32:33 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 08:32:33 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 08:32:33 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.552  loss_cls: 0.164  loss_box_reg: 0.319  loss_rpn_cls: 0.010  loss_rpn_loc: 0.053  time: 1.0266  data_time: 0.0077  lr: 0.004995  max_mem: 5397M
[32m[04/28 08:32:33 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:04 (1.0277 s / it)
[32m[04/28 08:32:33 d2.engine.hooks]: [0mTotal training time: 0:17:10 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 08:32:34 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 08:32:35 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 08:32:35 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 08:32:36 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1142 s / img. ETA=0:16:04
[32m[04/28 08:32:42 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1140 s / img. ETA=0:16:00
[32m[04/28 08:32:47 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1139 s / img. ETA=0:15:54
[32m[04/28 08:32:52 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1140 s / img. ETA=0:15:49
[32m[04/28 08:32:57 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1140 s / img. ETA=0:15:44
[32m[04/28 08:33:02 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1141 s / img. ETA=0:15:40
[32m[04/28 08:33:07 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1141 s / img. ETA=0:15:35
[32m[04/28 08:33:12 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1141 s / img. ETA=0:15:30
[32m[04/28 08:33:17 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1142 s / img. ETA=0:15:25
[32m[04/28 08:33:22 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1142 s / img. ETA=0:15:21
[32m[04/28 08:33:27 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1142 s / img. ETA=0:15:16
[32m[04/28 08:33:33 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1142 s / img. ETA=0:15:10
[32m[04/28 08:33:38 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1141 s / img. ETA=0:15:05
[32m[04/28 08:33:43 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1141 s / img. ETA=0:15:00
[32m[04/28 08:33:48 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1141 s / img. ETA=0:14:55
[32m[04/28 08:33:53 d2.evaluation.evaluator]: [0mInference done 670/8355. 0.1142 s / img. ETA=0:14:50
[32m[04/28 08:33:58 d2.evaluation.evaluator]: [0mInference done 713/8355. 0.1142 s / img. ETA=0:14:45
[32m[04/28 08:34:03 d2.evaluation.evaluator]: [0mInference done 756/8355. 0.1143 s / img. ETA=0:14:41
[32m[04/28 08:34:08 d2.evaluation.evaluator]: [0mInference done 799/8355. 0.1143 s / img. ETA=0:14:36
[32m[04/28 08:34:13 d2.evaluation.evaluator]: [0mInference done 843/8355. 0.1143 s / img. ETA=0:14:31
[32m[04/28 08:34:18 d2.evaluation.evaluator]: [0mInference done 886/8355. 0.1144 s / img. ETA=0:14:26
[32m[04/28 08:34:23 d2.evaluation.evaluator]: [0mInference done 929/8355. 0.1144 s / img. ETA=0:14:22
[32m[04/28 08:34:28 d2.evaluation.evaluator]: [0mInference done 972/8355. 0.1144 s / img. ETA=0:14:17
[32m[04/28 08:34:33 d2.evaluation.evaluator]: [0mInference done 1015/8355. 0.1144 s / img. ETA=0:14:12
[32m[04/28 08:34:38 d2.evaluation.evaluator]: [0mInference done 1058/8355. 0.1144 s / img. ETA=0:14:07
[32m[04/28 08:34:43 d2.evaluation.evaluator]: [0mInference done 1102/8355. 0.1144 s / img. ETA=0:14:02
[32m[04/28 08:34:48 d2.evaluation.evaluator]: [0mInference done 1145/8355. 0.1144 s / img. ETA=0:13:57
[32m[04/28 08:34:53 d2.evaluation.evaluator]: [0mInference done 1189/8355. 0.1144 s / img. ETA=0:13:52
[32m[04/28 08:34:58 d2.evaluation.evaluator]: [0mInference done 1233/8355. 0.1144 s / img. ETA=0:13:46
[32m[04/28 08:35:03 d2.evaluation.evaluator]: [0mInference done 1277/8355. 0.1144 s / img. ETA=0:13:41
[32m[04/28 08:35:09 d2.evaluation.evaluator]: [0mInference done 1320/8355. 0.1145 s / img. ETA=0:13:37
[32m[04/28 08:35:14 d2.evaluation.evaluator]: [0mInference done 1364/8355. 0.1144 s / img. ETA=0:13:31
[32m[04/28 08:35:19 d2.evaluation.evaluator]: [0mInference done 1408/8355. 0.1144 s / img. ETA=0:13:26
[32m[04/28 08:35:24 d2.evaluation.evaluator]: [0mInference done 1451/8355. 0.1144 s / img. ETA=0:13:21
[32m[04/28 08:35:29 d2.evaluation.evaluator]: [0mInference done 1494/8355. 0.1145 s / img. ETA=0:13:16
[32m[04/28 08:35:34 d2.evaluation.evaluator]: [0mInference done 1537/8355. 0.1145 s / img. ETA=0:13:12
[32m[04/28 08:35:39 d2.evaluation.evaluator]: [0mInference done 1580/8355. 0.1146 s / img. ETA=0:13:07
[32m[04/28 08:35:44 d2.evaluation.evaluator]: [0mInference done 1623/8355. 0.1146 s / img. ETA=0:13:03
[32m[04/28 08:35:49 d2.evaluation.evaluator]: [0mInference done 1666/8355. 0.1146 s / img. ETA=0:12:58
[32m[04/28 08:35:54 d2.evaluation.evaluator]: [0mInference done 1709/8355. 0.1146 s / img. ETA=0:12:53
[32m[04/28 08:35:59 d2.evaluation.evaluator]: [0mInference done 1752/8355. 0.1147 s / img. ETA=0:12:48
[32m[04/28 08:36:04 d2.evaluation.evaluator]: [0mInference done 1795/8355. 0.1147 s / img. ETA=0:12:43
[32m[04/28 08:36:09 d2.evaluation.evaluator]: [0mInference done 1838/8355. 0.1147 s / img. ETA=0:12:38
[32m[04/28 08:36:14 d2.evaluation.evaluator]: [0mInference done 1881/8355. 0.1148 s / img. ETA=0:12:34
[32m[04/28 08:36:19 d2.evaluation.evaluator]: [0mInference done 1924/8355. 0.1148 s / img. ETA=0:12:29
[32m[04/28 08:36:24 d2.evaluation.evaluator]: [0mInference done 1967/8355. 0.1148 s / img. ETA=0:12:24
[32m[04/28 08:36:29 d2.evaluation.evaluator]: [0mInference done 2010/8355. 0.1148 s / img. ETA=0:12:19
[32m[04/28 08:36:34 d2.evaluation.evaluator]: [0mInference done 2053/8355. 0.1148 s / img. ETA=0:12:14
[32m[04/28 08:36:39 d2.evaluation.evaluator]: [0mInference done 2096/8355. 0.1148 s / img. ETA=0:12:09
[32m[04/28 08:36:45 d2.evaluation.evaluator]: [0mInference done 2139/8355. 0.1148 s / img. ETA=0:12:04
[32m[04/28 08:36:50 d2.evaluation.evaluator]: [0mInference done 2182/8355. 0.1148 s / img. ETA=0:11:59
[32m[04/28 08:36:55 d2.evaluation.evaluator]: [0mInference done 2225/8355. 0.1148 s / img. ETA=0:11:54
[32m[04/28 08:37:00 d2.evaluation.evaluator]: [0mInference done 2268/8355. 0.1149 s / img. ETA=0:11:49
[32m[04/28 08:37:05 d2.evaluation.evaluator]: [0mInference done 2311/8355. 0.1149 s / img. ETA=0:11:44
[32m[04/28 08:37:10 d2.evaluation.evaluator]: [0mInference done 2354/8355. 0.1149 s / img. ETA=0:11:39
[32m[04/28 08:37:15 d2.evaluation.evaluator]: [0mInference done 2397/8355. 0.1149 s / img. ETA=0:11:35
[32m[04/28 08:37:20 d2.evaluation.evaluator]: [0mInference done 2440/8355. 0.1149 s / img. ETA=0:11:30
[32m[04/28 08:37:25 d2.evaluation.evaluator]: [0mInference done 2483/8355. 0.1149 s / img. ETA=0:11:25
[32m[04/28 08:37:30 d2.evaluation.evaluator]: [0mInference done 2526/8355. 0.1149 s / img. ETA=0:11:20
[32m[04/28 08:37:35 d2.evaluation.evaluator]: [0mInference done 2569/8355. 0.1149 s / img. ETA=0:11:15
[32m[04/28 08:37:40 d2.evaluation.evaluator]: [0mInference done 2612/8355. 0.1149 s / img. ETA=0:11:10
[32m[04/28 08:37:45 d2.evaluation.evaluator]: [0mInference done 2655/8355. 0.1149 s / img. ETA=0:11:05
[32m[04/28 08:37:50 d2.evaluation.evaluator]: [0mInference done 2698/8355. 0.1150 s / img. ETA=0:11:00
[32m[04/28 08:37:55 d2.evaluation.evaluator]: [0mInference done 2741/8355. 0.1150 s / img. ETA=0:10:55
[32m[04/28 08:38:00 d2.evaluation.evaluator]: [0mInference done 2784/8355. 0.1150 s / img. ETA=0:10:50
[32m[04/28 08:38:05 d2.evaluation.evaluator]: [0mInference done 2827/8355. 0.1150 s / img. ETA=0:10:45
[32m[04/28 08:38:10 d2.evaluation.evaluator]: [0mInference done 2870/8355. 0.1150 s / img. ETA=0:10:40
[32m[04/28 08:38:15 d2.evaluation.evaluator]: [0mInference done 2913/8355. 0.1150 s / img. ETA=0:10:35
[32m[04/28 08:38:20 d2.evaluation.evaluator]: [0mInference done 2956/8355. 0.1150 s / img. ETA=0:10:30
[32m[04/28 08:38:25 d2.evaluation.evaluator]: [0mInference done 2999/8355. 0.1150 s / img. ETA=0:10:25
[32m[04/28 08:38:31 d2.evaluation.evaluator]: [0mInference done 3042/8355. 0.1150 s / img. ETA=0:10:20
[32m[04/28 08:38:36 d2.evaluation.evaluator]: [0mInference done 3085/8355. 0.1151 s / img. ETA=0:10:15
[32m[04/28 08:38:41 d2.evaluation.evaluator]: [0mInference done 3128/8355. 0.1151 s / img. ETA=0:10:10
[32m[04/28 08:38:46 d2.evaluation.evaluator]: [0mInference done 3172/8355. 0.1150 s / img. ETA=0:10:05
[32m[04/28 08:38:51 d2.evaluation.evaluator]: [0mInference done 3215/8355. 0.1151 s / img. ETA=0:10:00
[32m[04/28 08:38:56 d2.evaluation.evaluator]: [0mInference done 3258/8355. 0.1151 s / img. ETA=0:09:55
[32m[04/28 08:39:01 d2.evaluation.evaluator]: [0mInference done 3301/8355. 0.1150 s / img. ETA=0:09:50
[32m[04/28 08:39:06 d2.evaluation.evaluator]: [0mInference done 3345/8355. 0.1150 s / img. ETA=0:09:45
[32m[04/28 08:39:11 d2.evaluation.evaluator]: [0mInference done 3388/8355. 0.1150 s / img. ETA=0:09:40
[32m[04/28 08:39:16 d2.evaluation.evaluator]: [0mInference done 3431/8355. 0.1150 s / img. ETA=0:09:35
[32m[04/28 08:39:21 d2.evaluation.evaluator]: [0mInference done 3475/8355. 0.1150 s / img. ETA=0:09:29
[32m[04/28 08:39:26 d2.evaluation.evaluator]: [0mInference done 3518/8355. 0.1151 s / img. ETA=0:09:25
[32m[04/28 08:39:31 d2.evaluation.evaluator]: [0mInference done 3561/8355. 0.1150 s / img. ETA=0:09:19
[32m[04/28 08:39:36 d2.evaluation.evaluator]: [0mInference done 3604/8355. 0.1150 s / img. ETA=0:09:14
[32m[04/28 08:39:41 d2.evaluation.evaluator]: [0mInference done 3647/8355. 0.1151 s / img. ETA=0:09:09
[32m[04/28 08:39:46 d2.evaluation.evaluator]: [0mInference done 3690/8355. 0.1151 s / img. ETA=0:09:05
[32m[04/28 08:39:51 d2.evaluation.evaluator]: [0mInference done 3734/8355. 0.1151 s / img. ETA=0:08:59
[32m[04/28 08:39:56 d2.evaluation.evaluator]: [0mInference done 3777/8355. 0.1151 s / img. ETA=0:08:54
[32m[04/28 08:40:02 d2.evaluation.evaluator]: [0mInference done 3820/8355. 0.1151 s / img. ETA=0:08:49
[32m[04/28 08:40:07 d2.evaluation.evaluator]: [0mInference done 3863/8355. 0.1151 s / img. ETA=0:08:44
[32m[04/28 08:40:12 d2.evaluation.evaluator]: [0mInference done 3906/8355. 0.1151 s / img. ETA=0:08:39
[32m[04/28 08:40:17 d2.evaluation.evaluator]: [0mInference done 3950/8355. 0.1151 s / img. ETA=0:08:34
[32m[04/28 08:40:22 d2.evaluation.evaluator]: [0mInference done 3993/8355. 0.1151 s / img. ETA=0:08:29
[32m[04/28 08:40:27 d2.evaluation.evaluator]: [0mInference done 4036/8355. 0.1151 s / img. ETA=0:08:24
[32m[04/28 08:40:32 d2.evaluation.evaluator]: [0mInference done 4079/8355. 0.1151 s / img. ETA=0:08:19
[32m[04/28 08:40:37 d2.evaluation.evaluator]: [0mInference done 4122/8355. 0.1151 s / img. ETA=0:08:14
[32m[04/28 08:40:42 d2.evaluation.evaluator]: [0mInference done 4165/8355. 0.1151 s / img. ETA=0:08:09
[32m[04/28 08:40:47 d2.evaluation.evaluator]: [0mInference done 4208/8355. 0.1151 s / img. ETA=0:08:04
[32m[04/28 08:40:52 d2.evaluation.evaluator]: [0mInference done 4251/8355. 0.1151 s / img. ETA=0:07:59
[32m[04/28 08:40:57 d2.evaluation.evaluator]: [0mInference done 4294/8355. 0.1151 s / img. ETA=0:07:54
[32m[04/28 08:41:02 d2.evaluation.evaluator]: [0mInference done 4337/8355. 0.1151 s / img. ETA=0:07:49
[32m[04/28 08:41:07 d2.evaluation.evaluator]: [0mInference done 4381/8355. 0.1151 s / img. ETA=0:07:44
[32m[04/28 08:41:12 d2.evaluation.evaluator]: [0mInference done 4424/8355. 0.1151 s / img. ETA=0:07:39
[32m[04/28 08:41:17 d2.evaluation.evaluator]: [0mInference done 4467/8355. 0.1151 s / img. ETA=0:07:34
[32m[04/28 08:41:22 d2.evaluation.evaluator]: [0mInference done 4510/8355. 0.1151 s / img. ETA=0:07:29
[32m[04/28 08:41:27 d2.evaluation.evaluator]: [0mInference done 4553/8355. 0.1151 s / img. ETA=0:07:24
[32m[04/28 08:41:32 d2.evaluation.evaluator]: [0mInference done 4596/8355. 0.1151 s / img. ETA=0:07:19
[32m[04/28 08:41:37 d2.evaluation.evaluator]: [0mInference done 4639/8355. 0.1151 s / img. ETA=0:07:14
[32m[04/28 08:41:42 d2.evaluation.evaluator]: [0mInference done 4682/8355. 0.1151 s / img. ETA=0:07:09
[32m[04/28 08:41:47 d2.evaluation.evaluator]: [0mInference done 4725/8355. 0.1151 s / img. ETA=0:07:04
[32m[04/28 08:41:52 d2.evaluation.evaluator]: [0mInference done 4768/8355. 0.1151 s / img. ETA=0:06:59
[32m[04/28 08:41:58 d2.evaluation.evaluator]: [0mInference done 4811/8355. 0.1151 s / img. ETA=0:06:54
[32m[04/28 08:42:03 d2.evaluation.evaluator]: [0mInference done 4854/8355. 0.1151 s / img. ETA=0:06:49
[32m[04/28 08:42:08 d2.evaluation.evaluator]: [0mInference done 4898/8355. 0.1151 s / img. ETA=0:06:44
[32m[04/28 08:42:13 d2.evaluation.evaluator]: [0mInference done 4941/8355. 0.1151 s / img. ETA=0:06:39
[32m[04/28 08:42:18 d2.evaluation.evaluator]: [0mInference done 4984/8355. 0.1151 s / img. ETA=0:06:34
[32m[04/28 08:42:23 d2.evaluation.evaluator]: [0mInference done 5027/8355. 0.1151 s / img. ETA=0:06:29
[32m[04/28 08:42:28 d2.evaluation.evaluator]: [0mInference done 5070/8355. 0.1151 s / img. ETA=0:06:24
[32m[04/28 08:42:33 d2.evaluation.evaluator]: [0mInference done 5113/8355. 0.1151 s / img. ETA=0:06:18
[32m[04/28 08:42:38 d2.evaluation.evaluator]: [0mInference done 5156/8355. 0.1151 s / img. ETA=0:06:14
[32m[04/28 08:42:43 d2.evaluation.evaluator]: [0mInference done 5199/8355. 0.1151 s / img. ETA=0:06:08
[32m[04/28 08:42:48 d2.evaluation.evaluator]: [0mInference done 5242/8355. 0.1151 s / img. ETA=0:06:03
[32m[04/28 08:42:53 d2.evaluation.evaluator]: [0mInference done 5285/8355. 0.1151 s / img. ETA=0:05:58
[32m[04/28 08:42:58 d2.evaluation.evaluator]: [0mInference done 5328/8355. 0.1151 s / img. ETA=0:05:53
[32m[04/28 08:43:03 d2.evaluation.evaluator]: [0mInference done 5371/8355. 0.1151 s / img. ETA=0:05:48
[32m[04/28 08:43:08 d2.evaluation.evaluator]: [0mInference done 5414/8355. 0.1151 s / img. ETA=0:05:43
[32m[04/28 08:43:13 d2.evaluation.evaluator]: [0mInference done 5457/8355. 0.1152 s / img. ETA=0:05:38
[32m[04/28 08:43:18 d2.evaluation.evaluator]: [0mInference done 5500/8355. 0.1151 s / img. ETA=0:05:33
[32m[04/28 08:43:23 d2.evaluation.evaluator]: [0mInference done 5543/8355. 0.1151 s / img. ETA=0:05:28
[32m[04/28 08:43:28 d2.evaluation.evaluator]: [0mInference done 5586/8355. 0.1151 s / img. ETA=0:05:23
[32m[04/28 08:43:33 d2.evaluation.evaluator]: [0mInference done 5629/8355. 0.1151 s / img. ETA=0:05:18
[32m[04/28 08:43:39 d2.evaluation.evaluator]: [0mInference done 5672/8355. 0.1151 s / img. ETA=0:05:13
[32m[04/28 08:43:44 d2.evaluation.evaluator]: [0mInference done 5715/8355. 0.1152 s / img. ETA=0:05:08
[32m[04/28 08:43:49 d2.evaluation.evaluator]: [0mInference done 5758/8355. 0.1152 s / img. ETA=0:05:03
[32m[04/28 08:43:54 d2.evaluation.evaluator]: [0mInference done 5801/8355. 0.1152 s / img. ETA=0:04:58
[32m[04/28 08:43:59 d2.evaluation.evaluator]: [0mInference done 5844/8355. 0.1152 s / img. ETA=0:04:53
[32m[04/28 08:44:04 d2.evaluation.evaluator]: [0mInference done 5887/8355. 0.1152 s / img. ETA=0:04:48
[32m[04/28 08:44:09 d2.evaluation.evaluator]: [0mInference done 5930/8355. 0.1152 s / img. ETA=0:04:43
[32m[04/28 08:44:14 d2.evaluation.evaluator]: [0mInference done 5973/8355. 0.1152 s / img. ETA=0:04:38
[32m[04/28 08:44:19 d2.evaluation.evaluator]: [0mInference done 6016/8355. 0.1152 s / img. ETA=0:04:33
[32m[04/28 08:44:24 d2.evaluation.evaluator]: [0mInference done 6059/8355. 0.1152 s / img. ETA=0:04:28
[32m[04/28 08:44:29 d2.evaluation.evaluator]: [0mInference done 6102/8355. 0.1152 s / img. ETA=0:04:23
[32m[04/28 08:44:34 d2.evaluation.evaluator]: [0mInference done 6144/8355. 0.1152 s / img. ETA=0:04:18
[32m[04/28 08:44:39 d2.evaluation.evaluator]: [0mInference done 6187/8355. 0.1152 s / img. ETA=0:04:13
[32m[04/28 08:44:44 d2.evaluation.evaluator]: [0mInference done 6230/8355. 0.1152 s / img. ETA=0:04:08
[32m[04/28 08:44:49 d2.evaluation.evaluator]: [0mInference done 6273/8355. 0.1152 s / img. ETA=0:04:03
[32m[04/28 08:44:55 d2.evaluation.evaluator]: [0mInference done 6316/8355. 0.1153 s / img. ETA=0:03:58
[32m[04/28 08:45:00 d2.evaluation.evaluator]: [0mInference done 6359/8355. 0.1153 s / img. ETA=0:03:53
[32m[04/28 08:45:05 d2.evaluation.evaluator]: [0mInference done 6402/8355. 0.1153 s / img. ETA=0:03:48
[32m[04/28 08:45:10 d2.evaluation.evaluator]: [0mInference done 6445/8355. 0.1153 s / img. ETA=0:03:43
[32m[04/28 08:45:15 d2.evaluation.evaluator]: [0mInference done 6488/8355. 0.1153 s / img. ETA=0:03:38
[32m[04/28 08:45:20 d2.evaluation.evaluator]: [0mInference done 6531/8355. 0.1153 s / img. ETA=0:03:33
[32m[04/28 08:45:25 d2.evaluation.evaluator]: [0mInference done 6574/8355. 0.1153 s / img. ETA=0:03:28
[32m[04/28 08:45:30 d2.evaluation.evaluator]: [0mInference done 6617/8355. 0.1153 s / img. ETA=0:03:23
[32m[04/28 08:45:35 d2.evaluation.evaluator]: [0mInference done 6660/8355. 0.1153 s / img. ETA=0:03:18
[32m[04/28 08:45:40 d2.evaluation.evaluator]: [0mInference done 6703/8355. 0.1153 s / img. ETA=0:03:13
[32m[04/28 08:45:45 d2.evaluation.evaluator]: [0mInference done 6746/8355. 0.1153 s / img. ETA=0:03:08
[32m[04/28 08:45:50 d2.evaluation.evaluator]: [0mInference done 6789/8355. 0.1153 s / img. ETA=0:03:03
[32m[04/28 08:45:55 d2.evaluation.evaluator]: [0mInference done 6832/8355. 0.1153 s / img. ETA=0:02:58
[32m[04/28 08:46:00 d2.evaluation.evaluator]: [0mInference done 6875/8355. 0.1153 s / img. ETA=0:02:53
[32m[04/28 08:46:05 d2.evaluation.evaluator]: [0mInference done 6918/8355. 0.1153 s / img. ETA=0:02:48
[32m[04/28 08:46:10 d2.evaluation.evaluator]: [0mInference done 6961/8355. 0.1153 s / img. ETA=0:02:43
[32m[04/28 08:46:15 d2.evaluation.evaluator]: [0mInference done 7004/8355. 0.1153 s / img. ETA=0:02:38
[32m[04/28 08:46:20 d2.evaluation.evaluator]: [0mInference done 7047/8355. 0.1153 s / img. ETA=0:02:33
[32m[04/28 08:46:25 d2.evaluation.evaluator]: [0mInference done 7089/8355. 0.1153 s / img. ETA=0:02:28
[32m[04/28 08:46:30 d2.evaluation.evaluator]: [0mInference done 7132/8355. 0.1153 s / img. ETA=0:02:23
[32m[04/28 08:46:35 d2.evaluation.evaluator]: [0mInference done 7175/8355. 0.1153 s / img. ETA=0:02:18
[32m[04/28 08:46:40 d2.evaluation.evaluator]: [0mInference done 7217/8355. 0.1153 s / img. ETA=0:02:13
[32m[04/28 08:46:45 d2.evaluation.evaluator]: [0mInference done 7260/8355. 0.1153 s / img. ETA=0:02:08
[32m[04/28 08:46:51 d2.evaluation.evaluator]: [0mInference done 7303/8355. 0.1153 s / img. ETA=0:02:03
[32m[04/28 08:46:56 d2.evaluation.evaluator]: [0mInference done 7346/8355. 0.1153 s / img. ETA=0:01:58
[32m[04/28 08:47:01 d2.evaluation.evaluator]: [0mInference done 7389/8355. 0.1153 s / img. ETA=0:01:53
[32m[04/28 08:47:06 d2.evaluation.evaluator]: [0mInference done 7432/8355. 0.1153 s / img. ETA=0:01:48
[32m[04/28 08:47:11 d2.evaluation.evaluator]: [0mInference done 7474/8355. 0.1153 s / img. ETA=0:01:43
[32m[04/28 08:47:16 d2.evaluation.evaluator]: [0mInference done 7517/8355. 0.1153 s / img. ETA=0:01:38
[32m[04/28 08:47:21 d2.evaluation.evaluator]: [0mInference done 7560/8355. 0.1153 s / img. ETA=0:01:33
[32m[04/28 08:47:26 d2.evaluation.evaluator]: [0mInference done 7603/8355. 0.1153 s / img. ETA=0:01:28
[32m[04/28 08:47:31 d2.evaluation.evaluator]: [0mInference done 7646/8355. 0.1153 s / img. ETA=0:01:23
[32m[04/28 08:47:36 d2.evaluation.evaluator]: [0mInference done 7689/8355. 0.1154 s / img. ETA=0:01:18
[32m[04/28 08:47:41 d2.evaluation.evaluator]: [0mInference done 7732/8355. 0.1154 s / img. ETA=0:01:12
[32m[04/28 08:47:46 d2.evaluation.evaluator]: [0mInference done 7775/8355. 0.1154 s / img. ETA=0:01:07
[32m[04/28 08:47:51 d2.evaluation.evaluator]: [0mInference done 7818/8355. 0.1154 s / img. ETA=0:01:02
[32m[04/28 08:47:56 d2.evaluation.evaluator]: [0mInference done 7861/8355. 0.1154 s / img. ETA=0:00:57
[32m[04/28 08:48:01 d2.evaluation.evaluator]: [0mInference done 7904/8355. 0.1154 s / img. ETA=0:00:52
[32m[04/28 08:48:06 d2.evaluation.evaluator]: [0mInference done 7947/8355. 0.1154 s / img. ETA=0:00:47
[32m[04/28 08:48:12 d2.evaluation.evaluator]: [0mInference done 7990/8355. 0.1154 s / img. ETA=0:00:42
[32m[04/28 08:48:17 d2.evaluation.evaluator]: [0mInference done 8033/8355. 0.1154 s / img. ETA=0:00:37
[32m[04/28 08:48:22 d2.evaluation.evaluator]: [0mInference done 8076/8355. 0.1154 s / img. ETA=0:00:32
[32m[04/28 08:48:27 d2.evaluation.evaluator]: [0mInference done 8120/8355. 0.1154 s / img. ETA=0:00:27
[32m[04/28 08:48:32 d2.evaluation.evaluator]: [0mInference done 8163/8355. 0.1154 s / img. ETA=0:00:22
[32m[04/28 08:48:37 d2.evaluation.evaluator]: [0mInference done 8206/8355. 0.1154 s / img. ETA=0:00:17
[32m[04/28 08:48:42 d2.evaluation.evaluator]: [0mInference done 8249/8355. 0.1154 s / img. ETA=0:00:12
[32m[04/28 08:48:47 d2.evaluation.evaluator]: [0mInference done 8292/8355. 0.1154 s / img. ETA=0:00:07
[32m[04/28 08:48:52 d2.evaluation.evaluator]: [0mInference done 8335/8355. 0.1154 s / img. ETA=0:00:02
[32m[04/28 08:48:54 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:18.551754 (0.117192 s / img per device, on 1 devices)
[32m[04/28 08:48:54 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:03 (0.115374 s / img per device, on 1 devices)
[32m[04/28 08:48:55 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 08:48:55 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 08:48:55 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.43s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.89s).
Accumulating evaluation results...
DONE (t=2.20s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.820
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.423
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.352
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.559
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.679
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.169
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.504
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.520
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.435
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716
[32m[04/28 08:49:17 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.561 | 81.967 | 42.317 | 35.231 | 55.870 | 67.925 |
[32m[04/28 08:49:17 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 45.986 | bicycle       | 32.064 | car            | 55.634 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 08:49:18 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 08:49:18 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 08:49:18 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 08:49:19 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1148 s / img. ETA=0:02:25
[32m[04/28 08:49:24 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1147 s / img. ETA=0:02:20
[32m[04/28 08:49:29 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1149 s / img. ETA=0:02:15
[32m[04/28 08:49:34 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1148 s / img. ETA=0:02:10
[32m[04/28 08:49:39 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1148 s / img. ETA=0:02:05
[32m[04/28 08:49:44 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1148 s / img. ETA=0:02:00
[32m[04/28 08:49:49 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1148 s / img. ETA=0:01:55
[32m[04/28 08:49:54 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1148 s / img. ETA=0:01:50
[32m[04/28 08:49:59 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1148 s / img. ETA=0:01:45
[32m[04/28 08:50:04 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1148 s / img. ETA=0:01:40
[32m[04/28 08:50:10 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1148 s / img. ETA=0:01:35
[32m[04/28 08:50:15 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1148 s / img. ETA=0:01:30
[32m[04/28 08:50:20 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1148 s / img. ETA=0:01:25
[32m[04/28 08:50:25 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1148 s / img. ETA=0:01:20
[32m[04/28 08:50:30 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1148 s / img. ETA=0:01:15
[32m[04/28 08:50:35 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1149 s / img. ETA=0:01:10
[32m[04/28 08:50:40 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1149 s / img. ETA=0:01:05
[32m[04/28 08:50:45 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1149 s / img. ETA=0:01:00
[32m[04/28 08:50:50 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1149 s / img. ETA=0:00:55
[32m[04/28 08:50:55 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1149 s / img. ETA=0:00:50
[32m[04/28 08:51:00 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1150 s / img. ETA=0:00:45
[32m[04/28 08:51:05 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1150 s / img. ETA=0:00:40
[32m[04/28 08:51:10 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1150 s / img. ETA=0:00:35
[32m[04/28 08:51:15 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1150 s / img. ETA=0:00:30
[32m[04/28 08:51:20 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1150 s / img. ETA=0:00:25
[32m[04/28 08:51:25 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1150 s / img. ETA=0:00:19
[32m[04/28 08:51:30 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1151 s / img. ETA=0:00:14
[32m[04/28 08:51:35 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1151 s / img. ETA=0:00:09
[32m[04/28 08:51:40 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1151 s / img. ETA=0:00:04
[32m[04/28 08:51:45 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.496574 (0.117010 s / img per device, on 1 devices)
[32m[04/28 08:51:45 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115123 s / img per device, on 1 devices)
[32m[04/28 08:51:45 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 08:51:45 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 08:51:45 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.88s).
Accumulating evaluation results...
DONE (t=0.38s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.382
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.735
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.339
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.427
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.527
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.177
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.465
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.414
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.502
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.564
[32m[04/28 08:51:49 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 38.174 | 73.525 | 33.938 | 29.998 | 42.690 | 52.730 |
[32m[04/28 08:51:49 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 42.126 | bicycle       | 17.732 | car            | 54.665 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  12  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 08:51:49 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 08:51:50 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 08:51:50 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 08:51:50 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 08:51:50 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 08:51:50 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 08:51:50 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 08:52:11 d2.utils.events]: [0m eta: 0:17:10  iter: 19  total_loss: 0.510  loss_cls: 0.157  loss_box_reg: 0.285  loss_rpn_cls: 0.008  loss_rpn_loc: 0.043  time: 1.0389  data_time: 0.0203  lr: 0.000100  max_mem: 5397M
[32m[04/28 08:52:31 d2.utils.events]: [0m eta: 0:16:27  iter: 39  total_loss: 0.519  loss_cls: 0.157  loss_box_reg: 0.300  loss_rpn_cls: 0.012  loss_rpn_loc: 0.056  time: 1.0210  data_time: 0.0075  lr: 0.000200  max_mem: 5397M
[32m[04/28 08:52:52 d2.utils.events]: [0m eta: 0:16:15  iter: 59  total_loss: 0.496  loss_cls: 0.161  loss_box_reg: 0.295  loss_rpn_cls: 0.010  loss_rpn_loc: 0.036  time: 1.0236  data_time: 0.0077  lr: 0.000300  max_mem: 5397M
[32m[04/28 08:53:13 d2.utils.events]: [0m eta: 0:16:00  iter: 79  total_loss: 0.541  loss_cls: 0.178  loss_box_reg: 0.318  loss_rpn_cls: 0.009  loss_rpn_loc: 0.038  time: 1.0290  data_time: 0.0078  lr: 0.000400  max_mem: 5397M
[32m[04/28 08:53:34 d2.utils.events]: [0m eta: 0:15:46  iter: 99  total_loss: 0.546  loss_cls: 0.164  loss_box_reg: 0.309  loss_rpn_cls: 0.009  loss_rpn_loc: 0.051  time: 1.0310  data_time: 0.0076  lr: 0.000500  max_mem: 5397M
[32m[04/28 08:53:54 d2.utils.events]: [0m eta: 0:15:25  iter: 119  total_loss: 0.486  loss_cls: 0.154  loss_box_reg: 0.284  loss_rpn_cls: 0.007  loss_rpn_loc: 0.039  time: 1.0303  data_time: 0.0086  lr: 0.000599  max_mem: 5397M
[32m[04/28 08:54:15 d2.utils.events]: [0m eta: 0:15:00  iter: 139  total_loss: 0.440  loss_cls: 0.134  loss_box_reg: 0.268  loss_rpn_cls: 0.009  loss_rpn_loc: 0.040  time: 1.0283  data_time: 0.0078  lr: 0.000699  max_mem: 5397M
[32m[04/28 08:54:36 d2.utils.events]: [0m eta: 0:14:41  iter: 159  total_loss: 0.534  loss_cls: 0.169  loss_box_reg: 0.316  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0304  data_time: 0.0076  lr: 0.000799  max_mem: 5397M
[32m[04/28 08:54:56 d2.utils.events]: [0m eta: 0:14:15  iter: 179  total_loss: 0.463  loss_cls: 0.136  loss_box_reg: 0.270  loss_rpn_cls: 0.007  loss_rpn_loc: 0.040  time: 1.0271  data_time: 0.0078  lr: 0.000899  max_mem: 5397M
[32m[04/28 08:55:16 d2.utils.events]: [0m eta: 0:13:52  iter: 199  total_loss: 0.585  loss_cls: 0.183  loss_box_reg: 0.338  loss_rpn_cls: 0.009  loss_rpn_loc: 0.064  time: 1.0274  data_time: 0.0075  lr: 0.000999  max_mem: 5397M
[32m[04/28 08:55:37 d2.utils.events]: [0m eta: 0:13:34  iter: 219  total_loss: 0.613  loss_cls: 0.192  loss_box_reg: 0.351  loss_rpn_cls: 0.007  loss_rpn_loc: 0.055  time: 1.0301  data_time: 0.0078  lr: 0.001099  max_mem: 5397M
[32m[04/28 08:55:58 d2.utils.events]: [0m eta: 0:13:16  iter: 239  total_loss: 0.476  loss_cls: 0.145  loss_box_reg: 0.272  loss_rpn_cls: 0.006  loss_rpn_loc: 0.051  time: 1.0311  data_time: 0.0079  lr: 0.001199  max_mem: 5397M
[32m[04/28 08:56:19 d2.utils.events]: [0m eta: 0:12:56  iter: 259  total_loss: 0.500  loss_cls: 0.145  loss_box_reg: 0.293  loss_rpn_cls: 0.006  loss_rpn_loc: 0.050  time: 1.0315  data_time: 0.0080  lr: 0.001299  max_mem: 5397M
[32m[04/28 08:56:40 d2.utils.events]: [0m eta: 0:12:34  iter: 279  total_loss: 0.523  loss_cls: 0.156  loss_box_reg: 0.310  loss_rpn_cls: 0.005  loss_rpn_loc: 0.047  time: 1.0307  data_time: 0.0076  lr: 0.001399  max_mem: 5397M
[32m[04/28 08:57:01 d2.utils.events]: [0m eta: 0:12:14  iter: 299  total_loss: 0.572  loss_cls: 0.187  loss_box_reg: 0.323  loss_rpn_cls: 0.005  loss_rpn_loc: 0.050  time: 1.0325  data_time: 0.0078  lr: 0.001499  max_mem: 5397M
[32m[04/28 08:57:21 d2.utils.events]: [0m eta: 0:11:52  iter: 319  total_loss: 0.552  loss_cls: 0.170  loss_box_reg: 0.317  loss_rpn_cls: 0.006  loss_rpn_loc: 0.066  time: 1.0309  data_time: 0.0079  lr: 0.001598  max_mem: 5397M
[32m[04/28 08:57:42 d2.utils.events]: [0m eta: 0:11:32  iter: 339  total_loss: 0.545  loss_cls: 0.174  loss_box_reg: 0.302  loss_rpn_cls: 0.006  loss_rpn_loc: 0.050  time: 1.0326  data_time: 0.0079  lr: 0.001698  max_mem: 5397M
[32m[04/28 08:58:03 d2.utils.events]: [0m eta: 0:11:12  iter: 359  total_loss: 0.436  loss_cls: 0.137  loss_box_reg: 0.240  loss_rpn_cls: 0.006  loss_rpn_loc: 0.034  time: 1.0328  data_time: 0.0077  lr: 0.001798  max_mem: 5397M
[32m[04/28 08:58:24 d2.utils.events]: [0m eta: 0:10:51  iter: 379  total_loss: 0.520  loss_cls: 0.161  loss_box_reg: 0.310  loss_rpn_cls: 0.006  loss_rpn_loc: 0.048  time: 1.0334  data_time: 0.0078  lr: 0.001898  max_mem: 5397M
[32m[04/28 08:58:45 d2.utils.events]: [0m eta: 0:10:30  iter: 399  total_loss: 0.478  loss_cls: 0.155  loss_box_reg: 0.278  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0333  data_time: 0.0085  lr: 0.001998  max_mem: 5397M
[32m[04/28 08:59:05 d2.utils.events]: [0m eta: 0:10:09  iter: 419  total_loss: 0.500  loss_cls: 0.157  loss_box_reg: 0.297  loss_rpn_cls: 0.008  loss_rpn_loc: 0.041  time: 1.0331  data_time: 0.0079  lr: 0.002098  max_mem: 5397M
[32m[04/28 08:59:26 d2.utils.events]: [0m eta: 0:09:49  iter: 439  total_loss: 0.474  loss_cls: 0.137  loss_box_reg: 0.273  loss_rpn_cls: 0.007  loss_rpn_loc: 0.037  time: 1.0339  data_time: 0.0078  lr: 0.002198  max_mem: 5397M
[32m[04/28 08:59:47 d2.utils.events]: [0m eta: 0:09:28  iter: 459  total_loss: 0.545  loss_cls: 0.171  loss_box_reg: 0.307  loss_rpn_cls: 0.007  loss_rpn_loc: 0.042  time: 1.0347  data_time: 0.0077  lr: 0.002298  max_mem: 5397M
[32m[04/28 09:00:08 d2.utils.events]: [0m eta: 0:09:07  iter: 479  total_loss: 0.463  loss_cls: 0.153  loss_box_reg: 0.271  loss_rpn_cls: 0.004  loss_rpn_loc: 0.042  time: 1.0350  data_time: 0.0078  lr: 0.002398  max_mem: 5397M
[32m[04/28 09:00:29 d2.utils.events]: [0m eta: 0:08:46  iter: 499  total_loss: 0.495  loss_cls: 0.155  loss_box_reg: 0.284  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0347  data_time: 0.0077  lr: 0.002498  max_mem: 5397M
[32m[04/28 09:00:50 d2.utils.events]: [0m eta: 0:08:25  iter: 519  total_loss: 0.546  loss_cls: 0.184  loss_box_reg: 0.313  loss_rpn_cls: 0.005  loss_rpn_loc: 0.048  time: 1.0345  data_time: 0.0078  lr: 0.002597  max_mem: 5397M
[32m[04/28 09:01:10 d2.utils.events]: [0m eta: 0:08:03  iter: 539  total_loss: 0.540  loss_cls: 0.157  loss_box_reg: 0.317  loss_rpn_cls: 0.008  loss_rpn_loc: 0.052  time: 1.0332  data_time: 0.0078  lr: 0.002697  max_mem: 5397M
[32m[04/28 09:01:30 d2.utils.events]: [0m eta: 0:07:42  iter: 559  total_loss: 0.467  loss_cls: 0.143  loss_box_reg: 0.278  loss_rpn_cls: 0.006  loss_rpn_loc: 0.037  time: 1.0333  data_time: 0.0077  lr: 0.002797  max_mem: 5397M
[32m[04/28 09:01:50 d2.utils.events]: [0m eta: 0:07:21  iter: 579  total_loss: 0.572  loss_cls: 0.172  loss_box_reg: 0.337  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 1.0321  data_time: 0.0078  lr: 0.002897  max_mem: 5397M
[32m[04/28 09:02:11 d2.utils.events]: [0m eta: 0:06:59  iter: 599  total_loss: 0.548  loss_cls: 0.177  loss_box_reg: 0.318  loss_rpn_cls: 0.009  loss_rpn_loc: 0.054  time: 1.0316  data_time: 0.0080  lr: 0.002997  max_mem: 5397M
[32m[04/28 09:02:31 d2.utils.events]: [0m eta: 0:06:38  iter: 619  total_loss: 0.537  loss_cls: 0.162  loss_box_reg: 0.319  loss_rpn_cls: 0.009  loss_rpn_loc: 0.057  time: 1.0309  data_time: 0.0079  lr: 0.003097  max_mem: 5397M
[32m[04/28 09:02:52 d2.utils.events]: [0m eta: 0:06:17  iter: 639  total_loss: 0.580  loss_cls: 0.179  loss_box_reg: 0.317  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 1.0313  data_time: 0.0076  lr: 0.003197  max_mem: 5397M
[32m[04/28 09:03:12 d2.utils.events]: [0m eta: 0:05:56  iter: 659  total_loss: 0.523  loss_cls: 0.161  loss_box_reg: 0.295  loss_rpn_cls: 0.008  loss_rpn_loc: 0.046  time: 1.0304  data_time: 0.0081  lr: 0.003297  max_mem: 5397M
[32m[04/28 09:03:33 d2.utils.events]: [0m eta: 0:05:35  iter: 679  total_loss: 0.530  loss_cls: 0.161  loss_box_reg: 0.312  loss_rpn_cls: 0.008  loss_rpn_loc: 0.041  time: 1.0303  data_time: 0.0079  lr: 0.003397  max_mem: 5397M
[32m[04/28 09:03:53 d2.utils.events]: [0m eta: 0:05:13  iter: 699  total_loss: 0.533  loss_cls: 0.166  loss_box_reg: 0.301  loss_rpn_cls: 0.008  loss_rpn_loc: 0.049  time: 1.0293  data_time: 0.0076  lr: 0.003497  max_mem: 5397M
[32m[04/28 09:04:13 d2.utils.events]: [0m eta: 0:04:52  iter: 719  total_loss: 0.460  loss_cls: 0.137  loss_box_reg: 0.276  loss_rpn_cls: 0.009  loss_rpn_loc: 0.039  time: 1.0290  data_time: 0.0076  lr: 0.003596  max_mem: 5397M
[32m[04/28 09:04:34 d2.utils.events]: [0m eta: 0:04:31  iter: 739  total_loss: 0.508  loss_cls: 0.162  loss_box_reg: 0.285  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0289  data_time: 0.0084  lr: 0.003696  max_mem: 5397M
[32m[04/28 09:04:54 d2.utils.events]: [0m eta: 0:04:10  iter: 759  total_loss: 0.452  loss_cls: 0.150  loss_box_reg: 0.263  loss_rpn_cls: 0.007  loss_rpn_loc: 0.043  time: 1.0292  data_time: 0.0079  lr: 0.003796  max_mem: 5397M
[32m[04/28 09:05:16 d2.utils.events]: [0m eta: 0:03:51  iter: 779  total_loss: 0.530  loss_cls: 0.155  loss_box_reg: 0.312  loss_rpn_cls: 0.008  loss_rpn_loc: 0.048  time: 1.0305  data_time: 0.0079  lr: 0.003896  max_mem: 5397M
[32m[04/28 09:05:37 d2.utils.events]: [0m eta: 0:03:30  iter: 799  total_loss: 0.526  loss_cls: 0.160  loss_box_reg: 0.303  loss_rpn_cls: 0.007  loss_rpn_loc: 0.046  time: 1.0307  data_time: 0.0076  lr: 0.003996  max_mem: 5397M
[32m[04/28 09:05:58 d2.utils.events]: [0m eta: 0:03:09  iter: 819  total_loss: 0.545  loss_cls: 0.165  loss_box_reg: 0.312  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0307  data_time: 0.0077  lr: 0.004096  max_mem: 5397M
[32m[04/28 09:06:18 d2.utils.events]: [0m eta: 0:02:48  iter: 839  total_loss: 0.449  loss_cls: 0.140  loss_box_reg: 0.264  loss_rpn_cls: 0.007  loss_rpn_loc: 0.039  time: 1.0307  data_time: 0.0078  lr: 0.004196  max_mem: 5397M
[32m[04/28 09:06:39 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.545  loss_cls: 0.162  loss_box_reg: 0.307  loss_rpn_cls: 0.008  loss_rpn_loc: 0.054  time: 1.0305  data_time: 0.0076  lr: 0.004296  max_mem: 5397M
[32m[04/28 09:06:59 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.516  loss_cls: 0.155  loss_box_reg: 0.311  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0305  data_time: 0.0075  lr: 0.004396  max_mem: 5397M
[32m[04/28 09:07:20 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.559  loss_cls: 0.191  loss_box_reg: 0.308  loss_rpn_cls: 0.009  loss_rpn_loc: 0.042  time: 1.0305  data_time: 0.0076  lr: 0.004496  max_mem: 5397M
[32m[04/28 09:07:41 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.559  loss_cls: 0.175  loss_box_reg: 0.329  loss_rpn_cls: 0.012  loss_rpn_loc: 0.051  time: 1.0311  data_time: 0.0076  lr: 0.004595  max_mem: 5397M
[32m[04/28 09:08:02 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.525  loss_cls: 0.160  loss_box_reg: 0.316  loss_rpn_cls: 0.008  loss_rpn_loc: 0.048  time: 1.0313  data_time: 0.0075  lr: 0.004695  max_mem: 5397M
[32m[04/28 09:08:23 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.536  loss_cls: 0.170  loss_box_reg: 0.295  loss_rpn_cls: 0.010  loss_rpn_loc: 0.049  time: 1.0311  data_time: 0.0076  lr: 0.004795  max_mem: 5397M
[32m[04/28 09:08:43 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.555  loss_cls: 0.172  loss_box_reg: 0.314  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0312  data_time: 0.0078  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 09:09:06 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 09:09:06 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 09:09:06 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 09:09:06 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.495  loss_cls: 0.170  loss_box_reg: 0.272  loss_rpn_cls: 0.014  loss_rpn_loc: 0.042  time: 1.0311  data_time: 0.0077  lr: 0.004995  max_mem: 5397M
[32m[04/28 09:09:07 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:09 (1.0321 s / it)
[32m[04/28 09:09:07 d2.engine.hooks]: [0mTotal training time: 0:17:14 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 09:09:08 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 09:09:08 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 09:09:08 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 09:09:10 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1140 s / img. ETA=0:16:01
[32m[04/28 09:09:15 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1141 s / img. ETA=0:16:00
[32m[04/28 09:09:20 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1140 s / img. ETA=0:15:54
[32m[04/28 09:09:25 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1140 s / img. ETA=0:15:49
[32m[04/28 09:09:30 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1141 s / img. ETA=0:15:44
[32m[04/28 09:09:35 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1141 s / img. ETA=0:15:40
[32m[04/28 09:09:40 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1142 s / img. ETA=0:15:35
[32m[04/28 09:09:45 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1142 s / img. ETA=0:15:30
[32m[04/28 09:09:50 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1142 s / img. ETA=0:15:25
[32m[04/28 09:09:56 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1142 s / img. ETA=0:15:20
[32m[04/28 09:10:01 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1142 s / img. ETA=0:15:15
[32m[04/28 09:10:06 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1142 s / img. ETA=0:15:10
[32m[04/28 09:10:11 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1141 s / img. ETA=0:15:05
[32m[04/28 09:10:16 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1141 s / img. ETA=0:15:00
[32m[04/28 09:10:21 d2.evaluation.evaluator]: [0mInference done 626/8355. 0.1143 s / img. ETA=0:14:56
[32m[04/28 09:10:26 d2.evaluation.evaluator]: [0mInference done 670/8355. 0.1143 s / img. ETA=0:14:51
[32m[04/28 09:10:31 d2.evaluation.evaluator]: [0mInference done 714/8355. 0.1143 s / img. ETA=0:14:46
[32m[04/28 09:10:36 d2.evaluation.evaluator]: [0mInference done 758/8355. 0.1143 s / img. ETA=0:14:41
[32m[04/28 09:10:41 d2.evaluation.evaluator]: [0mInference done 801/8355. 0.1143 s / img. ETA=0:14:36
[32m[04/28 09:10:46 d2.evaluation.evaluator]: [0mInference done 845/8355. 0.1143 s / img. ETA=0:14:31
[32m[04/28 09:10:52 d2.evaluation.evaluator]: [0mInference done 888/8355. 0.1144 s / img. ETA=0:14:26
[32m[04/28 09:10:57 d2.evaluation.evaluator]: [0mInference done 932/8355. 0.1144 s / img. ETA=0:14:21
[32m[04/28 09:11:02 d2.evaluation.evaluator]: [0mInference done 975/8355. 0.1144 s / img. ETA=0:14:16
[32m[04/28 09:11:07 d2.evaluation.evaluator]: [0mInference done 1019/8355. 0.1144 s / img. ETA=0:14:11
[32m[04/28 09:11:12 d2.evaluation.evaluator]: [0mInference done 1062/8355. 0.1144 s / img. ETA=0:14:07
[32m[04/28 09:11:17 d2.evaluation.evaluator]: [0mInference done 1106/8355. 0.1144 s / img. ETA=0:14:01
[32m[04/28 09:11:22 d2.evaluation.evaluator]: [0mInference done 1149/8355. 0.1145 s / img. ETA=0:13:57
[32m[04/28 09:11:27 d2.evaluation.evaluator]: [0mInference done 1193/8355. 0.1145 s / img. ETA=0:13:52
[32m[04/28 09:11:32 d2.evaluation.evaluator]: [0mInference done 1236/8355. 0.1145 s / img. ETA=0:13:47
[32m[04/28 09:11:37 d2.evaluation.evaluator]: [0mInference done 1279/8355. 0.1145 s / img. ETA=0:13:42
[32m[04/28 09:11:42 d2.evaluation.evaluator]: [0mInference done 1323/8355. 0.1145 s / img. ETA=0:13:37
[32m[04/28 09:11:47 d2.evaluation.evaluator]: [0mInference done 1365/8355. 0.1147 s / img. ETA=0:13:33
[32m[04/28 09:11:52 d2.evaluation.evaluator]: [0mInference done 1409/8355. 0.1146 s / img. ETA=0:13:28
[32m[04/28 09:11:57 d2.evaluation.evaluator]: [0mInference done 1453/8355. 0.1146 s / img. ETA=0:13:22
[32m[04/28 09:12:02 d2.evaluation.evaluator]: [0mInference done 1495/8355. 0.1147 s / img. ETA=0:13:18
[32m[04/28 09:12:07 d2.evaluation.evaluator]: [0mInference done 1538/8355. 0.1147 s / img. ETA=0:13:13
[32m[04/28 09:12:13 d2.evaluation.evaluator]: [0mInference done 1581/8355. 0.1147 s / img. ETA=0:13:08
[32m[04/28 09:12:18 d2.evaluation.evaluator]: [0mInference done 1624/8355. 0.1148 s / img. ETA=0:13:03
[32m[04/28 09:12:23 d2.evaluation.evaluator]: [0mInference done 1667/8355. 0.1148 s / img. ETA=0:12:59
[32m[04/28 09:12:28 d2.evaluation.evaluator]: [0mInference done 1710/8355. 0.1148 s / img. ETA=0:12:54
[32m[04/28 09:12:33 d2.evaluation.evaluator]: [0mInference done 1753/8355. 0.1148 s / img. ETA=0:12:49
[32m[04/28 09:12:38 d2.evaluation.evaluator]: [0mInference done 1796/8355. 0.1149 s / img. ETA=0:12:44
[32m[04/28 09:12:43 d2.evaluation.evaluator]: [0mInference done 1839/8355. 0.1149 s / img. ETA=0:12:39
[32m[04/28 09:12:48 d2.evaluation.evaluator]: [0mInference done 1882/8355. 0.1149 s / img. ETA=0:12:34
[32m[04/28 09:12:53 d2.evaluation.evaluator]: [0mInference done 1925/8355. 0.1149 s / img. ETA=0:12:30
[32m[04/28 09:12:58 d2.evaluation.evaluator]: [0mInference done 1968/8355. 0.1149 s / img. ETA=0:12:25
[32m[04/28 09:13:03 d2.evaluation.evaluator]: [0mInference done 2011/8355. 0.1149 s / img. ETA=0:12:20
[32m[04/28 09:13:08 d2.evaluation.evaluator]: [0mInference done 2054/8355. 0.1149 s / img. ETA=0:12:15
[32m[04/28 09:13:13 d2.evaluation.evaluator]: [0mInference done 2097/8355. 0.1149 s / img. ETA=0:12:10
[32m[04/28 09:13:18 d2.evaluation.evaluator]: [0mInference done 2141/8355. 0.1149 s / img. ETA=0:12:04
[32m[04/28 09:13:23 d2.evaluation.evaluator]: [0mInference done 2184/8355. 0.1149 s / img. ETA=0:11:59
[32m[04/28 09:13:28 d2.evaluation.evaluator]: [0mInference done 2227/8355. 0.1149 s / img. ETA=0:11:54
[32m[04/28 09:13:33 d2.evaluation.evaluator]: [0mInference done 2270/8355. 0.1149 s / img. ETA=0:11:50
[32m[04/28 09:13:38 d2.evaluation.evaluator]: [0mInference done 2313/8355. 0.1150 s / img. ETA=0:11:45
[32m[04/28 09:13:43 d2.evaluation.evaluator]: [0mInference done 2356/8355. 0.1150 s / img. ETA=0:11:40
[32m[04/28 09:13:48 d2.evaluation.evaluator]: [0mInference done 2399/8355. 0.1150 s / img. ETA=0:11:35
[32m[04/28 09:13:53 d2.evaluation.evaluator]: [0mInference done 2442/8355. 0.1150 s / img. ETA=0:11:30
[32m[04/28 09:13:58 d2.evaluation.evaluator]: [0mInference done 2485/8355. 0.1150 s / img. ETA=0:11:25
[32m[04/28 09:14:03 d2.evaluation.evaluator]: [0mInference done 2528/8355. 0.1150 s / img. ETA=0:11:20
[32m[04/28 09:14:09 d2.evaluation.evaluator]: [0mInference done 2571/8355. 0.1150 s / img. ETA=0:11:15
[32m[04/28 09:14:14 d2.evaluation.evaluator]: [0mInference done 2614/8355. 0.1150 s / img. ETA=0:11:10
[32m[04/28 09:14:19 d2.evaluation.evaluator]: [0mInference done 2657/8355. 0.1150 s / img. ETA=0:11:05
[32m[04/28 09:14:24 d2.evaluation.evaluator]: [0mInference done 2700/8355. 0.1150 s / img. ETA=0:11:00
[32m[04/28 09:14:29 d2.evaluation.evaluator]: [0mInference done 2743/8355. 0.1150 s / img. ETA=0:10:55
[32m[04/28 09:14:34 d2.evaluation.evaluator]: [0mInference done 2786/8355. 0.1150 s / img. ETA=0:10:49
[32m[04/28 09:14:39 d2.evaluation.evaluator]: [0mInference done 2829/8355. 0.1150 s / img. ETA=0:10:44
[32m[04/28 09:14:44 d2.evaluation.evaluator]: [0mInference done 2872/8355. 0.1150 s / img. ETA=0:10:40
[32m[04/28 09:14:49 d2.evaluation.evaluator]: [0mInference done 2915/8355. 0.1150 s / img. ETA=0:10:35
[32m[04/28 09:14:54 d2.evaluation.evaluator]: [0mInference done 2958/8355. 0.1150 s / img. ETA=0:10:30
[32m[04/28 09:14:59 d2.evaluation.evaluator]: [0mInference done 3001/8355. 0.1150 s / img. ETA=0:10:25
[32m[04/28 09:15:04 d2.evaluation.evaluator]: [0mInference done 3044/8355. 0.1150 s / img. ETA=0:10:20
[32m[04/28 09:15:09 d2.evaluation.evaluator]: [0mInference done 3088/8355. 0.1150 s / img. ETA=0:10:14
[32m[04/28 09:15:14 d2.evaluation.evaluator]: [0mInference done 3131/8355. 0.1150 s / img. ETA=0:10:09
[32m[04/28 09:15:19 d2.evaluation.evaluator]: [0mInference done 3175/8355. 0.1150 s / img. ETA=0:10:04
[32m[04/28 09:15:24 d2.evaluation.evaluator]: [0mInference done 3218/8355. 0.1150 s / img. ETA=0:09:59
[32m[04/28 09:15:29 d2.evaluation.evaluator]: [0mInference done 3261/8355. 0.1150 s / img. ETA=0:09:54
[32m[04/28 09:15:34 d2.evaluation.evaluator]: [0mInference done 3305/8355. 0.1150 s / img. ETA=0:09:49
[32m[04/28 09:15:39 d2.evaluation.evaluator]: [0mInference done 3348/8355. 0.1150 s / img. ETA=0:09:44
[32m[04/28 09:15:44 d2.evaluation.evaluator]: [0mInference done 3392/8355. 0.1150 s / img. ETA=0:09:39
[32m[04/28 09:15:49 d2.evaluation.evaluator]: [0mInference done 3435/8355. 0.1150 s / img. ETA=0:09:34
[32m[04/28 09:15:54 d2.evaluation.evaluator]: [0mInference done 3479/8355. 0.1149 s / img. ETA=0:09:29
[32m[04/28 09:16:00 d2.evaluation.evaluator]: [0mInference done 3522/8355. 0.1150 s / img. ETA=0:09:24
[32m[04/28 09:16:05 d2.evaluation.evaluator]: [0mInference done 3566/8355. 0.1150 s / img. ETA=0:09:18
[32m[04/28 09:16:10 d2.evaluation.evaluator]: [0mInference done 3610/8355. 0.1149 s / img. ETA=0:09:13
[32m[04/28 09:16:15 d2.evaluation.evaluator]: [0mInference done 3653/8355. 0.1149 s / img. ETA=0:09:08
[32m[04/28 09:16:20 d2.evaluation.evaluator]: [0mInference done 3697/8355. 0.1149 s / img. ETA=0:09:03
[32m[04/28 09:16:25 d2.evaluation.evaluator]: [0mInference done 3741/8355. 0.1149 s / img. ETA=0:08:58
[32m[04/28 09:16:30 d2.evaluation.evaluator]: [0mInference done 3784/8355. 0.1149 s / img. ETA=0:08:53
[32m[04/28 09:16:35 d2.evaluation.evaluator]: [0mInference done 3827/8355. 0.1149 s / img. ETA=0:08:48
[32m[04/28 09:16:40 d2.evaluation.evaluator]: [0mInference done 3870/8355. 0.1149 s / img. ETA=0:08:43
[32m[04/28 09:16:45 d2.evaluation.evaluator]: [0mInference done 3913/8355. 0.1149 s / img. ETA=0:08:38
[32m[04/28 09:16:50 d2.evaluation.evaluator]: [0mInference done 3956/8355. 0.1149 s / img. ETA=0:08:33
[32m[04/28 09:16:55 d2.evaluation.evaluator]: [0mInference done 3999/8355. 0.1149 s / img. ETA=0:08:28
[32m[04/28 09:17:00 d2.evaluation.evaluator]: [0mInference done 4042/8355. 0.1149 s / img. ETA=0:08:23
[32m[04/28 09:17:05 d2.evaluation.evaluator]: [0mInference done 4085/8355. 0.1149 s / img. ETA=0:08:18
[32m[04/28 09:17:10 d2.evaluation.evaluator]: [0mInference done 4128/8355. 0.1149 s / img. ETA=0:08:13
[32m[04/28 09:17:15 d2.evaluation.evaluator]: [0mInference done 4172/8355. 0.1149 s / img. ETA=0:08:08
[32m[04/28 09:17:20 d2.evaluation.evaluator]: [0mInference done 4215/8355. 0.1149 s / img. ETA=0:08:03
[32m[04/28 09:17:25 d2.evaluation.evaluator]: [0mInference done 4259/8355. 0.1149 s / img. ETA=0:07:58
[32m[04/28 09:17:31 d2.evaluation.evaluator]: [0mInference done 4302/8355. 0.1149 s / img. ETA=0:07:53
[32m[04/28 09:17:36 d2.evaluation.evaluator]: [0mInference done 4345/8355. 0.1149 s / img. ETA=0:07:47
[32m[04/28 09:17:41 d2.evaluation.evaluator]: [0mInference done 4388/8355. 0.1149 s / img. ETA=0:07:43
[32m[04/28 09:17:46 d2.evaluation.evaluator]: [0mInference done 4431/8355. 0.1149 s / img. ETA=0:07:37
[32m[04/28 09:17:51 d2.evaluation.evaluator]: [0mInference done 4474/8355. 0.1149 s / img. ETA=0:07:32
[32m[04/28 09:17:56 d2.evaluation.evaluator]: [0mInference done 4517/8355. 0.1149 s / img. ETA=0:07:27
[32m[04/28 09:18:01 d2.evaluation.evaluator]: [0mInference done 4560/8355. 0.1149 s / img. ETA=0:07:22
[32m[04/28 09:18:06 d2.evaluation.evaluator]: [0mInference done 4603/8355. 0.1149 s / img. ETA=0:07:17
[32m[04/28 09:18:11 d2.evaluation.evaluator]: [0mInference done 4646/8355. 0.1149 s / img. ETA=0:07:12
[32m[04/28 09:18:16 d2.evaluation.evaluator]: [0mInference done 4689/8355. 0.1149 s / img. ETA=0:07:07
[32m[04/28 09:18:21 d2.evaluation.evaluator]: [0mInference done 4733/8355. 0.1149 s / img. ETA=0:07:02
[32m[04/28 09:18:26 d2.evaluation.evaluator]: [0mInference done 4776/8355. 0.1149 s / img. ETA=0:06:57
[32m[04/28 09:18:31 d2.evaluation.evaluator]: [0mInference done 4819/8355. 0.1149 s / img. ETA=0:06:52
[32m[04/28 09:18:36 d2.evaluation.evaluator]: [0mInference done 4862/8355. 0.1149 s / img. ETA=0:06:47
[32m[04/28 09:18:41 d2.evaluation.evaluator]: [0mInference done 4905/8355. 0.1149 s / img. ETA=0:06:42
[32m[04/28 09:18:46 d2.evaluation.evaluator]: [0mInference done 4948/8355. 0.1149 s / img. ETA=0:06:37
[32m[04/28 09:18:51 d2.evaluation.evaluator]: [0mInference done 4991/8355. 0.1149 s / img. ETA=0:06:32
[32m[04/28 09:18:56 d2.evaluation.evaluator]: [0mInference done 5034/8355. 0.1149 s / img. ETA=0:06:27
[32m[04/28 09:19:01 d2.evaluation.evaluator]: [0mInference done 5077/8355. 0.1150 s / img. ETA=0:06:22
[32m[04/28 09:19:06 d2.evaluation.evaluator]: [0mInference done 5120/8355. 0.1150 s / img. ETA=0:06:17
[32m[04/28 09:19:11 d2.evaluation.evaluator]: [0mInference done 5163/8355. 0.1150 s / img. ETA=0:06:12
[32m[04/28 09:19:16 d2.evaluation.evaluator]: [0mInference done 5206/8355. 0.1150 s / img. ETA=0:06:07
[32m[04/28 09:19:21 d2.evaluation.evaluator]: [0mInference done 5249/8355. 0.1150 s / img. ETA=0:06:02
[32m[04/28 09:19:26 d2.evaluation.evaluator]: [0mInference done 5292/8355. 0.1150 s / img. ETA=0:05:57
[32m[04/28 09:19:31 d2.evaluation.evaluator]: [0mInference done 5335/8355. 0.1150 s / img. ETA=0:05:52
[32m[04/28 09:19:36 d2.evaluation.evaluator]: [0mInference done 5378/8355. 0.1150 s / img. ETA=0:05:47
[32m[04/28 09:19:41 d2.evaluation.evaluator]: [0mInference done 5421/8355. 0.1150 s / img. ETA=0:05:42
[32m[04/28 09:19:46 d2.evaluation.evaluator]: [0mInference done 5464/8355. 0.1150 s / img. ETA=0:05:37
[32m[04/28 09:19:51 d2.evaluation.evaluator]: [0mInference done 5507/8355. 0.1150 s / img. ETA=0:05:32
[32m[04/28 09:19:56 d2.evaluation.evaluator]: [0mInference done 5550/8355. 0.1150 s / img. ETA=0:05:27
[32m[04/28 09:20:02 d2.evaluation.evaluator]: [0mInference done 5594/8355. 0.1150 s / img. ETA=0:05:22
[32m[04/28 09:20:07 d2.evaluation.evaluator]: [0mInference done 5637/8355. 0.1150 s / img. ETA=0:05:17
[32m[04/28 09:20:12 d2.evaluation.evaluator]: [0mInference done 5680/8355. 0.1150 s / img. ETA=0:05:12
[32m[04/28 09:20:17 d2.evaluation.evaluator]: [0mInference done 5723/8355. 0.1150 s / img. ETA=0:05:07
[32m[04/28 09:20:22 d2.evaluation.evaluator]: [0mInference done 5766/8355. 0.1150 s / img. ETA=0:05:02
[32m[04/28 09:20:27 d2.evaluation.evaluator]: [0mInference done 5809/8355. 0.1150 s / img. ETA=0:04:57
[32m[04/28 09:20:32 d2.evaluation.evaluator]: [0mInference done 5851/8355. 0.1150 s / img. ETA=0:04:52
[32m[04/28 09:20:37 d2.evaluation.evaluator]: [0mInference done 5894/8355. 0.1150 s / img. ETA=0:04:47
[32m[04/28 09:20:42 d2.evaluation.evaluator]: [0mInference done 5937/8355. 0.1150 s / img. ETA=0:04:42
[32m[04/28 09:20:47 d2.evaluation.evaluator]: [0mInference done 5980/8355. 0.1150 s / img. ETA=0:04:37
[32m[04/28 09:20:52 d2.evaluation.evaluator]: [0mInference done 6023/8355. 0.1150 s / img. ETA=0:04:32
[32m[04/28 09:20:57 d2.evaluation.evaluator]: [0mInference done 6066/8355. 0.1150 s / img. ETA=0:04:27
[32m[04/28 09:21:02 d2.evaluation.evaluator]: [0mInference done 6109/8355. 0.1150 s / img. ETA=0:04:22
[32m[04/28 09:21:07 d2.evaluation.evaluator]: [0mInference done 6152/8355. 0.1151 s / img. ETA=0:04:17
[32m[04/28 09:21:12 d2.evaluation.evaluator]: [0mInference done 6195/8355. 0.1151 s / img. ETA=0:04:12
[32m[04/28 09:21:17 d2.evaluation.evaluator]: [0mInference done 6238/8355. 0.1151 s / img. ETA=0:04:07
[32m[04/28 09:21:23 d2.evaluation.evaluator]: [0mInference done 6281/8355. 0.1151 s / img. ETA=0:04:02
[32m[04/28 09:21:28 d2.evaluation.evaluator]: [0mInference done 6324/8355. 0.1151 s / img. ETA=0:03:57
[32m[04/28 09:21:33 d2.evaluation.evaluator]: [0mInference done 6367/8355. 0.1151 s / img. ETA=0:03:52
[32m[04/28 09:21:38 d2.evaluation.evaluator]: [0mInference done 6410/8355. 0.1151 s / img. ETA=0:03:47
[32m[04/28 09:21:43 d2.evaluation.evaluator]: [0mInference done 6453/8355. 0.1151 s / img. ETA=0:03:42
[32m[04/28 09:21:48 d2.evaluation.evaluator]: [0mInference done 6497/8355. 0.1151 s / img. ETA=0:03:37
[32m[04/28 09:21:53 d2.evaluation.evaluator]: [0mInference done 6540/8355. 0.1151 s / img. ETA=0:03:32
[32m[04/28 09:21:58 d2.evaluation.evaluator]: [0mInference done 6583/8355. 0.1151 s / img. ETA=0:03:27
[32m[04/28 09:22:03 d2.evaluation.evaluator]: [0mInference done 6626/8355. 0.1151 s / img. ETA=0:03:22
[32m[04/28 09:22:08 d2.evaluation.evaluator]: [0mInference done 6669/8355. 0.1151 s / img. ETA=0:03:17
[32m[04/28 09:22:13 d2.evaluation.evaluator]: [0mInference done 6713/8355. 0.1151 s / img. ETA=0:03:11
[32m[04/28 09:22:18 d2.evaluation.evaluator]: [0mInference done 6756/8355. 0.1151 s / img. ETA=0:03:06
[32m[04/28 09:22:23 d2.evaluation.evaluator]: [0mInference done 6799/8355. 0.1151 s / img. ETA=0:03:01
[32m[04/28 09:22:28 d2.evaluation.evaluator]: [0mInference done 6842/8355. 0.1151 s / img. ETA=0:02:56
[32m[04/28 09:22:33 d2.evaluation.evaluator]: [0mInference done 6885/8355. 0.1151 s / img. ETA=0:02:51
[32m[04/28 09:22:38 d2.evaluation.evaluator]: [0mInference done 6928/8355. 0.1151 s / img. ETA=0:02:46
[32m[04/28 09:22:43 d2.evaluation.evaluator]: [0mInference done 6971/8355. 0.1151 s / img. ETA=0:02:41
[32m[04/28 09:22:48 d2.evaluation.evaluator]: [0mInference done 7014/8355. 0.1151 s / img. ETA=0:02:36
[32m[04/28 09:22:53 d2.evaluation.evaluator]: [0mInference done 7057/8355. 0.1151 s / img. ETA=0:02:31
[32m[04/28 09:22:58 d2.evaluation.evaluator]: [0mInference done 7100/8355. 0.1151 s / img. ETA=0:02:26
[32m[04/28 09:23:04 d2.evaluation.evaluator]: [0mInference done 7143/8355. 0.1151 s / img. ETA=0:02:21
[32m[04/28 09:23:09 d2.evaluation.evaluator]: [0mInference done 7186/8355. 0.1151 s / img. ETA=0:02:16
[32m[04/28 09:23:14 d2.evaluation.evaluator]: [0mInference done 7229/8355. 0.1151 s / img. ETA=0:02:11
[32m[04/28 09:23:19 d2.evaluation.evaluator]: [0mInference done 7272/8355. 0.1151 s / img. ETA=0:02:06
[32m[04/28 09:23:24 d2.evaluation.evaluator]: [0mInference done 7315/8355. 0.1151 s / img. ETA=0:02:01
[32m[04/28 09:23:29 d2.evaluation.evaluator]: [0mInference done 7358/8355. 0.1151 s / img. ETA=0:01:56
[32m[04/28 09:23:34 d2.evaluation.evaluator]: [0mInference done 7401/8355. 0.1151 s / img. ETA=0:01:51
[32m[04/28 09:23:39 d2.evaluation.evaluator]: [0mInference done 7444/8355. 0.1152 s / img. ETA=0:01:46
[32m[04/28 09:23:44 d2.evaluation.evaluator]: [0mInference done 7487/8355. 0.1152 s / img. ETA=0:01:41
[32m[04/28 09:23:49 d2.evaluation.evaluator]: [0mInference done 7530/8355. 0.1152 s / img. ETA=0:01:36
[32m[04/28 09:23:54 d2.evaluation.evaluator]: [0mInference done 7573/8355. 0.1152 s / img. ETA=0:01:31
[32m[04/28 09:23:59 d2.evaluation.evaluator]: [0mInference done 7616/8355. 0.1152 s / img. ETA=0:01:26
[32m[04/28 09:24:04 d2.evaluation.evaluator]: [0mInference done 7659/8355. 0.1152 s / img. ETA=0:01:21
[32m[04/28 09:24:09 d2.evaluation.evaluator]: [0mInference done 7702/8355. 0.1152 s / img. ETA=0:01:16
[32m[04/28 09:24:15 d2.evaluation.evaluator]: [0mInference done 7745/8355. 0.1152 s / img. ETA=0:01:11
[32m[04/28 09:24:20 d2.evaluation.evaluator]: [0mInference done 7788/8355. 0.1152 s / img. ETA=0:01:06
[32m[04/28 09:24:25 d2.evaluation.evaluator]: [0mInference done 7831/8355. 0.1152 s / img. ETA=0:01:01
[32m[04/28 09:24:30 d2.evaluation.evaluator]: [0mInference done 7874/8355. 0.1152 s / img. ETA=0:00:56
[32m[04/28 09:24:35 d2.evaluation.evaluator]: [0mInference done 7917/8355. 0.1152 s / img. ETA=0:00:51
[32m[04/28 09:24:40 d2.evaluation.evaluator]: [0mInference done 7960/8355. 0.1152 s / img. ETA=0:00:46
[32m[04/28 09:24:45 d2.evaluation.evaluator]: [0mInference done 8003/8355. 0.1152 s / img. ETA=0:00:41
[32m[04/28 09:24:50 d2.evaluation.evaluator]: [0mInference done 8047/8355. 0.1152 s / img. ETA=0:00:36
[32m[04/28 09:24:55 d2.evaluation.evaluator]: [0mInference done 8090/8355. 0.1152 s / img. ETA=0:00:31
[32m[04/28 09:25:00 d2.evaluation.evaluator]: [0mInference done 8133/8355. 0.1152 s / img. ETA=0:00:25
[32m[04/28 09:25:05 d2.evaluation.evaluator]: [0mInference done 8176/8355. 0.1152 s / img. ETA=0:00:20
[32m[04/28 09:25:10 d2.evaluation.evaluator]: [0mInference done 8219/8355. 0.1152 s / img. ETA=0:00:15
[32m[04/28 09:25:15 d2.evaluation.evaluator]: [0mInference done 8262/8355. 0.1152 s / img. ETA=0:00:10
[32m[04/28 09:25:20 d2.evaluation.evaluator]: [0mInference done 8305/8355. 0.1152 s / img. ETA=0:00:05
[32m[04/28 09:25:25 d2.evaluation.evaluator]: [0mInference done 8348/8355. 0.1152 s / img. ETA=0:00:00
[32m[04/28 09:25:26 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:17.106802 (0.117019 s / img per device, on 1 devices)
[32m[04/28 09:25:26 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:01 (0.115198 s / img per device, on 1 devices)
[32m[04/28 09:25:26 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 09:25:26 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 09:25:27 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.67s).
Accumulating evaluation results...
DONE (t=2.17s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.831
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.473
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.364
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.608
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.735
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.521
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.537
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.442
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.668
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.781
[32m[04/28 09:25:49 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.222 | 83.107 | 47.254 | 36.368 | 60.756 | 73.517 |
[32m[04/28 09:25:49 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 46.182 | bicycle       | 39.843 | car            | 55.641 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 09:25:49 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 09:25:49 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 09:25:49 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 09:25:51 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1146 s / img. ETA=0:02:24
[32m[04/28 09:25:56 d2.evaluation.evaluator]: [0mInference done 55/1257. 0.1144 s / img. ETA=0:02:19
[32m[04/28 09:26:01 d2.evaluation.evaluator]: [0mInference done 98/1257. 0.1146 s / img. ETA=0:02:14
[32m[04/28 09:26:06 d2.evaluation.evaluator]: [0mInference done 141/1257. 0.1146 s / img. ETA=0:02:09
[32m[04/28 09:26:11 d2.evaluation.evaluator]: [0mInference done 184/1257. 0.1147 s / img. ETA=0:02:05
[32m[04/28 09:26:16 d2.evaluation.evaluator]: [0mInference done 228/1257. 0.1146 s / img. ETA=0:01:59
[32m[04/28 09:26:21 d2.evaluation.evaluator]: [0mInference done 271/1257. 0.1147 s / img. ETA=0:01:54
[32m[04/28 09:26:26 d2.evaluation.evaluator]: [0mInference done 314/1257. 0.1147 s / img. ETA=0:01:49
[32m[04/28 09:26:31 d2.evaluation.evaluator]: [0mInference done 357/1257. 0.1147 s / img. ETA=0:01:44
[32m[04/28 09:26:36 d2.evaluation.evaluator]: [0mInference done 400/1257. 0.1147 s / img. ETA=0:01:39
[32m[04/28 09:26:41 d2.evaluation.evaluator]: [0mInference done 443/1257. 0.1146 s / img. ETA=0:01:34
[32m[04/28 09:26:46 d2.evaluation.evaluator]: [0mInference done 487/1257. 0.1146 s / img. ETA=0:01:29
[32m[04/28 09:26:51 d2.evaluation.evaluator]: [0mInference done 530/1257. 0.1147 s / img. ETA=0:01:24
[32m[04/28 09:26:56 d2.evaluation.evaluator]: [0mInference done 573/1257. 0.1147 s / img. ETA=0:01:19
[32m[04/28 09:27:01 d2.evaluation.evaluator]: [0mInference done 616/1257. 0.1147 s / img. ETA=0:01:14
[32m[04/28 09:27:06 d2.evaluation.evaluator]: [0mInference done 659/1257. 0.1147 s / img. ETA=0:01:09
[32m[04/28 09:27:11 d2.evaluation.evaluator]: [0mInference done 702/1257. 0.1147 s / img. ETA=0:01:04
[32m[04/28 09:27:16 d2.evaluation.evaluator]: [0mInference done 745/1257. 0.1147 s / img. ETA=0:00:59
[32m[04/28 09:27:21 d2.evaluation.evaluator]: [0mInference done 789/1257. 0.1147 s / img. ETA=0:00:54
[32m[04/28 09:27:26 d2.evaluation.evaluator]: [0mInference done 832/1257. 0.1147 s / img. ETA=0:00:49
[32m[04/28 09:27:31 d2.evaluation.evaluator]: [0mInference done 875/1257. 0.1148 s / img. ETA=0:00:44
[32m[04/28 09:27:36 d2.evaluation.evaluator]: [0mInference done 918/1257. 0.1148 s / img. ETA=0:00:39
[32m[04/28 09:27:41 d2.evaluation.evaluator]: [0mInference done 961/1257. 0.1148 s / img. ETA=0:00:34
[32m[04/28 09:27:47 d2.evaluation.evaluator]: [0mInference done 1004/1257. 0.1148 s / img. ETA=0:00:29
[32m[04/28 09:27:52 d2.evaluation.evaluator]: [0mInference done 1047/1257. 0.1149 s / img. ETA=0:00:24
[32m[04/28 09:27:57 d2.evaluation.evaluator]: [0mInference done 1090/1257. 0.1149 s / img. ETA=0:00:19
[32m[04/28 09:28:02 d2.evaluation.evaluator]: [0mInference done 1133/1257. 0.1149 s / img. ETA=0:00:14
[32m[04/28 09:28:07 d2.evaluation.evaluator]: [0mInference done 1176/1257. 0.1149 s / img. ETA=0:00:09
[32m[04/28 09:28:12 d2.evaluation.evaluator]: [0mInference done 1219/1257. 0.1150 s / img. ETA=0:00:04
[32m[04/28 09:28:16 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.269998 (0.116829 s / img per device, on 1 devices)
[32m[04/28 09:28:16 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:23 (0.114950 s / img per device, on 1 devices)
[32m[04/28 09:28:16 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 09:28:16 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 09:28:16 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.30s).
Accumulating evaluation results...
DONE (t=0.37s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.395
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.770
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.348
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.466
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.559
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.476
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.392
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.599
[32m[04/28 09:28:20 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.496 | 76.960 | 34.811 | 28.255 | 46.629 | 55.943 |
[32m[04/28 09:28:20 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 42.543 | bicycle       | 22.904 | car            | 53.040 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  13  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 09:28:21 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 09:28:21 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 09:28:21 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 09:28:21 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 09:28:22 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 09:28:22 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 09:28:22 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 09:28:42 d2.utils.events]: [0m eta: 0:16:43  iter: 19  total_loss: 0.496  loss_cls: 0.152  loss_box_reg: 0.292  loss_rpn_cls: 0.008  loss_rpn_loc: 0.043  time: 1.0176  data_time: 0.0233  lr: 0.000100  max_mem: 5397M
[32m[04/28 09:29:03 d2.utils.events]: [0m eta: 0:16:31  iter: 39  total_loss: 0.534  loss_cls: 0.170  loss_box_reg: 0.321  loss_rpn_cls: 0.008  loss_rpn_loc: 0.051  time: 1.0225  data_time: 0.0077  lr: 0.000200  max_mem: 5397M
[32m[04/28 09:29:23 d2.utils.events]: [0m eta: 0:16:03  iter: 59  total_loss: 0.460  loss_cls: 0.132  loss_box_reg: 0.267  loss_rpn_cls: 0.006  loss_rpn_loc: 0.044  time: 1.0166  data_time: 0.0077  lr: 0.000300  max_mem: 5397M
[32m[04/28 09:29:43 d2.utils.events]: [0m eta: 0:15:39  iter: 79  total_loss: 0.536  loss_cls: 0.168  loss_box_reg: 0.305  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0140  data_time: 0.0078  lr: 0.000400  max_mem: 5397M
[32m[04/28 09:30:04 d2.utils.events]: [0m eta: 0:15:20  iter: 99  total_loss: 0.489  loss_cls: 0.157  loss_box_reg: 0.283  loss_rpn_cls: 0.009  loss_rpn_loc: 0.041  time: 1.0190  data_time: 0.0078  lr: 0.000500  max_mem: 5397M
[32m[04/28 09:30:25 d2.utils.events]: [0m eta: 0:15:04  iter: 119  total_loss: 0.542  loss_cls: 0.163  loss_box_reg: 0.314  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 1.0224  data_time: 0.0078  lr: 0.000599  max_mem: 5397M
[32m[04/28 09:30:45 d2.utils.events]: [0m eta: 0:14:39  iter: 139  total_loss: 0.523  loss_cls: 0.163  loss_box_reg: 0.313  loss_rpn_cls: 0.007  loss_rpn_loc: 0.063  time: 1.0208  data_time: 0.0077  lr: 0.000699  max_mem: 5397M
[32m[04/28 09:31:05 d2.utils.events]: [0m eta: 0:14:17  iter: 159  total_loss: 0.475  loss_cls: 0.138  loss_box_reg: 0.282  loss_rpn_cls: 0.008  loss_rpn_loc: 0.037  time: 1.0193  data_time: 0.0075  lr: 0.000799  max_mem: 5397M
[32m[04/28 09:31:26 d2.utils.events]: [0m eta: 0:13:58  iter: 179  total_loss: 0.456  loss_cls: 0.135  loss_box_reg: 0.261  loss_rpn_cls: 0.008  loss_rpn_loc: 0.035  time: 1.0194  data_time: 0.0077  lr: 0.000899  max_mem: 5397M
[32m[04/28 09:31:47 d2.utils.events]: [0m eta: 0:13:40  iter: 199  total_loss: 0.538  loss_cls: 0.165  loss_box_reg: 0.310  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0210  data_time: 0.0077  lr: 0.000999  max_mem: 5397M
[32m[04/28 09:32:07 d2.utils.events]: [0m eta: 0:13:22  iter: 219  total_loss: 0.539  loss_cls: 0.169  loss_box_reg: 0.318  loss_rpn_cls: 0.007  loss_rpn_loc: 0.042  time: 1.0228  data_time: 0.0077  lr: 0.001099  max_mem: 5397M
[32m[04/28 09:32:28 d2.utils.events]: [0m eta: 0:13:02  iter: 239  total_loss: 0.511  loss_cls: 0.151  loss_box_reg: 0.281  loss_rpn_cls: 0.009  loss_rpn_loc: 0.039  time: 1.0234  data_time: 0.0077  lr: 0.001199  max_mem: 5397M
[32m[04/28 09:32:49 d2.utils.events]: [0m eta: 0:12:46  iter: 259  total_loss: 0.549  loss_cls: 0.173  loss_box_reg: 0.335  loss_rpn_cls: 0.011  loss_rpn_loc: 0.054  time: 1.0251  data_time: 0.0077  lr: 0.001299  max_mem: 5397M
[32m[04/28 09:33:10 d2.utils.events]: [0m eta: 0:12:25  iter: 279  total_loss: 0.581  loss_cls: 0.175  loss_box_reg: 0.326  loss_rpn_cls: 0.010  loss_rpn_loc: 0.051  time: 1.0245  data_time: 0.0079  lr: 0.001399  max_mem: 5397M
[32m[04/28 09:33:30 d2.utils.events]: [0m eta: 0:12:05  iter: 299  total_loss: 0.467  loss_cls: 0.145  loss_box_reg: 0.281  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0252  data_time: 0.0079  lr: 0.001499  max_mem: 5397M
[32m[04/28 09:33:51 d2.utils.events]: [0m eta: 0:11:45  iter: 319  total_loss: 0.503  loss_cls: 0.156  loss_box_reg: 0.290  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0255  data_time: 0.0078  lr: 0.001598  max_mem: 5397M
[32m[04/28 09:34:11 d2.utils.events]: [0m eta: 0:11:23  iter: 339  total_loss: 0.486  loss_cls: 0.145  loss_box_reg: 0.296  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0253  data_time: 0.0078  lr: 0.001698  max_mem: 5397M
[32m[04/28 09:34:31 d2.utils.events]: [0m eta: 0:11:00  iter: 359  total_loss: 0.526  loss_cls: 0.162  loss_box_reg: 0.301  loss_rpn_cls: 0.008  loss_rpn_loc: 0.042  time: 1.0236  data_time: 0.0083  lr: 0.001798  max_mem: 5397M
[32m[04/28 09:34:52 d2.utils.events]: [0m eta: 0:10:39  iter: 379  total_loss: 0.518  loss_cls: 0.148  loss_box_reg: 0.297  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0238  data_time: 0.0078  lr: 0.001898  max_mem: 5397M
[32m[04/28 09:35:12 d2.utils.events]: [0m eta: 0:10:18  iter: 399  total_loss: 0.421  loss_cls: 0.131  loss_box_reg: 0.267  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0236  data_time: 0.0078  lr: 0.001998  max_mem: 5397M
[32m[04/28 09:35:33 d2.utils.events]: [0m eta: 0:09:58  iter: 419  total_loss: 0.560  loss_cls: 0.164  loss_box_reg: 0.327  loss_rpn_cls: 0.007  loss_rpn_loc: 0.040  time: 1.0239  data_time: 0.0079  lr: 0.002098  max_mem: 5397M
[32m[04/28 09:35:53 d2.utils.events]: [0m eta: 0:09:36  iter: 439  total_loss: 0.533  loss_cls: 0.164  loss_box_reg: 0.311  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0229  data_time: 0.0076  lr: 0.002198  max_mem: 5397M
[32m[04/28 09:36:14 d2.utils.events]: [0m eta: 0:09:16  iter: 459  total_loss: 0.493  loss_cls: 0.153  loss_box_reg: 0.278  loss_rpn_cls: 0.008  loss_rpn_loc: 0.045  time: 1.0231  data_time: 0.0077  lr: 0.002298  max_mem: 5397M
[32m[04/28 09:36:35 d2.utils.events]: [0m eta: 0:08:58  iter: 479  total_loss: 0.533  loss_cls: 0.170  loss_box_reg: 0.306  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0246  data_time: 0.0078  lr: 0.002398  max_mem: 5397M
[32m[04/28 09:36:56 d2.utils.events]: [0m eta: 0:08:38  iter: 499  total_loss: 0.509  loss_cls: 0.160  loss_box_reg: 0.304  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0254  data_time: 0.0079  lr: 0.002498  max_mem: 5397M
[32m[04/28 09:37:17 d2.utils.events]: [0m eta: 0:08:19  iter: 519  total_loss: 0.510  loss_cls: 0.164  loss_box_reg: 0.293  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 1.0262  data_time: 0.0076  lr: 0.002597  max_mem: 5397M
[32m[04/28 09:37:37 d2.utils.events]: [0m eta: 0:07:58  iter: 539  total_loss: 0.488  loss_cls: 0.149  loss_box_reg: 0.286  loss_rpn_cls: 0.007  loss_rpn_loc: 0.039  time: 1.0262  data_time: 0.0077  lr: 0.002697  max_mem: 5397M
[32m[04/28 09:37:58 d2.utils.events]: [0m eta: 0:07:38  iter: 559  total_loss: 0.467  loss_cls: 0.149  loss_box_reg: 0.269  loss_rpn_cls: 0.005  loss_rpn_loc: 0.039  time: 1.0271  data_time: 0.0076  lr: 0.002797  max_mem: 5397M
[32m[04/28 09:38:19 d2.utils.events]: [0m eta: 0:07:18  iter: 579  total_loss: 0.483  loss_cls: 0.154  loss_box_reg: 0.277  loss_rpn_cls: 0.008  loss_rpn_loc: 0.045  time: 1.0273  data_time: 0.0076  lr: 0.002897  max_mem: 5397M
[32m[04/28 09:38:40 d2.utils.events]: [0m eta: 0:06:57  iter: 599  total_loss: 0.534  loss_cls: 0.161  loss_box_reg: 0.312  loss_rpn_cls: 0.006  loss_rpn_loc: 0.037  time: 1.0277  data_time: 0.0078  lr: 0.002997  max_mem: 5397M
[32m[04/28 09:39:00 d2.utils.events]: [0m eta: 0:06:36  iter: 619  total_loss: 0.512  loss_cls: 0.159  loss_box_reg: 0.295  loss_rpn_cls: 0.005  loss_rpn_loc: 0.045  time: 1.0274  data_time: 0.0076  lr: 0.003097  max_mem: 5397M
[32m[04/28 09:39:22 d2.utils.events]: [0m eta: 0:06:15  iter: 639  total_loss: 0.569  loss_cls: 0.163  loss_box_reg: 0.326  loss_rpn_cls: 0.009  loss_rpn_loc: 0.046  time: 1.0281  data_time: 0.0077  lr: 0.003197  max_mem: 5397M
[32m[04/28 09:39:42 d2.utils.events]: [0m eta: 0:05:55  iter: 659  total_loss: 0.508  loss_cls: 0.164  loss_box_reg: 0.293  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0282  data_time: 0.0077  lr: 0.003297  max_mem: 5397M
[32m[04/28 09:40:03 d2.utils.events]: [0m eta: 0:05:34  iter: 679  total_loss: 0.565  loss_cls: 0.179  loss_box_reg: 0.304  loss_rpn_cls: 0.007  loss_rpn_loc: 0.052  time: 1.0279  data_time: 0.0077  lr: 0.003397  max_mem: 5397M
[32m[04/28 09:40:23 d2.utils.events]: [0m eta: 0:05:12  iter: 699  total_loss: 0.577  loss_cls: 0.171  loss_box_reg: 0.323  loss_rpn_cls: 0.008  loss_rpn_loc: 0.053  time: 1.0270  data_time: 0.0075  lr: 0.003497  max_mem: 5397M
[32m[04/28 09:40:43 d2.utils.events]: [0m eta: 0:04:51  iter: 719  total_loss: 0.549  loss_cls: 0.165  loss_box_reg: 0.305  loss_rpn_cls: 0.009  loss_rpn_loc: 0.059  time: 1.0265  data_time: 0.0076  lr: 0.003596  max_mem: 5397M
[32m[04/28 09:41:03 d2.utils.events]: [0m eta: 0:04:30  iter: 739  total_loss: 0.476  loss_cls: 0.150  loss_box_reg: 0.281  loss_rpn_cls: 0.007  loss_rpn_loc: 0.045  time: 1.0266  data_time: 0.0076  lr: 0.003696  max_mem: 5397M
[32m[04/28 09:41:24 d2.utils.events]: [0m eta: 0:04:10  iter: 759  total_loss: 0.531  loss_cls: 0.147  loss_box_reg: 0.301  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0271  data_time: 0.0079  lr: 0.003796  max_mem: 5397M
[32m[04/28 09:41:45 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.527  loss_cls: 0.162  loss_box_reg: 0.309  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0269  data_time: 0.0076  lr: 0.003896  max_mem: 5397M
[32m[04/28 09:42:05 d2.utils.events]: [0m eta: 0:03:28  iter: 799  total_loss: 0.590  loss_cls: 0.184  loss_box_reg: 0.337  loss_rpn_cls: 0.007  loss_rpn_loc: 0.057  time: 1.0269  data_time: 0.0075  lr: 0.003996  max_mem: 5397M
[32m[04/28 09:42:26 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.563  loss_cls: 0.162  loss_box_reg: 0.313  loss_rpn_cls: 0.005  loss_rpn_loc: 0.051  time: 1.0266  data_time: 0.0077  lr: 0.004096  max_mem: 5397M
[32m[04/28 09:42:47 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.513  loss_cls: 0.155  loss_box_reg: 0.300  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0272  data_time: 0.0078  lr: 0.004196  max_mem: 5397M
[32m[04/28 09:43:07 d2.utils.events]: [0m eta: 0:02:26  iter: 859  total_loss: 0.559  loss_cls: 0.169  loss_box_reg: 0.329  loss_rpn_cls: 0.010  loss_rpn_loc: 0.057  time: 1.0269  data_time: 0.0075  lr: 0.004296  max_mem: 5397M
[32m[04/28 09:43:28 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.480  loss_cls: 0.146  loss_box_reg: 0.283  loss_rpn_cls: 0.007  loss_rpn_loc: 0.043  time: 1.0272  data_time: 0.0076  lr: 0.004396  max_mem: 5397M
[32m[04/28 09:43:48 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.605  loss_cls: 0.185  loss_box_reg: 0.346  loss_rpn_cls: 0.006  loss_rpn_loc: 0.055  time: 1.0269  data_time: 0.0075  lr: 0.004496  max_mem: 5397M
[32m[04/28 09:44:09 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.546  loss_cls: 0.168  loss_box_reg: 0.296  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 1.0265  data_time: 0.0076  lr: 0.004595  max_mem: 5397M
[32m[04/28 09:44:29 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.563  loss_cls: 0.174  loss_box_reg: 0.307  loss_rpn_cls: 0.009  loss_rpn_loc: 0.043  time: 1.0261  data_time: 0.0076  lr: 0.004695  max_mem: 5397M
[32m[04/28 09:44:49 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.570  loss_cls: 0.175  loss_box_reg: 0.316  loss_rpn_cls: 0.008  loss_rpn_loc: 0.061  time: 1.0258  data_time: 0.0076  lr: 0.004795  max_mem: 5397M
[32m[04/28 09:45:09 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.579  loss_cls: 0.181  loss_box_reg: 0.322  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 1.0255  data_time: 0.0076  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 09:45:32 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 09:45:32 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 09:45:32 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 09:45:32 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.589  loss_cls: 0.179  loss_box_reg: 0.347  loss_rpn_cls: 0.009  loss_rpn_loc: 0.050  time: 1.0255  data_time: 0.0074  lr: 0.004995  max_mem: 5397M
[32m[04/28 09:45:33 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:03 (1.0265 s / it)
[32m[04/28 09:45:33 d2.engine.hooks]: [0mTotal training time: 0:17:08 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 09:45:34 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 09:45:34 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 09:45:35 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 09:45:36 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1143 s / img. ETA=0:16:05
[32m[04/28 09:45:41 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1142 s / img. ETA=0:16:01
[32m[04/28 09:45:46 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1140 s / img. ETA=0:15:54
[32m[04/28 09:45:51 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1140 s / img. ETA=0:15:49
[32m[04/28 09:45:56 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1140 s / img. ETA=0:15:44
[32m[04/28 09:46:01 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1140 s / img. ETA=0:15:39
[32m[04/28 09:46:07 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1141 s / img. ETA=0:15:35
[32m[04/28 09:46:12 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1141 s / img. ETA=0:15:30
[32m[04/28 09:46:17 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1141 s / img. ETA=0:15:25
[32m[04/28 09:46:22 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1142 s / img. ETA=0:15:20
[32m[04/28 09:46:27 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1142 s / img. ETA=0:15:15
[32m[04/28 09:46:32 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1141 s / img. ETA=0:15:10
[32m[04/28 09:46:37 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1141 s / img. ETA=0:15:05
[32m[04/28 09:46:42 d2.evaluation.evaluator]: [0mInference done 582/8355. 0.1142 s / img. ETA=0:15:00
[32m[04/28 09:46:47 d2.evaluation.evaluator]: [0mInference done 625/8355. 0.1142 s / img. ETA=0:14:55
[32m[04/28 09:46:52 d2.evaluation.evaluator]: [0mInference done 669/8355. 0.1142 s / img. ETA=0:14:50
[32m[04/28 09:46:57 d2.evaluation.evaluator]: [0mInference done 712/8355. 0.1144 s / img. ETA=0:14:47
[32m[04/28 09:47:02 d2.evaluation.evaluator]: [0mInference done 756/8355. 0.1143 s / img. ETA=0:14:41
[32m[04/28 09:47:08 d2.evaluation.evaluator]: [0mInference done 800/8355. 0.1144 s / img. ETA=0:14:36
[32m[04/28 09:47:13 d2.evaluation.evaluator]: [0mInference done 844/8355. 0.1143 s / img. ETA=0:14:31
[32m[04/28 09:47:18 d2.evaluation.evaluator]: [0mInference done 887/8355. 0.1144 s / img. ETA=0:14:26
[32m[04/28 09:47:23 d2.evaluation.evaluator]: [0mInference done 930/8355. 0.1144 s / img. ETA=0:14:22
[32m[04/28 09:47:28 d2.evaluation.evaluator]: [0mInference done 973/8355. 0.1144 s / img. ETA=0:14:17
[32m[04/28 09:47:33 d2.evaluation.evaluator]: [0mInference done 1017/8355. 0.1144 s / img. ETA=0:14:12
[32m[04/28 09:47:38 d2.evaluation.evaluator]: [0mInference done 1060/8355. 0.1145 s / img. ETA=0:14:07
[32m[04/28 09:47:43 d2.evaluation.evaluator]: [0mInference done 1104/8355. 0.1145 s / img. ETA=0:14:02
[32m[04/28 09:47:48 d2.evaluation.evaluator]: [0mInference done 1148/8355. 0.1145 s / img. ETA=0:13:57
[32m[04/28 09:47:53 d2.evaluation.evaluator]: [0mInference done 1192/8355. 0.1144 s / img. ETA=0:13:51
[32m[04/28 09:47:58 d2.evaluation.evaluator]: [0mInference done 1236/8355. 0.1144 s / img. ETA=0:13:46
[32m[04/28 09:48:03 d2.evaluation.evaluator]: [0mInference done 1279/8355. 0.1145 s / img. ETA=0:13:41
[32m[04/28 09:48:08 d2.evaluation.evaluator]: [0mInference done 1323/8355. 0.1144 s / img. ETA=0:13:36
[32m[04/28 09:48:13 d2.evaluation.evaluator]: [0mInference done 1367/8355. 0.1144 s / img. ETA=0:13:31
[32m[04/28 09:48:19 d2.evaluation.evaluator]: [0mInference done 1411/8355. 0.1144 s / img. ETA=0:13:26
[32m[04/28 09:48:24 d2.evaluation.evaluator]: [0mInference done 1455/8355. 0.1144 s / img. ETA=0:13:21
[32m[04/28 09:48:29 d2.evaluation.evaluator]: [0mInference done 1497/8355. 0.1145 s / img. ETA=0:13:16
[32m[04/28 09:48:34 d2.evaluation.evaluator]: [0mInference done 1540/8355. 0.1145 s / img. ETA=0:13:12
[32m[04/28 09:48:39 d2.evaluation.evaluator]: [0mInference done 1582/8355. 0.1146 s / img. ETA=0:13:07
[32m[04/28 09:48:44 d2.evaluation.evaluator]: [0mInference done 1625/8355. 0.1146 s / img. ETA=0:13:02
[32m[04/28 09:48:49 d2.evaluation.evaluator]: [0mInference done 1668/8355. 0.1147 s / img. ETA=0:12:58
[32m[04/28 09:48:54 d2.evaluation.evaluator]: [0mInference done 1711/8355. 0.1147 s / img. ETA=0:12:53
[32m[04/28 09:48:59 d2.evaluation.evaluator]: [0mInference done 1754/8355. 0.1147 s / img. ETA=0:12:48
[32m[04/28 09:49:04 d2.evaluation.evaluator]: [0mInference done 1796/8355. 0.1147 s / img. ETA=0:12:43
[32m[04/28 09:49:09 d2.evaluation.evaluator]: [0mInference done 1839/8355. 0.1148 s / img. ETA=0:12:39
[32m[04/28 09:49:14 d2.evaluation.evaluator]: [0mInference done 1882/8355. 0.1148 s / img. ETA=0:12:34
[32m[04/28 09:49:19 d2.evaluation.evaluator]: [0mInference done 1925/8355. 0.1148 s / img. ETA=0:12:29
[32m[04/28 09:49:24 d2.evaluation.evaluator]: [0mInference done 1968/8355. 0.1148 s / img. ETA=0:12:24
[32m[04/28 09:49:29 d2.evaluation.evaluator]: [0mInference done 2011/8355. 0.1148 s / img. ETA=0:12:19
[32m[04/28 09:49:34 d2.evaluation.evaluator]: [0mInference done 2054/8355. 0.1148 s / img. ETA=0:12:14
[32m[04/28 09:49:39 d2.evaluation.evaluator]: [0mInference done 2097/8355. 0.1149 s / img. ETA=0:12:09
[32m[04/28 09:49:44 d2.evaluation.evaluator]: [0mInference done 2141/8355. 0.1148 s / img. ETA=0:12:04
[32m[04/28 09:49:49 d2.evaluation.evaluator]: [0mInference done 2184/8355. 0.1149 s / img. ETA=0:11:59
[32m[04/28 09:49:54 d2.evaluation.evaluator]: [0mInference done 2227/8355. 0.1149 s / img. ETA=0:11:54
[32m[04/28 09:49:59 d2.evaluation.evaluator]: [0mInference done 2270/8355. 0.1149 s / img. ETA=0:11:49
[32m[04/28 09:50:05 d2.evaluation.evaluator]: [0mInference done 2313/8355. 0.1149 s / img. ETA=0:11:44
[32m[04/28 09:50:10 d2.evaluation.evaluator]: [0mInference done 2356/8355. 0.1149 s / img. ETA=0:11:39
[32m[04/28 09:50:15 d2.evaluation.evaluator]: [0mInference done 2399/8355. 0.1149 s / img. ETA=0:11:34
[32m[04/28 09:50:20 d2.evaluation.evaluator]: [0mInference done 2442/8355. 0.1149 s / img. ETA=0:11:29
[32m[04/28 09:50:25 d2.evaluation.evaluator]: [0mInference done 2485/8355. 0.1149 s / img. ETA=0:11:24
[32m[04/28 09:50:30 d2.evaluation.evaluator]: [0mInference done 2528/8355. 0.1149 s / img. ETA=0:11:19
[32m[04/28 09:50:35 d2.evaluation.evaluator]: [0mInference done 2571/8355. 0.1149 s / img. ETA=0:11:14
[32m[04/28 09:50:40 d2.evaluation.evaluator]: [0mInference done 2614/8355. 0.1150 s / img. ETA=0:11:10
[32m[04/28 09:50:45 d2.evaluation.evaluator]: [0mInference done 2657/8355. 0.1150 s / img. ETA=0:11:05
[32m[04/28 09:50:50 d2.evaluation.evaluator]: [0mInference done 2700/8355. 0.1150 s / img. ETA=0:11:00
[32m[04/28 09:50:55 d2.evaluation.evaluator]: [0mInference done 2743/8355. 0.1150 s / img. ETA=0:10:55
[32m[04/28 09:51:00 d2.evaluation.evaluator]: [0mInference done 2786/8355. 0.1150 s / img. ETA=0:10:50
[32m[04/28 09:51:05 d2.evaluation.evaluator]: [0mInference done 2829/8355. 0.1150 s / img. ETA=0:10:45
[32m[04/28 09:51:10 d2.evaluation.evaluator]: [0mInference done 2872/8355. 0.1150 s / img. ETA=0:10:40
[32m[04/28 09:51:15 d2.evaluation.evaluator]: [0mInference done 2915/8355. 0.1150 s / img. ETA=0:10:35
[32m[04/28 09:51:20 d2.evaluation.evaluator]: [0mInference done 2958/8355. 0.1150 s / img. ETA=0:10:30
[32m[04/28 09:51:25 d2.evaluation.evaluator]: [0mInference done 3002/8355. 0.1150 s / img. ETA=0:10:25
[32m[04/28 09:51:30 d2.evaluation.evaluator]: [0mInference done 3045/8355. 0.1150 s / img. ETA=0:10:20
[32m[04/28 09:51:35 d2.evaluation.evaluator]: [0mInference done 3088/8355. 0.1150 s / img. ETA=0:10:15
[32m[04/28 09:51:40 d2.evaluation.evaluator]: [0mInference done 3131/8355. 0.1150 s / img. ETA=0:10:10
[32m[04/28 09:51:46 d2.evaluation.evaluator]: [0mInference done 3175/8355. 0.1150 s / img. ETA=0:10:04
[32m[04/28 09:51:51 d2.evaluation.evaluator]: [0mInference done 3219/8355. 0.1150 s / img. ETA=0:09:59
[32m[04/28 09:51:56 d2.evaluation.evaluator]: [0mInference done 3262/8355. 0.1150 s / img. ETA=0:09:54
[32m[04/28 09:52:01 d2.evaluation.evaluator]: [0mInference done 3305/8355. 0.1150 s / img. ETA=0:09:49
[32m[04/28 09:52:06 d2.evaluation.evaluator]: [0mInference done 3348/8355. 0.1150 s / img. ETA=0:09:44
[32m[04/28 09:52:11 d2.evaluation.evaluator]: [0mInference done 3391/8355. 0.1150 s / img. ETA=0:09:39
[32m[04/28 09:52:16 d2.evaluation.evaluator]: [0mInference done 3434/8355. 0.1150 s / img. ETA=0:09:34
[32m[04/28 09:52:21 d2.evaluation.evaluator]: [0mInference done 3478/8355. 0.1150 s / img. ETA=0:09:29
[32m[04/28 09:52:26 d2.evaluation.evaluator]: [0mInference done 3521/8355. 0.1150 s / img. ETA=0:09:24
[32m[04/28 09:52:31 d2.evaluation.evaluator]: [0mInference done 3564/8355. 0.1150 s / img. ETA=0:09:19
[32m[04/28 09:52:36 d2.evaluation.evaluator]: [0mInference done 3607/8355. 0.1150 s / img. ETA=0:09:14
[32m[04/28 09:52:41 d2.evaluation.evaluator]: [0mInference done 3650/8355. 0.1150 s / img. ETA=0:09:09
[32m[04/28 09:52:46 d2.evaluation.evaluator]: [0mInference done 3693/8355. 0.1150 s / img. ETA=0:09:04
[32m[04/28 09:52:51 d2.evaluation.evaluator]: [0mInference done 3737/8355. 0.1150 s / img. ETA=0:08:59
[32m[04/28 09:52:56 d2.evaluation.evaluator]: [0mInference done 3780/8355. 0.1150 s / img. ETA=0:08:54
[32m[04/28 09:53:01 d2.evaluation.evaluator]: [0mInference done 3823/8355. 0.1150 s / img. ETA=0:08:49
[32m[04/28 09:53:06 d2.evaluation.evaluator]: [0mInference done 3866/8355. 0.1150 s / img. ETA=0:08:44
[32m[04/28 09:53:11 d2.evaluation.evaluator]: [0mInference done 3909/8355. 0.1150 s / img. ETA=0:08:39
[32m[04/28 09:53:16 d2.evaluation.evaluator]: [0mInference done 3952/8355. 0.1150 s / img. ETA=0:08:34
[32m[04/28 09:53:21 d2.evaluation.evaluator]: [0mInference done 3995/8355. 0.1150 s / img. ETA=0:08:29
[32m[04/28 09:53:26 d2.evaluation.evaluator]: [0mInference done 4038/8355. 0.1150 s / img. ETA=0:08:24
[32m[04/28 09:53:32 d2.evaluation.evaluator]: [0mInference done 4081/8355. 0.1150 s / img. ETA=0:08:19
[32m[04/28 09:53:37 d2.evaluation.evaluator]: [0mInference done 4124/8355. 0.1151 s / img. ETA=0:08:14
[32m[04/28 09:53:42 d2.evaluation.evaluator]: [0mInference done 4167/8355. 0.1150 s / img. ETA=0:08:09
[32m[04/28 09:53:47 d2.evaluation.evaluator]: [0mInference done 4210/8355. 0.1150 s / img. ETA=0:08:04
[32m[04/28 09:53:52 d2.evaluation.evaluator]: [0mInference done 4254/8355. 0.1150 s / img. ETA=0:07:59
[32m[04/28 09:53:57 d2.evaluation.evaluator]: [0mInference done 4297/8355. 0.1150 s / img. ETA=0:07:54
[32m[04/28 09:54:02 d2.evaluation.evaluator]: [0mInference done 4340/8355. 0.1150 s / img. ETA=0:07:49
[32m[04/28 09:54:07 d2.evaluation.evaluator]: [0mInference done 4383/8355. 0.1150 s / img. ETA=0:07:44
[32m[04/28 09:54:12 d2.evaluation.evaluator]: [0mInference done 4426/8355. 0.1150 s / img. ETA=0:07:39
[32m[04/28 09:54:17 d2.evaluation.evaluator]: [0mInference done 4469/8355. 0.1150 s / img. ETA=0:07:33
[32m[04/28 09:54:22 d2.evaluation.evaluator]: [0mInference done 4511/8355. 0.1151 s / img. ETA=0:07:29
[32m[04/28 09:54:27 d2.evaluation.evaluator]: [0mInference done 4554/8355. 0.1151 s / img. ETA=0:07:24
[32m[04/28 09:54:32 d2.evaluation.evaluator]: [0mInference done 4597/8355. 0.1151 s / img. ETA=0:07:19
[32m[04/28 09:54:37 d2.evaluation.evaluator]: [0mInference done 4640/8355. 0.1151 s / img. ETA=0:07:14
[32m[04/28 09:54:42 d2.evaluation.evaluator]: [0mInference done 4683/8355. 0.1151 s / img. ETA=0:07:09
[32m[04/28 09:54:47 d2.evaluation.evaluator]: [0mInference done 4726/8355. 0.1151 s / img. ETA=0:07:04
[32m[04/28 09:54:52 d2.evaluation.evaluator]: [0mInference done 4769/8355. 0.1151 s / img. ETA=0:06:59
[32m[04/28 09:54:57 d2.evaluation.evaluator]: [0mInference done 4812/8355. 0.1151 s / img. ETA=0:06:54
[32m[04/28 09:55:02 d2.evaluation.evaluator]: [0mInference done 4855/8355. 0.1151 s / img. ETA=0:06:49
[32m[04/28 09:55:07 d2.evaluation.evaluator]: [0mInference done 4898/8355. 0.1151 s / img. ETA=0:06:44
[32m[04/28 09:55:12 d2.evaluation.evaluator]: [0mInference done 4941/8355. 0.1151 s / img. ETA=0:06:39
[32m[04/28 09:55:17 d2.evaluation.evaluator]: [0mInference done 4984/8355. 0.1151 s / img. ETA=0:06:33
[32m[04/28 09:55:22 d2.evaluation.evaluator]: [0mInference done 5027/8355. 0.1151 s / img. ETA=0:06:29
[32m[04/28 09:55:27 d2.evaluation.evaluator]: [0mInference done 5070/8355. 0.1151 s / img. ETA=0:06:23
[32m[04/28 09:55:32 d2.evaluation.evaluator]: [0mInference done 5113/8355. 0.1151 s / img. ETA=0:06:18
[32m[04/28 09:55:37 d2.evaluation.evaluator]: [0mInference done 5156/8355. 0.1151 s / img. ETA=0:06:13
[32m[04/28 09:55:42 d2.evaluation.evaluator]: [0mInference done 5199/8355. 0.1151 s / img. ETA=0:06:08
[32m[04/28 09:55:48 d2.evaluation.evaluator]: [0mInference done 5242/8355. 0.1151 s / img. ETA=0:06:03
[32m[04/28 09:55:53 d2.evaluation.evaluator]: [0mInference done 5285/8355. 0.1151 s / img. ETA=0:05:58
[32m[04/28 09:55:58 d2.evaluation.evaluator]: [0mInference done 5328/8355. 0.1151 s / img. ETA=0:05:53
[32m[04/28 09:56:03 d2.evaluation.evaluator]: [0mInference done 5371/8355. 0.1151 s / img. ETA=0:05:48
[32m[04/28 09:56:08 d2.evaluation.evaluator]: [0mInference done 5414/8355. 0.1151 s / img. ETA=0:05:43
[32m[04/28 09:56:13 d2.evaluation.evaluator]: [0mInference done 5457/8355. 0.1151 s / img. ETA=0:05:38
[32m[04/28 09:56:18 d2.evaluation.evaluator]: [0mInference done 5500/8355. 0.1151 s / img. ETA=0:05:33
[32m[04/28 09:56:23 d2.evaluation.evaluator]: [0mInference done 5543/8355. 0.1151 s / img. ETA=0:05:28
[32m[04/28 09:56:28 d2.evaluation.evaluator]: [0mInference done 5586/8355. 0.1151 s / img. ETA=0:05:23
[32m[04/28 09:56:33 d2.evaluation.evaluator]: [0mInference done 5629/8355. 0.1151 s / img. ETA=0:05:18
[32m[04/28 09:56:38 d2.evaluation.evaluator]: [0mInference done 5672/8355. 0.1151 s / img. ETA=0:05:13
[32m[04/28 09:56:43 d2.evaluation.evaluator]: [0mInference done 5715/8355. 0.1151 s / img. ETA=0:05:08
[32m[04/28 09:56:48 d2.evaluation.evaluator]: [0mInference done 5758/8355. 0.1151 s / img. ETA=0:05:03
[32m[04/28 09:56:53 d2.evaluation.evaluator]: [0mInference done 5801/8355. 0.1151 s / img. ETA=0:04:58
[32m[04/28 09:56:58 d2.evaluation.evaluator]: [0mInference done 5844/8355. 0.1152 s / img. ETA=0:04:53
[32m[04/28 09:57:03 d2.evaluation.evaluator]: [0mInference done 5887/8355. 0.1152 s / img. ETA=0:04:48
[32m[04/28 09:57:08 d2.evaluation.evaluator]: [0mInference done 5930/8355. 0.1152 s / img. ETA=0:04:43
[32m[04/28 09:57:14 d2.evaluation.evaluator]: [0mInference done 5973/8355. 0.1152 s / img. ETA=0:04:38
[32m[04/28 09:57:19 d2.evaluation.evaluator]: [0mInference done 6016/8355. 0.1152 s / img. ETA=0:04:33
[32m[04/28 09:57:24 d2.evaluation.evaluator]: [0mInference done 6059/8355. 0.1152 s / img. ETA=0:04:28
[32m[04/28 09:57:29 d2.evaluation.evaluator]: [0mInference done 6102/8355. 0.1152 s / img. ETA=0:04:23
[32m[04/28 09:57:34 d2.evaluation.evaluator]: [0mInference done 6145/8355. 0.1152 s / img. ETA=0:04:18
[32m[04/28 09:57:39 d2.evaluation.evaluator]: [0mInference done 6188/8355. 0.1152 s / img. ETA=0:04:13
[32m[04/28 09:57:44 d2.evaluation.evaluator]: [0mInference done 6231/8355. 0.1152 s / img. ETA=0:04:08
[32m[04/28 09:57:49 d2.evaluation.evaluator]: [0mInference done 6274/8355. 0.1153 s / img. ETA=0:04:03
[32m[04/28 09:57:54 d2.evaluation.evaluator]: [0mInference done 6316/8355. 0.1153 s / img. ETA=0:03:58
[32m[04/28 09:57:59 d2.evaluation.evaluator]: [0mInference done 6358/8355. 0.1153 s / img. ETA=0:03:53
[32m[04/28 09:58:04 d2.evaluation.evaluator]: [0mInference done 6401/8355. 0.1153 s / img. ETA=0:03:48
[32m[04/28 09:58:09 d2.evaluation.evaluator]: [0mInference done 6444/8355. 0.1153 s / img. ETA=0:03:43
[32m[04/28 09:58:14 d2.evaluation.evaluator]: [0mInference done 6487/8355. 0.1153 s / img. ETA=0:03:38
[32m[04/28 09:58:19 d2.evaluation.evaluator]: [0mInference done 6530/8355. 0.1153 s / img. ETA=0:03:33
[32m[04/28 09:58:24 d2.evaluation.evaluator]: [0mInference done 6573/8355. 0.1153 s / img. ETA=0:03:28
[32m[04/28 09:58:29 d2.evaluation.evaluator]: [0mInference done 6616/8355. 0.1153 s / img. ETA=0:03:23
[32m[04/28 09:58:34 d2.evaluation.evaluator]: [0mInference done 6659/8355. 0.1153 s / img. ETA=0:03:18
[32m[04/28 09:58:39 d2.evaluation.evaluator]: [0mInference done 6702/8355. 0.1153 s / img. ETA=0:03:13
[32m[04/28 09:58:44 d2.evaluation.evaluator]: [0mInference done 6745/8355. 0.1153 s / img. ETA=0:03:08
[32m[04/28 09:58:49 d2.evaluation.evaluator]: [0mInference done 6788/8355. 0.1153 s / img. ETA=0:03:03
[32m[04/28 09:58:54 d2.evaluation.evaluator]: [0mInference done 6831/8355. 0.1153 s / img. ETA=0:02:58
[32m[04/28 09:59:00 d2.evaluation.evaluator]: [0mInference done 6874/8355. 0.1153 s / img. ETA=0:02:53
[32m[04/28 09:59:05 d2.evaluation.evaluator]: [0mInference done 6917/8355. 0.1153 s / img. ETA=0:02:48
[32m[04/28 09:59:10 d2.evaluation.evaluator]: [0mInference done 6960/8355. 0.1153 s / img. ETA=0:02:43
[32m[04/28 09:59:15 d2.evaluation.evaluator]: [0mInference done 7003/8355. 0.1153 s / img. ETA=0:02:38
[32m[04/28 09:59:20 d2.evaluation.evaluator]: [0mInference done 7046/8355. 0.1153 s / img. ETA=0:02:33
[32m[04/28 09:59:25 d2.evaluation.evaluator]: [0mInference done 7089/8355. 0.1153 s / img. ETA=0:02:28
[32m[04/28 09:59:30 d2.evaluation.evaluator]: [0mInference done 7132/8355. 0.1153 s / img. ETA=0:02:23
[32m[04/28 09:59:35 d2.evaluation.evaluator]: [0mInference done 7175/8355. 0.1153 s / img. ETA=0:02:18
[32m[04/28 09:59:40 d2.evaluation.evaluator]: [0mInference done 7218/8355. 0.1153 s / img. ETA=0:02:13
[32m[04/28 09:59:45 d2.evaluation.evaluator]: [0mInference done 7261/8355. 0.1153 s / img. ETA=0:02:08
[32m[04/28 09:59:50 d2.evaluation.evaluator]: [0mInference done 7304/8355. 0.1153 s / img. ETA=0:02:03
[32m[04/28 09:59:55 d2.evaluation.evaluator]: [0mInference done 7347/8355. 0.1153 s / img. ETA=0:01:58
[32m[04/28 10:00:00 d2.evaluation.evaluator]: [0mInference done 7390/8355. 0.1153 s / img. ETA=0:01:53
[32m[04/28 10:00:05 d2.evaluation.evaluator]: [0mInference done 7432/8355. 0.1154 s / img. ETA=0:01:48
[32m[04/28 10:00:11 d2.evaluation.evaluator]: [0mInference done 7475/8355. 0.1154 s / img. ETA=0:01:43
[32m[04/28 10:00:16 d2.evaluation.evaluator]: [0mInference done 7518/8355. 0.1154 s / img. ETA=0:01:38
[32m[04/28 10:00:21 d2.evaluation.evaluator]: [0mInference done 7561/8355. 0.1154 s / img. ETA=0:01:33
[32m[04/28 10:00:26 d2.evaluation.evaluator]: [0mInference done 7604/8355. 0.1154 s / img. ETA=0:01:28
[32m[04/28 10:00:31 d2.evaluation.evaluator]: [0mInference done 7647/8355. 0.1154 s / img. ETA=0:01:22
[32m[04/28 10:00:36 d2.evaluation.evaluator]: [0mInference done 7690/8355. 0.1154 s / img. ETA=0:01:17
[32m[04/28 10:00:41 d2.evaluation.evaluator]: [0mInference done 7733/8355. 0.1154 s / img. ETA=0:01:12
[32m[04/28 10:00:46 d2.evaluation.evaluator]: [0mInference done 7776/8355. 0.1154 s / img. ETA=0:01:07
[32m[04/28 10:00:51 d2.evaluation.evaluator]: [0mInference done 7819/8355. 0.1154 s / img. ETA=0:01:02
[32m[04/28 10:00:56 d2.evaluation.evaluator]: [0mInference done 7862/8355. 0.1154 s / img. ETA=0:00:57
[32m[04/28 10:01:01 d2.evaluation.evaluator]: [0mInference done 7905/8355. 0.1154 s / img. ETA=0:00:52
[32m[04/28 10:01:06 d2.evaluation.evaluator]: [0mInference done 7948/8355. 0.1154 s / img. ETA=0:00:47
[32m[04/28 10:01:11 d2.evaluation.evaluator]: [0mInference done 7991/8355. 0.1154 s / img. ETA=0:00:42
[32m[04/28 10:01:16 d2.evaluation.evaluator]: [0mInference done 8034/8355. 0.1154 s / img. ETA=0:00:37
[32m[04/28 10:01:21 d2.evaluation.evaluator]: [0mInference done 8077/8355. 0.1154 s / img. ETA=0:00:32
[32m[04/28 10:01:26 d2.evaluation.evaluator]: [0mInference done 8120/8355. 0.1154 s / img. ETA=0:00:27
[32m[04/28 10:01:31 d2.evaluation.evaluator]: [0mInference done 8163/8355. 0.1154 s / img. ETA=0:00:22
[32m[04/28 10:01:36 d2.evaluation.evaluator]: [0mInference done 8206/8355. 0.1154 s / img. ETA=0:00:17
[32m[04/28 10:01:41 d2.evaluation.evaluator]: [0mInference done 8248/8355. 0.1154 s / img. ETA=0:00:12
[32m[04/28 10:01:47 d2.evaluation.evaluator]: [0mInference done 8291/8355. 0.1154 s / img. ETA=0:00:07
[32m[04/28 10:01:52 d2.evaluation.evaluator]: [0mInference done 8334/8355. 0.1154 s / img. ETA=0:00:02
[32m[04/28 10:01:54 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:18.777114 (0.117219 s / img per device, on 1 devices)
[32m[04/28 10:01:54 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:03 (0.115403 s / img per device, on 1 devices)
[32m[04/28 10:01:54 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 10:01:54 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 10:01:55 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.88s).
Accumulating evaluation results...
DONE (t=2.17s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.834
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.459
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.359
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.597
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.732
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.515
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.532
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.437
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.776
[32m[04/28 10:02:17 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.677 | 83.400 | 45.923 | 35.884 | 59.749 | 73.244 |
[32m[04/28 10:02:17 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 45.673 | bicycle       | 38.425 | car            | 55.933 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 10:02:17 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 10:02:17 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 10:02:17 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 10:02:19 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1149 s / img. ETA=0:02:25
[32m[04/28 10:02:24 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1150 s / img. ETA=0:02:20
[32m[04/28 10:02:29 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1150 s / img. ETA=0:02:15
[32m[04/28 10:02:34 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1150 s / img. ETA=0:02:10
[32m[04/28 10:02:39 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1150 s / img. ETA=0:02:05
[32m[04/28 10:02:44 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1149 s / img. ETA=0:02:00
[32m[04/28 10:02:49 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1150 s / img. ETA=0:01:55
[32m[04/28 10:02:54 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1150 s / img. ETA=0:01:50
[32m[04/28 10:02:59 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1149 s / img. ETA=0:01:45
[32m[04/28 10:03:04 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1149 s / img. ETA=0:01:40
[32m[04/28 10:03:09 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1149 s / img. ETA=0:01:35
[32m[04/28 10:03:14 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1149 s / img. ETA=0:01:30
[32m[04/28 10:03:19 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1149 s / img. ETA=0:01:25
[32m[04/28 10:03:24 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1149 s / img. ETA=0:01:20
[32m[04/28 10:03:29 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1149 s / img. ETA=0:01:15
[32m[04/28 10:03:34 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1150 s / img. ETA=0:01:10
[32m[04/28 10:03:39 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1150 s / img. ETA=0:01:05
[32m[04/28 10:03:44 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1150 s / img. ETA=0:01:00
[32m[04/28 10:03:49 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1150 s / img. ETA=0:00:55
[32m[04/28 10:03:54 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1150 s / img. ETA=0:00:50
[32m[04/28 10:03:59 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1151 s / img. ETA=0:00:45
[32m[04/28 10:04:04 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1151 s / img. ETA=0:00:40
[32m[04/28 10:04:09 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1151 s / img. ETA=0:00:35
[32m[04/28 10:04:15 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1151 s / img. ETA=0:00:30
[32m[04/28 10:04:20 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1151 s / img. ETA=0:00:25
[32m[04/28 10:04:25 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1151 s / img. ETA=0:00:20
[32m[04/28 10:04:30 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1151 s / img. ETA=0:00:14
[32m[04/28 10:04:35 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1152 s / img. ETA=0:00:09
[32m[04/28 10:04:40 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1152 s / img. ETA=0:00:04
[32m[04/28 10:04:45 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.564257 (0.117064 s / img per device, on 1 devices)
[32m[04/28 10:04:45 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115180 s / img per device, on 1 devices)
[32m[04/28 10:04:45 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 10:04:45 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 10:04:45 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.19s).
Accumulating evaluation results...
DONE (t=0.36s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.384
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.752
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.338
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.272
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.572
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.192
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.458
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.622
[32m[04/28 10:04:48 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 38.399 | 75.162 | 33.798 | 27.209 | 45.519 | 57.185 |
[32m[04/28 10:04:48 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 38.581 | bicycle       | 23.167 | car            | 53.449 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  14  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 10:04:49 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 10:04:50 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 10:04:50 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 10:04:50 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 10:04:50 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 10:04:50 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 10:04:50 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 10:05:10 d2.utils.events]: [0m eta: 0:16:45  iter: 19  total_loss: 0.547  loss_cls: 0.172  loss_box_reg: 0.323  loss_rpn_cls: 0.009  loss_rpn_loc: 0.046  time: 1.0181  data_time: 0.0183  lr: 0.000100  max_mem: 5397M
[32m[04/28 10:05:31 d2.utils.events]: [0m eta: 0:16:14  iter: 39  total_loss: 0.549  loss_cls: 0.167  loss_box_reg: 0.317  loss_rpn_cls: 0.008  loss_rpn_loc: 0.055  time: 1.0124  data_time: 0.0075  lr: 0.000200  max_mem: 5397M
[32m[04/28 10:05:51 d2.utils.events]: [0m eta: 0:15:54  iter: 59  total_loss: 0.484  loss_cls: 0.135  loss_box_reg: 0.275  loss_rpn_cls: 0.007  loss_rpn_loc: 0.040  time: 1.0073  data_time: 0.0075  lr: 0.000300  max_mem: 5397M
[32m[04/28 10:06:11 d2.utils.events]: [0m eta: 0:15:34  iter: 79  total_loss: 0.506  loss_cls: 0.162  loss_box_reg: 0.298  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0095  data_time: 0.0077  lr: 0.000400  max_mem: 5397M
[32m[04/28 10:06:32 d2.utils.events]: [0m eta: 0:15:16  iter: 99  total_loss: 0.540  loss_cls: 0.159  loss_box_reg: 0.305  loss_rpn_cls: 0.010  loss_rpn_loc: 0.053  time: 1.0134  data_time: 0.0076  lr: 0.000500  max_mem: 5397M
[32m[04/28 10:06:53 d2.utils.events]: [0m eta: 0:15:01  iter: 119  total_loss: 0.479  loss_cls: 0.146  loss_box_reg: 0.289  loss_rpn_cls: 0.008  loss_rpn_loc: 0.041  time: 1.0184  data_time: 0.0076  lr: 0.000599  max_mem: 5397M
[32m[04/28 10:07:14 d2.utils.events]: [0m eta: 0:14:47  iter: 139  total_loss: 0.512  loss_cls: 0.157  loss_box_reg: 0.300  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0242  data_time: 0.0079  lr: 0.000699  max_mem: 5397M
[32m[04/28 10:07:35 d2.utils.events]: [0m eta: 0:14:32  iter: 159  total_loss: 0.479  loss_cls: 0.144  loss_box_reg: 0.275  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 1.0262  data_time: 0.0077  lr: 0.000799  max_mem: 5397M
[32m[04/28 10:07:55 d2.utils.events]: [0m eta: 0:14:14  iter: 179  total_loss: 0.484  loss_cls: 0.159  loss_box_reg: 0.291  loss_rpn_cls: 0.007  loss_rpn_loc: 0.038  time: 1.0272  data_time: 0.0076  lr: 0.000899  max_mem: 5397M
[32m[04/28 10:08:16 d2.utils.events]: [0m eta: 0:13:50  iter: 199  total_loss: 0.494  loss_cls: 0.154  loss_box_reg: 0.292  loss_rpn_cls: 0.009  loss_rpn_loc: 0.043  time: 1.0277  data_time: 0.0077  lr: 0.000999  max_mem: 5397M
[32m[04/28 10:08:36 d2.utils.events]: [0m eta: 0:13:29  iter: 219  total_loss: 0.521  loss_cls: 0.152  loss_box_reg: 0.296  loss_rpn_cls: 0.007  loss_rpn_loc: 0.051  time: 1.0271  data_time: 0.0084  lr: 0.001099  max_mem: 5397M
[32m[04/28 10:08:57 d2.utils.events]: [0m eta: 0:13:08  iter: 239  total_loss: 0.410  loss_cls: 0.122  loss_box_reg: 0.253  loss_rpn_cls: 0.005  loss_rpn_loc: 0.035  time: 1.0264  data_time: 0.0076  lr: 0.001199  max_mem: 5397M
[32m[04/28 10:09:18 d2.utils.events]: [0m eta: 0:12:48  iter: 259  total_loss: 0.453  loss_cls: 0.131  loss_box_reg: 0.270  loss_rpn_cls: 0.006  loss_rpn_loc: 0.035  time: 1.0274  data_time: 0.0078  lr: 0.001299  max_mem: 5397M
[32m[04/28 10:09:39 d2.utils.events]: [0m eta: 0:12:27  iter: 279  total_loss: 0.504  loss_cls: 0.158  loss_box_reg: 0.302  loss_rpn_cls: 0.011  loss_rpn_loc: 0.049  time: 1.0285  data_time: 0.0076  lr: 0.001399  max_mem: 5397M
[32m[04/28 10:09:59 d2.utils.events]: [0m eta: 0:12:05  iter: 299  total_loss: 0.477  loss_cls: 0.151  loss_box_reg: 0.270  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 1.0265  data_time: 0.0075  lr: 0.001499  max_mem: 5397M
[32m[04/28 10:10:19 d2.utils.events]: [0m eta: 0:11:41  iter: 319  total_loss: 0.473  loss_cls: 0.141  loss_box_reg: 0.283  loss_rpn_cls: 0.006  loss_rpn_loc: 0.031  time: 1.0254  data_time: 0.0076  lr: 0.001598  max_mem: 5397M
[32m[04/28 10:10:39 d2.utils.events]: [0m eta: 0:11:19  iter: 339  total_loss: 0.516  loss_cls: 0.152  loss_box_reg: 0.299  loss_rpn_cls: 0.007  loss_rpn_loc: 0.054  time: 1.0255  data_time: 0.0076  lr: 0.001698  max_mem: 5397M
[32m[04/28 10:11:01 d2.utils.events]: [0m eta: 0:11:00  iter: 359  total_loss: 0.430  loss_cls: 0.143  loss_box_reg: 0.248  loss_rpn_cls: 0.008  loss_rpn_loc: 0.042  time: 1.0268  data_time: 0.0076  lr: 0.001798  max_mem: 5397M
[32m[04/28 10:11:21 d2.utils.events]: [0m eta: 0:10:40  iter: 379  total_loss: 0.536  loss_cls: 0.160  loss_box_reg: 0.313  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0274  data_time: 0.0078  lr: 0.001898  max_mem: 5397M
[32m[04/28 10:11:42 d2.utils.events]: [0m eta: 0:10:19  iter: 399  total_loss: 0.502  loss_cls: 0.143  loss_box_reg: 0.304  loss_rpn_cls: 0.008  loss_rpn_loc: 0.040  time: 1.0270  data_time: 0.0076  lr: 0.001998  max_mem: 5397M
[32m[04/28 10:12:03 d2.utils.events]: [0m eta: 0:10:00  iter: 419  total_loss: 0.498  loss_cls: 0.145  loss_box_reg: 0.296  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0279  data_time: 0.0078  lr: 0.002098  max_mem: 5397M
[32m[04/28 10:12:23 d2.utils.events]: [0m eta: 0:09:40  iter: 439  total_loss: 0.548  loss_cls: 0.160  loss_box_reg: 0.306  loss_rpn_cls: 0.007  loss_rpn_loc: 0.041  time: 1.0281  data_time: 0.0077  lr: 0.002198  max_mem: 5397M
[32m[04/28 10:12:44 d2.utils.events]: [0m eta: 0:09:20  iter: 459  total_loss: 0.502  loss_cls: 0.139  loss_box_reg: 0.289  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 1.0283  data_time: 0.0077  lr: 0.002298  max_mem: 5397M
[32m[04/28 10:13:04 d2.utils.events]: [0m eta: 0:08:57  iter: 479  total_loss: 0.599  loss_cls: 0.170  loss_box_reg: 0.328  loss_rpn_cls: 0.009  loss_rpn_loc: 0.051  time: 1.0274  data_time: 0.0076  lr: 0.002398  max_mem: 5397M
[32m[04/28 10:13:25 d2.utils.events]: [0m eta: 0:08:36  iter: 499  total_loss: 0.503  loss_cls: 0.144  loss_box_reg: 0.287  loss_rpn_cls: 0.010  loss_rpn_loc: 0.045  time: 1.0269  data_time: 0.0076  lr: 0.002498  max_mem: 5397M
[32m[04/28 10:13:45 d2.utils.events]: [0m eta: 0:08:15  iter: 519  total_loss: 0.453  loss_cls: 0.141  loss_box_reg: 0.264  loss_rpn_cls: 0.004  loss_rpn_loc: 0.037  time: 1.0267  data_time: 0.0077  lr: 0.002597  max_mem: 5397M
[32m[04/28 10:14:06 d2.utils.events]: [0m eta: 0:07:56  iter: 539  total_loss: 0.459  loss_cls: 0.132  loss_box_reg: 0.285  loss_rpn_cls: 0.006  loss_rpn_loc: 0.034  time: 1.0273  data_time: 0.0075  lr: 0.002697  max_mem: 5397M
[32m[04/28 10:14:27 d2.utils.events]: [0m eta: 0:07:35  iter: 559  total_loss: 0.488  loss_cls: 0.163  loss_box_reg: 0.281  loss_rpn_cls: 0.007  loss_rpn_loc: 0.053  time: 1.0272  data_time: 0.0076  lr: 0.002797  max_mem: 5397M
[32m[04/28 10:14:47 d2.utils.events]: [0m eta: 0:07:14  iter: 579  total_loss: 0.479  loss_cls: 0.157  loss_box_reg: 0.278  loss_rpn_cls: 0.006  loss_rpn_loc: 0.048  time: 1.0273  data_time: 0.0079  lr: 0.002897  max_mem: 5397M
[32m[04/28 10:15:08 d2.utils.events]: [0m eta: 0:06:53  iter: 599  total_loss: 0.542  loss_cls: 0.165  loss_box_reg: 0.298  loss_rpn_cls: 0.008  loss_rpn_loc: 0.052  time: 1.0273  data_time: 0.0075  lr: 0.002997  max_mem: 5397M
[32m[04/28 10:15:29 d2.utils.events]: [0m eta: 0:06:33  iter: 619  total_loss: 0.501  loss_cls: 0.156  loss_box_reg: 0.301  loss_rpn_cls: 0.006  loss_rpn_loc: 0.050  time: 1.0274  data_time: 0.0077  lr: 0.003097  max_mem: 5397M
[32m[04/28 10:15:49 d2.utils.events]: [0m eta: 0:06:12  iter: 639  total_loss: 0.590  loss_cls: 0.182  loss_box_reg: 0.347  loss_rpn_cls: 0.007  loss_rpn_loc: 0.051  time: 1.0278  data_time: 0.0078  lr: 0.003197  max_mem: 5397M
[32m[04/28 10:16:11 d2.utils.events]: [0m eta: 0:05:53  iter: 659  total_loss: 0.533  loss_cls: 0.172  loss_box_reg: 0.315  loss_rpn_cls: 0.005  loss_rpn_loc: 0.048  time: 1.0288  data_time: 0.0079  lr: 0.003297  max_mem: 5397M
[32m[04/28 10:16:30 d2.utils.events]: [0m eta: 0:05:31  iter: 679  total_loss: 0.478  loss_cls: 0.147  loss_box_reg: 0.278  loss_rpn_cls: 0.007  loss_rpn_loc: 0.038  time: 1.0276  data_time: 0.0076  lr: 0.003397  max_mem: 5397M
[32m[04/28 10:16:51 d2.utils.events]: [0m eta: 0:05:11  iter: 699  total_loss: 0.529  loss_cls: 0.155  loss_box_reg: 0.316  loss_rpn_cls: 0.007  loss_rpn_loc: 0.042  time: 1.0281  data_time: 0.0078  lr: 0.003497  max_mem: 5397M
[32m[04/28 10:17:12 d2.utils.events]: [0m eta: 0:04:50  iter: 719  total_loss: 0.511  loss_cls: 0.158  loss_box_reg: 0.289  loss_rpn_cls: 0.009  loss_rpn_loc: 0.050  time: 1.0282  data_time: 0.0078  lr: 0.003596  max_mem: 5397M
[32m[04/28 10:17:33 d2.utils.events]: [0m eta: 0:04:30  iter: 739  total_loss: 0.504  loss_cls: 0.159  loss_box_reg: 0.293  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 1.0287  data_time: 0.0076  lr: 0.003696  max_mem: 5397M
[32m[04/28 10:17:53 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.536  loss_cls: 0.166  loss_box_reg: 0.310  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 1.0280  data_time: 0.0074  lr: 0.003796  max_mem: 5397M
[32m[04/28 10:18:14 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.525  loss_cls: 0.155  loss_box_reg: 0.322  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0281  data_time: 0.0076  lr: 0.003896  max_mem: 5397M
[32m[04/28 10:18:34 d2.utils.events]: [0m eta: 0:03:28  iter: 799  total_loss: 0.551  loss_cls: 0.162  loss_box_reg: 0.318  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0280  data_time: 0.0079  lr: 0.003996  max_mem: 5397M
[32m[04/28 10:18:55 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.537  loss_cls: 0.166  loss_box_reg: 0.295  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0275  data_time: 0.0076  lr: 0.004096  max_mem: 5397M
[32m[04/28 10:19:15 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.513  loss_cls: 0.169  loss_box_reg: 0.304  loss_rpn_cls: 0.007  loss_rpn_loc: 0.039  time: 1.0278  data_time: 0.0077  lr: 0.004196  max_mem: 5397M
[32m[04/28 10:19:36 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.479  loss_cls: 0.140  loss_box_reg: 0.290  loss_rpn_cls: 0.009  loss_rpn_loc: 0.050  time: 1.0279  data_time: 0.0076  lr: 0.004296  max_mem: 5397M
[32m[04/28 10:19:56 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.495  loss_cls: 0.154  loss_box_reg: 0.292  loss_rpn_cls: 0.008  loss_rpn_loc: 0.055  time: 1.0274  data_time: 0.0075  lr: 0.004396  max_mem: 5397M
[32m[04/28 10:20:17 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.501  loss_cls: 0.157  loss_box_reg: 0.296  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0272  data_time: 0.0075  lr: 0.004496  max_mem: 5397M
[32m[04/28 10:20:37 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.531  loss_cls: 0.153  loss_box_reg: 0.311  loss_rpn_cls: 0.008  loss_rpn_loc: 0.058  time: 1.0268  data_time: 0.0077  lr: 0.004595  max_mem: 5397M
[32m[04/28 10:20:57 d2.utils.events]: [0m eta: 0:01:02  iter: 939  total_loss: 0.610  loss_cls: 0.196  loss_box_reg: 0.336  loss_rpn_cls: 0.012  loss_rpn_loc: 0.056  time: 1.0265  data_time: 0.0076  lr: 0.004695  max_mem: 5397M
[32m[04/28 10:21:18 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.576  loss_cls: 0.185  loss_box_reg: 0.333  loss_rpn_cls: 0.009  loss_rpn_loc: 0.055  time: 1.0269  data_time: 0.0077  lr: 0.004795  max_mem: 5397M
[32m[04/28 10:21:39 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.537  loss_cls: 0.162  loss_box_reg: 0.300  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 1.0271  data_time: 0.0074  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 10:22:02 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 10:22:02 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 10:22:02 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 10:22:02 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.542  loss_cls: 0.177  loss_box_reg: 0.316  loss_rpn_cls: 0.010  loss_rpn_loc: 0.043  time: 1.0273  data_time: 0.0077  lr: 0.004995  max_mem: 5397M
[32m[04/28 10:22:03 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:05 (1.0284 s / it)
[32m[04/28 10:22:03 d2.engine.hooks]: [0mTotal training time: 0:17:10 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 10:22:04 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 10:22:04 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 10:22:04 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 10:22:06 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1142 s / img. ETA=0:16:04
[32m[04/28 10:22:11 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1138 s / img. ETA=0:15:58
[32m[04/28 10:22:16 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1138 s / img. ETA=0:15:52
[32m[04/28 10:22:21 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1138 s / img. ETA=0:15:48
[32m[04/28 10:22:26 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1138 s / img. ETA=0:15:43
[32m[04/28 10:22:31 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1139 s / img. ETA=0:15:38
[32m[04/28 10:22:36 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1140 s / img. ETA=0:15:34
[32m[04/28 10:22:41 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1140 s / img. ETA=0:15:29
[32m[04/28 10:22:47 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1141 s / img. ETA=0:15:25
[32m[04/28 10:22:52 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1141 s / img. ETA=0:15:20
[32m[04/28 10:22:57 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1141 s / img. ETA=0:15:15
[32m[04/28 10:23:02 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1141 s / img. ETA=0:15:09
[32m[04/28 10:23:07 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1141 s / img. ETA=0:15:04
[32m[04/28 10:23:12 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1140 s / img. ETA=0:14:59
[32m[04/28 10:23:17 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1140 s / img. ETA=0:14:54
[32m[04/28 10:23:22 d2.evaluation.evaluator]: [0mInference done 671/8355. 0.1140 s / img. ETA=0:14:49
[32m[04/28 10:23:27 d2.evaluation.evaluator]: [0mInference done 714/8355. 0.1141 s / img. ETA=0:14:44
[32m[04/28 10:23:32 d2.evaluation.evaluator]: [0mInference done 757/8355. 0.1141 s / img. ETA=0:14:40
[32m[04/28 10:23:37 d2.evaluation.evaluator]: [0mInference done 800/8355. 0.1142 s / img. ETA=0:14:35
[32m[04/28 10:23:42 d2.evaluation.evaluator]: [0mInference done 844/8355. 0.1142 s / img. ETA=0:14:30
[32m[04/28 10:23:47 d2.evaluation.evaluator]: [0mInference done 887/8355. 0.1142 s / img. ETA=0:14:25
[32m[04/28 10:23:52 d2.evaluation.evaluator]: [0mInference done 930/8355. 0.1143 s / img. ETA=0:14:21
[32m[04/28 10:23:58 d2.evaluation.evaluator]: [0mInference done 974/8355. 0.1143 s / img. ETA=0:14:16
[32m[04/28 10:24:03 d2.evaluation.evaluator]: [0mInference done 1018/8355. 0.1143 s / img. ETA=0:14:11
[32m[04/28 10:24:08 d2.evaluation.evaluator]: [0mInference done 1062/8355. 0.1142 s / img. ETA=0:14:05
[32m[04/28 10:24:13 d2.evaluation.evaluator]: [0mInference done 1106/8355. 0.1142 s / img. ETA=0:14:00
[32m[04/28 10:24:18 d2.evaluation.evaluator]: [0mInference done 1150/8355. 0.1142 s / img. ETA=0:13:55
[32m[04/28 10:24:23 d2.evaluation.evaluator]: [0mInference done 1194/8355. 0.1142 s / img. ETA=0:13:50
[32m[04/28 10:24:28 d2.evaluation.evaluator]: [0mInference done 1238/8355. 0.1142 s / img. ETA=0:13:44
[32m[04/28 10:24:33 d2.evaluation.evaluator]: [0mInference done 1282/8355. 0.1142 s / img. ETA=0:13:39
[32m[04/28 10:24:38 d2.evaluation.evaluator]: [0mInference done 1326/8355. 0.1142 s / img. ETA=0:13:34
[32m[04/28 10:24:43 d2.evaluation.evaluator]: [0mInference done 1370/8355. 0.1141 s / img. ETA=0:13:29
[32m[04/28 10:24:48 d2.evaluation.evaluator]: [0mInference done 1414/8355. 0.1141 s / img. ETA=0:13:24
[32m[04/28 10:24:53 d2.evaluation.evaluator]: [0mInference done 1458/8355. 0.1141 s / img. ETA=0:13:19
[32m[04/28 10:24:59 d2.evaluation.evaluator]: [0mInference done 1501/8355. 0.1142 s / img. ETA=0:13:14
[32m[04/28 10:25:04 d2.evaluation.evaluator]: [0mInference done 1544/8355. 0.1142 s / img. ETA=0:13:09
[32m[04/28 10:25:09 d2.evaluation.evaluator]: [0mInference done 1587/8355. 0.1143 s / img. ETA=0:13:05
[32m[04/28 10:25:14 d2.evaluation.evaluator]: [0mInference done 1630/8355. 0.1143 s / img. ETA=0:13:00
[32m[04/28 10:25:19 d2.evaluation.evaluator]: [0mInference done 1673/8355. 0.1144 s / img. ETA=0:12:55
[32m[04/28 10:25:24 d2.evaluation.evaluator]: [0mInference done 1715/8355. 0.1144 s / img. ETA=0:12:51
[32m[04/28 10:25:29 d2.evaluation.evaluator]: [0mInference done 1758/8355. 0.1145 s / img. ETA=0:12:46
[32m[04/28 10:25:34 d2.evaluation.evaluator]: [0mInference done 1800/8355. 0.1145 s / img. ETA=0:12:42
[32m[04/28 10:25:39 d2.evaluation.evaluator]: [0mInference done 1843/8355. 0.1146 s / img. ETA=0:12:37
[32m[04/28 10:25:44 d2.evaluation.evaluator]: [0mInference done 1886/8355. 0.1146 s / img. ETA=0:12:32
[32m[04/28 10:25:49 d2.evaluation.evaluator]: [0mInference done 1929/8355. 0.1146 s / img. ETA=0:12:27
[32m[04/28 10:25:54 d2.evaluation.evaluator]: [0mInference done 1972/8355. 0.1146 s / img. ETA=0:12:22
[32m[04/28 10:25:59 d2.evaluation.evaluator]: [0mInference done 2015/8355. 0.1146 s / img. ETA=0:12:18
[32m[04/28 10:26:04 d2.evaluation.evaluator]: [0mInference done 2058/8355. 0.1146 s / img. ETA=0:12:13
[32m[04/28 10:26:09 d2.evaluation.evaluator]: [0mInference done 2101/8355. 0.1147 s / img. ETA=0:12:08
[32m[04/28 10:26:14 d2.evaluation.evaluator]: [0mInference done 2145/8355. 0.1147 s / img. ETA=0:12:02
[32m[04/28 10:26:19 d2.evaluation.evaluator]: [0mInference done 2188/8355. 0.1147 s / img. ETA=0:11:58
[32m[04/28 10:26:24 d2.evaluation.evaluator]: [0mInference done 2231/8355. 0.1147 s / img. ETA=0:11:53
[32m[04/28 10:26:29 d2.evaluation.evaluator]: [0mInference done 2274/8355. 0.1147 s / img. ETA=0:11:48
[32m[04/28 10:26:35 d2.evaluation.evaluator]: [0mInference done 2317/8355. 0.1147 s / img. ETA=0:11:43
[32m[04/28 10:26:40 d2.evaluation.evaluator]: [0mInference done 2360/8355. 0.1148 s / img. ETA=0:11:38
[32m[04/28 10:26:45 d2.evaluation.evaluator]: [0mInference done 2403/8355. 0.1148 s / img. ETA=0:11:33
[32m[04/28 10:26:50 d2.evaluation.evaluator]: [0mInference done 2446/8355. 0.1148 s / img. ETA=0:11:28
[32m[04/28 10:26:55 d2.evaluation.evaluator]: [0mInference done 2489/8355. 0.1148 s / img. ETA=0:11:23
[32m[04/28 10:27:00 d2.evaluation.evaluator]: [0mInference done 2532/8355. 0.1148 s / img. ETA=0:11:18
[32m[04/28 10:27:05 d2.evaluation.evaluator]: [0mInference done 2575/8355. 0.1148 s / img. ETA=0:11:14
[32m[04/28 10:27:10 d2.evaluation.evaluator]: [0mInference done 2618/8355. 0.1149 s / img. ETA=0:11:09
[32m[04/28 10:27:15 d2.evaluation.evaluator]: [0mInference done 2661/8355. 0.1149 s / img. ETA=0:11:04
[32m[04/28 10:27:20 d2.evaluation.evaluator]: [0mInference done 2704/8355. 0.1149 s / img. ETA=0:10:59
[32m[04/28 10:27:25 d2.evaluation.evaluator]: [0mInference done 2747/8355. 0.1149 s / img. ETA=0:10:54
[32m[04/28 10:27:30 d2.evaluation.evaluator]: [0mInference done 2790/8355. 0.1149 s / img. ETA=0:10:49
[32m[04/28 10:27:35 d2.evaluation.evaluator]: [0mInference done 2833/8355. 0.1149 s / img. ETA=0:10:44
[32m[04/28 10:27:40 d2.evaluation.evaluator]: [0mInference done 2876/8355. 0.1149 s / img. ETA=0:10:39
[32m[04/28 10:27:45 d2.evaluation.evaluator]: [0mInference done 2919/8355. 0.1149 s / img. ETA=0:10:34
[32m[04/28 10:27:50 d2.evaluation.evaluator]: [0mInference done 2962/8355. 0.1149 s / img. ETA=0:10:29
[32m[04/28 10:27:55 d2.evaluation.evaluator]: [0mInference done 3005/8355. 0.1149 s / img. ETA=0:10:24
[32m[04/28 10:28:00 d2.evaluation.evaluator]: [0mInference done 3048/8355. 0.1149 s / img. ETA=0:10:19
[32m[04/28 10:28:05 d2.evaluation.evaluator]: [0mInference done 3091/8355. 0.1150 s / img. ETA=0:10:14
[32m[04/28 10:28:10 d2.evaluation.evaluator]: [0mInference done 3134/8355. 0.1150 s / img. ETA=0:10:09
[32m[04/28 10:28:16 d2.evaluation.evaluator]: [0mInference done 3178/8355. 0.1149 s / img. ETA=0:10:04
[32m[04/28 10:28:21 d2.evaluation.evaluator]: [0mInference done 3222/8355. 0.1149 s / img. ETA=0:09:59
[32m[04/28 10:28:26 d2.evaluation.evaluator]: [0mInference done 3265/8355. 0.1149 s / img. ETA=0:09:54
[32m[04/28 10:28:31 d2.evaluation.evaluator]: [0mInference done 3308/8355. 0.1149 s / img. ETA=0:09:49
[32m[04/28 10:28:36 d2.evaluation.evaluator]: [0mInference done 3352/8355. 0.1149 s / img. ETA=0:09:43
[32m[04/28 10:28:41 d2.evaluation.evaluator]: [0mInference done 3396/8355. 0.1149 s / img. ETA=0:09:38
[32m[04/28 10:28:46 d2.evaluation.evaluator]: [0mInference done 3437/8355. 0.1150 s / img. ETA=0:09:34
[32m[04/28 10:28:51 d2.evaluation.evaluator]: [0mInference done 3480/8355. 0.1150 s / img. ETA=0:09:29
[32m[04/28 10:28:56 d2.evaluation.evaluator]: [0mInference done 3523/8355. 0.1150 s / img. ETA=0:09:24
[32m[04/28 10:29:01 d2.evaluation.evaluator]: [0mInference done 3567/8355. 0.1150 s / img. ETA=0:09:19
[32m[04/28 10:29:06 d2.evaluation.evaluator]: [0mInference done 3610/8355. 0.1150 s / img. ETA=0:09:14
[32m[04/28 10:29:11 d2.evaluation.evaluator]: [0mInference done 3653/8355. 0.1150 s / img. ETA=0:09:09
[32m[04/28 10:29:16 d2.evaluation.evaluator]: [0mInference done 3696/8355. 0.1150 s / img. ETA=0:09:04
[32m[04/28 10:29:21 d2.evaluation.evaluator]: [0mInference done 3739/8355. 0.1150 s / img. ETA=0:08:59
[32m[04/28 10:29:26 d2.evaluation.evaluator]: [0mInference done 3781/8355. 0.1150 s / img. ETA=0:08:54
[32m[04/28 10:29:31 d2.evaluation.evaluator]: [0mInference done 3824/8355. 0.1150 s / img. ETA=0:08:49
[32m[04/28 10:29:36 d2.evaluation.evaluator]: [0mInference done 3867/8355. 0.1150 s / img. ETA=0:08:44
[32m[04/28 10:29:41 d2.evaluation.evaluator]: [0mInference done 3911/8355. 0.1150 s / img. ETA=0:08:38
[32m[04/28 10:29:46 d2.evaluation.evaluator]: [0mInference done 3954/8355. 0.1150 s / img. ETA=0:08:33
[32m[04/28 10:29:51 d2.evaluation.evaluator]: [0mInference done 3997/8355. 0.1150 s / img. ETA=0:08:28
[32m[04/28 10:29:56 d2.evaluation.evaluator]: [0mInference done 4040/8355. 0.1150 s / img. ETA=0:08:23
[32m[04/28 10:30:01 d2.evaluation.evaluator]: [0mInference done 4083/8355. 0.1150 s / img. ETA=0:08:18
[32m[04/28 10:30:06 d2.evaluation.evaluator]: [0mInference done 4126/8355. 0.1150 s / img. ETA=0:08:13
[32m[04/28 10:30:11 d2.evaluation.evaluator]: [0mInference done 4169/8355. 0.1150 s / img. ETA=0:08:08
[32m[04/28 10:30:16 d2.evaluation.evaluator]: [0mInference done 4212/8355. 0.1150 s / img. ETA=0:08:03
[32m[04/28 10:30:22 d2.evaluation.evaluator]: [0mInference done 4255/8355. 0.1150 s / img. ETA=0:07:58
[32m[04/28 10:30:27 d2.evaluation.evaluator]: [0mInference done 4299/8355. 0.1150 s / img. ETA=0:07:53
[32m[04/28 10:30:32 d2.evaluation.evaluator]: [0mInference done 4342/8355. 0.1150 s / img. ETA=0:07:48
[32m[04/28 10:30:37 d2.evaluation.evaluator]: [0mInference done 4385/8355. 0.1150 s / img. ETA=0:07:43
[32m[04/28 10:30:42 d2.evaluation.evaluator]: [0mInference done 4428/8355. 0.1150 s / img. ETA=0:07:38
[32m[04/28 10:30:47 d2.evaluation.evaluator]: [0mInference done 4471/8355. 0.1150 s / img. ETA=0:07:33
[32m[04/28 10:30:52 d2.evaluation.evaluator]: [0mInference done 4514/8355. 0.1150 s / img. ETA=0:07:28
[32m[04/28 10:30:57 d2.evaluation.evaluator]: [0mInference done 4557/8355. 0.1150 s / img. ETA=0:07:23
[32m[04/28 10:31:02 d2.evaluation.evaluator]: [0mInference done 4600/8355. 0.1150 s / img. ETA=0:07:18
[32m[04/28 10:31:07 d2.evaluation.evaluator]: [0mInference done 4643/8355. 0.1150 s / img. ETA=0:07:13
[32m[04/28 10:31:12 d2.evaluation.evaluator]: [0mInference done 4686/8355. 0.1150 s / img. ETA=0:07:08
[32m[04/28 10:31:17 d2.evaluation.evaluator]: [0mInference done 4729/8355. 0.1150 s / img. ETA=0:07:03
[32m[04/28 10:31:22 d2.evaluation.evaluator]: [0mInference done 4772/8355. 0.1150 s / img. ETA=0:06:58
[32m[04/28 10:31:27 d2.evaluation.evaluator]: [0mInference done 4815/8355. 0.1150 s / img. ETA=0:06:53
[32m[04/28 10:31:32 d2.evaluation.evaluator]: [0mInference done 4858/8355. 0.1150 s / img. ETA=0:06:48
[32m[04/28 10:31:37 d2.evaluation.evaluator]: [0mInference done 4901/8355. 0.1150 s / img. ETA=0:06:43
[32m[04/28 10:31:42 d2.evaluation.evaluator]: [0mInference done 4944/8355. 0.1150 s / img. ETA=0:06:38
[32m[04/28 10:31:47 d2.evaluation.evaluator]: [0mInference done 4987/8355. 0.1150 s / img. ETA=0:06:33
[32m[04/28 10:31:52 d2.evaluation.evaluator]: [0mInference done 5030/8355. 0.1150 s / img. ETA=0:06:28
[32m[04/28 10:31:57 d2.evaluation.evaluator]: [0mInference done 5073/8355. 0.1150 s / img. ETA=0:06:23
[32m[04/28 10:32:02 d2.evaluation.evaluator]: [0mInference done 5116/8355. 0.1150 s / img. ETA=0:06:18
[32m[04/28 10:32:07 d2.evaluation.evaluator]: [0mInference done 5159/8355. 0.1150 s / img. ETA=0:06:13
[32m[04/28 10:32:12 d2.evaluation.evaluator]: [0mInference done 5202/8355. 0.1150 s / img. ETA=0:06:08
[32m[04/28 10:32:17 d2.evaluation.evaluator]: [0mInference done 5245/8355. 0.1150 s / img. ETA=0:06:03
[32m[04/28 10:32:22 d2.evaluation.evaluator]: [0mInference done 5288/8355. 0.1150 s / img. ETA=0:05:58
[32m[04/28 10:32:27 d2.evaluation.evaluator]: [0mInference done 5331/8355. 0.1150 s / img. ETA=0:05:53
[32m[04/28 10:32:33 d2.evaluation.evaluator]: [0mInference done 5374/8355. 0.1150 s / img. ETA=0:05:48
[32m[04/28 10:32:38 d2.evaluation.evaluator]: [0mInference done 5417/8355. 0.1150 s / img. ETA=0:05:43
[32m[04/28 10:32:43 d2.evaluation.evaluator]: [0mInference done 5460/8355. 0.1150 s / img. ETA=0:05:38
[32m[04/28 10:32:48 d2.evaluation.evaluator]: [0mInference done 5503/8355. 0.1150 s / img. ETA=0:05:33
[32m[04/28 10:32:53 d2.evaluation.evaluator]: [0mInference done 5547/8355. 0.1150 s / img. ETA=0:05:28
[32m[04/28 10:32:58 d2.evaluation.evaluator]: [0mInference done 5591/8355. 0.1150 s / img. ETA=0:05:22
[32m[04/28 10:33:03 d2.evaluation.evaluator]: [0mInference done 5634/8355. 0.1150 s / img. ETA=0:05:17
[32m[04/28 10:33:08 d2.evaluation.evaluator]: [0mInference done 5677/8355. 0.1150 s / img. ETA=0:05:12
[32m[04/28 10:33:13 d2.evaluation.evaluator]: [0mInference done 5720/8355. 0.1150 s / img. ETA=0:05:07
[32m[04/28 10:33:18 d2.evaluation.evaluator]: [0mInference done 5763/8355. 0.1150 s / img. ETA=0:05:02
[32m[04/28 10:33:23 d2.evaluation.evaluator]: [0mInference done 5806/8355. 0.1150 s / img. ETA=0:04:57
[32m[04/28 10:33:28 d2.evaluation.evaluator]: [0mInference done 5848/8355. 0.1151 s / img. ETA=0:04:53
[32m[04/28 10:33:33 d2.evaluation.evaluator]: [0mInference done 5891/8355. 0.1151 s / img. ETA=0:04:48
[32m[04/28 10:33:38 d2.evaluation.evaluator]: [0mInference done 5934/8355. 0.1151 s / img. ETA=0:04:43
[32m[04/28 10:33:43 d2.evaluation.evaluator]: [0mInference done 5976/8355. 0.1151 s / img. ETA=0:04:38
[32m[04/28 10:33:48 d2.evaluation.evaluator]: [0mInference done 6019/8355. 0.1151 s / img. ETA=0:04:33
[32m[04/28 10:33:53 d2.evaluation.evaluator]: [0mInference done 6062/8355. 0.1151 s / img. ETA=0:04:28
[32m[04/28 10:33:58 d2.evaluation.evaluator]: [0mInference done 6104/8355. 0.1151 s / img. ETA=0:04:23
[32m[04/28 10:34:04 d2.evaluation.evaluator]: [0mInference done 6147/8355. 0.1151 s / img. ETA=0:04:18
[32m[04/28 10:34:09 d2.evaluation.evaluator]: [0mInference done 6190/8355. 0.1151 s / img. ETA=0:04:13
[32m[04/28 10:34:14 d2.evaluation.evaluator]: [0mInference done 6233/8355. 0.1151 s / img. ETA=0:04:08
[32m[04/28 10:34:19 d2.evaluation.evaluator]: [0mInference done 6276/8355. 0.1152 s / img. ETA=0:04:03
[32m[04/28 10:34:24 d2.evaluation.evaluator]: [0mInference done 6319/8355. 0.1152 s / img. ETA=0:03:58
[32m[04/28 10:34:29 d2.evaluation.evaluator]: [0mInference done 6362/8355. 0.1152 s / img. ETA=0:03:53
[32m[04/28 10:34:34 d2.evaluation.evaluator]: [0mInference done 6405/8355. 0.1152 s / img. ETA=0:03:48
[32m[04/28 10:34:39 d2.evaluation.evaluator]: [0mInference done 6448/8355. 0.1152 s / img. ETA=0:03:43
[32m[04/28 10:34:44 d2.evaluation.evaluator]: [0mInference done 6491/8355. 0.1152 s / img. ETA=0:03:38
[32m[04/28 10:34:49 d2.evaluation.evaluator]: [0mInference done 6534/8355. 0.1152 s / img. ETA=0:03:33
[32m[04/28 10:34:54 d2.evaluation.evaluator]: [0mInference done 6577/8355. 0.1152 s / img. ETA=0:03:28
[32m[04/28 10:34:59 d2.evaluation.evaluator]: [0mInference done 6620/8355. 0.1152 s / img. ETA=0:03:23
[32m[04/28 10:35:04 d2.evaluation.evaluator]: [0mInference done 6664/8355. 0.1152 s / img. ETA=0:03:17
[32m[04/28 10:35:09 d2.evaluation.evaluator]: [0mInference done 6708/8355. 0.1152 s / img. ETA=0:03:12
[32m[04/28 10:35:14 d2.evaluation.evaluator]: [0mInference done 6752/8355. 0.1152 s / img. ETA=0:03:07
[32m[04/28 10:35:20 d2.evaluation.evaluator]: [0mInference done 6795/8355. 0.1152 s / img. ETA=0:03:02
[32m[04/28 10:35:25 d2.evaluation.evaluator]: [0mInference done 6838/8355. 0.1152 s / img. ETA=0:02:57
[32m[04/28 10:35:30 d2.evaluation.evaluator]: [0mInference done 6881/8355. 0.1152 s / img. ETA=0:02:52
[32m[04/28 10:35:35 d2.evaluation.evaluator]: [0mInference done 6925/8355. 0.1152 s / img. ETA=0:02:47
[32m[04/28 10:35:40 d2.evaluation.evaluator]: [0mInference done 6968/8355. 0.1152 s / img. ETA=0:02:42
[32m[04/28 10:35:45 d2.evaluation.evaluator]: [0mInference done 7011/8355. 0.1152 s / img. ETA=0:02:37
[32m[04/28 10:35:50 d2.evaluation.evaluator]: [0mInference done 7054/8355. 0.1152 s / img. ETA=0:02:32
[32m[04/28 10:35:55 d2.evaluation.evaluator]: [0mInference done 7097/8355. 0.1152 s / img. ETA=0:02:27
[32m[04/28 10:36:00 d2.evaluation.evaluator]: [0mInference done 7140/8355. 0.1152 s / img. ETA=0:02:22
[32m[04/28 10:36:05 d2.evaluation.evaluator]: [0mInference done 7183/8355. 0.1152 s / img. ETA=0:02:17
[32m[04/28 10:36:10 d2.evaluation.evaluator]: [0mInference done 7226/8355. 0.1152 s / img. ETA=0:02:12
[32m[04/28 10:36:15 d2.evaluation.evaluator]: [0mInference done 7268/8355. 0.1152 s / img. ETA=0:02:07
[32m[04/28 10:36:20 d2.evaluation.evaluator]: [0mInference done 7311/8355. 0.1152 s / img. ETA=0:02:02
[32m[04/28 10:36:25 d2.evaluation.evaluator]: [0mInference done 7353/8355. 0.1152 s / img. ETA=0:01:57
[32m[04/28 10:36:30 d2.evaluation.evaluator]: [0mInference done 7395/8355. 0.1152 s / img. ETA=0:01:52
[32m[04/28 10:36:35 d2.evaluation.evaluator]: [0mInference done 7438/8355. 0.1153 s / img. ETA=0:01:47
[32m[04/28 10:36:40 d2.evaluation.evaluator]: [0mInference done 7480/8355. 0.1153 s / img. ETA=0:01:42
[32m[04/28 10:36:45 d2.evaluation.evaluator]: [0mInference done 7523/8355. 0.1153 s / img. ETA=0:01:37
[32m[04/28 10:36:51 d2.evaluation.evaluator]: [0mInference done 7566/8355. 0.1153 s / img. ETA=0:01:32
[32m[04/28 10:36:56 d2.evaluation.evaluator]: [0mInference done 7609/8355. 0.1153 s / img. ETA=0:01:27
[32m[04/28 10:37:01 d2.evaluation.evaluator]: [0mInference done 7652/8355. 0.1153 s / img. ETA=0:01:22
[32m[04/28 10:37:06 d2.evaluation.evaluator]: [0mInference done 7695/8355. 0.1153 s / img. ETA=0:01:17
[32m[04/28 10:37:11 d2.evaluation.evaluator]: [0mInference done 7737/8355. 0.1153 s / img. ETA=0:01:12
[32m[04/28 10:37:16 d2.evaluation.evaluator]: [0mInference done 7780/8355. 0.1153 s / img. ETA=0:01:07
[32m[04/28 10:37:21 d2.evaluation.evaluator]: [0mInference done 7823/8355. 0.1153 s / img. ETA=0:01:02
[32m[04/28 10:37:26 d2.evaluation.evaluator]: [0mInference done 7866/8355. 0.1153 s / img. ETA=0:00:57
[32m[04/28 10:37:31 d2.evaluation.evaluator]: [0mInference done 7909/8355. 0.1153 s / img. ETA=0:00:52
[32m[04/28 10:37:36 d2.evaluation.evaluator]: [0mInference done 7952/8355. 0.1153 s / img. ETA=0:00:47
[32m[04/28 10:37:41 d2.evaluation.evaluator]: [0mInference done 7995/8355. 0.1153 s / img. ETA=0:00:42
[32m[04/28 10:37:46 d2.evaluation.evaluator]: [0mInference done 8038/8355. 0.1153 s / img. ETA=0:00:37
[32m[04/28 10:37:51 d2.evaluation.evaluator]: [0mInference done 8081/8355. 0.1153 s / img. ETA=0:00:32
[32m[04/28 10:37:56 d2.evaluation.evaluator]: [0mInference done 8124/8355. 0.1153 s / img. ETA=0:00:27
[32m[04/28 10:38:01 d2.evaluation.evaluator]: [0mInference done 8167/8355. 0.1153 s / img. ETA=0:00:22
[32m[04/28 10:38:06 d2.evaluation.evaluator]: [0mInference done 8210/8355. 0.1153 s / img. ETA=0:00:16
[32m[04/28 10:38:11 d2.evaluation.evaluator]: [0mInference done 8253/8355. 0.1153 s / img. ETA=0:00:11
[32m[04/28 10:38:16 d2.evaluation.evaluator]: [0mInference done 8296/8355. 0.1153 s / img. ETA=0:00:06
[32m[04/28 10:38:21 d2.evaluation.evaluator]: [0mInference done 8339/8355. 0.1153 s / img. ETA=0:00:01
[32m[04/28 10:38:23 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:18.152437 (0.117144 s / img per device, on 1 devices)
[32m[04/28 10:38:23 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:02 (0.115302 s / img per device, on 1 devices)
[32m[04/28 10:38:24 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 10:38:24 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 10:38:24 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.55s).
Accumulating evaluation results...
DONE (t=2.14s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.821
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.475
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.363
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.601
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.513
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.438
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.653
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.775
[32m[04/28 10:38:46 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.129 | 82.140 | 47.480 | 36.340 | 60.079 | 73.260 |
[32m[04/28 10:38:46 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 45.131 | bicycle       | 40.154 | car            | 56.103 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 10:38:46 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 10:38:46 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 10:38:46 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 10:38:47 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1150 s / img. ETA=0:02:25
[32m[04/28 10:38:53 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1150 s / img. ETA=0:02:20
[32m[04/28 10:38:58 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1150 s / img. ETA=0:02:15
[32m[04/28 10:39:03 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1149 s / img. ETA=0:02:10
[32m[04/28 10:39:08 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1150 s / img. ETA=0:02:05
[32m[04/28 10:39:13 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1149 s / img. ETA=0:02:00
[32m[04/28 10:39:18 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1150 s / img. ETA=0:01:55
[32m[04/28 10:39:23 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1149 s / img. ETA=0:01:50
[32m[04/28 10:39:28 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1149 s / img. ETA=0:01:45
[32m[04/28 10:39:33 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1149 s / img. ETA=0:01:40
[32m[04/28 10:39:38 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1149 s / img. ETA=0:01:35
[32m[04/28 10:39:43 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1149 s / img. ETA=0:01:30
[32m[04/28 10:39:48 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1149 s / img. ETA=0:01:25
[32m[04/28 10:39:53 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1149 s / img. ETA=0:01:20
[32m[04/28 10:39:58 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1149 s / img. ETA=0:01:15
[32m[04/28 10:40:03 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1149 s / img. ETA=0:01:10
[32m[04/28 10:40:08 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1149 s / img. ETA=0:01:05
[32m[04/28 10:40:13 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1150 s / img. ETA=0:01:00
[32m[04/28 10:40:18 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1149 s / img. ETA=0:00:55
[32m[04/28 10:40:23 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1150 s / img. ETA=0:00:50
[32m[04/28 10:40:28 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1150 s / img. ETA=0:00:45
[32m[04/28 10:40:33 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1151 s / img. ETA=0:00:40
[32m[04/28 10:40:38 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1150 s / img. ETA=0:00:35
[32m[04/28 10:40:43 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1151 s / img. ETA=0:00:30
[32m[04/28 10:40:48 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1151 s / img. ETA=0:00:25
[32m[04/28 10:40:53 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1151 s / img. ETA=0:00:20
[32m[04/28 10:40:58 d2.evaluation.evaluator]: [0mInference done 1128/1257. 0.1152 s / img. ETA=0:00:15
[32m[04/28 10:41:03 d2.evaluation.evaluator]: [0mInference done 1171/1257. 0.1152 s / img. ETA=0:00:10
[32m[04/28 10:41:08 d2.evaluation.evaluator]: [0mInference done 1214/1257. 0.1151 s / img. ETA=0:00:05
[32m[04/28 10:41:13 d2.evaluation.evaluator]: [0mInference done 1257/1257. 0.1152 s / img. ETA=0:00:00
[32m[04/28 10:41:13 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.615622 (0.117105 s / img per device, on 1 devices)
[32m[04/28 10:41:13 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115184 s / img per device, on 1 devices)
[32m[04/28 10:41:13 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 10:41:13 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 10:41:14 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.16s).
Accumulating evaluation results...
DONE (t=0.36s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.380
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.748
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.329
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.272
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.440
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.564
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.449
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.503
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.615
[32m[04/28 10:41:17 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 38.050 | 74.774 | 32.935 | 27.206 | 44.050 | 56.384 |
[32m[04/28 10:41:17 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 38.395 | bicycle       | 21.417 | car            | 54.337 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  15  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 10:41:18 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 10:41:18 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 10:41:18 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 10:41:18 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 10:41:19 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 10:41:19 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 10:41:19 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 10:41:39 d2.utils.events]: [0m eta: 0:16:46  iter: 19  total_loss: 0.593  loss_cls: 0.180  loss_box_reg: 0.335  loss_rpn_cls: 0.012  loss_rpn_loc: 0.056  time: 1.0082  data_time: 0.0183  lr: 0.000100  max_mem: 5397M
[32m[04/28 10:41:59 d2.utils.events]: [0m eta: 0:16:15  iter: 39  total_loss: 0.570  loss_cls: 0.172  loss_box_reg: 0.320  loss_rpn_cls: 0.010  loss_rpn_loc: 0.064  time: 1.0076  data_time: 0.0078  lr: 0.000200  max_mem: 5397M
[32m[04/28 10:42:20 d2.utils.events]: [0m eta: 0:15:49  iter: 59  total_loss: 0.519  loss_cls: 0.169  loss_box_reg: 0.310  loss_rpn_cls: 0.009  loss_rpn_loc: 0.043  time: 1.0100  data_time: 0.0077  lr: 0.000300  max_mem: 5397M
[32m[04/28 10:42:40 d2.utils.events]: [0m eta: 0:15:36  iter: 79  total_loss: 0.564  loss_cls: 0.175  loss_box_reg: 0.316  loss_rpn_cls: 0.008  loss_rpn_loc: 0.047  time: 1.0172  data_time: 0.0077  lr: 0.000400  max_mem: 5397M
[32m[04/28 10:43:01 d2.utils.events]: [0m eta: 0:15:14  iter: 99  total_loss: 0.553  loss_cls: 0.163  loss_box_reg: 0.297  loss_rpn_cls: 0.012  loss_rpn_loc: 0.055  time: 1.0159  data_time: 0.0076  lr: 0.000500  max_mem: 5397M
[32m[04/28 10:43:21 d2.utils.events]: [0m eta: 0:14:57  iter: 119  total_loss: 0.580  loss_cls: 0.176  loss_box_reg: 0.319  loss_rpn_cls: 0.008  loss_rpn_loc: 0.063  time: 1.0149  data_time: 0.0079  lr: 0.000599  max_mem: 5397M
[32m[04/28 10:43:42 d2.utils.events]: [0m eta: 0:14:44  iter: 139  total_loss: 0.553  loss_cls: 0.176  loss_box_reg: 0.325  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 1.0173  data_time: 0.0079  lr: 0.000699  max_mem: 5397M
[32m[04/28 10:44:03 d2.utils.events]: [0m eta: 0:14:30  iter: 159  total_loss: 0.516  loss_cls: 0.156  loss_box_reg: 0.305  loss_rpn_cls: 0.007  loss_rpn_loc: 0.036  time: 1.0221  data_time: 0.0077  lr: 0.000799  max_mem: 5397M
[32m[04/28 10:44:24 d2.utils.events]: [0m eta: 0:14:13  iter: 179  total_loss: 0.444  loss_cls: 0.138  loss_box_reg: 0.274  loss_rpn_cls: 0.006  loss_rpn_loc: 0.034  time: 1.0249  data_time: 0.0078  lr: 0.000899  max_mem: 5397M
[32m[04/28 10:44:44 d2.utils.events]: [0m eta: 0:13:48  iter: 199  total_loss: 0.553  loss_cls: 0.167  loss_box_reg: 0.318  loss_rpn_cls: 0.008  loss_rpn_loc: 0.049  time: 1.0236  data_time: 0.0076  lr: 0.000999  max_mem: 5397M
[32m[04/28 10:45:05 d2.utils.events]: [0m eta: 0:13:26  iter: 219  total_loss: 0.517  loss_cls: 0.148  loss_box_reg: 0.300  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0236  data_time: 0.0078  lr: 0.001099  max_mem: 5397M
[32m[04/28 10:45:25 d2.utils.events]: [0m eta: 0:13:05  iter: 239  total_loss: 0.508  loss_cls: 0.156  loss_box_reg: 0.297  loss_rpn_cls: 0.007  loss_rpn_loc: 0.045  time: 1.0240  data_time: 0.0076  lr: 0.001199  max_mem: 5397M
[32m[04/28 10:45:46 d2.utils.events]: [0m eta: 0:12:46  iter: 259  total_loss: 0.497  loss_cls: 0.153  loss_box_reg: 0.291  loss_rpn_cls: 0.007  loss_rpn_loc: 0.039  time: 1.0252  data_time: 0.0077  lr: 0.001299  max_mem: 5397M
[32m[04/28 10:46:07 d2.utils.events]: [0m eta: 0:12:26  iter: 279  total_loss: 0.480  loss_cls: 0.158  loss_box_reg: 0.284  loss_rpn_cls: 0.005  loss_rpn_loc: 0.042  time: 1.0266  data_time: 0.0079  lr: 0.001399  max_mem: 5397M
[32m[04/28 10:46:27 d2.utils.events]: [0m eta: 0:12:05  iter: 299  total_loss: 0.477  loss_cls: 0.153  loss_box_reg: 0.271  loss_rpn_cls: 0.006  loss_rpn_loc: 0.040  time: 1.0262  data_time: 0.0078  lr: 0.001499  max_mem: 5397M
[32m[04/28 10:46:48 d2.utils.events]: [0m eta: 0:11:44  iter: 319  total_loss: 0.522  loss_cls: 0.164  loss_box_reg: 0.290  loss_rpn_cls: 0.008  loss_rpn_loc: 0.042  time: 1.0268  data_time: 0.0079  lr: 0.001598  max_mem: 5397M
[32m[04/28 10:47:09 d2.utils.events]: [0m eta: 0:11:23  iter: 339  total_loss: 0.498  loss_cls: 0.138  loss_box_reg: 0.297  loss_rpn_cls: 0.010  loss_rpn_loc: 0.040  time: 1.0279  data_time: 0.0079  lr: 0.001698  max_mem: 5397M
[32m[04/28 10:47:30 d2.utils.events]: [0m eta: 0:11:03  iter: 359  total_loss: 0.493  loss_cls: 0.159  loss_box_reg: 0.280  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0275  data_time: 0.0077  lr: 0.001798  max_mem: 5397M
[32m[04/28 10:47:50 d2.utils.events]: [0m eta: 0:10:42  iter: 379  total_loss: 0.544  loss_cls: 0.168  loss_box_reg: 0.330  loss_rpn_cls: 0.008  loss_rpn_loc: 0.045  time: 1.0282  data_time: 0.0075  lr: 0.001898  max_mem: 5397M
[32m[04/28 10:48:11 d2.utils.events]: [0m eta: 0:10:21  iter: 399  total_loss: 0.495  loss_cls: 0.158  loss_box_reg: 0.299  loss_rpn_cls: 0.008  loss_rpn_loc: 0.043  time: 1.0278  data_time: 0.0076  lr: 0.001998  max_mem: 5397M
[32m[04/28 10:48:32 d2.utils.events]: [0m eta: 0:10:01  iter: 419  total_loss: 0.521  loss_cls: 0.155  loss_box_reg: 0.304  loss_rpn_cls: 0.006  loss_rpn_loc: 0.051  time: 1.0289  data_time: 0.0077  lr: 0.002098  max_mem: 5397M
[32m[04/28 10:48:52 d2.utils.events]: [0m eta: 0:09:40  iter: 439  total_loss: 0.561  loss_cls: 0.173  loss_box_reg: 0.332  loss_rpn_cls: 0.006  loss_rpn_loc: 0.052  time: 1.0285  data_time: 0.0076  lr: 0.002198  max_mem: 5397M
[32m[04/28 10:49:13 d2.utils.events]: [0m eta: 0:09:20  iter: 459  total_loss: 0.461  loss_cls: 0.143  loss_box_reg: 0.264  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0287  data_time: 0.0080  lr: 0.002298  max_mem: 5397M
[32m[04/28 10:49:34 d2.utils.events]: [0m eta: 0:09:01  iter: 479  total_loss: 0.508  loss_cls: 0.164  loss_box_reg: 0.307  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0293  data_time: 0.0078  lr: 0.002398  max_mem: 5397M
[32m[04/28 10:49:55 d2.utils.events]: [0m eta: 0:08:40  iter: 499  total_loss: 0.475  loss_cls: 0.155  loss_box_reg: 0.268  loss_rpn_cls: 0.005  loss_rpn_loc: 0.034  time: 1.0299  data_time: 0.0075  lr: 0.002498  max_mem: 5397M
[32m[04/28 10:50:16 d2.utils.events]: [0m eta: 0:08:20  iter: 519  total_loss: 0.537  loss_cls: 0.166  loss_box_reg: 0.296  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0299  data_time: 0.0077  lr: 0.002597  max_mem: 5397M
[32m[04/28 10:50:36 d2.utils.events]: [0m eta: 0:07:59  iter: 539  total_loss: 0.539  loss_cls: 0.152  loss_box_reg: 0.305  loss_rpn_cls: 0.007  loss_rpn_loc: 0.042  time: 1.0302  data_time: 0.0076  lr: 0.002697  max_mem: 5397M
[32m[04/28 10:50:57 d2.utils.events]: [0m eta: 0:07:39  iter: 559  total_loss: 0.467  loss_cls: 0.145  loss_box_reg: 0.276  loss_rpn_cls: 0.007  loss_rpn_loc: 0.046  time: 1.0309  data_time: 0.0077  lr: 0.002797  max_mem: 5397M
[32m[04/28 10:51:18 d2.utils.events]: [0m eta: 0:07:18  iter: 579  total_loss: 0.487  loss_cls: 0.158  loss_box_reg: 0.278  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 1.0309  data_time: 0.0075  lr: 0.002897  max_mem: 5397M
[32m[04/28 10:51:38 d2.utils.events]: [0m eta: 0:06:57  iter: 599  total_loss: 0.533  loss_cls: 0.168  loss_box_reg: 0.299  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0302  data_time: 0.0076  lr: 0.002997  max_mem: 5397M
[32m[04/28 10:51:59 d2.utils.events]: [0m eta: 0:06:36  iter: 619  total_loss: 0.568  loss_cls: 0.185  loss_box_reg: 0.313  loss_rpn_cls: 0.006  loss_rpn_loc: 0.049  time: 1.0300  data_time: 0.0077  lr: 0.003097  max_mem: 5397M
[32m[04/28 10:52:19 d2.utils.events]: [0m eta: 0:06:15  iter: 639  total_loss: 0.565  loss_cls: 0.168  loss_box_reg: 0.325  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 1.0296  data_time: 0.0077  lr: 0.003197  max_mem: 5397M
[32m[04/28 10:52:40 d2.utils.events]: [0m eta: 0:05:54  iter: 659  total_loss: 0.561  loss_cls: 0.163  loss_box_reg: 0.314  loss_rpn_cls: 0.008  loss_rpn_loc: 0.043  time: 1.0304  data_time: 0.0077  lr: 0.003297  max_mem: 5397M
[32m[04/28 10:53:01 d2.utils.events]: [0m eta: 0:05:33  iter: 679  total_loss: 0.502  loss_cls: 0.146  loss_box_reg: 0.298  loss_rpn_cls: 0.005  loss_rpn_loc: 0.048  time: 1.0303  data_time: 0.0079  lr: 0.003397  max_mem: 5397M
[32m[04/28 10:53:21 d2.utils.events]: [0m eta: 0:05:12  iter: 699  total_loss: 0.570  loss_cls: 0.171  loss_box_reg: 0.336  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 1.0298  data_time: 0.0076  lr: 0.003497  max_mem: 5397M
[32m[04/28 10:53:42 d2.utils.events]: [0m eta: 0:04:52  iter: 719  total_loss: 0.480  loss_cls: 0.153  loss_box_reg: 0.296  loss_rpn_cls: 0.009  loss_rpn_loc: 0.037  time: 1.0297  data_time: 0.0077  lr: 0.003596  max_mem: 5397M
[32m[04/28 10:54:03 d2.utils.events]: [0m eta: 0:04:31  iter: 739  total_loss: 0.494  loss_cls: 0.153  loss_box_reg: 0.285  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 1.0299  data_time: 0.0077  lr: 0.003696  max_mem: 5397M
[32m[04/28 10:54:23 d2.utils.events]: [0m eta: 0:04:10  iter: 759  total_loss: 0.548  loss_cls: 0.172  loss_box_reg: 0.312  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0298  data_time: 0.0075  lr: 0.003796  max_mem: 5397M
[32m[04/28 10:54:44 d2.utils.events]: [0m eta: 0:03:49  iter: 779  total_loss: 0.471  loss_cls: 0.142  loss_box_reg: 0.273  loss_rpn_cls: 0.008  loss_rpn_loc: 0.043  time: 1.0300  data_time: 0.0077  lr: 0.003896  max_mem: 5397M
[32m[04/28 10:55:05 d2.utils.events]: [0m eta: 0:03:29  iter: 799  total_loss: 0.562  loss_cls: 0.176  loss_box_reg: 0.340  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 1.0303  data_time: 0.0076  lr: 0.003996  max_mem: 5397M
[32m[04/28 10:55:26 d2.utils.events]: [0m eta: 0:03:08  iter: 819  total_loss: 0.506  loss_cls: 0.155  loss_box_reg: 0.292  loss_rpn_cls: 0.009  loss_rpn_loc: 0.042  time: 1.0302  data_time: 0.0076  lr: 0.004096  max_mem: 5397M
[32m[04/28 10:55:46 d2.utils.events]: [0m eta: 0:02:47  iter: 839  total_loss: 0.506  loss_cls: 0.157  loss_box_reg: 0.291  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0298  data_time: 0.0075  lr: 0.004196  max_mem: 5397M
[32m[04/28 10:56:06 d2.utils.events]: [0m eta: 0:02:26  iter: 859  total_loss: 0.563  loss_cls: 0.172  loss_box_reg: 0.313  loss_rpn_cls: 0.006  loss_rpn_loc: 0.048  time: 1.0294  data_time: 0.0075  lr: 0.004296  max_mem: 5397M
[32m[04/28 10:56:27 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.531  loss_cls: 0.162  loss_box_reg: 0.312  loss_rpn_cls: 0.008  loss_rpn_loc: 0.052  time: 1.0300  data_time: 0.0077  lr: 0.004396  max_mem: 5397M
[32m[04/28 10:56:48 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.538  loss_cls: 0.175  loss_box_reg: 0.307  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0302  data_time: 0.0076  lr: 0.004496  max_mem: 5397M
[32m[04/28 10:57:09 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.498  loss_cls: 0.164  loss_box_reg: 0.291  loss_rpn_cls: 0.007  loss_rpn_loc: 0.035  time: 1.0306  data_time: 0.0078  lr: 0.004595  max_mem: 5397M
[32m[04/28 10:57:29 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.486  loss_cls: 0.145  loss_box_reg: 0.287  loss_rpn_cls: 0.007  loss_rpn_loc: 0.035  time: 1.0302  data_time: 0.0077  lr: 0.004695  max_mem: 5397M
[32m[04/28 10:57:50 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.492  loss_cls: 0.147  loss_box_reg: 0.285  loss_rpn_cls: 0.008  loss_rpn_loc: 0.040  time: 1.0301  data_time: 0.0077  lr: 0.004795  max_mem: 5397M
[32m[04/28 10:58:11 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.549  loss_cls: 0.171  loss_box_reg: 0.309  loss_rpn_cls: 0.010  loss_rpn_loc: 0.054  time: 1.0302  data_time: 0.0077  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 10:58:34 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 10:58:34 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 10:58:34 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 10:58:34 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.492  loss_cls: 0.148  loss_box_reg: 0.289  loss_rpn_cls: 0.009  loss_rpn_loc: 0.040  time: 1.0304  data_time: 0.0077  lr: 0.004995  max_mem: 5397M
[32m[04/28 10:58:35 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:08 (1.0314 s / it)
[32m[04/28 10:58:35 d2.engine.hooks]: [0mTotal training time: 0:17:13 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 10:58:36 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 10:58:36 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 10:58:36 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 10:58:38 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1153 s / img. ETA=0:16:13
[32m[04/28 10:58:43 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1146 s / img. ETA=0:16:04
[32m[04/28 10:58:48 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1145 s / img. ETA=0:15:59
[32m[04/28 10:58:53 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1145 s / img. ETA=0:15:53
[32m[04/28 10:58:58 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1144 s / img. ETA=0:15:48
[32m[04/28 10:59:03 d2.evaluation.evaluator]: [0mInference done 230/8355. 0.1145 s / img. ETA=0:15:43
[32m[04/28 10:59:08 d2.evaluation.evaluator]: [0mInference done 273/8355. 0.1146 s / img. ETA=0:15:39
[32m[04/28 10:59:13 d2.evaluation.evaluator]: [0mInference done 316/8355. 0.1146 s / img. ETA=0:15:34
[32m[04/28 10:59:18 d2.evaluation.evaluator]: [0mInference done 359/8355. 0.1146 s / img. ETA=0:15:29
[32m[04/28 10:59:23 d2.evaluation.evaluator]: [0mInference done 402/8355. 0.1147 s / img. ETA=0:15:25
[32m[04/28 10:59:28 d2.evaluation.evaluator]: [0mInference done 445/8355. 0.1147 s / img. ETA=0:15:20
[32m[04/28 10:59:33 d2.evaluation.evaluator]: [0mInference done 489/8355. 0.1147 s / img. ETA=0:15:15
[32m[04/28 10:59:38 d2.evaluation.evaluator]: [0mInference done 533/8355. 0.1147 s / img. ETA=0:15:09
[32m[04/28 10:59:43 d2.evaluation.evaluator]: [0mInference done 576/8355. 0.1146 s / img. ETA=0:15:04
[32m[04/28 10:59:48 d2.evaluation.evaluator]: [0mInference done 619/8355. 0.1147 s / img. ETA=0:15:00
[32m[04/28 10:59:53 d2.evaluation.evaluator]: [0mInference done 662/8355. 0.1147 s / img. ETA=0:14:55
[32m[04/28 10:59:58 d2.evaluation.evaluator]: [0mInference done 705/8355. 0.1147 s / img. ETA=0:14:50
[32m[04/28 11:00:04 d2.evaluation.evaluator]: [0mInference done 748/8355. 0.1148 s / img. ETA=0:14:45
[32m[04/28 11:00:09 d2.evaluation.evaluator]: [0mInference done 791/8355. 0.1148 s / img. ETA=0:14:41
[32m[04/28 11:00:14 d2.evaluation.evaluator]: [0mInference done 834/8355. 0.1148 s / img. ETA=0:14:36
[32m[04/28 11:00:19 d2.evaluation.evaluator]: [0mInference done 877/8355. 0.1148 s / img. ETA=0:14:31
[32m[04/28 11:00:24 d2.evaluation.evaluator]: [0mInference done 920/8355. 0.1149 s / img. ETA=0:14:26
[32m[04/28 11:00:29 d2.evaluation.evaluator]: [0mInference done 963/8355. 0.1149 s / img. ETA=0:14:22
[32m[04/28 11:00:34 d2.evaluation.evaluator]: [0mInference done 1006/8355. 0.1149 s / img. ETA=0:14:17
[32m[04/28 11:00:39 d2.evaluation.evaluator]: [0mInference done 1050/8355. 0.1149 s / img. ETA=0:14:11
[32m[04/28 11:00:44 d2.evaluation.evaluator]: [0mInference done 1093/8355. 0.1150 s / img. ETA=0:14:07
[32m[04/28 11:00:49 d2.evaluation.evaluator]: [0mInference done 1137/8355. 0.1149 s / img. ETA=0:14:01
[32m[04/28 11:00:54 d2.evaluation.evaluator]: [0mInference done 1181/8355. 0.1149 s / img. ETA=0:13:56
[32m[04/28 11:00:59 d2.evaluation.evaluator]: [0mInference done 1224/8355. 0.1149 s / img. ETA=0:13:51
[32m[04/28 11:01:04 d2.evaluation.evaluator]: [0mInference done 1268/8355. 0.1149 s / img. ETA=0:13:46
[32m[04/28 11:01:09 d2.evaluation.evaluator]: [0mInference done 1312/8355. 0.1149 s / img. ETA=0:13:41
[32m[04/28 11:01:14 d2.evaluation.evaluator]: [0mInference done 1356/8355. 0.1149 s / img. ETA=0:13:35
[32m[04/28 11:01:20 d2.evaluation.evaluator]: [0mInference done 1399/8355. 0.1149 s / img. ETA=0:13:31
[32m[04/28 11:01:25 d2.evaluation.evaluator]: [0mInference done 1442/8355. 0.1149 s / img. ETA=0:13:26
[32m[04/28 11:01:30 d2.evaluation.evaluator]: [0mInference done 1485/8355. 0.1149 s / img. ETA=0:13:21
[32m[04/28 11:01:35 d2.evaluation.evaluator]: [0mInference done 1528/8355. 0.1150 s / img. ETA=0:13:16
[32m[04/28 11:01:40 d2.evaluation.evaluator]: [0mInference done 1571/8355. 0.1150 s / img. ETA=0:13:11
[32m[04/28 11:01:45 d2.evaluation.evaluator]: [0mInference done 1614/8355. 0.1150 s / img. ETA=0:13:07
[32m[04/28 11:01:50 d2.evaluation.evaluator]: [0mInference done 1657/8355. 0.1151 s / img. ETA=0:13:02
[32m[04/28 11:01:55 d2.evaluation.evaluator]: [0mInference done 1700/8355. 0.1151 s / img. ETA=0:12:57
[32m[04/28 11:02:00 d2.evaluation.evaluator]: [0mInference done 1743/8355. 0.1151 s / img. ETA=0:12:52
[32m[04/28 11:02:05 d2.evaluation.evaluator]: [0mInference done 1786/8355. 0.1152 s / img. ETA=0:12:47
[32m[04/28 11:02:10 d2.evaluation.evaluator]: [0mInference done 1829/8355. 0.1152 s / img. ETA=0:12:43
[32m[04/28 11:02:15 d2.evaluation.evaluator]: [0mInference done 1872/8355. 0.1152 s / img. ETA=0:12:38
[32m[04/28 11:02:20 d2.evaluation.evaluator]: [0mInference done 1915/8355. 0.1153 s / img. ETA=0:12:33
[32m[04/28 11:02:25 d2.evaluation.evaluator]: [0mInference done 1958/8355. 0.1153 s / img. ETA=0:12:28
[32m[04/28 11:02:31 d2.evaluation.evaluator]: [0mInference done 2001/8355. 0.1153 s / img. ETA=0:12:23
[32m[04/28 11:02:36 d2.evaluation.evaluator]: [0mInference done 2044/8355. 0.1153 s / img. ETA=0:12:18
[32m[04/28 11:02:41 d2.evaluation.evaluator]: [0mInference done 2087/8355. 0.1153 s / img. ETA=0:12:13
[32m[04/28 11:02:46 d2.evaluation.evaluator]: [0mInference done 2130/8355. 0.1153 s / img. ETA=0:12:08
[32m[04/28 11:02:51 d2.evaluation.evaluator]: [0mInference done 2173/8355. 0.1153 s / img. ETA=0:12:03
[32m[04/28 11:02:56 d2.evaluation.evaluator]: [0mInference done 2216/8355. 0.1153 s / img. ETA=0:11:58
[32m[04/28 11:03:01 d2.evaluation.evaluator]: [0mInference done 2259/8355. 0.1153 s / img. ETA=0:11:53
[32m[04/28 11:03:06 d2.evaluation.evaluator]: [0mInference done 2302/8355. 0.1154 s / img. ETA=0:11:48
[32m[04/28 11:03:11 d2.evaluation.evaluator]: [0mInference done 2345/8355. 0.1154 s / img. ETA=0:11:43
[32m[04/28 11:03:16 d2.evaluation.evaluator]: [0mInference done 2388/8355. 0.1154 s / img. ETA=0:11:39
[32m[04/28 11:03:21 d2.evaluation.evaluator]: [0mInference done 2431/8355. 0.1154 s / img. ETA=0:11:34
[32m[04/28 11:03:26 d2.evaluation.evaluator]: [0mInference done 2474/8355. 0.1154 s / img. ETA=0:11:29
[32m[04/28 11:03:31 d2.evaluation.evaluator]: [0mInference done 2517/8355. 0.1154 s / img. ETA=0:11:24
[32m[04/28 11:03:36 d2.evaluation.evaluator]: [0mInference done 2560/8355. 0.1154 s / img. ETA=0:11:19
[32m[04/28 11:03:41 d2.evaluation.evaluator]: [0mInference done 2603/8355. 0.1155 s / img. ETA=0:11:14
[32m[04/28 11:03:47 d2.evaluation.evaluator]: [0mInference done 2646/8355. 0.1155 s / img. ETA=0:11:09
[32m[04/28 11:03:52 d2.evaluation.evaluator]: [0mInference done 2689/8355. 0.1155 s / img. ETA=0:11:04
[32m[04/28 11:03:57 d2.evaluation.evaluator]: [0mInference done 2732/8355. 0.1155 s / img. ETA=0:10:59
[32m[04/28 11:04:02 d2.evaluation.evaluator]: [0mInference done 2775/8355. 0.1155 s / img. ETA=0:10:54
[32m[04/28 11:04:07 d2.evaluation.evaluator]: [0mInference done 2818/8355. 0.1155 s / img. ETA=0:10:49
[32m[04/28 11:04:12 d2.evaluation.evaluator]: [0mInference done 2861/8355. 0.1155 s / img. ETA=0:10:44
[32m[04/28 11:04:17 d2.evaluation.evaluator]: [0mInference done 2904/8355. 0.1155 s / img. ETA=0:10:39
[32m[04/28 11:04:22 d2.evaluation.evaluator]: [0mInference done 2947/8355. 0.1155 s / img. ETA=0:10:34
[32m[04/28 11:04:27 d2.evaluation.evaluator]: [0mInference done 2990/8355. 0.1155 s / img. ETA=0:10:29
[32m[04/28 11:04:32 d2.evaluation.evaluator]: [0mInference done 3033/8355. 0.1155 s / img. ETA=0:10:24
[32m[04/28 11:04:37 d2.evaluation.evaluator]: [0mInference done 3076/8355. 0.1155 s / img. ETA=0:10:19
[32m[04/28 11:04:42 d2.evaluation.evaluator]: [0mInference done 3119/8355. 0.1156 s / img. ETA=0:10:14
[32m[04/28 11:04:47 d2.evaluation.evaluator]: [0mInference done 3162/8355. 0.1155 s / img. ETA=0:10:09
[32m[04/28 11:04:52 d2.evaluation.evaluator]: [0mInference done 3206/8355. 0.1155 s / img. ETA=0:10:03
[32m[04/28 11:04:58 d2.evaluation.evaluator]: [0mInference done 3249/8355. 0.1155 s / img. ETA=0:09:58
[32m[04/28 11:05:03 d2.evaluation.evaluator]: [0mInference done 3292/8355. 0.1155 s / img. ETA=0:09:53
[32m[04/28 11:05:08 d2.evaluation.evaluator]: [0mInference done 3335/8355. 0.1155 s / img. ETA=0:09:48
[32m[04/28 11:05:13 d2.evaluation.evaluator]: [0mInference done 3378/8355. 0.1155 s / img. ETA=0:09:43
[32m[04/28 11:05:18 d2.evaluation.evaluator]: [0mInference done 3421/8355. 0.1155 s / img. ETA=0:09:38
[32m[04/28 11:05:23 d2.evaluation.evaluator]: [0mInference done 3464/8355. 0.1155 s / img. ETA=0:09:33
[32m[04/28 11:05:28 d2.evaluation.evaluator]: [0mInference done 3507/8355. 0.1155 s / img. ETA=0:09:28
[32m[04/28 11:05:33 d2.evaluation.evaluator]: [0mInference done 3550/8355. 0.1155 s / img. ETA=0:09:23
[32m[04/28 11:05:38 d2.evaluation.evaluator]: [0mInference done 3593/8355. 0.1155 s / img. ETA=0:09:18
[32m[04/28 11:05:43 d2.evaluation.evaluator]: [0mInference done 3636/8355. 0.1155 s / img. ETA=0:09:13
[32m[04/28 11:05:48 d2.evaluation.evaluator]: [0mInference done 3679/8355. 0.1155 s / img. ETA=0:09:08
[32m[04/28 11:05:53 d2.evaluation.evaluator]: [0mInference done 3722/8355. 0.1155 s / img. ETA=0:09:03
[32m[04/28 11:05:58 d2.evaluation.evaluator]: [0mInference done 3765/8355. 0.1155 s / img. ETA=0:08:58
[32m[04/28 11:06:03 d2.evaluation.evaluator]: [0mInference done 3808/8355. 0.1155 s / img. ETA=0:08:53
[32m[04/28 11:06:08 d2.evaluation.evaluator]: [0mInference done 3851/8355. 0.1155 s / img. ETA=0:08:48
[32m[04/28 11:06:13 d2.evaluation.evaluator]: [0mInference done 3894/8355. 0.1155 s / img. ETA=0:08:43
[32m[04/28 11:06:18 d2.evaluation.evaluator]: [0mInference done 3937/8355. 0.1155 s / img. ETA=0:08:38
[32m[04/28 11:06:23 d2.evaluation.evaluator]: [0mInference done 3980/8355. 0.1155 s / img. ETA=0:08:33
[32m[04/28 11:06:28 d2.evaluation.evaluator]: [0mInference done 4023/8355. 0.1155 s / img. ETA=0:08:28
[32m[04/28 11:06:33 d2.evaluation.evaluator]: [0mInference done 4066/8355. 0.1155 s / img. ETA=0:08:23
[32m[04/28 11:06:38 d2.evaluation.evaluator]: [0mInference done 4109/8355. 0.1155 s / img. ETA=0:08:18
[32m[04/28 11:06:44 d2.evaluation.evaluator]: [0mInference done 4152/8355. 0.1155 s / img. ETA=0:08:13
[32m[04/28 11:06:49 d2.evaluation.evaluator]: [0mInference done 4195/8355. 0.1155 s / img. ETA=0:08:08
[32m[04/28 11:06:54 d2.evaluation.evaluator]: [0mInference done 4238/8355. 0.1155 s / img. ETA=0:08:02
[32m[04/28 11:06:59 d2.evaluation.evaluator]: [0mInference done 4281/8355. 0.1155 s / img. ETA=0:07:57
[32m[04/28 11:07:04 d2.evaluation.evaluator]: [0mInference done 4323/8355. 0.1156 s / img. ETA=0:07:53
[32m[04/28 11:07:09 d2.evaluation.evaluator]: [0mInference done 4366/8355. 0.1156 s / img. ETA=0:07:48
[32m[04/28 11:07:14 d2.evaluation.evaluator]: [0mInference done 4409/8355. 0.1156 s / img. ETA=0:07:42
[32m[04/28 11:07:19 d2.evaluation.evaluator]: [0mInference done 4452/8355. 0.1156 s / img. ETA=0:07:37
[32m[04/28 11:07:24 d2.evaluation.evaluator]: [0mInference done 4495/8355. 0.1156 s / img. ETA=0:07:32
[32m[04/28 11:07:29 d2.evaluation.evaluator]: [0mInference done 4538/8355. 0.1156 s / img. ETA=0:07:27
[32m[04/28 11:07:34 d2.evaluation.evaluator]: [0mInference done 4581/8355. 0.1156 s / img. ETA=0:07:22
[32m[04/28 11:07:39 d2.evaluation.evaluator]: [0mInference done 4624/8355. 0.1156 s / img. ETA=0:07:17
[32m[04/28 11:07:44 d2.evaluation.evaluator]: [0mInference done 4667/8355. 0.1156 s / img. ETA=0:07:12
[32m[04/28 11:07:49 d2.evaluation.evaluator]: [0mInference done 4710/8355. 0.1156 s / img. ETA=0:07:07
[32m[04/28 11:07:54 d2.evaluation.evaluator]: [0mInference done 4753/8355. 0.1156 s / img. ETA=0:07:02
[32m[04/28 11:07:59 d2.evaluation.evaluator]: [0mInference done 4796/8355. 0.1156 s / img. ETA=0:06:57
[32m[04/28 11:08:04 d2.evaluation.evaluator]: [0mInference done 4839/8355. 0.1156 s / img. ETA=0:06:52
[32m[04/28 11:08:09 d2.evaluation.evaluator]: [0mInference done 4882/8355. 0.1156 s / img. ETA=0:06:47
[32m[04/28 11:08:14 d2.evaluation.evaluator]: [0mInference done 4925/8355. 0.1156 s / img. ETA=0:06:42
[32m[04/28 11:08:19 d2.evaluation.evaluator]: [0mInference done 4968/8355. 0.1156 s / img. ETA=0:06:37
[32m[04/28 11:08:24 d2.evaluation.evaluator]: [0mInference done 5011/8355. 0.1156 s / img. ETA=0:06:32
[32m[04/28 11:08:29 d2.evaluation.evaluator]: [0mInference done 5054/8355. 0.1156 s / img. ETA=0:06:27
[32m[04/28 11:08:35 d2.evaluation.evaluator]: [0mInference done 5097/8355. 0.1156 s / img. ETA=0:06:22
[32m[04/28 11:08:40 d2.evaluation.evaluator]: [0mInference done 5139/8355. 0.1156 s / img. ETA=0:06:17
[32m[04/28 11:08:45 d2.evaluation.evaluator]: [0mInference done 5182/8355. 0.1156 s / img. ETA=0:06:12
[32m[04/28 11:08:50 d2.evaluation.evaluator]: [0mInference done 5225/8355. 0.1156 s / img. ETA=0:06:07
[32m[04/28 11:08:55 d2.evaluation.evaluator]: [0mInference done 5268/8355. 0.1156 s / img. ETA=0:06:02
[32m[04/28 11:09:00 d2.evaluation.evaluator]: [0mInference done 5311/8355. 0.1156 s / img. ETA=0:05:57
[32m[04/28 11:09:05 d2.evaluation.evaluator]: [0mInference done 5354/8355. 0.1156 s / img. ETA=0:05:52
[32m[04/28 11:09:10 d2.evaluation.evaluator]: [0mInference done 5397/8355. 0.1156 s / img. ETA=0:05:47
[32m[04/28 11:09:15 d2.evaluation.evaluator]: [0mInference done 5440/8355. 0.1156 s / img. ETA=0:05:42
[32m[04/28 11:09:20 d2.evaluation.evaluator]: [0mInference done 5483/8355. 0.1156 s / img. ETA=0:05:37
[32m[04/28 11:09:25 d2.evaluation.evaluator]: [0mInference done 5526/8355. 0.1156 s / img. ETA=0:05:32
[32m[04/28 11:09:30 d2.evaluation.evaluator]: [0mInference done 5569/8355. 0.1156 s / img. ETA=0:05:26
[32m[04/28 11:09:35 d2.evaluation.evaluator]: [0mInference done 5612/8355. 0.1156 s / img. ETA=0:05:21
[32m[04/28 11:09:40 d2.evaluation.evaluator]: [0mInference done 5655/8355. 0.1156 s / img. ETA=0:05:16
[32m[04/28 11:09:45 d2.evaluation.evaluator]: [0mInference done 5698/8355. 0.1156 s / img. ETA=0:05:11
[32m[04/28 11:09:50 d2.evaluation.evaluator]: [0mInference done 5741/8355. 0.1156 s / img. ETA=0:05:06
[32m[04/28 11:09:55 d2.evaluation.evaluator]: [0mInference done 5784/8355. 0.1156 s / img. ETA=0:05:01
[32m[04/28 11:10:00 d2.evaluation.evaluator]: [0mInference done 5827/8355. 0.1156 s / img. ETA=0:04:56
[32m[04/28 11:10:05 d2.evaluation.evaluator]: [0mInference done 5870/8355. 0.1156 s / img. ETA=0:04:51
[32m[04/28 11:10:10 d2.evaluation.evaluator]: [0mInference done 5913/8355. 0.1156 s / img. ETA=0:04:46
[32m[04/28 11:10:16 d2.evaluation.evaluator]: [0mInference done 5953/8355. 0.1157 s / img. ETA=0:04:42
[32m[04/28 11:10:21 d2.evaluation.evaluator]: [0mInference done 5996/8355. 0.1157 s / img. ETA=0:04:37
[32m[04/28 11:10:26 d2.evaluation.evaluator]: [0mInference done 6039/8355. 0.1157 s / img. ETA=0:04:32
[32m[04/28 11:10:31 d2.evaluation.evaluator]: [0mInference done 6082/8355. 0.1157 s / img. ETA=0:04:26
[32m[04/28 11:10:36 d2.evaluation.evaluator]: [0mInference done 6125/8355. 0.1157 s / img. ETA=0:04:21
[32m[04/28 11:10:41 d2.evaluation.evaluator]: [0mInference done 6168/8355. 0.1157 s / img. ETA=0:04:16
[32m[04/28 11:10:46 d2.evaluation.evaluator]: [0mInference done 6211/8355. 0.1157 s / img. ETA=0:04:11
[32m[04/28 11:10:51 d2.evaluation.evaluator]: [0mInference done 6254/8355. 0.1157 s / img. ETA=0:04:06
[32m[04/28 11:10:56 d2.evaluation.evaluator]: [0mInference done 6297/8355. 0.1157 s / img. ETA=0:04:01
[32m[04/28 11:11:01 d2.evaluation.evaluator]: [0mInference done 6340/8355. 0.1157 s / img. ETA=0:03:56
[32m[04/28 11:11:06 d2.evaluation.evaluator]: [0mInference done 6383/8355. 0.1157 s / img. ETA=0:03:51
[32m[04/28 11:11:11 d2.evaluation.evaluator]: [0mInference done 6426/8355. 0.1157 s / img. ETA=0:03:46
[32m[04/28 11:11:17 d2.evaluation.evaluator]: [0mInference done 6469/8355. 0.1157 s / img. ETA=0:03:41
[32m[04/28 11:11:22 d2.evaluation.evaluator]: [0mInference done 6512/8355. 0.1157 s / img. ETA=0:03:36
[32m[04/28 11:11:27 d2.evaluation.evaluator]: [0mInference done 6555/8355. 0.1157 s / img. ETA=0:03:31
[32m[04/28 11:11:32 d2.evaluation.evaluator]: [0mInference done 6598/8355. 0.1157 s / img. ETA=0:03:26
[32m[04/28 11:11:37 d2.evaluation.evaluator]: [0mInference done 6641/8355. 0.1157 s / img. ETA=0:03:21
[32m[04/28 11:11:42 d2.evaluation.evaluator]: [0mInference done 6685/8355. 0.1157 s / img. ETA=0:03:16
[32m[04/28 11:11:47 d2.evaluation.evaluator]: [0mInference done 6728/8355. 0.1157 s / img. ETA=0:03:11
[32m[04/28 11:11:52 d2.evaluation.evaluator]: [0mInference done 6772/8355. 0.1157 s / img. ETA=0:03:05
[32m[04/28 11:11:57 d2.evaluation.evaluator]: [0mInference done 6815/8355. 0.1157 s / img. ETA=0:03:00
[32m[04/28 11:12:02 d2.evaluation.evaluator]: [0mInference done 6858/8355. 0.1157 s / img. ETA=0:02:55
[32m[04/28 11:12:07 d2.evaluation.evaluator]: [0mInference done 6901/8355. 0.1157 s / img. ETA=0:02:50
[32m[04/28 11:12:12 d2.evaluation.evaluator]: [0mInference done 6944/8355. 0.1157 s / img. ETA=0:02:45
[32m[04/28 11:12:17 d2.evaluation.evaluator]: [0mInference done 6987/8355. 0.1157 s / img. ETA=0:02:40
[32m[04/28 11:12:22 d2.evaluation.evaluator]: [0mInference done 7030/8355. 0.1157 s / img. ETA=0:02:35
[32m[04/28 11:12:27 d2.evaluation.evaluator]: [0mInference done 7073/8355. 0.1157 s / img. ETA=0:02:30
[32m[04/28 11:12:32 d2.evaluation.evaluator]: [0mInference done 7116/8355. 0.1157 s / img. ETA=0:02:25
[32m[04/28 11:12:37 d2.evaluation.evaluator]: [0mInference done 7158/8355. 0.1157 s / img. ETA=0:02:20
[32m[04/28 11:12:43 d2.evaluation.evaluator]: [0mInference done 7201/8355. 0.1157 s / img. ETA=0:02:15
[32m[04/28 11:12:48 d2.evaluation.evaluator]: [0mInference done 7244/8355. 0.1157 s / img. ETA=0:02:10
[32m[04/28 11:12:53 d2.evaluation.evaluator]: [0mInference done 7287/8355. 0.1157 s / img. ETA=0:02:05
[32m[04/28 11:12:58 d2.evaluation.evaluator]: [0mInference done 7330/8355. 0.1157 s / img. ETA=0:02:00
[32m[04/28 11:13:03 d2.evaluation.evaluator]: [0mInference done 7373/8355. 0.1157 s / img. ETA=0:01:55
[32m[04/28 11:13:08 d2.evaluation.evaluator]: [0mInference done 7416/8355. 0.1158 s / img. ETA=0:01:50
[32m[04/28 11:13:13 d2.evaluation.evaluator]: [0mInference done 7459/8355. 0.1158 s / img. ETA=0:01:45
[32m[04/28 11:13:18 d2.evaluation.evaluator]: [0mInference done 7502/8355. 0.1158 s / img. ETA=0:01:40
[32m[04/28 11:13:23 d2.evaluation.evaluator]: [0mInference done 7545/8355. 0.1158 s / img. ETA=0:01:35
[32m[04/28 11:13:28 d2.evaluation.evaluator]: [0mInference done 7588/8355. 0.1158 s / img. ETA=0:01:30
[32m[04/28 11:13:33 d2.evaluation.evaluator]: [0mInference done 7631/8355. 0.1158 s / img. ETA=0:01:25
[32m[04/28 11:13:38 d2.evaluation.evaluator]: [0mInference done 7674/8355. 0.1158 s / img. ETA=0:01:20
[32m[04/28 11:13:43 d2.evaluation.evaluator]: [0mInference done 7716/8355. 0.1158 s / img. ETA=0:01:15
[32m[04/28 11:13:48 d2.evaluation.evaluator]: [0mInference done 7759/8355. 0.1158 s / img. ETA=0:01:10
[32m[04/28 11:13:54 d2.evaluation.evaluator]: [0mInference done 7802/8355. 0.1158 s / img. ETA=0:01:05
[32m[04/28 11:13:59 d2.evaluation.evaluator]: [0mInference done 7845/8355. 0.1158 s / img. ETA=0:00:59
[32m[04/28 11:14:04 d2.evaluation.evaluator]: [0mInference done 7888/8355. 0.1158 s / img. ETA=0:00:54
[32m[04/28 11:14:09 d2.evaluation.evaluator]: [0mInference done 7931/8355. 0.1158 s / img. ETA=0:00:49
[32m[04/28 11:14:14 d2.evaluation.evaluator]: [0mInference done 7974/8355. 0.1158 s / img. ETA=0:00:44
[32m[04/28 11:14:19 d2.evaluation.evaluator]: [0mInference done 8017/8355. 0.1158 s / img. ETA=0:00:39
[32m[04/28 11:14:24 d2.evaluation.evaluator]: [0mInference done 8060/8355. 0.1158 s / img. ETA=0:00:34
[32m[04/28 11:14:29 d2.evaluation.evaluator]: [0mInference done 8103/8355. 0.1158 s / img. ETA=0:00:29
[32m[04/28 11:14:34 d2.evaluation.evaluator]: [0mInference done 8146/8355. 0.1158 s / img. ETA=0:00:24
[32m[04/28 11:14:39 d2.evaluation.evaluator]: [0mInference done 8189/8355. 0.1158 s / img. ETA=0:00:19
[32m[04/28 11:14:44 d2.evaluation.evaluator]: [0mInference done 8232/8355. 0.1158 s / img. ETA=0:00:14
[32m[04/28 11:14:49 d2.evaluation.evaluator]: [0mInference done 8275/8355. 0.1158 s / img. ETA=0:00:09
[32m[04/28 11:14:54 d2.evaluation.evaluator]: [0mInference done 8318/8355. 0.1158 s / img. ETA=0:00:04
[32m[04/28 11:14:58 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:21.476230 (0.117542 s / img per device, on 1 devices)
[32m[04/28 11:14:58 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:06 (0.115756 s / img per device, on 1 devices)
[32m[04/28 11:14:59 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 11:14:59 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 11:14:59 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.29s).
Accumulating evaluation results...
DONE (t=2.11s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.822
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.477
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.362
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.609
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.737
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.518
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.434
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.669
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779
[32m[04/28 11:15:21 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.385 | 82.243 | 47.692 | 36.181 | 60.869 | 73.715 |
[32m[04/28 11:15:21 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 46.886 | bicycle       | 39.167 | car            | 56.103 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 11:15:21 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 11:15:21 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 11:15:21 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 11:15:22 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1151 s / img. ETA=0:02:25
[32m[04/28 11:15:27 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1149 s / img. ETA=0:02:20
[32m[04/28 11:15:32 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1150 s / img. ETA=0:02:15
[32m[04/28 11:15:37 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1149 s / img. ETA=0:02:10
[32m[04/28 11:15:42 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1149 s / img. ETA=0:02:05
[32m[04/28 11:15:47 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1149 s / img. ETA=0:02:00
[32m[04/28 11:15:52 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1149 s / img. ETA=0:01:55
[32m[04/28 11:15:57 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1149 s / img. ETA=0:01:50
[32m[04/28 11:16:03 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1149 s / img. ETA=0:01:45
[32m[04/28 11:16:08 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1149 s / img. ETA=0:01:40
[32m[04/28 11:16:13 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1149 s / img. ETA=0:01:35
[32m[04/28 11:16:18 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1149 s / img. ETA=0:01:30
[32m[04/28 11:16:23 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1149 s / img. ETA=0:01:25
[32m[04/28 11:16:28 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1149 s / img. ETA=0:01:20
[32m[04/28 11:16:33 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1149 s / img. ETA=0:01:15
[32m[04/28 11:16:38 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1150 s / img. ETA=0:01:10
[32m[04/28 11:16:43 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1150 s / img. ETA=0:01:05
[32m[04/28 11:16:48 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1150 s / img. ETA=0:01:00
[32m[04/28 11:16:53 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1150 s / img. ETA=0:00:55
[32m[04/28 11:16:58 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1150 s / img. ETA=0:00:50
[32m[04/28 11:17:03 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1151 s / img. ETA=0:00:45
[32m[04/28 11:17:08 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1151 s / img. ETA=0:00:40
[32m[04/28 11:17:13 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1151 s / img. ETA=0:00:35
[32m[04/28 11:17:18 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1151 s / img. ETA=0:00:30
[32m[04/28 11:17:23 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1152 s / img. ETA=0:00:25
[32m[04/28 11:17:28 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1152 s / img. ETA=0:00:20
[32m[04/28 11:17:33 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1152 s / img. ETA=0:00:14
[32m[04/28 11:17:38 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1152 s / img. ETA=0:00:09
[32m[04/28 11:17:43 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1152 s / img. ETA=0:00:04
[32m[04/28 11:17:48 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.645888 (0.117129 s / img per device, on 1 devices)
[32m[04/28 11:17:48 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115239 s / img per device, on 1 devices)
[32m[04/28 11:17:48 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 11:17:48 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 11:17:48 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.89s).
Accumulating evaluation results...
DONE (t=0.36s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.760
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.367
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.294
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.468
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.581
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.470
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.379
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.537
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.642
[32m[04/28 11:17:52 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.197 | 75.992 | 36.701 | 29.437 | 46.817 | 58.054 |
[32m[04/28 11:17:52 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 42.644 | bicycle       | 24.007 | car            | 53.941 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  16  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 11:17:52 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 11:17:53 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 11:17:53 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 11:17:53 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 11:17:53 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 11:17:53 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 11:17:54 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 11:18:14 d2.utils.events]: [0m eta: 0:16:49  iter: 19  total_loss: 0.592  loss_cls: 0.183  loss_box_reg: 0.335  loss_rpn_cls: 0.009  loss_rpn_loc: 0.058  time: 1.0217  data_time: 0.0232  lr: 0.000100  max_mem: 5397M
[32m[04/28 11:18:35 d2.utils.events]: [0m eta: 0:16:48  iter: 39  total_loss: 0.502  loss_cls: 0.165  loss_box_reg: 0.286  loss_rpn_cls: 0.009  loss_rpn_loc: 0.037  time: 1.0368  data_time: 0.0079  lr: 0.000200  max_mem: 5397M
[32m[04/28 11:18:56 d2.utils.events]: [0m eta: 0:16:20  iter: 59  total_loss: 0.510  loss_cls: 0.161  loss_box_reg: 0.292  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0311  data_time: 0.0076  lr: 0.000300  max_mem: 5397M
[32m[04/28 11:19:16 d2.utils.events]: [0m eta: 0:15:59  iter: 79  total_loss: 0.490  loss_cls: 0.152  loss_box_reg: 0.273  loss_rpn_cls: 0.008  loss_rpn_loc: 0.040  time: 1.0301  data_time: 0.0079  lr: 0.000400  max_mem: 5397M
[32m[04/28 11:19:37 d2.utils.events]: [0m eta: 0:15:40  iter: 99  total_loss: 0.540  loss_cls: 0.161  loss_box_reg: 0.305  loss_rpn_cls: 0.006  loss_rpn_loc: 0.056  time: 1.0354  data_time: 0.0078  lr: 0.000500  max_mem: 5397M
[32m[04/28 11:19:58 d2.utils.events]: [0m eta: 0:15:18  iter: 119  total_loss: 0.529  loss_cls: 0.165  loss_box_reg: 0.302  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0353  data_time: 0.0080  lr: 0.000599  max_mem: 5397M
[32m[04/28 11:20:18 d2.utils.events]: [0m eta: 0:14:57  iter: 139  total_loss: 0.516  loss_cls: 0.160  loss_box_reg: 0.288  loss_rpn_cls: 0.008  loss_rpn_loc: 0.046  time: 1.0327  data_time: 0.0076  lr: 0.000699  max_mem: 5397M
[32m[04/28 11:20:39 d2.utils.events]: [0m eta: 0:14:34  iter: 159  total_loss: 0.557  loss_cls: 0.167  loss_box_reg: 0.314  loss_rpn_cls: 0.006  loss_rpn_loc: 0.053  time: 1.0316  data_time: 0.0076  lr: 0.000799  max_mem: 5397M
[32m[04/28 11:20:59 d2.utils.events]: [0m eta: 0:14:10  iter: 179  total_loss: 0.510  loss_cls: 0.167  loss_box_reg: 0.301  loss_rpn_cls: 0.010  loss_rpn_loc: 0.045  time: 1.0292  data_time: 0.0075  lr: 0.000899  max_mem: 5397M
[32m[04/28 11:21:20 d2.utils.events]: [0m eta: 0:13:51  iter: 199  total_loss: 0.488  loss_cls: 0.147  loss_box_reg: 0.296  loss_rpn_cls: 0.004  loss_rpn_loc: 0.036  time: 1.0314  data_time: 0.0078  lr: 0.000999  max_mem: 5397M
[32m[04/28 11:21:41 d2.utils.events]: [0m eta: 0:13:33  iter: 219  total_loss: 0.539  loss_cls: 0.167  loss_box_reg: 0.302  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0325  data_time: 0.0077  lr: 0.001099  max_mem: 5397M
[32m[04/28 11:22:01 d2.utils.events]: [0m eta: 0:13:08  iter: 239  total_loss: 0.428  loss_cls: 0.137  loss_box_reg: 0.243  loss_rpn_cls: 0.007  loss_rpn_loc: 0.036  time: 1.0302  data_time: 0.0076  lr: 0.001199  max_mem: 5397M
[32m[04/28 11:22:22 d2.utils.events]: [0m eta: 0:12:47  iter: 259  total_loss: 0.513  loss_cls: 0.160  loss_box_reg: 0.294  loss_rpn_cls: 0.007  loss_rpn_loc: 0.054  time: 1.0300  data_time: 0.0076  lr: 0.001299  max_mem: 5397M
[32m[04/28 11:22:43 d2.utils.events]: [0m eta: 0:12:27  iter: 279  total_loss: 0.509  loss_cls: 0.155  loss_box_reg: 0.296  loss_rpn_cls: 0.009  loss_rpn_loc: 0.039  time: 1.0297  data_time: 0.0074  lr: 0.001399  max_mem: 5397M
[32m[04/28 11:23:03 d2.utils.events]: [0m eta: 0:12:07  iter: 299  total_loss: 0.541  loss_cls: 0.160  loss_box_reg: 0.302  loss_rpn_cls: 0.010  loss_rpn_loc: 0.056  time: 1.0305  data_time: 0.0077  lr: 0.001499  max_mem: 5397M
[32m[04/28 11:23:24 d2.utils.events]: [0m eta: 0:11:44  iter: 319  total_loss: 0.510  loss_cls: 0.171  loss_box_reg: 0.288  loss_rpn_cls: 0.006  loss_rpn_loc: 0.048  time: 1.0304  data_time: 0.0077  lr: 0.001598  max_mem: 5397M
[32m[04/28 11:23:44 d2.utils.events]: [0m eta: 0:11:24  iter: 339  total_loss: 0.484  loss_cls: 0.150  loss_box_reg: 0.280  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0295  data_time: 0.0075  lr: 0.001698  max_mem: 5397M
[32m[04/28 11:24:05 d2.utils.events]: [0m eta: 0:11:04  iter: 359  total_loss: 0.515  loss_cls: 0.157  loss_box_reg: 0.308  loss_rpn_cls: 0.007  loss_rpn_loc: 0.043  time: 1.0304  data_time: 0.0079  lr: 0.001798  max_mem: 5397M
[32m[04/28 11:24:26 d2.utils.events]: [0m eta: 0:10:43  iter: 379  total_loss: 0.506  loss_cls: 0.150  loss_box_reg: 0.294  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0297  data_time: 0.0077  lr: 0.001898  max_mem: 5397M
[32m[04/28 11:24:46 d2.utils.events]: [0m eta: 0:10:21  iter: 399  total_loss: 0.517  loss_cls: 0.150  loss_box_reg: 0.317  loss_rpn_cls: 0.005  loss_rpn_loc: 0.045  time: 1.0295  data_time: 0.0077  lr: 0.001998  max_mem: 5397M
[32m[04/28 11:25:07 d2.utils.events]: [0m eta: 0:10:01  iter: 419  total_loss: 0.523  loss_cls: 0.142  loss_box_reg: 0.294  loss_rpn_cls: 0.007  loss_rpn_loc: 0.052  time: 1.0300  data_time: 0.0076  lr: 0.002098  max_mem: 5397M
[32m[04/28 11:25:28 d2.utils.events]: [0m eta: 0:09:41  iter: 439  total_loss: 0.523  loss_cls: 0.159  loss_box_reg: 0.291  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0305  data_time: 0.0076  lr: 0.002198  max_mem: 5397M
[32m[04/28 11:25:49 d2.utils.events]: [0m eta: 0:09:20  iter: 459  total_loss: 0.504  loss_cls: 0.150  loss_box_reg: 0.293  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0301  data_time: 0.0077  lr: 0.002298  max_mem: 5397M
[32m[04/28 11:26:09 d2.utils.events]: [0m eta: 0:08:59  iter: 479  total_loss: 0.465  loss_cls: 0.149  loss_box_reg: 0.271  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0298  data_time: 0.0078  lr: 0.002398  max_mem: 5397M
[32m[04/28 11:26:29 d2.utils.events]: [0m eta: 0:08:38  iter: 499  total_loss: 0.526  loss_cls: 0.158  loss_box_reg: 0.309  loss_rpn_cls: 0.008  loss_rpn_loc: 0.049  time: 1.0294  data_time: 0.0075  lr: 0.002498  max_mem: 5397M
[32m[04/28 11:26:50 d2.utils.events]: [0m eta: 0:08:17  iter: 519  total_loss: 0.488  loss_cls: 0.149  loss_box_reg: 0.287  loss_rpn_cls: 0.005  loss_rpn_loc: 0.046  time: 1.0286  data_time: 0.0078  lr: 0.002597  max_mem: 5397M
[32m[04/28 11:27:10 d2.utils.events]: [0m eta: 0:07:56  iter: 539  total_loss: 0.505  loss_cls: 0.153  loss_box_reg: 0.313  loss_rpn_cls: 0.004  loss_rpn_loc: 0.043  time: 1.0280  data_time: 0.0077  lr: 0.002697  max_mem: 5397M
[32m[04/28 11:27:31 d2.utils.events]: [0m eta: 0:07:37  iter: 559  total_loss: 0.456  loss_cls: 0.136  loss_box_reg: 0.279  loss_rpn_cls: 0.006  loss_rpn_loc: 0.036  time: 1.0289  data_time: 0.0077  lr: 0.002797  max_mem: 5397M
[32m[04/28 11:27:51 d2.utils.events]: [0m eta: 0:07:16  iter: 579  total_loss: 0.557  loss_cls: 0.164  loss_box_reg: 0.311  loss_rpn_cls: 0.007  loss_rpn_loc: 0.057  time: 1.0284  data_time: 0.0076  lr: 0.002897  max_mem: 5397M
[32m[04/28 11:28:12 d2.utils.events]: [0m eta: 0:06:55  iter: 599  total_loss: 0.460  loss_cls: 0.138  loss_box_reg: 0.273  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0285  data_time: 0.0078  lr: 0.002997  max_mem: 5397M
[32m[04/28 11:28:33 d2.utils.events]: [0m eta: 0:06:34  iter: 619  total_loss: 0.539  loss_cls: 0.169  loss_box_reg: 0.322  loss_rpn_cls: 0.008  loss_rpn_loc: 0.047  time: 1.0291  data_time: 0.0078  lr: 0.003097  max_mem: 5397M
[32m[04/28 11:28:54 d2.utils.events]: [0m eta: 0:06:13  iter: 639  total_loss: 0.487  loss_cls: 0.152  loss_box_reg: 0.285  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0287  data_time: 0.0077  lr: 0.003197  max_mem: 5397M
[32m[04/28 11:29:14 d2.utils.events]: [0m eta: 0:05:52  iter: 659  total_loss: 0.495  loss_cls: 0.159  loss_box_reg: 0.299  loss_rpn_cls: 0.007  loss_rpn_loc: 0.043  time: 1.0284  data_time: 0.0076  lr: 0.003297  max_mem: 5397M
[32m[04/28 11:29:34 d2.utils.events]: [0m eta: 0:05:31  iter: 679  total_loss: 0.547  loss_cls: 0.161  loss_box_reg: 0.310  loss_rpn_cls: 0.008  loss_rpn_loc: 0.039  time: 1.0280  data_time: 0.0077  lr: 0.003397  max_mem: 5397M
[32m[04/28 11:29:55 d2.utils.events]: [0m eta: 0:05:10  iter: 699  total_loss: 0.511  loss_cls: 0.155  loss_box_reg: 0.303  loss_rpn_cls: 0.007  loss_rpn_loc: 0.045  time: 1.0278  data_time: 0.0077  lr: 0.003497  max_mem: 5397M
[32m[04/28 11:30:15 d2.utils.events]: [0m eta: 0:04:49  iter: 719  total_loss: 0.538  loss_cls: 0.166  loss_box_reg: 0.305  loss_rpn_cls: 0.008  loss_rpn_loc: 0.047  time: 1.0274  data_time: 0.0075  lr: 0.003596  max_mem: 5397M
[32m[04/28 11:30:36 d2.utils.events]: [0m eta: 0:04:29  iter: 739  total_loss: 0.521  loss_cls: 0.168  loss_box_reg: 0.312  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 1.0275  data_time: 0.0078  lr: 0.003696  max_mem: 5397M
[32m[04/28 11:30:57 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.519  loss_cls: 0.162  loss_box_reg: 0.304  loss_rpn_cls: 0.007  loss_rpn_loc: 0.046  time: 1.0282  data_time: 0.0078  lr: 0.003796  max_mem: 5397M
[32m[04/28 11:31:18 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.491  loss_cls: 0.158  loss_box_reg: 0.269  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0282  data_time: 0.0077  lr: 0.003896  max_mem: 5397M
[32m[04/28 11:31:39 d2.utils.events]: [0m eta: 0:03:28  iter: 799  total_loss: 0.528  loss_cls: 0.160  loss_box_reg: 0.301  loss_rpn_cls: 0.007  loss_rpn_loc: 0.039  time: 1.0288  data_time: 0.0077  lr: 0.003996  max_mem: 5397M
[32m[04/28 11:31:59 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.528  loss_cls: 0.152  loss_box_reg: 0.305  loss_rpn_cls: 0.004  loss_rpn_loc: 0.045  time: 1.0286  data_time: 0.0076  lr: 0.004096  max_mem: 5397M
[32m[04/28 11:32:20 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.474  loss_cls: 0.139  loss_box_reg: 0.280  loss_rpn_cls: 0.006  loss_rpn_loc: 0.044  time: 1.0288  data_time: 0.0075  lr: 0.004196  max_mem: 5397M
[32m[04/28 11:32:41 d2.utils.events]: [0m eta: 0:02:26  iter: 859  total_loss: 0.537  loss_cls: 0.173  loss_box_reg: 0.318  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0290  data_time: 0.0077  lr: 0.004296  max_mem: 5397M
[32m[04/28 11:33:01 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.576  loss_cls: 0.164  loss_box_reg: 0.336  loss_rpn_cls: 0.007  loss_rpn_loc: 0.049  time: 1.0292  data_time: 0.0077  lr: 0.004396  max_mem: 5397M
[32m[04/28 11:33:22 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.548  loss_cls: 0.158  loss_box_reg: 0.311  loss_rpn_cls: 0.008  loss_rpn_loc: 0.047  time: 1.0289  data_time: 0.0076  lr: 0.004496  max_mem: 5397M
[32m[04/28 11:33:43 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.509  loss_cls: 0.155  loss_box_reg: 0.295  loss_rpn_cls: 0.007  loss_rpn_loc: 0.042  time: 1.0294  data_time: 0.0079  lr: 0.004595  max_mem: 5397M
[32m[04/28 11:34:03 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.498  loss_cls: 0.158  loss_box_reg: 0.295  loss_rpn_cls: 0.008  loss_rpn_loc: 0.045  time: 1.0293  data_time: 0.0078  lr: 0.004695  max_mem: 5397M
[32m[04/28 11:34:24 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.542  loss_cls: 0.162  loss_box_reg: 0.305  loss_rpn_cls: 0.008  loss_rpn_loc: 0.041  time: 1.0294  data_time: 0.0077  lr: 0.004795  max_mem: 5397M
[32m[04/28 11:34:44 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.495  loss_cls: 0.147  loss_box_reg: 0.294  loss_rpn_cls: 0.006  loss_rpn_loc: 0.052  time: 1.0288  data_time: 0.0076  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 11:35:07 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 11:35:07 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 11:35:07 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 11:35:07 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.536  loss_cls: 0.166  loss_box_reg: 0.300  loss_rpn_cls: 0.010  loss_rpn_loc: 0.048  time: 1.0282  data_time: 0.0076  lr: 0.004995  max_mem: 5397M
[32m[04/28 11:35:07 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:06 (1.0293 s / it)
[32m[04/28 11:35:07 d2.engine.hooks]: [0mTotal training time: 0:17:11 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 11:35:09 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 11:35:09 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 11:35:09 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 11:35:10 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1139 s / img. ETA=0:16:02
[32m[04/28 11:35:16 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1143 s / img. ETA=0:16:02
[32m[04/28 11:35:21 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1140 s / img. ETA=0:15:55
[32m[04/28 11:35:26 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1140 s / img. ETA=0:15:50
[32m[04/28 11:35:31 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1140 s / img. ETA=0:15:44
[32m[04/28 11:35:36 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1140 s / img. ETA=0:15:39
[32m[04/28 11:35:41 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1141 s / img. ETA=0:15:35
[32m[04/28 11:35:46 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1141 s / img. ETA=0:15:30
[32m[04/28 11:35:51 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1141 s / img. ETA=0:15:25
[32m[04/28 11:35:56 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1142 s / img. ETA=0:15:21
[32m[04/28 11:36:01 d2.evaluation.evaluator]: [0mInference done 450/8355. 0.1142 s / img. ETA=0:15:16
[32m[04/28 11:36:06 d2.evaluation.evaluator]: [0mInference done 494/8355. 0.1141 s / img. ETA=0:15:10
[32m[04/28 11:36:11 d2.evaluation.evaluator]: [0mInference done 538/8355. 0.1141 s / img. ETA=0:15:05
[32m[04/28 11:36:16 d2.evaluation.evaluator]: [0mInference done 581/8355. 0.1141 s / img. ETA=0:15:00
[32m[04/28 11:36:22 d2.evaluation.evaluator]: [0mInference done 625/8355. 0.1141 s / img. ETA=0:14:55
[32m[04/28 11:36:27 d2.evaluation.evaluator]: [0mInference done 669/8355. 0.1142 s / img. ETA=0:14:50
[32m[04/28 11:36:32 d2.evaluation.evaluator]: [0mInference done 712/8355. 0.1143 s / img. ETA=0:14:46
[32m[04/28 11:36:37 d2.evaluation.evaluator]: [0mInference done 756/8355. 0.1143 s / img. ETA=0:14:41
[32m[04/28 11:36:42 d2.evaluation.evaluator]: [0mInference done 800/8355. 0.1143 s / img. ETA=0:14:36
[32m[04/28 11:36:47 d2.evaluation.evaluator]: [0mInference done 844/8355. 0.1143 s / img. ETA=0:14:30
[32m[04/28 11:36:52 d2.evaluation.evaluator]: [0mInference done 887/8355. 0.1143 s / img. ETA=0:14:26
[32m[04/28 11:36:57 d2.evaluation.evaluator]: [0mInference done 930/8355. 0.1143 s / img. ETA=0:14:21
[32m[04/28 11:37:02 d2.evaluation.evaluator]: [0mInference done 974/8355. 0.1143 s / img. ETA=0:14:16
[32m[04/28 11:37:07 d2.evaluation.evaluator]: [0mInference done 1017/8355. 0.1143 s / img. ETA=0:14:11
[32m[04/28 11:37:12 d2.evaluation.evaluator]: [0mInference done 1061/8355. 0.1143 s / img. ETA=0:14:06
[32m[04/28 11:37:17 d2.evaluation.evaluator]: [0mInference done 1105/8355. 0.1143 s / img. ETA=0:14:01
[32m[04/28 11:37:22 d2.evaluation.evaluator]: [0mInference done 1148/8355. 0.1143 s / img. ETA=0:13:56
[32m[04/28 11:37:27 d2.evaluation.evaluator]: [0mInference done 1192/8355. 0.1143 s / img. ETA=0:13:51
[32m[04/28 11:37:32 d2.evaluation.evaluator]: [0mInference done 1236/8355. 0.1143 s / img. ETA=0:13:45
[32m[04/28 11:37:38 d2.evaluation.evaluator]: [0mInference done 1280/8355. 0.1142 s / img. ETA=0:13:40
[32m[04/28 11:37:43 d2.evaluation.evaluator]: [0mInference done 1324/8355. 0.1142 s / img. ETA=0:13:35
[32m[04/28 11:37:48 d2.evaluation.evaluator]: [0mInference done 1367/8355. 0.1142 s / img. ETA=0:13:30
[32m[04/28 11:37:53 d2.evaluation.evaluator]: [0mInference done 1411/8355. 0.1142 s / img. ETA=0:13:25
[32m[04/28 11:37:58 d2.evaluation.evaluator]: [0mInference done 1455/8355. 0.1142 s / img. ETA=0:13:20
[32m[04/28 11:38:03 d2.evaluation.evaluator]: [0mInference done 1498/8355. 0.1143 s / img. ETA=0:13:15
[32m[04/28 11:38:08 d2.evaluation.evaluator]: [0mInference done 1541/8355. 0.1143 s / img. ETA=0:13:10
[32m[04/28 11:38:13 d2.evaluation.evaluator]: [0mInference done 1584/8355. 0.1144 s / img. ETA=0:13:06
[32m[04/28 11:38:18 d2.evaluation.evaluator]: [0mInference done 1627/8355. 0.1144 s / img. ETA=0:13:01
[32m[04/28 11:38:23 d2.evaluation.evaluator]: [0mInference done 1670/8355. 0.1145 s / img. ETA=0:12:56
[32m[04/28 11:38:28 d2.evaluation.evaluator]: [0mInference done 1713/8355. 0.1145 s / img. ETA=0:12:52
[32m[04/28 11:38:33 d2.evaluation.evaluator]: [0mInference done 1756/8355. 0.1146 s / img. ETA=0:12:47
[32m[04/28 11:38:38 d2.evaluation.evaluator]: [0mInference done 1799/8355. 0.1146 s / img. ETA=0:12:42
[32m[04/28 11:38:44 d2.evaluation.evaluator]: [0mInference done 1842/8355. 0.1146 s / img. ETA=0:12:38
[32m[04/28 11:38:49 d2.evaluation.evaluator]: [0mInference done 1885/8355. 0.1147 s / img. ETA=0:12:33
[32m[04/28 11:38:54 d2.evaluation.evaluator]: [0mInference done 1928/8355. 0.1147 s / img. ETA=0:12:28
[32m[04/28 11:38:59 d2.evaluation.evaluator]: [0mInference done 1971/8355. 0.1147 s / img. ETA=0:12:23
[32m[04/28 11:39:04 d2.evaluation.evaluator]: [0mInference done 2014/8355. 0.1148 s / img. ETA=0:12:18
[32m[04/28 11:39:09 d2.evaluation.evaluator]: [0mInference done 2057/8355. 0.1148 s / img. ETA=0:12:13
[32m[04/28 11:39:14 d2.evaluation.evaluator]: [0mInference done 2100/8355. 0.1148 s / img. ETA=0:12:08
[32m[04/28 11:39:19 d2.evaluation.evaluator]: [0mInference done 2143/8355. 0.1148 s / img. ETA=0:12:03
[32m[04/28 11:39:24 d2.evaluation.evaluator]: [0mInference done 2186/8355. 0.1148 s / img. ETA=0:11:58
[32m[04/28 11:39:29 d2.evaluation.evaluator]: [0mInference done 2229/8355. 0.1148 s / img. ETA=0:11:54
[32m[04/28 11:39:34 d2.evaluation.evaluator]: [0mInference done 2272/8355. 0.1148 s / img. ETA=0:11:49
[32m[04/28 11:39:39 d2.evaluation.evaluator]: [0mInference done 2315/8355. 0.1148 s / img. ETA=0:11:44
[32m[04/28 11:39:44 d2.evaluation.evaluator]: [0mInference done 2358/8355. 0.1148 s / img. ETA=0:11:39
[32m[04/28 11:39:49 d2.evaluation.evaluator]: [0mInference done 2401/8355. 0.1149 s / img. ETA=0:11:34
[32m[04/28 11:39:54 d2.evaluation.evaluator]: [0mInference done 2444/8355. 0.1149 s / img. ETA=0:11:29
[32m[04/28 11:39:59 d2.evaluation.evaluator]: [0mInference done 2487/8355. 0.1149 s / img. ETA=0:11:24
[32m[04/28 11:40:04 d2.evaluation.evaluator]: [0mInference done 2530/8355. 0.1149 s / img. ETA=0:11:19
[32m[04/28 11:40:09 d2.evaluation.evaluator]: [0mInference done 2573/8355. 0.1149 s / img. ETA=0:11:14
[32m[04/28 11:40:14 d2.evaluation.evaluator]: [0mInference done 2616/8355. 0.1149 s / img. ETA=0:11:09
[32m[04/28 11:40:19 d2.evaluation.evaluator]: [0mInference done 2659/8355. 0.1149 s / img. ETA=0:11:04
[32m[04/28 11:40:25 d2.evaluation.evaluator]: [0mInference done 2702/8355. 0.1149 s / img. ETA=0:10:59
[32m[04/28 11:40:30 d2.evaluation.evaluator]: [0mInference done 2745/8355. 0.1149 s / img. ETA=0:10:54
[32m[04/28 11:40:35 d2.evaluation.evaluator]: [0mInference done 2788/8355. 0.1150 s / img. ETA=0:10:50
[32m[04/28 11:40:40 d2.evaluation.evaluator]: [0mInference done 2831/8355. 0.1150 s / img. ETA=0:10:45
[32m[04/28 11:40:45 d2.evaluation.evaluator]: [0mInference done 2874/8355. 0.1150 s / img. ETA=0:10:40
[32m[04/28 11:40:50 d2.evaluation.evaluator]: [0mInference done 2917/8355. 0.1150 s / img. ETA=0:10:35
[32m[04/28 11:40:55 d2.evaluation.evaluator]: [0mInference done 2960/8355. 0.1150 s / img. ETA=0:10:30
[32m[04/28 11:41:00 d2.evaluation.evaluator]: [0mInference done 3003/8355. 0.1150 s / img. ETA=0:10:25
[32m[04/28 11:41:05 d2.evaluation.evaluator]: [0mInference done 3046/8355. 0.1150 s / img. ETA=0:10:20
[32m[04/28 11:41:10 d2.evaluation.evaluator]: [0mInference done 3089/8355. 0.1150 s / img. ETA=0:10:15
[32m[04/28 11:41:15 d2.evaluation.evaluator]: [0mInference done 3132/8355. 0.1150 s / img. ETA=0:10:10
[32m[04/28 11:41:20 d2.evaluation.evaluator]: [0mInference done 3176/8355. 0.1150 s / img. ETA=0:10:04
[32m[04/28 11:41:25 d2.evaluation.evaluator]: [0mInference done 3220/8355. 0.1150 s / img. ETA=0:09:59
[32m[04/28 11:41:30 d2.evaluation.evaluator]: [0mInference done 3263/8355. 0.1150 s / img. ETA=0:09:54
[32m[04/28 11:41:35 d2.evaluation.evaluator]: [0mInference done 3306/8355. 0.1150 s / img. ETA=0:09:49
[32m[04/28 11:41:40 d2.evaluation.evaluator]: [0mInference done 3349/8355. 0.1150 s / img. ETA=0:09:44
[32m[04/28 11:41:45 d2.evaluation.evaluator]: [0mInference done 3393/8355. 0.1150 s / img. ETA=0:09:39
[32m[04/28 11:41:50 d2.evaluation.evaluator]: [0mInference done 3436/8355. 0.1150 s / img. ETA=0:09:34
[32m[04/28 11:41:55 d2.evaluation.evaluator]: [0mInference done 3479/8355. 0.1150 s / img. ETA=0:09:29
[32m[04/28 11:42:00 d2.evaluation.evaluator]: [0mInference done 3522/8355. 0.1150 s / img. ETA=0:09:24
[32m[04/28 11:42:05 d2.evaluation.evaluator]: [0mInference done 3565/8355. 0.1150 s / img. ETA=0:09:19
[32m[04/28 11:42:10 d2.evaluation.evaluator]: [0mInference done 3608/8355. 0.1150 s / img. ETA=0:09:14
[32m[04/28 11:42:15 d2.evaluation.evaluator]: [0mInference done 3651/8355. 0.1150 s / img. ETA=0:09:09
[32m[04/28 11:42:21 d2.evaluation.evaluator]: [0mInference done 3694/8355. 0.1150 s / img. ETA=0:09:04
[32m[04/28 11:42:26 d2.evaluation.evaluator]: [0mInference done 3738/8355. 0.1150 s / img. ETA=0:08:59
[32m[04/28 11:42:31 d2.evaluation.evaluator]: [0mInference done 3781/8355. 0.1150 s / img. ETA=0:08:54
[32m[04/28 11:42:36 d2.evaluation.evaluator]: [0mInference done 3824/8355. 0.1150 s / img. ETA=0:08:49
[32m[04/28 11:42:41 d2.evaluation.evaluator]: [0mInference done 3867/8355. 0.1150 s / img. ETA=0:08:44
[32m[04/28 11:42:46 d2.evaluation.evaluator]: [0mInference done 3911/8355. 0.1150 s / img. ETA=0:08:39
[32m[04/28 11:42:51 d2.evaluation.evaluator]: [0mInference done 3954/8355. 0.1150 s / img. ETA=0:08:33
[32m[04/28 11:42:56 d2.evaluation.evaluator]: [0mInference done 3998/8355. 0.1150 s / img. ETA=0:08:28
[32m[04/28 11:43:01 d2.evaluation.evaluator]: [0mInference done 4041/8355. 0.1150 s / img. ETA=0:08:23
[32m[04/28 11:43:06 d2.evaluation.evaluator]: [0mInference done 4084/8355. 0.1150 s / img. ETA=0:08:18
[32m[04/28 11:43:11 d2.evaluation.evaluator]: [0mInference done 4127/8355. 0.1150 s / img. ETA=0:08:13
[32m[04/28 11:43:16 d2.evaluation.evaluator]: [0mInference done 4170/8355. 0.1150 s / img. ETA=0:08:08
[32m[04/28 11:43:21 d2.evaluation.evaluator]: [0mInference done 4213/8355. 0.1150 s / img. ETA=0:08:03
[32m[04/28 11:43:26 d2.evaluation.evaluator]: [0mInference done 4257/8355. 0.1150 s / img. ETA=0:07:58
[32m[04/28 11:43:31 d2.evaluation.evaluator]: [0mInference done 4300/8355. 0.1150 s / img. ETA=0:07:53
[32m[04/28 11:43:36 d2.evaluation.evaluator]: [0mInference done 4343/8355. 0.1150 s / img. ETA=0:07:48
[32m[04/28 11:43:41 d2.evaluation.evaluator]: [0mInference done 4386/8355. 0.1150 s / img. ETA=0:07:43
[32m[04/28 11:43:46 d2.evaluation.evaluator]: [0mInference done 4429/8355. 0.1150 s / img. ETA=0:07:38
[32m[04/28 11:43:51 d2.evaluation.evaluator]: [0mInference done 4472/8355. 0.1150 s / img. ETA=0:07:33
[32m[04/28 11:43:57 d2.evaluation.evaluator]: [0mInference done 4515/8355. 0.1150 s / img. ETA=0:07:28
[32m[04/28 11:44:02 d2.evaluation.evaluator]: [0mInference done 4558/8355. 0.1150 s / img. ETA=0:07:23
[32m[04/28 11:44:07 d2.evaluation.evaluator]: [0mInference done 4601/8355. 0.1150 s / img. ETA=0:07:18
[32m[04/28 11:44:12 d2.evaluation.evaluator]: [0mInference done 4644/8355. 0.1150 s / img. ETA=0:07:13
[32m[04/28 11:44:17 d2.evaluation.evaluator]: [0mInference done 4687/8355. 0.1150 s / img. ETA=0:07:08
[32m[04/28 11:44:22 d2.evaluation.evaluator]: [0mInference done 4730/8355. 0.1150 s / img. ETA=0:07:03
[32m[04/28 11:44:27 d2.evaluation.evaluator]: [0mInference done 4773/8355. 0.1150 s / img. ETA=0:06:58
[32m[04/28 11:44:32 d2.evaluation.evaluator]: [0mInference done 4816/8355. 0.1150 s / img. ETA=0:06:53
[32m[04/28 11:44:37 d2.evaluation.evaluator]: [0mInference done 4859/8355. 0.1150 s / img. ETA=0:06:48
[32m[04/28 11:44:42 d2.evaluation.evaluator]: [0mInference done 4902/8355. 0.1150 s / img. ETA=0:06:43
[32m[04/28 11:44:47 d2.evaluation.evaluator]: [0mInference done 4945/8355. 0.1150 s / img. ETA=0:06:38
[32m[04/28 11:44:52 d2.evaluation.evaluator]: [0mInference done 4988/8355. 0.1150 s / img. ETA=0:06:33
[32m[04/28 11:44:57 d2.evaluation.evaluator]: [0mInference done 5031/8355. 0.1150 s / img. ETA=0:06:28
[32m[04/28 11:45:02 d2.evaluation.evaluator]: [0mInference done 5074/8355. 0.1150 s / img. ETA=0:06:23
[32m[04/28 11:45:07 d2.evaluation.evaluator]: [0mInference done 5117/8355. 0.1150 s / img. ETA=0:06:18
[32m[04/28 11:45:12 d2.evaluation.evaluator]: [0mInference done 5160/8355. 0.1150 s / img. ETA=0:06:13
[32m[04/28 11:45:17 d2.evaluation.evaluator]: [0mInference done 5203/8355. 0.1151 s / img. ETA=0:06:08
[32m[04/28 11:45:22 d2.evaluation.evaluator]: [0mInference done 5246/8355. 0.1151 s / img. ETA=0:06:03
[32m[04/28 11:45:27 d2.evaluation.evaluator]: [0mInference done 5289/8355. 0.1151 s / img. ETA=0:05:58
[32m[04/28 11:45:32 d2.evaluation.evaluator]: [0mInference done 5332/8355. 0.1151 s / img. ETA=0:05:53
[32m[04/28 11:45:37 d2.evaluation.evaluator]: [0mInference done 5375/8355. 0.1151 s / img. ETA=0:05:48
[32m[04/28 11:45:42 d2.evaluation.evaluator]: [0mInference done 5418/8355. 0.1151 s / img. ETA=0:05:43
[32m[04/28 11:45:48 d2.evaluation.evaluator]: [0mInference done 5461/8355. 0.1151 s / img. ETA=0:05:38
[32m[04/28 11:45:53 d2.evaluation.evaluator]: [0mInference done 5504/8355. 0.1151 s / img. ETA=0:05:33
[32m[04/28 11:45:58 d2.evaluation.evaluator]: [0mInference done 5547/8355. 0.1151 s / img. ETA=0:05:28
[32m[04/28 11:46:03 d2.evaluation.evaluator]: [0mInference done 5590/8355. 0.1151 s / img. ETA=0:05:23
[32m[04/28 11:46:08 d2.evaluation.evaluator]: [0mInference done 5633/8355. 0.1151 s / img. ETA=0:05:18
[32m[04/28 11:46:13 d2.evaluation.evaluator]: [0mInference done 5676/8355. 0.1151 s / img. ETA=0:05:13
[32m[04/28 11:46:18 d2.evaluation.evaluator]: [0mInference done 5719/8355. 0.1151 s / img. ETA=0:05:08
[32m[04/28 11:46:23 d2.evaluation.evaluator]: [0mInference done 5762/8355. 0.1151 s / img. ETA=0:05:03
[32m[04/28 11:46:28 d2.evaluation.evaluator]: [0mInference done 5805/8355. 0.1151 s / img. ETA=0:04:58
[32m[04/28 11:46:33 d2.evaluation.evaluator]: [0mInference done 5847/8355. 0.1151 s / img. ETA=0:04:53
[32m[04/28 11:46:38 d2.evaluation.evaluator]: [0mInference done 5890/8355. 0.1151 s / img. ETA=0:04:48
[32m[04/28 11:46:43 d2.evaluation.evaluator]: [0mInference done 5933/8355. 0.1151 s / img. ETA=0:04:43
[32m[04/28 11:46:48 d2.evaluation.evaluator]: [0mInference done 5975/8355. 0.1151 s / img. ETA=0:04:38
[32m[04/28 11:46:53 d2.evaluation.evaluator]: [0mInference done 6017/8355. 0.1152 s / img. ETA=0:04:33
[32m[04/28 11:46:58 d2.evaluation.evaluator]: [0mInference done 6060/8355. 0.1152 s / img. ETA=0:04:28
[32m[04/28 11:47:03 d2.evaluation.evaluator]: [0mInference done 6103/8355. 0.1152 s / img. ETA=0:04:23
[32m[04/28 11:47:08 d2.evaluation.evaluator]: [0mInference done 6146/8355. 0.1152 s / img. ETA=0:04:18
[32m[04/28 11:47:13 d2.evaluation.evaluator]: [0mInference done 6189/8355. 0.1152 s / img. ETA=0:04:13
[32m[04/28 11:47:18 d2.evaluation.evaluator]: [0mInference done 6231/8355. 0.1152 s / img. ETA=0:04:08
[32m[04/28 11:47:23 d2.evaluation.evaluator]: [0mInference done 6274/8355. 0.1152 s / img. ETA=0:04:03
[32m[04/28 11:47:29 d2.evaluation.evaluator]: [0mInference done 6317/8355. 0.1152 s / img. ETA=0:03:58
[32m[04/28 11:47:34 d2.evaluation.evaluator]: [0mInference done 6360/8355. 0.1152 s / img. ETA=0:03:53
[32m[04/28 11:47:39 d2.evaluation.evaluator]: [0mInference done 6403/8355. 0.1152 s / img. ETA=0:03:48
[32m[04/28 11:47:44 d2.evaluation.evaluator]: [0mInference done 6446/8355. 0.1152 s / img. ETA=0:03:43
[32m[04/28 11:47:49 d2.evaluation.evaluator]: [0mInference done 6489/8355. 0.1152 s / img. ETA=0:03:38
[32m[04/28 11:47:54 d2.evaluation.evaluator]: [0mInference done 6532/8355. 0.1152 s / img. ETA=0:03:33
[32m[04/28 11:47:59 d2.evaluation.evaluator]: [0mInference done 6575/8355. 0.1152 s / img. ETA=0:03:28
[32m[04/28 11:48:04 d2.evaluation.evaluator]: [0mInference done 6618/8355. 0.1152 s / img. ETA=0:03:23
[32m[04/28 11:48:09 d2.evaluation.evaluator]: [0mInference done 6662/8355. 0.1152 s / img. ETA=0:03:18
[32m[04/28 11:48:14 d2.evaluation.evaluator]: [0mInference done 6706/8355. 0.1152 s / img. ETA=0:03:13
[32m[04/28 11:48:19 d2.evaluation.evaluator]: [0mInference done 6749/8355. 0.1152 s / img. ETA=0:03:07
[32m[04/28 11:48:24 d2.evaluation.evaluator]: [0mInference done 6793/8355. 0.1152 s / img. ETA=0:03:02
[32m[04/28 11:48:29 d2.evaluation.evaluator]: [0mInference done 6836/8355. 0.1152 s / img. ETA=0:02:57
[32m[04/28 11:48:34 d2.evaluation.evaluator]: [0mInference done 6879/8355. 0.1152 s / img. ETA=0:02:52
[32m[04/28 11:48:39 d2.evaluation.evaluator]: [0mInference done 6922/8355. 0.1152 s / img. ETA=0:02:47
[32m[04/28 11:48:44 d2.evaluation.evaluator]: [0mInference done 6964/8355. 0.1152 s / img. ETA=0:02:42
[32m[04/28 11:48:49 d2.evaluation.evaluator]: [0mInference done 7007/8355. 0.1152 s / img. ETA=0:02:37
[32m[04/28 11:48:54 d2.evaluation.evaluator]: [0mInference done 7050/8355. 0.1152 s / img. ETA=0:02:32
[32m[04/28 11:49:00 d2.evaluation.evaluator]: [0mInference done 7093/8355. 0.1152 s / img. ETA=0:02:27
[32m[04/28 11:49:05 d2.evaluation.evaluator]: [0mInference done 7136/8355. 0.1153 s / img. ETA=0:02:22
[32m[04/28 11:49:10 d2.evaluation.evaluator]: [0mInference done 7179/8355. 0.1153 s / img. ETA=0:02:17
[32m[04/28 11:49:15 d2.evaluation.evaluator]: [0mInference done 7221/8355. 0.1153 s / img. ETA=0:02:12
[32m[04/28 11:49:20 d2.evaluation.evaluator]: [0mInference done 7264/8355. 0.1153 s / img. ETA=0:02:07
[32m[04/28 11:49:25 d2.evaluation.evaluator]: [0mInference done 7307/8355. 0.1153 s / img. ETA=0:02:02
[32m[04/28 11:49:30 d2.evaluation.evaluator]: [0mInference done 7350/8355. 0.1153 s / img. ETA=0:01:57
[32m[04/28 11:49:35 d2.evaluation.evaluator]: [0mInference done 7392/8355. 0.1153 s / img. ETA=0:01:52
[32m[04/28 11:49:40 d2.evaluation.evaluator]: [0mInference done 7435/8355. 0.1153 s / img. ETA=0:01:47
[32m[04/28 11:49:45 d2.evaluation.evaluator]: [0mInference done 7477/8355. 0.1153 s / img. ETA=0:01:42
[32m[04/28 11:49:50 d2.evaluation.evaluator]: [0mInference done 7520/8355. 0.1153 s / img. ETA=0:01:37
[32m[04/28 11:49:55 d2.evaluation.evaluator]: [0mInference done 7563/8355. 0.1153 s / img. ETA=0:01:32
[32m[04/28 11:50:00 d2.evaluation.evaluator]: [0mInference done 7606/8355. 0.1153 s / img. ETA=0:01:27
[32m[04/28 11:50:05 d2.evaluation.evaluator]: [0mInference done 7649/8355. 0.1153 s / img. ETA=0:01:22
[32m[04/28 11:50:10 d2.evaluation.evaluator]: [0mInference done 7692/8355. 0.1153 s / img. ETA=0:01:17
[32m[04/28 11:50:16 d2.evaluation.evaluator]: [0mInference done 7735/8355. 0.1154 s / img. ETA=0:01:12
[32m[04/28 11:50:21 d2.evaluation.evaluator]: [0mInference done 7778/8355. 0.1154 s / img. ETA=0:01:07
[32m[04/28 11:50:26 d2.evaluation.evaluator]: [0mInference done 7821/8355. 0.1154 s / img. ETA=0:01:02
[32m[04/28 11:50:31 d2.evaluation.evaluator]: [0mInference done 7864/8355. 0.1154 s / img. ETA=0:00:57
[32m[04/28 11:50:36 d2.evaluation.evaluator]: [0mInference done 7907/8355. 0.1154 s / img. ETA=0:00:52
[32m[04/28 11:50:41 d2.evaluation.evaluator]: [0mInference done 7950/8355. 0.1154 s / img. ETA=0:00:47
[32m[04/28 11:50:46 d2.evaluation.evaluator]: [0mInference done 7993/8355. 0.1154 s / img. ETA=0:00:42
[32m[04/28 11:50:51 d2.evaluation.evaluator]: [0mInference done 8036/8355. 0.1154 s / img. ETA=0:00:37
[32m[04/28 11:50:56 d2.evaluation.evaluator]: [0mInference done 8079/8355. 0.1154 s / img. ETA=0:00:32
[32m[04/28 11:51:01 d2.evaluation.evaluator]: [0mInference done 8122/8355. 0.1154 s / img. ETA=0:00:27
[32m[04/28 11:51:06 d2.evaluation.evaluator]: [0mInference done 8165/8355. 0.1154 s / img. ETA=0:00:22
[32m[04/28 11:51:11 d2.evaluation.evaluator]: [0mInference done 8208/8355. 0.1154 s / img. ETA=0:00:17
[32m[04/28 11:51:16 d2.evaluation.evaluator]: [0mInference done 8251/8355. 0.1154 s / img. ETA=0:00:12
[32m[04/28 11:51:21 d2.evaluation.evaluator]: [0mInference done 8291/8355. 0.1154 s / img. ETA=0:00:07
[32m[04/28 11:51:26 d2.evaluation.evaluator]: [0mInference done 8334/8355. 0.1154 s / img. ETA=0:00:02
[32m[04/28 11:51:29 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:19.051712 (0.117252 s / img per device, on 1 devices)
[32m[04/28 11:51:29 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:03 (0.115410 s / img per device, on 1 devices)
[32m[04/28 11:51:29 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 11:51:29 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 11:51:29 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.53s).
Accumulating evaluation results...
DONE (t=2.19s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.839
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.482
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.379
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.601
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.712
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.525
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.544
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.456
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.750
[32m[04/28 11:51:52 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.884 | 83.862 | 48.244 | 37.873 | 60.146 | 71.208 |
[32m[04/28 11:51:52 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 47.741 | bicycle       | 38.374 | car            | 57.536 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 11:51:53 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 11:51:53 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 11:51:53 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 11:51:54 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1154 s / img. ETA=0:02:25
[32m[04/28 11:51:59 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1151 s / img. ETA=0:02:20
[32m[04/28 11:52:04 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1151 s / img. ETA=0:02:15
[32m[04/28 11:52:09 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1151 s / img. ETA=0:02:10
[32m[04/28 11:52:14 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1152 s / img. ETA=0:02:05
[32m[04/28 11:52:19 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1151 s / img. ETA=0:02:00
[32m[04/28 11:52:24 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1152 s / img. ETA=0:01:55
[32m[04/28 11:52:29 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1151 s / img. ETA=0:01:50
[32m[04/28 11:52:34 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1151 s / img. ETA=0:01:45
[32m[04/28 11:52:39 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1151 s / img. ETA=0:01:40
[32m[04/28 11:52:44 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1151 s / img. ETA=0:01:35
[32m[04/28 11:52:49 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1150 s / img. ETA=0:01:30
[32m[04/28 11:52:54 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1151 s / img. ETA=0:01:25
[32m[04/28 11:52:59 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1151 s / img. ETA=0:01:20
[32m[04/28 11:53:04 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1151 s / img. ETA=0:01:15
[32m[04/28 11:53:10 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1151 s / img. ETA=0:01:10
[32m[04/28 11:53:15 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1151 s / img. ETA=0:01:05
[32m[04/28 11:53:20 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1151 s / img. ETA=0:01:00
[32m[04/28 11:53:25 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1151 s / img. ETA=0:00:55
[32m[04/28 11:53:30 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1151 s / img. ETA=0:00:50
[32m[04/28 11:53:35 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1152 s / img. ETA=0:00:45
[32m[04/28 11:53:40 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1152 s / img. ETA=0:00:40
[32m[04/28 11:53:45 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1152 s / img. ETA=0:00:35
[32m[04/28 11:53:50 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1153 s / img. ETA=0:00:30
[32m[04/28 11:53:55 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1153 s / img. ETA=0:00:25
[32m[04/28 11:54:00 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1153 s / img. ETA=0:00:20
[32m[04/28 11:54:05 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1153 s / img. ETA=0:00:15
[32m[04/28 11:54:10 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1153 s / img. ETA=0:00:09
[32m[04/28 11:54:15 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1154 s / img. ETA=0:00:04
[32m[04/28 11:54:20 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.825517 (0.117273 s / img per device, on 1 devices)
[32m[04/28 11:54:20 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115368 s / img per device, on 1 devices)
[32m[04/28 11:54:20 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 11:54:20 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 11:54:20 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.10s).
Accumulating evaluation results...
DONE (t=0.38s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.746
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.351
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.291
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.444
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.537
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.461
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.390
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.512
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.601
[32m[04/28 11:54:24 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 38.684 | 74.559 | 35.149 | 29.124 | 44.403 | 53.696 |
[32m[04/28 11:54:24 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 40.956 | bicycle       | 20.514 | car            | 54.582 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  17  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 11:54:25 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 11:54:25 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 11:54:25 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 11:54:25 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 11:54:25 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 11:54:25 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 11:54:25 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 11:54:46 d2.utils.events]: [0m eta: 0:17:15  iter: 19  total_loss: 0.488  loss_cls: 0.146  loss_box_reg: 0.287  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0272  data_time: 0.0197  lr: 0.000100  max_mem: 5397M
[32m[04/28 11:55:06 d2.utils.events]: [0m eta: 0:16:26  iter: 39  total_loss: 0.530  loss_cls: 0.159  loss_box_reg: 0.310  loss_rpn_cls: 0.009  loss_rpn_loc: 0.050  time: 1.0222  data_time: 0.0078  lr: 0.000200  max_mem: 5397M
[32m[04/28 11:55:27 d2.utils.events]: [0m eta: 0:16:16  iter: 59  total_loss: 0.479  loss_cls: 0.149  loss_box_reg: 0.274  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0238  data_time: 0.0078  lr: 0.000300  max_mem: 5397M
[32m[04/28 11:55:47 d2.utils.events]: [0m eta: 0:15:45  iter: 79  total_loss: 0.514  loss_cls: 0.164  loss_box_reg: 0.296  loss_rpn_cls: 0.009  loss_rpn_loc: 0.053  time: 1.0192  data_time: 0.0077  lr: 0.000400  max_mem: 5397M
[32m[04/28 11:56:08 d2.utils.events]: [0m eta: 0:15:41  iter: 99  total_loss: 0.523  loss_cls: 0.163  loss_box_reg: 0.298  loss_rpn_cls: 0.007  loss_rpn_loc: 0.043  time: 1.0262  data_time: 0.0078  lr: 0.000500  max_mem: 5397M
[32m[04/28 11:56:29 d2.utils.events]: [0m eta: 0:15:24  iter: 119  total_loss: 0.428  loss_cls: 0.139  loss_box_reg: 0.263  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0296  data_time: 0.0079  lr: 0.000599  max_mem: 5397M
[32m[04/28 11:56:50 d2.utils.events]: [0m eta: 0:15:03  iter: 139  total_loss: 0.487  loss_cls: 0.149  loss_box_reg: 0.304  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0304  data_time: 0.0077  lr: 0.000699  max_mem: 5397M
[32m[04/28 11:57:11 d2.utils.events]: [0m eta: 0:14:47  iter: 159  total_loss: 0.468  loss_cls: 0.146  loss_box_reg: 0.284  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0337  data_time: 0.0079  lr: 0.000799  max_mem: 5397M
[32m[04/28 11:57:31 d2.utils.events]: [0m eta: 0:14:21  iter: 179  total_loss: 0.476  loss_cls: 0.144  loss_box_reg: 0.284  loss_rpn_cls: 0.007  loss_rpn_loc: 0.037  time: 1.0301  data_time: 0.0078  lr: 0.000899  max_mem: 5397M
[32m[04/28 11:57:51 d2.utils.events]: [0m eta: 0:13:50  iter: 199  total_loss: 0.532  loss_cls: 0.166  loss_box_reg: 0.308  loss_rpn_cls: 0.004  loss_rpn_loc: 0.043  time: 1.0269  data_time: 0.0080  lr: 0.000999  max_mem: 5397M
[32m[04/28 11:58:12 d2.utils.events]: [0m eta: 0:13:29  iter: 219  total_loss: 0.489  loss_cls: 0.149  loss_box_reg: 0.286  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 1.0268  data_time: 0.0077  lr: 0.001099  max_mem: 5397M
[32m[04/28 11:58:33 d2.utils.events]: [0m eta: 0:13:09  iter: 239  total_loss: 0.523  loss_cls: 0.154  loss_box_reg: 0.286  loss_rpn_cls: 0.004  loss_rpn_loc: 0.048  time: 1.0284  data_time: 0.0079  lr: 0.001199  max_mem: 5397M
[32m[04/28 11:58:53 d2.utils.events]: [0m eta: 0:12:48  iter: 259  total_loss: 0.532  loss_cls: 0.163  loss_box_reg: 0.302  loss_rpn_cls: 0.009  loss_rpn_loc: 0.054  time: 1.0278  data_time: 0.0078  lr: 0.001299  max_mem: 5397M
[32m[04/28 11:59:14 d2.utils.events]: [0m eta: 0:12:30  iter: 279  total_loss: 0.540  loss_cls: 0.165  loss_box_reg: 0.308  loss_rpn_cls: 0.006  loss_rpn_loc: 0.050  time: 1.0286  data_time: 0.0077  lr: 0.001399  max_mem: 5397M
[32m[04/28 11:59:35 d2.utils.events]: [0m eta: 0:12:09  iter: 299  total_loss: 0.493  loss_cls: 0.153  loss_box_reg: 0.292  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0279  data_time: 0.0075  lr: 0.001499  max_mem: 5397M
[32m[04/28 11:59:55 d2.utils.events]: [0m eta: 0:11:49  iter: 319  total_loss: 0.478  loss_cls: 0.150  loss_box_reg: 0.284  loss_rpn_cls: 0.004  loss_rpn_loc: 0.048  time: 1.0285  data_time: 0.0079  lr: 0.001598  max_mem: 5397M
[32m[04/28 12:00:16 d2.utils.events]: [0m eta: 0:11:29  iter: 339  total_loss: 0.480  loss_cls: 0.143  loss_box_reg: 0.281  loss_rpn_cls: 0.009  loss_rpn_loc: 0.043  time: 1.0294  data_time: 0.0078  lr: 0.001698  max_mem: 5397M
[32m[04/28 12:00:37 d2.utils.events]: [0m eta: 0:11:07  iter: 359  total_loss: 0.552  loss_cls: 0.166  loss_box_reg: 0.330  loss_rpn_cls: 0.010  loss_rpn_loc: 0.061  time: 1.0285  data_time: 0.0075  lr: 0.001798  max_mem: 5397M
[32m[04/28 12:00:57 d2.utils.events]: [0m eta: 0:10:46  iter: 379  total_loss: 0.535  loss_cls: 0.167  loss_box_reg: 0.324  loss_rpn_cls: 0.005  loss_rpn_loc: 0.057  time: 1.0280  data_time: 0.0075  lr: 0.001898  max_mem: 5397M
[32m[04/28 12:01:18 d2.utils.events]: [0m eta: 0:10:25  iter: 399  total_loss: 0.489  loss_cls: 0.150  loss_box_reg: 0.281  loss_rpn_cls: 0.006  loss_rpn_loc: 0.050  time: 1.0278  data_time: 0.0076  lr: 0.001998  max_mem: 5397M
[32m[04/28 12:01:39 d2.utils.events]: [0m eta: 0:10:05  iter: 419  total_loss: 0.441  loss_cls: 0.149  loss_box_reg: 0.254  loss_rpn_cls: 0.006  loss_rpn_loc: 0.036  time: 1.0304  data_time: 0.0079  lr: 0.002098  max_mem: 5397M
[32m[04/28 12:02:00 d2.utils.events]: [0m eta: 0:09:46  iter: 439  total_loss: 0.448  loss_cls: 0.127  loss_box_reg: 0.269  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0305  data_time: 0.0078  lr: 0.002198  max_mem: 5397M
[32m[04/28 12:02:20 d2.utils.events]: [0m eta: 0:09:24  iter: 459  total_loss: 0.493  loss_cls: 0.155  loss_box_reg: 0.289  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0300  data_time: 0.0075  lr: 0.002298  max_mem: 5397M
[32m[04/28 12:02:41 d2.utils.events]: [0m eta: 0:09:03  iter: 479  total_loss: 0.494  loss_cls: 0.152  loss_box_reg: 0.287  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0302  data_time: 0.0076  lr: 0.002398  max_mem: 5397M
[32m[04/28 12:03:02 d2.utils.events]: [0m eta: 0:08:42  iter: 499  total_loss: 0.575  loss_cls: 0.167  loss_box_reg: 0.331  loss_rpn_cls: 0.007  loss_rpn_loc: 0.049  time: 1.0305  data_time: 0.0078  lr: 0.002498  max_mem: 5397M
[32m[04/28 12:03:23 d2.utils.events]: [0m eta: 0:08:21  iter: 519  total_loss: 0.499  loss_cls: 0.148  loss_box_reg: 0.276  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0304  data_time: 0.0076  lr: 0.002597  max_mem: 5397M
[32m[04/28 12:03:43 d2.utils.events]: [0m eta: 0:08:01  iter: 539  total_loss: 0.541  loss_cls: 0.181  loss_box_reg: 0.317  loss_rpn_cls: 0.009  loss_rpn_loc: 0.046  time: 1.0307  data_time: 0.0076  lr: 0.002697  max_mem: 5397M
[32m[04/28 12:04:04 d2.utils.events]: [0m eta: 0:07:40  iter: 559  total_loss: 0.449  loss_cls: 0.144  loss_box_reg: 0.256  loss_rpn_cls: 0.006  loss_rpn_loc: 0.036  time: 1.0310  data_time: 0.0078  lr: 0.002797  max_mem: 5397M
[32m[04/28 12:04:25 d2.utils.events]: [0m eta: 0:07:20  iter: 579  total_loss: 0.485  loss_cls: 0.153  loss_box_reg: 0.283  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0316  data_time: 0.0076  lr: 0.002897  max_mem: 5397M
[32m[04/28 12:04:46 d2.utils.events]: [0m eta: 0:06:59  iter: 599  total_loss: 0.463  loss_cls: 0.140  loss_box_reg: 0.280  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0318  data_time: 0.0076  lr: 0.002997  max_mem: 5397M
[32m[04/28 12:05:07 d2.utils.events]: [0m eta: 0:06:38  iter: 619  total_loss: 0.606  loss_cls: 0.184  loss_box_reg: 0.336  loss_rpn_cls: 0.009  loss_rpn_loc: 0.059  time: 1.0316  data_time: 0.0078  lr: 0.003097  max_mem: 5397M
[32m[04/28 12:05:28 d2.utils.events]: [0m eta: 0:06:17  iter: 639  total_loss: 0.503  loss_cls: 0.158  loss_box_reg: 0.293  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0320  data_time: 0.0079  lr: 0.003197  max_mem: 5397M
[32m[04/28 12:05:48 d2.utils.events]: [0m eta: 0:05:55  iter: 659  total_loss: 0.496  loss_cls: 0.149  loss_box_reg: 0.302  loss_rpn_cls: 0.007  loss_rpn_loc: 0.038  time: 1.0311  data_time: 0.0079  lr: 0.003297  max_mem: 5397M
[32m[04/28 12:06:08 d2.utils.events]: [0m eta: 0:05:34  iter: 679  total_loss: 0.622  loss_cls: 0.193  loss_box_reg: 0.342  loss_rpn_cls: 0.009  loss_rpn_loc: 0.061  time: 1.0311  data_time: 0.0077  lr: 0.003397  max_mem: 5397M
[32m[04/28 12:06:29 d2.utils.events]: [0m eta: 0:05:13  iter: 699  total_loss: 0.514  loss_cls: 0.152  loss_box_reg: 0.289  loss_rpn_cls: 0.007  loss_rpn_loc: 0.052  time: 1.0308  data_time: 0.0078  lr: 0.003497  max_mem: 5397M
[32m[04/28 12:06:49 d2.utils.events]: [0m eta: 0:04:52  iter: 719  total_loss: 0.535  loss_cls: 0.150  loss_box_reg: 0.311  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0306  data_time: 0.0077  lr: 0.003596  max_mem: 5397M
[32m[04/28 12:07:10 d2.utils.events]: [0m eta: 0:04:32  iter: 739  total_loss: 0.461  loss_cls: 0.150  loss_box_reg: 0.262  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0310  data_time: 0.0079  lr: 0.003696  max_mem: 5397M
[32m[04/28 12:07:31 d2.utils.events]: [0m eta: 0:04:11  iter: 759  total_loss: 0.627  loss_cls: 0.204  loss_box_reg: 0.335  loss_rpn_cls: 0.006  loss_rpn_loc: 0.044  time: 1.0313  data_time: 0.0078  lr: 0.003796  max_mem: 5397M
[32m[04/28 12:07:51 d2.utils.events]: [0m eta: 0:03:50  iter: 779  total_loss: 0.455  loss_cls: 0.132  loss_box_reg: 0.274  loss_rpn_cls: 0.009  loss_rpn_loc: 0.041  time: 1.0308  data_time: 0.0077  lr: 0.003896  max_mem: 5397M
[32m[04/28 12:08:13 d2.utils.events]: [0m eta: 0:03:30  iter: 799  total_loss: 0.485  loss_cls: 0.145  loss_box_reg: 0.294  loss_rpn_cls: 0.007  loss_rpn_loc: 0.042  time: 1.0315  data_time: 0.0079  lr: 0.003996  max_mem: 5397M
[32m[04/28 12:08:33 d2.utils.events]: [0m eta: 0:03:08  iter: 819  total_loss: 0.553  loss_cls: 0.166  loss_box_reg: 0.310  loss_rpn_cls: 0.009  loss_rpn_loc: 0.050  time: 1.0309  data_time: 0.0078  lr: 0.004096  max_mem: 5397M
[32m[04/28 12:08:53 d2.utils.events]: [0m eta: 0:02:48  iter: 839  total_loss: 0.562  loss_cls: 0.171  loss_box_reg: 0.298  loss_rpn_cls: 0.010  loss_rpn_loc: 0.055  time: 1.0308  data_time: 0.0078  lr: 0.004196  max_mem: 5397M
[32m[04/28 12:09:14 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.444  loss_cls: 0.132  loss_box_reg: 0.261  loss_rpn_cls: 0.008  loss_rpn_loc: 0.042  time: 1.0308  data_time: 0.0078  lr: 0.004296  max_mem: 5397M
[32m[04/28 12:09:35 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.561  loss_cls: 0.182  loss_box_reg: 0.304  loss_rpn_cls: 0.011  loss_rpn_loc: 0.061  time: 1.0308  data_time: 0.0078  lr: 0.004396  max_mem: 5397M
[32m[04/28 12:09:56 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.459  loss_cls: 0.144  loss_box_reg: 0.270  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0311  data_time: 0.0078  lr: 0.004496  max_mem: 5397M
[32m[04/28 12:10:16 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.467  loss_cls: 0.145  loss_box_reg: 0.267  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0310  data_time: 0.0077  lr: 0.004595  max_mem: 5397M
[32m[04/28 12:10:37 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.594  loss_cls: 0.176  loss_box_reg: 0.337  loss_rpn_cls: 0.008  loss_rpn_loc: 0.049  time: 1.0312  data_time: 0.0078  lr: 0.004695  max_mem: 5397M
[32m[04/28 12:10:58 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.539  loss_cls: 0.162  loss_box_reg: 0.321  loss_rpn_cls: 0.008  loss_rpn_loc: 0.052  time: 1.0315  data_time: 0.0079  lr: 0.004795  max_mem: 5397M
[32m[04/28 12:11:19 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.522  loss_cls: 0.179  loss_box_reg: 0.277  loss_rpn_cls: 0.006  loss_rpn_loc: 0.049  time: 1.0312  data_time: 0.0079  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 12:11:42 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 12:11:42 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 12:11:42 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 12:11:42 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.517  loss_cls: 0.167  loss_box_reg: 0.297  loss_rpn_cls: 0.007  loss_rpn_loc: 0.049  time: 1.0316  data_time: 0.0078  lr: 0.004995  max_mem: 5397M
[32m[04/28 12:11:43 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:09 (1.0327 s / it)
[32m[04/28 12:11:43 d2.engine.hooks]: [0mTotal training time: 0:17:15 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 12:11:44 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 12:11:44 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 12:11:44 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 12:11:46 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1144 s / img. ETA=0:16:06
[32m[04/28 12:11:51 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1141 s / img. ETA=0:16:00
[32m[04/28 12:11:56 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1140 s / img. ETA=0:15:55
[32m[04/28 12:12:01 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1140 s / img. ETA=0:15:49
[32m[04/28 12:12:06 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1140 s / img. ETA=0:15:44
[32m[04/28 12:12:11 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1140 s / img. ETA=0:15:40
[32m[04/28 12:12:16 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1141 s / img. ETA=0:15:35
[32m[04/28 12:12:22 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1142 s / img. ETA=0:15:30
[32m[04/28 12:12:27 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1142 s / img. ETA=0:15:25
[32m[04/28 12:12:32 d2.evaluation.evaluator]: [0mInference done 406/8355. 0.1142 s / img. ETA=0:15:21
[32m[04/28 12:12:37 d2.evaluation.evaluator]: [0mInference done 449/8355. 0.1143 s / img. ETA=0:15:16
[32m[04/28 12:12:42 d2.evaluation.evaluator]: [0mInference done 493/8355. 0.1142 s / img. ETA=0:15:11
[32m[04/28 12:12:47 d2.evaluation.evaluator]: [0mInference done 537/8355. 0.1142 s / img. ETA=0:15:06
[32m[04/28 12:12:52 d2.evaluation.evaluator]: [0mInference done 581/8355. 0.1142 s / img. ETA=0:15:00
[32m[04/28 12:12:57 d2.evaluation.evaluator]: [0mInference done 624/8355. 0.1142 s / img. ETA=0:14:56
[32m[04/28 12:13:02 d2.evaluation.evaluator]: [0mInference done 667/8355. 0.1143 s / img. ETA=0:14:51
[32m[04/28 12:13:07 d2.evaluation.evaluator]: [0mInference done 710/8355. 0.1143 s / img. ETA=0:14:46
[32m[04/28 12:13:12 d2.evaluation.evaluator]: [0mInference done 753/8355. 0.1144 s / img. ETA=0:14:42
[32m[04/28 12:13:17 d2.evaluation.evaluator]: [0mInference done 796/8355. 0.1144 s / img. ETA=0:14:37
[32m[04/28 12:13:22 d2.evaluation.evaluator]: [0mInference done 840/8355. 0.1144 s / img. ETA=0:14:32
[32m[04/28 12:13:27 d2.evaluation.evaluator]: [0mInference done 884/8355. 0.1144 s / img. ETA=0:14:27
[32m[04/28 12:13:32 d2.evaluation.evaluator]: [0mInference done 927/8355. 0.1145 s / img. ETA=0:14:22
[32m[04/28 12:13:37 d2.evaluation.evaluator]: [0mInference done 970/8355. 0.1145 s / img. ETA=0:14:17
[32m[04/28 12:13:42 d2.evaluation.evaluator]: [0mInference done 1014/8355. 0.1145 s / img. ETA=0:14:12
[32m[04/28 12:13:47 d2.evaluation.evaluator]: [0mInference done 1058/8355. 0.1144 s / img. ETA=0:14:07
[32m[04/28 12:13:53 d2.evaluation.evaluator]: [0mInference done 1102/8355. 0.1144 s / img. ETA=0:14:02
[32m[04/28 12:13:58 d2.evaluation.evaluator]: [0mInference done 1146/8355. 0.1144 s / img. ETA=0:13:57
[32m[04/28 12:14:03 d2.evaluation.evaluator]: [0mInference done 1190/8355. 0.1144 s / img. ETA=0:13:51
[32m[04/28 12:14:08 d2.evaluation.evaluator]: [0mInference done 1234/8355. 0.1144 s / img. ETA=0:13:46
[32m[04/28 12:14:13 d2.evaluation.evaluator]: [0mInference done 1278/8355. 0.1144 s / img. ETA=0:13:41
[32m[04/28 12:14:18 d2.evaluation.evaluator]: [0mInference done 1322/8355. 0.1144 s / img. ETA=0:13:36
[32m[04/28 12:14:23 d2.evaluation.evaluator]: [0mInference done 1365/8355. 0.1144 s / img. ETA=0:13:31
[32m[04/28 12:14:28 d2.evaluation.evaluator]: [0mInference done 1409/8355. 0.1144 s / img. ETA=0:13:26
[32m[04/28 12:14:33 d2.evaluation.evaluator]: [0mInference done 1452/8355. 0.1144 s / img. ETA=0:13:21
[32m[04/28 12:14:38 d2.evaluation.evaluator]: [0mInference done 1495/8355. 0.1144 s / img. ETA=0:13:16
[32m[04/28 12:14:43 d2.evaluation.evaluator]: [0mInference done 1538/8355. 0.1145 s / img. ETA=0:13:12
[32m[04/28 12:14:48 d2.evaluation.evaluator]: [0mInference done 1581/8355. 0.1145 s / img. ETA=0:13:07
[32m[04/28 12:14:53 d2.evaluation.evaluator]: [0mInference done 1623/8355. 0.1146 s / img. ETA=0:13:03
[32m[04/28 12:14:58 d2.evaluation.evaluator]: [0mInference done 1666/8355. 0.1146 s / img. ETA=0:12:58
[32m[04/28 12:15:03 d2.evaluation.evaluator]: [0mInference done 1709/8355. 0.1147 s / img. ETA=0:12:53
[32m[04/28 12:15:09 d2.evaluation.evaluator]: [0mInference done 1752/8355. 0.1147 s / img. ETA=0:12:48
[32m[04/28 12:15:14 d2.evaluation.evaluator]: [0mInference done 1795/8355. 0.1147 s / img. ETA=0:12:43
[32m[04/28 12:15:19 d2.evaluation.evaluator]: [0mInference done 1838/8355. 0.1148 s / img. ETA=0:12:39
[32m[04/28 12:15:24 d2.evaluation.evaluator]: [0mInference done 1881/8355. 0.1148 s / img. ETA=0:12:34
[32m[04/28 12:15:29 d2.evaluation.evaluator]: [0mInference done 1924/8355. 0.1148 s / img. ETA=0:12:29
[32m[04/28 12:15:34 d2.evaluation.evaluator]: [0mInference done 1967/8355. 0.1148 s / img. ETA=0:12:24
[32m[04/28 12:15:39 d2.evaluation.evaluator]: [0mInference done 2010/8355. 0.1148 s / img. ETA=0:12:19
[32m[04/28 12:15:44 d2.evaluation.evaluator]: [0mInference done 2053/8355. 0.1149 s / img. ETA=0:12:14
[32m[04/28 12:15:49 d2.evaluation.evaluator]: [0mInference done 2096/8355. 0.1149 s / img. ETA=0:12:09
[32m[04/28 12:15:54 d2.evaluation.evaluator]: [0mInference done 2139/8355. 0.1149 s / img. ETA=0:12:04
[32m[04/28 12:15:59 d2.evaluation.evaluator]: [0mInference done 2182/8355. 0.1149 s / img. ETA=0:11:59
[32m[04/28 12:16:04 d2.evaluation.evaluator]: [0mInference done 2225/8355. 0.1149 s / img. ETA=0:11:54
[32m[04/28 12:16:09 d2.evaluation.evaluator]: [0mInference done 2268/8355. 0.1149 s / img. ETA=0:11:49
[32m[04/28 12:16:14 d2.evaluation.evaluator]: [0mInference done 2311/8355. 0.1149 s / img. ETA=0:11:45
[32m[04/28 12:16:19 d2.evaluation.evaluator]: [0mInference done 2354/8355. 0.1149 s / img. ETA=0:11:40
[32m[04/28 12:16:24 d2.evaluation.evaluator]: [0mInference done 2397/8355. 0.1149 s / img. ETA=0:11:35
[32m[04/28 12:16:29 d2.evaluation.evaluator]: [0mInference done 2440/8355. 0.1149 s / img. ETA=0:11:30
[32m[04/28 12:16:34 d2.evaluation.evaluator]: [0mInference done 2483/8355. 0.1149 s / img. ETA=0:11:25
[32m[04/28 12:16:39 d2.evaluation.evaluator]: [0mInference done 2526/8355. 0.1149 s / img. ETA=0:11:20
[32m[04/28 12:16:44 d2.evaluation.evaluator]: [0mInference done 2569/8355. 0.1150 s / img. ETA=0:11:15
[32m[04/28 12:16:49 d2.evaluation.evaluator]: [0mInference done 2612/8355. 0.1150 s / img. ETA=0:11:10
[32m[04/28 12:16:54 d2.evaluation.evaluator]: [0mInference done 2655/8355. 0.1150 s / img. ETA=0:11:05
[32m[04/28 12:17:00 d2.evaluation.evaluator]: [0mInference done 2698/8355. 0.1150 s / img. ETA=0:11:00
[32m[04/28 12:17:05 d2.evaluation.evaluator]: [0mInference done 2741/8355. 0.1150 s / img. ETA=0:10:55
[32m[04/28 12:17:10 d2.evaluation.evaluator]: [0mInference done 2784/8355. 0.1150 s / img. ETA=0:10:50
[32m[04/28 12:17:15 d2.evaluation.evaluator]: [0mInference done 2827/8355. 0.1150 s / img. ETA=0:10:45
[32m[04/28 12:17:20 d2.evaluation.evaluator]: [0mInference done 2870/8355. 0.1150 s / img. ETA=0:10:40
[32m[04/28 12:17:25 d2.evaluation.evaluator]: [0mInference done 2913/8355. 0.1150 s / img. ETA=0:10:35
[32m[04/28 12:17:30 d2.evaluation.evaluator]: [0mInference done 2956/8355. 0.1150 s / img. ETA=0:10:30
[32m[04/28 12:17:35 d2.evaluation.evaluator]: [0mInference done 2999/8355. 0.1150 s / img. ETA=0:10:25
[32m[04/28 12:17:40 d2.evaluation.evaluator]: [0mInference done 3042/8355. 0.1150 s / img. ETA=0:10:20
[32m[04/28 12:17:45 d2.evaluation.evaluator]: [0mInference done 3085/8355. 0.1151 s / img. ETA=0:10:15
[32m[04/28 12:17:50 d2.evaluation.evaluator]: [0mInference done 3128/8355. 0.1151 s / img. ETA=0:10:10
[32m[04/28 12:17:55 d2.evaluation.evaluator]: [0mInference done 3171/8355. 0.1151 s / img. ETA=0:10:05
[32m[04/28 12:18:00 d2.evaluation.evaluator]: [0mInference done 3215/8355. 0.1150 s / img. ETA=0:10:00
[32m[04/28 12:18:05 d2.evaluation.evaluator]: [0mInference done 3258/8355. 0.1150 s / img. ETA=0:09:55
[32m[04/28 12:18:10 d2.evaluation.evaluator]: [0mInference done 3302/8355. 0.1150 s / img. ETA=0:09:50
[32m[04/28 12:18:15 d2.evaluation.evaluator]: [0mInference done 3345/8355. 0.1150 s / img. ETA=0:09:45
[32m[04/28 12:18:20 d2.evaluation.evaluator]: [0mInference done 3389/8355. 0.1150 s / img. ETA=0:09:40
[32m[04/28 12:18:25 d2.evaluation.evaluator]: [0mInference done 3432/8355. 0.1150 s / img. ETA=0:09:34
[32m[04/28 12:18:30 d2.evaluation.evaluator]: [0mInference done 3475/8355. 0.1150 s / img. ETA=0:09:29
[32m[04/28 12:18:35 d2.evaluation.evaluator]: [0mInference done 3518/8355. 0.1150 s / img. ETA=0:09:24
[32m[04/28 12:18:40 d2.evaluation.evaluator]: [0mInference done 3561/8355. 0.1150 s / img. ETA=0:09:19
[32m[04/28 12:18:45 d2.evaluation.evaluator]: [0mInference done 3604/8355. 0.1150 s / img. ETA=0:09:14
[32m[04/28 12:18:50 d2.evaluation.evaluator]: [0mInference done 3647/8355. 0.1150 s / img. ETA=0:09:09
[32m[04/28 12:18:56 d2.evaluation.evaluator]: [0mInference done 3690/8355. 0.1150 s / img. ETA=0:09:04
[32m[04/28 12:19:01 d2.evaluation.evaluator]: [0mInference done 3734/8355. 0.1150 s / img. ETA=0:08:59
[32m[04/28 12:19:06 d2.evaluation.evaluator]: [0mInference done 3778/8355. 0.1150 s / img. ETA=0:08:54
[32m[04/28 12:19:11 d2.evaluation.evaluator]: [0mInference done 3821/8355. 0.1150 s / img. ETA=0:08:49
[32m[04/28 12:19:16 d2.evaluation.evaluator]: [0mInference done 3864/8355. 0.1150 s / img. ETA=0:08:44
[32m[04/28 12:19:21 d2.evaluation.evaluator]: [0mInference done 3908/8355. 0.1150 s / img. ETA=0:08:39
[32m[04/28 12:19:26 d2.evaluation.evaluator]: [0mInference done 3951/8355. 0.1150 s / img. ETA=0:08:34
[32m[04/28 12:19:31 d2.evaluation.evaluator]: [0mInference done 3994/8355. 0.1150 s / img. ETA=0:08:29
[32m[04/28 12:19:36 d2.evaluation.evaluator]: [0mInference done 4037/8355. 0.1150 s / img. ETA=0:08:24
[32m[04/28 12:19:41 d2.evaluation.evaluator]: [0mInference done 4080/8355. 0.1150 s / img. ETA=0:08:19
[32m[04/28 12:19:46 d2.evaluation.evaluator]: [0mInference done 4122/8355. 0.1150 s / img. ETA=0:08:14
[32m[04/28 12:19:51 d2.evaluation.evaluator]: [0mInference done 4166/8355. 0.1150 s / img. ETA=0:08:09
[32m[04/28 12:19:56 d2.evaluation.evaluator]: [0mInference done 4209/8355. 0.1150 s / img. ETA=0:08:04
[32m[04/28 12:20:01 d2.evaluation.evaluator]: [0mInference done 4253/8355. 0.1150 s / img. ETA=0:07:59
[32m[04/28 12:20:06 d2.evaluation.evaluator]: [0mInference done 4296/8355. 0.1150 s / img. ETA=0:07:54
[32m[04/28 12:20:11 d2.evaluation.evaluator]: [0mInference done 4339/8355. 0.1150 s / img. ETA=0:07:49
[32m[04/28 12:20:17 d2.evaluation.evaluator]: [0mInference done 4383/8355. 0.1150 s / img. ETA=0:07:43
[32m[04/28 12:20:22 d2.evaluation.evaluator]: [0mInference done 4426/8355. 0.1150 s / img. ETA=0:07:38
[32m[04/28 12:20:27 d2.evaluation.evaluator]: [0mInference done 4469/8355. 0.1150 s / img. ETA=0:07:33
[32m[04/28 12:20:32 d2.evaluation.evaluator]: [0mInference done 4512/8355. 0.1150 s / img. ETA=0:07:28
[32m[04/28 12:20:37 d2.evaluation.evaluator]: [0mInference done 4555/8355. 0.1150 s / img. ETA=0:07:23
[32m[04/28 12:20:42 d2.evaluation.evaluator]: [0mInference done 4598/8355. 0.1150 s / img. ETA=0:07:18
[32m[04/28 12:20:47 d2.evaluation.evaluator]: [0mInference done 4641/8355. 0.1151 s / img. ETA=0:07:13
[32m[04/28 12:20:52 d2.evaluation.evaluator]: [0mInference done 4684/8355. 0.1151 s / img. ETA=0:07:08
[32m[04/28 12:20:57 d2.evaluation.evaluator]: [0mInference done 4727/8355. 0.1151 s / img. ETA=0:07:03
[32m[04/28 12:21:02 d2.evaluation.evaluator]: [0mInference done 4770/8355. 0.1151 s / img. ETA=0:06:58
[32m[04/28 12:21:07 d2.evaluation.evaluator]: [0mInference done 4813/8355. 0.1151 s / img. ETA=0:06:53
[32m[04/28 12:21:12 d2.evaluation.evaluator]: [0mInference done 4856/8355. 0.1151 s / img. ETA=0:06:48
[32m[04/28 12:21:17 d2.evaluation.evaluator]: [0mInference done 4900/8355. 0.1151 s / img. ETA=0:06:43
[32m[04/28 12:21:22 d2.evaluation.evaluator]: [0mInference done 4944/8355. 0.1151 s / img. ETA=0:06:38
[32m[04/28 12:21:27 d2.evaluation.evaluator]: [0mInference done 4987/8355. 0.1151 s / img. ETA=0:06:33
[32m[04/28 12:21:32 d2.evaluation.evaluator]: [0mInference done 5030/8355. 0.1151 s / img. ETA=0:06:28
[32m[04/28 12:21:37 d2.evaluation.evaluator]: [0mInference done 5073/8355. 0.1151 s / img. ETA=0:06:23
[32m[04/28 12:21:42 d2.evaluation.evaluator]: [0mInference done 5116/8355. 0.1151 s / img. ETA=0:06:18
[32m[04/28 12:21:47 d2.evaluation.evaluator]: [0mInference done 5159/8355. 0.1151 s / img. ETA=0:06:13
[32m[04/28 12:21:52 d2.evaluation.evaluator]: [0mInference done 5202/8355. 0.1151 s / img. ETA=0:06:08
[32m[04/28 12:21:58 d2.evaluation.evaluator]: [0mInference done 5245/8355. 0.1151 s / img. ETA=0:06:03
[32m[04/28 12:22:03 d2.evaluation.evaluator]: [0mInference done 5288/8355. 0.1151 s / img. ETA=0:05:58
[32m[04/28 12:22:08 d2.evaluation.evaluator]: [0mInference done 5331/8355. 0.1151 s / img. ETA=0:05:53
[32m[04/28 12:22:13 d2.evaluation.evaluator]: [0mInference done 5374/8355. 0.1151 s / img. ETA=0:05:48
[32m[04/28 12:22:18 d2.evaluation.evaluator]: [0mInference done 5417/8355. 0.1151 s / img. ETA=0:05:43
[32m[04/28 12:22:23 d2.evaluation.evaluator]: [0mInference done 5460/8355. 0.1151 s / img. ETA=0:05:38
[32m[04/28 12:22:28 d2.evaluation.evaluator]: [0mInference done 5503/8355. 0.1151 s / img. ETA=0:05:33
[32m[04/28 12:22:33 d2.evaluation.evaluator]: [0mInference done 5546/8355. 0.1151 s / img. ETA=0:05:28
[32m[04/28 12:22:38 d2.evaluation.evaluator]: [0mInference done 5589/8355. 0.1151 s / img. ETA=0:05:23
[32m[04/28 12:22:43 d2.evaluation.evaluator]: [0mInference done 5632/8355. 0.1151 s / img. ETA=0:05:18
[32m[04/28 12:22:48 d2.evaluation.evaluator]: [0mInference done 5675/8355. 0.1151 s / img. ETA=0:05:13
[32m[04/28 12:22:53 d2.evaluation.evaluator]: [0mInference done 5718/8355. 0.1151 s / img. ETA=0:05:08
[32m[04/28 12:22:58 d2.evaluation.evaluator]: [0mInference done 5761/8355. 0.1151 s / img. ETA=0:05:03
[32m[04/28 12:23:03 d2.evaluation.evaluator]: [0mInference done 5804/8355. 0.1151 s / img. ETA=0:04:58
[32m[04/28 12:23:08 d2.evaluation.evaluator]: [0mInference done 5847/8355. 0.1151 s / img. ETA=0:04:53
[32m[04/28 12:23:13 d2.evaluation.evaluator]: [0mInference done 5890/8355. 0.1151 s / img. ETA=0:04:48
[32m[04/28 12:23:18 d2.evaluation.evaluator]: [0mInference done 5933/8355. 0.1151 s / img. ETA=0:04:43
[32m[04/28 12:23:23 d2.evaluation.evaluator]: [0mInference done 5976/8355. 0.1151 s / img. ETA=0:04:38
[32m[04/28 12:23:28 d2.evaluation.evaluator]: [0mInference done 6019/8355. 0.1151 s / img. ETA=0:04:33
[32m[04/28 12:23:33 d2.evaluation.evaluator]: [0mInference done 6061/8355. 0.1151 s / img. ETA=0:04:28
[32m[04/28 12:23:38 d2.evaluation.evaluator]: [0mInference done 6104/8355. 0.1152 s / img. ETA=0:04:23
[32m[04/28 12:23:43 d2.evaluation.evaluator]: [0mInference done 6147/8355. 0.1152 s / img. ETA=0:04:18
[32m[04/28 12:23:49 d2.evaluation.evaluator]: [0mInference done 6190/8355. 0.1152 s / img. ETA=0:04:13
[32m[04/28 12:23:54 d2.evaluation.evaluator]: [0mInference done 6233/8355. 0.1152 s / img. ETA=0:04:08
[32m[04/28 12:23:59 d2.evaluation.evaluator]: [0mInference done 6276/8355. 0.1152 s / img. ETA=0:04:03
[32m[04/28 12:24:04 d2.evaluation.evaluator]: [0mInference done 6319/8355. 0.1152 s / img. ETA=0:03:58
[32m[04/28 12:24:09 d2.evaluation.evaluator]: [0mInference done 6362/8355. 0.1152 s / img. ETA=0:03:53
[32m[04/28 12:24:14 d2.evaluation.evaluator]: [0mInference done 6405/8355. 0.1152 s / img. ETA=0:03:48
[32m[04/28 12:24:19 d2.evaluation.evaluator]: [0mInference done 6448/8355. 0.1152 s / img. ETA=0:03:43
[32m[04/28 12:24:24 d2.evaluation.evaluator]: [0mInference done 6491/8355. 0.1152 s / img. ETA=0:03:38
[32m[04/28 12:24:29 d2.evaluation.evaluator]: [0mInference done 6534/8355. 0.1152 s / img. ETA=0:03:33
[32m[04/28 12:24:34 d2.evaluation.evaluator]: [0mInference done 6577/8355. 0.1152 s / img. ETA=0:03:28
[32m[04/28 12:24:39 d2.evaluation.evaluator]: [0mInference done 6620/8355. 0.1152 s / img. ETA=0:03:22
[32m[04/28 12:24:44 d2.evaluation.evaluator]: [0mInference done 6663/8355. 0.1152 s / img. ETA=0:03:17
[32m[04/28 12:24:49 d2.evaluation.evaluator]: [0mInference done 6706/8355. 0.1152 s / img. ETA=0:03:12
[32m[04/28 12:24:54 d2.evaluation.evaluator]: [0mInference done 6750/8355. 0.1152 s / img. ETA=0:03:07
[32m[04/28 12:24:59 d2.evaluation.evaluator]: [0mInference done 6793/8355. 0.1152 s / img. ETA=0:03:02
[32m[04/28 12:25:04 d2.evaluation.evaluator]: [0mInference done 6836/8355. 0.1152 s / img. ETA=0:02:57
[32m[04/28 12:25:09 d2.evaluation.evaluator]: [0mInference done 6879/8355. 0.1152 s / img. ETA=0:02:52
[32m[04/28 12:25:14 d2.evaluation.evaluator]: [0mInference done 6922/8355. 0.1152 s / img. ETA=0:02:47
[32m[04/28 12:25:19 d2.evaluation.evaluator]: [0mInference done 6965/8355. 0.1152 s / img. ETA=0:02:42
[32m[04/28 12:25:24 d2.evaluation.evaluator]: [0mInference done 7008/8355. 0.1152 s / img. ETA=0:02:37
[32m[04/28 12:25:30 d2.evaluation.evaluator]: [0mInference done 7051/8355. 0.1152 s / img. ETA=0:02:32
[32m[04/28 12:25:35 d2.evaluation.evaluator]: [0mInference done 7094/8355. 0.1152 s / img. ETA=0:02:27
[32m[04/28 12:25:40 d2.evaluation.evaluator]: [0mInference done 7137/8355. 0.1152 s / img. ETA=0:02:22
[32m[04/28 12:25:45 d2.evaluation.evaluator]: [0mInference done 7180/8355. 0.1152 s / img. ETA=0:02:17
[32m[04/28 12:25:50 d2.evaluation.evaluator]: [0mInference done 7223/8355. 0.1152 s / img. ETA=0:02:12
[32m[04/28 12:25:55 d2.evaluation.evaluator]: [0mInference done 7266/8355. 0.1152 s / img. ETA=0:02:07
[32m[04/28 12:26:00 d2.evaluation.evaluator]: [0mInference done 7309/8355. 0.1152 s / img. ETA=0:02:02
[32m[04/28 12:26:05 d2.evaluation.evaluator]: [0mInference done 7352/8355. 0.1152 s / img. ETA=0:01:57
[32m[04/28 12:26:10 d2.evaluation.evaluator]: [0mInference done 7395/8355. 0.1152 s / img. ETA=0:01:52
[32m[04/28 12:26:15 d2.evaluation.evaluator]: [0mInference done 7438/8355. 0.1152 s / img. ETA=0:01:47
[32m[04/28 12:26:20 d2.evaluation.evaluator]: [0mInference done 7481/8355. 0.1153 s / img. ETA=0:01:42
[32m[04/28 12:26:25 d2.evaluation.evaluator]: [0mInference done 7524/8355. 0.1152 s / img. ETA=0:01:37
[32m[04/28 12:26:30 d2.evaluation.evaluator]: [0mInference done 7567/8355. 0.1153 s / img. ETA=0:01:32
[32m[04/28 12:26:35 d2.evaluation.evaluator]: [0mInference done 7610/8355. 0.1153 s / img. ETA=0:01:27
[32m[04/28 12:26:40 d2.evaluation.evaluator]: [0mInference done 7653/8355. 0.1153 s / img. ETA=0:01:22
[32m[04/28 12:26:46 d2.evaluation.evaluator]: [0mInference done 7696/8355. 0.1153 s / img. ETA=0:01:17
[32m[04/28 12:26:51 d2.evaluation.evaluator]: [0mInference done 7739/8355. 0.1153 s / img. ETA=0:01:12
[32m[04/28 12:26:56 d2.evaluation.evaluator]: [0mInference done 7782/8355. 0.1153 s / img. ETA=0:01:07
[32m[04/28 12:27:01 d2.evaluation.evaluator]: [0mInference done 7825/8355. 0.1153 s / img. ETA=0:01:02
[32m[04/28 12:27:06 d2.evaluation.evaluator]: [0mInference done 7868/8355. 0.1153 s / img. ETA=0:00:57
[32m[04/28 12:27:11 d2.evaluation.evaluator]: [0mInference done 7911/8355. 0.1153 s / img. ETA=0:00:51
[32m[04/28 12:27:16 d2.evaluation.evaluator]: [0mInference done 7953/8355. 0.1153 s / img. ETA=0:00:47
[32m[04/28 12:27:21 d2.evaluation.evaluator]: [0mInference done 7996/8355. 0.1153 s / img. ETA=0:00:42
[32m[04/28 12:27:26 d2.evaluation.evaluator]: [0mInference done 8039/8355. 0.1153 s / img. ETA=0:00:37
[32m[04/28 12:27:31 d2.evaluation.evaluator]: [0mInference done 8083/8355. 0.1153 s / img. ETA=0:00:31
[32m[04/28 12:27:36 d2.evaluation.evaluator]: [0mInference done 8127/8355. 0.1153 s / img. ETA=0:00:26
[32m[04/28 12:27:41 d2.evaluation.evaluator]: [0mInference done 8170/8355. 0.1153 s / img. ETA=0:00:21
[32m[04/28 12:27:46 d2.evaluation.evaluator]: [0mInference done 8213/8355. 0.1153 s / img. ETA=0:00:16
[32m[04/28 12:27:51 d2.evaluation.evaluator]: [0mInference done 8256/8355. 0.1153 s / img. ETA=0:00:11
[32m[04/28 12:27:56 d2.evaluation.evaluator]: [0mInference done 8299/8355. 0.1153 s / img. ETA=0:00:06
[32m[04/28 12:28:01 d2.evaluation.evaluator]: [0mInference done 8341/8355. 0.1153 s / img. ETA=0:00:01
[32m[04/28 12:28:03 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:17.737349 (0.117094 s / img per device, on 1 devices)
[32m[04/28 12:28:03 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:02 (0.115280 s / img per device, on 1 devices)
[32m[04/28 12:28:03 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 12:28:03 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 12:28:03 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.08s).
Accumulating evaluation results...
DONE (t=2.19s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.860
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.504
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.390
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.624
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.750
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.543
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.561
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.468
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.686
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.795
[32m[04/28 12:28:26 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.455 | 85.969 | 50.449 | 38.973 | 62.373 | 74.952 |
[32m[04/28 12:28:26 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 48.676 | bicycle       | 42.528 | car            | 57.161 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 12:28:26 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 12:28:26 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 12:28:26 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 12:28:28 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1153 s / img. ETA=0:02:25
[32m[04/28 12:28:33 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1147 s / img. ETA=0:02:20
[32m[04/28 12:28:38 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1148 s / img. ETA=0:02:15
[32m[04/28 12:28:43 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1147 s / img. ETA=0:02:10
[32m[04/28 12:28:48 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1148 s / img. ETA=0:02:05
[32m[04/28 12:28:53 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1148 s / img. ETA=0:02:00
[32m[04/28 12:28:58 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1148 s / img. ETA=0:01:55
[32m[04/28 12:29:03 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1148 s / img. ETA=0:01:50
[32m[04/28 12:29:08 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1148 s / img. ETA=0:01:45
[32m[04/28 12:29:13 d2.evaluation.evaluator]: [0mInference done 397/1257. 0.1152 s / img. ETA=0:01:40
[32m[04/28 12:29:18 d2.evaluation.evaluator]: [0mInference done 440/1257. 0.1151 s / img. ETA=0:01:35
[32m[04/28 12:29:23 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1151 s / img. ETA=0:01:30
[32m[04/28 12:29:28 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1151 s / img. ETA=0:01:25
[32m[04/28 12:29:33 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1151 s / img. ETA=0:01:20
[32m[04/28 12:29:38 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1150 s / img. ETA=0:01:15
[32m[04/28 12:29:43 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1150 s / img. ETA=0:01:10
[32m[04/28 12:29:48 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1150 s / img. ETA=0:01:05
[32m[04/28 12:29:53 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1150 s / img. ETA=0:01:00
[32m[04/28 12:29:58 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1150 s / img. ETA=0:00:55
[32m[04/28 12:30:03 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1151 s / img. ETA=0:00:50
[32m[04/28 12:30:08 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1151 s / img. ETA=0:00:45
[32m[04/28 12:30:13 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1151 s / img. ETA=0:00:40
[32m[04/28 12:30:18 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1151 s / img. ETA=0:00:35
[32m[04/28 12:30:23 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1151 s / img. ETA=0:00:30
[32m[04/28 12:30:28 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1151 s / img. ETA=0:00:25
[32m[04/28 12:30:33 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1151 s / img. ETA=0:00:19
[32m[04/28 12:30:38 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1152 s / img. ETA=0:00:14
[32m[04/28 12:30:44 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1152 s / img. ETA=0:00:09
[32m[04/28 12:30:49 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1152 s / img. ETA=0:00:04
[32m[04/28 12:30:54 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.537660 (0.117043 s / img per device, on 1 devices)
[32m[04/28 12:30:54 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115228 s / img per device, on 1 devices)
[32m[04/28 12:30:54 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 12:30:54 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 12:30:54 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.00s).
Accumulating evaluation results...
DONE (t=0.37s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.407
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.779
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.372
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.302
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.474
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.586
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.483
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.489
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.395
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.548
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650
[32m[04/28 12:30:57 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.740 | 77.940 | 37.182 | 30.219 | 47.420 | 58.635 |
[32m[04/28 12:30:57 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 43.253 | bicycle       | 25.327 | car            | 53.639 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  18  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 12:30:58 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 12:30:58 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 12:30:58 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 12:30:59 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 12:30:59 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 12:30:59 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 12:30:59 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 12:31:20 d2.utils.events]: [0m eta: 0:17:16  iter: 19  total_loss: 0.534  loss_cls: 0.168  loss_box_reg: 0.316  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0391  data_time: 0.0202  lr: 0.000100  max_mem: 5397M
[32m[04/28 12:31:40 d2.utils.events]: [0m eta: 0:16:51  iter: 39  total_loss: 0.478  loss_cls: 0.145  loss_box_reg: 0.282  loss_rpn_cls: 0.006  loss_rpn_loc: 0.040  time: 1.0267  data_time: 0.0079  lr: 0.000200  max_mem: 5397M
[32m[04/28 12:32:00 d2.utils.events]: [0m eta: 0:15:54  iter: 59  total_loss: 0.456  loss_cls: 0.128  loss_box_reg: 0.261  loss_rpn_cls: 0.005  loss_rpn_loc: 0.035  time: 1.0163  data_time: 0.0078  lr: 0.000300  max_mem: 5397M
[32m[04/28 12:32:21 d2.utils.events]: [0m eta: 0:15:41  iter: 79  total_loss: 0.519  loss_cls: 0.166  loss_box_reg: 0.298  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0234  data_time: 0.0075  lr: 0.000400  max_mem: 5397M
[32m[04/28 12:32:42 d2.utils.events]: [0m eta: 0:15:47  iter: 99  total_loss: 0.487  loss_cls: 0.148  loss_box_reg: 0.291  loss_rpn_cls: 0.006  loss_rpn_loc: 0.039  time: 1.0269  data_time: 0.0075  lr: 0.000500  max_mem: 5397M
[32m[04/28 12:33:03 d2.utils.events]: [0m eta: 0:15:26  iter: 119  total_loss: 0.460  loss_cls: 0.146  loss_box_reg: 0.261  loss_rpn_cls: 0.005  loss_rpn_loc: 0.032  time: 1.0301  data_time: 0.0078  lr: 0.000599  max_mem: 5397M
[32m[04/28 12:33:23 d2.utils.events]: [0m eta: 0:14:59  iter: 139  total_loss: 0.496  loss_cls: 0.153  loss_box_reg: 0.289  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0283  data_time: 0.0077  lr: 0.000699  max_mem: 5397M
[32m[04/28 12:33:43 d2.utils.events]: [0m eta: 0:14:25  iter: 159  total_loss: 0.486  loss_cls: 0.161  loss_box_reg: 0.289  loss_rpn_cls: 0.009  loss_rpn_loc: 0.042  time: 1.0258  data_time: 0.0076  lr: 0.000799  max_mem: 5397M
[32m[04/28 12:34:04 d2.utils.events]: [0m eta: 0:13:57  iter: 179  total_loss: 0.435  loss_cls: 0.131  loss_box_reg: 0.267  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0238  data_time: 0.0077  lr: 0.000899  max_mem: 5397M
[32m[04/28 12:34:24 d2.utils.events]: [0m eta: 0:13:37  iter: 199  total_loss: 0.517  loss_cls: 0.149  loss_box_reg: 0.300  loss_rpn_cls: 0.007  loss_rpn_loc: 0.052  time: 1.0236  data_time: 0.0078  lr: 0.000999  max_mem: 5397M
[32m[04/28 12:34:45 d2.utils.events]: [0m eta: 0:13:17  iter: 219  total_loss: 0.526  loss_cls: 0.164  loss_box_reg: 0.294  loss_rpn_cls: 0.005  loss_rpn_loc: 0.050  time: 1.0236  data_time: 0.0076  lr: 0.001099  max_mem: 5397M
[32m[04/28 12:35:06 d2.utils.events]: [0m eta: 0:13:06  iter: 239  total_loss: 0.478  loss_cls: 0.153  loss_box_reg: 0.292  loss_rpn_cls: 0.005  loss_rpn_loc: 0.042  time: 1.0269  data_time: 0.0078  lr: 0.001199  max_mem: 5397M
[32m[04/28 12:35:27 d2.utils.events]: [0m eta: 0:12:47  iter: 259  total_loss: 0.464  loss_cls: 0.143  loss_box_reg: 0.268  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0270  data_time: 0.0075  lr: 0.001299  max_mem: 5397M
[32m[04/28 12:35:47 d2.utils.events]: [0m eta: 0:12:27  iter: 279  total_loss: 0.518  loss_cls: 0.156  loss_box_reg: 0.316  loss_rpn_cls: 0.008  loss_rpn_loc: 0.041  time: 1.0273  data_time: 0.0077  lr: 0.001399  max_mem: 5397M
[32m[04/28 12:36:08 d2.utils.events]: [0m eta: 0:12:06  iter: 299  total_loss: 0.512  loss_cls: 0.138  loss_box_reg: 0.303  loss_rpn_cls: 0.005  loss_rpn_loc: 0.048  time: 1.0275  data_time: 0.0076  lr: 0.001499  max_mem: 5397M
[32m[04/28 12:36:28 d2.utils.events]: [0m eta: 0:11:44  iter: 319  total_loss: 0.499  loss_cls: 0.142  loss_box_reg: 0.291  loss_rpn_cls: 0.008  loss_rpn_loc: 0.040  time: 1.0273  data_time: 0.0076  lr: 0.001598  max_mem: 5397M
[32m[04/28 12:36:49 d2.utils.events]: [0m eta: 0:11:25  iter: 339  total_loss: 0.420  loss_cls: 0.127  loss_box_reg: 0.252  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0279  data_time: 0.0078  lr: 0.001698  max_mem: 5397M
[32m[04/28 12:37:10 d2.utils.events]: [0m eta: 0:11:03  iter: 359  total_loss: 0.507  loss_cls: 0.166  loss_box_reg: 0.300  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 1.0274  data_time: 0.0076  lr: 0.001798  max_mem: 5397M
[32m[04/28 12:37:30 d2.utils.events]: [0m eta: 0:10:41  iter: 379  total_loss: 0.510  loss_cls: 0.145  loss_box_reg: 0.297  loss_rpn_cls: 0.005  loss_rpn_loc: 0.038  time: 1.0272  data_time: 0.0077  lr: 0.001898  max_mem: 5397M
[32m[04/28 12:37:51 d2.utils.events]: [0m eta: 0:10:21  iter: 399  total_loss: 0.448  loss_cls: 0.139  loss_box_reg: 0.255  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0273  data_time: 0.0076  lr: 0.001998  max_mem: 5397M
[32m[04/28 12:38:12 d2.utils.events]: [0m eta: 0:10:02  iter: 419  total_loss: 0.496  loss_cls: 0.164  loss_box_reg: 0.306  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0285  data_time: 0.0077  lr: 0.002098  max_mem: 5397M
[32m[04/28 12:38:32 d2.utils.events]: [0m eta: 0:09:42  iter: 439  total_loss: 0.487  loss_cls: 0.151  loss_box_reg: 0.281  loss_rpn_cls: 0.006  loss_rpn_loc: 0.050  time: 1.0283  data_time: 0.0078  lr: 0.002198  max_mem: 5397M
[32m[04/28 12:38:53 d2.utils.events]: [0m eta: 0:09:21  iter: 459  total_loss: 0.522  loss_cls: 0.157  loss_box_reg: 0.306  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0287  data_time: 0.0076  lr: 0.002298  max_mem: 5397M
[32m[04/28 12:39:14 d2.utils.events]: [0m eta: 0:09:00  iter: 479  total_loss: 0.537  loss_cls: 0.162  loss_box_reg: 0.298  loss_rpn_cls: 0.008  loss_rpn_loc: 0.046  time: 1.0289  data_time: 0.0077  lr: 0.002398  max_mem: 5397M
[32m[04/28 12:39:35 d2.utils.events]: [0m eta: 0:08:40  iter: 499  total_loss: 0.475  loss_cls: 0.146  loss_box_reg: 0.263  loss_rpn_cls: 0.006  loss_rpn_loc: 0.040  time: 1.0296  data_time: 0.0077  lr: 0.002498  max_mem: 5397M
[32m[04/28 12:39:55 d2.utils.events]: [0m eta: 0:08:20  iter: 519  total_loss: 0.468  loss_cls: 0.143  loss_box_reg: 0.280  loss_rpn_cls: 0.006  loss_rpn_loc: 0.039  time: 1.0293  data_time: 0.0077  lr: 0.002597  max_mem: 5397M
[32m[04/28 12:40:16 d2.utils.events]: [0m eta: 0:07:59  iter: 539  total_loss: 0.547  loss_cls: 0.170  loss_box_reg: 0.312  loss_rpn_cls: 0.008  loss_rpn_loc: 0.043  time: 1.0297  data_time: 0.0079  lr: 0.002697  max_mem: 5397M
[32m[04/28 12:40:37 d2.utils.events]: [0m eta: 0:07:40  iter: 559  total_loss: 0.529  loss_cls: 0.155  loss_box_reg: 0.316  loss_rpn_cls: 0.005  loss_rpn_loc: 0.047  time: 1.0301  data_time: 0.0077  lr: 0.002797  max_mem: 5397M
[32m[04/28 12:40:58 d2.utils.events]: [0m eta: 0:07:18  iter: 579  total_loss: 0.498  loss_cls: 0.147  loss_box_reg: 0.274  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0299  data_time: 0.0079  lr: 0.002897  max_mem: 5397M
[32m[04/28 12:41:18 d2.utils.events]: [0m eta: 0:06:58  iter: 599  total_loss: 0.479  loss_cls: 0.158  loss_box_reg: 0.275  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0300  data_time: 0.0078  lr: 0.002997  max_mem: 5397M
[32m[04/28 12:41:40 d2.utils.events]: [0m eta: 0:06:38  iter: 619  total_loss: 0.506  loss_cls: 0.154  loss_box_reg: 0.296  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0309  data_time: 0.0079  lr: 0.003097  max_mem: 5397M
[32m[04/28 12:42:00 d2.utils.events]: [0m eta: 0:06:17  iter: 639  total_loss: 0.518  loss_cls: 0.152  loss_box_reg: 0.309  loss_rpn_cls: 0.008  loss_rpn_loc: 0.043  time: 1.0305  data_time: 0.0077  lr: 0.003197  max_mem: 5397M
[32m[04/28 12:42:21 d2.utils.events]: [0m eta: 0:05:56  iter: 659  total_loss: 0.467  loss_cls: 0.153  loss_box_reg: 0.267  loss_rpn_cls: 0.006  loss_rpn_loc: 0.039  time: 1.0312  data_time: 0.0080  lr: 0.003297  max_mem: 5397M
[32m[04/28 12:42:42 d2.utils.events]: [0m eta: 0:05:35  iter: 679  total_loss: 0.530  loss_cls: 0.166  loss_box_reg: 0.323  loss_rpn_cls: 0.006  loss_rpn_loc: 0.050  time: 1.0310  data_time: 0.0076  lr: 0.003397  max_mem: 5397M
[32m[04/28 12:43:02 d2.utils.events]: [0m eta: 0:05:14  iter: 699  total_loss: 0.517  loss_cls: 0.157  loss_box_reg: 0.300  loss_rpn_cls: 0.007  loss_rpn_loc: 0.043  time: 1.0307  data_time: 0.0075  lr: 0.003497  max_mem: 5397M
[32m[04/28 12:43:23 d2.utils.events]: [0m eta: 0:04:53  iter: 719  total_loss: 0.486  loss_cls: 0.142  loss_box_reg: 0.289  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 1.0311  data_time: 0.0077  lr: 0.003596  max_mem: 5397M
[32m[04/28 12:43:43 d2.utils.events]: [0m eta: 0:04:32  iter: 739  total_loss: 0.556  loss_cls: 0.175  loss_box_reg: 0.305  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 1.0306  data_time: 0.0074  lr: 0.003696  max_mem: 5397M
[32m[04/28 12:44:04 d2.utils.events]: [0m eta: 0:04:11  iter: 759  total_loss: 0.511  loss_cls: 0.157  loss_box_reg: 0.301  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0308  data_time: 0.0075  lr: 0.003796  max_mem: 5397M
[32m[04/28 12:44:25 d2.utils.events]: [0m eta: 0:03:50  iter: 779  total_loss: 0.527  loss_cls: 0.165  loss_box_reg: 0.326  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0309  data_time: 0.0076  lr: 0.003896  max_mem: 5397M
[32m[04/28 12:44:46 d2.utils.events]: [0m eta: 0:03:30  iter: 799  total_loss: 0.577  loss_cls: 0.175  loss_box_reg: 0.340  loss_rpn_cls: 0.010  loss_rpn_loc: 0.046  time: 1.0309  data_time: 0.0076  lr: 0.003996  max_mem: 5397M
[32m[04/28 12:45:06 d2.utils.events]: [0m eta: 0:03:09  iter: 819  total_loss: 0.459  loss_cls: 0.140  loss_box_reg: 0.260  loss_rpn_cls: 0.010  loss_rpn_loc: 0.040  time: 1.0310  data_time: 0.0077  lr: 0.004096  max_mem: 5397M
[32m[04/28 12:45:27 d2.utils.events]: [0m eta: 0:02:48  iter: 839  total_loss: 0.526  loss_cls: 0.166  loss_box_reg: 0.314  loss_rpn_cls: 0.006  loss_rpn_loc: 0.052  time: 1.0309  data_time: 0.0077  lr: 0.004196  max_mem: 5397M
[32m[04/28 12:45:48 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.532  loss_cls: 0.157  loss_box_reg: 0.304  loss_rpn_cls: 0.006  loss_rpn_loc: 0.053  time: 1.0312  data_time: 0.0077  lr: 0.004296  max_mem: 5397M
[32m[04/28 12:46:08 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.528  loss_cls: 0.153  loss_box_reg: 0.293  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 1.0308  data_time: 0.0079  lr: 0.004396  max_mem: 5397M
[32m[04/28 12:46:29 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.538  loss_cls: 0.158  loss_box_reg: 0.296  loss_rpn_cls: 0.008  loss_rpn_loc: 0.059  time: 1.0311  data_time: 0.0076  lr: 0.004496  max_mem: 5397M
[32m[04/28 12:46:50 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.459  loss_cls: 0.155  loss_box_reg: 0.267  loss_rpn_cls: 0.006  loss_rpn_loc: 0.039  time: 1.0308  data_time: 0.0076  lr: 0.004595  max_mem: 5397M
[32m[04/28 12:47:10 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.580  loss_cls: 0.171  loss_box_reg: 0.329  loss_rpn_cls: 0.007  loss_rpn_loc: 0.051  time: 1.0308  data_time: 0.0076  lr: 0.004695  max_mem: 5397M
[32m[04/28 12:47:31 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.502  loss_cls: 0.158  loss_box_reg: 0.301  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 1.0305  data_time: 0.0077  lr: 0.004795  max_mem: 5397M
[32m[04/28 12:47:51 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.551  loss_cls: 0.172  loss_box_reg: 0.312  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 1.0303  data_time: 0.0077  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 12:48:15 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 12:48:15 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 12:48:15 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 12:48:15 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.517  loss_cls: 0.165  loss_box_reg: 0.305  loss_rpn_cls: 0.006  loss_rpn_loc: 0.050  time: 1.0308  data_time: 0.0078  lr: 0.004995  max_mem: 5397M
[32m[04/28 12:48:15 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:08 (1.0319 s / it)
[32m[04/28 12:48:15 d2.engine.hooks]: [0mTotal training time: 0:17:14 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 12:48:17 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 12:48:17 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 12:48:17 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 12:48:18 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1144 s / img. ETA=0:16:06
[32m[04/28 12:48:23 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1143 s / img. ETA=0:16:02
[32m[04/28 12:48:29 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1141 s / img. ETA=0:15:55
[32m[04/28 12:48:34 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1141 s / img. ETA=0:15:50
[32m[04/28 12:48:39 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1141 s / img. ETA=0:15:45
[32m[04/28 12:48:44 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1141 s / img. ETA=0:15:40
[32m[04/28 12:48:49 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1142 s / img. ETA=0:15:36
[32m[04/28 12:48:54 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1142 s / img. ETA=0:15:31
[32m[04/28 12:48:59 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1142 s / img. ETA=0:15:26
[32m[04/28 12:49:04 d2.evaluation.evaluator]: [0mInference done 406/8355. 0.1143 s / img. ETA=0:15:22
[32m[04/28 12:49:09 d2.evaluation.evaluator]: [0mInference done 449/8355. 0.1143 s / img. ETA=0:15:17
[32m[04/28 12:49:14 d2.evaluation.evaluator]: [0mInference done 493/8355. 0.1143 s / img. ETA=0:15:11
[32m[04/28 12:49:19 d2.evaluation.evaluator]: [0mInference done 537/8355. 0.1143 s / img. ETA=0:15:06
[32m[04/28 12:49:24 d2.evaluation.evaluator]: [0mInference done 581/8355. 0.1143 s / img. ETA=0:15:01
[32m[04/28 12:49:30 d2.evaluation.evaluator]: [0mInference done 625/8355. 0.1143 s / img. ETA=0:14:56
[32m[04/28 12:49:35 d2.evaluation.evaluator]: [0mInference done 668/8355. 0.1143 s / img. ETA=0:14:51
[32m[04/28 12:49:40 d2.evaluation.evaluator]: [0mInference done 711/8355. 0.1143 s / img. ETA=0:14:46
[32m[04/28 12:49:45 d2.evaluation.evaluator]: [0mInference done 754/8355. 0.1144 s / img. ETA=0:14:42
[32m[04/28 12:49:50 d2.evaluation.evaluator]: [0mInference done 797/8355. 0.1144 s / img. ETA=0:14:37
[32m[04/28 12:49:55 d2.evaluation.evaluator]: [0mInference done 840/8355. 0.1144 s / img. ETA=0:14:32
[32m[04/28 12:50:00 d2.evaluation.evaluator]: [0mInference done 883/8355. 0.1145 s / img. ETA=0:14:28
[32m[04/28 12:50:05 d2.evaluation.evaluator]: [0mInference done 926/8355. 0.1145 s / img. ETA=0:14:23
[32m[04/28 12:50:10 d2.evaluation.evaluator]: [0mInference done 970/8355. 0.1145 s / img. ETA=0:14:18
[32m[04/28 12:50:15 d2.evaluation.evaluator]: [0mInference done 1014/8355. 0.1145 s / img. ETA=0:14:12
[32m[04/28 12:50:20 d2.evaluation.evaluator]: [0mInference done 1057/8355. 0.1145 s / img. ETA=0:14:08
[32m[04/28 12:50:25 d2.evaluation.evaluator]: [0mInference done 1101/8355. 0.1145 s / img. ETA=0:14:03
[32m[04/28 12:50:30 d2.evaluation.evaluator]: [0mInference done 1145/8355. 0.1145 s / img. ETA=0:13:57
[32m[04/28 12:50:35 d2.evaluation.evaluator]: [0mInference done 1188/8355. 0.1145 s / img. ETA=0:13:52
[32m[04/28 12:50:40 d2.evaluation.evaluator]: [0mInference done 1231/8355. 0.1145 s / img. ETA=0:13:48
[32m[04/28 12:50:45 d2.evaluation.evaluator]: [0mInference done 1275/8355. 0.1145 s / img. ETA=0:13:42
[32m[04/28 12:50:50 d2.evaluation.evaluator]: [0mInference done 1319/8355. 0.1145 s / img. ETA=0:13:37
[32m[04/28 12:50:55 d2.evaluation.evaluator]: [0mInference done 1363/8355. 0.1145 s / img. ETA=0:13:32
[32m[04/28 12:51:00 d2.evaluation.evaluator]: [0mInference done 1406/8355. 0.1145 s / img. ETA=0:13:27
[32m[04/28 12:51:06 d2.evaluation.evaluator]: [0mInference done 1449/8355. 0.1145 s / img. ETA=0:13:22
[32m[04/28 12:51:11 d2.evaluation.evaluator]: [0mInference done 1492/8355. 0.1145 s / img. ETA=0:13:17
[32m[04/28 12:51:16 d2.evaluation.evaluator]: [0mInference done 1535/8355. 0.1146 s / img. ETA=0:13:13
[32m[04/28 12:51:21 d2.evaluation.evaluator]: [0mInference done 1577/8355. 0.1147 s / img. ETA=0:13:08
[32m[04/28 12:51:26 d2.evaluation.evaluator]: [0mInference done 1620/8355. 0.1147 s / img. ETA=0:13:03
[32m[04/28 12:51:31 d2.evaluation.evaluator]: [0mInference done 1663/8355. 0.1147 s / img. ETA=0:12:59
[32m[04/28 12:51:36 d2.evaluation.evaluator]: [0mInference done 1706/8355. 0.1148 s / img. ETA=0:12:54
[32m[04/28 12:51:41 d2.evaluation.evaluator]: [0mInference done 1749/8355. 0.1148 s / img. ETA=0:12:49
[32m[04/28 12:51:46 d2.evaluation.evaluator]: [0mInference done 1792/8355. 0.1148 s / img. ETA=0:12:45
[32m[04/28 12:51:51 d2.evaluation.evaluator]: [0mInference done 1835/8355. 0.1149 s / img. ETA=0:12:40
[32m[04/28 12:51:56 d2.evaluation.evaluator]: [0mInference done 1878/8355. 0.1149 s / img. ETA=0:12:35
[32m[04/28 12:52:01 d2.evaluation.evaluator]: [0mInference done 1920/8355. 0.1150 s / img. ETA=0:12:30
[32m[04/28 12:52:06 d2.evaluation.evaluator]: [0mInference done 1963/8355. 0.1150 s / img. ETA=0:12:26
[32m[04/28 12:52:11 d2.evaluation.evaluator]: [0mInference done 2006/8355. 0.1150 s / img. ETA=0:12:21
[32m[04/28 12:52:16 d2.evaluation.evaluator]: [0mInference done 2049/8355. 0.1150 s / img. ETA=0:12:16
[32m[04/28 12:52:21 d2.evaluation.evaluator]: [0mInference done 2092/8355. 0.1150 s / img. ETA=0:12:11
[32m[04/28 12:52:26 d2.evaluation.evaluator]: [0mInference done 2135/8355. 0.1150 s / img. ETA=0:12:06
[32m[04/28 12:52:31 d2.evaluation.evaluator]: [0mInference done 2178/8355. 0.1150 s / img. ETA=0:12:01
[32m[04/28 12:52:36 d2.evaluation.evaluator]: [0mInference done 2221/8355. 0.1150 s / img. ETA=0:11:56
[32m[04/28 12:52:42 d2.evaluation.evaluator]: [0mInference done 2264/8355. 0.1150 s / img. ETA=0:11:51
[32m[04/28 12:52:47 d2.evaluation.evaluator]: [0mInference done 2307/8355. 0.1151 s / img. ETA=0:11:46
[32m[04/28 12:52:52 d2.evaluation.evaluator]: [0mInference done 2350/8355. 0.1151 s / img. ETA=0:11:41
[32m[04/28 12:52:57 d2.evaluation.evaluator]: [0mInference done 2393/8355. 0.1151 s / img. ETA=0:11:36
[32m[04/28 12:53:02 d2.evaluation.evaluator]: [0mInference done 2436/8355. 0.1151 s / img. ETA=0:11:31
[32m[04/28 12:53:07 d2.evaluation.evaluator]: [0mInference done 2479/8355. 0.1151 s / img. ETA=0:11:26
[32m[04/28 12:53:12 d2.evaluation.evaluator]: [0mInference done 2522/8355. 0.1151 s / img. ETA=0:11:21
[32m[04/28 12:53:17 d2.evaluation.evaluator]: [0mInference done 2565/8355. 0.1151 s / img. ETA=0:11:16
[32m[04/28 12:53:22 d2.evaluation.evaluator]: [0mInference done 2608/8355. 0.1152 s / img. ETA=0:11:11
[32m[04/28 12:53:27 d2.evaluation.evaluator]: [0mInference done 2651/8355. 0.1152 s / img. ETA=0:11:06
[32m[04/28 12:53:32 d2.evaluation.evaluator]: [0mInference done 2694/8355. 0.1152 s / img. ETA=0:11:02
[32m[04/28 12:53:37 d2.evaluation.evaluator]: [0mInference done 2737/8355. 0.1152 s / img. ETA=0:10:57
[32m[04/28 12:53:42 d2.evaluation.evaluator]: [0mInference done 2780/8355. 0.1152 s / img. ETA=0:10:52
[32m[04/28 12:53:47 d2.evaluation.evaluator]: [0mInference done 2823/8355. 0.1152 s / img. ETA=0:10:47
[32m[04/28 12:53:52 d2.evaluation.evaluator]: [0mInference done 2866/8355. 0.1152 s / img. ETA=0:10:42
[32m[04/28 12:53:57 d2.evaluation.evaluator]: [0mInference done 2909/8355. 0.1153 s / img. ETA=0:10:37
[32m[04/28 12:54:03 d2.evaluation.evaluator]: [0mInference done 2952/8355. 0.1153 s / img. ETA=0:10:32
[32m[04/28 12:54:08 d2.evaluation.evaluator]: [0mInference done 2995/8355. 0.1153 s / img. ETA=0:10:27
[32m[04/28 12:54:13 d2.evaluation.evaluator]: [0mInference done 3038/8355. 0.1153 s / img. ETA=0:10:22
[32m[04/28 12:54:18 d2.evaluation.evaluator]: [0mInference done 3081/8355. 0.1153 s / img. ETA=0:10:17
[32m[04/28 12:54:23 d2.evaluation.evaluator]: [0mInference done 3124/8355. 0.1153 s / img. ETA=0:10:12
[32m[04/28 12:54:28 d2.evaluation.evaluator]: [0mInference done 3168/8355. 0.1153 s / img. ETA=0:10:07
[32m[04/28 12:54:33 d2.evaluation.evaluator]: [0mInference done 3212/8355. 0.1153 s / img. ETA=0:10:01
[32m[04/28 12:54:38 d2.evaluation.evaluator]: [0mInference done 3255/8355. 0.1153 s / img. ETA=0:09:56
[32m[04/28 12:54:43 d2.evaluation.evaluator]: [0mInference done 3298/8355. 0.1153 s / img. ETA=0:09:51
[32m[04/28 12:54:48 d2.evaluation.evaluator]: [0mInference done 3341/8355. 0.1153 s / img. ETA=0:09:46
[32m[04/28 12:54:53 d2.evaluation.evaluator]: [0mInference done 3384/8355. 0.1153 s / img. ETA=0:09:41
[32m[04/28 12:54:58 d2.evaluation.evaluator]: [0mInference done 3427/8355. 0.1153 s / img. ETA=0:09:36
[32m[04/28 12:55:03 d2.evaluation.evaluator]: [0mInference done 3470/8355. 0.1153 s / img. ETA=0:09:31
[32m[04/28 12:55:08 d2.evaluation.evaluator]: [0mInference done 3513/8355. 0.1153 s / img. ETA=0:09:26
[32m[04/28 12:55:13 d2.evaluation.evaluator]: [0mInference done 3556/8355. 0.1153 s / img. ETA=0:09:21
[32m[04/28 12:55:18 d2.evaluation.evaluator]: [0mInference done 3599/8355. 0.1153 s / img. ETA=0:09:16
[32m[04/28 12:55:23 d2.evaluation.evaluator]: [0mInference done 3642/8355. 0.1153 s / img. ETA=0:09:11
[32m[04/28 12:55:28 d2.evaluation.evaluator]: [0mInference done 3685/8355. 0.1153 s / img. ETA=0:09:06
[32m[04/28 12:55:33 d2.evaluation.evaluator]: [0mInference done 3728/8355. 0.1153 s / img. ETA=0:09:01
[32m[04/28 12:55:38 d2.evaluation.evaluator]: [0mInference done 3771/8355. 0.1153 s / img. ETA=0:08:56
[32m[04/28 12:55:44 d2.evaluation.evaluator]: [0mInference done 3814/8355. 0.1153 s / img. ETA=0:08:51
[32m[04/28 12:55:49 d2.evaluation.evaluator]: [0mInference done 3857/8355. 0.1153 s / img. ETA=0:08:46
[32m[04/28 12:55:54 d2.evaluation.evaluator]: [0mInference done 3900/8355. 0.1153 s / img. ETA=0:08:41
[32m[04/28 12:55:59 d2.evaluation.evaluator]: [0mInference done 3943/8355. 0.1153 s / img. ETA=0:08:36
[32m[04/28 12:56:04 d2.evaluation.evaluator]: [0mInference done 3986/8355. 0.1153 s / img. ETA=0:08:31
[32m[04/28 12:56:09 d2.evaluation.evaluator]: [0mInference done 4029/8355. 0.1153 s / img. ETA=0:08:26
[32m[04/28 12:56:14 d2.evaluation.evaluator]: [0mInference done 4072/8355. 0.1153 s / img. ETA=0:08:21
[32m[04/28 12:56:19 d2.evaluation.evaluator]: [0mInference done 4115/8355. 0.1153 s / img. ETA=0:08:16
[32m[04/28 12:56:24 d2.evaluation.evaluator]: [0mInference done 4158/8355. 0.1153 s / img. ETA=0:08:11
[32m[04/28 12:56:29 d2.evaluation.evaluator]: [0mInference done 4201/8355. 0.1153 s / img. ETA=0:08:06
[32m[04/28 12:56:34 d2.evaluation.evaluator]: [0mInference done 4244/8355. 0.1153 s / img. ETA=0:08:01
[32m[04/28 12:56:39 d2.evaluation.evaluator]: [0mInference done 4287/8355. 0.1153 s / img. ETA=0:07:56
[32m[04/28 12:56:44 d2.evaluation.evaluator]: [0mInference done 4330/8355. 0.1153 s / img. ETA=0:07:51
[32m[04/28 12:56:49 d2.evaluation.evaluator]: [0mInference done 4373/8355. 0.1153 s / img. ETA=0:07:46
[32m[04/28 12:56:54 d2.evaluation.evaluator]: [0mInference done 4416/8355. 0.1153 s / img. ETA=0:07:41
[32m[04/28 12:56:59 d2.evaluation.evaluator]: [0mInference done 4459/8355. 0.1153 s / img. ETA=0:07:36
[32m[04/28 12:57:04 d2.evaluation.evaluator]: [0mInference done 4502/8355. 0.1153 s / img. ETA=0:07:31
[32m[04/28 12:57:09 d2.evaluation.evaluator]: [0mInference done 4545/8355. 0.1153 s / img. ETA=0:07:26
[32m[04/28 12:57:14 d2.evaluation.evaluator]: [0mInference done 4588/8355. 0.1153 s / img. ETA=0:07:21
[32m[04/28 12:57:19 d2.evaluation.evaluator]: [0mInference done 4631/8355. 0.1153 s / img. ETA=0:07:16
[32m[04/28 12:57:24 d2.evaluation.evaluator]: [0mInference done 4673/8355. 0.1153 s / img. ETA=0:07:11
[32m[04/28 12:57:29 d2.evaluation.evaluator]: [0mInference done 4716/8355. 0.1153 s / img. ETA=0:07:06
[32m[04/28 12:57:35 d2.evaluation.evaluator]: [0mInference done 4759/8355. 0.1153 s / img. ETA=0:07:01
[32m[04/28 12:57:40 d2.evaluation.evaluator]: [0mInference done 4802/8355. 0.1153 s / img. ETA=0:06:56
[32m[04/28 12:57:45 d2.evaluation.evaluator]: [0mInference done 4845/8355. 0.1153 s / img. ETA=0:06:51
[32m[04/28 12:57:50 d2.evaluation.evaluator]: [0mInference done 4888/8355. 0.1153 s / img. ETA=0:06:46
[32m[04/28 12:57:55 d2.evaluation.evaluator]: [0mInference done 4931/8355. 0.1153 s / img. ETA=0:06:41
[32m[04/28 12:58:00 d2.evaluation.evaluator]: [0mInference done 4974/8355. 0.1153 s / img. ETA=0:06:36
[32m[04/28 12:58:05 d2.evaluation.evaluator]: [0mInference done 5017/8355. 0.1153 s / img. ETA=0:06:31
[32m[04/28 12:58:10 d2.evaluation.evaluator]: [0mInference done 5059/8355. 0.1153 s / img. ETA=0:06:26
[32m[04/28 12:58:15 d2.evaluation.evaluator]: [0mInference done 5102/8355. 0.1153 s / img. ETA=0:06:21
[32m[04/28 12:58:20 d2.evaluation.evaluator]: [0mInference done 5145/8355. 0.1153 s / img. ETA=0:06:16
[32m[04/28 12:58:25 d2.evaluation.evaluator]: [0mInference done 5188/8355. 0.1153 s / img. ETA=0:06:11
[32m[04/28 12:58:30 d2.evaluation.evaluator]: [0mInference done 5231/8355. 0.1154 s / img. ETA=0:06:06
[32m[04/28 12:58:35 d2.evaluation.evaluator]: [0mInference done 5274/8355. 0.1154 s / img. ETA=0:06:01
[32m[04/28 12:58:40 d2.evaluation.evaluator]: [0mInference done 5317/8355. 0.1154 s / img. ETA=0:05:55
[32m[04/28 12:58:45 d2.evaluation.evaluator]: [0mInference done 5360/8355. 0.1154 s / img. ETA=0:05:50
[32m[04/28 12:58:50 d2.evaluation.evaluator]: [0mInference done 5403/8355. 0.1154 s / img. ETA=0:05:45
[32m[04/28 12:58:55 d2.evaluation.evaluator]: [0mInference done 5445/8355. 0.1154 s / img. ETA=0:05:41
[32m[04/28 12:59:00 d2.evaluation.evaluator]: [0mInference done 5488/8355. 0.1154 s / img. ETA=0:05:35
[32m[04/28 12:59:05 d2.evaluation.evaluator]: [0mInference done 5531/8355. 0.1154 s / img. ETA=0:05:30
[32m[04/28 12:59:10 d2.evaluation.evaluator]: [0mInference done 5574/8355. 0.1154 s / img. ETA=0:05:25
[32m[04/28 12:59:15 d2.evaluation.evaluator]: [0mInference done 5617/8355. 0.1154 s / img. ETA=0:05:20
[32m[04/28 12:59:20 d2.evaluation.evaluator]: [0mInference done 5660/8355. 0.1154 s / img. ETA=0:05:15
[32m[04/28 12:59:25 d2.evaluation.evaluator]: [0mInference done 5703/8355. 0.1154 s / img. ETA=0:05:10
[32m[04/28 12:59:30 d2.evaluation.evaluator]: [0mInference done 5746/8355. 0.1154 s / img. ETA=0:05:05
[32m[04/28 12:59:35 d2.evaluation.evaluator]: [0mInference done 5789/8355. 0.1154 s / img. ETA=0:05:00
[32m[04/28 12:59:41 d2.evaluation.evaluator]: [0mInference done 5832/8355. 0.1154 s / img. ETA=0:04:55
[32m[04/28 12:59:46 d2.evaluation.evaluator]: [0mInference done 5875/8355. 0.1154 s / img. ETA=0:04:50
[32m[04/28 12:59:51 d2.evaluation.evaluator]: [0mInference done 5918/8355. 0.1154 s / img. ETA=0:04:45
[32m[04/28 12:59:56 d2.evaluation.evaluator]: [0mInference done 5961/8355. 0.1154 s / img. ETA=0:04:40
[32m[04/28 13:00:01 d2.evaluation.evaluator]: [0mInference done 6004/8355. 0.1154 s / img. ETA=0:04:35
[32m[04/28 13:00:06 d2.evaluation.evaluator]: [0mInference done 6047/8355. 0.1154 s / img. ETA=0:04:30
[32m[04/28 13:00:11 d2.evaluation.evaluator]: [0mInference done 6090/8355. 0.1154 s / img. ETA=0:04:25
[32m[04/28 13:00:16 d2.evaluation.evaluator]: [0mInference done 6133/8355. 0.1154 s / img. ETA=0:04:20
[32m[04/28 13:00:21 d2.evaluation.evaluator]: [0mInference done 6176/8355. 0.1154 s / img. ETA=0:04:15
[32m[04/28 13:00:26 d2.evaluation.evaluator]: [0mInference done 6219/8355. 0.1154 s / img. ETA=0:04:10
[32m[04/28 13:00:31 d2.evaluation.evaluator]: [0mInference done 6262/8355. 0.1154 s / img. ETA=0:04:05
[32m[04/28 13:00:36 d2.evaluation.evaluator]: [0mInference done 6305/8355. 0.1154 s / img. ETA=0:04:00
[32m[04/28 13:00:42 d2.evaluation.evaluator]: [0mInference done 6348/8355. 0.1154 s / img. ETA=0:03:55
[32m[04/28 13:00:47 d2.evaluation.evaluator]: [0mInference done 6391/8355. 0.1154 s / img. ETA=0:03:50
[32m[04/28 13:00:52 d2.evaluation.evaluator]: [0mInference done 6434/8355. 0.1155 s / img. ETA=0:03:45
[32m[04/28 13:00:57 d2.evaluation.evaluator]: [0mInference done 6477/8355. 0.1155 s / img. ETA=0:03:40
[32m[04/28 13:01:02 d2.evaluation.evaluator]: [0mInference done 6521/8355. 0.1154 s / img. ETA=0:03:35
[32m[04/28 13:01:07 d2.evaluation.evaluator]: [0mInference done 6565/8355. 0.1154 s / img. ETA=0:03:29
[32m[04/28 13:01:12 d2.evaluation.evaluator]: [0mInference done 6608/8355. 0.1154 s / img. ETA=0:03:24
[32m[04/28 13:01:17 d2.evaluation.evaluator]: [0mInference done 6651/8355. 0.1154 s / img. ETA=0:03:19
[32m[04/28 13:01:22 d2.evaluation.evaluator]: [0mInference done 6694/8355. 0.1154 s / img. ETA=0:03:14
[32m[04/28 13:01:27 d2.evaluation.evaluator]: [0mInference done 6737/8355. 0.1154 s / img. ETA=0:03:09
[32m[04/28 13:01:32 d2.evaluation.evaluator]: [0mInference done 6781/8355. 0.1154 s / img. ETA=0:03:04
[32m[04/28 13:01:37 d2.evaluation.evaluator]: [0mInference done 6824/8355. 0.1154 s / img. ETA=0:02:59
[32m[04/28 13:01:42 d2.evaluation.evaluator]: [0mInference done 6867/8355. 0.1154 s / img. ETA=0:02:54
[32m[04/28 13:01:47 d2.evaluation.evaluator]: [0mInference done 6910/8355. 0.1154 s / img. ETA=0:02:49
[32m[04/28 13:01:52 d2.evaluation.evaluator]: [0mInference done 6953/8355. 0.1154 s / img. ETA=0:02:44
[32m[04/28 13:01:57 d2.evaluation.evaluator]: [0mInference done 6996/8355. 0.1154 s / img. ETA=0:02:39
[32m[04/28 13:02:02 d2.evaluation.evaluator]: [0mInference done 7039/8355. 0.1154 s / img. ETA=0:02:34
[32m[04/28 13:02:07 d2.evaluation.evaluator]: [0mInference done 7082/8355. 0.1154 s / img. ETA=0:02:29
[32m[04/28 13:02:12 d2.evaluation.evaluator]: [0mInference done 7124/8355. 0.1154 s / img. ETA=0:02:24
[32m[04/28 13:02:18 d2.evaluation.evaluator]: [0mInference done 7167/8355. 0.1154 s / img. ETA=0:02:19
[32m[04/28 13:02:23 d2.evaluation.evaluator]: [0mInference done 7210/8355. 0.1154 s / img. ETA=0:02:14
[32m[04/28 13:02:28 d2.evaluation.evaluator]: [0mInference done 7253/8355. 0.1154 s / img. ETA=0:02:09
[32m[04/28 13:02:33 d2.evaluation.evaluator]: [0mInference done 7296/8355. 0.1155 s / img. ETA=0:02:04
[32m[04/28 13:02:38 d2.evaluation.evaluator]: [0mInference done 7339/8355. 0.1155 s / img. ETA=0:01:59
[32m[04/28 13:02:43 d2.evaluation.evaluator]: [0mInference done 7382/8355. 0.1155 s / img. ETA=0:01:54
[32m[04/28 13:02:48 d2.evaluation.evaluator]: [0mInference done 7425/8355. 0.1155 s / img. ETA=0:01:49
[32m[04/28 13:02:53 d2.evaluation.evaluator]: [0mInference done 7467/8355. 0.1155 s / img. ETA=0:01:44
[32m[04/28 13:02:58 d2.evaluation.evaluator]: [0mInference done 7510/8355. 0.1155 s / img. ETA=0:01:39
[32m[04/28 13:03:03 d2.evaluation.evaluator]: [0mInference done 7553/8355. 0.1155 s / img. ETA=0:01:34
[32m[04/28 13:03:08 d2.evaluation.evaluator]: [0mInference done 7596/8355. 0.1155 s / img. ETA=0:01:29
[32m[04/28 13:03:13 d2.evaluation.evaluator]: [0mInference done 7639/8355. 0.1155 s / img. ETA=0:01:24
[32m[04/28 13:03:18 d2.evaluation.evaluator]: [0mInference done 7681/8355. 0.1155 s / img. ETA=0:01:19
[32m[04/28 13:03:23 d2.evaluation.evaluator]: [0mInference done 7724/8355. 0.1155 s / img. ETA=0:01:14
[32m[04/28 13:03:28 d2.evaluation.evaluator]: [0mInference done 7767/8355. 0.1155 s / img. ETA=0:01:08
[32m[04/28 13:03:34 d2.evaluation.evaluator]: [0mInference done 7810/8355. 0.1155 s / img. ETA=0:01:03
[32m[04/28 13:03:39 d2.evaluation.evaluator]: [0mInference done 7852/8355. 0.1155 s / img. ETA=0:00:59
[32m[04/28 13:03:44 d2.evaluation.evaluator]: [0mInference done 7895/8355. 0.1155 s / img. ETA=0:00:53
[32m[04/28 13:03:49 d2.evaluation.evaluator]: [0mInference done 7938/8355. 0.1155 s / img. ETA=0:00:48
[32m[04/28 13:03:54 d2.evaluation.evaluator]: [0mInference done 7981/8355. 0.1155 s / img. ETA=0:00:43
[32m[04/28 13:03:59 d2.evaluation.evaluator]: [0mInference done 8024/8355. 0.1155 s / img. ETA=0:00:38
[32m[04/28 13:04:04 d2.evaluation.evaluator]: [0mInference done 8067/8355. 0.1155 s / img. ETA=0:00:33
[32m[04/28 13:04:09 d2.evaluation.evaluator]: [0mInference done 8110/8355. 0.1155 s / img. ETA=0:00:28
[32m[04/28 13:04:14 d2.evaluation.evaluator]: [0mInference done 8153/8355. 0.1155 s / img. ETA=0:00:23
[32m[04/28 13:04:19 d2.evaluation.evaluator]: [0mInference done 8197/8355. 0.1155 s / img. ETA=0:00:18
[32m[04/28 13:04:24 d2.evaluation.evaluator]: [0mInference done 8240/8355. 0.1155 s / img. ETA=0:00:13
[32m[04/28 13:04:29 d2.evaluation.evaluator]: [0mInference done 8283/8355. 0.1155 s / img. ETA=0:00:08
[32m[04/28 13:04:34 d2.evaluation.evaluator]: [0mInference done 8326/8355. 0.1155 s / img. ETA=0:00:03
[32m[04/28 13:04:38 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:20.277999 (0.117399 s / img per device, on 1 devices)
[32m[04/28 13:04:38 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:04 (0.115553 s / img per device, on 1 devices)
[32m[04/28 13:04:38 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 13:04:38 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 13:04:39 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.38s).
Accumulating evaluation results...
DONE (t=2.19s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.489
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.857
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.482
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.385
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.615
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.736
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.532
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.552
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.462
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.676
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[32m[04/28 13:05:01 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.862 | 85.722 | 48.190 | 38.499 | 61.502 | 73.600 |
[32m[04/28 13:05:01 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 47.422 | bicycle       | 40.576 | car            | 58.589 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 13:05:02 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 13:05:02 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 13:05:02 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 13:05:03 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1154 s / img. ETA=0:02:25
[32m[04/28 13:05:08 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1152 s / img. ETA=0:02:20
[32m[04/28 13:05:13 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1152 s / img. ETA=0:02:15
[32m[04/28 13:05:18 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1152 s / img. ETA=0:02:10
[32m[04/28 13:05:23 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1152 s / img. ETA=0:02:05
[32m[04/28 13:05:28 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1152 s / img. ETA=0:02:00
[32m[04/28 13:05:33 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1153 s / img. ETA=0:01:55
[32m[04/28 13:05:38 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1152 s / img. ETA=0:01:50
[32m[04/28 13:05:43 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1152 s / img. ETA=0:01:45
[32m[04/28 13:05:48 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1152 s / img. ETA=0:01:40
[32m[04/28 13:05:53 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1152 s / img. ETA=0:01:35
[32m[04/28 13:05:58 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1151 s / img. ETA=0:01:30
[32m[04/28 13:06:03 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1151 s / img. ETA=0:01:25
[32m[04/28 13:06:09 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1152 s / img. ETA=0:01:20
[32m[04/28 13:06:14 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1151 s / img. ETA=0:01:15
[32m[04/28 13:06:19 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1152 s / img. ETA=0:01:10
[32m[04/28 13:06:24 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1152 s / img. ETA=0:01:05
[32m[04/28 13:06:29 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1152 s / img. ETA=0:01:00
[32m[04/28 13:06:34 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1152 s / img. ETA=0:00:55
[32m[04/28 13:06:39 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1152 s / img. ETA=0:00:50
[32m[04/28 13:06:44 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1153 s / img. ETA=0:00:45
[32m[04/28 13:06:49 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1153 s / img. ETA=0:00:40
[32m[04/28 13:06:54 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1153 s / img. ETA=0:00:35
[32m[04/28 13:06:59 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1153 s / img. ETA=0:00:30
[32m[04/28 13:07:04 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1153 s / img. ETA=0:00:25
[32m[04/28 13:07:09 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1153 s / img. ETA=0:00:20
[32m[04/28 13:07:14 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1154 s / img. ETA=0:00:15
[32m[04/28 13:07:19 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1154 s / img. ETA=0:00:09
[32m[04/28 13:07:24 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1154 s / img. ETA=0:00:04
[32m[04/28 13:07:29 d2.evaluation.evaluator]: [0mInference done 1257/1257. 0.1154 s / img. ETA=0:00:00
[32m[04/28 13:07:29 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.933734 (0.117359 s / img per device, on 1 devices)
[32m[04/28 13:07:29 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115445 s / img per device, on 1 devices)
[32m[04/28 13:07:29 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 13:07:29 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 13:07:29 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.08s).
Accumulating evaluation results...
DONE (t=0.37s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.409
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.771
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.371
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.299
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.474
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.553
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.478
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.397
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.624
[32m[04/28 13:07:33 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.876 | 77.063 | 37.059 | 29.889 | 47.442 | 55.297 |
[32m[04/28 13:07:33 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 42.405 | bicycle       | 25.366 | car            | 54.858 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  19  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 13:07:34 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 13:07:34 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 13:07:34 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 13:07:34 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 13:07:34 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 13:07:34 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 13:07:35 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 13:07:55 d2.utils.events]: [0m eta: 0:17:04  iter: 19  total_loss: 0.543  loss_cls: 0.176  loss_box_reg: 0.317  loss_rpn_cls: 0.009  loss_rpn_loc: 0.048  time: 1.0275  data_time: 0.0223  lr: 0.000100  max_mem: 5397M
[32m[04/28 13:08:16 d2.utils.events]: [0m eta: 0:16:56  iter: 39  total_loss: 0.541  loss_cls: 0.154  loss_box_reg: 0.302  loss_rpn_cls: 0.009  loss_rpn_loc: 0.050  time: 1.0370  data_time: 0.0076  lr: 0.000200  max_mem: 5397M
[32m[04/28 13:08:37 d2.utils.events]: [0m eta: 0:16:27  iter: 59  total_loss: 0.447  loss_cls: 0.134  loss_box_reg: 0.268  loss_rpn_cls: 0.007  loss_rpn_loc: 0.031  time: 1.0340  data_time: 0.0078  lr: 0.000300  max_mem: 5397M
[32m[04/28 13:08:58 d2.utils.events]: [0m eta: 0:16:09  iter: 79  total_loss: 0.479  loss_cls: 0.142  loss_box_reg: 0.278  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0371  data_time: 0.0078  lr: 0.000400  max_mem: 5397M
[32m[04/28 13:09:18 d2.utils.events]: [0m eta: 0:15:45  iter: 99  total_loss: 0.543  loss_cls: 0.166  loss_box_reg: 0.308  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 1.0353  data_time: 0.0079  lr: 0.000500  max_mem: 5397M
[32m[04/28 13:09:39 d2.utils.events]: [0m eta: 0:15:24  iter: 119  total_loss: 0.447  loss_cls: 0.133  loss_box_reg: 0.264  loss_rpn_cls: 0.007  loss_rpn_loc: 0.038  time: 1.0360  data_time: 0.0077  lr: 0.000599  max_mem: 5397M
[32m[04/28 13:10:00 d2.utils.events]: [0m eta: 0:15:02  iter: 139  total_loss: 0.445  loss_cls: 0.149  loss_box_reg: 0.262  loss_rpn_cls: 0.007  loss_rpn_loc: 0.038  time: 1.0338  data_time: 0.0077  lr: 0.000699  max_mem: 5397M
[32m[04/28 13:10:20 d2.utils.events]: [0m eta: 0:14:39  iter: 159  total_loss: 0.462  loss_cls: 0.152  loss_box_reg: 0.276  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0317  data_time: 0.0075  lr: 0.000799  max_mem: 5397M
[32m[04/28 13:10:40 d2.utils.events]: [0m eta: 0:14:13  iter: 179  total_loss: 0.501  loss_cls: 0.153  loss_box_reg: 0.295  loss_rpn_cls: 0.007  loss_rpn_loc: 0.046  time: 1.0281  data_time: 0.0077  lr: 0.000899  max_mem: 5397M
[32m[04/28 13:11:00 d2.utils.events]: [0m eta: 0:13:44  iter: 199  total_loss: 0.542  loss_cls: 0.156  loss_box_reg: 0.304  loss_rpn_cls: 0.006  loss_rpn_loc: 0.050  time: 1.0266  data_time: 0.0077  lr: 0.000999  max_mem: 5397M
[32m[04/28 13:11:21 d2.utils.events]: [0m eta: 0:13:23  iter: 219  total_loss: 0.470  loss_cls: 0.140  loss_box_reg: 0.271  loss_rpn_cls: 0.007  loss_rpn_loc: 0.037  time: 1.0261  data_time: 0.0077  lr: 0.001099  max_mem: 5397M
[32m[04/28 13:11:42 d2.utils.events]: [0m eta: 0:13:05  iter: 239  total_loss: 0.510  loss_cls: 0.149  loss_box_reg: 0.306  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0274  data_time: 0.0084  lr: 0.001199  max_mem: 5397M
[32m[04/28 13:12:02 d2.utils.events]: [0m eta: 0:12:44  iter: 259  total_loss: 0.487  loss_cls: 0.157  loss_box_reg: 0.295  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0276  data_time: 0.0078  lr: 0.001299  max_mem: 5397M
[32m[04/28 13:12:23 d2.utils.events]: [0m eta: 0:12:22  iter: 279  total_loss: 0.532  loss_cls: 0.153  loss_box_reg: 0.310  loss_rpn_cls: 0.006  loss_rpn_loc: 0.044  time: 1.0278  data_time: 0.0075  lr: 0.001399  max_mem: 5397M
[32m[04/28 13:12:44 d2.utils.events]: [0m eta: 0:12:03  iter: 299  total_loss: 0.541  loss_cls: 0.156  loss_box_reg: 0.312  loss_rpn_cls: 0.005  loss_rpn_loc: 0.049  time: 1.0291  data_time: 0.0076  lr: 0.001499  max_mem: 5397M
[32m[04/28 13:13:05 d2.utils.events]: [0m eta: 0:11:42  iter: 319  total_loss: 0.507  loss_cls: 0.143  loss_box_reg: 0.296  loss_rpn_cls: 0.005  loss_rpn_loc: 0.057  time: 1.0294  data_time: 0.0077  lr: 0.001598  max_mem: 5397M
[32m[04/28 13:13:25 d2.utils.events]: [0m eta: 0:11:21  iter: 339  total_loss: 0.511  loss_cls: 0.158  loss_box_reg: 0.301  loss_rpn_cls: 0.004  loss_rpn_loc: 0.036  time: 1.0292  data_time: 0.0077  lr: 0.001698  max_mem: 5397M
[32m[04/28 13:13:46 d2.utils.events]: [0m eta: 0:11:01  iter: 359  total_loss: 0.487  loss_cls: 0.139  loss_box_reg: 0.297  loss_rpn_cls: 0.005  loss_rpn_loc: 0.039  time: 1.0295  data_time: 0.0085  lr: 0.001798  max_mem: 5397M
[32m[04/28 13:14:07 d2.utils.events]: [0m eta: 0:10:40  iter: 379  total_loss: 0.527  loss_cls: 0.155  loss_box_reg: 0.319  loss_rpn_cls: 0.006  loss_rpn_loc: 0.049  time: 1.0294  data_time: 0.0075  lr: 0.001898  max_mem: 5397M
[32m[04/28 13:14:28 d2.utils.events]: [0m eta: 0:10:23  iter: 399  total_loss: 0.497  loss_cls: 0.150  loss_box_reg: 0.298  loss_rpn_cls: 0.004  loss_rpn_loc: 0.044  time: 1.0304  data_time: 0.0076  lr: 0.001998  max_mem: 5397M
[32m[04/28 13:14:49 d2.utils.events]: [0m eta: 0:10:03  iter: 419  total_loss: 0.532  loss_cls: 0.163  loss_box_reg: 0.292  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0312  data_time: 0.0078  lr: 0.002098  max_mem: 5397M
[32m[04/28 13:15:09 d2.utils.events]: [0m eta: 0:09:42  iter: 439  total_loss: 0.485  loss_cls: 0.153  loss_box_reg: 0.280  loss_rpn_cls: 0.007  loss_rpn_loc: 0.054  time: 1.0308  data_time: 0.0077  lr: 0.002198  max_mem: 5397M
[32m[04/28 13:15:30 d2.utils.events]: [0m eta: 0:09:22  iter: 459  total_loss: 0.509  loss_cls: 0.155  loss_box_reg: 0.305  loss_rpn_cls: 0.004  loss_rpn_loc: 0.043  time: 1.0310  data_time: 0.0077  lr: 0.002298  max_mem: 5397M
[32m[04/28 13:15:51 d2.utils.events]: [0m eta: 0:09:01  iter: 479  total_loss: 0.536  loss_cls: 0.148  loss_box_reg: 0.328  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0310  data_time: 0.0077  lr: 0.002398  max_mem: 5397M
[32m[04/28 13:16:12 d2.utils.events]: [0m eta: 0:08:41  iter: 499  total_loss: 0.549  loss_cls: 0.163  loss_box_reg: 0.336  loss_rpn_cls: 0.005  loss_rpn_loc: 0.055  time: 1.0310  data_time: 0.0078  lr: 0.002498  max_mem: 5397M
[32m[04/28 13:16:32 d2.utils.events]: [0m eta: 0:08:20  iter: 519  total_loss: 0.516  loss_cls: 0.169  loss_box_reg: 0.300  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 1.0306  data_time: 0.0083  lr: 0.002597  max_mem: 5397M
[32m[04/28 13:16:53 d2.utils.events]: [0m eta: 0:07:58  iter: 539  total_loss: 0.457  loss_cls: 0.142  loss_box_reg: 0.261  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0308  data_time: 0.0078  lr: 0.002697  max_mem: 5397M
[32m[04/28 13:17:13 d2.utils.events]: [0m eta: 0:07:38  iter: 559  total_loss: 0.513  loss_cls: 0.151  loss_box_reg: 0.296  loss_rpn_cls: 0.008  loss_rpn_loc: 0.046  time: 1.0305  data_time: 0.0080  lr: 0.002797  max_mem: 5397M
[32m[04/28 13:17:34 d2.utils.events]: [0m eta: 0:07:17  iter: 579  total_loss: 0.519  loss_cls: 0.150  loss_box_reg: 0.308  loss_rpn_cls: 0.006  loss_rpn_loc: 0.051  time: 1.0301  data_time: 0.0076  lr: 0.002897  max_mem: 5397M
[32m[04/28 13:17:55 d2.utils.events]: [0m eta: 0:06:57  iter: 599  total_loss: 0.483  loss_cls: 0.141  loss_box_reg: 0.293  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0304  data_time: 0.0078  lr: 0.002997  max_mem: 5397M
[32m[04/28 13:18:15 d2.utils.events]: [0m eta: 0:06:35  iter: 619  total_loss: 0.501  loss_cls: 0.152  loss_box_reg: 0.297  loss_rpn_cls: 0.005  loss_rpn_loc: 0.053  time: 1.0297  data_time: 0.0076  lr: 0.003097  max_mem: 5397M
[32m[04/28 13:18:35 d2.utils.events]: [0m eta: 0:06:14  iter: 639  total_loss: 0.449  loss_cls: 0.134  loss_box_reg: 0.266  loss_rpn_cls: 0.004  loss_rpn_loc: 0.043  time: 1.0295  data_time: 0.0076  lr: 0.003197  max_mem: 5397M
[32m[04/28 13:18:56 d2.utils.events]: [0m eta: 0:05:53  iter: 659  total_loss: 0.478  loss_cls: 0.145  loss_box_reg: 0.275  loss_rpn_cls: 0.005  loss_rpn_loc: 0.042  time: 1.0292  data_time: 0.0076  lr: 0.003297  max_mem: 5397M
[32m[04/28 13:19:17 d2.utils.events]: [0m eta: 0:05:33  iter: 679  total_loss: 0.526  loss_cls: 0.164  loss_box_reg: 0.306  loss_rpn_cls: 0.010  loss_rpn_loc: 0.056  time: 1.0296  data_time: 0.0077  lr: 0.003397  max_mem: 5397M
[32m[04/28 13:19:37 d2.utils.events]: [0m eta: 0:05:12  iter: 699  total_loss: 0.539  loss_cls: 0.164  loss_box_reg: 0.324  loss_rpn_cls: 0.004  loss_rpn_loc: 0.044  time: 1.0295  data_time: 0.0075  lr: 0.003497  max_mem: 5397M
[32m[04/28 13:19:58 d2.utils.events]: [0m eta: 0:04:51  iter: 719  total_loss: 0.544  loss_cls: 0.163  loss_box_reg: 0.314  loss_rpn_cls: 0.007  loss_rpn_loc: 0.053  time: 1.0294  data_time: 0.0076  lr: 0.003596  max_mem: 5397M
[32m[04/28 13:20:18 d2.utils.events]: [0m eta: 0:04:30  iter: 739  total_loss: 0.520  loss_cls: 0.155  loss_box_reg: 0.289  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0292  data_time: 0.0076  lr: 0.003696  max_mem: 5397M
[32m[04/28 13:20:39 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.545  loss_cls: 0.168  loss_box_reg: 0.305  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 1.0290  data_time: 0.0076  lr: 0.003796  max_mem: 5397M
[32m[04/28 13:21:00 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.488  loss_cls: 0.154  loss_box_reg: 0.290  loss_rpn_cls: 0.008  loss_rpn_loc: 0.038  time: 1.0291  data_time: 0.0079  lr: 0.003896  max_mem: 5397M
[32m[04/28 13:21:20 d2.utils.events]: [0m eta: 0:03:28  iter: 799  total_loss: 0.510  loss_cls: 0.149  loss_box_reg: 0.295  loss_rpn_cls: 0.006  loss_rpn_loc: 0.055  time: 1.0291  data_time: 0.0078  lr: 0.003996  max_mem: 5397M
[32m[04/28 13:21:41 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.585  loss_cls: 0.171  loss_box_reg: 0.337  loss_rpn_cls: 0.008  loss_rpn_loc: 0.058  time: 1.0291  data_time: 0.0077  lr: 0.004096  max_mem: 5397M
[32m[04/28 13:22:01 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.497  loss_cls: 0.148  loss_box_reg: 0.297  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0289  data_time: 0.0078  lr: 0.004196  max_mem: 5397M
[32m[04/28 13:22:22 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.548  loss_cls: 0.170  loss_box_reg: 0.318  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0287  data_time: 0.0076  lr: 0.004296  max_mem: 5397M
[32m[04/28 13:22:42 d2.utils.events]: [0m eta: 0:02:04  iter: 879  total_loss: 0.549  loss_cls: 0.163  loss_box_reg: 0.311  loss_rpn_cls: 0.011  loss_rpn_loc: 0.063  time: 1.0279  data_time: 0.0076  lr: 0.004396  max_mem: 5397M
[32m[04/28 13:23:03 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.517  loss_cls: 0.169  loss_box_reg: 0.306  loss_rpn_cls: 0.007  loss_rpn_loc: 0.056  time: 1.0284  data_time: 0.0076  lr: 0.004496  max_mem: 5397M
[32m[04/28 13:23:23 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.531  loss_cls: 0.164  loss_box_reg: 0.297  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0281  data_time: 0.0075  lr: 0.004595  max_mem: 5397M
[32m[04/28 13:23:44 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.502  loss_cls: 0.155  loss_box_reg: 0.304  loss_rpn_cls: 0.004  loss_rpn_loc: 0.044  time: 1.0282  data_time: 0.0077  lr: 0.004695  max_mem: 5397M
[32m[04/28 13:24:05 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.538  loss_cls: 0.163  loss_box_reg: 0.315  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 1.0283  data_time: 0.0077  lr: 0.004795  max_mem: 5397M
[32m[04/28 13:24:25 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.512  loss_cls: 0.157  loss_box_reg: 0.303  loss_rpn_cls: 0.007  loss_rpn_loc: 0.037  time: 1.0281  data_time: 0.0075  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 13:24:48 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 13:24:48 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 13:24:48 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 13:24:48 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.568  loss_cls: 0.167  loss_box_reg: 0.331  loss_rpn_cls: 0.008  loss_rpn_loc: 0.059  time: 1.0276  data_time: 0.0077  lr: 0.004995  max_mem: 5397M
[32m[04/28 13:24:48 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:05 (1.0287 s / it)
[32m[04/28 13:24:48 d2.engine.hooks]: [0mTotal training time: 0:17:11 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 13:24:49 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 13:24:49 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 13:24:50 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 13:24:51 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1148 s / img. ETA=0:16:09
[32m[04/28 13:24:56 d2.evaluation.evaluator]: [0mInference done 54/8355. 0.1147 s / img. ETA=0:16:05
[32m[04/28 13:25:01 d2.evaluation.evaluator]: [0mInference done 98/8355. 0.1147 s / img. ETA=0:16:00
[32m[04/28 13:25:07 d2.evaluation.evaluator]: [0mInference done 142/8355. 0.1146 s / img. ETA=0:15:54
[32m[04/28 13:25:12 d2.evaluation.evaluator]: [0mInference done 185/8355. 0.1147 s / img. ETA=0:15:50
[32m[04/28 13:25:17 d2.evaluation.evaluator]: [0mInference done 228/8355. 0.1147 s / img. ETA=0:15:45
[32m[04/28 13:25:22 d2.evaluation.evaluator]: [0mInference done 271/8355. 0.1148 s / img. ETA=0:15:41
[32m[04/28 13:25:27 d2.evaluation.evaluator]: [0mInference done 314/8355. 0.1148 s / img. ETA=0:15:36
[32m[04/28 13:25:32 d2.evaluation.evaluator]: [0mInference done 357/8355. 0.1148 s / img. ETA=0:15:31
[32m[04/28 13:25:37 d2.evaluation.evaluator]: [0mInference done 400/8355. 0.1149 s / img. ETA=0:15:27
[32m[04/28 13:25:42 d2.evaluation.evaluator]: [0mInference done 443/8355. 0.1149 s / img. ETA=0:15:22
[32m[04/28 13:25:47 d2.evaluation.evaluator]: [0mInference done 487/8355. 0.1149 s / img. ETA=0:15:17
[32m[04/28 13:25:52 d2.evaluation.evaluator]: [0mInference done 531/8355. 0.1148 s / img. ETA=0:15:11
[32m[04/28 13:25:57 d2.evaluation.evaluator]: [0mInference done 574/8355. 0.1148 s / img. ETA=0:15:06
[32m[04/28 13:26:02 d2.evaluation.evaluator]: [0mInference done 617/8355. 0.1148 s / img. ETA=0:15:01
[32m[04/28 13:26:07 d2.evaluation.evaluator]: [0mInference done 660/8355. 0.1148 s / img. ETA=0:14:56
[32m[04/28 13:26:12 d2.evaluation.evaluator]: [0mInference done 703/8355. 0.1149 s / img. ETA=0:14:51
[32m[04/28 13:26:17 d2.evaluation.evaluator]: [0mInference done 746/8355. 0.1150 s / img. ETA=0:14:47
[32m[04/28 13:26:22 d2.evaluation.evaluator]: [0mInference done 789/8355. 0.1150 s / img. ETA=0:14:42
[32m[04/28 13:26:27 d2.evaluation.evaluator]: [0mInference done 832/8355. 0.1150 s / img. ETA=0:14:37
[32m[04/28 13:26:32 d2.evaluation.evaluator]: [0mInference done 875/8355. 0.1150 s / img. ETA=0:14:33
[32m[04/28 13:26:37 d2.evaluation.evaluator]: [0mInference done 918/8355. 0.1151 s / img. ETA=0:14:28
[32m[04/28 13:26:42 d2.evaluation.evaluator]: [0mInference done 961/8355. 0.1151 s / img. ETA=0:14:23
[32m[04/28 13:26:47 d2.evaluation.evaluator]: [0mInference done 1004/8355. 0.1151 s / img. ETA=0:14:18
[32m[04/28 13:26:52 d2.evaluation.evaluator]: [0mInference done 1047/8355. 0.1151 s / img. ETA=0:14:13
[32m[04/28 13:26:57 d2.evaluation.evaluator]: [0mInference done 1090/8355. 0.1151 s / img. ETA=0:14:08
[32m[04/28 13:27:02 d2.evaluation.evaluator]: [0mInference done 1134/8355. 0.1150 s / img. ETA=0:14:03
[32m[04/28 13:27:07 d2.evaluation.evaluator]: [0mInference done 1178/8355. 0.1150 s / img. ETA=0:13:57
[32m[04/28 13:27:13 d2.evaluation.evaluator]: [0mInference done 1222/8355. 0.1150 s / img. ETA=0:13:52
[32m[04/28 13:27:18 d2.evaluation.evaluator]: [0mInference done 1265/8355. 0.1150 s / img. ETA=0:13:47
[32m[04/28 13:27:23 d2.evaluation.evaluator]: [0mInference done 1308/8355. 0.1150 s / img. ETA=0:13:42
[32m[04/28 13:27:28 d2.evaluation.evaluator]: [0mInference done 1351/8355. 0.1150 s / img. ETA=0:13:37
[32m[04/28 13:27:33 d2.evaluation.evaluator]: [0mInference done 1394/8355. 0.1150 s / img. ETA=0:13:32
[32m[04/28 13:27:38 d2.evaluation.evaluator]: [0mInference done 1437/8355. 0.1150 s / img. ETA=0:13:27
[32m[04/28 13:27:43 d2.evaluation.evaluator]: [0mInference done 1480/8355. 0.1150 s / img. ETA=0:13:22
[32m[04/28 13:27:48 d2.evaluation.evaluator]: [0mInference done 1523/8355. 0.1150 s / img. ETA=0:13:17
[32m[04/28 13:27:53 d2.evaluation.evaluator]: [0mInference done 1566/8355. 0.1151 s / img. ETA=0:13:12
[32m[04/28 13:27:58 d2.evaluation.evaluator]: [0mInference done 1609/8355. 0.1151 s / img. ETA=0:13:08
[32m[04/28 13:28:03 d2.evaluation.evaluator]: [0mInference done 1651/8355. 0.1152 s / img. ETA=0:13:03
[32m[04/28 13:28:08 d2.evaluation.evaluator]: [0mInference done 1694/8355. 0.1152 s / img. ETA=0:12:59
[32m[04/28 13:28:13 d2.evaluation.evaluator]: [0mInference done 1737/8355. 0.1152 s / img. ETA=0:12:54
[32m[04/28 13:28:18 d2.evaluation.evaluator]: [0mInference done 1780/8355. 0.1153 s / img. ETA=0:12:49
[32m[04/28 13:28:23 d2.evaluation.evaluator]: [0mInference done 1823/8355. 0.1153 s / img. ETA=0:12:44
[32m[04/28 13:28:29 d2.evaluation.evaluator]: [0mInference done 1866/8355. 0.1154 s / img. ETA=0:12:39
[32m[04/28 13:28:34 d2.evaluation.evaluator]: [0mInference done 1909/8355. 0.1154 s / img. ETA=0:12:35
[32m[04/28 13:28:39 d2.evaluation.evaluator]: [0mInference done 1952/8355. 0.1154 s / img. ETA=0:12:30
[32m[04/28 13:28:44 d2.evaluation.evaluator]: [0mInference done 1995/8355. 0.1154 s / img. ETA=0:12:25
[32m[04/28 13:28:49 d2.evaluation.evaluator]: [0mInference done 2038/8355. 0.1154 s / img. ETA=0:12:20
[32m[04/28 13:28:54 d2.evaluation.evaluator]: [0mInference done 2081/8355. 0.1155 s / img. ETA=0:12:15
[32m[04/28 13:28:59 d2.evaluation.evaluator]: [0mInference done 2124/8355. 0.1155 s / img. ETA=0:12:10
[32m[04/28 13:29:04 d2.evaluation.evaluator]: [0mInference done 2167/8355. 0.1155 s / img. ETA=0:12:05
[32m[04/28 13:29:09 d2.evaluation.evaluator]: [0mInference done 2210/8355. 0.1155 s / img. ETA=0:12:00
[32m[04/28 13:29:14 d2.evaluation.evaluator]: [0mInference done 2252/8355. 0.1155 s / img. ETA=0:11:55
[32m[04/28 13:29:19 d2.evaluation.evaluator]: [0mInference done 2294/8355. 0.1156 s / img. ETA=0:11:51
[32m[04/28 13:29:24 d2.evaluation.evaluator]: [0mInference done 2337/8355. 0.1156 s / img. ETA=0:11:46
[32m[04/28 13:29:29 d2.evaluation.evaluator]: [0mInference done 2380/8355. 0.1156 s / img. ETA=0:11:41
[32m[04/28 13:29:34 d2.evaluation.evaluator]: [0mInference done 2423/8355. 0.1156 s / img. ETA=0:11:36
[32m[04/28 13:29:39 d2.evaluation.evaluator]: [0mInference done 2466/8355. 0.1156 s / img. ETA=0:11:31
[32m[04/28 13:29:44 d2.evaluation.evaluator]: [0mInference done 2509/8355. 0.1156 s / img. ETA=0:11:26
[32m[04/28 13:29:50 d2.evaluation.evaluator]: [0mInference done 2552/8355. 0.1156 s / img. ETA=0:11:21
[32m[04/28 13:29:55 d2.evaluation.evaluator]: [0mInference done 2595/8355. 0.1156 s / img. ETA=0:11:16
[32m[04/28 13:30:00 d2.evaluation.evaluator]: [0mInference done 2638/8355. 0.1156 s / img. ETA=0:11:11
[32m[04/28 13:30:05 d2.evaluation.evaluator]: [0mInference done 2681/8355. 0.1156 s / img. ETA=0:11:06
[32m[04/28 13:30:10 d2.evaluation.evaluator]: [0mInference done 2724/8355. 0.1156 s / img. ETA=0:11:01
[32m[04/28 13:30:15 d2.evaluation.evaluator]: [0mInference done 2767/8355. 0.1156 s / img. ETA=0:10:56
[32m[04/28 13:30:20 d2.evaluation.evaluator]: [0mInference done 2810/8355. 0.1156 s / img. ETA=0:10:51
[32m[04/28 13:30:25 d2.evaluation.evaluator]: [0mInference done 2853/8355. 0.1157 s / img. ETA=0:10:46
[32m[04/28 13:30:30 d2.evaluation.evaluator]: [0mInference done 2896/8355. 0.1157 s / img. ETA=0:10:41
[32m[04/28 13:30:35 d2.evaluation.evaluator]: [0mInference done 2939/8355. 0.1157 s / img. ETA=0:10:36
[32m[04/28 13:30:40 d2.evaluation.evaluator]: [0mInference done 2982/8355. 0.1157 s / img. ETA=0:10:31
[32m[04/28 13:30:45 d2.evaluation.evaluator]: [0mInference done 3025/8355. 0.1157 s / img. ETA=0:10:26
[32m[04/28 13:30:50 d2.evaluation.evaluator]: [0mInference done 3068/8355. 0.1157 s / img. ETA=0:10:21
[32m[04/28 13:30:55 d2.evaluation.evaluator]: [0mInference done 3111/8355. 0.1157 s / img. ETA=0:10:16
[32m[04/28 13:31:01 d2.evaluation.evaluator]: [0mInference done 3154/8355. 0.1157 s / img. ETA=0:10:11
[32m[04/28 13:31:06 d2.evaluation.evaluator]: [0mInference done 3198/8355. 0.1157 s / img. ETA=0:10:05
[32m[04/28 13:31:11 d2.evaluation.evaluator]: [0mInference done 3241/8355. 0.1157 s / img. ETA=0:10:00
[32m[04/28 13:31:16 d2.evaluation.evaluator]: [0mInference done 3284/8355. 0.1157 s / img. ETA=0:09:55
[32m[04/28 13:31:21 d2.evaluation.evaluator]: [0mInference done 3327/8355. 0.1157 s / img. ETA=0:09:50
[32m[04/28 13:31:26 d2.evaluation.evaluator]: [0mInference done 3370/8355. 0.1156 s / img. ETA=0:09:45
[32m[04/28 13:31:31 d2.evaluation.evaluator]: [0mInference done 3413/8355. 0.1156 s / img. ETA=0:09:40
[32m[04/28 13:31:36 d2.evaluation.evaluator]: [0mInference done 3456/8355. 0.1156 s / img. ETA=0:09:35
[32m[04/28 13:31:41 d2.evaluation.evaluator]: [0mInference done 3499/8355. 0.1156 s / img. ETA=0:09:30
[32m[04/28 13:31:46 d2.evaluation.evaluator]: [0mInference done 3542/8355. 0.1156 s / img. ETA=0:09:25
[32m[04/28 13:31:51 d2.evaluation.evaluator]: [0mInference done 3585/8355. 0.1156 s / img. ETA=0:09:20
[32m[04/28 13:31:56 d2.evaluation.evaluator]: [0mInference done 3628/8355. 0.1156 s / img. ETA=0:09:15
[32m[04/28 13:32:01 d2.evaluation.evaluator]: [0mInference done 3671/8355. 0.1156 s / img. ETA=0:09:09
[32m[04/28 13:32:06 d2.evaluation.evaluator]: [0mInference done 3714/8355. 0.1156 s / img. ETA=0:09:04
[32m[04/28 13:32:11 d2.evaluation.evaluator]: [0mInference done 3757/8355. 0.1156 s / img. ETA=0:08:59
[32m[04/28 13:32:16 d2.evaluation.evaluator]: [0mInference done 3800/8355. 0.1156 s / img. ETA=0:08:54
[32m[04/28 13:32:21 d2.evaluation.evaluator]: [0mInference done 3843/8355. 0.1156 s / img. ETA=0:08:49
[32m[04/28 13:32:26 d2.evaluation.evaluator]: [0mInference done 3886/8355. 0.1156 s / img. ETA=0:08:44
[32m[04/28 13:32:31 d2.evaluation.evaluator]: [0mInference done 3929/8355. 0.1156 s / img. ETA=0:08:39
[32m[04/28 13:32:36 d2.evaluation.evaluator]: [0mInference done 3972/8355. 0.1156 s / img. ETA=0:08:34
[32m[04/28 13:32:41 d2.evaluation.evaluator]: [0mInference done 4015/8355. 0.1156 s / img. ETA=0:08:29
[32m[04/28 13:32:46 d2.evaluation.evaluator]: [0mInference done 4058/8355. 0.1156 s / img. ETA=0:08:24
[32m[04/28 13:32:52 d2.evaluation.evaluator]: [0mInference done 4101/8355. 0.1156 s / img. ETA=0:08:19
[32m[04/28 13:32:57 d2.evaluation.evaluator]: [0mInference done 4144/8355. 0.1156 s / img. ETA=0:08:14
[32m[04/28 13:33:02 d2.evaluation.evaluator]: [0mInference done 4187/8355. 0.1156 s / img. ETA=0:08:09
[32m[04/28 13:33:07 d2.evaluation.evaluator]: [0mInference done 4230/8355. 0.1156 s / img. ETA=0:08:04
[32m[04/28 13:33:12 d2.evaluation.evaluator]: [0mInference done 4273/8355. 0.1156 s / img. ETA=0:07:59
[32m[04/28 13:33:17 d2.evaluation.evaluator]: [0mInference done 4316/8355. 0.1156 s / img. ETA=0:07:54
[32m[04/28 13:33:22 d2.evaluation.evaluator]: [0mInference done 4359/8355. 0.1156 s / img. ETA=0:07:49
[32m[04/28 13:33:27 d2.evaluation.evaluator]: [0mInference done 4402/8355. 0.1156 s / img. ETA=0:07:44
[32m[04/28 13:33:32 d2.evaluation.evaluator]: [0mInference done 4445/8355. 0.1156 s / img. ETA=0:07:39
[32m[04/28 13:33:37 d2.evaluation.evaluator]: [0mInference done 4488/8355. 0.1156 s / img. ETA=0:07:34
[32m[04/28 13:33:42 d2.evaluation.evaluator]: [0mInference done 4531/8355. 0.1156 s / img. ETA=0:07:29
[32m[04/28 13:33:47 d2.evaluation.evaluator]: [0mInference done 4574/8355. 0.1156 s / img. ETA=0:07:24
[32m[04/28 13:33:52 d2.evaluation.evaluator]: [0mInference done 4617/8355. 0.1156 s / img. ETA=0:07:19
[32m[04/28 13:33:57 d2.evaluation.evaluator]: [0mInference done 4660/8355. 0.1156 s / img. ETA=0:07:13
[32m[04/28 13:34:02 d2.evaluation.evaluator]: [0mInference done 4702/8355. 0.1157 s / img. ETA=0:07:09
[32m[04/28 13:34:07 d2.evaluation.evaluator]: [0mInference done 4745/8355. 0.1156 s / img. ETA=0:07:04
[32m[04/28 13:34:12 d2.evaluation.evaluator]: [0mInference done 4788/8355. 0.1156 s / img. ETA=0:06:59
[32m[04/28 13:34:17 d2.evaluation.evaluator]: [0mInference done 4831/8355. 0.1156 s / img. ETA=0:06:53
[32m[04/28 13:34:23 d2.evaluation.evaluator]: [0mInference done 4874/8355. 0.1156 s / img. ETA=0:06:48
[32m[04/28 13:34:28 d2.evaluation.evaluator]: [0mInference done 4917/8355. 0.1156 s / img. ETA=0:06:43
[32m[04/28 13:34:33 d2.evaluation.evaluator]: [0mInference done 4960/8355. 0.1156 s / img. ETA=0:06:38
[32m[04/28 13:34:38 d2.evaluation.evaluator]: [0mInference done 5003/8355. 0.1156 s / img. ETA=0:06:33
[32m[04/28 13:34:43 d2.evaluation.evaluator]: [0mInference done 5046/8355. 0.1156 s / img. ETA=0:06:28
[32m[04/28 13:34:48 d2.evaluation.evaluator]: [0mInference done 5089/8355. 0.1156 s / img. ETA=0:06:23
[32m[04/28 13:34:53 d2.evaluation.evaluator]: [0mInference done 5132/8355. 0.1156 s / img. ETA=0:06:18
[32m[04/28 13:34:58 d2.evaluation.evaluator]: [0mInference done 5175/8355. 0.1156 s / img. ETA=0:06:13
[32m[04/28 13:35:03 d2.evaluation.evaluator]: [0mInference done 5218/8355. 0.1156 s / img. ETA=0:06:08
[32m[04/28 13:35:08 d2.evaluation.evaluator]: [0mInference done 5261/8355. 0.1156 s / img. ETA=0:06:03
[32m[04/28 13:35:13 d2.evaluation.evaluator]: [0mInference done 5304/8355. 0.1156 s / img. ETA=0:05:58
[32m[04/28 13:35:18 d2.evaluation.evaluator]: [0mInference done 5347/8355. 0.1156 s / img. ETA=0:05:53
[32m[04/28 13:35:23 d2.evaluation.evaluator]: [0mInference done 5390/8355. 0.1156 s / img. ETA=0:05:48
[32m[04/28 13:35:28 d2.evaluation.evaluator]: [0mInference done 5433/8355. 0.1156 s / img. ETA=0:05:43
[32m[04/28 13:35:33 d2.evaluation.evaluator]: [0mInference done 5476/8355. 0.1156 s / img. ETA=0:05:38
[32m[04/28 13:35:38 d2.evaluation.evaluator]: [0mInference done 5519/8355. 0.1156 s / img. ETA=0:05:33
[32m[04/28 13:35:43 d2.evaluation.evaluator]: [0mInference done 5562/8355. 0.1156 s / img. ETA=0:05:28
[32m[04/28 13:35:48 d2.evaluation.evaluator]: [0mInference done 5605/8355. 0.1156 s / img. ETA=0:05:23
[32m[04/28 13:35:53 d2.evaluation.evaluator]: [0mInference done 5648/8355. 0.1156 s / img. ETA=0:05:17
[32m[04/28 13:35:58 d2.evaluation.evaluator]: [0mInference done 5691/8355. 0.1156 s / img. ETA=0:05:12
[32m[04/28 13:36:04 d2.evaluation.evaluator]: [0mInference done 5734/8355. 0.1156 s / img. ETA=0:05:07
[32m[04/28 13:36:09 d2.evaluation.evaluator]: [0mInference done 5777/8355. 0.1156 s / img. ETA=0:05:02
[32m[04/28 13:36:14 d2.evaluation.evaluator]: [0mInference done 5820/8355. 0.1156 s / img. ETA=0:04:57
[32m[04/28 13:36:19 d2.evaluation.evaluator]: [0mInference done 5863/8355. 0.1156 s / img. ETA=0:04:52
[32m[04/28 13:36:24 d2.evaluation.evaluator]: [0mInference done 5905/8355. 0.1157 s / img. ETA=0:04:47
[32m[04/28 13:36:29 d2.evaluation.evaluator]: [0mInference done 5948/8355. 0.1157 s / img. ETA=0:04:42
[32m[04/28 13:36:34 d2.evaluation.evaluator]: [0mInference done 5991/8355. 0.1157 s / img. ETA=0:04:37
[32m[04/28 13:36:39 d2.evaluation.evaluator]: [0mInference done 6034/8355. 0.1157 s / img. ETA=0:04:32
[32m[04/28 13:36:44 d2.evaluation.evaluator]: [0mInference done 6077/8355. 0.1157 s / img. ETA=0:04:27
[32m[04/28 13:36:49 d2.evaluation.evaluator]: [0mInference done 6120/8355. 0.1157 s / img. ETA=0:04:22
[32m[04/28 13:36:54 d2.evaluation.evaluator]: [0mInference done 6163/8355. 0.1157 s / img. ETA=0:04:17
[32m[04/28 13:36:59 d2.evaluation.evaluator]: [0mInference done 6206/8355. 0.1157 s / img. ETA=0:04:12
[32m[04/28 13:37:04 d2.evaluation.evaluator]: [0mInference done 6248/8355. 0.1157 s / img. ETA=0:04:07
[32m[04/28 13:37:09 d2.evaluation.evaluator]: [0mInference done 6291/8355. 0.1157 s / img. ETA=0:04:02
[32m[04/28 13:37:15 d2.evaluation.evaluator]: [0mInference done 6334/8355. 0.1157 s / img. ETA=0:03:57
[32m[04/28 13:37:20 d2.evaluation.evaluator]: [0mInference done 6377/8355. 0.1157 s / img. ETA=0:03:52
[32m[04/28 13:37:25 d2.evaluation.evaluator]: [0mInference done 6420/8355. 0.1157 s / img. ETA=0:03:47
[32m[04/28 13:37:30 d2.evaluation.evaluator]: [0mInference done 6463/8355. 0.1157 s / img. ETA=0:03:42
[32m[04/28 13:37:35 d2.evaluation.evaluator]: [0mInference done 6506/8355. 0.1157 s / img. ETA=0:03:37
[32m[04/28 13:37:40 d2.evaluation.evaluator]: [0mInference done 6549/8355. 0.1157 s / img. ETA=0:03:32
[32m[04/28 13:37:45 d2.evaluation.evaluator]: [0mInference done 6592/8355. 0.1157 s / img. ETA=0:03:27
[32m[04/28 13:37:50 d2.evaluation.evaluator]: [0mInference done 6635/8355. 0.1157 s / img. ETA=0:03:22
[32m[04/28 13:37:55 d2.evaluation.evaluator]: [0mInference done 6678/8355. 0.1157 s / img. ETA=0:03:17
[32m[04/28 13:38:00 d2.evaluation.evaluator]: [0mInference done 6721/8355. 0.1157 s / img. ETA=0:03:12
[32m[04/28 13:38:05 d2.evaluation.evaluator]: [0mInference done 6764/8355. 0.1157 s / img. ETA=0:03:06
[32m[04/28 13:38:10 d2.evaluation.evaluator]: [0mInference done 6807/8355. 0.1157 s / img. ETA=0:03:01
[32m[04/28 13:38:15 d2.evaluation.evaluator]: [0mInference done 6850/8355. 0.1157 s / img. ETA=0:02:56
[32m[04/28 13:38:20 d2.evaluation.evaluator]: [0mInference done 6893/8355. 0.1157 s / img. ETA=0:02:51
[32m[04/28 13:38:25 d2.evaluation.evaluator]: [0mInference done 6936/8355. 0.1157 s / img. ETA=0:02:46
[32m[04/28 13:38:30 d2.evaluation.evaluator]: [0mInference done 6979/8355. 0.1157 s / img. ETA=0:02:41
[32m[04/28 13:38:35 d2.evaluation.evaluator]: [0mInference done 7022/8355. 0.1157 s / img. ETA=0:02:36
[32m[04/28 13:38:40 d2.evaluation.evaluator]: [0mInference done 7065/8355. 0.1157 s / img. ETA=0:02:31
[32m[04/28 13:38:45 d2.evaluation.evaluator]: [0mInference done 7107/8355. 0.1157 s / img. ETA=0:02:26
[32m[04/28 13:38:50 d2.evaluation.evaluator]: [0mInference done 7150/8355. 0.1157 s / img. ETA=0:02:21
[32m[04/28 13:38:56 d2.evaluation.evaluator]: [0mInference done 7193/8355. 0.1157 s / img. ETA=0:02:16
[32m[04/28 13:39:01 d2.evaluation.evaluator]: [0mInference done 7236/8355. 0.1157 s / img. ETA=0:02:11
[32m[04/28 13:39:06 d2.evaluation.evaluator]: [0mInference done 7279/8355. 0.1157 s / img. ETA=0:02:06
[32m[04/28 13:39:11 d2.evaluation.evaluator]: [0mInference done 7322/8355. 0.1157 s / img. ETA=0:02:01
[32m[04/28 13:39:16 d2.evaluation.evaluator]: [0mInference done 7365/8355. 0.1157 s / img. ETA=0:01:56
[32m[04/28 13:39:21 d2.evaluation.evaluator]: [0mInference done 7408/8355. 0.1157 s / img. ETA=0:01:51
[32m[04/28 13:39:26 d2.evaluation.evaluator]: [0mInference done 7450/8355. 0.1158 s / img. ETA=0:01:46
[32m[04/28 13:39:31 d2.evaluation.evaluator]: [0mInference done 7492/8355. 0.1158 s / img. ETA=0:01:41
[32m[04/28 13:39:36 d2.evaluation.evaluator]: [0mInference done 7535/8355. 0.1158 s / img. ETA=0:01:36
[32m[04/28 13:39:41 d2.evaluation.evaluator]: [0mInference done 7578/8355. 0.1158 s / img. ETA=0:01:31
[32m[04/28 13:39:46 d2.evaluation.evaluator]: [0mInference done 7621/8355. 0.1158 s / img. ETA=0:01:26
[32m[04/28 13:39:51 d2.evaluation.evaluator]: [0mInference done 7664/8355. 0.1158 s / img. ETA=0:01:21
[32m[04/28 13:39:56 d2.evaluation.evaluator]: [0mInference done 7707/8355. 0.1158 s / img. ETA=0:01:16
[32m[04/28 13:40:02 d2.evaluation.evaluator]: [0mInference done 7750/8355. 0.1158 s / img. ETA=0:01:11
[32m[04/28 13:40:07 d2.evaluation.evaluator]: [0mInference done 7792/8355. 0.1158 s / img. ETA=0:01:06
[32m[04/28 13:40:12 d2.evaluation.evaluator]: [0mInference done 7835/8355. 0.1158 s / img. ETA=0:01:01
[32m[04/28 13:40:17 d2.evaluation.evaluator]: [0mInference done 7878/8355. 0.1158 s / img. ETA=0:00:56
[32m[04/28 13:40:22 d2.evaluation.evaluator]: [0mInference done 7921/8355. 0.1158 s / img. ETA=0:00:51
[32m[04/28 13:40:27 d2.evaluation.evaluator]: [0mInference done 7964/8355. 0.1158 s / img. ETA=0:00:45
[32m[04/28 13:40:32 d2.evaluation.evaluator]: [0mInference done 8007/8355. 0.1158 s / img. ETA=0:00:40
[32m[04/28 13:40:37 d2.evaluation.evaluator]: [0mInference done 8050/8355. 0.1158 s / img. ETA=0:00:35
[32m[04/28 13:40:42 d2.evaluation.evaluator]: [0mInference done 8093/8355. 0.1158 s / img. ETA=0:00:30
[32m[04/28 13:40:47 d2.evaluation.evaluator]: [0mInference done 8136/8355. 0.1158 s / img. ETA=0:00:25
[32m[04/28 13:40:52 d2.evaluation.evaluator]: [0mInference done 8179/8355. 0.1158 s / img. ETA=0:00:20
[32m[04/28 13:40:57 d2.evaluation.evaluator]: [0mInference done 8222/8355. 0.1158 s / img. ETA=0:00:15
[32m[04/28 13:41:02 d2.evaluation.evaluator]: [0mInference done 8265/8355. 0.1158 s / img. ETA=0:00:10
[32m[04/28 13:41:07 d2.evaluation.evaluator]: [0mInference done 8308/8355. 0.1158 s / img. ETA=0:00:05
[32m[04/28 13:41:12 d2.evaluation.evaluator]: [0mInference done 8351/8355. 0.1158 s / img. ETA=0:00:00
[32m[04/28 13:41:13 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:22.242718 (0.117634 s / img per device, on 1 devices)
[32m[04/28 13:41:13 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:06 (0.115786 s / img per device, on 1 devices)
[32m[04/28 13:41:13 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 13:41:13 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 13:41:13 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.51s).
Accumulating evaluation results...
DONE (t=2.15s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.840
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.467
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.599
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.708
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.523
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.539
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.452
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.739
[32m[04/28 13:41:35 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.332 | 83.983 | 46.736 | 37.474 | 59.916 | 70.762 |
[32m[04/28 13:41:35 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 44.223 | bicycle       | 41.304 | car            | 56.468 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 13:41:36 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 13:41:36 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 13:41:36 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 13:41:37 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1152 s / img. ETA=0:02:25
[32m[04/28 13:41:42 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1154 s / img. ETA=0:02:21
[32m[04/28 13:41:47 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1155 s / img. ETA=0:02:16
[32m[04/28 13:41:52 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1154 s / img. ETA=0:02:10
[32m[04/28 13:41:57 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1154 s / img. ETA=0:02:05
[32m[04/28 13:42:02 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1153 s / img. ETA=0:02:00
[32m[04/28 13:42:07 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1154 s / img. ETA=0:01:55
[32m[04/28 13:42:13 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1154 s / img. ETA=0:01:50
[32m[04/28 13:42:18 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1154 s / img. ETA=0:01:45
[32m[04/28 13:42:23 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1154 s / img. ETA=0:01:40
[32m[04/28 13:42:28 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1154 s / img. ETA=0:01:35
[32m[04/28 13:42:33 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1154 s / img. ETA=0:01:30
[32m[04/28 13:42:38 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1154 s / img. ETA=0:01:25
[32m[04/28 13:42:43 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1154 s / img. ETA=0:01:20
[32m[04/28 13:42:48 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1154 s / img. ETA=0:01:15
[32m[04/28 13:42:53 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1154 s / img. ETA=0:01:10
[32m[04/28 13:42:58 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1154 s / img. ETA=0:01:05
[32m[04/28 13:43:03 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1155 s / img. ETA=0:01:00
[32m[04/28 13:43:08 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1154 s / img. ETA=0:00:55
[32m[04/28 13:43:13 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1155 s / img. ETA=0:00:50
[32m[04/28 13:43:18 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1155 s / img. ETA=0:00:45
[32m[04/28 13:43:23 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1156 s / img. ETA=0:00:40
[32m[04/28 13:43:28 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1156 s / img. ETA=0:00:35
[32m[04/28 13:43:33 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1156 s / img. ETA=0:00:30
[32m[04/28 13:43:38 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1156 s / img. ETA=0:00:25
[32m[04/28 13:43:44 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1156 s / img. ETA=0:00:20
[32m[04/28 13:43:49 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1156 s / img. ETA=0:00:15
[32m[04/28 13:43:54 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1156 s / img. ETA=0:00:09
[32m[04/28 13:43:59 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1156 s / img. ETA=0:00:04
[32m[04/28 13:44:04 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:27.187697 (0.117562 s / img per device, on 1 devices)
[32m[04/28 13:44:04 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115641 s / img per device, on 1 devices)
[32m[04/28 13:44:04 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 13:44:04 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 13:44:04 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.26s).
Accumulating evaluation results...
DONE (t=0.37s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.357
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.733
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.297
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.272
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.411
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.468
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.172
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.437
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.442
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.383
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.479
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.509
[32m[04/28 13:44:08 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 35.707 | 73.295 | 29.734 | 27.182 | 41.084 | 46.839 |
[32m[04/28 13:44:08 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 37.111 | bicycle       | 17.956 | car            | 52.055 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  20  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 13:44:08 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 13:44:08 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 13:44:09 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 13:44:09 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 13:44:09 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 13:44:09 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 13:44:09 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 13:44:30 d2.utils.events]: [0m eta: 0:17:19  iter: 19  total_loss: 0.493  loss_cls: 0.147  loss_box_reg: 0.303  loss_rpn_cls: 0.007  loss_rpn_loc: 0.045  time: 1.0416  data_time: 0.0187  lr: 0.000100  max_mem: 5397M
[32m[04/28 13:44:50 d2.utils.events]: [0m eta: 0:16:36  iter: 39  total_loss: 0.489  loss_cls: 0.158  loss_box_reg: 0.268  loss_rpn_cls: 0.005  loss_rpn_loc: 0.045  time: 1.0286  data_time: 0.0078  lr: 0.000200  max_mem: 5397M
[32m[04/28 13:45:11 d2.utils.events]: [0m eta: 0:15:53  iter: 59  total_loss: 0.501  loss_cls: 0.149  loss_box_reg: 0.266  loss_rpn_cls: 0.008  loss_rpn_loc: 0.043  time: 1.0223  data_time: 0.0076  lr: 0.000300  max_mem: 5397M
[32m[04/28 13:45:31 d2.utils.events]: [0m eta: 0:15:32  iter: 79  total_loss: 0.535  loss_cls: 0.169  loss_box_reg: 0.310  loss_rpn_cls: 0.007  loss_rpn_loc: 0.059  time: 1.0207  data_time: 0.0077  lr: 0.000400  max_mem: 5397M
[32m[04/28 13:45:51 d2.utils.events]: [0m eta: 0:15:15  iter: 99  total_loss: 0.459  loss_cls: 0.143  loss_box_reg: 0.282  loss_rpn_cls: 0.007  loss_rpn_loc: 0.039  time: 1.0206  data_time: 0.0076  lr: 0.000500  max_mem: 5397M
[32m[04/28 13:46:12 d2.utils.events]: [0m eta: 0:14:55  iter: 119  total_loss: 0.497  loss_cls: 0.155  loss_box_reg: 0.292  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 1.0214  data_time: 0.0079  lr: 0.000599  max_mem: 5397M
[32m[04/28 13:46:32 d2.utils.events]: [0m eta: 0:14:35  iter: 139  total_loss: 0.463  loss_cls: 0.148  loss_box_reg: 0.275  loss_rpn_cls: 0.005  loss_rpn_loc: 0.039  time: 1.0210  data_time: 0.0077  lr: 0.000699  max_mem: 5397M
[32m[04/28 13:46:53 d2.utils.events]: [0m eta: 0:14:16  iter: 159  total_loss: 0.444  loss_cls: 0.133  loss_box_reg: 0.256  loss_rpn_cls: 0.003  loss_rpn_loc: 0.036  time: 1.0228  data_time: 0.0078  lr: 0.000799  max_mem: 5397M
[32m[04/28 13:47:14 d2.utils.events]: [0m eta: 0:13:57  iter: 179  total_loss: 0.461  loss_cls: 0.138  loss_box_reg: 0.271  loss_rpn_cls: 0.005  loss_rpn_loc: 0.037  time: 1.0257  data_time: 0.0077  lr: 0.000899  max_mem: 5397M
[32m[04/28 13:47:35 d2.utils.events]: [0m eta: 0:13:39  iter: 199  total_loss: 0.490  loss_cls: 0.151  loss_box_reg: 0.296  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0263  data_time: 0.0077  lr: 0.000999  max_mem: 5397M
[32m[04/28 13:47:56 d2.utils.events]: [0m eta: 0:13:24  iter: 219  total_loss: 0.472  loss_cls: 0.148  loss_box_reg: 0.276  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0273  data_time: 0.0076  lr: 0.001099  max_mem: 5397M
[32m[04/28 13:48:17 d2.utils.events]: [0m eta: 0:13:09  iter: 239  total_loss: 0.519  loss_cls: 0.159  loss_box_reg: 0.309  loss_rpn_cls: 0.009  loss_rpn_loc: 0.047  time: 1.0292  data_time: 0.0078  lr: 0.001199  max_mem: 5397M
[32m[04/28 13:48:37 d2.utils.events]: [0m eta: 0:12:46  iter: 259  total_loss: 0.499  loss_cls: 0.138  loss_box_reg: 0.285  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0284  data_time: 0.0078  lr: 0.001299  max_mem: 5397M
[32m[04/28 13:48:58 d2.utils.events]: [0m eta: 0:12:25  iter: 279  total_loss: 0.444  loss_cls: 0.134  loss_box_reg: 0.263  loss_rpn_cls: 0.004  loss_rpn_loc: 0.040  time: 1.0281  data_time: 0.0076  lr: 0.001399  max_mem: 5397M
[32m[04/28 13:49:18 d2.utils.events]: [0m eta: 0:12:03  iter: 299  total_loss: 0.459  loss_cls: 0.136  loss_box_reg: 0.274  loss_rpn_cls: 0.005  loss_rpn_loc: 0.046  time: 1.0277  data_time: 0.0076  lr: 0.001499  max_mem: 5397M
[32m[04/28 13:49:39 d2.utils.events]: [0m eta: 0:11:44  iter: 319  total_loss: 0.472  loss_cls: 0.142  loss_box_reg: 0.294  loss_rpn_cls: 0.004  loss_rpn_loc: 0.037  time: 1.0279  data_time: 0.0079  lr: 0.001598  max_mem: 5397M
[32m[04/28 13:49:59 d2.utils.events]: [0m eta: 0:11:23  iter: 339  total_loss: 0.507  loss_cls: 0.160  loss_box_reg: 0.292  loss_rpn_cls: 0.008  loss_rpn_loc: 0.040  time: 1.0279  data_time: 0.0078  lr: 0.001698  max_mem: 5397M
[32m[04/28 13:50:20 d2.utils.events]: [0m eta: 0:11:02  iter: 359  total_loss: 0.495  loss_cls: 0.154  loss_box_reg: 0.289  loss_rpn_cls: 0.004  loss_rpn_loc: 0.042  time: 1.0282  data_time: 0.0079  lr: 0.001798  max_mem: 5397M
[32m[04/28 13:50:41 d2.utils.events]: [0m eta: 0:10:41  iter: 379  total_loss: 0.457  loss_cls: 0.138  loss_box_reg: 0.275  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0282  data_time: 0.0077  lr: 0.001898  max_mem: 5397M
[32m[04/28 13:51:02 d2.utils.events]: [0m eta: 0:10:21  iter: 399  total_loss: 0.445  loss_cls: 0.142  loss_box_reg: 0.268  loss_rpn_cls: 0.005  loss_rpn_loc: 0.039  time: 1.0285  data_time: 0.0078  lr: 0.001998  max_mem: 5397M
[32m[04/28 13:51:23 d2.utils.events]: [0m eta: 0:10:03  iter: 419  total_loss: 0.441  loss_cls: 0.140  loss_box_reg: 0.250  loss_rpn_cls: 0.004  loss_rpn_loc: 0.041  time: 1.0298  data_time: 0.0076  lr: 0.002098  max_mem: 5397M
[32m[04/28 13:51:43 d2.utils.events]: [0m eta: 0:09:42  iter: 439  total_loss: 0.460  loss_cls: 0.146  loss_box_reg: 0.278  loss_rpn_cls: 0.007  loss_rpn_loc: 0.039  time: 1.0295  data_time: 0.0074  lr: 0.002198  max_mem: 5397M
[32m[04/28 13:52:05 d2.utils.events]: [0m eta: 0:09:23  iter: 459  total_loss: 0.506  loss_cls: 0.150  loss_box_reg: 0.290  loss_rpn_cls: 0.007  loss_rpn_loc: 0.038  time: 1.0310  data_time: 0.0076  lr: 0.002298  max_mem: 5397M
[32m[04/28 13:52:25 d2.utils.events]: [0m eta: 0:09:02  iter: 479  total_loss: 0.491  loss_cls: 0.149  loss_box_reg: 0.275  loss_rpn_cls: 0.007  loss_rpn_loc: 0.041  time: 1.0307  data_time: 0.0077  lr: 0.002398  max_mem: 5397M
[32m[04/28 13:52:46 d2.utils.events]: [0m eta: 0:08:41  iter: 499  total_loss: 0.479  loss_cls: 0.150  loss_box_reg: 0.288  loss_rpn_cls: 0.006  loss_rpn_loc: 0.048  time: 1.0303  data_time: 0.0077  lr: 0.002498  max_mem: 5397M
[32m[04/28 13:53:06 d2.utils.events]: [0m eta: 0:08:20  iter: 519  total_loss: 0.473  loss_cls: 0.142  loss_box_reg: 0.285  loss_rpn_cls: 0.004  loss_rpn_loc: 0.036  time: 1.0307  data_time: 0.0076  lr: 0.002597  max_mem: 5397M
[32m[04/28 13:53:27 d2.utils.events]: [0m eta: 0:08:00  iter: 539  total_loss: 0.457  loss_cls: 0.150  loss_box_reg: 0.273  loss_rpn_cls: 0.005  loss_rpn_loc: 0.034  time: 1.0312  data_time: 0.0074  lr: 0.002697  max_mem: 5397M
[32m[04/28 13:53:48 d2.utils.events]: [0m eta: 0:07:39  iter: 559  total_loss: 0.472  loss_cls: 0.140  loss_box_reg: 0.287  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 1.0315  data_time: 0.0077  lr: 0.002797  max_mem: 5397M
[32m[04/28 13:54:09 d2.utils.events]: [0m eta: 0:07:19  iter: 579  total_loss: 0.442  loss_cls: 0.134  loss_box_reg: 0.251  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0321  data_time: 0.0078  lr: 0.002897  max_mem: 5397M
[32m[04/28 13:54:30 d2.utils.events]: [0m eta: 0:06:59  iter: 599  total_loss: 0.499  loss_cls: 0.144  loss_box_reg: 0.283  loss_rpn_cls: 0.007  loss_rpn_loc: 0.049  time: 1.0325  data_time: 0.0076  lr: 0.002997  max_mem: 5397M
[32m[04/28 13:54:51 d2.utils.events]: [0m eta: 0:06:37  iter: 619  total_loss: 0.531  loss_cls: 0.148  loss_box_reg: 0.324  loss_rpn_cls: 0.006  loss_rpn_loc: 0.039  time: 1.0322  data_time: 0.0079  lr: 0.003097  max_mem: 5397M
[32m[04/28 13:55:11 d2.utils.events]: [0m eta: 0:06:17  iter: 639  total_loss: 0.511  loss_cls: 0.151  loss_box_reg: 0.294  loss_rpn_cls: 0.007  loss_rpn_loc: 0.054  time: 1.0324  data_time: 0.0077  lr: 0.003197  max_mem: 5397M
[32m[04/28 13:55:32 d2.utils.events]: [0m eta: 0:05:55  iter: 659  total_loss: 0.503  loss_cls: 0.151  loss_box_reg: 0.297  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 1.0320  data_time: 0.0077  lr: 0.003297  max_mem: 5397M
[32m[04/28 13:55:53 d2.utils.events]: [0m eta: 0:05:35  iter: 679  total_loss: 0.487  loss_cls: 0.155  loss_box_reg: 0.270  loss_rpn_cls: 0.008  loss_rpn_loc: 0.045  time: 1.0322  data_time: 0.0079  lr: 0.003397  max_mem: 5397M
[32m[04/28 13:56:14 d2.utils.events]: [0m eta: 0:05:14  iter: 699  total_loss: 0.573  loss_cls: 0.175  loss_box_reg: 0.324  loss_rpn_cls: 0.009  loss_rpn_loc: 0.056  time: 1.0330  data_time: 0.0083  lr: 0.003497  max_mem: 5397M
[32m[04/28 13:56:34 d2.utils.events]: [0m eta: 0:04:53  iter: 719  total_loss: 0.525  loss_cls: 0.156  loss_box_reg: 0.293  loss_rpn_cls: 0.006  loss_rpn_loc: 0.048  time: 1.0327  data_time: 0.0078  lr: 0.003596  max_mem: 5397M
[32m[04/28 13:56:55 d2.utils.events]: [0m eta: 0:04:32  iter: 739  total_loss: 0.513  loss_cls: 0.158  loss_box_reg: 0.301  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0323  data_time: 0.0076  lr: 0.003696  max_mem: 5397M
[32m[04/28 13:57:16 d2.utils.events]: [0m eta: 0:04:12  iter: 759  total_loss: 0.586  loss_cls: 0.181  loss_box_reg: 0.332  loss_rpn_cls: 0.008  loss_rpn_loc: 0.053  time: 1.0327  data_time: 0.0076  lr: 0.003796  max_mem: 5397M
[32m[04/28 13:57:36 d2.utils.events]: [0m eta: 0:03:50  iter: 779  total_loss: 0.534  loss_cls: 0.162  loss_box_reg: 0.309  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 1.0326  data_time: 0.0077  lr: 0.003896  max_mem: 5397M
[32m[04/28 13:57:57 d2.utils.events]: [0m eta: 0:03:29  iter: 799  total_loss: 0.506  loss_cls: 0.164  loss_box_reg: 0.297  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 1.0323  data_time: 0.0077  lr: 0.003996  max_mem: 5397M
[32m[04/28 13:58:18 d2.utils.events]: [0m eta: 0:03:09  iter: 819  total_loss: 0.513  loss_cls: 0.154  loss_box_reg: 0.306  loss_rpn_cls: 0.006  loss_rpn_loc: 0.044  time: 1.0321  data_time: 0.0074  lr: 0.004096  max_mem: 5397M
[32m[04/28 13:58:39 d2.utils.events]: [0m eta: 0:02:48  iter: 839  total_loss: 0.491  loss_cls: 0.153  loss_box_reg: 0.288  loss_rpn_cls: 0.005  loss_rpn_loc: 0.042  time: 1.0326  data_time: 0.0078  lr: 0.004196  max_mem: 5397M
[32m[04/28 13:58:59 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.498  loss_cls: 0.149  loss_box_reg: 0.299  loss_rpn_cls: 0.007  loss_rpn_loc: 0.051  time: 1.0325  data_time: 0.0076  lr: 0.004296  max_mem: 5397M
[32m[04/28 13:59:20 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.486  loss_cls: 0.151  loss_box_reg: 0.306  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 1.0323  data_time: 0.0077  lr: 0.004396  max_mem: 5397M
[32m[04/28 13:59:41 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.467  loss_cls: 0.151  loss_box_reg: 0.284  loss_rpn_cls: 0.005  loss_rpn_loc: 0.035  time: 1.0327  data_time: 0.0077  lr: 0.004496  max_mem: 5397M
[32m[04/28 14:00:01 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.518  loss_cls: 0.161  loss_box_reg: 0.304  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0324  data_time: 0.0076  lr: 0.004595  max_mem: 5397M
[32m[04/28 14:00:22 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.528  loss_cls: 0.147  loss_box_reg: 0.311  loss_rpn_cls: 0.006  loss_rpn_loc: 0.044  time: 1.0324  data_time: 0.0075  lr: 0.004695  max_mem: 5397M
[32m[04/28 14:00:42 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.530  loss_cls: 0.164  loss_box_reg: 0.308  loss_rpn_cls: 0.007  loss_rpn_loc: 0.045  time: 1.0321  data_time: 0.0075  lr: 0.004795  max_mem: 5397M
[32m[04/28 14:01:03 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.514  loss_cls: 0.157  loss_box_reg: 0.299  loss_rpn_cls: 0.006  loss_rpn_loc: 0.054  time: 1.0320  data_time: 0.0077  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 14:01:26 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 14:01:26 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 14:01:26 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 14:01:26 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.482  loss_cls: 0.146  loss_box_reg: 0.297  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0323  data_time: 0.0077  lr: 0.004995  max_mem: 5397M
[32m[04/28 14:01:27 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:10 (1.0334 s / it)
[32m[04/28 14:01:27 d2.engine.hooks]: [0mTotal training time: 0:17:15 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 14:01:28 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 14:01:28 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 14:01:29 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 14:01:30 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1142 s / img. ETA=0:16:04
[32m[04/28 14:01:35 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1143 s / img. ETA=0:16:02
[32m[04/28 14:01:40 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1141 s / img. ETA=0:15:55
[32m[04/28 14:01:45 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1141 s / img. ETA=0:15:50
[32m[04/28 14:01:50 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1141 s / img. ETA=0:15:45
[32m[04/28 14:01:56 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1142 s / img. ETA=0:15:41
[32m[04/28 14:02:01 d2.evaluation.evaluator]: [0mInference done 274/8355. 0.1143 s / img. ETA=0:15:36
[32m[04/28 14:02:06 d2.evaluation.evaluator]: [0mInference done 318/8355. 0.1143 s / img. ETA=0:15:32
[32m[04/28 14:02:11 d2.evaluation.evaluator]: [0mInference done 362/8355. 0.1143 s / img. ETA=0:15:27
[32m[04/28 14:02:16 d2.evaluation.evaluator]: [0mInference done 405/8355. 0.1144 s / img. ETA=0:15:22
[32m[04/28 14:02:21 d2.evaluation.evaluator]: [0mInference done 448/8355. 0.1144 s / img. ETA=0:15:17
[32m[04/28 14:02:26 d2.evaluation.evaluator]: [0mInference done 492/8355. 0.1143 s / img. ETA=0:15:12
[32m[04/28 14:02:31 d2.evaluation.evaluator]: [0mInference done 536/8355. 0.1143 s / img. ETA=0:15:06
[32m[04/28 14:02:36 d2.evaluation.evaluator]: [0mInference done 580/8355. 0.1143 s / img. ETA=0:15:01
[32m[04/28 14:02:41 d2.evaluation.evaluator]: [0mInference done 624/8355. 0.1143 s / img. ETA=0:14:56
[32m[04/28 14:02:46 d2.evaluation.evaluator]: [0mInference done 668/8355. 0.1143 s / img. ETA=0:14:51
[32m[04/28 14:02:51 d2.evaluation.evaluator]: [0mInference done 712/8355. 0.1143 s / img. ETA=0:14:46
[32m[04/28 14:02:56 d2.evaluation.evaluator]: [0mInference done 756/8355. 0.1143 s / img. ETA=0:14:41
[32m[04/28 14:03:01 d2.evaluation.evaluator]: [0mInference done 799/8355. 0.1143 s / img. ETA=0:14:36
[32m[04/28 14:03:06 d2.evaluation.evaluator]: [0mInference done 842/8355. 0.1144 s / img. ETA=0:14:31
[32m[04/28 14:03:11 d2.evaluation.evaluator]: [0mInference done 885/8355. 0.1144 s / img. ETA=0:14:27
[32m[04/28 14:03:16 d2.evaluation.evaluator]: [0mInference done 928/8355. 0.1144 s / img. ETA=0:14:22
[32m[04/28 14:03:22 d2.evaluation.evaluator]: [0mInference done 972/8355. 0.1144 s / img. ETA=0:14:17
[32m[04/28 14:03:27 d2.evaluation.evaluator]: [0mInference done 1015/8355. 0.1144 s / img. ETA=0:14:12
[32m[04/28 14:03:32 d2.evaluation.evaluator]: [0mInference done 1059/8355. 0.1144 s / img. ETA=0:14:06
[32m[04/28 14:03:37 d2.evaluation.evaluator]: [0mInference done 1103/8355. 0.1144 s / img. ETA=0:14:01
[32m[04/28 14:03:42 d2.evaluation.evaluator]: [0mInference done 1147/8355. 0.1144 s / img. ETA=0:13:56
[32m[04/28 14:03:47 d2.evaluation.evaluator]: [0mInference done 1191/8355. 0.1144 s / img. ETA=0:13:51
[32m[04/28 14:03:52 d2.evaluation.evaluator]: [0mInference done 1235/8355. 0.1143 s / img. ETA=0:13:45
[32m[04/28 14:03:57 d2.evaluation.evaluator]: [0mInference done 1279/8355. 0.1143 s / img. ETA=0:13:40
[32m[04/28 14:04:02 d2.evaluation.evaluator]: [0mInference done 1323/8355. 0.1143 s / img. ETA=0:13:35
[32m[04/28 14:04:07 d2.evaluation.evaluator]: [0mInference done 1367/8355. 0.1143 s / img. ETA=0:13:30
[32m[04/28 14:04:12 d2.evaluation.evaluator]: [0mInference done 1411/8355. 0.1143 s / img. ETA=0:13:25
[32m[04/28 14:04:17 d2.evaluation.evaluator]: [0mInference done 1454/8355. 0.1143 s / img. ETA=0:13:20
[32m[04/28 14:04:22 d2.evaluation.evaluator]: [0mInference done 1497/8355. 0.1143 s / img. ETA=0:13:15
[32m[04/28 14:04:27 d2.evaluation.evaluator]: [0mInference done 1540/8355. 0.1144 s / img. ETA=0:13:10
[32m[04/28 14:04:32 d2.evaluation.evaluator]: [0mInference done 1582/8355. 0.1144 s / img. ETA=0:13:06
[32m[04/28 14:04:38 d2.evaluation.evaluator]: [0mInference done 1625/8355. 0.1145 s / img. ETA=0:13:01
[32m[04/28 14:04:43 d2.evaluation.evaluator]: [0mInference done 1668/8355. 0.1145 s / img. ETA=0:12:57
[32m[04/28 14:04:48 d2.evaluation.evaluator]: [0mInference done 1711/8355. 0.1146 s / img. ETA=0:12:52
[32m[04/28 14:04:53 d2.evaluation.evaluator]: [0mInference done 1754/8355. 0.1146 s / img. ETA=0:12:47
[32m[04/28 14:04:58 d2.evaluation.evaluator]: [0mInference done 1797/8355. 0.1146 s / img. ETA=0:12:42
[32m[04/28 14:05:03 d2.evaluation.evaluator]: [0mInference done 1840/8355. 0.1146 s / img. ETA=0:12:37
[32m[04/28 14:05:08 d2.evaluation.evaluator]: [0mInference done 1883/8355. 0.1147 s / img. ETA=0:12:33
[32m[04/28 14:05:13 d2.evaluation.evaluator]: [0mInference done 1926/8355. 0.1147 s / img. ETA=0:12:28
[32m[04/28 14:05:18 d2.evaluation.evaluator]: [0mInference done 1969/8355. 0.1147 s / img. ETA=0:12:23
[32m[04/28 14:05:23 d2.evaluation.evaluator]: [0mInference done 2012/8355. 0.1147 s / img. ETA=0:12:18
[32m[04/28 14:05:28 d2.evaluation.evaluator]: [0mInference done 2055/8355. 0.1147 s / img. ETA=0:12:13
[32m[04/28 14:05:33 d2.evaluation.evaluator]: [0mInference done 2098/8355. 0.1147 s / img. ETA=0:12:08
[32m[04/28 14:05:38 d2.evaluation.evaluator]: [0mInference done 2141/8355. 0.1147 s / img. ETA=0:12:03
[32m[04/28 14:05:43 d2.evaluation.evaluator]: [0mInference done 2184/8355. 0.1147 s / img. ETA=0:11:58
[32m[04/28 14:05:48 d2.evaluation.evaluator]: [0mInference done 2227/8355. 0.1148 s / img. ETA=0:11:53
[32m[04/28 14:05:53 d2.evaluation.evaluator]: [0mInference done 2270/8355. 0.1148 s / img. ETA=0:11:48
[32m[04/28 14:05:58 d2.evaluation.evaluator]: [0mInference done 2313/8355. 0.1148 s / img. ETA=0:11:44
[32m[04/28 14:06:03 d2.evaluation.evaluator]: [0mInference done 2356/8355. 0.1148 s / img. ETA=0:11:39
[32m[04/28 14:06:08 d2.evaluation.evaluator]: [0mInference done 2399/8355. 0.1149 s / img. ETA=0:11:34
[32m[04/28 14:06:13 d2.evaluation.evaluator]: [0mInference done 2442/8355. 0.1149 s / img. ETA=0:11:29
[32m[04/28 14:06:19 d2.evaluation.evaluator]: [0mInference done 2485/8355. 0.1149 s / img. ETA=0:11:24
[32m[04/28 14:06:24 d2.evaluation.evaluator]: [0mInference done 2528/8355. 0.1149 s / img. ETA=0:11:19
[32m[04/28 14:06:29 d2.evaluation.evaluator]: [0mInference done 2571/8355. 0.1149 s / img. ETA=0:11:14
[32m[04/28 14:06:34 d2.evaluation.evaluator]: [0mInference done 2614/8355. 0.1149 s / img. ETA=0:11:09
[32m[04/28 14:06:39 d2.evaluation.evaluator]: [0mInference done 2657/8355. 0.1149 s / img. ETA=0:11:04
[32m[04/28 14:06:44 d2.evaluation.evaluator]: [0mInference done 2700/8355. 0.1149 s / img. ETA=0:10:59
[32m[04/28 14:06:49 d2.evaluation.evaluator]: [0mInference done 2743/8355. 0.1150 s / img. ETA=0:10:54
[32m[04/28 14:06:54 d2.evaluation.evaluator]: [0mInference done 2786/8355. 0.1150 s / img. ETA=0:10:49
[32m[04/28 14:06:59 d2.evaluation.evaluator]: [0mInference done 2829/8355. 0.1150 s / img. ETA=0:10:44
[32m[04/28 14:07:04 d2.evaluation.evaluator]: [0mInference done 2872/8355. 0.1150 s / img. ETA=0:10:39
[32m[04/28 14:07:09 d2.evaluation.evaluator]: [0mInference done 2915/8355. 0.1150 s / img. ETA=0:10:34
[32m[04/28 14:07:14 d2.evaluation.evaluator]: [0mInference done 2958/8355. 0.1150 s / img. ETA=0:10:30
[32m[04/28 14:07:19 d2.evaluation.evaluator]: [0mInference done 3001/8355. 0.1150 s / img. ETA=0:10:25
[32m[04/28 14:07:24 d2.evaluation.evaluator]: [0mInference done 3044/8355. 0.1150 s / img. ETA=0:10:20
[32m[04/28 14:07:29 d2.evaluation.evaluator]: [0mInference done 3087/8355. 0.1150 s / img. ETA=0:10:15
[32m[04/28 14:07:34 d2.evaluation.evaluator]: [0mInference done 3130/8355. 0.1150 s / img. ETA=0:10:10
[32m[04/28 14:07:39 d2.evaluation.evaluator]: [0mInference done 3174/8355. 0.1150 s / img. ETA=0:10:04
[32m[04/28 14:07:44 d2.evaluation.evaluator]: [0mInference done 3218/8355. 0.1150 s / img. ETA=0:09:59
[32m[04/28 14:07:49 d2.evaluation.evaluator]: [0mInference done 3261/8355. 0.1150 s / img. ETA=0:09:54
[32m[04/28 14:07:54 d2.evaluation.evaluator]: [0mInference done 3304/8355. 0.1150 s / img. ETA=0:09:49
[32m[04/28 14:08:00 d2.evaluation.evaluator]: [0mInference done 3348/8355. 0.1150 s / img. ETA=0:09:44
[32m[04/28 14:08:05 d2.evaluation.evaluator]: [0mInference done 3392/8355. 0.1150 s / img. ETA=0:09:39
[32m[04/28 14:08:10 d2.evaluation.evaluator]: [0mInference done 3435/8355. 0.1150 s / img. ETA=0:09:34
[32m[04/28 14:08:15 d2.evaluation.evaluator]: [0mInference done 3478/8355. 0.1150 s / img. ETA=0:09:29
[32m[04/28 14:08:20 d2.evaluation.evaluator]: [0mInference done 3521/8355. 0.1150 s / img. ETA=0:09:24
[32m[04/28 14:08:25 d2.evaluation.evaluator]: [0mInference done 3565/8355. 0.1150 s / img. ETA=0:09:19
[32m[04/28 14:08:30 d2.evaluation.evaluator]: [0mInference done 3608/8355. 0.1150 s / img. ETA=0:09:14
[32m[04/28 14:08:35 d2.evaluation.evaluator]: [0mInference done 3651/8355. 0.1150 s / img. ETA=0:09:09
[32m[04/28 14:08:40 d2.evaluation.evaluator]: [0mInference done 3694/8355. 0.1150 s / img. ETA=0:09:04
[32m[04/28 14:08:45 d2.evaluation.evaluator]: [0mInference done 3737/8355. 0.1150 s / img. ETA=0:08:59
[32m[04/28 14:08:50 d2.evaluation.evaluator]: [0mInference done 3780/8355. 0.1150 s / img. ETA=0:08:53
[32m[04/28 14:08:55 d2.evaluation.evaluator]: [0mInference done 3823/8355. 0.1150 s / img. ETA=0:08:48
[32m[04/28 14:09:00 d2.evaluation.evaluator]: [0mInference done 3865/8355. 0.1150 s / img. ETA=0:08:44
[32m[04/28 14:09:05 d2.evaluation.evaluator]: [0mInference done 3909/8355. 0.1150 s / img. ETA=0:08:39
[32m[04/28 14:09:10 d2.evaluation.evaluator]: [0mInference done 3953/8355. 0.1150 s / img. ETA=0:08:33
[32m[04/28 14:09:15 d2.evaluation.evaluator]: [0mInference done 3996/8355. 0.1150 s / img. ETA=0:08:28
[32m[04/28 14:09:20 d2.evaluation.evaluator]: [0mInference done 4039/8355. 0.1150 s / img. ETA=0:08:23
[32m[04/28 14:09:25 d2.evaluation.evaluator]: [0mInference done 4082/8355. 0.1150 s / img. ETA=0:08:18
[32m[04/28 14:09:30 d2.evaluation.evaluator]: [0mInference done 4125/8355. 0.1150 s / img. ETA=0:08:13
[32m[04/28 14:09:35 d2.evaluation.evaluator]: [0mInference done 4168/8355. 0.1150 s / img. ETA=0:08:08
[32m[04/28 14:09:40 d2.evaluation.evaluator]: [0mInference done 4210/8355. 0.1150 s / img. ETA=0:08:04
[32m[04/28 14:09:46 d2.evaluation.evaluator]: [0mInference done 4254/8355. 0.1150 s / img. ETA=0:07:58
[32m[04/28 14:09:51 d2.evaluation.evaluator]: [0mInference done 4298/8355. 0.1150 s / img. ETA=0:07:53
[32m[04/28 14:09:56 d2.evaluation.evaluator]: [0mInference done 4341/8355. 0.1150 s / img. ETA=0:07:48
[32m[04/28 14:10:01 d2.evaluation.evaluator]: [0mInference done 4384/8355. 0.1150 s / img. ETA=0:07:43
[32m[04/28 14:10:06 d2.evaluation.evaluator]: [0mInference done 4427/8355. 0.1150 s / img. ETA=0:07:38
[32m[04/28 14:10:11 d2.evaluation.evaluator]: [0mInference done 4470/8355. 0.1150 s / img. ETA=0:07:33
[32m[04/28 14:10:16 d2.evaluation.evaluator]: [0mInference done 4513/8355. 0.1150 s / img. ETA=0:07:28
[32m[04/28 14:10:21 d2.evaluation.evaluator]: [0mInference done 4556/8355. 0.1150 s / img. ETA=0:07:23
[32m[04/28 14:10:26 d2.evaluation.evaluator]: [0mInference done 4599/8355. 0.1150 s / img. ETA=0:07:18
[32m[04/28 14:10:31 d2.evaluation.evaluator]: [0mInference done 4642/8355. 0.1150 s / img. ETA=0:07:13
[32m[04/28 14:10:36 d2.evaluation.evaluator]: [0mInference done 4685/8355. 0.1150 s / img. ETA=0:07:08
[32m[04/28 14:10:41 d2.evaluation.evaluator]: [0mInference done 4729/8355. 0.1150 s / img. ETA=0:07:03
[32m[04/28 14:10:46 d2.evaluation.evaluator]: [0mInference done 4772/8355. 0.1150 s / img. ETA=0:06:58
[32m[04/28 14:10:51 d2.evaluation.evaluator]: [0mInference done 4815/8355. 0.1150 s / img. ETA=0:06:53
[32m[04/28 14:10:56 d2.evaluation.evaluator]: [0mInference done 4858/8355. 0.1151 s / img. ETA=0:06:48
[32m[04/28 14:11:01 d2.evaluation.evaluator]: [0mInference done 4901/8355. 0.1150 s / img. ETA=0:06:43
[32m[04/28 14:11:06 d2.evaluation.evaluator]: [0mInference done 4944/8355. 0.1150 s / img. ETA=0:06:38
[32m[04/28 14:11:11 d2.evaluation.evaluator]: [0mInference done 4987/8355. 0.1150 s / img. ETA=0:06:33
[32m[04/28 14:11:16 d2.evaluation.evaluator]: [0mInference done 5030/8355. 0.1150 s / img. ETA=0:06:28
[32m[04/28 14:11:21 d2.evaluation.evaluator]: [0mInference done 5073/8355. 0.1151 s / img. ETA=0:06:23
[32m[04/28 14:11:26 d2.evaluation.evaluator]: [0mInference done 5116/8355. 0.1151 s / img. ETA=0:06:18
[32m[04/28 14:11:31 d2.evaluation.evaluator]: [0mInference done 5159/8355. 0.1151 s / img. ETA=0:06:13
[32m[04/28 14:11:37 d2.evaluation.evaluator]: [0mInference done 5202/8355. 0.1151 s / img. ETA=0:06:08
[32m[04/28 14:11:42 d2.evaluation.evaluator]: [0mInference done 5245/8355. 0.1151 s / img. ETA=0:06:03
[32m[04/28 14:11:47 d2.evaluation.evaluator]: [0mInference done 5288/8355. 0.1151 s / img. ETA=0:05:58
[32m[04/28 14:11:52 d2.evaluation.evaluator]: [0mInference done 5331/8355. 0.1151 s / img. ETA=0:05:53
[32m[04/28 14:11:57 d2.evaluation.evaluator]: [0mInference done 5374/8355. 0.1151 s / img. ETA=0:05:48
[32m[04/28 14:12:02 d2.evaluation.evaluator]: [0mInference done 5417/8355. 0.1151 s / img. ETA=0:05:43
[32m[04/28 14:12:07 d2.evaluation.evaluator]: [0mInference done 5460/8355. 0.1151 s / img. ETA=0:05:38
[32m[04/28 14:12:12 d2.evaluation.evaluator]: [0mInference done 5503/8355. 0.1151 s / img. ETA=0:05:33
[32m[04/28 14:12:17 d2.evaluation.evaluator]: [0mInference done 5546/8355. 0.1151 s / img. ETA=0:05:28
[32m[04/28 14:12:22 d2.evaluation.evaluator]: [0mInference done 5590/8355. 0.1151 s / img. ETA=0:05:23
[32m[04/28 14:12:27 d2.evaluation.evaluator]: [0mInference done 5633/8355. 0.1151 s / img. ETA=0:05:18
[32m[04/28 14:12:32 d2.evaluation.evaluator]: [0mInference done 5676/8355. 0.1151 s / img. ETA=0:05:13
[32m[04/28 14:12:37 d2.evaluation.evaluator]: [0mInference done 5719/8355. 0.1151 s / img. ETA=0:05:08
[32m[04/28 14:12:42 d2.evaluation.evaluator]: [0mInference done 5762/8355. 0.1151 s / img. ETA=0:05:03
[32m[04/28 14:12:47 d2.evaluation.evaluator]: [0mInference done 5805/8355. 0.1151 s / img. ETA=0:04:57
[32m[04/28 14:12:52 d2.evaluation.evaluator]: [0mInference done 5848/8355. 0.1151 s / img. ETA=0:04:52
[32m[04/28 14:12:57 d2.evaluation.evaluator]: [0mInference done 5891/8355. 0.1151 s / img. ETA=0:04:47
[32m[04/28 14:13:02 d2.evaluation.evaluator]: [0mInference done 5934/8355. 0.1151 s / img. ETA=0:04:42
[32m[04/28 14:13:07 d2.evaluation.evaluator]: [0mInference done 5977/8355. 0.1151 s / img. ETA=0:04:37
[32m[04/28 14:13:12 d2.evaluation.evaluator]: [0mInference done 6020/8355. 0.1151 s / img. ETA=0:04:32
[32m[04/28 14:13:18 d2.evaluation.evaluator]: [0mInference done 6063/8355. 0.1151 s / img. ETA=0:04:27
[32m[04/28 14:13:23 d2.evaluation.evaluator]: [0mInference done 6106/8355. 0.1151 s / img. ETA=0:04:22
[32m[04/28 14:13:28 d2.evaluation.evaluator]: [0mInference done 6149/8355. 0.1151 s / img. ETA=0:04:17
[32m[04/28 14:13:33 d2.evaluation.evaluator]: [0mInference done 6192/8355. 0.1151 s / img. ETA=0:04:12
[32m[04/28 14:13:38 d2.evaluation.evaluator]: [0mInference done 6235/8355. 0.1152 s / img. ETA=0:04:07
[32m[04/28 14:13:43 d2.evaluation.evaluator]: [0mInference done 6278/8355. 0.1152 s / img. ETA=0:04:02
[32m[04/28 14:13:48 d2.evaluation.evaluator]: [0mInference done 6321/8355. 0.1152 s / img. ETA=0:03:57
[32m[04/28 14:13:53 d2.evaluation.evaluator]: [0mInference done 6364/8355. 0.1152 s / img. ETA=0:03:52
[32m[04/28 14:13:58 d2.evaluation.evaluator]: [0mInference done 6407/8355. 0.1152 s / img. ETA=0:03:47
[32m[04/28 14:14:03 d2.evaluation.evaluator]: [0mInference done 6450/8355. 0.1152 s / img. ETA=0:03:42
[32m[04/28 14:14:08 d2.evaluation.evaluator]: [0mInference done 6493/8355. 0.1152 s / img. ETA=0:03:37
[32m[04/28 14:14:13 d2.evaluation.evaluator]: [0mInference done 6536/8355. 0.1152 s / img. ETA=0:03:32
[32m[04/28 14:14:18 d2.evaluation.evaluator]: [0mInference done 6580/8355. 0.1152 s / img. ETA=0:03:27
[32m[04/28 14:14:23 d2.evaluation.evaluator]: [0mInference done 6623/8355. 0.1152 s / img. ETA=0:03:22
[32m[04/28 14:14:29 d2.evaluation.evaluator]: [0mInference done 6667/8355. 0.1152 s / img. ETA=0:03:17
[32m[04/28 14:14:34 d2.evaluation.evaluator]: [0mInference done 6711/8355. 0.1152 s / img. ETA=0:03:12
[32m[04/28 14:14:39 d2.evaluation.evaluator]: [0mInference done 6755/8355. 0.1152 s / img. ETA=0:03:07
[32m[04/28 14:14:44 d2.evaluation.evaluator]: [0mInference done 6798/8355. 0.1152 s / img. ETA=0:03:02
[32m[04/28 14:14:49 d2.evaluation.evaluator]: [0mInference done 6841/8355. 0.1152 s / img. ETA=0:02:57
[32m[04/28 14:14:54 d2.evaluation.evaluator]: [0mInference done 6884/8355. 0.1152 s / img. ETA=0:02:52
[32m[04/28 14:14:59 d2.evaluation.evaluator]: [0mInference done 6927/8355. 0.1152 s / img. ETA=0:02:47
[32m[04/28 14:15:04 d2.evaluation.evaluator]: [0mInference done 6970/8355. 0.1152 s / img. ETA=0:02:41
[32m[04/28 14:15:09 d2.evaluation.evaluator]: [0mInference done 7013/8355. 0.1152 s / img. ETA=0:02:36
[32m[04/28 14:15:14 d2.evaluation.evaluator]: [0mInference done 7056/8355. 0.1152 s / img. ETA=0:02:31
[32m[04/28 14:15:19 d2.evaluation.evaluator]: [0mInference done 7099/8355. 0.1152 s / img. ETA=0:02:26
[32m[04/28 14:15:24 d2.evaluation.evaluator]: [0mInference done 7141/8355. 0.1152 s / img. ETA=0:02:22
[32m[04/28 14:15:29 d2.evaluation.evaluator]: [0mInference done 7184/8355. 0.1152 s / img. ETA=0:02:16
[32m[04/28 14:15:34 d2.evaluation.evaluator]: [0mInference done 7227/8355. 0.1152 s / img. ETA=0:02:11
[32m[04/28 14:15:39 d2.evaluation.evaluator]: [0mInference done 7270/8355. 0.1152 s / img. ETA=0:02:06
[32m[04/28 14:15:44 d2.evaluation.evaluator]: [0mInference done 7313/8355. 0.1152 s / img. ETA=0:02:01
[32m[04/28 14:15:49 d2.evaluation.evaluator]: [0mInference done 7356/8355. 0.1152 s / img. ETA=0:01:56
[32m[04/28 14:15:54 d2.evaluation.evaluator]: [0mInference done 7399/8355. 0.1152 s / img. ETA=0:01:51
[32m[04/28 14:16:00 d2.evaluation.evaluator]: [0mInference done 7442/8355. 0.1152 s / img. ETA=0:01:46
[32m[04/28 14:16:05 d2.evaluation.evaluator]: [0mInference done 7485/8355. 0.1152 s / img. ETA=0:01:41
[32m[04/28 14:16:10 d2.evaluation.evaluator]: [0mInference done 7528/8355. 0.1152 s / img. ETA=0:01:36
[32m[04/28 14:16:15 d2.evaluation.evaluator]: [0mInference done 7571/8355. 0.1152 s / img. ETA=0:01:31
[32m[04/28 14:16:20 d2.evaluation.evaluator]: [0mInference done 7614/8355. 0.1152 s / img. ETA=0:01:26
[32m[04/28 14:16:25 d2.evaluation.evaluator]: [0mInference done 7657/8355. 0.1152 s / img. ETA=0:01:21
[32m[04/28 14:16:30 d2.evaluation.evaluator]: [0mInference done 7700/8355. 0.1152 s / img. ETA=0:01:16
[32m[04/28 14:16:35 d2.evaluation.evaluator]: [0mInference done 7743/8355. 0.1152 s / img. ETA=0:01:11
[32m[04/28 14:16:40 d2.evaluation.evaluator]: [0mInference done 7785/8355. 0.1152 s / img. ETA=0:01:06
[32m[04/28 14:16:45 d2.evaluation.evaluator]: [0mInference done 7828/8355. 0.1152 s / img. ETA=0:01:01
[32m[04/28 14:16:50 d2.evaluation.evaluator]: [0mInference done 7871/8355. 0.1152 s / img. ETA=0:00:56
[32m[04/28 14:16:55 d2.evaluation.evaluator]: [0mInference done 7914/8355. 0.1152 s / img. ETA=0:00:51
[32m[04/28 14:17:00 d2.evaluation.evaluator]: [0mInference done 7957/8355. 0.1153 s / img. ETA=0:00:46
[32m[04/28 14:17:05 d2.evaluation.evaluator]: [0mInference done 8000/8355. 0.1153 s / img. ETA=0:00:41
[32m[04/28 14:17:10 d2.evaluation.evaluator]: [0mInference done 8043/8355. 0.1153 s / img. ETA=0:00:36
[32m[04/28 14:17:15 d2.evaluation.evaluator]: [0mInference done 8086/8355. 0.1153 s / img. ETA=0:00:31
[32m[04/28 14:17:20 d2.evaluation.evaluator]: [0mInference done 8130/8355. 0.1152 s / img. ETA=0:00:26
[32m[04/28 14:17:25 d2.evaluation.evaluator]: [0mInference done 8174/8355. 0.1152 s / img. ETA=0:00:21
[32m[04/28 14:17:30 d2.evaluation.evaluator]: [0mInference done 8217/8355. 0.1152 s / img. ETA=0:00:16
[32m[04/28 14:17:36 d2.evaluation.evaluator]: [0mInference done 8260/8355. 0.1152 s / img. ETA=0:00:11
[32m[04/28 14:17:41 d2.evaluation.evaluator]: [0mInference done 8303/8355. 0.1152 s / img. ETA=0:00:06
[32m[04/28 14:17:46 d2.evaluation.evaluator]: [0mInference done 8346/8355. 0.1152 s / img. ETA=0:00:01
[32m[04/28 14:17:47 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:17.364135 (0.117050 s / img per device, on 1 devices)
[32m[04/28 14:17:47 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:02 (0.115240 s / img per device, on 1 devices)
[32m[04/28 14:17:47 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 14:17:47 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 14:17:47 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.01s).
Accumulating evaluation results...
DONE (t=2.17s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.847
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.503
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.384
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.747
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.184
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.534
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.553
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.461
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[32m[04/28 14:18:10 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.202 | 84.695 | 50.271 | 38.410 | 61.677 | 74.704 |
[32m[04/28 14:18:10 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 48.981 | bicycle       | 41.107 | car            | 57.520 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 14:18:10 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 14:18:10 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 14:18:10 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 14:18:12 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1152 s / img. ETA=0:02:25
[32m[04/28 14:18:17 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1149 s / img. ETA=0:02:20
[32m[04/28 14:18:22 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1150 s / img. ETA=0:02:15
[32m[04/28 14:18:27 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1149 s / img. ETA=0:02:10
[32m[04/28 14:18:32 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1149 s / img. ETA=0:02:05
[32m[04/28 14:18:37 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1149 s / img. ETA=0:02:00
[32m[04/28 14:18:42 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1149 s / img. ETA=0:01:55
[32m[04/28 14:18:47 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1149 s / img. ETA=0:01:50
[32m[04/28 14:18:52 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1149 s / img. ETA=0:01:45
[32m[04/28 14:18:57 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1149 s / img. ETA=0:01:40
[32m[04/28 14:19:02 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1149 s / img. ETA=0:01:35
[32m[04/28 14:19:07 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1149 s / img. ETA=0:01:30
[32m[04/28 14:19:12 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1149 s / img. ETA=0:01:25
[32m[04/28 14:19:17 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1149 s / img. ETA=0:01:20
[32m[04/28 14:19:22 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1149 s / img. ETA=0:01:15
[32m[04/28 14:19:27 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1150 s / img. ETA=0:01:10
[32m[04/28 14:19:32 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1150 s / img. ETA=0:01:05
[32m[04/28 14:19:37 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1150 s / img. ETA=0:01:00
[32m[04/28 14:19:42 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1150 s / img. ETA=0:00:55
[32m[04/28 14:19:47 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1150 s / img. ETA=0:00:50
[32m[04/28 14:19:52 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1150 s / img. ETA=0:00:45
[32m[04/28 14:19:57 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1151 s / img. ETA=0:00:40
[32m[04/28 14:20:02 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1151 s / img. ETA=0:00:35
[32m[04/28 14:20:07 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1151 s / img. ETA=0:00:30
[32m[04/28 14:20:12 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1151 s / img. ETA=0:00:25
[32m[04/28 14:20:17 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1151 s / img. ETA=0:00:20
[32m[04/28 14:20:22 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1151 s / img. ETA=0:00:14
[32m[04/28 14:20:27 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1152 s / img. ETA=0:00:09
[32m[04/28 14:20:33 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1152 s / img. ETA=0:00:04
[32m[04/28 14:20:37 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.553721 (0.117056 s / img per device, on 1 devices)
[32m[04/28 14:20:37 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115166 s / img per device, on 1 devices)
[32m[04/28 14:20:38 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 14:20:38 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 14:20:38 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.30s).
Accumulating evaluation results...
DONE (t=0.37s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.385
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.744
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.348
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.284
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.438
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.558
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.177
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.460
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.398
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.501
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621
[32m[04/28 14:20:41 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 38.522 | 74.358 | 34.834 | 28.441 | 43.818 | 55.780 |
[32m[04/28 14:20:41 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 43.626 | bicycle       | 17.821 | car            | 54.120 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  21  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 14:20:42 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 14:20:42 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 14:20:42 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 14:20:43 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 14:20:43 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 14:20:43 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 14:20:43 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 14:21:03 d2.utils.events]: [0m eta: 0:16:05  iter: 19  total_loss: 0.486  loss_cls: 0.157  loss_box_reg: 0.284  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 0.9837  data_time: 0.0180  lr: 0.000100  max_mem: 5397M
[32m[04/28 14:21:23 d2.utils.events]: [0m eta: 0:16:05  iter: 39  total_loss: 0.488  loss_cls: 0.147  loss_box_reg: 0.277  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 0.9992  data_time: 0.0076  lr: 0.000200  max_mem: 5397M
[32m[04/28 14:21:44 d2.utils.events]: [0m eta: 0:15:58  iter: 59  total_loss: 0.522  loss_cls: 0.151  loss_box_reg: 0.305  loss_rpn_cls: 0.007  loss_rpn_loc: 0.041  time: 1.0168  data_time: 0.0078  lr: 0.000300  max_mem: 5397M
[32m[04/28 14:22:05 d2.utils.events]: [0m eta: 0:15:46  iter: 79  total_loss: 0.568  loss_cls: 0.178  loss_box_reg: 0.336  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0231  data_time: 0.0077  lr: 0.000400  max_mem: 5397M
[32m[04/28 14:22:26 d2.utils.events]: [0m eta: 0:15:25  iter: 99  total_loss: 0.541  loss_cls: 0.157  loss_box_reg: 0.310  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0260  data_time: 0.0077  lr: 0.000500  max_mem: 5397M
[32m[04/28 14:22:46 d2.utils.events]: [0m eta: 0:15:01  iter: 119  total_loss: 0.421  loss_cls: 0.134  loss_box_reg: 0.251  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0204  data_time: 0.0078  lr: 0.000599  max_mem: 5397M
[32m[04/28 14:23:06 d2.utils.events]: [0m eta: 0:14:42  iter: 139  total_loss: 0.479  loss_cls: 0.145  loss_box_reg: 0.274  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0203  data_time: 0.0076  lr: 0.000699  max_mem: 5397M
[32m[04/28 14:23:27 d2.utils.events]: [0m eta: 0:14:26  iter: 159  total_loss: 0.496  loss_cls: 0.156  loss_box_reg: 0.299  loss_rpn_cls: 0.007  loss_rpn_loc: 0.045  time: 1.0233  data_time: 0.0077  lr: 0.000799  max_mem: 5397M
[32m[04/28 14:23:47 d2.utils.events]: [0m eta: 0:14:01  iter: 179  total_loss: 0.539  loss_cls: 0.170  loss_box_reg: 0.293  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 1.0220  data_time: 0.0079  lr: 0.000899  max_mem: 5397M
[32m[04/28 14:24:08 d2.utils.events]: [0m eta: 0:13:43  iter: 199  total_loss: 0.476  loss_cls: 0.141  loss_box_reg: 0.282  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0237  data_time: 0.0077  lr: 0.000999  max_mem: 5397M
[32m[04/28 14:24:29 d2.utils.events]: [0m eta: 0:13:23  iter: 219  total_loss: 0.489  loss_cls: 0.154  loss_box_reg: 0.293  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0239  data_time: 0.0078  lr: 0.001099  max_mem: 5397M
[32m[04/28 14:24:49 d2.utils.events]: [0m eta: 0:13:02  iter: 239  total_loss: 0.492  loss_cls: 0.149  loss_box_reg: 0.291  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0237  data_time: 0.0077  lr: 0.001199  max_mem: 5397M
[32m[04/28 14:25:10 d2.utils.events]: [0m eta: 0:12:43  iter: 259  total_loss: 0.485  loss_cls: 0.147  loss_box_reg: 0.280  loss_rpn_cls: 0.007  loss_rpn_loc: 0.053  time: 1.0245  data_time: 0.0078  lr: 0.001299  max_mem: 5397M
[32m[04/28 14:25:31 d2.utils.events]: [0m eta: 0:12:27  iter: 279  total_loss: 0.505  loss_cls: 0.156  loss_box_reg: 0.297  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0263  data_time: 0.0079  lr: 0.001399  max_mem: 5397M
[32m[04/28 14:25:52 d2.utils.events]: [0m eta: 0:12:06  iter: 299  total_loss: 0.549  loss_cls: 0.162  loss_box_reg: 0.312  loss_rpn_cls: 0.006  loss_rpn_loc: 0.052  time: 1.0267  data_time: 0.0079  lr: 0.001499  max_mem: 5397M
[32m[04/28 14:26:12 d2.utils.events]: [0m eta: 0:11:46  iter: 319  total_loss: 0.483  loss_cls: 0.146  loss_box_reg: 0.284  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0269  data_time: 0.0077  lr: 0.001598  max_mem: 5397M
[32m[04/28 14:26:33 d2.utils.events]: [0m eta: 0:11:23  iter: 339  total_loss: 0.461  loss_cls: 0.134  loss_box_reg: 0.265  loss_rpn_cls: 0.004  loss_rpn_loc: 0.037  time: 1.0257  data_time: 0.0077  lr: 0.001698  max_mem: 5397M
[32m[04/28 14:26:54 d2.utils.events]: [0m eta: 0:11:05  iter: 359  total_loss: 0.465  loss_cls: 0.140  loss_box_reg: 0.284  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0275  data_time: 0.0081  lr: 0.001798  max_mem: 5397M
[32m[04/28 14:27:14 d2.utils.events]: [0m eta: 0:10:43  iter: 379  total_loss: 0.479  loss_cls: 0.147  loss_box_reg: 0.270  loss_rpn_cls: 0.004  loss_rpn_loc: 0.046  time: 1.0272  data_time: 0.0079  lr: 0.001898  max_mem: 5397M
[32m[04/28 14:27:35 d2.utils.events]: [0m eta: 0:10:23  iter: 399  total_loss: 0.418  loss_cls: 0.125  loss_box_reg: 0.247  loss_rpn_cls: 0.004  loss_rpn_loc: 0.038  time: 1.0282  data_time: 0.0078  lr: 0.001998  max_mem: 5397M
[32m[04/28 14:27:56 d2.utils.events]: [0m eta: 0:10:02  iter: 419  total_loss: 0.490  loss_cls: 0.150  loss_box_reg: 0.291  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0275  data_time: 0.0077  lr: 0.002098  max_mem: 5397M
[32m[04/28 14:28:16 d2.utils.events]: [0m eta: 0:09:39  iter: 439  total_loss: 0.446  loss_cls: 0.136  loss_box_reg: 0.261  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0270  data_time: 0.0076  lr: 0.002198  max_mem: 5397M
[32m[04/28 14:28:36 d2.utils.events]: [0m eta: 0:09:16  iter: 459  total_loss: 0.516  loss_cls: 0.152  loss_box_reg: 0.311  loss_rpn_cls: 0.007  loss_rpn_loc: 0.049  time: 1.0263  data_time: 0.0077  lr: 0.002298  max_mem: 5397M
[32m[04/28 14:28:57 d2.utils.events]: [0m eta: 0:08:57  iter: 479  total_loss: 0.545  loss_cls: 0.163  loss_box_reg: 0.321  loss_rpn_cls: 0.009  loss_rpn_loc: 0.047  time: 1.0266  data_time: 0.0078  lr: 0.002398  max_mem: 5397M
[32m[04/28 14:29:18 d2.utils.events]: [0m eta: 0:08:37  iter: 499  total_loss: 0.491  loss_cls: 0.165  loss_box_reg: 0.288  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0272  data_time: 0.0080  lr: 0.002498  max_mem: 5397M
[32m[04/28 14:29:39 d2.utils.events]: [0m eta: 0:08:17  iter: 519  total_loss: 0.568  loss_cls: 0.174  loss_box_reg: 0.335  loss_rpn_cls: 0.006  loss_rpn_loc: 0.048  time: 1.0273  data_time: 0.0079  lr: 0.002597  max_mem: 5397M
[32m[04/28 14:29:59 d2.utils.events]: [0m eta: 0:07:55  iter: 539  total_loss: 0.470  loss_cls: 0.148  loss_box_reg: 0.269  loss_rpn_cls: 0.006  loss_rpn_loc: 0.035  time: 1.0267  data_time: 0.0076  lr: 0.002697  max_mem: 5397M
[32m[04/28 14:30:20 d2.utils.events]: [0m eta: 0:07:35  iter: 559  total_loss: 0.508  loss_cls: 0.156  loss_box_reg: 0.286  loss_rpn_cls: 0.006  loss_rpn_loc: 0.044  time: 1.0275  data_time: 0.0079  lr: 0.002797  max_mem: 5397M
[32m[04/28 14:30:40 d2.utils.events]: [0m eta: 0:07:13  iter: 579  total_loss: 0.474  loss_cls: 0.138  loss_box_reg: 0.283  loss_rpn_cls: 0.007  loss_rpn_loc: 0.035  time: 1.0265  data_time: 0.0078  lr: 0.002897  max_mem: 5397M
[32m[04/28 14:31:01 d2.utils.events]: [0m eta: 0:06:53  iter: 599  total_loss: 0.547  loss_cls: 0.172  loss_box_reg: 0.326  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 1.0268  data_time: 0.0076  lr: 0.002997  max_mem: 5397M
[32m[04/28 14:31:21 d2.utils.events]: [0m eta: 0:06:33  iter: 619  total_loss: 0.543  loss_cls: 0.161  loss_box_reg: 0.316  loss_rpn_cls: 0.005  loss_rpn_loc: 0.050  time: 1.0268  data_time: 0.0078  lr: 0.003097  max_mem: 5397M
[32m[04/28 14:31:42 d2.utils.events]: [0m eta: 0:06:13  iter: 639  total_loss: 0.521  loss_cls: 0.149  loss_box_reg: 0.304  loss_rpn_cls: 0.006  loss_rpn_loc: 0.051  time: 1.0271  data_time: 0.0079  lr: 0.003197  max_mem: 5397M
[32m[04/28 14:32:03 d2.utils.events]: [0m eta: 0:05:52  iter: 659  total_loss: 0.511  loss_cls: 0.151  loss_box_reg: 0.302  loss_rpn_cls: 0.005  loss_rpn_loc: 0.046  time: 1.0274  data_time: 0.0077  lr: 0.003297  max_mem: 5397M
[32m[04/28 14:32:24 d2.utils.events]: [0m eta: 0:05:31  iter: 679  total_loss: 0.501  loss_cls: 0.146  loss_box_reg: 0.294  loss_rpn_cls: 0.006  loss_rpn_loc: 0.050  time: 1.0274  data_time: 0.0076  lr: 0.003397  max_mem: 5397M
[32m[04/28 14:32:44 d2.utils.events]: [0m eta: 0:05:11  iter: 699  total_loss: 0.431  loss_cls: 0.118  loss_box_reg: 0.258  loss_rpn_cls: 0.007  loss_rpn_loc: 0.037  time: 1.0274  data_time: 0.0077  lr: 0.003497  max_mem: 5397M
[32m[04/28 14:33:04 d2.utils.events]: [0m eta: 0:04:50  iter: 719  total_loss: 0.509  loss_cls: 0.155  loss_box_reg: 0.298  loss_rpn_cls: 0.009  loss_rpn_loc: 0.046  time: 1.0270  data_time: 0.0077  lr: 0.003596  max_mem: 5397M
[32m[04/28 14:33:25 d2.utils.events]: [0m eta: 0:04:29  iter: 739  total_loss: 0.541  loss_cls: 0.162  loss_box_reg: 0.312  loss_rpn_cls: 0.007  loss_rpn_loc: 0.057  time: 1.0276  data_time: 0.0078  lr: 0.003696  max_mem: 5397M
[32m[04/28 14:33:47 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.506  loss_cls: 0.164  loss_box_reg: 0.289  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 1.0283  data_time: 0.0077  lr: 0.003796  max_mem: 5397M
[32m[04/28 14:34:06 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.477  loss_cls: 0.145  loss_box_reg: 0.283  loss_rpn_cls: 0.006  loss_rpn_loc: 0.039  time: 1.0274  data_time: 0.0076  lr: 0.003896  max_mem: 5397M
[32m[04/28 14:34:27 d2.utils.events]: [0m eta: 0:03:27  iter: 799  total_loss: 0.518  loss_cls: 0.161  loss_box_reg: 0.307  loss_rpn_cls: 0.003  loss_rpn_loc: 0.038  time: 1.0273  data_time: 0.0077  lr: 0.003996  max_mem: 5397M
[32m[04/28 14:34:48 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.508  loss_cls: 0.154  loss_box_reg: 0.286  loss_rpn_cls: 0.006  loss_rpn_loc: 0.044  time: 1.0277  data_time: 0.0076  lr: 0.004096  max_mem: 5397M
[32m[04/28 14:35:08 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.480  loss_cls: 0.151  loss_box_reg: 0.303  loss_rpn_cls: 0.006  loss_rpn_loc: 0.059  time: 1.0272  data_time: 0.0076  lr: 0.004196  max_mem: 5397M
[32m[04/28 14:35:29 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.512  loss_cls: 0.155  loss_box_reg: 0.300  loss_rpn_cls: 0.009  loss_rpn_loc: 0.047  time: 1.0274  data_time: 0.0076  lr: 0.004296  max_mem: 5397M
[32m[04/28 14:35:50 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.468  loss_cls: 0.148  loss_box_reg: 0.293  loss_rpn_cls: 0.004  loss_rpn_loc: 0.046  time: 1.0275  data_time: 0.0076  lr: 0.004396  max_mem: 5397M
[32m[04/28 14:36:10 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.505  loss_cls: 0.154  loss_box_reg: 0.293  loss_rpn_cls: 0.004  loss_rpn_loc: 0.041  time: 1.0275  data_time: 0.0077  lr: 0.004496  max_mem: 5397M
[32m[04/28 14:36:30 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.520  loss_cls: 0.161  loss_box_reg: 0.313  loss_rpn_cls: 0.005  loss_rpn_loc: 0.046  time: 1.0272  data_time: 0.0077  lr: 0.004595  max_mem: 5397M
[32m[04/28 14:36:51 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.515  loss_cls: 0.153  loss_box_reg: 0.301  loss_rpn_cls: 0.007  loss_rpn_loc: 0.053  time: 1.0275  data_time: 0.0077  lr: 0.004695  max_mem: 5397M
[32m[04/28 14:37:11 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.490  loss_cls: 0.154  loss_box_reg: 0.278  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 1.0269  data_time: 0.0075  lr: 0.004795  max_mem: 5397M
[32m[04/28 14:37:33 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.562  loss_cls: 0.171  loss_box_reg: 0.338  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 1.0275  data_time: 0.0076  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 14:37:56 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 14:37:56 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 14:37:56 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 14:37:56 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.445  loss_cls: 0.128  loss_box_reg: 0.280  loss_rpn_cls: 0.005  loss_rpn_loc: 0.037  time: 1.0278  data_time: 0.0078  lr: 0.004995  max_mem: 5397M
[32m[04/28 14:37:56 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:05 (1.0288 s / it)
[32m[04/28 14:37:56 d2.engine.hooks]: [0mTotal training time: 0:17:11 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 14:37:58 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 14:37:58 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 14:37:58 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 14:37:59 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1142 s / img. ETA=0:16:05
[32m[04/28 14:38:05 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1141 s / img. ETA=0:16:00
[32m[04/28 14:38:10 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1140 s / img. ETA=0:15:54
[32m[04/28 14:38:15 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1140 s / img. ETA=0:15:49
[32m[04/28 14:38:20 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1140 s / img. ETA=0:15:44
[32m[04/28 14:38:25 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1140 s / img. ETA=0:15:40
[32m[04/28 14:38:30 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1141 s / img. ETA=0:15:35
[32m[04/28 14:38:35 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1141 s / img. ETA=0:15:30
[32m[04/28 14:38:40 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1141 s / img. ETA=0:15:25
[32m[04/28 14:38:45 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1141 s / img. ETA=0:15:20
[32m[04/28 14:38:50 d2.evaluation.evaluator]: [0mInference done 450/8355. 0.1142 s / img. ETA=0:15:16
[32m[04/28 14:38:55 d2.evaluation.evaluator]: [0mInference done 494/8355. 0.1141 s / img. ETA=0:15:10
[32m[04/28 14:39:00 d2.evaluation.evaluator]: [0mInference done 538/8355. 0.1141 s / img. ETA=0:15:05
[32m[04/28 14:39:06 d2.evaluation.evaluator]: [0mInference done 582/8355. 0.1141 s / img. ETA=0:15:00
[32m[04/28 14:39:11 d2.evaluation.evaluator]: [0mInference done 626/8355. 0.1141 s / img. ETA=0:14:55
[32m[04/28 14:39:16 d2.evaluation.evaluator]: [0mInference done 670/8355. 0.1142 s / img. ETA=0:14:50
[32m[04/28 14:39:21 d2.evaluation.evaluator]: [0mInference done 713/8355. 0.1142 s / img. ETA=0:14:45
[32m[04/28 14:39:26 d2.evaluation.evaluator]: [0mInference done 756/8355. 0.1142 s / img. ETA=0:14:41
[32m[04/28 14:39:31 d2.evaluation.evaluator]: [0mInference done 799/8355. 0.1143 s / img. ETA=0:14:36
[32m[04/28 14:39:36 d2.evaluation.evaluator]: [0mInference done 843/8355. 0.1143 s / img. ETA=0:14:31
[32m[04/28 14:39:41 d2.evaluation.evaluator]: [0mInference done 886/8355. 0.1143 s / img. ETA=0:14:26
[32m[04/28 14:39:46 d2.evaluation.evaluator]: [0mInference done 929/8355. 0.1144 s / img. ETA=0:14:22
[32m[04/28 14:39:51 d2.evaluation.evaluator]: [0mInference done 973/8355. 0.1144 s / img. ETA=0:14:17
[32m[04/28 14:39:56 d2.evaluation.evaluator]: [0mInference done 1016/8355. 0.1144 s / img. ETA=0:14:12
[32m[04/28 14:40:01 d2.evaluation.evaluator]: [0mInference done 1059/8355. 0.1144 s / img. ETA=0:14:07
[32m[04/28 14:40:06 d2.evaluation.evaluator]: [0mInference done 1102/8355. 0.1144 s / img. ETA=0:14:02
[32m[04/28 14:40:11 d2.evaluation.evaluator]: [0mInference done 1145/8355. 0.1144 s / img. ETA=0:13:57
[32m[04/28 14:40:16 d2.evaluation.evaluator]: [0mInference done 1189/8355. 0.1144 s / img. ETA=0:13:52
[32m[04/28 14:40:21 d2.evaluation.evaluator]: [0mInference done 1233/8355. 0.1144 s / img. ETA=0:13:47
[32m[04/28 14:40:26 d2.evaluation.evaluator]: [0mInference done 1276/8355. 0.1145 s / img. ETA=0:13:42
[32m[04/28 14:40:32 d2.evaluation.evaluator]: [0mInference done 1320/8355. 0.1144 s / img. ETA=0:13:37
[32m[04/28 14:40:37 d2.evaluation.evaluator]: [0mInference done 1364/8355. 0.1144 s / img. ETA=0:13:32
[32m[04/28 14:40:42 d2.evaluation.evaluator]: [0mInference done 1408/8355. 0.1144 s / img. ETA=0:13:27
[32m[04/28 14:40:47 d2.evaluation.evaluator]: [0mInference done 1451/8355. 0.1144 s / img. ETA=0:13:22
[32m[04/28 14:40:52 d2.evaluation.evaluator]: [0mInference done 1494/8355. 0.1145 s / img. ETA=0:13:17
[32m[04/28 14:40:57 d2.evaluation.evaluator]: [0mInference done 1537/8355. 0.1145 s / img. ETA=0:13:12
[32m[04/28 14:41:02 d2.evaluation.evaluator]: [0mInference done 1580/8355. 0.1146 s / img. ETA=0:13:08
[32m[04/28 14:41:07 d2.evaluation.evaluator]: [0mInference done 1623/8355. 0.1146 s / img. ETA=0:13:03
[32m[04/28 14:41:12 d2.evaluation.evaluator]: [0mInference done 1666/8355. 0.1146 s / img. ETA=0:12:58
[32m[04/28 14:41:17 d2.evaluation.evaluator]: [0mInference done 1709/8355. 0.1147 s / img. ETA=0:12:53
[32m[04/28 14:41:22 d2.evaluation.evaluator]: [0mInference done 1752/8355. 0.1147 s / img. ETA=0:12:48
[32m[04/28 14:41:27 d2.evaluation.evaluator]: [0mInference done 1795/8355. 0.1147 s / img. ETA=0:12:44
[32m[04/28 14:41:32 d2.evaluation.evaluator]: [0mInference done 1838/8355. 0.1148 s / img. ETA=0:12:39
[32m[04/28 14:41:37 d2.evaluation.evaluator]: [0mInference done 1881/8355. 0.1148 s / img. ETA=0:12:34
[32m[04/28 14:41:42 d2.evaluation.evaluator]: [0mInference done 1924/8355. 0.1148 s / img. ETA=0:12:29
[32m[04/28 14:41:48 d2.evaluation.evaluator]: [0mInference done 1967/8355. 0.1148 s / img. ETA=0:12:24
[32m[04/28 14:41:53 d2.evaluation.evaluator]: [0mInference done 2010/8355. 0.1148 s / img. ETA=0:12:19
[32m[04/28 14:41:58 d2.evaluation.evaluator]: [0mInference done 2053/8355. 0.1149 s / img. ETA=0:12:14
[32m[04/28 14:42:03 d2.evaluation.evaluator]: [0mInference done 2096/8355. 0.1149 s / img. ETA=0:12:10
[32m[04/28 14:42:08 d2.evaluation.evaluator]: [0mInference done 2139/8355. 0.1149 s / img. ETA=0:12:05
[32m[04/28 14:42:13 d2.evaluation.evaluator]: [0mInference done 2182/8355. 0.1149 s / img. ETA=0:12:00
[32m[04/28 14:42:18 d2.evaluation.evaluator]: [0mInference done 2225/8355. 0.1149 s / img. ETA=0:11:55
[32m[04/28 14:42:23 d2.evaluation.evaluator]: [0mInference done 2268/8355. 0.1149 s / img. ETA=0:11:50
[32m[04/28 14:42:28 d2.evaluation.evaluator]: [0mInference done 2311/8355. 0.1150 s / img. ETA=0:11:45
[32m[04/28 14:42:33 d2.evaluation.evaluator]: [0mInference done 2354/8355. 0.1150 s / img. ETA=0:11:40
[32m[04/28 14:42:38 d2.evaluation.evaluator]: [0mInference done 2397/8355. 0.1150 s / img. ETA=0:11:35
[32m[04/28 14:42:43 d2.evaluation.evaluator]: [0mInference done 2440/8355. 0.1150 s / img. ETA=0:11:30
[32m[04/28 14:42:48 d2.evaluation.evaluator]: [0mInference done 2483/8355. 0.1150 s / img. ETA=0:11:25
[32m[04/28 14:42:53 d2.evaluation.evaluator]: [0mInference done 2526/8355. 0.1150 s / img. ETA=0:11:20
[32m[04/28 14:42:58 d2.evaluation.evaluator]: [0mInference done 2569/8355. 0.1150 s / img. ETA=0:11:15
[32m[04/28 14:43:03 d2.evaluation.evaluator]: [0mInference done 2612/8355. 0.1150 s / img. ETA=0:11:10
[32m[04/28 14:43:08 d2.evaluation.evaluator]: [0mInference done 2655/8355. 0.1150 s / img. ETA=0:11:05
[32m[04/28 14:43:13 d2.evaluation.evaluator]: [0mInference done 2698/8355. 0.1151 s / img. ETA=0:11:01
[32m[04/28 14:43:18 d2.evaluation.evaluator]: [0mInference done 2741/8355. 0.1151 s / img. ETA=0:10:55
[32m[04/28 14:43:24 d2.evaluation.evaluator]: [0mInference done 2784/8355. 0.1151 s / img. ETA=0:10:51
[32m[04/28 14:43:29 d2.evaluation.evaluator]: [0mInference done 2827/8355. 0.1151 s / img. ETA=0:10:46
[32m[04/28 14:43:34 d2.evaluation.evaluator]: [0mInference done 2870/8355. 0.1151 s / img. ETA=0:10:41
[32m[04/28 14:43:39 d2.evaluation.evaluator]: [0mInference done 2913/8355. 0.1151 s / img. ETA=0:10:36
[32m[04/28 14:43:44 d2.evaluation.evaluator]: [0mInference done 2955/8355. 0.1151 s / img. ETA=0:10:31
[32m[04/28 14:43:49 d2.evaluation.evaluator]: [0mInference done 2998/8355. 0.1151 s / img. ETA=0:10:26
[32m[04/28 14:43:54 d2.evaluation.evaluator]: [0mInference done 3041/8355. 0.1151 s / img. ETA=0:10:21
[32m[04/28 14:43:59 d2.evaluation.evaluator]: [0mInference done 3084/8355. 0.1151 s / img. ETA=0:10:16
[32m[04/28 14:44:04 d2.evaluation.evaluator]: [0mInference done 3127/8355. 0.1151 s / img. ETA=0:10:11
[32m[04/28 14:44:09 d2.evaluation.evaluator]: [0mInference done 3170/8355. 0.1151 s / img. ETA=0:10:06
[32m[04/28 14:44:14 d2.evaluation.evaluator]: [0mInference done 3213/8355. 0.1151 s / img. ETA=0:10:01
[32m[04/28 14:44:19 d2.evaluation.evaluator]: [0mInference done 3256/8355. 0.1151 s / img. ETA=0:09:56
[32m[04/28 14:44:24 d2.evaluation.evaluator]: [0mInference done 3299/8355. 0.1151 s / img. ETA=0:09:51
[32m[04/28 14:44:29 d2.evaluation.evaluator]: [0mInference done 3342/8355. 0.1151 s / img. ETA=0:09:46
[32m[04/28 14:44:34 d2.evaluation.evaluator]: [0mInference done 3385/8355. 0.1151 s / img. ETA=0:09:41
[32m[04/28 14:44:39 d2.evaluation.evaluator]: [0mInference done 3428/8355. 0.1151 s / img. ETA=0:09:36
[32m[04/28 14:44:44 d2.evaluation.evaluator]: [0mInference done 3471/8355. 0.1151 s / img. ETA=0:09:31
[32m[04/28 14:44:49 d2.evaluation.evaluator]: [0mInference done 3514/8355. 0.1151 s / img. ETA=0:09:25
[32m[04/28 14:44:54 d2.evaluation.evaluator]: [0mInference done 3557/8355. 0.1151 s / img. ETA=0:09:20
[32m[04/28 14:44:59 d2.evaluation.evaluator]: [0mInference done 3600/8355. 0.1151 s / img. ETA=0:09:15
[32m[04/28 14:45:04 d2.evaluation.evaluator]: [0mInference done 3643/8355. 0.1151 s / img. ETA=0:09:10
[32m[04/28 14:45:09 d2.evaluation.evaluator]: [0mInference done 3686/8355. 0.1151 s / img. ETA=0:09:05
[32m[04/28 14:45:14 d2.evaluation.evaluator]: [0mInference done 3729/8355. 0.1151 s / img. ETA=0:09:00
[32m[04/28 14:45:19 d2.evaluation.evaluator]: [0mInference done 3772/8355. 0.1151 s / img. ETA=0:08:55
[32m[04/28 14:45:24 d2.evaluation.evaluator]: [0mInference done 3815/8355. 0.1151 s / img. ETA=0:08:50
[32m[04/28 14:45:29 d2.evaluation.evaluator]: [0mInference done 3858/8355. 0.1151 s / img. ETA=0:08:45
[32m[04/28 14:45:34 d2.evaluation.evaluator]: [0mInference done 3901/8355. 0.1151 s / img. ETA=0:08:40
[32m[04/28 14:45:39 d2.evaluation.evaluator]: [0mInference done 3944/8355. 0.1151 s / img. ETA=0:08:35
[32m[04/28 14:45:44 d2.evaluation.evaluator]: [0mInference done 3987/8355. 0.1151 s / img. ETA=0:08:30
[32m[04/28 14:45:49 d2.evaluation.evaluator]: [0mInference done 4030/8355. 0.1151 s / img. ETA=0:08:25
[32m[04/28 14:45:54 d2.evaluation.evaluator]: [0mInference done 4073/8355. 0.1151 s / img. ETA=0:08:20
[32m[04/28 14:45:59 d2.evaluation.evaluator]: [0mInference done 4116/8355. 0.1151 s / img. ETA=0:08:15
[32m[04/28 14:46:05 d2.evaluation.evaluator]: [0mInference done 4159/8355. 0.1151 s / img. ETA=0:08:10
[32m[04/28 14:46:10 d2.evaluation.evaluator]: [0mInference done 4202/8355. 0.1151 s / img. ETA=0:08:05
[32m[04/28 14:46:15 d2.evaluation.evaluator]: [0mInference done 4245/8355. 0.1151 s / img. ETA=0:08:00
[32m[04/28 14:46:20 d2.evaluation.evaluator]: [0mInference done 4288/8355. 0.1151 s / img. ETA=0:07:55
[32m[04/28 14:46:25 d2.evaluation.evaluator]: [0mInference done 4331/8355. 0.1151 s / img. ETA=0:07:50
[32m[04/28 14:46:30 d2.evaluation.evaluator]: [0mInference done 4374/8355. 0.1151 s / img. ETA=0:07:45
[32m[04/28 14:46:35 d2.evaluation.evaluator]: [0mInference done 4417/8355. 0.1151 s / img. ETA=0:07:40
[32m[04/28 14:46:40 d2.evaluation.evaluator]: [0mInference done 4460/8355. 0.1151 s / img. ETA=0:07:35
[32m[04/28 14:46:45 d2.evaluation.evaluator]: [0mInference done 4503/8355. 0.1151 s / img. ETA=0:07:30
[32m[04/28 14:46:50 d2.evaluation.evaluator]: [0mInference done 4546/8355. 0.1151 s / img. ETA=0:07:25
[32m[04/28 14:46:55 d2.evaluation.evaluator]: [0mInference done 4589/8355. 0.1151 s / img. ETA=0:07:20
[32m[04/28 14:47:00 d2.evaluation.evaluator]: [0mInference done 4632/8355. 0.1151 s / img. ETA=0:07:15
[32m[04/28 14:47:05 d2.evaluation.evaluator]: [0mInference done 4675/8355. 0.1151 s / img. ETA=0:07:10
[32m[04/28 14:47:10 d2.evaluation.evaluator]: [0mInference done 4718/8355. 0.1151 s / img. ETA=0:07:05
[32m[04/28 14:47:15 d2.evaluation.evaluator]: [0mInference done 4761/8355. 0.1151 s / img. ETA=0:07:00
[32m[04/28 14:47:20 d2.evaluation.evaluator]: [0mInference done 4804/8355. 0.1151 s / img. ETA=0:06:55
[32m[04/28 14:47:25 d2.evaluation.evaluator]: [0mInference done 4847/8355. 0.1151 s / img. ETA=0:06:50
[32m[04/28 14:47:30 d2.evaluation.evaluator]: [0mInference done 4890/8355. 0.1151 s / img. ETA=0:06:45
[32m[04/28 14:47:35 d2.evaluation.evaluator]: [0mInference done 4933/8355. 0.1151 s / img. ETA=0:06:40
[32m[04/28 14:47:40 d2.evaluation.evaluator]: [0mInference done 4976/8355. 0.1151 s / img. ETA=0:06:35
[32m[04/28 14:47:45 d2.evaluation.evaluator]: [0mInference done 5019/8355. 0.1151 s / img. ETA=0:06:30
[32m[04/28 14:47:50 d2.evaluation.evaluator]: [0mInference done 5062/8355. 0.1151 s / img. ETA=0:06:25
[32m[04/28 14:47:55 d2.evaluation.evaluator]: [0mInference done 5105/8355. 0.1151 s / img. ETA=0:06:20
[32m[04/28 14:48:00 d2.evaluation.evaluator]: [0mInference done 5147/8355. 0.1152 s / img. ETA=0:06:15
[32m[04/28 14:48:05 d2.evaluation.evaluator]: [0mInference done 5190/8355. 0.1152 s / img. ETA=0:06:10
[32m[04/28 14:48:10 d2.evaluation.evaluator]: [0mInference done 5233/8355. 0.1152 s / img. ETA=0:06:05
[32m[04/28 14:48:15 d2.evaluation.evaluator]: [0mInference done 5276/8355. 0.1152 s / img. ETA=0:06:00
[32m[04/28 14:48:20 d2.evaluation.evaluator]: [0mInference done 5319/8355. 0.1152 s / img. ETA=0:05:55
[32m[04/28 14:48:25 d2.evaluation.evaluator]: [0mInference done 5362/8355. 0.1152 s / img. ETA=0:05:50
[32m[04/28 14:48:31 d2.evaluation.evaluator]: [0mInference done 5405/8355. 0.1152 s / img. ETA=0:05:45
[32m[04/28 14:48:36 d2.evaluation.evaluator]: [0mInference done 5448/8355. 0.1152 s / img. ETA=0:05:40
[32m[04/28 14:48:41 d2.evaluation.evaluator]: [0mInference done 5491/8355. 0.1152 s / img. ETA=0:05:35
[32m[04/28 14:48:46 d2.evaluation.evaluator]: [0mInference done 5532/8355. 0.1152 s / img. ETA=0:05:30
[32m[04/28 14:48:51 d2.evaluation.evaluator]: [0mInference done 5576/8355. 0.1152 s / img. ETA=0:05:25
[32m[04/28 14:48:56 d2.evaluation.evaluator]: [0mInference done 5619/8355. 0.1152 s / img. ETA=0:05:20
[32m[04/28 14:49:01 d2.evaluation.evaluator]: [0mInference done 5662/8355. 0.1152 s / img. ETA=0:05:15
[32m[04/28 14:49:06 d2.evaluation.evaluator]: [0mInference done 5705/8355. 0.1152 s / img. ETA=0:05:10
[32m[04/28 14:49:11 d2.evaluation.evaluator]: [0mInference done 5747/8355. 0.1152 s / img. ETA=0:05:05
[32m[04/28 14:49:16 d2.evaluation.evaluator]: [0mInference done 5790/8355. 0.1152 s / img. ETA=0:05:00
[32m[04/28 14:49:21 d2.evaluation.evaluator]: [0mInference done 5833/8355. 0.1152 s / img. ETA=0:04:55
[32m[04/28 14:49:26 d2.evaluation.evaluator]: [0mInference done 5875/8355. 0.1152 s / img. ETA=0:04:50
[32m[04/28 14:49:31 d2.evaluation.evaluator]: [0mInference done 5918/8355. 0.1152 s / img. ETA=0:04:45
[32m[04/28 14:49:36 d2.evaluation.evaluator]: [0mInference done 5960/8355. 0.1153 s / img. ETA=0:04:40
[32m[04/28 14:49:41 d2.evaluation.evaluator]: [0mInference done 6003/8355. 0.1153 s / img. ETA=0:04:35
[32m[04/28 14:49:46 d2.evaluation.evaluator]: [0mInference done 6046/8355. 0.1153 s / img. ETA=0:04:30
[32m[04/28 14:49:51 d2.evaluation.evaluator]: [0mInference done 6089/8355. 0.1153 s / img. ETA=0:04:25
[32m[04/28 14:49:56 d2.evaluation.evaluator]: [0mInference done 6132/8355. 0.1153 s / img. ETA=0:04:20
[32m[04/28 14:50:01 d2.evaluation.evaluator]: [0mInference done 6175/8355. 0.1153 s / img. ETA=0:04:15
[32m[04/28 14:50:06 d2.evaluation.evaluator]: [0mInference done 6218/8355. 0.1153 s / img. ETA=0:04:10
[32m[04/28 14:50:12 d2.evaluation.evaluator]: [0mInference done 6261/8355. 0.1153 s / img. ETA=0:04:05
[32m[04/28 14:50:17 d2.evaluation.evaluator]: [0mInference done 6304/8355. 0.1153 s / img. ETA=0:04:00
[32m[04/28 14:50:22 d2.evaluation.evaluator]: [0mInference done 6347/8355. 0.1153 s / img. ETA=0:03:55
[32m[04/28 14:50:27 d2.evaluation.evaluator]: [0mInference done 6390/8355. 0.1153 s / img. ETA=0:03:50
[32m[04/28 14:50:32 d2.evaluation.evaluator]: [0mInference done 6433/8355. 0.1153 s / img. ETA=0:03:45
[32m[04/28 14:50:37 d2.evaluation.evaluator]: [0mInference done 6476/8355. 0.1153 s / img. ETA=0:03:40
[32m[04/28 14:50:42 d2.evaluation.evaluator]: [0mInference done 6519/8355. 0.1153 s / img. ETA=0:03:35
[32m[04/28 14:50:47 d2.evaluation.evaluator]: [0mInference done 6562/8355. 0.1153 s / img. ETA=0:03:30
[32m[04/28 14:50:52 d2.evaluation.evaluator]: [0mInference done 6605/8355. 0.1153 s / img. ETA=0:03:25
[32m[04/28 14:50:57 d2.evaluation.evaluator]: [0mInference done 6648/8355. 0.1153 s / img. ETA=0:03:19
[32m[04/28 14:51:02 d2.evaluation.evaluator]: [0mInference done 6692/8355. 0.1153 s / img. ETA=0:03:14
[32m[04/28 14:51:07 d2.evaluation.evaluator]: [0mInference done 6736/8355. 0.1153 s / img. ETA=0:03:09
[32m[04/28 14:51:12 d2.evaluation.evaluator]: [0mInference done 6780/8355. 0.1153 s / img. ETA=0:03:04
[32m[04/28 14:51:17 d2.evaluation.evaluator]: [0mInference done 6823/8355. 0.1153 s / img. ETA=0:02:59
[32m[04/28 14:51:22 d2.evaluation.evaluator]: [0mInference done 6866/8355. 0.1153 s / img. ETA=0:02:54
[32m[04/28 14:51:27 d2.evaluation.evaluator]: [0mInference done 6909/8355. 0.1153 s / img. ETA=0:02:49
[32m[04/28 14:51:32 d2.evaluation.evaluator]: [0mInference done 6952/8355. 0.1153 s / img. ETA=0:02:44
[32m[04/28 14:51:37 d2.evaluation.evaluator]: [0mInference done 6995/8355. 0.1153 s / img. ETA=0:02:39
[32m[04/28 14:51:42 d2.evaluation.evaluator]: [0mInference done 7038/8355. 0.1153 s / img. ETA=0:02:34
[32m[04/28 14:51:48 d2.evaluation.evaluator]: [0mInference done 7081/8355. 0.1153 s / img. ETA=0:02:29
[32m[04/28 14:51:53 d2.evaluation.evaluator]: [0mInference done 7124/8355. 0.1153 s / img. ETA=0:02:24
[32m[04/28 14:51:58 d2.evaluation.evaluator]: [0mInference done 7167/8355. 0.1153 s / img. ETA=0:02:19
[32m[04/28 14:52:03 d2.evaluation.evaluator]: [0mInference done 7210/8355. 0.1153 s / img. ETA=0:02:14
[32m[04/28 14:52:08 d2.evaluation.evaluator]: [0mInference done 7252/8355. 0.1153 s / img. ETA=0:02:09
[32m[04/28 14:52:13 d2.evaluation.evaluator]: [0mInference done 7295/8355. 0.1153 s / img. ETA=0:02:04
[32m[04/28 14:52:18 d2.evaluation.evaluator]: [0mInference done 7338/8355. 0.1153 s / img. ETA=0:01:59
[32m[04/28 14:52:23 d2.evaluation.evaluator]: [0mInference done 7381/8355. 0.1153 s / img. ETA=0:01:54
[32m[04/28 14:52:28 d2.evaluation.evaluator]: [0mInference done 7424/8355. 0.1154 s / img. ETA=0:01:49
[32m[04/28 14:52:33 d2.evaluation.evaluator]: [0mInference done 7466/8355. 0.1154 s / img. ETA=0:01:44
[32m[04/28 14:52:38 d2.evaluation.evaluator]: [0mInference done 7509/8355. 0.1154 s / img. ETA=0:01:39
[32m[04/28 14:52:43 d2.evaluation.evaluator]: [0mInference done 7552/8355. 0.1154 s / img. ETA=0:01:34
[32m[04/28 14:52:48 d2.evaluation.evaluator]: [0mInference done 7595/8355. 0.1154 s / img. ETA=0:01:29
[32m[04/28 14:52:53 d2.evaluation.evaluator]: [0mInference done 7638/8355. 0.1154 s / img. ETA=0:01:24
[32m[04/28 14:52:58 d2.evaluation.evaluator]: [0mInference done 7681/8355. 0.1154 s / img. ETA=0:01:18
[32m[04/28 14:53:03 d2.evaluation.evaluator]: [0mInference done 7724/8355. 0.1154 s / img. ETA=0:01:13
[32m[04/28 14:53:09 d2.evaluation.evaluator]: [0mInference done 7767/8355. 0.1154 s / img. ETA=0:01:08
[32m[04/28 14:53:14 d2.evaluation.evaluator]: [0mInference done 7810/8355. 0.1154 s / img. ETA=0:01:03
[32m[04/28 14:53:19 d2.evaluation.evaluator]: [0mInference done 7853/8355. 0.1154 s / img. ETA=0:00:58
[32m[04/28 14:53:24 d2.evaluation.evaluator]: [0mInference done 7896/8355. 0.1154 s / img. ETA=0:00:53
[32m[04/28 14:53:29 d2.evaluation.evaluator]: [0mInference done 7939/8355. 0.1154 s / img. ETA=0:00:48
[32m[04/28 14:53:34 d2.evaluation.evaluator]: [0mInference done 7982/8355. 0.1154 s / img. ETA=0:00:43
[32m[04/28 14:53:39 d2.evaluation.evaluator]: [0mInference done 8025/8355. 0.1154 s / img. ETA=0:00:38
[32m[04/28 14:53:44 d2.evaluation.evaluator]: [0mInference done 8068/8355. 0.1154 s / img. ETA=0:00:33
[32m[04/28 14:53:49 d2.evaluation.evaluator]: [0mInference done 8112/8355. 0.1154 s / img. ETA=0:00:28
[32m[04/28 14:53:54 d2.evaluation.evaluator]: [0mInference done 8155/8355. 0.1154 s / img. ETA=0:00:23
[32m[04/28 14:53:59 d2.evaluation.evaluator]: [0mInference done 8199/8355. 0.1154 s / img. ETA=0:00:18
[32m[04/28 14:54:04 d2.evaluation.evaluator]: [0mInference done 8242/8355. 0.1154 s / img. ETA=0:00:13
[32m[04/28 14:54:09 d2.evaluation.evaluator]: [0mInference done 8285/8355. 0.1154 s / img. ETA=0:00:08
[32m[04/28 14:54:14 d2.evaluation.evaluator]: [0mInference done 8327/8355. 0.1154 s / img. ETA=0:00:03
[32m[04/28 14:54:18 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:18.912060 (0.117235 s / img per device, on 1 devices)
[32m[04/28 14:54:18 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:03 (0.115393 s / img per device, on 1 devices)
[32m[04/28 14:54:18 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 14:54:18 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 14:54:18 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.46s).
Accumulating evaluation results...
DONE (t=2.20s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.491
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.874
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.392
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.761
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.184
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.537
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.559
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.474
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.676
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.801
[32m[04/28 14:54:41 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.104 | 87.410 | 47.975 | 39.212 | 61.086 | 76.052 |
[32m[04/28 14:54:41 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 46.939 | bicycle       | 41.473 | car            | 58.899 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 14:54:41 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 14:54:41 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 14:54:41 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 14:54:43 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1151 s / img. ETA=0:02:25
[32m[04/28 14:54:48 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1149 s / img. ETA=0:02:20
[32m[04/28 14:54:53 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1150 s / img. ETA=0:02:15
[32m[04/28 14:54:58 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1149 s / img. ETA=0:02:10
[32m[04/28 14:55:03 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1150 s / img. ETA=0:02:05
[32m[04/28 14:55:08 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1149 s / img. ETA=0:02:00
[32m[04/28 14:55:13 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1150 s / img. ETA=0:01:55
[32m[04/28 14:55:18 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1149 s / img. ETA=0:01:50
[32m[04/28 14:55:23 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1150 s / img. ETA=0:01:45
[32m[04/28 14:55:28 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1150 s / img. ETA=0:01:40
[32m[04/28 14:55:33 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1149 s / img. ETA=0:01:35
[32m[04/28 14:55:38 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1149 s / img. ETA=0:01:30
[32m[04/28 14:55:43 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1149 s / img. ETA=0:01:25
[32m[04/28 14:55:48 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1150 s / img. ETA=0:01:20
[32m[04/28 14:55:53 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1150 s / img. ETA=0:01:15
[32m[04/28 14:55:58 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1150 s / img. ETA=0:01:10
[32m[04/28 14:56:03 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1150 s / img. ETA=0:01:05
[32m[04/28 14:56:08 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1150 s / img. ETA=0:01:00
[32m[04/28 14:56:13 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1150 s / img. ETA=0:00:55
[32m[04/28 14:56:18 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1151 s / img. ETA=0:00:50
[32m[04/28 14:56:24 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1151 s / img. ETA=0:00:45
[32m[04/28 14:56:29 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1152 s / img. ETA=0:00:40
[32m[04/28 14:56:34 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1152 s / img. ETA=0:00:35
[32m[04/28 14:56:39 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1152 s / img. ETA=0:00:30
[32m[04/28 14:56:44 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1152 s / img. ETA=0:00:25
[32m[04/28 14:56:49 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1152 s / img. ETA=0:00:20
[32m[04/28 14:56:54 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1152 s / img. ETA=0:00:14
[32m[04/28 14:56:59 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1152 s / img. ETA=0:00:09
[32m[04/28 14:57:04 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1152 s / img. ETA=0:00:04
[32m[04/28 14:57:09 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.696737 (0.117170 s / img per device, on 1 devices)
[32m[04/28 14:57:09 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115252 s / img per device, on 1 devices)
[32m[04/28 14:57:09 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 14:57:09 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 14:57:09 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.04s).
Accumulating evaluation results...
DONE (t=0.38s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.404
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.777
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.354
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.297
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.466
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.484
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.403
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.539
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688
[32m[04/28 14:57:13 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.426 | 77.707 | 35.449 | 29.677 | 46.645 | 62.254 |
[32m[04/28 14:57:13 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 40.100 | bicycle       | 26.501 | car            | 54.676 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  22  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 14:57:13 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 14:57:14 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 14:57:14 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 14:57:14 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 14:57:14 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 14:57:14 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 14:57:14 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 14:57:35 d2.utils.events]: [0m eta: 0:17:14  iter: 19  total_loss: 0.466  loss_cls: 0.142  loss_box_reg: 0.277  loss_rpn_cls: 0.005  loss_rpn_loc: 0.046  time: 1.0291  data_time: 0.0235  lr: 0.000100  max_mem: 5397M
[32m[04/28 14:57:56 d2.utils.events]: [0m eta: 0:16:50  iter: 39  total_loss: 0.407  loss_cls: 0.125  loss_box_reg: 0.254  loss_rpn_cls: 0.005  loss_rpn_loc: 0.035  time: 1.0272  data_time: 0.0077  lr: 0.000200  max_mem: 5397M
[32m[04/28 14:58:16 d2.utils.events]: [0m eta: 0:16:18  iter: 59  total_loss: 0.444  loss_cls: 0.146  loss_box_reg: 0.266  loss_rpn_cls: 0.007  loss_rpn_loc: 0.042  time: 1.0199  data_time: 0.0077  lr: 0.000300  max_mem: 5397M
[32m[04/28 14:58:36 d2.utils.events]: [0m eta: 0:15:40  iter: 79  total_loss: 0.540  loss_cls: 0.165  loss_box_reg: 0.321  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0153  data_time: 0.0077  lr: 0.000400  max_mem: 5397M
[32m[04/28 14:58:57 d2.utils.events]: [0m eta: 0:15:32  iter: 99  total_loss: 0.515  loss_cls: 0.161  loss_box_reg: 0.301  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0198  data_time: 0.0080  lr: 0.000500  max_mem: 5397M
[32m[04/28 14:59:17 d2.utils.events]: [0m eta: 0:15:08  iter: 119  total_loss: 0.536  loss_cls: 0.160  loss_box_reg: 0.306  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0214  data_time: 0.0077  lr: 0.000599  max_mem: 5397M
[32m[04/28 14:59:38 d2.utils.events]: [0m eta: 0:14:38  iter: 139  total_loss: 0.478  loss_cls: 0.147  loss_box_reg: 0.283  loss_rpn_cls: 0.004  loss_rpn_loc: 0.038  time: 1.0209  data_time: 0.0076  lr: 0.000699  max_mem: 5397M
[32m[04/28 14:59:59 d2.utils.events]: [0m eta: 0:14:31  iter: 159  total_loss: 0.520  loss_cls: 0.160  loss_box_reg: 0.314  loss_rpn_cls: 0.006  loss_rpn_loc: 0.050  time: 1.0259  data_time: 0.0078  lr: 0.000799  max_mem: 5397M
[32m[04/28 15:00:19 d2.utils.events]: [0m eta: 0:14:02  iter: 179  total_loss: 0.468  loss_cls: 0.135  loss_box_reg: 0.285  loss_rpn_cls: 0.006  loss_rpn_loc: 0.039  time: 1.0253  data_time: 0.0076  lr: 0.000899  max_mem: 5397M
[32m[04/28 15:00:40 d2.utils.events]: [0m eta: 0:13:48  iter: 199  total_loss: 0.499  loss_cls: 0.149  loss_box_reg: 0.302  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0277  data_time: 0.0079  lr: 0.000999  max_mem: 5397M
[32m[04/28 15:01:01 d2.utils.events]: [0m eta: 0:13:26  iter: 219  total_loss: 0.490  loss_cls: 0.146  loss_box_reg: 0.281  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 1.0269  data_time: 0.0078  lr: 0.001099  max_mem: 5397M
[32m[04/28 15:01:21 d2.utils.events]: [0m eta: 0:13:03  iter: 239  total_loss: 0.491  loss_cls: 0.144  loss_box_reg: 0.291  loss_rpn_cls: 0.007  loss_rpn_loc: 0.042  time: 1.0256  data_time: 0.0084  lr: 0.001199  max_mem: 5397M
[32m[04/28 15:01:42 d2.utils.events]: [0m eta: 0:12:43  iter: 259  total_loss: 0.463  loss_cls: 0.131  loss_box_reg: 0.269  loss_rpn_cls: 0.005  loss_rpn_loc: 0.034  time: 1.0269  data_time: 0.0076  lr: 0.001299  max_mem: 5397M
[32m[04/28 15:02:02 d2.utils.events]: [0m eta: 0:12:22  iter: 279  total_loss: 0.502  loss_cls: 0.153  loss_box_reg: 0.308  loss_rpn_cls: 0.007  loss_rpn_loc: 0.040  time: 1.0262  data_time: 0.0077  lr: 0.001399  max_mem: 5397M
[32m[04/28 15:02:23 d2.utils.events]: [0m eta: 0:12:00  iter: 299  total_loss: 0.445  loss_cls: 0.139  loss_box_reg: 0.269  loss_rpn_cls: 0.005  loss_rpn_loc: 0.031  time: 1.0258  data_time: 0.0080  lr: 0.001499  max_mem: 5397M
[32m[04/28 15:02:44 d2.utils.events]: [0m eta: 0:11:39  iter: 319  total_loss: 0.452  loss_cls: 0.137  loss_box_reg: 0.276  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0262  data_time: 0.0077  lr: 0.001598  max_mem: 5397M
[32m[04/28 15:03:04 d2.utils.events]: [0m eta: 0:11:18  iter: 339  total_loss: 0.589  loss_cls: 0.174  loss_box_reg: 0.339  loss_rpn_cls: 0.006  loss_rpn_loc: 0.053  time: 1.0256  data_time: 0.0076  lr: 0.001698  max_mem: 5397M
[32m[04/28 15:03:25 d2.utils.events]: [0m eta: 0:10:58  iter: 359  total_loss: 0.487  loss_cls: 0.162  loss_box_reg: 0.281  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0257  data_time: 0.0077  lr: 0.001798  max_mem: 5397M
[32m[04/28 15:03:46 d2.utils.events]: [0m eta: 0:10:40  iter: 379  total_loss: 0.473  loss_cls: 0.134  loss_box_reg: 0.274  loss_rpn_cls: 0.004  loss_rpn_loc: 0.044  time: 1.0271  data_time: 0.0077  lr: 0.001898  max_mem: 5397M
[32m[04/28 15:04:06 d2.utils.events]: [0m eta: 0:10:17  iter: 399  total_loss: 0.439  loss_cls: 0.135  loss_box_reg: 0.262  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0256  data_time: 0.0077  lr: 0.001998  max_mem: 5397M
[32m[04/28 15:04:26 d2.utils.events]: [0m eta: 0:09:56  iter: 419  total_loss: 0.479  loss_cls: 0.146  loss_box_reg: 0.279  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 1.0247  data_time: 0.0079  lr: 0.002098  max_mem: 5397M
[32m[04/28 15:04:47 d2.utils.events]: [0m eta: 0:09:37  iter: 439  total_loss: 0.535  loss_cls: 0.158  loss_box_reg: 0.318  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0259  data_time: 0.0077  lr: 0.002198  max_mem: 5397M
[32m[04/28 15:05:07 d2.utils.events]: [0m eta: 0:09:16  iter: 459  total_loss: 0.494  loss_cls: 0.153  loss_box_reg: 0.285  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0246  data_time: 0.0077  lr: 0.002298  max_mem: 5397M
[32m[04/28 15:05:28 d2.utils.events]: [0m eta: 0:08:55  iter: 479  total_loss: 0.502  loss_cls: 0.147  loss_box_reg: 0.298  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0251  data_time: 0.0075  lr: 0.002398  max_mem: 5397M
[32m[04/28 15:05:49 d2.utils.events]: [0m eta: 0:08:36  iter: 499  total_loss: 0.512  loss_cls: 0.152  loss_box_reg: 0.297  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0258  data_time: 0.0077  lr: 0.002498  max_mem: 5397M
[32m[04/28 15:06:09 d2.utils.events]: [0m eta: 0:08:16  iter: 519  total_loss: 0.497  loss_cls: 0.151  loss_box_reg: 0.282  loss_rpn_cls: 0.010  loss_rpn_loc: 0.046  time: 1.0264  data_time: 0.0078  lr: 0.002597  max_mem: 5397M
[32m[04/28 15:06:30 d2.utils.events]: [0m eta: 0:07:55  iter: 539  total_loss: 0.507  loss_cls: 0.144  loss_box_reg: 0.295  loss_rpn_cls: 0.004  loss_rpn_loc: 0.046  time: 1.0266  data_time: 0.0076  lr: 0.002697  max_mem: 5397M
[32m[04/28 15:06:51 d2.utils.events]: [0m eta: 0:07:34  iter: 559  total_loss: 0.468  loss_cls: 0.132  loss_box_reg: 0.286  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0273  data_time: 0.0076  lr: 0.002797  max_mem: 5397M
[32m[04/28 15:07:11 d2.utils.events]: [0m eta: 0:07:13  iter: 579  total_loss: 0.514  loss_cls: 0.156  loss_box_reg: 0.301  loss_rpn_cls: 0.006  loss_rpn_loc: 0.040  time: 1.0270  data_time: 0.0079  lr: 0.002897  max_mem: 5397M
[32m[04/28 15:07:33 d2.utils.events]: [0m eta: 0:06:54  iter: 599  total_loss: 0.503  loss_cls: 0.152  loss_box_reg: 0.292  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0281  data_time: 0.0078  lr: 0.002997  max_mem: 5397M
[32m[04/28 15:07:54 d2.utils.events]: [0m eta: 0:06:33  iter: 619  total_loss: 0.514  loss_cls: 0.158  loss_box_reg: 0.303  loss_rpn_cls: 0.005  loss_rpn_loc: 0.038  time: 1.0286  data_time: 0.0077  lr: 0.003097  max_mem: 5397M
[32m[04/28 15:08:15 d2.utils.events]: [0m eta: 0:06:14  iter: 639  total_loss: 0.572  loss_cls: 0.158  loss_box_reg: 0.334  loss_rpn_cls: 0.006  loss_rpn_loc: 0.053  time: 1.0290  data_time: 0.0076  lr: 0.003197  max_mem: 5397M
[32m[04/28 15:08:35 d2.utils.events]: [0m eta: 0:05:52  iter: 659  total_loss: 0.489  loss_cls: 0.149  loss_box_reg: 0.289  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 1.0285  data_time: 0.0077  lr: 0.003297  max_mem: 5397M
[32m[04/28 15:08:56 d2.utils.events]: [0m eta: 0:05:32  iter: 679  total_loss: 0.595  loss_cls: 0.180  loss_box_reg: 0.332  loss_rpn_cls: 0.010  loss_rpn_loc: 0.063  time: 1.0292  data_time: 0.0078  lr: 0.003397  max_mem: 5397M
[32m[04/28 15:09:16 d2.utils.events]: [0m eta: 0:05:12  iter: 699  total_loss: 0.440  loss_cls: 0.139  loss_box_reg: 0.269  loss_rpn_cls: 0.004  loss_rpn_loc: 0.033  time: 1.0292  data_time: 0.0079  lr: 0.003497  max_mem: 5397M
[32m[04/28 15:09:38 d2.utils.events]: [0m eta: 0:04:51  iter: 719  total_loss: 0.498  loss_cls: 0.155  loss_box_reg: 0.281  loss_rpn_cls: 0.005  loss_rpn_loc: 0.047  time: 1.0297  data_time: 0.0076  lr: 0.003596  max_mem: 5397M
[32m[04/28 15:09:58 d2.utils.events]: [0m eta: 0:04:30  iter: 739  total_loss: 0.484  loss_cls: 0.130  loss_box_reg: 0.274  loss_rpn_cls: 0.007  loss_rpn_loc: 0.039  time: 1.0291  data_time: 0.0075  lr: 0.003696  max_mem: 5397M
[32m[04/28 15:10:19 d2.utils.events]: [0m eta: 0:04:10  iter: 759  total_loss: 0.478  loss_cls: 0.143  loss_box_reg: 0.281  loss_rpn_cls: 0.006  loss_rpn_loc: 0.037  time: 1.0300  data_time: 0.0080  lr: 0.003796  max_mem: 5397M
[32m[04/28 15:10:39 d2.utils.events]: [0m eta: 0:03:49  iter: 779  total_loss: 0.454  loss_cls: 0.142  loss_box_reg: 0.275  loss_rpn_cls: 0.005  loss_rpn_loc: 0.035  time: 1.0297  data_time: 0.0079  lr: 0.003896  max_mem: 5397M
[32m[04/28 15:11:00 d2.utils.events]: [0m eta: 0:03:28  iter: 799  total_loss: 0.504  loss_cls: 0.141  loss_box_reg: 0.302  loss_rpn_cls: 0.005  loss_rpn_loc: 0.045  time: 1.0298  data_time: 0.0076  lr: 0.003996  max_mem: 5397M
[32m[04/28 15:11:21 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.514  loss_cls: 0.153  loss_box_reg: 0.316  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0299  data_time: 0.0077  lr: 0.004096  max_mem: 5397M
[32m[04/28 15:11:41 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.473  loss_cls: 0.146  loss_box_reg: 0.275  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0293  data_time: 0.0075  lr: 0.004196  max_mem: 5397M
[32m[04/28 15:12:02 d2.utils.events]: [0m eta: 0:02:26  iter: 859  total_loss: 0.503  loss_cls: 0.160  loss_box_reg: 0.292  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0293  data_time: 0.0077  lr: 0.004296  max_mem: 5397M
[32m[04/28 15:12:22 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.492  loss_cls: 0.146  loss_box_reg: 0.286  loss_rpn_cls: 0.007  loss_rpn_loc: 0.049  time: 1.0289  data_time: 0.0076  lr: 0.004396  max_mem: 5397M
[32m[04/28 15:12:42 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.483  loss_cls: 0.136  loss_box_reg: 0.267  loss_rpn_cls: 0.006  loss_rpn_loc: 0.052  time: 1.0286  data_time: 0.0075  lr: 0.004496  max_mem: 5397M
[32m[04/28 15:13:02 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.533  loss_cls: 0.155  loss_box_reg: 0.323  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0279  data_time: 0.0075  lr: 0.004595  max_mem: 5397M
[32m[04/28 15:13:22 d2.utils.events]: [0m eta: 0:01:02  iter: 939  total_loss: 0.484  loss_cls: 0.137  loss_box_reg: 0.283  loss_rpn_cls: 0.006  loss_rpn_loc: 0.058  time: 1.0272  data_time: 0.0073  lr: 0.004695  max_mem: 5397M
[32m[04/28 15:13:43 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.466  loss_cls: 0.141  loss_box_reg: 0.277  loss_rpn_cls: 0.005  loss_rpn_loc: 0.046  time: 1.0276  data_time: 0.0078  lr: 0.004795  max_mem: 5397M
[32m[04/28 15:14:04 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.482  loss_cls: 0.149  loss_box_reg: 0.270  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0276  data_time: 0.0075  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 15:14:27 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 15:14:27 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 15:14:27 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 15:14:27 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.492  loss_cls: 0.152  loss_box_reg: 0.286  loss_rpn_cls: 0.005  loss_rpn_loc: 0.039  time: 1.0275  data_time: 0.0076  lr: 0.004995  max_mem: 5397M
[32m[04/28 15:14:27 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:05 (1.0285 s / it)
[32m[04/28 15:14:27 d2.engine.hooks]: [0mTotal training time: 0:17:10 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 15:14:28 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 15:14:28 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 15:14:29 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 15:14:30 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1141 s / img. ETA=0:16:04
[32m[04/28 15:14:36 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1140 s / img. ETA=0:15:59
[32m[04/28 15:14:41 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1138 s / img. ETA=0:15:53
[32m[04/28 15:14:46 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1138 s / img. ETA=0:15:48
[32m[04/28 15:14:51 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1138 s / img. ETA=0:15:43
[32m[04/28 15:14:56 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1139 s / img. ETA=0:15:38
[32m[04/28 15:15:01 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1139 s / img. ETA=0:15:34
[32m[04/28 15:15:06 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1140 s / img. ETA=0:15:29
[32m[04/28 15:15:11 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1140 s / img. ETA=0:15:24
[32m[04/28 15:15:16 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1141 s / img. ETA=0:15:20
[32m[04/28 15:15:21 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1141 s / img. ETA=0:15:15
[32m[04/28 15:15:26 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1140 s / img. ETA=0:15:09
[32m[04/28 15:15:32 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1140 s / img. ETA=0:15:04
[32m[04/28 15:15:37 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1140 s / img. ETA=0:14:59
[32m[04/28 15:15:42 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1140 s / img. ETA=0:14:54
[32m[04/28 15:15:47 d2.evaluation.evaluator]: [0mInference done 671/8355. 0.1140 s / img. ETA=0:14:49
[32m[04/28 15:15:52 d2.evaluation.evaluator]: [0mInference done 715/8355. 0.1140 s / img. ETA=0:14:44
[32m[04/28 15:15:57 d2.evaluation.evaluator]: [0mInference done 758/8355. 0.1141 s / img. ETA=0:14:39
[32m[04/28 15:16:02 d2.evaluation.evaluator]: [0mInference done 801/8355. 0.1141 s / img. ETA=0:14:34
[32m[04/28 15:16:07 d2.evaluation.evaluator]: [0mInference done 845/8355. 0.1141 s / img. ETA=0:14:29
[32m[04/28 15:16:12 d2.evaluation.evaluator]: [0mInference done 888/8355. 0.1141 s / img. ETA=0:14:25
[32m[04/28 15:16:17 d2.evaluation.evaluator]: [0mInference done 931/8355. 0.1142 s / img. ETA=0:14:20
[32m[04/28 15:16:22 d2.evaluation.evaluator]: [0mInference done 974/8355. 0.1142 s / img. ETA=0:14:15
[32m[04/28 15:16:27 d2.evaluation.evaluator]: [0mInference done 1017/8355. 0.1142 s / img. ETA=0:14:10
[32m[04/28 15:16:32 d2.evaluation.evaluator]: [0mInference done 1061/8355. 0.1142 s / img. ETA=0:14:05
[32m[04/28 15:16:37 d2.evaluation.evaluator]: [0mInference done 1105/8355. 0.1142 s / img. ETA=0:14:00
[32m[04/28 15:16:42 d2.evaluation.evaluator]: [0mInference done 1149/8355. 0.1142 s / img. ETA=0:13:54
[32m[04/28 15:16:47 d2.evaluation.evaluator]: [0mInference done 1193/8355. 0.1141 s / img. ETA=0:13:49
[32m[04/28 15:16:52 d2.evaluation.evaluator]: [0mInference done 1237/8355. 0.1141 s / img. ETA=0:13:44
[32m[04/28 15:16:58 d2.evaluation.evaluator]: [0mInference done 1281/8355. 0.1141 s / img. ETA=0:13:39
[32m[04/28 15:17:03 d2.evaluation.evaluator]: [0mInference done 1325/8355. 0.1141 s / img. ETA=0:13:34
[32m[04/28 15:17:08 d2.evaluation.evaluator]: [0mInference done 1369/8355. 0.1141 s / img. ETA=0:13:28
[32m[04/28 15:17:13 d2.evaluation.evaluator]: [0mInference done 1412/8355. 0.1141 s / img. ETA=0:13:24
[32m[04/28 15:17:18 d2.evaluation.evaluator]: [0mInference done 1456/8355. 0.1141 s / img. ETA=0:13:19
[32m[04/28 15:17:23 d2.evaluation.evaluator]: [0mInference done 1499/8355. 0.1142 s / img. ETA=0:13:14
[32m[04/28 15:17:28 d2.evaluation.evaluator]: [0mInference done 1542/8355. 0.1142 s / img. ETA=0:13:09
[32m[04/28 15:17:33 d2.evaluation.evaluator]: [0mInference done 1585/8355. 0.1142 s / img. ETA=0:13:05
[32m[04/28 15:17:38 d2.evaluation.evaluator]: [0mInference done 1628/8355. 0.1143 s / img. ETA=0:13:00
[32m[04/28 15:17:43 d2.evaluation.evaluator]: [0mInference done 1671/8355. 0.1143 s / img. ETA=0:12:55
[32m[04/28 15:17:48 d2.evaluation.evaluator]: [0mInference done 1714/8355. 0.1144 s / img. ETA=0:12:50
[32m[04/28 15:17:53 d2.evaluation.evaluator]: [0mInference done 1757/8355. 0.1144 s / img. ETA=0:12:46
[32m[04/28 15:17:58 d2.evaluation.evaluator]: [0mInference done 1800/8355. 0.1145 s / img. ETA=0:12:41
[32m[04/28 15:18:03 d2.evaluation.evaluator]: [0mInference done 1843/8355. 0.1145 s / img. ETA=0:12:36
[32m[04/28 15:18:08 d2.evaluation.evaluator]: [0mInference done 1886/8355. 0.1145 s / img. ETA=0:12:31
[32m[04/28 15:18:13 d2.evaluation.evaluator]: [0mInference done 1929/8355. 0.1145 s / img. ETA=0:12:27
[32m[04/28 15:18:19 d2.evaluation.evaluator]: [0mInference done 1972/8355. 0.1146 s / img. ETA=0:12:22
[32m[04/28 15:18:24 d2.evaluation.evaluator]: [0mInference done 2015/8355. 0.1146 s / img. ETA=0:12:17
[32m[04/28 15:18:29 d2.evaluation.evaluator]: [0mInference done 2058/8355. 0.1146 s / img. ETA=0:12:12
[32m[04/28 15:18:34 d2.evaluation.evaluator]: [0mInference done 2101/8355. 0.1146 s / img. ETA=0:12:07
[32m[04/28 15:18:39 d2.evaluation.evaluator]: [0mInference done 2145/8355. 0.1146 s / img. ETA=0:12:02
[32m[04/28 15:18:44 d2.evaluation.evaluator]: [0mInference done 2188/8355. 0.1146 s / img. ETA=0:11:57
[32m[04/28 15:18:49 d2.evaluation.evaluator]: [0mInference done 2231/8355. 0.1146 s / img. ETA=0:11:52
[32m[04/28 15:18:54 d2.evaluation.evaluator]: [0mInference done 2274/8355. 0.1146 s / img. ETA=0:11:47
[32m[04/28 15:18:59 d2.evaluation.evaluator]: [0mInference done 2317/8355. 0.1147 s / img. ETA=0:11:42
[32m[04/28 15:19:04 d2.evaluation.evaluator]: [0mInference done 2360/8355. 0.1147 s / img. ETA=0:11:37
[32m[04/28 15:19:09 d2.evaluation.evaluator]: [0mInference done 2403/8355. 0.1147 s / img. ETA=0:11:33
[32m[04/28 15:19:14 d2.evaluation.evaluator]: [0mInference done 2446/8355. 0.1147 s / img. ETA=0:11:28
[32m[04/28 15:19:19 d2.evaluation.evaluator]: [0mInference done 2489/8355. 0.1147 s / img. ETA=0:11:23
[32m[04/28 15:19:24 d2.evaluation.evaluator]: [0mInference done 2532/8355. 0.1147 s / img. ETA=0:11:18
[32m[04/28 15:19:29 d2.evaluation.evaluator]: [0mInference done 2575/8355. 0.1147 s / img. ETA=0:11:13
[32m[04/28 15:19:34 d2.evaluation.evaluator]: [0mInference done 2618/8355. 0.1147 s / img. ETA=0:11:08
[32m[04/28 15:19:39 d2.evaluation.evaluator]: [0mInference done 2661/8355. 0.1147 s / img. ETA=0:11:03
[32m[04/28 15:19:44 d2.evaluation.evaluator]: [0mInference done 2704/8355. 0.1148 s / img. ETA=0:10:58
[32m[04/28 15:19:49 d2.evaluation.evaluator]: [0mInference done 2747/8355. 0.1148 s / img. ETA=0:10:53
[32m[04/28 15:19:54 d2.evaluation.evaluator]: [0mInference done 2790/8355. 0.1148 s / img. ETA=0:10:48
[32m[04/28 15:19:59 d2.evaluation.evaluator]: [0mInference done 2833/8355. 0.1148 s / img. ETA=0:10:43
[32m[04/28 15:20:05 d2.evaluation.evaluator]: [0mInference done 2876/8355. 0.1148 s / img. ETA=0:10:38
[32m[04/28 15:20:10 d2.evaluation.evaluator]: [0mInference done 2919/8355. 0.1148 s / img. ETA=0:10:33
[32m[04/28 15:20:15 d2.evaluation.evaluator]: [0mInference done 2962/8355. 0.1148 s / img. ETA=0:10:28
[32m[04/28 15:20:20 d2.evaluation.evaluator]: [0mInference done 3005/8355. 0.1148 s / img. ETA=0:10:23
[32m[04/28 15:20:25 d2.evaluation.evaluator]: [0mInference done 3048/8355. 0.1148 s / img. ETA=0:10:18
[32m[04/28 15:20:30 d2.evaluation.evaluator]: [0mInference done 3091/8355. 0.1149 s / img. ETA=0:10:13
[32m[04/28 15:20:35 d2.evaluation.evaluator]: [0mInference done 3134/8355. 0.1149 s / img. ETA=0:10:08
[32m[04/28 15:20:40 d2.evaluation.evaluator]: [0mInference done 3178/8355. 0.1148 s / img. ETA=0:10:03
[32m[04/28 15:20:45 d2.evaluation.evaluator]: [0mInference done 3222/8355. 0.1148 s / img. ETA=0:09:58
[32m[04/28 15:20:50 d2.evaluation.evaluator]: [0mInference done 3265/8355. 0.1148 s / img. ETA=0:09:53
[32m[04/28 15:20:55 d2.evaluation.evaluator]: [0mInference done 3308/8355. 0.1148 s / img. ETA=0:09:48
[32m[04/28 15:21:00 d2.evaluation.evaluator]: [0mInference done 3352/8355. 0.1148 s / img. ETA=0:09:43
[32m[04/28 15:21:05 d2.evaluation.evaluator]: [0mInference done 3395/8355. 0.1148 s / img. ETA=0:09:38
[32m[04/28 15:21:10 d2.evaluation.evaluator]: [0mInference done 3439/8355. 0.1148 s / img. ETA=0:09:33
[32m[04/28 15:21:15 d2.evaluation.evaluator]: [0mInference done 3482/8355. 0.1148 s / img. ETA=0:09:28
[32m[04/28 15:21:20 d2.evaluation.evaluator]: [0mInference done 3525/8355. 0.1148 s / img. ETA=0:09:23
[32m[04/28 15:21:25 d2.evaluation.evaluator]: [0mInference done 3569/8355. 0.1148 s / img. ETA=0:09:17
[32m[04/28 15:21:30 d2.evaluation.evaluator]: [0mInference done 3612/8355. 0.1148 s / img. ETA=0:09:13
[32m[04/28 15:21:35 d2.evaluation.evaluator]: [0mInference done 3655/8355. 0.1148 s / img. ETA=0:09:08
[32m[04/28 15:21:40 d2.evaluation.evaluator]: [0mInference done 3698/8355. 0.1148 s / img. ETA=0:09:02
[32m[04/28 15:21:45 d2.evaluation.evaluator]: [0mInference done 3741/8355. 0.1148 s / img. ETA=0:08:57
[32m[04/28 15:21:50 d2.evaluation.evaluator]: [0mInference done 3784/8355. 0.1148 s / img. ETA=0:08:52
[32m[04/28 15:21:55 d2.evaluation.evaluator]: [0mInference done 3827/8355. 0.1148 s / img. ETA=0:08:48
[32m[04/28 15:22:00 d2.evaluation.evaluator]: [0mInference done 3870/8355. 0.1148 s / img. ETA=0:08:42
[32m[04/28 15:22:06 d2.evaluation.evaluator]: [0mInference done 3914/8355. 0.1148 s / img. ETA=0:08:37
[32m[04/28 15:22:11 d2.evaluation.evaluator]: [0mInference done 3957/8355. 0.1148 s / img. ETA=0:08:32
[32m[04/28 15:22:16 d2.evaluation.evaluator]: [0mInference done 4000/8355. 0.1148 s / img. ETA=0:08:27
[32m[04/28 15:22:21 d2.evaluation.evaluator]: [0mInference done 4043/8355. 0.1148 s / img. ETA=0:08:22
[32m[04/28 15:22:26 d2.evaluation.evaluator]: [0mInference done 4086/8355. 0.1148 s / img. ETA=0:08:17
[32m[04/28 15:22:31 d2.evaluation.evaluator]: [0mInference done 4129/8355. 0.1148 s / img. ETA=0:08:12
[32m[04/28 15:22:36 d2.evaluation.evaluator]: [0mInference done 4172/8355. 0.1148 s / img. ETA=0:08:07
[32m[04/28 15:22:41 d2.evaluation.evaluator]: [0mInference done 4215/8355. 0.1148 s / img. ETA=0:08:02
[32m[04/28 15:22:46 d2.evaluation.evaluator]: [0mInference done 4258/8355. 0.1148 s / img. ETA=0:07:57
[32m[04/28 15:22:51 d2.evaluation.evaluator]: [0mInference done 4301/8355. 0.1148 s / img. ETA=0:07:52
[32m[04/28 15:22:56 d2.evaluation.evaluator]: [0mInference done 4344/8355. 0.1148 s / img. ETA=0:07:47
[32m[04/28 15:23:01 d2.evaluation.evaluator]: [0mInference done 4387/8355. 0.1148 s / img. ETA=0:07:42
[32m[04/28 15:23:06 d2.evaluation.evaluator]: [0mInference done 4430/8355. 0.1148 s / img. ETA=0:07:37
[32m[04/28 15:23:11 d2.evaluation.evaluator]: [0mInference done 4473/8355. 0.1148 s / img. ETA=0:07:32
[32m[04/28 15:23:16 d2.evaluation.evaluator]: [0mInference done 4516/8355. 0.1148 s / img. ETA=0:07:27
[32m[04/28 15:23:21 d2.evaluation.evaluator]: [0mInference done 4559/8355. 0.1148 s / img. ETA=0:07:22
[32m[04/28 15:23:26 d2.evaluation.evaluator]: [0mInference done 4602/8355. 0.1148 s / img. ETA=0:07:17
[32m[04/28 15:23:31 d2.evaluation.evaluator]: [0mInference done 4645/8355. 0.1148 s / img. ETA=0:07:12
[32m[04/28 15:23:36 d2.evaluation.evaluator]: [0mInference done 4688/8355. 0.1148 s / img. ETA=0:07:07
[32m[04/28 15:23:41 d2.evaluation.evaluator]: [0mInference done 4731/8355. 0.1148 s / img. ETA=0:07:02
[32m[04/28 15:23:46 d2.evaluation.evaluator]: [0mInference done 4774/8355. 0.1148 s / img. ETA=0:06:57
[32m[04/28 15:23:51 d2.evaluation.evaluator]: [0mInference done 4817/8355. 0.1149 s / img. ETA=0:06:52
[32m[04/28 15:23:56 d2.evaluation.evaluator]: [0mInference done 4860/8355. 0.1149 s / img. ETA=0:06:47
[32m[04/28 15:24:01 d2.evaluation.evaluator]: [0mInference done 4903/8355. 0.1149 s / img. ETA=0:06:42
[32m[04/28 15:24:06 d2.evaluation.evaluator]: [0mInference done 4946/8355. 0.1149 s / img. ETA=0:06:37
[32m[04/28 15:24:11 d2.evaluation.evaluator]: [0mInference done 4989/8355. 0.1149 s / img. ETA=0:06:32
[32m[04/28 15:24:16 d2.evaluation.evaluator]: [0mInference done 5032/8355. 0.1149 s / img. ETA=0:06:27
[32m[04/28 15:24:21 d2.evaluation.evaluator]: [0mInference done 5075/8355. 0.1149 s / img. ETA=0:06:22
[32m[04/28 15:24:26 d2.evaluation.evaluator]: [0mInference done 5118/8355. 0.1149 s / img. ETA=0:06:17
[32m[04/28 15:24:31 d2.evaluation.evaluator]: [0mInference done 5161/8355. 0.1149 s / img. ETA=0:06:12
[32m[04/28 15:24:36 d2.evaluation.evaluator]: [0mInference done 5204/8355. 0.1149 s / img. ETA=0:06:07
[32m[04/28 15:24:41 d2.evaluation.evaluator]: [0mInference done 5247/8355. 0.1149 s / img. ETA=0:06:02
[32m[04/28 15:24:46 d2.evaluation.evaluator]: [0mInference done 5290/8355. 0.1149 s / img. ETA=0:05:57
[32m[04/28 15:24:51 d2.evaluation.evaluator]: [0mInference done 5333/8355. 0.1149 s / img. ETA=0:05:52
[32m[04/28 15:24:56 d2.evaluation.evaluator]: [0mInference done 5376/8355. 0.1149 s / img. ETA=0:05:47
[32m[04/28 15:25:02 d2.evaluation.evaluator]: [0mInference done 5419/8355. 0.1149 s / img. ETA=0:05:42
[32m[04/28 15:25:07 d2.evaluation.evaluator]: [0mInference done 5462/8355. 0.1149 s / img. ETA=0:05:37
[32m[04/28 15:25:12 d2.evaluation.evaluator]: [0mInference done 5505/8355. 0.1149 s / img. ETA=0:05:32
[32m[04/28 15:25:17 d2.evaluation.evaluator]: [0mInference done 5549/8355. 0.1149 s / img. ETA=0:05:27
[32m[04/28 15:25:22 d2.evaluation.evaluator]: [0mInference done 5593/8355. 0.1149 s / img. ETA=0:05:22
[32m[04/28 15:25:27 d2.evaluation.evaluator]: [0mInference done 5636/8355. 0.1149 s / img. ETA=0:05:17
[32m[04/28 15:25:32 d2.evaluation.evaluator]: [0mInference done 5679/8355. 0.1149 s / img. ETA=0:05:12
[32m[04/28 15:25:37 d2.evaluation.evaluator]: [0mInference done 5722/8355. 0.1149 s / img. ETA=0:05:07
[32m[04/28 15:25:42 d2.evaluation.evaluator]: [0mInference done 5765/8355. 0.1149 s / img. ETA=0:05:02
[32m[04/28 15:25:47 d2.evaluation.evaluator]: [0mInference done 5808/8355. 0.1149 s / img. ETA=0:04:57
[32m[04/28 15:25:52 d2.evaluation.evaluator]: [0mInference done 5851/8355. 0.1149 s / img. ETA=0:04:52
[32m[04/28 15:25:57 d2.evaluation.evaluator]: [0mInference done 5894/8355. 0.1149 s / img. ETA=0:04:47
[32m[04/28 15:26:02 d2.evaluation.evaluator]: [0mInference done 5937/8355. 0.1149 s / img. ETA=0:04:42
[32m[04/28 15:26:07 d2.evaluation.evaluator]: [0mInference done 5980/8355. 0.1149 s / img. ETA=0:04:37
[32m[04/28 15:26:12 d2.evaluation.evaluator]: [0mInference done 6023/8355. 0.1149 s / img. ETA=0:04:32
[32m[04/28 15:26:18 d2.evaluation.evaluator]: [0mInference done 6066/8355. 0.1150 s / img. ETA=0:04:27
[32m[04/28 15:26:23 d2.evaluation.evaluator]: [0mInference done 6109/8355. 0.1150 s / img. ETA=0:04:22
[32m[04/28 15:26:28 d2.evaluation.evaluator]: [0mInference done 6152/8355. 0.1150 s / img. ETA=0:04:17
[32m[04/28 15:26:33 d2.evaluation.evaluator]: [0mInference done 6195/8355. 0.1150 s / img. ETA=0:04:12
[32m[04/28 15:26:38 d2.evaluation.evaluator]: [0mInference done 6238/8355. 0.1150 s / img. ETA=0:04:07
[32m[04/28 15:26:43 d2.evaluation.evaluator]: [0mInference done 6280/8355. 0.1150 s / img. ETA=0:04:02
[32m[04/28 15:26:48 d2.evaluation.evaluator]: [0mInference done 6323/8355. 0.1150 s / img. ETA=0:03:57
[32m[04/28 15:26:53 d2.evaluation.evaluator]: [0mInference done 6366/8355. 0.1150 s / img. ETA=0:03:52
[32m[04/28 15:26:58 d2.evaluation.evaluator]: [0mInference done 6409/8355. 0.1150 s / img. ETA=0:03:47
[32m[04/28 15:27:03 d2.evaluation.evaluator]: [0mInference done 6452/8355. 0.1150 s / img. ETA=0:03:42
[32m[04/28 15:27:08 d2.evaluation.evaluator]: [0mInference done 6495/8355. 0.1150 s / img. ETA=0:03:37
[32m[04/28 15:27:13 d2.evaluation.evaluator]: [0mInference done 6538/8355. 0.1150 s / img. ETA=0:03:32
[32m[04/28 15:27:18 d2.evaluation.evaluator]: [0mInference done 6581/8355. 0.1150 s / img. ETA=0:03:27
[32m[04/28 15:27:23 d2.evaluation.evaluator]: [0mInference done 6624/8355. 0.1150 s / img. ETA=0:03:22
[32m[04/28 15:27:28 d2.evaluation.evaluator]: [0mInference done 6667/8355. 0.1150 s / img. ETA=0:03:17
[32m[04/28 15:27:33 d2.evaluation.evaluator]: [0mInference done 6711/8355. 0.1150 s / img. ETA=0:03:12
[32m[04/28 15:27:38 d2.evaluation.evaluator]: [0mInference done 6755/8355. 0.1150 s / img. ETA=0:03:06
[32m[04/28 15:27:43 d2.evaluation.evaluator]: [0mInference done 6798/8355. 0.1150 s / img. ETA=0:03:01
[32m[04/28 15:27:48 d2.evaluation.evaluator]: [0mInference done 6841/8355. 0.1150 s / img. ETA=0:02:56
[32m[04/28 15:27:53 d2.evaluation.evaluator]: [0mInference done 6884/8355. 0.1150 s / img. ETA=0:02:51
[32m[04/28 15:27:58 d2.evaluation.evaluator]: [0mInference done 6927/8355. 0.1150 s / img. ETA=0:02:46
[32m[04/28 15:28:04 d2.evaluation.evaluator]: [0mInference done 6970/8355. 0.1150 s / img. ETA=0:02:41
[32m[04/28 15:28:09 d2.evaluation.evaluator]: [0mInference done 7013/8355. 0.1150 s / img. ETA=0:02:36
[32m[04/28 15:28:14 d2.evaluation.evaluator]: [0mInference done 7056/8355. 0.1150 s / img. ETA=0:02:31
[32m[04/28 15:28:19 d2.evaluation.evaluator]: [0mInference done 7099/8355. 0.1150 s / img. ETA=0:02:26
[32m[04/28 15:28:24 d2.evaluation.evaluator]: [0mInference done 7142/8355. 0.1150 s / img. ETA=0:02:21
[32m[04/28 15:28:29 d2.evaluation.evaluator]: [0mInference done 7185/8355. 0.1150 s / img. ETA=0:02:16
[32m[04/28 15:28:34 d2.evaluation.evaluator]: [0mInference done 7228/8355. 0.1151 s / img. ETA=0:02:11
[32m[04/28 15:28:39 d2.evaluation.evaluator]: [0mInference done 7271/8355. 0.1151 s / img. ETA=0:02:06
[32m[04/28 15:28:44 d2.evaluation.evaluator]: [0mInference done 7314/8355. 0.1151 s / img. ETA=0:02:01
[32m[04/28 15:28:49 d2.evaluation.evaluator]: [0mInference done 7357/8355. 0.1151 s / img. ETA=0:01:56
[32m[04/28 15:28:54 d2.evaluation.evaluator]: [0mInference done 7400/8355. 0.1151 s / img. ETA=0:01:51
[32m[04/28 15:28:59 d2.evaluation.evaluator]: [0mInference done 7443/8355. 0.1151 s / img. ETA=0:01:46
[32m[04/28 15:29:04 d2.evaluation.evaluator]: [0mInference done 7486/8355. 0.1151 s / img. ETA=0:01:41
[32m[04/28 15:29:09 d2.evaluation.evaluator]: [0mInference done 7529/8355. 0.1151 s / img. ETA=0:01:36
[32m[04/28 15:29:15 d2.evaluation.evaluator]: [0mInference done 7572/8355. 0.1151 s / img. ETA=0:01:31
[32m[04/28 15:29:20 d2.evaluation.evaluator]: [0mInference done 7615/8355. 0.1151 s / img. ETA=0:01:26
[32m[04/28 15:29:25 d2.evaluation.evaluator]: [0mInference done 7658/8355. 0.1151 s / img. ETA=0:01:21
[32m[04/28 15:29:30 d2.evaluation.evaluator]: [0mInference done 7701/8355. 0.1151 s / img. ETA=0:01:16
[32m[04/28 15:29:35 d2.evaluation.evaluator]: [0mInference done 7744/8355. 0.1151 s / img. ETA=0:01:11
[32m[04/28 15:29:40 d2.evaluation.evaluator]: [0mInference done 7787/8355. 0.1151 s / img. ETA=0:01:06
[32m[04/28 15:29:45 d2.evaluation.evaluator]: [0mInference done 7830/8355. 0.1151 s / img. ETA=0:01:01
[32m[04/28 15:29:50 d2.evaluation.evaluator]: [0mInference done 7873/8355. 0.1151 s / img. ETA=0:00:56
[32m[04/28 15:29:55 d2.evaluation.evaluator]: [0mInference done 7916/8355. 0.1151 s / img. ETA=0:00:51
[32m[04/28 15:30:00 d2.evaluation.evaluator]: [0mInference done 7959/8355. 0.1151 s / img. ETA=0:00:46
[32m[04/28 15:30:05 d2.evaluation.evaluator]: [0mInference done 8002/8355. 0.1151 s / img. ETA=0:00:41
[32m[04/28 15:30:10 d2.evaluation.evaluator]: [0mInference done 8045/8355. 0.1151 s / img. ETA=0:00:36
[32m[04/28 15:30:15 d2.evaluation.evaluator]: [0mInference done 8089/8355. 0.1151 s / img. ETA=0:00:31
[32m[04/28 15:30:20 d2.evaluation.evaluator]: [0mInference done 8133/8355. 0.1151 s / img. ETA=0:00:25
[32m[04/28 15:30:25 d2.evaluation.evaluator]: [0mInference done 8177/8355. 0.1151 s / img. ETA=0:00:20
[32m[04/28 15:30:30 d2.evaluation.evaluator]: [0mInference done 8220/8355. 0.1151 s / img. ETA=0:00:15
[32m[04/28 15:30:36 d2.evaluation.evaluator]: [0mInference done 8263/8355. 0.1151 s / img. ETA=0:00:10
[32m[04/28 15:30:41 d2.evaluation.evaluator]: [0mInference done 8306/8355. 0.1151 s / img. ETA=0:00:05
[32m[04/28 15:30:46 d2.evaluation.evaluator]: [0mInference done 8349/8355. 0.1151 s / img. ETA=0:00:00
[32m[04/28 15:30:46 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:16.623441 (0.116961 s / img per device, on 1 devices)
[32m[04/28 15:30:46 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:01 (0.115128 s / img per device, on 1 devices)
[32m[04/28 15:30:47 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 15:30:47 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 15:30:47 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.57s).
Accumulating evaluation results...
DONE (t=2.13s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.500
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.859
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.511
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.393
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.625
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.744
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.543
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.561
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.472
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.680
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.778
[32m[04/28 15:31:09 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.977 | 85.945 | 51.084 | 39.311 | 62.492 | 74.409 |
[32m[04/28 15:31:09 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 49.338 | bicycle       | 42.692 | car            | 57.902 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 15:31:09 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 15:31:09 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 15:31:09 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 15:31:11 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1152 s / img. ETA=0:02:25
[32m[04/28 15:31:16 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1147 s / img. ETA=0:02:20
[32m[04/28 15:31:21 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1148 s / img. ETA=0:02:15
[32m[04/28 15:31:26 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1147 s / img. ETA=0:02:10
[32m[04/28 15:31:31 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1148 s / img. ETA=0:02:05
[32m[04/28 15:31:36 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1147 s / img. ETA=0:02:00
[32m[04/28 15:31:41 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1148 s / img. ETA=0:01:55
[32m[04/28 15:31:46 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1148 s / img. ETA=0:01:50
[32m[04/28 15:31:51 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1148 s / img. ETA=0:01:45
[32m[04/28 15:31:56 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1148 s / img. ETA=0:01:40
[32m[04/28 15:32:01 d2.evaluation.evaluator]: [0mInference done 442/1257. 0.1148 s / img. ETA=0:01:35
[32m[04/28 15:32:06 d2.evaluation.evaluator]: [0mInference done 485/1257. 0.1147 s / img. ETA=0:01:30
[32m[04/28 15:32:11 d2.evaluation.evaluator]: [0mInference done 528/1257. 0.1147 s / img. ETA=0:01:24
[32m[04/28 15:32:16 d2.evaluation.evaluator]: [0mInference done 571/1257. 0.1148 s / img. ETA=0:01:19
[32m[04/28 15:32:21 d2.evaluation.evaluator]: [0mInference done 614/1257. 0.1147 s / img. ETA=0:01:14
[32m[04/28 15:32:26 d2.evaluation.evaluator]: [0mInference done 657/1257. 0.1148 s / img. ETA=0:01:09
[32m[04/28 15:32:31 d2.evaluation.evaluator]: [0mInference done 700/1257. 0.1148 s / img. ETA=0:01:04
[32m[04/28 15:32:36 d2.evaluation.evaluator]: [0mInference done 743/1257. 0.1148 s / img. ETA=0:00:59
[32m[04/28 15:32:41 d2.evaluation.evaluator]: [0mInference done 786/1257. 0.1148 s / img. ETA=0:00:54
[32m[04/28 15:32:46 d2.evaluation.evaluator]: [0mInference done 829/1257. 0.1148 s / img. ETA=0:00:49
[32m[04/28 15:32:51 d2.evaluation.evaluator]: [0mInference done 872/1257. 0.1149 s / img. ETA=0:00:44
[32m[04/28 15:32:56 d2.evaluation.evaluator]: [0mInference done 915/1257. 0.1149 s / img. ETA=0:00:39
[32m[04/28 15:33:01 d2.evaluation.evaluator]: [0mInference done 958/1257. 0.1149 s / img. ETA=0:00:34
[32m[04/28 15:33:06 d2.evaluation.evaluator]: [0mInference done 1001/1257. 0.1149 s / img. ETA=0:00:29
[32m[04/28 15:33:11 d2.evaluation.evaluator]: [0mInference done 1044/1257. 0.1150 s / img. ETA=0:00:24
[32m[04/28 15:33:16 d2.evaluation.evaluator]: [0mInference done 1087/1257. 0.1150 s / img. ETA=0:00:19
[32m[04/28 15:33:21 d2.evaluation.evaluator]: [0mInference done 1130/1257. 0.1150 s / img. ETA=0:00:14
[32m[04/28 15:33:27 d2.evaluation.evaluator]: [0mInference done 1173/1257. 0.1150 s / img. ETA=0:00:09
[32m[04/28 15:33:32 d2.evaluation.evaluator]: [0mInference done 1216/1257. 0.1150 s / img. ETA=0:00:04
[32m[04/28 15:33:36 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.359404 (0.116900 s / img per device, on 1 devices)
[32m[04/28 15:33:36 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115030 s / img per device, on 1 devices)
[32m[04/28 15:33:36 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 15:33:36 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 15:33:37 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.94s).
Accumulating evaluation results...
DONE (t=0.36s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.714
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.335
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.273
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.554
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.174
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.437
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.484
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.586
[32m[04/28 15:33:40 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 37.179 | 71.436 | 33.532 | 27.290 | 42.582 | 55.444 |
[32m[04/28 15:33:40 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 40.212 | bicycle       | 18.564 | car            | 52.762 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  23  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 15:33:41 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 15:33:41 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 15:33:41 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 15:33:41 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 15:33:42 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 15:33:42 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 15:33:42 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 15:34:02 d2.utils.events]: [0m eta: 0:16:33  iter: 19  total_loss: 0.482  loss_cls: 0.146  loss_box_reg: 0.274  loss_rpn_cls: 0.004  loss_rpn_loc: 0.038  time: 1.0144  data_time: 0.0182  lr: 0.000100  max_mem: 5397M
[32m[04/28 15:34:22 d2.utils.events]: [0m eta: 0:16:13  iter: 39  total_loss: 0.444  loss_cls: 0.142  loss_box_reg: 0.261  loss_rpn_cls: 0.005  loss_rpn_loc: 0.032  time: 1.0176  data_time: 0.0077  lr: 0.000200  max_mem: 5397M
[32m[04/28 15:34:43 d2.utils.events]: [0m eta: 0:16:05  iter: 59  total_loss: 0.462  loss_cls: 0.137  loss_box_reg: 0.290  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0255  data_time: 0.0075  lr: 0.000300  max_mem: 5397M
[32m[04/28 15:35:04 d2.utils.events]: [0m eta: 0:15:40  iter: 79  total_loss: 0.481  loss_cls: 0.148  loss_box_reg: 0.288  loss_rpn_cls: 0.007  loss_rpn_loc: 0.038  time: 1.0231  data_time: 0.0079  lr: 0.000400  max_mem: 5397M
[32m[04/28 15:35:24 d2.utils.events]: [0m eta: 0:15:18  iter: 99  total_loss: 0.503  loss_cls: 0.155  loss_box_reg: 0.301  loss_rpn_cls: 0.009  loss_rpn_loc: 0.050  time: 1.0212  data_time: 0.0077  lr: 0.000500  max_mem: 5397M
[32m[04/28 15:35:44 d2.utils.events]: [0m eta: 0:14:58  iter: 119  total_loss: 0.440  loss_cls: 0.137  loss_box_reg: 0.265  loss_rpn_cls: 0.004  loss_rpn_loc: 0.040  time: 1.0213  data_time: 0.0077  lr: 0.000599  max_mem: 5397M
[32m[04/28 15:36:05 d2.utils.events]: [0m eta: 0:14:38  iter: 139  total_loss: 0.459  loss_cls: 0.142  loss_box_reg: 0.281  loss_rpn_cls: 0.005  loss_rpn_loc: 0.047  time: 1.0215  data_time: 0.0078  lr: 0.000699  max_mem: 5397M
[32m[04/28 15:36:26 d2.utils.events]: [0m eta: 0:14:18  iter: 159  total_loss: 0.500  loss_cls: 0.158  loss_box_reg: 0.300  loss_rpn_cls: 0.005  loss_rpn_loc: 0.047  time: 1.0226  data_time: 0.0080  lr: 0.000799  max_mem: 5397M
[32m[04/28 15:36:47 d2.utils.events]: [0m eta: 0:14:00  iter: 179  total_loss: 0.476  loss_cls: 0.145  loss_box_reg: 0.293  loss_rpn_cls: 0.003  loss_rpn_loc: 0.042  time: 1.0248  data_time: 0.0079  lr: 0.000899  max_mem: 5397M
[32m[04/28 15:37:07 d2.utils.events]: [0m eta: 0:13:43  iter: 199  total_loss: 0.419  loss_cls: 0.130  loss_box_reg: 0.247  loss_rpn_cls: 0.003  loss_rpn_loc: 0.038  time: 1.0257  data_time: 0.0078  lr: 0.000999  max_mem: 5397M
[32m[04/28 15:37:28 d2.utils.events]: [0m eta: 0:13:24  iter: 219  total_loss: 0.514  loss_cls: 0.153  loss_box_reg: 0.295  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0271  data_time: 0.0078  lr: 0.001099  max_mem: 5397M
[32m[04/28 15:37:49 d2.utils.events]: [0m eta: 0:13:05  iter: 239  total_loss: 0.471  loss_cls: 0.144  loss_box_reg: 0.272  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0274  data_time: 0.0077  lr: 0.001199  max_mem: 5397M
[32m[04/28 15:38:09 d2.utils.events]: [0m eta: 0:12:45  iter: 259  total_loss: 0.402  loss_cls: 0.117  loss_box_reg: 0.253  loss_rpn_cls: 0.004  loss_rpn_loc: 0.034  time: 1.0276  data_time: 0.0077  lr: 0.001299  max_mem: 5397M
[32m[04/28 15:38:30 d2.utils.events]: [0m eta: 0:12:25  iter: 279  total_loss: 0.451  loss_cls: 0.132  loss_box_reg: 0.269  loss_rpn_cls: 0.005  loss_rpn_loc: 0.035  time: 1.0268  data_time: 0.0077  lr: 0.001399  max_mem: 5397M
[32m[04/28 15:38:51 d2.utils.events]: [0m eta: 0:12:05  iter: 299  total_loss: 0.552  loss_cls: 0.174  loss_box_reg: 0.318  loss_rpn_cls: 0.007  loss_rpn_loc: 0.051  time: 1.0286  data_time: 0.0080  lr: 0.001499  max_mem: 5397M
[32m[04/28 15:39:12 d2.utils.events]: [0m eta: 0:11:49  iter: 319  total_loss: 0.509  loss_cls: 0.163  loss_box_reg: 0.291  loss_rpn_cls: 0.003  loss_rpn_loc: 0.045  time: 1.0302  data_time: 0.0080  lr: 0.001598  max_mem: 5397M
[32m[04/28 15:39:32 d2.utils.events]: [0m eta: 0:11:24  iter: 339  total_loss: 0.416  loss_cls: 0.128  loss_box_reg: 0.260  loss_rpn_cls: 0.004  loss_rpn_loc: 0.035  time: 1.0288  data_time: 0.0077  lr: 0.001698  max_mem: 5397M
[32m[04/28 15:39:53 d2.utils.events]: [0m eta: 0:11:03  iter: 359  total_loss: 0.499  loss_cls: 0.137  loss_box_reg: 0.287  loss_rpn_cls: 0.006  loss_rpn_loc: 0.036  time: 1.0288  data_time: 0.0078  lr: 0.001798  max_mem: 5397M
[32m[04/28 15:40:14 d2.utils.events]: [0m eta: 0:10:44  iter: 379  total_loss: 0.452  loss_cls: 0.144  loss_box_reg: 0.276  loss_rpn_cls: 0.004  loss_rpn_loc: 0.046  time: 1.0298  data_time: 0.0079  lr: 0.001898  max_mem: 5397M
[32m[04/28 15:40:35 d2.utils.events]: [0m eta: 0:10:24  iter: 399  total_loss: 0.473  loss_cls: 0.141  loss_box_reg: 0.278  loss_rpn_cls: 0.006  loss_rpn_loc: 0.044  time: 1.0307  data_time: 0.0077  lr: 0.001998  max_mem: 5397M
[32m[04/28 15:40:55 d2.utils.events]: [0m eta: 0:10:03  iter: 419  total_loss: 0.566  loss_cls: 0.174  loss_box_reg: 0.307  loss_rpn_cls: 0.004  loss_rpn_loc: 0.051  time: 1.0298  data_time: 0.0079  lr: 0.002098  max_mem: 5397M
[32m[04/28 15:41:16 d2.utils.events]: [0m eta: 0:09:41  iter: 439  total_loss: 0.557  loss_cls: 0.169  loss_box_reg: 0.331  loss_rpn_cls: 0.007  loss_rpn_loc: 0.045  time: 1.0297  data_time: 0.0077  lr: 0.002198  max_mem: 5397M
[32m[04/28 15:41:36 d2.utils.events]: [0m eta: 0:09:19  iter: 459  total_loss: 0.502  loss_cls: 0.153  loss_box_reg: 0.299  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0287  data_time: 0.0076  lr: 0.002298  max_mem: 5397M
[32m[04/28 15:41:57 d2.utils.events]: [0m eta: 0:08:59  iter: 479  total_loss: 0.501  loss_cls: 0.145  loss_box_reg: 0.271  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0292  data_time: 0.0077  lr: 0.002398  max_mem: 5397M
[32m[04/28 15:42:17 d2.utils.events]: [0m eta: 0:08:38  iter: 499  total_loss: 0.468  loss_cls: 0.137  loss_box_reg: 0.270  loss_rpn_cls: 0.003  loss_rpn_loc: 0.039  time: 1.0291  data_time: 0.0076  lr: 0.002498  max_mem: 5397M
[32m[04/28 15:42:38 d2.utils.events]: [0m eta: 0:08:17  iter: 519  total_loss: 0.503  loss_cls: 0.153  loss_box_reg: 0.291  loss_rpn_cls: 0.009  loss_rpn_loc: 0.051  time: 1.0293  data_time: 0.0078  lr: 0.002597  max_mem: 5397M
[32m[04/28 15:42:59 d2.utils.events]: [0m eta: 0:07:57  iter: 539  total_loss: 0.451  loss_cls: 0.132  loss_box_reg: 0.269  loss_rpn_cls: 0.007  loss_rpn_loc: 0.049  time: 1.0295  data_time: 0.0077  lr: 0.002697  max_mem: 5397M
[32m[04/28 15:43:20 d2.utils.events]: [0m eta: 0:07:37  iter: 559  total_loss: 0.502  loss_cls: 0.149  loss_box_reg: 0.290  loss_rpn_cls: 0.008  loss_rpn_loc: 0.045  time: 1.0299  data_time: 0.0077  lr: 0.002797  max_mem: 5397M
[32m[04/28 15:43:40 d2.utils.events]: [0m eta: 0:07:16  iter: 579  total_loss: 0.528  loss_cls: 0.154  loss_box_reg: 0.314  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0299  data_time: 0.0076  lr: 0.002897  max_mem: 5397M
[32m[04/28 15:44:01 d2.utils.events]: [0m eta: 0:06:56  iter: 599  total_loss: 0.509  loss_cls: 0.156  loss_box_reg: 0.286  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0301  data_time: 0.0077  lr: 0.002997  max_mem: 5397M
[32m[04/28 15:44:21 d2.utils.events]: [0m eta: 0:06:34  iter: 619  total_loss: 0.520  loss_cls: 0.154  loss_box_reg: 0.295  loss_rpn_cls: 0.007  loss_rpn_loc: 0.051  time: 1.0287  data_time: 0.0076  lr: 0.003097  max_mem: 5397M
[32m[04/28 15:44:42 d2.utils.events]: [0m eta: 0:06:13  iter: 639  total_loss: 0.483  loss_cls: 0.153  loss_box_reg: 0.285  loss_rpn_cls: 0.003  loss_rpn_loc: 0.039  time: 1.0291  data_time: 0.0076  lr: 0.003197  max_mem: 5397M
[32m[04/28 15:45:02 d2.utils.events]: [0m eta: 0:05:52  iter: 659  total_loss: 0.417  loss_cls: 0.128  loss_box_reg: 0.246  loss_rpn_cls: 0.006  loss_rpn_loc: 0.033  time: 1.0290  data_time: 0.0075  lr: 0.003297  max_mem: 5397M
[32m[04/28 15:45:23 d2.utils.events]: [0m eta: 0:05:32  iter: 679  total_loss: 0.557  loss_cls: 0.162  loss_box_reg: 0.318  loss_rpn_cls: 0.006  loss_rpn_loc: 0.053  time: 1.0282  data_time: 0.0073  lr: 0.003397  max_mem: 5397M
[32m[04/28 15:45:43 d2.utils.events]: [0m eta: 0:05:11  iter: 699  total_loss: 0.509  loss_cls: 0.159  loss_box_reg: 0.292  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 1.0276  data_time: 0.0076  lr: 0.003497  max_mem: 5397M
[32m[04/28 15:46:03 d2.utils.events]: [0m eta: 0:04:50  iter: 719  total_loss: 0.503  loss_cls: 0.145  loss_box_reg: 0.301  loss_rpn_cls: 0.005  loss_rpn_loc: 0.057  time: 1.0271  data_time: 0.0077  lr: 0.003596  max_mem: 5397M
[32m[04/28 15:46:23 d2.utils.events]: [0m eta: 0:04:29  iter: 739  total_loss: 0.511  loss_cls: 0.143  loss_box_reg: 0.299  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 1.0264  data_time: 0.0079  lr: 0.003696  max_mem: 5397M
[32m[04/28 15:46:44 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.459  loss_cls: 0.140  loss_box_reg: 0.265  loss_rpn_cls: 0.003  loss_rpn_loc: 0.039  time: 1.0271  data_time: 0.0078  lr: 0.003796  max_mem: 5397M
[32m[04/28 15:47:04 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.498  loss_cls: 0.149  loss_box_reg: 0.276  loss_rpn_cls: 0.007  loss_rpn_loc: 0.055  time: 1.0264  data_time: 0.0076  lr: 0.003896  max_mem: 5397M
[32m[04/28 15:47:25 d2.utils.events]: [0m eta: 0:03:27  iter: 799  total_loss: 0.529  loss_cls: 0.148  loss_box_reg: 0.317  loss_rpn_cls: 0.008  loss_rpn_loc: 0.049  time: 1.0265  data_time: 0.0076  lr: 0.003996  max_mem: 5397M
[32m[04/28 15:47:45 d2.utils.events]: [0m eta: 0:03:06  iter: 819  total_loss: 0.459  loss_cls: 0.145  loss_box_reg: 0.267  loss_rpn_cls: 0.006  loss_rpn_loc: 0.049  time: 1.0262  data_time: 0.0076  lr: 0.004096  max_mem: 5397M
[32m[04/28 15:48:06 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.573  loss_cls: 0.169  loss_box_reg: 0.339  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0264  data_time: 0.0077  lr: 0.004196  max_mem: 5397M
[32m[04/28 15:48:26 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.537  loss_cls: 0.165  loss_box_reg: 0.296  loss_rpn_cls: 0.007  loss_rpn_loc: 0.058  time: 1.0263  data_time: 0.0074  lr: 0.004296  max_mem: 5397M
[32m[04/28 15:48:47 d2.utils.events]: [0m eta: 0:02:04  iter: 879  total_loss: 0.526  loss_cls: 0.172  loss_box_reg: 0.305  loss_rpn_cls: 0.005  loss_rpn_loc: 0.048  time: 1.0265  data_time: 0.0076  lr: 0.004396  max_mem: 5397M
[32m[04/28 15:49:08 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.528  loss_cls: 0.160  loss_box_reg: 0.314  loss_rpn_cls: 0.004  loss_rpn_loc: 0.044  time: 1.0265  data_time: 0.0076  lr: 0.004496  max_mem: 5397M
[32m[04/28 15:49:28 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.397  loss_cls: 0.119  loss_box_reg: 0.246  loss_rpn_cls: 0.004  loss_rpn_loc: 0.036  time: 1.0262  data_time: 0.0077  lr: 0.004595  max_mem: 5397M
[32m[04/28 15:49:49 d2.utils.events]: [0m eta: 0:01:02  iter: 939  total_loss: 0.531  loss_cls: 0.171  loss_box_reg: 0.296  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 1.0263  data_time: 0.0076  lr: 0.004695  max_mem: 5397M
[32m[04/28 15:50:10 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.511  loss_cls: 0.171  loss_box_reg: 0.285  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 1.0269  data_time: 0.0077  lr: 0.004795  max_mem: 5397M
[32m[04/28 15:50:30 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.469  loss_cls: 0.143  loss_box_reg: 0.272  loss_rpn_cls: 0.005  loss_rpn_loc: 0.048  time: 1.0269  data_time: 0.0076  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 15:50:54 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 15:50:54 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 15:50:54 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 15:50:54 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.591  loss_cls: 0.181  loss_box_reg: 0.328  loss_rpn_cls: 0.008  loss_rpn_loc: 0.054  time: 1.0276  data_time: 0.0076  lr: 0.004995  max_mem: 5397M
[32m[04/28 15:50:55 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:05 (1.0286 s / it)
[32m[04/28 15:50:55 d2.engine.hooks]: [0mTotal training time: 0:17:11 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 15:50:56 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 15:50:56 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 15:50:56 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 15:50:58 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1141 s / img. ETA=0:16:03
[32m[04/28 15:51:03 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1144 s / img. ETA=0:16:03
[32m[04/28 15:51:08 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1143 s / img. ETA=0:15:56
[32m[04/28 15:51:13 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1142 s / img. ETA=0:15:51
[32m[04/28 15:51:18 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1142 s / img. ETA=0:15:45
[32m[04/28 15:51:23 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1142 s / img. ETA=0:15:41
[32m[04/28 15:51:28 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1142 s / img. ETA=0:15:36
[32m[04/28 15:51:33 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1142 s / img. ETA=0:15:31
[32m[04/28 15:51:38 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1143 s / img. ETA=0:15:26
[32m[04/28 15:51:43 d2.evaluation.evaluator]: [0mInference done 406/8355. 0.1143 s / img. ETA=0:15:22
[32m[04/28 15:51:48 d2.evaluation.evaluator]: [0mInference done 449/8355. 0.1144 s / img. ETA=0:15:17
[32m[04/28 15:51:54 d2.evaluation.evaluator]: [0mInference done 493/8355. 0.1143 s / img. ETA=0:15:12
[32m[04/28 15:51:59 d2.evaluation.evaluator]: [0mInference done 537/8355. 0.1143 s / img. ETA=0:15:06
[32m[04/28 15:52:04 d2.evaluation.evaluator]: [0mInference done 581/8355. 0.1143 s / img. ETA=0:15:01
[32m[04/28 15:52:09 d2.evaluation.evaluator]: [0mInference done 625/8355. 0.1143 s / img. ETA=0:14:56
[32m[04/28 15:52:14 d2.evaluation.evaluator]: [0mInference done 669/8355. 0.1143 s / img. ETA=0:14:51
[32m[04/28 15:52:19 d2.evaluation.evaluator]: [0mInference done 713/8355. 0.1143 s / img. ETA=0:14:46
[32m[04/28 15:52:24 d2.evaluation.evaluator]: [0mInference done 756/8355. 0.1143 s / img. ETA=0:14:41
[32m[04/28 15:52:29 d2.evaluation.evaluator]: [0mInference done 799/8355. 0.1144 s / img. ETA=0:14:37
[32m[04/28 15:52:34 d2.evaluation.evaluator]: [0mInference done 843/8355. 0.1144 s / img. ETA=0:14:31
[32m[04/28 15:52:39 d2.evaluation.evaluator]: [0mInference done 886/8355. 0.1144 s / img. ETA=0:14:27
[32m[04/28 15:52:44 d2.evaluation.evaluator]: [0mInference done 929/8355. 0.1144 s / img. ETA=0:14:22
[32m[04/28 15:52:49 d2.evaluation.evaluator]: [0mInference done 972/8355. 0.1145 s / img. ETA=0:14:17
[32m[04/28 15:52:54 d2.evaluation.evaluator]: [0mInference done 1015/8355. 0.1145 s / img. ETA=0:14:12
[32m[04/28 15:52:59 d2.evaluation.evaluator]: [0mInference done 1059/8355. 0.1145 s / img. ETA=0:14:07
[32m[04/28 15:53:04 d2.evaluation.evaluator]: [0mInference done 1103/8355. 0.1145 s / img. ETA=0:14:02
[32m[04/28 15:53:09 d2.evaluation.evaluator]: [0mInference done 1146/8355. 0.1145 s / img. ETA=0:13:57
[32m[04/28 15:53:15 d2.evaluation.evaluator]: [0mInference done 1190/8355. 0.1145 s / img. ETA=0:13:52
[32m[04/28 15:53:20 d2.evaluation.evaluator]: [0mInference done 1234/8355. 0.1144 s / img. ETA=0:13:47
[32m[04/28 15:53:25 d2.evaluation.evaluator]: [0mInference done 1277/8355. 0.1145 s / img. ETA=0:13:42
[32m[04/28 15:53:30 d2.evaluation.evaluator]: [0mInference done 1321/8355. 0.1145 s / img. ETA=0:13:37
[32m[04/28 15:53:35 d2.evaluation.evaluator]: [0mInference done 1365/8355. 0.1145 s / img. ETA=0:13:32
[32m[04/28 15:53:40 d2.evaluation.evaluator]: [0mInference done 1408/8355. 0.1145 s / img. ETA=0:13:27
[32m[04/28 15:53:45 d2.evaluation.evaluator]: [0mInference done 1452/8355. 0.1144 s / img. ETA=0:13:21
[32m[04/28 15:53:50 d2.evaluation.evaluator]: [0mInference done 1495/8355. 0.1145 s / img. ETA=0:13:17
[32m[04/28 15:53:55 d2.evaluation.evaluator]: [0mInference done 1538/8355. 0.1145 s / img. ETA=0:13:12
[32m[04/28 15:54:00 d2.evaluation.evaluator]: [0mInference done 1581/8355. 0.1146 s / img. ETA=0:13:07
[32m[04/28 15:54:05 d2.evaluation.evaluator]: [0mInference done 1624/8355. 0.1146 s / img. ETA=0:13:03
[32m[04/28 15:54:10 d2.evaluation.evaluator]: [0mInference done 1667/8355. 0.1146 s / img. ETA=0:12:58
[32m[04/28 15:54:15 d2.evaluation.evaluator]: [0mInference done 1710/8355. 0.1147 s / img. ETA=0:12:53
[32m[04/28 15:54:20 d2.evaluation.evaluator]: [0mInference done 1753/8355. 0.1147 s / img. ETA=0:12:48
[32m[04/28 15:54:26 d2.evaluation.evaluator]: [0mInference done 1796/8355. 0.1147 s / img. ETA=0:12:43
[32m[04/28 15:54:31 d2.evaluation.evaluator]: [0mInference done 1839/8355. 0.1148 s / img. ETA=0:12:39
[32m[04/28 15:54:36 d2.evaluation.evaluator]: [0mInference done 1882/8355. 0.1148 s / img. ETA=0:12:34
[32m[04/28 15:54:41 d2.evaluation.evaluator]: [0mInference done 1925/8355. 0.1148 s / img. ETA=0:12:29
[32m[04/28 15:54:46 d2.evaluation.evaluator]: [0mInference done 1968/8355. 0.1148 s / img. ETA=0:12:24
[32m[04/28 15:54:51 d2.evaluation.evaluator]: [0mInference done 2011/8355. 0.1148 s / img. ETA=0:12:19
[32m[04/28 15:54:56 d2.evaluation.evaluator]: [0mInference done 2054/8355. 0.1148 s / img. ETA=0:12:14
[32m[04/28 15:55:01 d2.evaluation.evaluator]: [0mInference done 2097/8355. 0.1148 s / img. ETA=0:12:09
[32m[04/28 15:55:06 d2.evaluation.evaluator]: [0mInference done 2138/8355. 0.1150 s / img. ETA=0:12:05
[32m[04/28 15:55:11 d2.evaluation.evaluator]: [0mInference done 2181/8355. 0.1150 s / img. ETA=0:12:00
[32m[04/28 15:55:16 d2.evaluation.evaluator]: [0mInference done 2224/8355. 0.1150 s / img. ETA=0:11:55
[32m[04/28 15:55:21 d2.evaluation.evaluator]: [0mInference done 2267/8355. 0.1150 s / img. ETA=0:11:50
[32m[04/28 15:55:26 d2.evaluation.evaluator]: [0mInference done 2309/8355. 0.1150 s / img. ETA=0:11:46
[32m[04/28 15:55:31 d2.evaluation.evaluator]: [0mInference done 2352/8355. 0.1150 s / img. ETA=0:11:41
[32m[04/28 15:55:36 d2.evaluation.evaluator]: [0mInference done 2395/8355. 0.1150 s / img. ETA=0:11:36
[32m[04/28 15:55:41 d2.evaluation.evaluator]: [0mInference done 2438/8355. 0.1151 s / img. ETA=0:11:31
[32m[04/28 15:55:46 d2.evaluation.evaluator]: [0mInference done 2481/8355. 0.1151 s / img. ETA=0:11:26
[32m[04/28 15:55:51 d2.evaluation.evaluator]: [0mInference done 2524/8355. 0.1151 s / img. ETA=0:11:21
[32m[04/28 15:55:56 d2.evaluation.evaluator]: [0mInference done 2567/8355. 0.1151 s / img. ETA=0:11:16
[32m[04/28 15:56:01 d2.evaluation.evaluator]: [0mInference done 2610/8355. 0.1151 s / img. ETA=0:11:11
[32m[04/28 15:56:06 d2.evaluation.evaluator]: [0mInference done 2653/8355. 0.1151 s / img. ETA=0:11:06
[32m[04/28 15:56:12 d2.evaluation.evaluator]: [0mInference done 2696/8355. 0.1151 s / img. ETA=0:11:01
[32m[04/28 15:56:17 d2.evaluation.evaluator]: [0mInference done 2739/8355. 0.1151 s / img. ETA=0:10:56
[32m[04/28 15:56:22 d2.evaluation.evaluator]: [0mInference done 2781/8355. 0.1152 s / img. ETA=0:10:51
[32m[04/28 15:56:27 d2.evaluation.evaluator]: [0mInference done 2824/8355. 0.1152 s / img. ETA=0:10:46
[32m[04/28 15:56:32 d2.evaluation.evaluator]: [0mInference done 2867/8355. 0.1152 s / img. ETA=0:10:41
[32m[04/28 15:56:37 d2.evaluation.evaluator]: [0mInference done 2910/8355. 0.1152 s / img. ETA=0:10:36
[32m[04/28 15:56:42 d2.evaluation.evaluator]: [0mInference done 2953/8355. 0.1152 s / img. ETA=0:10:31
[32m[04/28 15:56:47 d2.evaluation.evaluator]: [0mInference done 2996/8355. 0.1152 s / img. ETA=0:10:26
[32m[04/28 15:56:52 d2.evaluation.evaluator]: [0mInference done 3039/8355. 0.1152 s / img. ETA=0:10:21
[32m[04/28 15:56:57 d2.evaluation.evaluator]: [0mInference done 3082/8355. 0.1152 s / img. ETA=0:10:16
[32m[04/28 15:57:02 d2.evaluation.evaluator]: [0mInference done 3125/8355. 0.1152 s / img. ETA=0:10:11
[32m[04/28 15:57:07 d2.evaluation.evaluator]: [0mInference done 3169/8355. 0.1152 s / img. ETA=0:10:06
[32m[04/28 15:57:12 d2.evaluation.evaluator]: [0mInference done 3213/8355. 0.1152 s / img. ETA=0:10:01
[32m[04/28 15:57:17 d2.evaluation.evaluator]: [0mInference done 3256/8355. 0.1152 s / img. ETA=0:09:56
[32m[04/28 15:57:22 d2.evaluation.evaluator]: [0mInference done 3300/8355. 0.1152 s / img. ETA=0:09:51
[32m[04/28 15:57:27 d2.evaluation.evaluator]: [0mInference done 3343/8355. 0.1152 s / img. ETA=0:09:46
[32m[04/28 15:57:32 d2.evaluation.evaluator]: [0mInference done 3386/8355. 0.1152 s / img. ETA=0:09:41
[32m[04/28 15:57:37 d2.evaluation.evaluator]: [0mInference done 3429/8355. 0.1151 s / img. ETA=0:09:36
[32m[04/28 15:57:42 d2.evaluation.evaluator]: [0mInference done 3472/8355. 0.1151 s / img. ETA=0:09:31
[32m[04/28 15:57:47 d2.evaluation.evaluator]: [0mInference done 3515/8355. 0.1151 s / img. ETA=0:09:25
[32m[04/28 15:57:52 d2.evaluation.evaluator]: [0mInference done 3558/8355. 0.1151 s / img. ETA=0:09:20
[32m[04/28 15:57:58 d2.evaluation.evaluator]: [0mInference done 3601/8355. 0.1152 s / img. ETA=0:09:16
[32m[04/28 15:58:03 d2.evaluation.evaluator]: [0mInference done 3644/8355. 0.1152 s / img. ETA=0:09:10
[32m[04/28 15:58:08 d2.evaluation.evaluator]: [0mInference done 3687/8355. 0.1152 s / img. ETA=0:09:05
[32m[04/28 15:58:13 d2.evaluation.evaluator]: [0mInference done 3730/8355. 0.1151 s / img. ETA=0:09:00
[32m[04/28 15:58:18 d2.evaluation.evaluator]: [0mInference done 3773/8355. 0.1151 s / img. ETA=0:08:55
[32m[04/28 15:58:23 d2.evaluation.evaluator]: [0mInference done 3816/8355. 0.1152 s / img. ETA=0:08:50
[32m[04/28 15:58:28 d2.evaluation.evaluator]: [0mInference done 3859/8355. 0.1152 s / img. ETA=0:08:45
[32m[04/28 15:58:33 d2.evaluation.evaluator]: [0mInference done 3903/8355. 0.1151 s / img. ETA=0:08:40
[32m[04/28 15:58:38 d2.evaluation.evaluator]: [0mInference done 3946/8355. 0.1151 s / img. ETA=0:08:35
[32m[04/28 15:58:43 d2.evaluation.evaluator]: [0mInference done 3989/8355. 0.1151 s / img. ETA=0:08:30
[32m[04/28 15:58:48 d2.evaluation.evaluator]: [0mInference done 4032/8355. 0.1152 s / img. ETA=0:08:25
[32m[04/28 15:58:53 d2.evaluation.evaluator]: [0mInference done 4075/8355. 0.1152 s / img. ETA=0:08:20
[32m[04/28 15:58:58 d2.evaluation.evaluator]: [0mInference done 4118/8355. 0.1152 s / img. ETA=0:08:15
[32m[04/28 15:59:03 d2.evaluation.evaluator]: [0mInference done 4161/8355. 0.1152 s / img. ETA=0:08:10
[32m[04/28 15:59:08 d2.evaluation.evaluator]: [0mInference done 4204/8355. 0.1152 s / img. ETA=0:08:05
[32m[04/28 15:59:13 d2.evaluation.evaluator]: [0mInference done 4248/8355. 0.1152 s / img. ETA=0:08:00
[32m[04/28 15:59:18 d2.evaluation.evaluator]: [0mInference done 4291/8355. 0.1152 s / img. ETA=0:07:55
[32m[04/28 15:59:23 d2.evaluation.evaluator]: [0mInference done 4334/8355. 0.1152 s / img. ETA=0:07:50
[32m[04/28 15:59:28 d2.evaluation.evaluator]: [0mInference done 4377/8355. 0.1152 s / img. ETA=0:07:45
[32m[04/28 15:59:33 d2.evaluation.evaluator]: [0mInference done 4420/8355. 0.1152 s / img. ETA=0:07:40
[32m[04/28 15:59:38 d2.evaluation.evaluator]: [0mInference done 4463/8355. 0.1152 s / img. ETA=0:07:35
[32m[04/28 15:59:43 d2.evaluation.evaluator]: [0mInference done 4506/8355. 0.1152 s / img. ETA=0:07:30
[32m[04/28 15:59:48 d2.evaluation.evaluator]: [0mInference done 4549/8355. 0.1152 s / img. ETA=0:07:25
[32m[04/28 15:59:53 d2.evaluation.evaluator]: [0mInference done 4592/8355. 0.1152 s / img. ETA=0:07:20
[32m[04/28 15:59:59 d2.evaluation.evaluator]: [0mInference done 4635/8355. 0.1152 s / img. ETA=0:07:15
[32m[04/28 16:00:04 d2.evaluation.evaluator]: [0mInference done 4678/8355. 0.1152 s / img. ETA=0:07:10
[32m[04/28 16:00:09 d2.evaluation.evaluator]: [0mInference done 4721/8355. 0.1152 s / img. ETA=0:07:05
[32m[04/28 16:00:14 d2.evaluation.evaluator]: [0mInference done 4764/8355. 0.1152 s / img. ETA=0:07:00
[32m[04/28 16:00:19 d2.evaluation.evaluator]: [0mInference done 4807/8355. 0.1152 s / img. ETA=0:06:55
[32m[04/28 16:00:24 d2.evaluation.evaluator]: [0mInference done 4850/8355. 0.1152 s / img. ETA=0:06:50
[32m[04/28 16:00:29 d2.evaluation.evaluator]: [0mInference done 4893/8355. 0.1152 s / img. ETA=0:06:45
[32m[04/28 16:00:34 d2.evaluation.evaluator]: [0mInference done 4936/8355. 0.1152 s / img. ETA=0:06:39
[32m[04/28 16:00:39 d2.evaluation.evaluator]: [0mInference done 4979/8355. 0.1152 s / img. ETA=0:06:34
[32m[04/28 16:00:44 d2.evaluation.evaluator]: [0mInference done 5022/8355. 0.1152 s / img. ETA=0:06:29
[32m[04/28 16:00:49 d2.evaluation.evaluator]: [0mInference done 5065/8355. 0.1152 s / img. ETA=0:06:24
[32m[04/28 16:00:54 d2.evaluation.evaluator]: [0mInference done 5108/8355. 0.1152 s / img. ETA=0:06:19
[32m[04/28 16:00:59 d2.evaluation.evaluator]: [0mInference done 5151/8355. 0.1152 s / img. ETA=0:06:14
[32m[04/28 16:01:04 d2.evaluation.evaluator]: [0mInference done 5194/8355. 0.1152 s / img. ETA=0:06:09
[32m[04/28 16:01:09 d2.evaluation.evaluator]: [0mInference done 5237/8355. 0.1152 s / img. ETA=0:06:04
[32m[04/28 16:01:14 d2.evaluation.evaluator]: [0mInference done 5280/8355. 0.1152 s / img. ETA=0:05:59
[32m[04/28 16:01:19 d2.evaluation.evaluator]: [0mInference done 5323/8355. 0.1152 s / img. ETA=0:05:54
[32m[04/28 16:01:24 d2.evaluation.evaluator]: [0mInference done 5366/8355. 0.1152 s / img. ETA=0:05:49
[32m[04/28 16:01:29 d2.evaluation.evaluator]: [0mInference done 5409/8355. 0.1152 s / img. ETA=0:05:44
[32m[04/28 16:01:34 d2.evaluation.evaluator]: [0mInference done 5452/8355. 0.1152 s / img. ETA=0:05:39
[32m[04/28 16:01:39 d2.evaluation.evaluator]: [0mInference done 5495/8355. 0.1152 s / img. ETA=0:05:34
[32m[04/28 16:01:44 d2.evaluation.evaluator]: [0mInference done 5538/8355. 0.1152 s / img. ETA=0:05:29
[32m[04/28 16:01:49 d2.evaluation.evaluator]: [0mInference done 5582/8355. 0.1152 s / img. ETA=0:05:24
[32m[04/28 16:01:55 d2.evaluation.evaluator]: [0mInference done 5625/8355. 0.1152 s / img. ETA=0:05:19
[32m[04/28 16:02:00 d2.evaluation.evaluator]: [0mInference done 5668/8355. 0.1152 s / img. ETA=0:05:14
[32m[04/28 16:02:05 d2.evaluation.evaluator]: [0mInference done 5711/8355. 0.1152 s / img. ETA=0:05:09
[32m[04/28 16:02:10 d2.evaluation.evaluator]: [0mInference done 5754/8355. 0.1152 s / img. ETA=0:05:04
[32m[04/28 16:02:15 d2.evaluation.evaluator]: [0mInference done 5797/8355. 0.1152 s / img. ETA=0:04:59
[32m[04/28 16:02:20 d2.evaluation.evaluator]: [0mInference done 5839/8355. 0.1152 s / img. ETA=0:04:54
[32m[04/28 16:02:25 d2.evaluation.evaluator]: [0mInference done 5882/8355. 0.1152 s / img. ETA=0:04:49
[32m[04/28 16:02:30 d2.evaluation.evaluator]: [0mInference done 5925/8355. 0.1152 s / img. ETA=0:04:44
[32m[04/28 16:02:35 d2.evaluation.evaluator]: [0mInference done 5968/8355. 0.1152 s / img. ETA=0:04:39
[32m[04/28 16:02:40 d2.evaluation.evaluator]: [0mInference done 6011/8355. 0.1152 s / img. ETA=0:04:34
[32m[04/28 16:02:45 d2.evaluation.evaluator]: [0mInference done 6054/8355. 0.1153 s / img. ETA=0:04:29
[32m[04/28 16:02:50 d2.evaluation.evaluator]: [0mInference done 6097/8355. 0.1153 s / img. ETA=0:04:24
[32m[04/28 16:02:55 d2.evaluation.evaluator]: [0mInference done 6140/8355. 0.1153 s / img. ETA=0:04:19
[32m[04/28 16:03:00 d2.evaluation.evaluator]: [0mInference done 6183/8355. 0.1153 s / img. ETA=0:04:14
[32m[04/28 16:03:05 d2.evaluation.evaluator]: [0mInference done 6226/8355. 0.1153 s / img. ETA=0:04:09
[32m[04/28 16:03:11 d2.evaluation.evaluator]: [0mInference done 6269/8355. 0.1153 s / img. ETA=0:04:04
[32m[04/28 16:03:16 d2.evaluation.evaluator]: [0mInference done 6311/8355. 0.1153 s / img. ETA=0:03:59
[32m[04/28 16:03:21 d2.evaluation.evaluator]: [0mInference done 6354/8355. 0.1153 s / img. ETA=0:03:54
[32m[04/28 16:03:26 d2.evaluation.evaluator]: [0mInference done 6397/8355. 0.1153 s / img. ETA=0:03:49
[32m[04/28 16:03:31 d2.evaluation.evaluator]: [0mInference done 6440/8355. 0.1153 s / img. ETA=0:03:44
[32m[04/28 16:03:36 d2.evaluation.evaluator]: [0mInference done 6483/8355. 0.1153 s / img. ETA=0:03:39
[32m[04/28 16:03:41 d2.evaluation.evaluator]: [0mInference done 6526/8355. 0.1153 s / img. ETA=0:03:34
[32m[04/28 16:03:46 d2.evaluation.evaluator]: [0mInference done 6569/8355. 0.1153 s / img. ETA=0:03:29
[32m[04/28 16:03:51 d2.evaluation.evaluator]: [0mInference done 6612/8355. 0.1153 s / img. ETA=0:03:24
[32m[04/28 16:03:56 d2.evaluation.evaluator]: [0mInference done 6655/8355. 0.1153 s / img. ETA=0:03:19
[32m[04/28 16:04:01 d2.evaluation.evaluator]: [0mInference done 6698/8355. 0.1153 s / img. ETA=0:03:14
[32m[04/28 16:04:06 d2.evaluation.evaluator]: [0mInference done 6742/8355. 0.1153 s / img. ETA=0:03:08
[32m[04/28 16:04:11 d2.evaluation.evaluator]: [0mInference done 6786/8355. 0.1153 s / img. ETA=0:03:03
[32m[04/28 16:04:16 d2.evaluation.evaluator]: [0mInference done 6829/8355. 0.1153 s / img. ETA=0:02:58
[32m[04/28 16:04:21 d2.evaluation.evaluator]: [0mInference done 6872/8355. 0.1153 s / img. ETA=0:02:53
[32m[04/28 16:04:26 d2.evaluation.evaluator]: [0mInference done 6915/8355. 0.1153 s / img. ETA=0:02:48
[32m[04/28 16:04:31 d2.evaluation.evaluator]: [0mInference done 6958/8355. 0.1153 s / img. ETA=0:02:43
[32m[04/28 16:04:36 d2.evaluation.evaluator]: [0mInference done 7001/8355. 0.1153 s / img. ETA=0:02:38
[32m[04/28 16:04:41 d2.evaluation.evaluator]: [0mInference done 7044/8355. 0.1153 s / img. ETA=0:02:33
[32m[04/28 16:04:46 d2.evaluation.evaluator]: [0mInference done 7087/8355. 0.1153 s / img. ETA=0:02:28
[32m[04/28 16:04:51 d2.evaluation.evaluator]: [0mInference done 7130/8355. 0.1153 s / img. ETA=0:02:23
[32m[04/28 16:04:56 d2.evaluation.evaluator]: [0mInference done 7173/8355. 0.1153 s / img. ETA=0:02:18
[32m[04/28 16:05:02 d2.evaluation.evaluator]: [0mInference done 7216/8355. 0.1153 s / img. ETA=0:02:13
[32m[04/28 16:05:07 d2.evaluation.evaluator]: [0mInference done 7258/8355. 0.1153 s / img. ETA=0:02:08
[32m[04/28 16:05:12 d2.evaluation.evaluator]: [0mInference done 7301/8355. 0.1153 s / img. ETA=0:02:03
[32m[04/28 16:05:17 d2.evaluation.evaluator]: [0mInference done 7344/8355. 0.1153 s / img. ETA=0:01:58
[32m[04/28 16:05:22 d2.evaluation.evaluator]: [0mInference done 7387/8355. 0.1153 s / img. ETA=0:01:53
[32m[04/28 16:05:27 d2.evaluation.evaluator]: [0mInference done 7430/8355. 0.1153 s / img. ETA=0:01:48
[32m[04/28 16:05:32 d2.evaluation.evaluator]: [0mInference done 7473/8355. 0.1153 s / img. ETA=0:01:43
[32m[04/28 16:05:37 d2.evaluation.evaluator]: [0mInference done 7516/8355. 0.1153 s / img. ETA=0:01:38
[32m[04/28 16:05:42 d2.evaluation.evaluator]: [0mInference done 7559/8355. 0.1153 s / img. ETA=0:01:33
[32m[04/28 16:05:47 d2.evaluation.evaluator]: [0mInference done 7602/8355. 0.1153 s / img. ETA=0:01:28
[32m[04/28 16:05:52 d2.evaluation.evaluator]: [0mInference done 7645/8355. 0.1153 s / img. ETA=0:01:23
[32m[04/28 16:05:57 d2.evaluation.evaluator]: [0mInference done 7688/8355. 0.1153 s / img. ETA=0:01:18
[32m[04/28 16:06:02 d2.evaluation.evaluator]: [0mInference done 7730/8355. 0.1154 s / img. ETA=0:01:13
[32m[04/28 16:06:07 d2.evaluation.evaluator]: [0mInference done 7773/8355. 0.1154 s / img. ETA=0:01:08
[32m[04/28 16:06:12 d2.evaluation.evaluator]: [0mInference done 7816/8355. 0.1154 s / img. ETA=0:01:03
[32m[04/28 16:06:17 d2.evaluation.evaluator]: [0mInference done 7859/8355. 0.1154 s / img. ETA=0:00:58
[32m[04/28 16:06:22 d2.evaluation.evaluator]: [0mInference done 7902/8355. 0.1154 s / img. ETA=0:00:53
[32m[04/28 16:06:28 d2.evaluation.evaluator]: [0mInference done 7945/8355. 0.1154 s / img. ETA=0:00:48
[32m[04/28 16:06:33 d2.evaluation.evaluator]: [0mInference done 7988/8355. 0.1154 s / img. ETA=0:00:43
[32m[04/28 16:06:38 d2.evaluation.evaluator]: [0mInference done 8031/8355. 0.1154 s / img. ETA=0:00:37
[32m[04/28 16:06:43 d2.evaluation.evaluator]: [0mInference done 8074/8355. 0.1154 s / img. ETA=0:00:32
[32m[04/28 16:06:48 d2.evaluation.evaluator]: [0mInference done 8118/8355. 0.1154 s / img. ETA=0:00:27
[32m[04/28 16:06:53 d2.evaluation.evaluator]: [0mInference done 8162/8355. 0.1154 s / img. ETA=0:00:22
[32m[04/28 16:06:58 d2.evaluation.evaluator]: [0mInference done 8205/8355. 0.1154 s / img. ETA=0:00:17
[32m[04/28 16:07:03 d2.evaluation.evaluator]: [0mInference done 8248/8355. 0.1154 s / img. ETA=0:00:12
[32m[04/28 16:07:08 d2.evaluation.evaluator]: [0mInference done 8291/8355. 0.1154 s / img. ETA=0:00:07
[32m[04/28 16:07:13 d2.evaluation.evaluator]: [0mInference done 8334/8355. 0.1154 s / img. ETA=0:00:02
[32m[04/28 16:07:15 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:18.565416 (0.117193 s / img per device, on 1 devices)
[32m[04/28 16:07:15 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:03 (0.115359 s / img per device, on 1 devices)
[32m[04/28 16:07:16 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 16:07:16 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 16:07:16 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.23s).
Accumulating evaluation results...
DONE (t=2.20s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.872
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.518
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.401
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.627
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.756
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.191
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.550
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.569
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.482
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.687
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.797
[32m[04/28 16:07:39 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.582 | 87.189 | 51.786 | 40.081 | 62.711 | 75.626 |
[32m[04/28 16:07:39 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 48.913 | bicycle       | 43.105 | car            | 59.727 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 16:07:39 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 16:07:39 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 16:07:39 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 16:07:40 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1152 s / img. ETA=0:02:25
[32m[04/28 16:07:45 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1148 s / img. ETA=0:02:20
[32m[04/28 16:07:51 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1149 s / img. ETA=0:02:15
[32m[04/28 16:07:56 d2.evaluation.evaluator]: [0mInference done 139/1257. 0.1160 s / img. ETA=0:02:11
[32m[04/28 16:08:01 d2.evaluation.evaluator]: [0mInference done 182/1257. 0.1158 s / img. ETA=0:02:06
[32m[04/28 16:08:06 d2.evaluation.evaluator]: [0mInference done 225/1257. 0.1156 s / img. ETA=0:02:01
[32m[04/28 16:08:11 d2.evaluation.evaluator]: [0mInference done 268/1257. 0.1156 s / img. ETA=0:01:56
[32m[04/28 16:08:16 d2.evaluation.evaluator]: [0mInference done 311/1257. 0.1155 s / img. ETA=0:01:51
[32m[04/28 16:08:21 d2.evaluation.evaluator]: [0mInference done 354/1257. 0.1154 s / img. ETA=0:01:45
[32m[04/28 16:08:26 d2.evaluation.evaluator]: [0mInference done 397/1257. 0.1154 s / img. ETA=0:01:40
[32m[04/28 16:08:31 d2.evaluation.evaluator]: [0mInference done 440/1257. 0.1153 s / img. ETA=0:01:35
[32m[04/28 16:08:36 d2.evaluation.evaluator]: [0mInference done 483/1257. 0.1153 s / img. ETA=0:01:30
[32m[04/28 16:08:41 d2.evaluation.evaluator]: [0mInference done 526/1257. 0.1153 s / img. ETA=0:01:25
[32m[04/28 16:08:46 d2.evaluation.evaluator]: [0mInference done 569/1257. 0.1153 s / img. ETA=0:01:20
[32m[04/28 16:08:51 d2.evaluation.evaluator]: [0mInference done 612/1257. 0.1152 s / img. ETA=0:01:15
[32m[04/28 16:08:56 d2.evaluation.evaluator]: [0mInference done 655/1257. 0.1152 s / img. ETA=0:01:10
[32m[04/28 16:09:01 d2.evaluation.evaluator]: [0mInference done 698/1257. 0.1152 s / img. ETA=0:01:05
[32m[04/28 16:09:06 d2.evaluation.evaluator]: [0mInference done 741/1257. 0.1152 s / img. ETA=0:01:00
[32m[04/28 16:09:11 d2.evaluation.evaluator]: [0mInference done 784/1257. 0.1152 s / img. ETA=0:00:55
[32m[04/28 16:09:16 d2.evaluation.evaluator]: [0mInference done 827/1257. 0.1152 s / img. ETA=0:00:50
[32m[04/28 16:09:21 d2.evaluation.evaluator]: [0mInference done 870/1257. 0.1153 s / img. ETA=0:00:45
[32m[04/28 16:09:26 d2.evaluation.evaluator]: [0mInference done 913/1257. 0.1153 s / img. ETA=0:00:40
[32m[04/28 16:09:31 d2.evaluation.evaluator]: [0mInference done 956/1257. 0.1153 s / img. ETA=0:00:35
[32m[04/28 16:09:36 d2.evaluation.evaluator]: [0mInference done 999/1257. 0.1154 s / img. ETA=0:00:30
[32m[04/28 16:09:41 d2.evaluation.evaluator]: [0mInference done 1042/1257. 0.1154 s / img. ETA=0:00:25
[32m[04/28 16:09:46 d2.evaluation.evaluator]: [0mInference done 1085/1257. 0.1154 s / img. ETA=0:00:20
[32m[04/28 16:09:51 d2.evaluation.evaluator]: [0mInference done 1128/1257. 0.1154 s / img. ETA=0:00:15
[32m[04/28 16:09:57 d2.evaluation.evaluator]: [0mInference done 1171/1257. 0.1154 s / img. ETA=0:00:10
[32m[04/28 16:10:02 d2.evaluation.evaluator]: [0mInference done 1214/1257. 0.1154 s / img. ETA=0:00:05
[32m[04/28 16:10:07 d2.evaluation.evaluator]: [0mInference done 1257/1257. 0.1154 s / img. ETA=0:00:00
[32m[04/28 16:10:07 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.873593 (0.117311 s / img per device, on 1 devices)
[32m[04/28 16:10:07 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115408 s / img per device, on 1 devices)
[32m[04/28 16:10:07 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 16:10:07 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 16:10:07 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.06s).
Accumulating evaluation results...
DONE (t=0.37s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.401
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.747
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.375
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.582
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.474
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.408
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.520
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.635
[32m[04/28 16:10:10 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.130 | 74.674 | 37.507 | 30.771 | 45.256 | 58.200 |
[32m[04/28 16:10:10 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 44.715 | bicycle       | 20.126 | car            | 55.550 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  24  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 16:10:11 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 16:10:11 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 16:10:11 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 16:10:12 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 16:10:12 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 16:10:12 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 16:10:12 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 16:10:33 d2.utils.events]: [0m eta: 0:17:19  iter: 19  total_loss: 0.529  loss_cls: 0.163  loss_box_reg: 0.302  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 1.0423  data_time: 0.0224  lr: 0.000100  max_mem: 5397M
[32m[04/28 16:10:54 d2.utils.events]: [0m eta: 0:16:58  iter: 39  total_loss: 0.518  loss_cls: 0.162  loss_box_reg: 0.309  loss_rpn_cls: 0.006  loss_rpn_loc: 0.052  time: 1.0405  data_time: 0.0078  lr: 0.000200  max_mem: 5397M
[32m[04/28 16:11:14 d2.utils.events]: [0m eta: 0:16:29  iter: 59  total_loss: 0.496  loss_cls: 0.153  loss_box_reg: 0.272  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0368  data_time: 0.0076  lr: 0.000300  max_mem: 5397M
[32m[04/28 16:11:35 d2.utils.events]: [0m eta: 0:16:08  iter: 79  total_loss: 0.501  loss_cls: 0.150  loss_box_reg: 0.291  loss_rpn_cls: 0.007  loss_rpn_loc: 0.052  time: 1.0358  data_time: 0.0077  lr: 0.000400  max_mem: 5397M
[32m[04/28 16:11:56 d2.utils.events]: [0m eta: 0:15:47  iter: 99  total_loss: 0.478  loss_cls: 0.140  loss_box_reg: 0.283  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0365  data_time: 0.0077  lr: 0.000500  max_mem: 5397M
[32m[04/28 16:12:16 d2.utils.events]: [0m eta: 0:15:09  iter: 119  total_loss: 0.535  loss_cls: 0.155  loss_box_reg: 0.306  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0335  data_time: 0.0074  lr: 0.000599  max_mem: 5397M
[32m[04/28 16:12:37 d2.utils.events]: [0m eta: 0:14:43  iter: 139  total_loss: 0.424  loss_cls: 0.122  loss_box_reg: 0.263  loss_rpn_cls: 0.005  loss_rpn_loc: 0.037  time: 1.0303  data_time: 0.0076  lr: 0.000699  max_mem: 5397M
[32m[04/28 16:12:58 d2.utils.events]: [0m eta: 0:14:28  iter: 159  total_loss: 0.482  loss_cls: 0.139  loss_box_reg: 0.298  loss_rpn_cls: 0.004  loss_rpn_loc: 0.042  time: 1.0319  data_time: 0.0077  lr: 0.000799  max_mem: 5397M
[32m[04/28 16:13:18 d2.utils.events]: [0m eta: 0:14:14  iter: 179  total_loss: 0.477  loss_cls: 0.132  loss_box_reg: 0.288  loss_rpn_cls: 0.005  loss_rpn_loc: 0.036  time: 1.0322  data_time: 0.0077  lr: 0.000899  max_mem: 5397M
[32m[04/28 16:13:39 d2.utils.events]: [0m eta: 0:13:58  iter: 199  total_loss: 0.447  loss_cls: 0.137  loss_box_reg: 0.282  loss_rpn_cls: 0.005  loss_rpn_loc: 0.037  time: 1.0339  data_time: 0.0077  lr: 0.000999  max_mem: 5397M
[32m[04/28 16:14:00 d2.utils.events]: [0m eta: 0:13:40  iter: 219  total_loss: 0.528  loss_cls: 0.162  loss_box_reg: 0.307  loss_rpn_cls: 0.009  loss_rpn_loc: 0.055  time: 1.0353  data_time: 0.0077  lr: 0.001099  max_mem: 5397M
[32m[04/28 16:14:21 d2.utils.events]: [0m eta: 0:13:19  iter: 239  total_loss: 0.503  loss_cls: 0.158  loss_box_reg: 0.289  loss_rpn_cls: 0.007  loss_rpn_loc: 0.043  time: 1.0364  data_time: 0.0078  lr: 0.001199  max_mem: 5397M
[32m[04/28 16:14:42 d2.utils.events]: [0m eta: 0:12:58  iter: 259  total_loss: 0.488  loss_cls: 0.155  loss_box_reg: 0.289  loss_rpn_cls: 0.004  loss_rpn_loc: 0.038  time: 1.0366  data_time: 0.0077  lr: 0.001299  max_mem: 5397M
[32m[04/28 16:15:03 d2.utils.events]: [0m eta: 0:12:37  iter: 279  total_loss: 0.421  loss_cls: 0.123  loss_box_reg: 0.276  loss_rpn_cls: 0.003  loss_rpn_loc: 0.038  time: 1.0362  data_time: 0.0077  lr: 0.001399  max_mem: 5397M
[32m[04/28 16:15:24 d2.utils.events]: [0m eta: 0:12:16  iter: 299  total_loss: 0.453  loss_cls: 0.135  loss_box_reg: 0.267  loss_rpn_cls: 0.004  loss_rpn_loc: 0.046  time: 1.0366  data_time: 0.0079  lr: 0.001499  max_mem: 5397M
[32m[04/28 16:15:45 d2.utils.events]: [0m eta: 0:11:55  iter: 319  total_loss: 0.486  loss_cls: 0.144  loss_box_reg: 0.287  loss_rpn_cls: 0.005  loss_rpn_loc: 0.053  time: 1.0367  data_time: 0.0079  lr: 0.001598  max_mem: 5397M
[32m[04/28 16:16:05 d2.utils.events]: [0m eta: 0:11:34  iter: 339  total_loss: 0.481  loss_cls: 0.140  loss_box_reg: 0.293  loss_rpn_cls: 0.005  loss_rpn_loc: 0.038  time: 1.0366  data_time: 0.0075  lr: 0.001698  max_mem: 5397M
[32m[04/28 16:16:26 d2.utils.events]: [0m eta: 0:11:13  iter: 359  total_loss: 0.485  loss_cls: 0.145  loss_box_reg: 0.292  loss_rpn_cls: 0.006  loss_rpn_loc: 0.034  time: 1.0353  data_time: 0.0076  lr: 0.001798  max_mem: 5397M
[32m[04/28 16:16:46 d2.utils.events]: [0m eta: 0:10:50  iter: 379  total_loss: 0.485  loss_cls: 0.145  loss_box_reg: 0.274  loss_rpn_cls: 0.007  loss_rpn_loc: 0.043  time: 1.0343  data_time: 0.0075  lr: 0.001898  max_mem: 5397M
[32m[04/28 16:17:07 d2.utils.events]: [0m eta: 0:10:30  iter: 399  total_loss: 0.436  loss_cls: 0.125  loss_box_reg: 0.264  loss_rpn_cls: 0.004  loss_rpn_loc: 0.032  time: 1.0347  data_time: 0.0078  lr: 0.001998  max_mem: 5397M
[32m[04/28 16:17:28 d2.utils.events]: [0m eta: 0:10:09  iter: 419  total_loss: 0.477  loss_cls: 0.141  loss_box_reg: 0.264  loss_rpn_cls: 0.004  loss_rpn_loc: 0.039  time: 1.0353  data_time: 0.0077  lr: 0.002098  max_mem: 5397M
[32m[04/28 16:17:49 d2.utils.events]: [0m eta: 0:09:49  iter: 439  total_loss: 0.527  loss_cls: 0.160  loss_box_reg: 0.300  loss_rpn_cls: 0.007  loss_rpn_loc: 0.060  time: 1.0358  data_time: 0.0078  lr: 0.002198  max_mem: 5397M
[32m[04/28 16:18:09 d2.utils.events]: [0m eta: 0:09:26  iter: 459  total_loss: 0.489  loss_cls: 0.139  loss_box_reg: 0.268  loss_rpn_cls: 0.004  loss_rpn_loc: 0.050  time: 1.0347  data_time: 0.0079  lr: 0.002298  max_mem: 5397M
[32m[04/28 16:18:30 d2.utils.events]: [0m eta: 0:09:06  iter: 479  total_loss: 0.457  loss_cls: 0.138  loss_box_reg: 0.262  loss_rpn_cls: 0.004  loss_rpn_loc: 0.050  time: 1.0351  data_time: 0.0077  lr: 0.002398  max_mem: 5397M
[32m[04/28 16:18:50 d2.utils.events]: [0m eta: 0:08:44  iter: 499  total_loss: 0.492  loss_cls: 0.144  loss_box_reg: 0.282  loss_rpn_cls: 0.004  loss_rpn_loc: 0.049  time: 1.0339  data_time: 0.0079  lr: 0.002498  max_mem: 5397M
[32m[04/28 16:19:11 d2.utils.events]: [0m eta: 0:08:23  iter: 519  total_loss: 0.479  loss_cls: 0.141  loss_box_reg: 0.276  loss_rpn_cls: 0.004  loss_rpn_loc: 0.044  time: 1.0346  data_time: 0.0077  lr: 0.002597  max_mem: 5397M
[32m[04/28 16:19:32 d2.utils.events]: [0m eta: 0:08:03  iter: 539  total_loss: 0.484  loss_cls: 0.148  loss_box_reg: 0.295  loss_rpn_cls: 0.005  loss_rpn_loc: 0.046  time: 1.0353  data_time: 0.0075  lr: 0.002697  max_mem: 5397M
[32m[04/28 16:19:53 d2.utils.events]: [0m eta: 0:07:42  iter: 559  total_loss: 0.498  loss_cls: 0.141  loss_box_reg: 0.293  loss_rpn_cls: 0.005  loss_rpn_loc: 0.052  time: 1.0354  data_time: 0.0077  lr: 0.002797  max_mem: 5397M
[32m[04/28 16:20:14 d2.utils.events]: [0m eta: 0:07:21  iter: 579  total_loss: 0.451  loss_cls: 0.135  loss_box_reg: 0.274  loss_rpn_cls: 0.005  loss_rpn_loc: 0.045  time: 1.0346  data_time: 0.0075  lr: 0.002897  max_mem: 5397M
[32m[04/28 16:20:34 d2.utils.events]: [0m eta: 0:07:00  iter: 599  total_loss: 0.468  loss_cls: 0.145  loss_box_reg: 0.261  loss_rpn_cls: 0.005  loss_rpn_loc: 0.045  time: 1.0343  data_time: 0.0076  lr: 0.002997  max_mem: 5397M
[32m[04/28 16:20:55 d2.utils.events]: [0m eta: 0:06:39  iter: 619  total_loss: 0.475  loss_cls: 0.149  loss_box_reg: 0.292  loss_rpn_cls: 0.005  loss_rpn_loc: 0.045  time: 1.0341  data_time: 0.0074  lr: 0.003097  max_mem: 5397M
[32m[04/28 16:21:15 d2.utils.events]: [0m eta: 0:06:17  iter: 639  total_loss: 0.452  loss_cls: 0.131  loss_box_reg: 0.265  loss_rpn_cls: 0.003  loss_rpn_loc: 0.041  time: 1.0331  data_time: 0.0078  lr: 0.003197  max_mem: 5397M
[32m[04/28 16:21:36 d2.utils.events]: [0m eta: 0:05:56  iter: 659  total_loss: 0.469  loss_cls: 0.144  loss_box_reg: 0.279  loss_rpn_cls: 0.006  loss_rpn_loc: 0.044  time: 1.0331  data_time: 0.0078  lr: 0.003297  max_mem: 5397M
[32m[04/28 16:21:56 d2.utils.events]: [0m eta: 0:05:35  iter: 679  total_loss: 0.488  loss_cls: 0.139  loss_box_reg: 0.285  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0329  data_time: 0.0077  lr: 0.003397  max_mem: 5397M
[32m[04/28 16:22:17 d2.utils.events]: [0m eta: 0:05:14  iter: 699  total_loss: 0.515  loss_cls: 0.155  loss_box_reg: 0.299  loss_rpn_cls: 0.005  loss_rpn_loc: 0.039  time: 1.0330  data_time: 0.0077  lr: 0.003497  max_mem: 5397M
[32m[04/28 16:22:38 d2.utils.events]: [0m eta: 0:04:53  iter: 719  total_loss: 0.497  loss_cls: 0.154  loss_box_reg: 0.294  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0330  data_time: 0.0085  lr: 0.003596  max_mem: 5397M
[32m[04/28 16:22:58 d2.utils.events]: [0m eta: 0:04:33  iter: 739  total_loss: 0.489  loss_cls: 0.152  loss_box_reg: 0.298  loss_rpn_cls: 0.007  loss_rpn_loc: 0.042  time: 1.0326  data_time: 0.0077  lr: 0.003696  max_mem: 5397M
[32m[04/28 16:23:19 d2.utils.events]: [0m eta: 0:04:12  iter: 759  total_loss: 0.479  loss_cls: 0.143  loss_box_reg: 0.294  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0329  data_time: 0.0078  lr: 0.003796  max_mem: 5397M
[32m[04/28 16:23:39 d2.utils.events]: [0m eta: 0:03:51  iter: 779  total_loss: 0.497  loss_cls: 0.149  loss_box_reg: 0.299  loss_rpn_cls: 0.008  loss_rpn_loc: 0.052  time: 1.0323  data_time: 0.0076  lr: 0.003896  max_mem: 5397M
[32m[04/28 16:24:00 d2.utils.events]: [0m eta: 0:03:30  iter: 799  total_loss: 0.502  loss_cls: 0.148  loss_box_reg: 0.301  loss_rpn_cls: 0.005  loss_rpn_loc: 0.039  time: 1.0321  data_time: 0.0079  lr: 0.003996  max_mem: 5397M
[32m[04/28 16:24:20 d2.utils.events]: [0m eta: 0:03:09  iter: 819  total_loss: 0.564  loss_cls: 0.169  loss_box_reg: 0.330  loss_rpn_cls: 0.008  loss_rpn_loc: 0.054  time: 1.0319  data_time: 0.0076  lr: 0.004096  max_mem: 5397M
[32m[04/28 16:24:41 d2.utils.events]: [0m eta: 0:02:48  iter: 839  total_loss: 0.469  loss_cls: 0.153  loss_box_reg: 0.255  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0320  data_time: 0.0080  lr: 0.004196  max_mem: 5397M
[32m[04/28 16:25:02 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.470  loss_cls: 0.150  loss_box_reg: 0.263  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0317  data_time: 0.0076  lr: 0.004296  max_mem: 5397M
[32m[04/28 16:25:22 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.539  loss_cls: 0.165  loss_box_reg: 0.321  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0315  data_time: 0.0077  lr: 0.004396  max_mem: 5397M
[32m[04/28 16:25:42 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.495  loss_cls: 0.143  loss_box_reg: 0.288  loss_rpn_cls: 0.006  loss_rpn_loc: 0.049  time: 1.0308  data_time: 0.0074  lr: 0.004496  max_mem: 5397M
[32m[04/28 16:26:02 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.494  loss_cls: 0.149  loss_box_reg: 0.282  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 1.0304  data_time: 0.0077  lr: 0.004595  max_mem: 5397M
[32m[04/28 16:26:23 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.472  loss_cls: 0.143  loss_box_reg: 0.278  loss_rpn_cls: 0.006  loss_rpn_loc: 0.052  time: 1.0305  data_time: 0.0082  lr: 0.004695  max_mem: 5397M
[32m[04/28 16:26:44 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.477  loss_cls: 0.140  loss_box_reg: 0.272  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 1.0306  data_time: 0.0079  lr: 0.004795  max_mem: 5397M
[32m[04/28 16:27:04 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.594  loss_cls: 0.185  loss_box_reg: 0.352  loss_rpn_cls: 0.012  loss_rpn_loc: 0.065  time: 1.0305  data_time: 0.0076  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 16:27:28 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 16:27:28 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 16:27:28 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 16:27:28 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.511  loss_cls: 0.157  loss_box_reg: 0.300  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 1.0310  data_time: 0.0078  lr: 0.004995  max_mem: 5397M
[32m[04/28 16:27:29 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:08 (1.0320 s / it)
[32m[04/28 16:27:29 d2.engine.hooks]: [0mTotal training time: 0:17:14 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 16:27:30 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 16:27:30 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 16:27:30 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 16:27:32 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1144 s / img. ETA=0:16:06
[32m[04/28 16:27:37 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1139 s / img. ETA=0:15:59
[32m[04/28 16:27:42 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1138 s / img. ETA=0:15:52
[32m[04/28 16:27:47 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1138 s / img. ETA=0:15:47
[32m[04/28 16:27:52 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1138 s / img. ETA=0:15:43
[32m[04/28 16:27:57 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1139 s / img. ETA=0:15:38
[32m[04/28 16:28:02 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1139 s / img. ETA=0:15:33
[32m[04/28 16:28:07 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1140 s / img. ETA=0:15:29
[32m[04/28 16:28:12 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1140 s / img. ETA=0:15:24
[32m[04/28 16:28:17 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1141 s / img. ETA=0:15:19
[32m[04/28 16:28:23 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1141 s / img. ETA=0:15:15
[32m[04/28 16:28:28 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1140 s / img. ETA=0:15:09
[32m[04/28 16:28:33 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1140 s / img. ETA=0:15:04
[32m[04/28 16:28:38 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1140 s / img. ETA=0:14:58
[32m[04/28 16:28:43 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1140 s / img. ETA=0:14:54
[32m[04/28 16:28:48 d2.evaluation.evaluator]: [0mInference done 670/8355. 0.1141 s / img. ETA=0:14:50
[32m[04/28 16:28:53 d2.evaluation.evaluator]: [0mInference done 714/8355. 0.1141 s / img. ETA=0:14:44
[32m[04/28 16:28:58 d2.evaluation.evaluator]: [0mInference done 758/8355. 0.1142 s / img. ETA=0:14:40
[32m[04/28 16:29:03 d2.evaluation.evaluator]: [0mInference done 802/8355. 0.1142 s / img. ETA=0:14:35
[32m[04/28 16:29:08 d2.evaluation.evaluator]: [0mInference done 846/8355. 0.1142 s / img. ETA=0:14:29
[32m[04/28 16:29:13 d2.evaluation.evaluator]: [0mInference done 889/8355. 0.1142 s / img. ETA=0:14:25
[32m[04/28 16:29:18 d2.evaluation.evaluator]: [0mInference done 932/8355. 0.1142 s / img. ETA=0:14:20
[32m[04/28 16:29:23 d2.evaluation.evaluator]: [0mInference done 975/8355. 0.1143 s / img. ETA=0:14:16
[32m[04/28 16:29:29 d2.evaluation.evaluator]: [0mInference done 1019/8355. 0.1143 s / img. ETA=0:14:10
[32m[04/28 16:29:34 d2.evaluation.evaluator]: [0mInference done 1063/8355. 0.1143 s / img. ETA=0:14:05
[32m[04/28 16:29:39 d2.evaluation.evaluator]: [0mInference done 1107/8355. 0.1143 s / img. ETA=0:14:00
[32m[04/28 16:29:44 d2.evaluation.evaluator]: [0mInference done 1151/8355. 0.1143 s / img. ETA=0:13:55
[32m[04/28 16:29:49 d2.evaluation.evaluator]: [0mInference done 1195/8355. 0.1142 s / img. ETA=0:13:50
[32m[04/28 16:29:54 d2.evaluation.evaluator]: [0mInference done 1239/8355. 0.1142 s / img. ETA=0:13:44
[32m[04/28 16:29:59 d2.evaluation.evaluator]: [0mInference done 1283/8355. 0.1142 s / img. ETA=0:13:39
[32m[04/28 16:30:04 d2.evaluation.evaluator]: [0mInference done 1326/8355. 0.1142 s / img. ETA=0:13:34
[32m[04/28 16:30:09 d2.evaluation.evaluator]: [0mInference done 1370/8355. 0.1142 s / img. ETA=0:13:29
[32m[04/28 16:30:14 d2.evaluation.evaluator]: [0mInference done 1414/8355. 0.1142 s / img. ETA=0:13:24
[32m[04/28 16:30:19 d2.evaluation.evaluator]: [0mInference done 1458/8355. 0.1142 s / img. ETA=0:13:19
[32m[04/28 16:30:24 d2.evaluation.evaluator]: [0mInference done 1501/8355. 0.1143 s / img. ETA=0:13:14
[32m[04/28 16:30:29 d2.evaluation.evaluator]: [0mInference done 1544/8355. 0.1143 s / img. ETA=0:13:10
[32m[04/28 16:30:35 d2.evaluation.evaluator]: [0mInference done 1587/8355. 0.1144 s / img. ETA=0:13:05
[32m[04/28 16:30:40 d2.evaluation.evaluator]: [0mInference done 1630/8355. 0.1144 s / img. ETA=0:13:00
[32m[04/28 16:30:45 d2.evaluation.evaluator]: [0mInference done 1673/8355. 0.1144 s / img. ETA=0:12:56
[32m[04/28 16:30:50 d2.evaluation.evaluator]: [0mInference done 1716/8355. 0.1145 s / img. ETA=0:12:51
[32m[04/28 16:30:55 d2.evaluation.evaluator]: [0mInference done 1759/8355. 0.1145 s / img. ETA=0:12:46
[32m[04/28 16:31:00 d2.evaluation.evaluator]: [0mInference done 1802/8355. 0.1145 s / img. ETA=0:12:41
[32m[04/28 16:31:05 d2.evaluation.evaluator]: [0mInference done 1845/8355. 0.1146 s / img. ETA=0:12:36
[32m[04/28 16:31:10 d2.evaluation.evaluator]: [0mInference done 1888/8355. 0.1146 s / img. ETA=0:12:32
[32m[04/28 16:31:15 d2.evaluation.evaluator]: [0mInference done 1931/8355. 0.1146 s / img. ETA=0:12:27
[32m[04/28 16:31:20 d2.evaluation.evaluator]: [0mInference done 1974/8355. 0.1146 s / img. ETA=0:12:22
[32m[04/28 16:31:25 d2.evaluation.evaluator]: [0mInference done 2017/8355. 0.1146 s / img. ETA=0:12:17
[32m[04/28 16:31:30 d2.evaluation.evaluator]: [0mInference done 2060/8355. 0.1146 s / img. ETA=0:12:12
[32m[04/28 16:31:35 d2.evaluation.evaluator]: [0mInference done 2103/8355. 0.1147 s / img. ETA=0:12:07
[32m[04/28 16:31:40 d2.evaluation.evaluator]: [0mInference done 2146/8355. 0.1147 s / img. ETA=0:12:02
[32m[04/28 16:31:45 d2.evaluation.evaluator]: [0mInference done 2189/8355. 0.1147 s / img. ETA=0:11:57
[32m[04/28 16:31:50 d2.evaluation.evaluator]: [0mInference done 2232/8355. 0.1147 s / img. ETA=0:11:52
[32m[04/28 16:31:55 d2.evaluation.evaluator]: [0mInference done 2275/8355. 0.1147 s / img. ETA=0:11:48
[32m[04/28 16:32:00 d2.evaluation.evaluator]: [0mInference done 2318/8355. 0.1148 s / img. ETA=0:11:43
[32m[04/28 16:32:05 d2.evaluation.evaluator]: [0mInference done 2361/8355. 0.1148 s / img. ETA=0:11:38
[32m[04/28 16:32:10 d2.evaluation.evaluator]: [0mInference done 2404/8355. 0.1148 s / img. ETA=0:11:33
[32m[04/28 16:32:16 d2.evaluation.evaluator]: [0mInference done 2447/8355. 0.1148 s / img. ETA=0:11:28
[32m[04/28 16:32:21 d2.evaluation.evaluator]: [0mInference done 2490/8355. 0.1148 s / img. ETA=0:11:23
[32m[04/28 16:32:26 d2.evaluation.evaluator]: [0mInference done 2533/8355. 0.1148 s / img. ETA=0:11:18
[32m[04/28 16:32:31 d2.evaluation.evaluator]: [0mInference done 2576/8355. 0.1148 s / img. ETA=0:11:13
[32m[04/28 16:32:36 d2.evaluation.evaluator]: [0mInference done 2619/8355. 0.1148 s / img. ETA=0:11:08
[32m[04/28 16:32:41 d2.evaluation.evaluator]: [0mInference done 2662/8355. 0.1148 s / img. ETA=0:11:03
[32m[04/28 16:32:46 d2.evaluation.evaluator]: [0mInference done 2705/8355. 0.1149 s / img. ETA=0:10:58
[32m[04/28 16:32:51 d2.evaluation.evaluator]: [0mInference done 2748/8355. 0.1149 s / img. ETA=0:10:53
[32m[04/28 16:32:56 d2.evaluation.evaluator]: [0mInference done 2791/8355. 0.1149 s / img. ETA=0:10:48
[32m[04/28 16:33:01 d2.evaluation.evaluator]: [0mInference done 2834/8355. 0.1149 s / img. ETA=0:10:44
[32m[04/28 16:33:06 d2.evaluation.evaluator]: [0mInference done 2877/8355. 0.1149 s / img. ETA=0:10:39
[32m[04/28 16:33:11 d2.evaluation.evaluator]: [0mInference done 2920/8355. 0.1149 s / img. ETA=0:10:34
[32m[04/28 16:33:16 d2.evaluation.evaluator]: [0mInference done 2963/8355. 0.1149 s / img. ETA=0:10:29
[32m[04/28 16:33:21 d2.evaluation.evaluator]: [0mInference done 3006/8355. 0.1149 s / img. ETA=0:10:24
[32m[04/28 16:33:26 d2.evaluation.evaluator]: [0mInference done 3049/8355. 0.1149 s / img. ETA=0:10:19
[32m[04/28 16:33:31 d2.evaluation.evaluator]: [0mInference done 3092/8355. 0.1149 s / img. ETA=0:10:14
[32m[04/28 16:33:36 d2.evaluation.evaluator]: [0mInference done 3135/8355. 0.1149 s / img. ETA=0:10:09
[32m[04/28 16:33:41 d2.evaluation.evaluator]: [0mInference done 3179/8355. 0.1149 s / img. ETA=0:10:04
[32m[04/28 16:33:46 d2.evaluation.evaluator]: [0mInference done 3223/8355. 0.1149 s / img. ETA=0:09:58
[32m[04/28 16:33:51 d2.evaluation.evaluator]: [0mInference done 3266/8355. 0.1149 s / img. ETA=0:09:53
[32m[04/28 16:33:56 d2.evaluation.evaluator]: [0mInference done 3309/8355. 0.1149 s / img. ETA=0:09:48
[32m[04/28 16:34:02 d2.evaluation.evaluator]: [0mInference done 3353/8355. 0.1149 s / img. ETA=0:09:43
[32m[04/28 16:34:07 d2.evaluation.evaluator]: [0mInference done 3396/8355. 0.1149 s / img. ETA=0:09:38
[32m[04/28 16:34:12 d2.evaluation.evaluator]: [0mInference done 3439/8355. 0.1149 s / img. ETA=0:09:33
[32m[04/28 16:34:17 d2.evaluation.evaluator]: [0mInference done 3482/8355. 0.1149 s / img. ETA=0:09:28
[32m[04/28 16:34:22 d2.evaluation.evaluator]: [0mInference done 3525/8355. 0.1149 s / img. ETA=0:09:23
[32m[04/28 16:34:27 d2.evaluation.evaluator]: [0mInference done 3569/8355. 0.1149 s / img. ETA=0:09:18
[32m[04/28 16:34:32 d2.evaluation.evaluator]: [0mInference done 3612/8355. 0.1149 s / img. ETA=0:09:13
[32m[04/28 16:34:37 d2.evaluation.evaluator]: [0mInference done 3655/8355. 0.1149 s / img. ETA=0:09:08
[32m[04/28 16:34:42 d2.evaluation.evaluator]: [0mInference done 3698/8355. 0.1149 s / img. ETA=0:09:03
[32m[04/28 16:34:47 d2.evaluation.evaluator]: [0mInference done 3741/8355. 0.1149 s / img. ETA=0:08:58
[32m[04/28 16:34:52 d2.evaluation.evaluator]: [0mInference done 3784/8355. 0.1149 s / img. ETA=0:08:53
[32m[04/28 16:34:57 d2.evaluation.evaluator]: [0mInference done 3827/8355. 0.1149 s / img. ETA=0:08:48
[32m[04/28 16:35:02 d2.evaluation.evaluator]: [0mInference done 3870/8355. 0.1149 s / img. ETA=0:08:43
[32m[04/28 16:35:07 d2.evaluation.evaluator]: [0mInference done 3914/8355. 0.1149 s / img. ETA=0:08:38
[32m[04/28 16:35:12 d2.evaluation.evaluator]: [0mInference done 3958/8355. 0.1149 s / img. ETA=0:08:33
[32m[04/28 16:35:17 d2.evaluation.evaluator]: [0mInference done 4001/8355. 0.1149 s / img. ETA=0:08:28
[32m[04/28 16:35:22 d2.evaluation.evaluator]: [0mInference done 4044/8355. 0.1149 s / img. ETA=0:08:23
[32m[04/28 16:35:27 d2.evaluation.evaluator]: [0mInference done 4087/8355. 0.1149 s / img. ETA=0:08:18
[32m[04/28 16:35:32 d2.evaluation.evaluator]: [0mInference done 4130/8355. 0.1149 s / img. ETA=0:08:13
[32m[04/28 16:35:37 d2.evaluation.evaluator]: [0mInference done 4173/8355. 0.1149 s / img. ETA=0:08:08
[32m[04/28 16:35:42 d2.evaluation.evaluator]: [0mInference done 4216/8355. 0.1149 s / img. ETA=0:08:03
[32m[04/28 16:35:47 d2.evaluation.evaluator]: [0mInference done 4260/8355. 0.1149 s / img. ETA=0:07:57
[32m[04/28 16:35:52 d2.evaluation.evaluator]: [0mInference done 4303/8355. 0.1149 s / img. ETA=0:07:52
[32m[04/28 16:35:57 d2.evaluation.evaluator]: [0mInference done 4346/8355. 0.1149 s / img. ETA=0:07:47
[32m[04/28 16:36:02 d2.evaluation.evaluator]: [0mInference done 4389/8355. 0.1149 s / img. ETA=0:07:42
[32m[04/28 16:36:08 d2.evaluation.evaluator]: [0mInference done 4432/8355. 0.1149 s / img. ETA=0:07:37
[32m[04/28 16:36:13 d2.evaluation.evaluator]: [0mInference done 4475/8355. 0.1149 s / img. ETA=0:07:32
[32m[04/28 16:36:18 d2.evaluation.evaluator]: [0mInference done 4518/8355. 0.1149 s / img. ETA=0:07:27
[32m[04/28 16:36:23 d2.evaluation.evaluator]: [0mInference done 4561/8355. 0.1149 s / img. ETA=0:07:22
[32m[04/28 16:36:28 d2.evaluation.evaluator]: [0mInference done 4604/8355. 0.1149 s / img. ETA=0:07:17
[32m[04/28 16:36:33 d2.evaluation.evaluator]: [0mInference done 4647/8355. 0.1149 s / img. ETA=0:07:12
[32m[04/28 16:36:38 d2.evaluation.evaluator]: [0mInference done 4690/8355. 0.1149 s / img. ETA=0:07:07
[32m[04/28 16:36:43 d2.evaluation.evaluator]: [0mInference done 4734/8355. 0.1149 s / img. ETA=0:07:02
[32m[04/28 16:36:48 d2.evaluation.evaluator]: [0mInference done 4777/8355. 0.1149 s / img. ETA=0:06:57
[32m[04/28 16:36:53 d2.evaluation.evaluator]: [0mInference done 4820/8355. 0.1149 s / img. ETA=0:06:52
[32m[04/28 16:36:58 d2.evaluation.evaluator]: [0mInference done 4863/8355. 0.1149 s / img. ETA=0:06:47
[32m[04/28 16:37:03 d2.evaluation.evaluator]: [0mInference done 4906/8355. 0.1149 s / img. ETA=0:06:42
[32m[04/28 16:37:08 d2.evaluation.evaluator]: [0mInference done 4949/8355. 0.1149 s / img. ETA=0:06:37
[32m[04/28 16:37:13 d2.evaluation.evaluator]: [0mInference done 4992/8355. 0.1149 s / img. ETA=0:06:32
[32m[04/28 16:37:18 d2.evaluation.evaluator]: [0mInference done 5035/8355. 0.1149 s / img. ETA=0:06:27
[32m[04/28 16:37:23 d2.evaluation.evaluator]: [0mInference done 5078/8355. 0.1149 s / img. ETA=0:06:22
[32m[04/28 16:37:28 d2.evaluation.evaluator]: [0mInference done 5121/8355. 0.1149 s / img. ETA=0:06:17
[32m[04/28 16:37:33 d2.evaluation.evaluator]: [0mInference done 5164/8355. 0.1149 s / img. ETA=0:06:12
[32m[04/28 16:37:38 d2.evaluation.evaluator]: [0mInference done 5207/8355. 0.1149 s / img. ETA=0:06:07
[32m[04/28 16:37:43 d2.evaluation.evaluator]: [0mInference done 5250/8355. 0.1149 s / img. ETA=0:06:02
[32m[04/28 16:37:48 d2.evaluation.evaluator]: [0mInference done 5293/8355. 0.1149 s / img. ETA=0:05:57
[32m[04/28 16:37:53 d2.evaluation.evaluator]: [0mInference done 5336/8355. 0.1149 s / img. ETA=0:05:52
[32m[04/28 16:37:58 d2.evaluation.evaluator]: [0mInference done 5379/8355. 0.1150 s / img. ETA=0:05:47
[32m[04/28 16:38:03 d2.evaluation.evaluator]: [0mInference done 5422/8355. 0.1150 s / img. ETA=0:05:42
[32m[04/28 16:38:08 d2.evaluation.evaluator]: [0mInference done 5465/8355. 0.1150 s / img. ETA=0:05:37
[32m[04/28 16:38:14 d2.evaluation.evaluator]: [0mInference done 5509/8355. 0.1150 s / img. ETA=0:05:32
[32m[04/28 16:38:19 d2.evaluation.evaluator]: [0mInference done 5553/8355. 0.1149 s / img. ETA=0:05:27
[32m[04/28 16:38:24 d2.evaluation.evaluator]: [0mInference done 5597/8355. 0.1149 s / img. ETA=0:05:21
[32m[04/28 16:38:29 d2.evaluation.evaluator]: [0mInference done 5640/8355. 0.1149 s / img. ETA=0:05:16
[32m[04/28 16:38:34 d2.evaluation.evaluator]: [0mInference done 5683/8355. 0.1149 s / img. ETA=0:05:11
[32m[04/28 16:38:39 d2.evaluation.evaluator]: [0mInference done 5726/8355. 0.1149 s / img. ETA=0:05:06
[32m[04/28 16:38:44 d2.evaluation.evaluator]: [0mInference done 5769/8355. 0.1149 s / img. ETA=0:05:01
[32m[04/28 16:38:49 d2.evaluation.evaluator]: [0mInference done 5812/8355. 0.1150 s / img. ETA=0:04:56
[32m[04/28 16:38:54 d2.evaluation.evaluator]: [0mInference done 5854/8355. 0.1150 s / img. ETA=0:04:52
[32m[04/28 16:38:59 d2.evaluation.evaluator]: [0mInference done 5897/8355. 0.1150 s / img. ETA=0:04:47
[32m[04/28 16:39:04 d2.evaluation.evaluator]: [0mInference done 5940/8355. 0.1150 s / img. ETA=0:04:42
[32m[04/28 16:39:09 d2.evaluation.evaluator]: [0mInference done 5983/8355. 0.1150 s / img. ETA=0:04:37
[32m[04/28 16:39:14 d2.evaluation.evaluator]: [0mInference done 6024/8355. 0.1150 s / img. ETA=0:04:32
[32m[04/28 16:39:19 d2.evaluation.evaluator]: [0mInference done 6067/8355. 0.1151 s / img. ETA=0:04:27
[32m[04/28 16:39:24 d2.evaluation.evaluator]: [0mInference done 6110/8355. 0.1151 s / img. ETA=0:04:22
[32m[04/28 16:39:30 d2.evaluation.evaluator]: [0mInference done 6153/8355. 0.1151 s / img. ETA=0:04:17
[32m[04/28 16:39:35 d2.evaluation.evaluator]: [0mInference done 6196/8355. 0.1151 s / img. ETA=0:04:12
[32m[04/28 16:39:40 d2.evaluation.evaluator]: [0mInference done 6239/8355. 0.1151 s / img. ETA=0:04:07
[32m[04/28 16:39:45 d2.evaluation.evaluator]: [0mInference done 6282/8355. 0.1151 s / img. ETA=0:04:02
[32m[04/28 16:39:50 d2.evaluation.evaluator]: [0mInference done 6325/8355. 0.1151 s / img. ETA=0:03:57
[32m[04/28 16:39:55 d2.evaluation.evaluator]: [0mInference done 6368/8355. 0.1151 s / img. ETA=0:03:52
[32m[04/28 16:40:00 d2.evaluation.evaluator]: [0mInference done 6411/8355. 0.1151 s / img. ETA=0:03:47
[32m[04/28 16:40:05 d2.evaluation.evaluator]: [0mInference done 6454/8355. 0.1151 s / img. ETA=0:03:42
[32m[04/28 16:40:10 d2.evaluation.evaluator]: [0mInference done 6498/8355. 0.1151 s / img. ETA=0:03:37
[32m[04/28 16:40:15 d2.evaluation.evaluator]: [0mInference done 6541/8355. 0.1151 s / img. ETA=0:03:32
[32m[04/28 16:40:20 d2.evaluation.evaluator]: [0mInference done 6585/8355. 0.1151 s / img. ETA=0:03:26
[32m[04/28 16:40:25 d2.evaluation.evaluator]: [0mInference done 6628/8355. 0.1151 s / img. ETA=0:03:21
[32m[04/28 16:40:30 d2.evaluation.evaluator]: [0mInference done 6672/8355. 0.1151 s / img. ETA=0:03:16
[32m[04/28 16:40:35 d2.evaluation.evaluator]: [0mInference done 6716/8355. 0.1151 s / img. ETA=0:03:11
[32m[04/28 16:40:41 d2.evaluation.evaluator]: [0mInference done 6759/8355. 0.1151 s / img. ETA=0:03:06
[32m[04/28 16:40:46 d2.evaluation.evaluator]: [0mInference done 6803/8355. 0.1151 s / img. ETA=0:03:01
[32m[04/28 16:40:51 d2.evaluation.evaluator]: [0mInference done 6846/8355. 0.1151 s / img. ETA=0:02:56
[32m[04/28 16:40:56 d2.evaluation.evaluator]: [0mInference done 6890/8355. 0.1151 s / img. ETA=0:02:51
[32m[04/28 16:41:01 d2.evaluation.evaluator]: [0mInference done 6933/8355. 0.1151 s / img. ETA=0:02:46
[32m[04/28 16:41:06 d2.evaluation.evaluator]: [0mInference done 6976/8355. 0.1151 s / img. ETA=0:02:41
[32m[04/28 16:41:11 d2.evaluation.evaluator]: [0mInference done 7019/8355. 0.1151 s / img. ETA=0:02:36
[32m[04/28 16:41:16 d2.evaluation.evaluator]: [0mInference done 7062/8355. 0.1151 s / img. ETA=0:02:31
[32m[04/28 16:41:21 d2.evaluation.evaluator]: [0mInference done 7105/8355. 0.1151 s / img. ETA=0:02:26
[32m[04/28 16:41:26 d2.evaluation.evaluator]: [0mInference done 7148/8355. 0.1151 s / img. ETA=0:02:21
[32m[04/28 16:41:31 d2.evaluation.evaluator]: [0mInference done 7191/8355. 0.1151 s / img. ETA=0:02:16
[32m[04/28 16:41:36 d2.evaluation.evaluator]: [0mInference done 7234/8355. 0.1151 s / img. ETA=0:02:11
[32m[04/28 16:41:41 d2.evaluation.evaluator]: [0mInference done 7277/8355. 0.1151 s / img. ETA=0:02:06
[32m[04/28 16:41:46 d2.evaluation.evaluator]: [0mInference done 7320/8355. 0.1151 s / img. ETA=0:02:01
[32m[04/28 16:41:51 d2.evaluation.evaluator]: [0mInference done 7363/8355. 0.1151 s / img. ETA=0:01:56
[32m[04/28 16:41:56 d2.evaluation.evaluator]: [0mInference done 7406/8355. 0.1151 s / img. ETA=0:01:50
[32m[04/28 16:42:01 d2.evaluation.evaluator]: [0mInference done 7448/8355. 0.1152 s / img. ETA=0:01:46
[32m[04/28 16:42:07 d2.evaluation.evaluator]: [0mInference done 7491/8355. 0.1152 s / img. ETA=0:01:41
[32m[04/28 16:42:12 d2.evaluation.evaluator]: [0mInference done 7534/8355. 0.1152 s / img. ETA=0:01:36
[32m[04/28 16:42:17 d2.evaluation.evaluator]: [0mInference done 7577/8355. 0.1152 s / img. ETA=0:01:31
[32m[04/28 16:42:22 d2.evaluation.evaluator]: [0mInference done 7620/8355. 0.1152 s / img. ETA=0:01:25
[32m[04/28 16:42:27 d2.evaluation.evaluator]: [0mInference done 7662/8355. 0.1152 s / img. ETA=0:01:21
[32m[04/28 16:42:32 d2.evaluation.evaluator]: [0mInference done 7705/8355. 0.1152 s / img. ETA=0:01:16
[32m[04/28 16:42:37 d2.evaluation.evaluator]: [0mInference done 7748/8355. 0.1152 s / img. ETA=0:01:11
[32m[04/28 16:42:42 d2.evaluation.evaluator]: [0mInference done 7791/8355. 0.1152 s / img. ETA=0:01:05
[32m[04/28 16:42:47 d2.evaluation.evaluator]: [0mInference done 7834/8355. 0.1152 s / img. ETA=0:01:00
[32m[04/28 16:42:52 d2.evaluation.evaluator]: [0mInference done 7877/8355. 0.1152 s / img. ETA=0:00:55
[32m[04/28 16:42:57 d2.evaluation.evaluator]: [0mInference done 7920/8355. 0.1152 s / img. ETA=0:00:50
[32m[04/28 16:43:02 d2.evaluation.evaluator]: [0mInference done 7963/8355. 0.1152 s / img. ETA=0:00:45
[32m[04/28 16:43:07 d2.evaluation.evaluator]: [0mInference done 8006/8355. 0.1152 s / img. ETA=0:00:40
[32m[04/28 16:43:12 d2.evaluation.evaluator]: [0mInference done 8050/8355. 0.1152 s / img. ETA=0:00:35
[32m[04/28 16:43:17 d2.evaluation.evaluator]: [0mInference done 8094/8355. 0.1152 s / img. ETA=0:00:30
[32m[04/28 16:43:22 d2.evaluation.evaluator]: [0mInference done 8137/8355. 0.1152 s / img. ETA=0:00:25
[32m[04/28 16:43:27 d2.evaluation.evaluator]: [0mInference done 8180/8355. 0.1152 s / img. ETA=0:00:20
[32m[04/28 16:43:32 d2.evaluation.evaluator]: [0mInference done 8223/8355. 0.1152 s / img. ETA=0:00:15
[32m[04/28 16:43:37 d2.evaluation.evaluator]: [0mInference done 8266/8355. 0.1152 s / img. ETA=0:00:10
[32m[04/28 16:43:42 d2.evaluation.evaluator]: [0mInference done 8309/8355. 0.1152 s / img. ETA=0:00:05
[32m[04/28 16:43:48 d2.evaluation.evaluator]: [0mInference done 8352/8355. 0.1152 s / img. ETA=0:00:00
[32m[04/28 16:43:48 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:16.961550 (0.117001 s / img per device, on 1 devices)
[32m[04/28 16:43:48 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:01 (0.115180 s / img per device, on 1 devices)
[32m[04/28 16:43:48 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 16:43:48 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 16:43:48 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=18.99s).
Accumulating evaluation results...
DONE (t=2.10s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.833
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.510
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.377
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.628
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.774
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.546
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.447
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.682
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.813
[32m[04/28 16:44:10 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.179 | 83.311 | 50.963 | 37.699 | 62.845 | 77.380 |
[32m[04/28 16:44:10 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 47.328 | bicycle       | 42.662 | car            | 57.548 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 16:44:10 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 16:44:10 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 16:44:10 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 16:44:11 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1157 s / img. ETA=0:02:26
[32m[04/28 16:44:16 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1149 s / img. ETA=0:02:20
[32m[04/28 16:44:22 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1150 s / img. ETA=0:02:15
[32m[04/28 16:44:27 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1149 s / img. ETA=0:02:10
[32m[04/28 16:44:32 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1149 s / img. ETA=0:02:05
[32m[04/28 16:44:37 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1149 s / img. ETA=0:02:00
[32m[04/28 16:44:42 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1150 s / img. ETA=0:01:55
[32m[04/28 16:44:47 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1150 s / img. ETA=0:01:50
[32m[04/28 16:44:52 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1149 s / img. ETA=0:01:45
[32m[04/28 16:44:57 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1149 s / img. ETA=0:01:40
[32m[04/28 16:45:02 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1149 s / img. ETA=0:01:35
[32m[04/28 16:45:07 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1149 s / img. ETA=0:01:30
[32m[04/28 16:45:12 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1149 s / img. ETA=0:01:25
[32m[04/28 16:45:17 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1149 s / img. ETA=0:01:20
[32m[04/28 16:45:22 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1149 s / img. ETA=0:01:15
[32m[04/28 16:45:27 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1149 s / img. ETA=0:01:10
[32m[04/28 16:45:32 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1149 s / img. ETA=0:01:05
[32m[04/28 16:45:37 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1149 s / img. ETA=0:01:00
[32m[04/28 16:45:42 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1149 s / img. ETA=0:00:55
[32m[04/28 16:45:47 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1149 s / img. ETA=0:00:50
[32m[04/28 16:45:52 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1150 s / img. ETA=0:00:45
[32m[04/28 16:45:57 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1150 s / img. ETA=0:00:40
[32m[04/28 16:46:02 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1150 s / img. ETA=0:00:35
[32m[04/28 16:46:07 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1150 s / img. ETA=0:00:30
[32m[04/28 16:46:12 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1150 s / img. ETA=0:00:25
[32m[04/28 16:46:17 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1150 s / img. ETA=0:00:19
[32m[04/28 16:46:22 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1150 s / img. ETA=0:00:14
[32m[04/28 16:46:27 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1150 s / img. ETA=0:00:09
[32m[04/28 16:46:32 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1151 s / img. ETA=0:00:04
[32m[04/28 16:46:37 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.480909 (0.116998 s / img per device, on 1 devices)
[32m[04/28 16:46:37 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115079 s / img per device, on 1 devices)
[32m[04/28 16:46:37 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 16:46:37 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 16:46:37 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.84s).
Accumulating evaluation results...
DONE (t=0.35s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.376
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.730
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.319
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.269
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.430
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.440
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.494
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648
[32m[04/28 16:46:41 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 37.583 | 72.958 | 31.858 | 26.899 | 42.967 | 60.221 |
[32m[04/28 16:46:41 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 39.638 | bicycle       | 20.219 | car            | 52.893 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  25  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 16:46:41 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 16:46:42 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 16:46:42 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 16:46:42 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 16:46:42 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 16:46:42 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 16:46:42 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 16:47:03 d2.utils.events]: [0m eta: 0:16:28  iter: 19  total_loss: 0.558  loss_cls: 0.167  loss_box_reg: 0.321  loss_rpn_cls: 0.005  loss_rpn_loc: 0.049  time: 0.9950  data_time: 0.0240  lr: 0.000100  max_mem: 5397M
[32m[04/28 16:47:22 d2.utils.events]: [0m eta: 0:16:07  iter: 39  total_loss: 0.512  loss_cls: 0.150  loss_box_reg: 0.310  loss_rpn_cls: 0.010  loss_rpn_loc: 0.041  time: 0.9960  data_time: 0.0076  lr: 0.000200  max_mem: 5397M
[32m[04/28 16:47:43 d2.utils.events]: [0m eta: 0:15:49  iter: 59  total_loss: 0.420  loss_cls: 0.127  loss_box_reg: 0.257  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 0.9983  data_time: 0.0076  lr: 0.000300  max_mem: 5397M
[32m[04/28 16:48:03 d2.utils.events]: [0m eta: 0:15:29  iter: 79  total_loss: 0.442  loss_cls: 0.141  loss_box_reg: 0.275  loss_rpn_cls: 0.007  loss_rpn_loc: 0.036  time: 1.0001  data_time: 0.0076  lr: 0.000400  max_mem: 5397M
[32m[04/28 16:48:23 d2.utils.events]: [0m eta: 0:15:14  iter: 99  total_loss: 0.509  loss_cls: 0.154  loss_box_reg: 0.295  loss_rpn_cls: 0.006  loss_rpn_loc: 0.052  time: 1.0056  data_time: 0.0076  lr: 0.000500  max_mem: 5397M
[32m[04/28 16:48:44 d2.utils.events]: [0m eta: 0:14:53  iter: 119  total_loss: 0.477  loss_cls: 0.140  loss_box_reg: 0.276  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0055  data_time: 0.0078  lr: 0.000599  max_mem: 5397M
[32m[04/28 16:49:04 d2.utils.events]: [0m eta: 0:14:34  iter: 139  total_loss: 0.433  loss_cls: 0.132  loss_box_reg: 0.268  loss_rpn_cls: 0.007  loss_rpn_loc: 0.035  time: 1.0081  data_time: 0.0076  lr: 0.000699  max_mem: 5397M
[32m[04/28 16:49:24 d2.utils.events]: [0m eta: 0:14:13  iter: 159  total_loss: 0.465  loss_cls: 0.139  loss_box_reg: 0.277  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0072  data_time: 0.0075  lr: 0.000799  max_mem: 5397M
[32m[04/28 16:49:45 d2.utils.events]: [0m eta: 0:13:53  iter: 179  total_loss: 0.528  loss_cls: 0.167  loss_box_reg: 0.304  loss_rpn_cls: 0.007  loss_rpn_loc: 0.053  time: 1.0088  data_time: 0.0078  lr: 0.000899  max_mem: 5397M
[32m[04/28 16:50:05 d2.utils.events]: [0m eta: 0:13:33  iter: 199  total_loss: 0.477  loss_cls: 0.145  loss_box_reg: 0.292  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0102  data_time: 0.0077  lr: 0.000999  max_mem: 5397M
[32m[04/28 16:50:26 d2.utils.events]: [0m eta: 0:13:17  iter: 219  total_loss: 0.430  loss_cls: 0.129  loss_box_reg: 0.271  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0130  data_time: 0.0077  lr: 0.001099  max_mem: 5397M
[32m[04/28 16:50:47 d2.utils.events]: [0m eta: 0:12:58  iter: 239  total_loss: 0.454  loss_cls: 0.126  loss_box_reg: 0.270  loss_rpn_cls: 0.005  loss_rpn_loc: 0.033  time: 1.0145  data_time: 0.0078  lr: 0.001199  max_mem: 5397M
[32m[04/28 16:51:07 d2.utils.events]: [0m eta: 0:12:37  iter: 259  total_loss: 0.459  loss_cls: 0.143  loss_box_reg: 0.277  loss_rpn_cls: 0.006  loss_rpn_loc: 0.036  time: 1.0155  data_time: 0.0078  lr: 0.001299  max_mem: 5397M
[32m[04/28 16:51:28 d2.utils.events]: [0m eta: 0:12:18  iter: 279  total_loss: 0.507  loss_cls: 0.142  loss_box_reg: 0.303  loss_rpn_cls: 0.005  loss_rpn_loc: 0.047  time: 1.0176  data_time: 0.0078  lr: 0.001399  max_mem: 5397M
[32m[04/28 16:51:48 d2.utils.events]: [0m eta: 0:11:57  iter: 299  total_loss: 0.442  loss_cls: 0.138  loss_box_reg: 0.271  loss_rpn_cls: 0.006  loss_rpn_loc: 0.035  time: 1.0167  data_time: 0.0079  lr: 0.001499  max_mem: 5397M
[32m[04/28 16:52:09 d2.utils.events]: [0m eta: 0:11:37  iter: 319  total_loss: 0.515  loss_cls: 0.152  loss_box_reg: 0.305  loss_rpn_cls: 0.003  loss_rpn_loc: 0.041  time: 1.0184  data_time: 0.0076  lr: 0.001598  max_mem: 5397M
[32m[04/28 16:52:30 d2.utils.events]: [0m eta: 0:11:18  iter: 339  total_loss: 0.445  loss_cls: 0.136  loss_box_reg: 0.268  loss_rpn_cls: 0.005  loss_rpn_loc: 0.035  time: 1.0197  data_time: 0.0079  lr: 0.001698  max_mem: 5397M
[32m[04/28 16:52:51 d2.utils.events]: [0m eta: 0:10:58  iter: 359  total_loss: 0.495  loss_cls: 0.147  loss_box_reg: 0.293  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0205  data_time: 0.0077  lr: 0.001798  max_mem: 5397M
[32m[04/28 16:53:12 d2.utils.events]: [0m eta: 0:10:41  iter: 379  total_loss: 0.499  loss_cls: 0.148  loss_box_reg: 0.288  loss_rpn_cls: 0.004  loss_rpn_loc: 0.049  time: 1.0224  data_time: 0.0077  lr: 0.001898  max_mem: 5397M
[32m[04/28 16:53:32 d2.utils.events]: [0m eta: 0:10:20  iter: 399  total_loss: 0.462  loss_cls: 0.150  loss_box_reg: 0.268  loss_rpn_cls: 0.003  loss_rpn_loc: 0.042  time: 1.0223  data_time: 0.0079  lr: 0.001998  max_mem: 5397M
[32m[04/28 16:53:53 d2.utils.events]: [0m eta: 0:10:01  iter: 419  total_loss: 0.511  loss_cls: 0.153  loss_box_reg: 0.308  loss_rpn_cls: 0.003  loss_rpn_loc: 0.041  time: 1.0236  data_time: 0.0078  lr: 0.002098  max_mem: 5397M
[32m[04/28 16:54:14 d2.utils.events]: [0m eta: 0:09:39  iter: 439  total_loss: 0.441  loss_cls: 0.133  loss_box_reg: 0.271  loss_rpn_cls: 0.005  loss_rpn_loc: 0.039  time: 1.0234  data_time: 0.0079  lr: 0.002198  max_mem: 5397M
[32m[04/28 16:54:34 d2.utils.events]: [0m eta: 0:09:16  iter: 459  total_loss: 0.490  loss_cls: 0.150  loss_box_reg: 0.289  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0225  data_time: 0.0076  lr: 0.002298  max_mem: 5397M
[32m[04/28 16:54:55 d2.utils.events]: [0m eta: 0:08:57  iter: 479  total_loss: 0.441  loss_cls: 0.127  loss_box_reg: 0.274  loss_rpn_cls: 0.006  loss_rpn_loc: 0.040  time: 1.0231  data_time: 0.0080  lr: 0.002398  max_mem: 5397M
[32m[04/28 16:55:16 d2.utils.events]: [0m eta: 0:08:37  iter: 499  total_loss: 0.509  loss_cls: 0.152  loss_box_reg: 0.277  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 1.0237  data_time: 0.0079  lr: 0.002498  max_mem: 5397M
[32m[04/28 16:55:37 d2.utils.events]: [0m eta: 0:08:18  iter: 519  total_loss: 0.483  loss_cls: 0.154  loss_box_reg: 0.283  loss_rpn_cls: 0.005  loss_rpn_loc: 0.045  time: 1.0250  data_time: 0.0078  lr: 0.002597  max_mem: 5397M
[32m[04/28 16:55:57 d2.utils.events]: [0m eta: 0:07:56  iter: 539  total_loss: 0.481  loss_cls: 0.151  loss_box_reg: 0.284  loss_rpn_cls: 0.007  loss_rpn_loc: 0.043  time: 1.0239  data_time: 0.0077  lr: 0.002697  max_mem: 5397M
[32m[04/28 16:56:18 d2.utils.events]: [0m eta: 0:07:36  iter: 559  total_loss: 0.417  loss_cls: 0.133  loss_box_reg: 0.242  loss_rpn_cls: 0.003  loss_rpn_loc: 0.032  time: 1.0243  data_time: 0.0075  lr: 0.002797  max_mem: 5397M
[32m[04/28 16:56:38 d2.utils.events]: [0m eta: 0:07:15  iter: 579  total_loss: 0.541  loss_cls: 0.171  loss_box_reg: 0.307  loss_rpn_cls: 0.008  loss_rpn_loc: 0.046  time: 1.0245  data_time: 0.0080  lr: 0.002897  max_mem: 5397M
[32m[04/28 16:56:59 d2.utils.events]: [0m eta: 0:06:54  iter: 599  total_loss: 0.523  loss_cls: 0.157  loss_box_reg: 0.294  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0245  data_time: 0.0076  lr: 0.002997  max_mem: 5397M
[32m[04/28 16:57:20 d2.utils.events]: [0m eta: 0:06:34  iter: 619  total_loss: 0.481  loss_cls: 0.146  loss_box_reg: 0.284  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 1.0250  data_time: 0.0076  lr: 0.003097  max_mem: 5397M
[32m[04/28 16:57:40 d2.utils.events]: [0m eta: 0:06:14  iter: 639  total_loss: 0.487  loss_cls: 0.143  loss_box_reg: 0.293  loss_rpn_cls: 0.006  loss_rpn_loc: 0.049  time: 1.0250  data_time: 0.0077  lr: 0.003197  max_mem: 5397M
[32m[04/28 16:58:01 d2.utils.events]: [0m eta: 0:05:53  iter: 659  total_loss: 0.427  loss_cls: 0.129  loss_box_reg: 0.251  loss_rpn_cls: 0.005  loss_rpn_loc: 0.035  time: 1.0260  data_time: 0.0079  lr: 0.003297  max_mem: 5397M
[32m[04/28 16:58:21 d2.utils.events]: [0m eta: 0:05:32  iter: 679  total_loss: 0.462  loss_cls: 0.133  loss_box_reg: 0.280  loss_rpn_cls: 0.005  loss_rpn_loc: 0.037  time: 1.0254  data_time: 0.0077  lr: 0.003397  max_mem: 5397M
[32m[04/28 16:58:42 d2.utils.events]: [0m eta: 0:05:11  iter: 699  total_loss: 0.536  loss_cls: 0.167  loss_box_reg: 0.321  loss_rpn_cls: 0.005  loss_rpn_loc: 0.047  time: 1.0253  data_time: 0.0077  lr: 0.003497  max_mem: 5397M
[32m[04/28 16:59:02 d2.utils.events]: [0m eta: 0:04:51  iter: 719  total_loss: 0.507  loss_cls: 0.153  loss_box_reg: 0.286  loss_rpn_cls: 0.004  loss_rpn_loc: 0.044  time: 1.0251  data_time: 0.0076  lr: 0.003596  max_mem: 5397M
[32m[04/28 16:59:22 d2.utils.events]: [0m eta: 0:04:30  iter: 739  total_loss: 0.482  loss_cls: 0.154  loss_box_reg: 0.277  loss_rpn_cls: 0.008  loss_rpn_loc: 0.041  time: 1.0244  data_time: 0.0077  lr: 0.003696  max_mem: 5397M
[32m[04/28 16:59:43 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.478  loss_cls: 0.137  loss_box_reg: 0.284  loss_rpn_cls: 0.006  loss_rpn_loc: 0.044  time: 1.0241  data_time: 0.0076  lr: 0.003796  max_mem: 5397M
[32m[04/28 17:00:03 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.481  loss_cls: 0.151  loss_box_reg: 0.283  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0240  data_time: 0.0078  lr: 0.003896  max_mem: 5397M
[32m[04/28 17:00:25 d2.utils.events]: [0m eta: 0:03:27  iter: 799  total_loss: 0.497  loss_cls: 0.154  loss_box_reg: 0.284  loss_rpn_cls: 0.004  loss_rpn_loc: 0.054  time: 1.0251  data_time: 0.0079  lr: 0.003996  max_mem: 5397M
[32m[04/28 17:00:45 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.487  loss_cls: 0.145  loss_box_reg: 0.299  loss_rpn_cls: 0.008  loss_rpn_loc: 0.040  time: 1.0253  data_time: 0.0077  lr: 0.004096  max_mem: 5397M
[32m[04/28 17:01:06 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.498  loss_cls: 0.139  loss_box_reg: 0.282  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0253  data_time: 0.0076  lr: 0.004196  max_mem: 5397M
[32m[04/28 17:01:26 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.423  loss_cls: 0.121  loss_box_reg: 0.248  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0254  data_time: 0.0078  lr: 0.004296  max_mem: 5397M
[32m[04/28 17:01:47 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.435  loss_cls: 0.125  loss_box_reg: 0.254  loss_rpn_cls: 0.004  loss_rpn_loc: 0.042  time: 1.0258  data_time: 0.0078  lr: 0.004396  max_mem: 5397M
[32m[04/28 17:02:08 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.409  loss_cls: 0.123  loss_box_reg: 0.248  loss_rpn_cls: 0.004  loss_rpn_loc: 0.034  time: 1.0261  data_time: 0.0077  lr: 0.004496  max_mem: 5397M
[32m[04/28 17:02:29 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.535  loss_cls: 0.148  loss_box_reg: 0.317  loss_rpn_cls: 0.005  loss_rpn_loc: 0.048  time: 1.0262  data_time: 0.0078  lr: 0.004595  max_mem: 5397M
[32m[04/28 17:02:49 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.535  loss_cls: 0.170  loss_box_reg: 0.292  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 1.0261  data_time: 0.0075  lr: 0.004695  max_mem: 5397M
[32m[04/28 17:03:10 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.513  loss_cls: 0.157  loss_box_reg: 0.286  loss_rpn_cls: 0.006  loss_rpn_loc: 0.055  time: 1.0261  data_time: 0.0077  lr: 0.004795  max_mem: 5397M
[32m[04/28 17:03:31 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.459  loss_cls: 0.135  loss_box_reg: 0.271  loss_rpn_cls: 0.006  loss_rpn_loc: 0.051  time: 1.0263  data_time: 0.0077  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 17:03:53 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 17:03:53 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 17:03:53 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 17:03:53 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.496  loss_cls: 0.151  loss_box_reg: 0.293  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0258  data_time: 0.0077  lr: 0.004995  max_mem: 5397M
[32m[04/28 17:03:54 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:03 (1.0269 s / it)
[32m[04/28 17:03:54 d2.engine.hooks]: [0mTotal training time: 0:17:09 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 17:03:55 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 17:03:55 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 17:03:56 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 17:03:57 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1142 s / img. ETA=0:16:04
[32m[04/28 17:04:02 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1138 s / img. ETA=0:15:57
[32m[04/28 17:04:07 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1136 s / img. ETA=0:15:51
[32m[04/28 17:04:12 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1136 s / img. ETA=0:15:46
[32m[04/28 17:04:17 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1136 s / img. ETA=0:15:41
[32m[04/28 17:04:22 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1137 s / img. ETA=0:15:36
[32m[04/28 17:04:27 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1137 s / img. ETA=0:15:32
[32m[04/28 17:04:32 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1137 s / img. ETA=0:15:27
[32m[04/28 17:04:38 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1138 s / img. ETA=0:15:22
[32m[04/28 17:04:43 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1138 s / img. ETA=0:15:18
[32m[04/28 17:04:48 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1139 s / img. ETA=0:15:13
[32m[04/28 17:04:53 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1138 s / img. ETA=0:15:07
[32m[04/28 17:04:58 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1138 s / img. ETA=0:15:02
[32m[04/28 17:05:03 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1137 s / img. ETA=0:14:57
[32m[04/28 17:05:08 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1137 s / img. ETA=0:14:52
[32m[04/28 17:05:13 d2.evaluation.evaluator]: [0mInference done 670/8355. 0.1138 s / img. ETA=0:14:47
[32m[04/28 17:05:18 d2.evaluation.evaluator]: [0mInference done 714/8355. 0.1138 s / img. ETA=0:14:42
[32m[04/28 17:05:23 d2.evaluation.evaluator]: [0mInference done 758/8355. 0.1138 s / img. ETA=0:14:37
[32m[04/28 17:05:28 d2.evaluation.evaluator]: [0mInference done 802/8355. 0.1139 s / img. ETA=0:14:32
[32m[04/28 17:05:33 d2.evaluation.evaluator]: [0mInference done 846/8355. 0.1139 s / img. ETA=0:14:27
[32m[04/28 17:05:38 d2.evaluation.evaluator]: [0mInference done 889/8355. 0.1139 s / img. ETA=0:14:23
[32m[04/28 17:05:43 d2.evaluation.evaluator]: [0mInference done 932/8355. 0.1140 s / img. ETA=0:14:18
[32m[04/28 17:05:49 d2.evaluation.evaluator]: [0mInference done 976/8355. 0.1139 s / img. ETA=0:14:13
[32m[04/28 17:05:54 d2.evaluation.evaluator]: [0mInference done 1020/8355. 0.1140 s / img. ETA=0:14:08
[32m[04/28 17:05:59 d2.evaluation.evaluator]: [0mInference done 1064/8355. 0.1139 s / img. ETA=0:14:03
[32m[04/28 17:06:04 d2.evaluation.evaluator]: [0mInference done 1108/8355. 0.1139 s / img. ETA=0:13:57
[32m[04/28 17:06:09 d2.evaluation.evaluator]: [0mInference done 1152/8355. 0.1139 s / img. ETA=0:13:52
[32m[04/28 17:06:14 d2.evaluation.evaluator]: [0mInference done 1196/8355. 0.1139 s / img. ETA=0:13:47
[32m[04/28 17:06:19 d2.evaluation.evaluator]: [0mInference done 1240/8355. 0.1139 s / img. ETA=0:13:42
[32m[04/28 17:06:24 d2.evaluation.evaluator]: [0mInference done 1284/8355. 0.1139 s / img. ETA=0:13:37
[32m[04/28 17:06:29 d2.evaluation.evaluator]: [0mInference done 1328/8355. 0.1139 s / img. ETA=0:13:32
[32m[04/28 17:06:34 d2.evaluation.evaluator]: [0mInference done 1372/8355. 0.1138 s / img. ETA=0:13:26
[32m[04/28 17:06:39 d2.evaluation.evaluator]: [0mInference done 1416/8355. 0.1139 s / img. ETA=0:13:21
[32m[04/28 17:06:44 d2.evaluation.evaluator]: [0mInference done 1460/8355. 0.1139 s / img. ETA=0:13:16
[32m[04/28 17:06:49 d2.evaluation.evaluator]: [0mInference done 1503/8355. 0.1139 s / img. ETA=0:13:12
[32m[04/28 17:06:54 d2.evaluation.evaluator]: [0mInference done 1546/8355. 0.1139 s / img. ETA=0:13:07
[32m[04/28 17:07:00 d2.evaluation.evaluator]: [0mInference done 1589/8355. 0.1140 s / img. ETA=0:13:02
[32m[04/28 17:07:05 d2.evaluation.evaluator]: [0mInference done 1632/8355. 0.1140 s / img. ETA=0:12:58
[32m[04/28 17:07:10 d2.evaluation.evaluator]: [0mInference done 1675/8355. 0.1141 s / img. ETA=0:12:53
[32m[04/28 17:07:15 d2.evaluation.evaluator]: [0mInference done 1718/8355. 0.1141 s / img. ETA=0:12:48
[32m[04/28 17:07:20 d2.evaluation.evaluator]: [0mInference done 1761/8355. 0.1141 s / img. ETA=0:12:43
[32m[04/28 17:07:25 d2.evaluation.evaluator]: [0mInference done 1804/8355. 0.1142 s / img. ETA=0:12:39
[32m[04/28 17:07:30 d2.evaluation.evaluator]: [0mInference done 1847/8355. 0.1142 s / img. ETA=0:12:34
[32m[04/28 17:07:35 d2.evaluation.evaluator]: [0mInference done 1890/8355. 0.1142 s / img. ETA=0:12:29
[32m[04/28 17:07:40 d2.evaluation.evaluator]: [0mInference done 1933/8355. 0.1142 s / img. ETA=0:12:24
[32m[04/28 17:07:45 d2.evaluation.evaluator]: [0mInference done 1976/8355. 0.1143 s / img. ETA=0:12:19
[32m[04/28 17:07:50 d2.evaluation.evaluator]: [0mInference done 2019/8355. 0.1143 s / img. ETA=0:12:15
[32m[04/28 17:07:55 d2.evaluation.evaluator]: [0mInference done 2062/8355. 0.1143 s / img. ETA=0:12:10
[32m[04/28 17:08:00 d2.evaluation.evaluator]: [0mInference done 2105/8355. 0.1143 s / img. ETA=0:12:05
[32m[04/28 17:08:05 d2.evaluation.evaluator]: [0mInference done 2148/8355. 0.1143 s / img. ETA=0:12:00
[32m[04/28 17:08:10 d2.evaluation.evaluator]: [0mInference done 2191/8355. 0.1143 s / img. ETA=0:11:55
[32m[04/28 17:08:15 d2.evaluation.evaluator]: [0mInference done 2234/8355. 0.1143 s / img. ETA=0:11:50
[32m[04/28 17:08:20 d2.evaluation.evaluator]: [0mInference done 2277/8355. 0.1143 s / img. ETA=0:11:45
[32m[04/28 17:08:25 d2.evaluation.evaluator]: [0mInference done 2320/8355. 0.1144 s / img. ETA=0:11:40
[32m[04/28 17:08:30 d2.evaluation.evaluator]: [0mInference done 2363/8355. 0.1144 s / img. ETA=0:11:35
[32m[04/28 17:08:35 d2.evaluation.evaluator]: [0mInference done 2406/8355. 0.1144 s / img. ETA=0:11:30
[32m[04/28 17:08:40 d2.evaluation.evaluator]: [0mInference done 2449/8355. 0.1144 s / img. ETA=0:11:26
[32m[04/28 17:08:45 d2.evaluation.evaluator]: [0mInference done 2493/8355. 0.1144 s / img. ETA=0:11:20
[32m[04/28 17:08:50 d2.evaluation.evaluator]: [0mInference done 2536/8355. 0.1144 s / img. ETA=0:11:15
[32m[04/28 17:08:55 d2.evaluation.evaluator]: [0mInference done 2579/8355. 0.1144 s / img. ETA=0:11:11
[32m[04/28 17:09:00 d2.evaluation.evaluator]: [0mInference done 2622/8355. 0.1144 s / img. ETA=0:11:06
[32m[04/28 17:09:05 d2.evaluation.evaluator]: [0mInference done 2665/8355. 0.1144 s / img. ETA=0:11:01
[32m[04/28 17:09:10 d2.evaluation.evaluator]: [0mInference done 2708/8355. 0.1145 s / img. ETA=0:10:56
[32m[04/28 17:09:15 d2.evaluation.evaluator]: [0mInference done 2751/8355. 0.1145 s / img. ETA=0:10:51
[32m[04/28 17:09:20 d2.evaluation.evaluator]: [0mInference done 2794/8355. 0.1145 s / img. ETA=0:10:46
[32m[04/28 17:09:25 d2.evaluation.evaluator]: [0mInference done 2837/8355. 0.1145 s / img. ETA=0:10:41
[32m[04/28 17:09:30 d2.evaluation.evaluator]: [0mInference done 2880/8355. 0.1145 s / img. ETA=0:10:36
[32m[04/28 17:09:35 d2.evaluation.evaluator]: [0mInference done 2923/8355. 0.1145 s / img. ETA=0:10:31
[32m[04/28 17:09:41 d2.evaluation.evaluator]: [0mInference done 2966/8355. 0.1145 s / img. ETA=0:10:26
[32m[04/28 17:09:46 d2.evaluation.evaluator]: [0mInference done 3009/8355. 0.1145 s / img. ETA=0:10:21
[32m[04/28 17:09:51 d2.evaluation.evaluator]: [0mInference done 3052/8355. 0.1145 s / img. ETA=0:10:16
[32m[04/28 17:09:56 d2.evaluation.evaluator]: [0mInference done 3095/8355. 0.1145 s / img. ETA=0:10:11
[32m[04/28 17:10:01 d2.evaluation.evaluator]: [0mInference done 3138/8355. 0.1145 s / img. ETA=0:10:06
[32m[04/28 17:10:06 d2.evaluation.evaluator]: [0mInference done 3182/8355. 0.1145 s / img. ETA=0:10:01
[32m[04/28 17:10:11 d2.evaluation.evaluator]: [0mInference done 3226/8355. 0.1145 s / img. ETA=0:09:56
[32m[04/28 17:10:16 d2.evaluation.evaluator]: [0mInference done 3269/8355. 0.1145 s / img. ETA=0:09:51
[32m[04/28 17:10:21 d2.evaluation.evaluator]: [0mInference done 3313/8355. 0.1145 s / img. ETA=0:09:46
[32m[04/28 17:10:26 d2.evaluation.evaluator]: [0mInference done 3357/8355. 0.1145 s / img. ETA=0:09:41
[32m[04/28 17:10:31 d2.evaluation.evaluator]: [0mInference done 3401/8355. 0.1145 s / img. ETA=0:09:35
[32m[04/28 17:10:36 d2.evaluation.evaluator]: [0mInference done 3445/8355. 0.1145 s / img. ETA=0:09:30
[32m[04/28 17:10:41 d2.evaluation.evaluator]: [0mInference done 3488/8355. 0.1145 s / img. ETA=0:09:25
[32m[04/28 17:10:46 d2.evaluation.evaluator]: [0mInference done 3532/8355. 0.1145 s / img. ETA=0:09:20
[32m[04/28 17:10:51 d2.evaluation.evaluator]: [0mInference done 3575/8355. 0.1145 s / img. ETA=0:09:15
[32m[04/28 17:10:56 d2.evaluation.evaluator]: [0mInference done 3619/8355. 0.1145 s / img. ETA=0:09:10
[32m[04/28 17:11:02 d2.evaluation.evaluator]: [0mInference done 3663/8355. 0.1145 s / img. ETA=0:09:05
[32m[04/28 17:11:07 d2.evaluation.evaluator]: [0mInference done 3707/8355. 0.1145 s / img. ETA=0:09:00
[32m[04/28 17:11:12 d2.evaluation.evaluator]: [0mInference done 3751/8355. 0.1145 s / img. ETA=0:08:55
[32m[04/28 17:11:17 d2.evaluation.evaluator]: [0mInference done 3794/8355. 0.1145 s / img. ETA=0:08:50
[32m[04/28 17:11:22 d2.evaluation.evaluator]: [0mInference done 3837/8355. 0.1145 s / img. ETA=0:08:45
[32m[04/28 17:11:27 d2.evaluation.evaluator]: [0mInference done 3881/8355. 0.1145 s / img. ETA=0:08:40
[32m[04/28 17:11:32 d2.evaluation.evaluator]: [0mInference done 3925/8355. 0.1145 s / img. ETA=0:08:35
[32m[04/28 17:11:37 d2.evaluation.evaluator]: [0mInference done 3968/8355. 0.1145 s / img. ETA=0:08:30
[32m[04/28 17:11:42 d2.evaluation.evaluator]: [0mInference done 4011/8355. 0.1145 s / img. ETA=0:08:25
[32m[04/28 17:11:47 d2.evaluation.evaluator]: [0mInference done 4054/8355. 0.1145 s / img. ETA=0:08:20
[32m[04/28 17:11:52 d2.evaluation.evaluator]: [0mInference done 4097/8355. 0.1145 s / img. ETA=0:08:15
[32m[04/28 17:11:57 d2.evaluation.evaluator]: [0mInference done 4140/8355. 0.1145 s / img. ETA=0:08:10
[32m[04/28 17:12:02 d2.evaluation.evaluator]: [0mInference done 4183/8355. 0.1145 s / img. ETA=0:08:05
[32m[04/28 17:12:07 d2.evaluation.evaluator]: [0mInference done 4226/8355. 0.1145 s / img. ETA=0:08:00
[32m[04/28 17:12:12 d2.evaluation.evaluator]: [0mInference done 4270/8355. 0.1145 s / img. ETA=0:07:55
[32m[04/28 17:12:17 d2.evaluation.evaluator]: [0mInference done 4313/8355. 0.1145 s / img. ETA=0:07:50
[32m[04/28 17:12:22 d2.evaluation.evaluator]: [0mInference done 4356/8355. 0.1145 s / img. ETA=0:07:45
[32m[04/28 17:12:27 d2.evaluation.evaluator]: [0mInference done 4399/8355. 0.1145 s / img. ETA=0:07:40
[32m[04/28 17:12:32 d2.evaluation.evaluator]: [0mInference done 4442/8355. 0.1145 s / img. ETA=0:07:35
[32m[04/28 17:12:37 d2.evaluation.evaluator]: [0mInference done 4485/8355. 0.1145 s / img. ETA=0:07:30
[32m[04/28 17:12:42 d2.evaluation.evaluator]: [0mInference done 4528/8355. 0.1145 s / img. ETA=0:07:25
[32m[04/28 17:12:47 d2.evaluation.evaluator]: [0mInference done 4571/8355. 0.1145 s / img. ETA=0:07:20
[32m[04/28 17:12:52 d2.evaluation.evaluator]: [0mInference done 4614/8355. 0.1145 s / img. ETA=0:07:15
[32m[04/28 17:12:57 d2.evaluation.evaluator]: [0mInference done 4657/8355. 0.1145 s / img. ETA=0:07:10
[32m[04/28 17:13:02 d2.evaluation.evaluator]: [0mInference done 4700/8355. 0.1145 s / img. ETA=0:07:05
[32m[04/28 17:13:07 d2.evaluation.evaluator]: [0mInference done 4743/8355. 0.1145 s / img. ETA=0:07:00
[32m[04/28 17:13:12 d2.evaluation.evaluator]: [0mInference done 4786/8355. 0.1145 s / img. ETA=0:06:55
[32m[04/28 17:13:17 d2.evaluation.evaluator]: [0mInference done 4829/8355. 0.1145 s / img. ETA=0:06:50
[32m[04/28 17:13:22 d2.evaluation.evaluator]: [0mInference done 4872/8355. 0.1145 s / img. ETA=0:06:45
[32m[04/28 17:13:27 d2.evaluation.evaluator]: [0mInference done 4915/8355. 0.1145 s / img. ETA=0:06:40
[32m[04/28 17:13:33 d2.evaluation.evaluator]: [0mInference done 4959/8355. 0.1145 s / img. ETA=0:06:35
[32m[04/28 17:13:38 d2.evaluation.evaluator]: [0mInference done 5003/8355. 0.1145 s / img. ETA=0:06:29
[32m[04/28 17:13:43 d2.evaluation.evaluator]: [0mInference done 5046/8355. 0.1145 s / img. ETA=0:06:24
[32m[04/28 17:13:48 d2.evaluation.evaluator]: [0mInference done 5089/8355. 0.1146 s / img. ETA=0:06:20
[32m[04/28 17:13:53 d2.evaluation.evaluator]: [0mInference done 5132/8355. 0.1146 s / img. ETA=0:06:15
[32m[04/28 17:13:58 d2.evaluation.evaluator]: [0mInference done 5175/8355. 0.1146 s / img. ETA=0:06:10
[32m[04/28 17:14:03 d2.evaluation.evaluator]: [0mInference done 5218/8355. 0.1146 s / img. ETA=0:06:05
[32m[04/28 17:14:08 d2.evaluation.evaluator]: [0mInference done 5261/8355. 0.1146 s / img. ETA=0:06:00
[32m[04/28 17:14:13 d2.evaluation.evaluator]: [0mInference done 5304/8355. 0.1146 s / img. ETA=0:05:55
[32m[04/28 17:14:18 d2.evaluation.evaluator]: [0mInference done 5347/8355. 0.1146 s / img. ETA=0:05:50
[32m[04/28 17:14:23 d2.evaluation.evaluator]: [0mInference done 5390/8355. 0.1146 s / img. ETA=0:05:45
[32m[04/28 17:14:28 d2.evaluation.evaluator]: [0mInference done 5433/8355. 0.1146 s / img. ETA=0:05:40
[32m[04/28 17:14:33 d2.evaluation.evaluator]: [0mInference done 5476/8355. 0.1146 s / img. ETA=0:05:35
[32m[04/28 17:14:38 d2.evaluation.evaluator]: [0mInference done 5519/8355. 0.1146 s / img. ETA=0:05:30
[32m[04/28 17:14:43 d2.evaluation.evaluator]: [0mInference done 5562/8355. 0.1146 s / img. ETA=0:05:25
[32m[04/28 17:14:48 d2.evaluation.evaluator]: [0mInference done 5605/8355. 0.1146 s / img. ETA=0:05:20
[32m[04/28 17:14:53 d2.evaluation.evaluator]: [0mInference done 5648/8355. 0.1146 s / img. ETA=0:05:15
[32m[04/28 17:14:58 d2.evaluation.evaluator]: [0mInference done 5691/8355. 0.1146 s / img. ETA=0:05:10
[32m[04/28 17:15:03 d2.evaluation.evaluator]: [0mInference done 5734/8355. 0.1146 s / img. ETA=0:05:05
[32m[04/28 17:15:08 d2.evaluation.evaluator]: [0mInference done 5777/8355. 0.1146 s / img. ETA=0:05:00
[32m[04/28 17:15:13 d2.evaluation.evaluator]: [0mInference done 5820/8355. 0.1146 s / img. ETA=0:04:55
[32m[04/28 17:15:18 d2.evaluation.evaluator]: [0mInference done 5863/8355. 0.1146 s / img. ETA=0:04:50
[32m[04/28 17:15:23 d2.evaluation.evaluator]: [0mInference done 5906/8355. 0.1146 s / img. ETA=0:04:45
[32m[04/28 17:15:28 d2.evaluation.evaluator]: [0mInference done 5949/8355. 0.1146 s / img. ETA=0:04:40
[32m[04/28 17:15:33 d2.evaluation.evaluator]: [0mInference done 5992/8355. 0.1147 s / img. ETA=0:04:35
[32m[04/28 17:15:39 d2.evaluation.evaluator]: [0mInference done 6035/8355. 0.1147 s / img. ETA=0:04:30
[32m[04/28 17:15:44 d2.evaluation.evaluator]: [0mInference done 6078/8355. 0.1147 s / img. ETA=0:04:25
[32m[04/28 17:15:49 d2.evaluation.evaluator]: [0mInference done 6121/8355. 0.1147 s / img. ETA=0:04:20
[32m[04/28 17:15:54 d2.evaluation.evaluator]: [0mInference done 6164/8355. 0.1147 s / img. ETA=0:04:15
[32m[04/28 17:15:59 d2.evaluation.evaluator]: [0mInference done 6207/8355. 0.1147 s / img. ETA=0:04:10
[32m[04/28 17:16:04 d2.evaluation.evaluator]: [0mInference done 6250/8355. 0.1147 s / img. ETA=0:04:05
[32m[04/28 17:16:09 d2.evaluation.evaluator]: [0mInference done 6293/8355. 0.1147 s / img. ETA=0:04:00
[32m[04/28 17:16:14 d2.evaluation.evaluator]: [0mInference done 6336/8355. 0.1147 s / img. ETA=0:03:55
[32m[04/28 17:16:19 d2.evaluation.evaluator]: [0mInference done 6378/8355. 0.1148 s / img. ETA=0:03:50
[32m[04/28 17:16:24 d2.evaluation.evaluator]: [0mInference done 6421/8355. 0.1148 s / img. ETA=0:03:45
[32m[04/28 17:16:29 d2.evaluation.evaluator]: [0mInference done 6464/8355. 0.1148 s / img. ETA=0:03:40
[32m[04/28 17:16:34 d2.evaluation.evaluator]: [0mInference done 6508/8355. 0.1148 s / img. ETA=0:03:35
[32m[04/28 17:16:39 d2.evaluation.evaluator]: [0mInference done 6552/8355. 0.1147 s / img. ETA=0:03:30
[32m[04/28 17:16:44 d2.evaluation.evaluator]: [0mInference done 6595/8355. 0.1148 s / img. ETA=0:03:25
[32m[04/28 17:16:49 d2.evaluation.evaluator]: [0mInference done 6638/8355. 0.1148 s / img. ETA=0:03:20
[32m[04/28 17:16:55 d2.evaluation.evaluator]: [0mInference done 6682/8355. 0.1148 s / img. ETA=0:03:15
[32m[04/28 17:17:00 d2.evaluation.evaluator]: [0mInference done 6725/8355. 0.1148 s / img. ETA=0:03:09
[32m[04/28 17:17:05 d2.evaluation.evaluator]: [0mInference done 6769/8355. 0.1147 s / img. ETA=0:03:04
[32m[04/28 17:17:10 d2.evaluation.evaluator]: [0mInference done 6813/8355. 0.1147 s / img. ETA=0:02:59
[32m[04/28 17:17:15 d2.evaluation.evaluator]: [0mInference done 6856/8355. 0.1147 s / img. ETA=0:02:54
[32m[04/28 17:17:20 d2.evaluation.evaluator]: [0mInference done 6900/8355. 0.1147 s / img. ETA=0:02:49
[32m[04/28 17:17:25 d2.evaluation.evaluator]: [0mInference done 6943/8355. 0.1147 s / img. ETA=0:02:44
[32m[04/28 17:17:30 d2.evaluation.evaluator]: [0mInference done 6986/8355. 0.1147 s / img. ETA=0:02:39
[32m[04/28 17:17:35 d2.evaluation.evaluator]: [0mInference done 7029/8355. 0.1148 s / img. ETA=0:02:34
[32m[04/28 17:17:40 d2.evaluation.evaluator]: [0mInference done 7072/8355. 0.1148 s / img. ETA=0:02:29
[32m[04/28 17:17:45 d2.evaluation.evaluator]: [0mInference done 7115/8355. 0.1148 s / img. ETA=0:02:24
[32m[04/28 17:17:50 d2.evaluation.evaluator]: [0mInference done 7158/8355. 0.1148 s / img. ETA=0:02:19
[32m[04/28 17:17:55 d2.evaluation.evaluator]: [0mInference done 7201/8355. 0.1148 s / img. ETA=0:02:14
[32m[04/28 17:18:00 d2.evaluation.evaluator]: [0mInference done 7243/8355. 0.1148 s / img. ETA=0:02:09
[32m[04/28 17:18:05 d2.evaluation.evaluator]: [0mInference done 7286/8355. 0.1148 s / img. ETA=0:02:04
[32m[04/28 17:18:10 d2.evaluation.evaluator]: [0mInference done 7329/8355. 0.1148 s / img. ETA=0:01:59
[32m[04/28 17:18:15 d2.evaluation.evaluator]: [0mInference done 7371/8355. 0.1148 s / img. ETA=0:01:54
[32m[04/28 17:18:20 d2.evaluation.evaluator]: [0mInference done 7414/8355. 0.1148 s / img. ETA=0:01:49
[32m[04/28 17:18:26 d2.evaluation.evaluator]: [0mInference done 7457/8355. 0.1148 s / img. ETA=0:01:44
[32m[04/28 17:18:31 d2.evaluation.evaluator]: [0mInference done 7500/8355. 0.1148 s / img. ETA=0:01:39
[32m[04/28 17:18:36 d2.evaluation.evaluator]: [0mInference done 7543/8355. 0.1149 s / img. ETA=0:01:34
[32m[04/28 17:18:41 d2.evaluation.evaluator]: [0mInference done 7586/8355. 0.1149 s / img. ETA=0:01:29
[32m[04/28 17:18:46 d2.evaluation.evaluator]: [0mInference done 7629/8355. 0.1149 s / img. ETA=0:01:24
[32m[04/28 17:18:51 d2.evaluation.evaluator]: [0mInference done 7672/8355. 0.1149 s / img. ETA=0:01:19
[32m[04/28 17:18:56 d2.evaluation.evaluator]: [0mInference done 7715/8355. 0.1149 s / img. ETA=0:01:14
[32m[04/28 17:19:01 d2.evaluation.evaluator]: [0mInference done 7758/8355. 0.1149 s / img. ETA=0:01:09
[32m[04/28 17:19:06 d2.evaluation.evaluator]: [0mInference done 7801/8355. 0.1149 s / img. ETA=0:01:04
[32m[04/28 17:19:11 d2.evaluation.evaluator]: [0mInference done 7844/8355. 0.1149 s / img. ETA=0:00:59
[32m[04/28 17:19:16 d2.evaluation.evaluator]: [0mInference done 7887/8355. 0.1149 s / img. ETA=0:00:54
[32m[04/28 17:19:21 d2.evaluation.evaluator]: [0mInference done 7930/8355. 0.1149 s / img. ETA=0:00:49
[32m[04/28 17:19:26 d2.evaluation.evaluator]: [0mInference done 7973/8355. 0.1149 s / img. ETA=0:00:44
[32m[04/28 17:19:31 d2.evaluation.evaluator]: [0mInference done 8016/8355. 0.1149 s / img. ETA=0:00:39
[32m[04/28 17:19:36 d2.evaluation.evaluator]: [0mInference done 8060/8355. 0.1149 s / img. ETA=0:00:34
[32m[04/28 17:19:41 d2.evaluation.evaluator]: [0mInference done 8104/8355. 0.1149 s / img. ETA=0:00:29
[32m[04/28 17:19:47 d2.evaluation.evaluator]: [0mInference done 8148/8355. 0.1149 s / img. ETA=0:00:24
[32m[04/28 17:19:52 d2.evaluation.evaluator]: [0mInference done 8191/8355. 0.1149 s / img. ETA=0:00:19
[32m[04/28 17:19:57 d2.evaluation.evaluator]: [0mInference done 8234/8355. 0.1149 s / img. ETA=0:00:14
[32m[04/28 17:20:02 d2.evaluation.evaluator]: [0mInference done 8277/8355. 0.1149 s / img. ETA=0:00:09
[32m[04/28 17:20:07 d2.evaluation.evaluator]: [0mInference done 8320/8355. 0.1149 s / img. ETA=0:00:04
[32m[04/28 17:20:11 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:14.708015 (0.116731 s / img per device, on 1 devices)
[32m[04/28 17:20:11 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:15:59 (0.114910 s / img per device, on 1 devices)
[32m[04/28 17:20:11 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 17:20:11 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 17:20:11 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.43s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.09s).
Accumulating evaluation results...
DONE (t=2.19s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.867
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.518
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.396
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.640
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.547
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.565
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.471
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.697
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.803
[32m[04/28 17:20:34 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.618 | 86.744 | 51.754 | 39.589 | 64.001 | 75.838 |
[32m[04/28 17:20:34 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 48.841 | bicycle       | 44.277 | car            | 58.737 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 17:20:35 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 17:20:35 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 17:20:35 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 17:20:36 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1149 s / img. ETA=0:02:25
[32m[04/28 17:20:41 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1148 s / img. ETA=0:02:20
[32m[04/28 17:20:46 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1149 s / img. ETA=0:02:15
[32m[04/28 17:20:51 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1149 s / img. ETA=0:02:10
[32m[04/28 17:20:56 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1150 s / img. ETA=0:02:05
[32m[04/28 17:21:01 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1150 s / img. ETA=0:02:00
[32m[04/28 17:21:06 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1151 s / img. ETA=0:01:55
[32m[04/28 17:21:11 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1151 s / img. ETA=0:01:50
[32m[04/28 17:21:16 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1150 s / img. ETA=0:01:45
[32m[04/28 17:21:21 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1150 s / img. ETA=0:01:40
[32m[04/28 17:21:26 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1150 s / img. ETA=0:01:35
[32m[04/28 17:21:31 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1150 s / img. ETA=0:01:30
[32m[04/28 17:21:36 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1150 s / img. ETA=0:01:25
[32m[04/28 17:21:41 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1150 s / img. ETA=0:01:20
[32m[04/28 17:21:46 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1150 s / img. ETA=0:01:15
[32m[04/28 17:21:52 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1150 s / img. ETA=0:01:10
[32m[04/28 17:21:57 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1151 s / img. ETA=0:01:05
[32m[04/28 17:22:02 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1151 s / img. ETA=0:01:00
[32m[04/28 17:22:07 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1151 s / img. ETA=0:00:55
[32m[04/28 17:22:12 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1151 s / img. ETA=0:00:50
[32m[04/28 17:22:17 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1152 s / img. ETA=0:00:45
[32m[04/28 17:22:22 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1152 s / img. ETA=0:00:40
[32m[04/28 17:22:27 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1152 s / img. ETA=0:00:35
[32m[04/28 17:22:32 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1152 s / img. ETA=0:00:30
[32m[04/28 17:22:37 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1152 s / img. ETA=0:00:25
[32m[04/28 17:22:42 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1153 s / img. ETA=0:00:20
[32m[04/28 17:22:47 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1153 s / img. ETA=0:00:14
[32m[04/28 17:22:52 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1153 s / img. ETA=0:00:09
[32m[04/28 17:22:57 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1153 s / img. ETA=0:00:04
[32m[04/28 17:23:02 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.710749 (0.117181 s / img per device, on 1 devices)
[32m[04/28 17:23:02 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115282 s / img per device, on 1 devices)
[32m[04/28 17:23:02 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 17:23:02 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 17:23:02 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.75s).
Accumulating evaluation results...
DONE (t=0.37s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.388
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.745
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.339
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.274
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.185
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.462
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.530
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.646
[32m[04/28 17:23:05 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 38.787 | 74.525 | 33.865 | 27.366 | 45.769 | 58.705 |
[32m[04/28 17:23:05 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 41.360 | bicycle       | 21.929 | car            | 53.072 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  26  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 17:23:06 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 17:23:07 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 17:23:07 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 17:23:07 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 17:23:07 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 17:23:07 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 17:23:07 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 17:23:28 d2.utils.events]: [0m eta: 0:17:12  iter: 19  total_loss: 0.537  loss_cls: 0.164  loss_box_reg: 0.320  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 1.0328  data_time: 0.0192  lr: 0.000100  max_mem: 5397M
[32m[04/28 17:23:48 d2.utils.events]: [0m eta: 0:16:25  iter: 39  total_loss: 0.497  loss_cls: 0.151  loss_box_reg: 0.289  loss_rpn_cls: 0.007  loss_rpn_loc: 0.042  time: 1.0145  data_time: 0.0078  lr: 0.000200  max_mem: 5397M
[32m[04/28 17:24:09 d2.utils.events]: [0m eta: 0:16:22  iter: 59  total_loss: 0.427  loss_cls: 0.125  loss_box_reg: 0.254  loss_rpn_cls: 0.006  loss_rpn_loc: 0.040  time: 1.0253  data_time: 0.0078  lr: 0.000300  max_mem: 5397M
[32m[04/28 17:24:29 d2.utils.events]: [0m eta: 0:16:09  iter: 79  total_loss: 0.522  loss_cls: 0.163  loss_box_reg: 0.307  loss_rpn_cls: 0.009  loss_rpn_loc: 0.047  time: 1.0262  data_time: 0.0076  lr: 0.000400  max_mem: 5397M
[32m[04/28 17:24:50 d2.utils.events]: [0m eta: 0:15:48  iter: 99  total_loss: 0.506  loss_cls: 0.145  loss_box_reg: 0.279  loss_rpn_cls: 0.007  loss_rpn_loc: 0.049  time: 1.0259  data_time: 0.0076  lr: 0.000500  max_mem: 5397M
[32m[04/28 17:25:11 d2.utils.events]: [0m eta: 0:15:27  iter: 119  total_loss: 0.500  loss_cls: 0.158  loss_box_reg: 0.292  loss_rpn_cls: 0.008  loss_rpn_loc: 0.047  time: 1.0266  data_time: 0.0079  lr: 0.000599  max_mem: 5397M
[32m[04/28 17:25:31 d2.utils.events]: [0m eta: 0:15:04  iter: 139  total_loss: 0.450  loss_cls: 0.151  loss_box_reg: 0.254  loss_rpn_cls: 0.005  loss_rpn_loc: 0.033  time: 1.0279  data_time: 0.0076  lr: 0.000699  max_mem: 5397M
[32m[04/28 17:25:52 d2.utils.events]: [0m eta: 0:14:43  iter: 159  total_loss: 0.462  loss_cls: 0.141  loss_box_reg: 0.262  loss_rpn_cls: 0.004  loss_rpn_loc: 0.046  time: 1.0293  data_time: 0.0076  lr: 0.000799  max_mem: 5397M
[32m[04/28 17:26:13 d2.utils.events]: [0m eta: 0:14:24  iter: 179  total_loss: 0.447  loss_cls: 0.135  loss_box_reg: 0.261  loss_rpn_cls: 0.004  loss_rpn_loc: 0.044  time: 1.0310  data_time: 0.0078  lr: 0.000899  max_mem: 5397M
[32m[04/28 17:26:34 d2.utils.events]: [0m eta: 0:14:00  iter: 199  total_loss: 0.440  loss_cls: 0.137  loss_box_reg: 0.265  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0310  data_time: 0.0076  lr: 0.000999  max_mem: 5397M
[32m[04/28 17:26:54 d2.utils.events]: [0m eta: 0:13:35  iter: 219  total_loss: 0.420  loss_cls: 0.134  loss_box_reg: 0.243  loss_rpn_cls: 0.007  loss_rpn_loc: 0.036  time: 1.0298  data_time: 0.0076  lr: 0.001099  max_mem: 5397M
[32m[04/28 17:27:15 d2.utils.events]: [0m eta: 0:13:15  iter: 239  total_loss: 0.467  loss_cls: 0.148  loss_box_reg: 0.274  loss_rpn_cls: 0.004  loss_rpn_loc: 0.042  time: 1.0309  data_time: 0.0078  lr: 0.001199  max_mem: 5397M
[32m[04/28 17:27:36 d2.utils.events]: [0m eta: 0:12:52  iter: 259  total_loss: 0.438  loss_cls: 0.138  loss_box_reg: 0.252  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0300  data_time: 0.0077  lr: 0.001299  max_mem: 5397M
[32m[04/28 17:27:57 d2.utils.events]: [0m eta: 0:12:34  iter: 279  total_loss: 0.426  loss_cls: 0.119  loss_box_reg: 0.254  loss_rpn_cls: 0.004  loss_rpn_loc: 0.036  time: 1.0312  data_time: 0.0079  lr: 0.001399  max_mem: 5397M
[32m[04/28 17:28:17 d2.utils.events]: [0m eta: 0:12:13  iter: 299  total_loss: 0.540  loss_cls: 0.171  loss_box_reg: 0.314  loss_rpn_cls: 0.006  loss_rpn_loc: 0.048  time: 1.0316  data_time: 0.0076  lr: 0.001499  max_mem: 5397M
[32m[04/28 17:28:38 d2.utils.events]: [0m eta: 0:11:54  iter: 319  total_loss: 0.563  loss_cls: 0.160  loss_box_reg: 0.323  loss_rpn_cls: 0.006  loss_rpn_loc: 0.044  time: 1.0331  data_time: 0.0080  lr: 0.001598  max_mem: 5397M
[32m[04/28 17:28:59 d2.utils.events]: [0m eta: 0:11:33  iter: 339  total_loss: 0.475  loss_cls: 0.141  loss_box_reg: 0.283  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0337  data_time: 0.0078  lr: 0.001698  max_mem: 5397M
[32m[04/28 17:29:19 d2.utils.events]: [0m eta: 0:11:10  iter: 359  total_loss: 0.428  loss_cls: 0.128  loss_box_reg: 0.266  loss_rpn_cls: 0.005  loss_rpn_loc: 0.037  time: 1.0315  data_time: 0.0076  lr: 0.001798  max_mem: 5397M
[32m[04/28 17:29:40 d2.utils.events]: [0m eta: 0:10:50  iter: 379  total_loss: 0.488  loss_cls: 0.141  loss_box_reg: 0.288  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0323  data_time: 0.0077  lr: 0.001898  max_mem: 5397M
[32m[04/28 17:30:01 d2.utils.events]: [0m eta: 0:10:28  iter: 399  total_loss: 0.483  loss_cls: 0.154  loss_box_reg: 0.273  loss_rpn_cls: 0.003  loss_rpn_loc: 0.043  time: 1.0311  data_time: 0.0076  lr: 0.001998  max_mem: 5397M
[32m[04/28 17:30:22 d2.utils.events]: [0m eta: 0:10:08  iter: 419  total_loss: 0.488  loss_cls: 0.149  loss_box_reg: 0.285  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0322  data_time: 0.0077  lr: 0.002098  max_mem: 5397M
[32m[04/28 17:30:43 d2.utils.events]: [0m eta: 0:09:48  iter: 439  total_loss: 0.507  loss_cls: 0.156  loss_box_reg: 0.283  loss_rpn_cls: 0.005  loss_rpn_loc: 0.049  time: 1.0327  data_time: 0.0078  lr: 0.002198  max_mem: 5397M
[32m[04/28 17:31:03 d2.utils.events]: [0m eta: 0:09:25  iter: 459  total_loss: 0.449  loss_cls: 0.138  loss_box_reg: 0.251  loss_rpn_cls: 0.007  loss_rpn_loc: 0.043  time: 1.0315  data_time: 0.0077  lr: 0.002298  max_mem: 5397M
[32m[04/28 17:31:23 d2.utils.events]: [0m eta: 0:09:04  iter: 479  total_loss: 0.501  loss_cls: 0.149  loss_box_reg: 0.286  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0310  data_time: 0.0078  lr: 0.002398  max_mem: 5397M
[32m[04/28 17:31:44 d2.utils.events]: [0m eta: 0:08:43  iter: 499  total_loss: 0.446  loss_cls: 0.133  loss_box_reg: 0.265  loss_rpn_cls: 0.006  loss_rpn_loc: 0.034  time: 1.0317  data_time: 0.0077  lr: 0.002498  max_mem: 5397M
[32m[04/28 17:32:05 d2.utils.events]: [0m eta: 0:08:22  iter: 519  total_loss: 0.479  loss_cls: 0.153  loss_box_reg: 0.283  loss_rpn_cls: 0.007  loss_rpn_loc: 0.039  time: 1.0314  data_time: 0.0074  lr: 0.002597  max_mem: 5397M
[32m[04/28 17:32:25 d2.utils.events]: [0m eta: 0:08:01  iter: 539  total_loss: 0.452  loss_cls: 0.137  loss_box_reg: 0.253  loss_rpn_cls: 0.004  loss_rpn_loc: 0.034  time: 1.0313  data_time: 0.0076  lr: 0.002697  max_mem: 5397M
[32m[04/28 17:32:46 d2.utils.events]: [0m eta: 0:07:41  iter: 559  total_loss: 0.441  loss_cls: 0.132  loss_box_reg: 0.252  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0319  data_time: 0.0077  lr: 0.002797  max_mem: 5397M
[32m[04/28 17:33:07 d2.utils.events]: [0m eta: 0:07:19  iter: 579  total_loss: 0.485  loss_cls: 0.136  loss_box_reg: 0.284  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 1.0313  data_time: 0.0078  lr: 0.002897  max_mem: 5397M
[32m[04/28 17:33:28 d2.utils.events]: [0m eta: 0:06:59  iter: 599  total_loss: 0.498  loss_cls: 0.142  loss_box_reg: 0.291  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 1.0316  data_time: 0.0078  lr: 0.002997  max_mem: 5397M
[32m[04/28 17:33:49 d2.utils.events]: [0m eta: 0:06:38  iter: 619  total_loss: 0.488  loss_cls: 0.147  loss_box_reg: 0.280  loss_rpn_cls: 0.005  loss_rpn_loc: 0.049  time: 1.0323  data_time: 0.0078  lr: 0.003097  max_mem: 5397M
[32m[04/28 17:34:09 d2.utils.events]: [0m eta: 0:06:17  iter: 639  total_loss: 0.535  loss_cls: 0.159  loss_box_reg: 0.305  loss_rpn_cls: 0.006  loss_rpn_loc: 0.044  time: 1.0323  data_time: 0.0077  lr: 0.003197  max_mem: 5397M
[32m[04/28 17:34:30 d2.utils.events]: [0m eta: 0:05:56  iter: 659  total_loss: 0.534  loss_cls: 0.160  loss_box_reg: 0.305  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0325  data_time: 0.0077  lr: 0.003297  max_mem: 5397M
[32m[04/28 17:34:51 d2.utils.events]: [0m eta: 0:05:35  iter: 679  total_loss: 0.469  loss_cls: 0.148  loss_box_reg: 0.273  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0322  data_time: 0.0078  lr: 0.003397  max_mem: 5397M
[32m[04/28 17:35:11 d2.utils.events]: [0m eta: 0:05:14  iter: 699  total_loss: 0.543  loss_cls: 0.168  loss_box_reg: 0.311  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0321  data_time: 0.0076  lr: 0.003497  max_mem: 5397M
[32m[04/28 17:35:32 d2.utils.events]: [0m eta: 0:04:53  iter: 719  total_loss: 0.502  loss_cls: 0.158  loss_box_reg: 0.300  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0316  data_time: 0.0075  lr: 0.003596  max_mem: 5397M
[32m[04/28 17:35:52 d2.utils.events]: [0m eta: 0:04:32  iter: 739  total_loss: 0.494  loss_cls: 0.152  loss_box_reg: 0.300  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0317  data_time: 0.0077  lr: 0.003696  max_mem: 5397M
[32m[04/28 17:36:13 d2.utils.events]: [0m eta: 0:04:12  iter: 759  total_loss: 0.467  loss_cls: 0.145  loss_box_reg: 0.274  loss_rpn_cls: 0.005  loss_rpn_loc: 0.042  time: 1.0319  data_time: 0.0078  lr: 0.003796  max_mem: 5397M
[32m[04/28 17:36:34 d2.utils.events]: [0m eta: 0:03:51  iter: 779  total_loss: 0.473  loss_cls: 0.142  loss_box_reg: 0.278  loss_rpn_cls: 0.005  loss_rpn_loc: 0.045  time: 1.0313  data_time: 0.0077  lr: 0.003896  max_mem: 5397M
[32m[04/28 17:36:54 d2.utils.events]: [0m eta: 0:03:29  iter: 799  total_loss: 0.437  loss_cls: 0.133  loss_box_reg: 0.258  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0308  data_time: 0.0076  lr: 0.003996  max_mem: 5397M
[32m[04/28 17:37:15 d2.utils.events]: [0m eta: 0:03:08  iter: 819  total_loss: 0.474  loss_cls: 0.139  loss_box_reg: 0.273  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0309  data_time: 0.0080  lr: 0.004096  max_mem: 5397M
[32m[04/28 17:37:35 d2.utils.events]: [0m eta: 0:02:47  iter: 839  total_loss: 0.475  loss_cls: 0.139  loss_box_reg: 0.270  loss_rpn_cls: 0.007  loss_rpn_loc: 0.037  time: 1.0309  data_time: 0.0077  lr: 0.004196  max_mem: 5397M
[32m[04/28 17:37:56 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.495  loss_cls: 0.152  loss_box_reg: 0.282  loss_rpn_cls: 0.006  loss_rpn_loc: 0.053  time: 1.0311  data_time: 0.0076  lr: 0.004296  max_mem: 5397M
[32m[04/28 17:38:17 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.563  loss_cls: 0.172  loss_box_reg: 0.318  loss_rpn_cls: 0.007  loss_rpn_loc: 0.054  time: 1.0312  data_time: 0.0077  lr: 0.004396  max_mem: 5397M
[32m[04/28 17:38:38 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.484  loss_cls: 0.133  loss_box_reg: 0.291  loss_rpn_cls: 0.004  loss_rpn_loc: 0.045  time: 1.0318  data_time: 0.0077  lr: 0.004496  max_mem: 5397M
[32m[04/28 17:38:59 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.458  loss_cls: 0.139  loss_box_reg: 0.283  loss_rpn_cls: 0.006  loss_rpn_loc: 0.039  time: 1.0320  data_time: 0.0075  lr: 0.004595  max_mem: 5397M
[32m[04/28 17:39:19 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.540  loss_cls: 0.156  loss_box_reg: 0.304  loss_rpn_cls: 0.006  loss_rpn_loc: 0.050  time: 1.0318  data_time: 0.0076  lr: 0.004695  max_mem: 5397M
[32m[04/28 17:39:40 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.558  loss_cls: 0.163  loss_box_reg: 0.305  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0313  data_time: 0.0077  lr: 0.004795  max_mem: 5397M
[32m[04/28 17:40:00 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.491  loss_cls: 0.142  loss_box_reg: 0.290  loss_rpn_cls: 0.005  loss_rpn_loc: 0.048  time: 1.0305  data_time: 0.0078  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 17:40:22 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 17:40:22 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 17:40:22 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 17:40:22 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.466  loss_cls: 0.134  loss_box_reg: 0.291  loss_rpn_cls: 0.005  loss_rpn_loc: 0.042  time: 1.0305  data_time: 0.0076  lr: 0.004995  max_mem: 5397M
[32m[04/28 17:40:23 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:08 (1.0315 s / it)
[32m[04/28 17:40:23 d2.engine.hooks]: [0mTotal training time: 0:17:13 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 17:40:24 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 17:40:24 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 17:40:25 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 17:40:26 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1144 s / img. ETA=0:16:05
[32m[04/28 17:40:31 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1142 s / img. ETA=0:16:01
[32m[04/28 17:40:36 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1140 s / img. ETA=0:15:54
[32m[04/28 17:40:42 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1140 s / img. ETA=0:15:49
[32m[04/28 17:40:47 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1139 s / img. ETA=0:15:44
[32m[04/28 17:40:52 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1140 s / img. ETA=0:15:39
[32m[04/28 17:40:57 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1141 s / img. ETA=0:15:35
[32m[04/28 17:41:02 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1141 s / img. ETA=0:15:30
[32m[04/28 17:41:07 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1141 s / img. ETA=0:15:25
[32m[04/28 17:41:12 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1142 s / img. ETA=0:15:20
[32m[04/28 17:41:17 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1142 s / img. ETA=0:15:15
[32m[04/28 17:41:22 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1141 s / img. ETA=0:15:10
[32m[04/28 17:41:27 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1141 s / img. ETA=0:15:04
[32m[04/28 17:41:32 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1141 s / img. ETA=0:14:59
[32m[04/28 17:41:38 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1141 s / img. ETA=0:14:54
[32m[04/28 17:41:43 d2.evaluation.evaluator]: [0mInference done 671/8355. 0.1141 s / img. ETA=0:14:49
[32m[04/28 17:41:48 d2.evaluation.evaluator]: [0mInference done 715/8355. 0.1141 s / img. ETA=0:14:44
[32m[04/28 17:41:53 d2.evaluation.evaluator]: [0mInference done 759/8355. 0.1141 s / img. ETA=0:14:39
[32m[04/28 17:41:58 d2.evaluation.evaluator]: [0mInference done 803/8355. 0.1141 s / img. ETA=0:14:34
[32m[04/28 17:42:03 d2.evaluation.evaluator]: [0mInference done 847/8355. 0.1141 s / img. ETA=0:14:29
[32m[04/28 17:42:08 d2.evaluation.evaluator]: [0mInference done 890/8355. 0.1142 s / img. ETA=0:14:24
[32m[04/28 17:42:13 d2.evaluation.evaluator]: [0mInference done 933/8355. 0.1142 s / img. ETA=0:14:19
[32m[04/28 17:42:18 d2.evaluation.evaluator]: [0mInference done 977/8355. 0.1142 s / img. ETA=0:14:14
[32m[04/28 17:42:23 d2.evaluation.evaluator]: [0mInference done 1021/8355. 0.1142 s / img. ETA=0:14:09
[32m[04/28 17:42:28 d2.evaluation.evaluator]: [0mInference done 1065/8355. 0.1142 s / img. ETA=0:14:04
[32m[04/28 17:42:33 d2.evaluation.evaluator]: [0mInference done 1109/8355. 0.1142 s / img. ETA=0:13:59
[32m[04/28 17:42:38 d2.evaluation.evaluator]: [0mInference done 1153/8355. 0.1142 s / img. ETA=0:13:53
[32m[04/28 17:42:44 d2.evaluation.evaluator]: [0mInference done 1197/8355. 0.1141 s / img. ETA=0:13:48
[32m[04/28 17:42:49 d2.evaluation.evaluator]: [0mInference done 1241/8355. 0.1141 s / img. ETA=0:13:43
[32m[04/28 17:42:54 d2.evaluation.evaluator]: [0mInference done 1285/8355. 0.1141 s / img. ETA=0:13:38
[32m[04/28 17:42:59 d2.evaluation.evaluator]: [0mInference done 1329/8355. 0.1141 s / img. ETA=0:13:33
[32m[04/28 17:43:04 d2.evaluation.evaluator]: [0mInference done 1373/8355. 0.1141 s / img. ETA=0:13:27
[32m[04/28 17:43:09 d2.evaluation.evaluator]: [0mInference done 1417/8355. 0.1141 s / img. ETA=0:13:22
[32m[04/28 17:43:14 d2.evaluation.evaluator]: [0mInference done 1461/8355. 0.1141 s / img. ETA=0:13:17
[32m[04/28 17:43:19 d2.evaluation.evaluator]: [0mInference done 1504/8355. 0.1142 s / img. ETA=0:13:13
[32m[04/28 17:43:24 d2.evaluation.evaluator]: [0mInference done 1547/8355. 0.1142 s / img. ETA=0:13:08
[32m[04/28 17:43:29 d2.evaluation.evaluator]: [0mInference done 1590/8355. 0.1143 s / img. ETA=0:13:04
[32m[04/28 17:43:34 d2.evaluation.evaluator]: [0mInference done 1633/8355. 0.1143 s / img. ETA=0:12:59
[32m[04/28 17:43:39 d2.evaluation.evaluator]: [0mInference done 1676/8355. 0.1143 s / img. ETA=0:12:54
[32m[04/28 17:43:44 d2.evaluation.evaluator]: [0mInference done 1719/8355. 0.1144 s / img. ETA=0:12:49
[32m[04/28 17:43:49 d2.evaluation.evaluator]: [0mInference done 1762/8355. 0.1144 s / img. ETA=0:12:45
[32m[04/28 17:43:55 d2.evaluation.evaluator]: [0mInference done 1805/8355. 0.1144 s / img. ETA=0:12:40
[32m[04/28 17:44:00 d2.evaluation.evaluator]: [0mInference done 1848/8355. 0.1145 s / img. ETA=0:12:35
[32m[04/28 17:44:05 d2.evaluation.evaluator]: [0mInference done 1891/8355. 0.1145 s / img. ETA=0:12:30
[32m[04/28 17:44:10 d2.evaluation.evaluator]: [0mInference done 1934/8355. 0.1145 s / img. ETA=0:12:26
[32m[04/28 17:44:15 d2.evaluation.evaluator]: [0mInference done 1977/8355. 0.1145 s / img. ETA=0:12:21
[32m[04/28 17:44:20 d2.evaluation.evaluator]: [0mInference done 2020/8355. 0.1146 s / img. ETA=0:12:16
[32m[04/28 17:44:25 d2.evaluation.evaluator]: [0mInference done 2063/8355. 0.1146 s / img. ETA=0:12:11
[32m[04/28 17:44:30 d2.evaluation.evaluator]: [0mInference done 2106/8355. 0.1146 s / img. ETA=0:12:06
[32m[04/28 17:44:35 d2.evaluation.evaluator]: [0mInference done 2150/8355. 0.1146 s / img. ETA=0:12:01
[32m[04/28 17:44:40 d2.evaluation.evaluator]: [0mInference done 2193/8355. 0.1146 s / img. ETA=0:11:56
[32m[04/28 17:44:45 d2.evaluation.evaluator]: [0mInference done 2236/8355. 0.1146 s / img. ETA=0:11:51
[32m[04/28 17:44:50 d2.evaluation.evaluator]: [0mInference done 2279/8355. 0.1147 s / img. ETA=0:11:46
[32m[04/28 17:44:55 d2.evaluation.evaluator]: [0mInference done 2322/8355. 0.1147 s / img. ETA=0:11:42
[32m[04/28 17:45:00 d2.evaluation.evaluator]: [0mInference done 2365/8355. 0.1147 s / img. ETA=0:11:37
[32m[04/28 17:45:05 d2.evaluation.evaluator]: [0mInference done 2408/8355. 0.1147 s / img. ETA=0:11:32
[32m[04/28 17:45:10 d2.evaluation.evaluator]: [0mInference done 2451/8355. 0.1147 s / img. ETA=0:11:27
[32m[04/28 17:45:15 d2.evaluation.evaluator]: [0mInference done 2494/8355. 0.1147 s / img. ETA=0:11:22
[32m[04/28 17:45:20 d2.evaluation.evaluator]: [0mInference done 2537/8355. 0.1147 s / img. ETA=0:11:17
[32m[04/28 17:45:25 d2.evaluation.evaluator]: [0mInference done 2580/8355. 0.1148 s / img. ETA=0:11:12
[32m[04/28 17:45:30 d2.evaluation.evaluator]: [0mInference done 2623/8355. 0.1148 s / img. ETA=0:11:07
[32m[04/28 17:45:36 d2.evaluation.evaluator]: [0mInference done 2666/8355. 0.1148 s / img. ETA=0:11:02
[32m[04/28 17:45:41 d2.evaluation.evaluator]: [0mInference done 2709/8355. 0.1148 s / img. ETA=0:10:57
[32m[04/28 17:45:46 d2.evaluation.evaluator]: [0mInference done 2752/8355. 0.1148 s / img. ETA=0:10:53
[32m[04/28 17:45:51 d2.evaluation.evaluator]: [0mInference done 2795/8355. 0.1148 s / img. ETA=0:10:48
[32m[04/28 17:45:56 d2.evaluation.evaluator]: [0mInference done 2838/8355. 0.1148 s / img. ETA=0:10:43
[32m[04/28 17:46:01 d2.evaluation.evaluator]: [0mInference done 2881/8355. 0.1148 s / img. ETA=0:10:38
[32m[04/28 17:46:06 d2.evaluation.evaluator]: [0mInference done 2924/8355. 0.1149 s / img. ETA=0:10:33
[32m[04/28 17:46:11 d2.evaluation.evaluator]: [0mInference done 2967/8355. 0.1149 s / img. ETA=0:10:28
[32m[04/28 17:46:16 d2.evaluation.evaluator]: [0mInference done 3010/8355. 0.1149 s / img. ETA=0:10:23
[32m[04/28 17:46:21 d2.evaluation.evaluator]: [0mInference done 3053/8355. 0.1149 s / img. ETA=0:10:18
[32m[04/28 17:46:26 d2.evaluation.evaluator]: [0mInference done 3096/8355. 0.1149 s / img. ETA=0:10:13
[32m[04/28 17:46:31 d2.evaluation.evaluator]: [0mInference done 3139/8355. 0.1149 s / img. ETA=0:10:08
[32m[04/28 17:46:36 d2.evaluation.evaluator]: [0mInference done 3183/8355. 0.1149 s / img. ETA=0:10:03
[32m[04/28 17:46:41 d2.evaluation.evaluator]: [0mInference done 3227/8355. 0.1149 s / img. ETA=0:09:57
[32m[04/28 17:46:46 d2.evaluation.evaluator]: [0mInference done 3270/8355. 0.1149 s / img. ETA=0:09:52
[32m[04/28 17:46:51 d2.evaluation.evaluator]: [0mInference done 3313/8355. 0.1149 s / img. ETA=0:09:47
[32m[04/28 17:46:56 d2.evaluation.evaluator]: [0mInference done 3357/8355. 0.1149 s / img. ETA=0:09:42
[32m[04/28 17:47:01 d2.evaluation.evaluator]: [0mInference done 3401/8355. 0.1149 s / img. ETA=0:09:37
[32m[04/28 17:47:06 d2.evaluation.evaluator]: [0mInference done 3444/8355. 0.1148 s / img. ETA=0:09:32
[32m[04/28 17:47:11 d2.evaluation.evaluator]: [0mInference done 3487/8355. 0.1148 s / img. ETA=0:09:27
[32m[04/28 17:47:16 d2.evaluation.evaluator]: [0mInference done 3530/8355. 0.1148 s / img. ETA=0:09:22
[32m[04/28 17:47:22 d2.evaluation.evaluator]: [0mInference done 3573/8355. 0.1148 s / img. ETA=0:09:17
[32m[04/28 17:47:27 d2.evaluation.evaluator]: [0mInference done 3616/8355. 0.1148 s / img. ETA=0:09:12
[32m[04/28 17:47:32 d2.evaluation.evaluator]: [0mInference done 3659/8355. 0.1148 s / img. ETA=0:09:07
[32m[04/28 17:47:37 d2.evaluation.evaluator]: [0mInference done 3702/8355. 0.1148 s / img. ETA=0:09:02
[32m[04/28 17:47:42 d2.evaluation.evaluator]: [0mInference done 3745/8355. 0.1149 s / img. ETA=0:08:57
[32m[04/28 17:47:47 d2.evaluation.evaluator]: [0mInference done 3788/8355. 0.1149 s / img. ETA=0:08:52
[32m[04/28 17:47:52 d2.evaluation.evaluator]: [0mInference done 3831/8355. 0.1149 s / img. ETA=0:08:47
[32m[04/28 17:47:57 d2.evaluation.evaluator]: [0mInference done 3874/8355. 0.1149 s / img. ETA=0:08:42
[32m[04/28 17:48:02 d2.evaluation.evaluator]: [0mInference done 3918/8355. 0.1149 s / img. ETA=0:08:37
[32m[04/28 17:48:07 d2.evaluation.evaluator]: [0mInference done 3961/8355. 0.1149 s / img. ETA=0:08:32
[32m[04/28 17:48:12 d2.evaluation.evaluator]: [0mInference done 4004/8355. 0.1149 s / img. ETA=0:08:27
[32m[04/28 17:48:17 d2.evaluation.evaluator]: [0mInference done 4047/8355. 0.1149 s / img. ETA=0:08:22
[32m[04/28 17:48:22 d2.evaluation.evaluator]: [0mInference done 4090/8355. 0.1149 s / img. ETA=0:08:17
[32m[04/28 17:48:27 d2.evaluation.evaluator]: [0mInference done 4133/8355. 0.1149 s / img. ETA=0:08:12
[32m[04/28 17:48:32 d2.evaluation.evaluator]: [0mInference done 4176/8355. 0.1149 s / img. ETA=0:08:07
[32m[04/28 17:48:37 d2.evaluation.evaluator]: [0mInference done 4219/8355. 0.1149 s / img. ETA=0:08:02
[32m[04/28 17:48:42 d2.evaluation.evaluator]: [0mInference done 4263/8355. 0.1149 s / img. ETA=0:07:57
[32m[04/28 17:48:47 d2.evaluation.evaluator]: [0mInference done 4306/8355. 0.1149 s / img. ETA=0:07:52
[32m[04/28 17:48:52 d2.evaluation.evaluator]: [0mInference done 4349/8355. 0.1149 s / img. ETA=0:07:47
[32m[04/28 17:48:57 d2.evaluation.evaluator]: [0mInference done 4392/8355. 0.1149 s / img. ETA=0:07:42
[32m[04/28 17:49:02 d2.evaluation.evaluator]: [0mInference done 4435/8355. 0.1149 s / img. ETA=0:07:37
[32m[04/28 17:49:07 d2.evaluation.evaluator]: [0mInference done 4478/8355. 0.1149 s / img. ETA=0:07:32
[32m[04/28 17:49:12 d2.evaluation.evaluator]: [0mInference done 4521/8355. 0.1149 s / img. ETA=0:07:27
[32m[04/28 17:49:17 d2.evaluation.evaluator]: [0mInference done 4564/8355. 0.1149 s / img. ETA=0:07:22
[32m[04/28 17:49:22 d2.evaluation.evaluator]: [0mInference done 4607/8355. 0.1149 s / img. ETA=0:07:17
[32m[04/28 17:49:28 d2.evaluation.evaluator]: [0mInference done 4650/8355. 0.1149 s / img. ETA=0:07:12
[32m[04/28 17:49:33 d2.evaluation.evaluator]: [0mInference done 4693/8355. 0.1149 s / img. ETA=0:07:07
[32m[04/28 17:49:38 d2.evaluation.evaluator]: [0mInference done 4736/8355. 0.1149 s / img. ETA=0:07:02
[32m[04/28 17:49:43 d2.evaluation.evaluator]: [0mInference done 4779/8355. 0.1149 s / img. ETA=0:06:57
[32m[04/28 17:49:48 d2.evaluation.evaluator]: [0mInference done 4822/8355. 0.1149 s / img. ETA=0:06:52
[32m[04/28 17:49:53 d2.evaluation.evaluator]: [0mInference done 4865/8355. 0.1149 s / img. ETA=0:06:47
[32m[04/28 17:49:58 d2.evaluation.evaluator]: [0mInference done 4909/8355. 0.1149 s / img. ETA=0:06:42
[32m[04/28 17:50:03 d2.evaluation.evaluator]: [0mInference done 4952/8355. 0.1149 s / img. ETA=0:06:37
[32m[04/28 17:50:08 d2.evaluation.evaluator]: [0mInference done 4995/8355. 0.1149 s / img. ETA=0:06:32
[32m[04/28 17:50:13 d2.evaluation.evaluator]: [0mInference done 5038/8355. 0.1149 s / img. ETA=0:06:27
[32m[04/28 17:50:18 d2.evaluation.evaluator]: [0mInference done 5081/8355. 0.1149 s / img. ETA=0:06:22
[32m[04/28 17:50:23 d2.evaluation.evaluator]: [0mInference done 5124/8355. 0.1149 s / img. ETA=0:06:17
[32m[04/28 17:50:28 d2.evaluation.evaluator]: [0mInference done 5167/8355. 0.1149 s / img. ETA=0:06:12
[32m[04/28 17:50:33 d2.evaluation.evaluator]: [0mInference done 5210/8355. 0.1149 s / img. ETA=0:06:07
[32m[04/28 17:50:38 d2.evaluation.evaluator]: [0mInference done 5253/8355. 0.1149 s / img. ETA=0:06:02
[32m[04/28 17:50:43 d2.evaluation.evaluator]: [0mInference done 5296/8355. 0.1149 s / img. ETA=0:05:57
[32m[04/28 17:50:48 d2.evaluation.evaluator]: [0mInference done 5339/8355. 0.1149 s / img. ETA=0:05:52
[32m[04/28 17:50:53 d2.evaluation.evaluator]: [0mInference done 5382/8355. 0.1149 s / img. ETA=0:05:47
[32m[04/28 17:50:58 d2.evaluation.evaluator]: [0mInference done 5425/8355. 0.1149 s / img. ETA=0:05:41
[32m[04/28 17:51:03 d2.evaluation.evaluator]: [0mInference done 5468/8355. 0.1150 s / img. ETA=0:05:36
[32m[04/28 17:51:08 d2.evaluation.evaluator]: [0mInference done 5511/8355. 0.1149 s / img. ETA=0:05:31
[32m[04/28 17:51:13 d2.evaluation.evaluator]: [0mInference done 5555/8355. 0.1149 s / img. ETA=0:05:26
[32m[04/28 17:51:18 d2.evaluation.evaluator]: [0mInference done 5599/8355. 0.1149 s / img. ETA=0:05:21
[32m[04/28 17:51:23 d2.evaluation.evaluator]: [0mInference done 5642/8355. 0.1149 s / img. ETA=0:05:16
[32m[04/28 17:51:29 d2.evaluation.evaluator]: [0mInference done 5685/8355. 0.1149 s / img. ETA=0:05:11
[32m[04/28 17:51:34 d2.evaluation.evaluator]: [0mInference done 5728/8355. 0.1149 s / img. ETA=0:05:06
[32m[04/28 17:51:39 d2.evaluation.evaluator]: [0mInference done 5771/8355. 0.1149 s / img. ETA=0:05:01
[32m[04/28 17:51:44 d2.evaluation.evaluator]: [0mInference done 5814/8355. 0.1150 s / img. ETA=0:04:56
[32m[04/28 17:51:49 d2.evaluation.evaluator]: [0mInference done 5857/8355. 0.1150 s / img. ETA=0:04:51
[32m[04/28 17:51:54 d2.evaluation.evaluator]: [0mInference done 5900/8355. 0.1150 s / img. ETA=0:04:46
[32m[04/28 17:51:59 d2.evaluation.evaluator]: [0mInference done 5942/8355. 0.1150 s / img. ETA=0:04:41
[32m[04/28 17:52:04 d2.evaluation.evaluator]: [0mInference done 5985/8355. 0.1150 s / img. ETA=0:04:36
[32m[04/28 17:52:09 d2.evaluation.evaluator]: [0mInference done 6028/8355. 0.1150 s / img. ETA=0:04:31
[32m[04/28 17:52:14 d2.evaluation.evaluator]: [0mInference done 6071/8355. 0.1150 s / img. ETA=0:04:26
[32m[04/28 17:52:19 d2.evaluation.evaluator]: [0mInference done 6114/8355. 0.1150 s / img. ETA=0:04:21
[32m[04/28 17:52:24 d2.evaluation.evaluator]: [0mInference done 6157/8355. 0.1150 s / img. ETA=0:04:16
[32m[04/28 17:52:29 d2.evaluation.evaluator]: [0mInference done 6200/8355. 0.1151 s / img. ETA=0:04:11
[32m[04/28 17:52:34 d2.evaluation.evaluator]: [0mInference done 6243/8355. 0.1151 s / img. ETA=0:04:06
[32m[04/28 17:52:40 d2.evaluation.evaluator]: [0mInference done 6286/8355. 0.1151 s / img. ETA=0:04:01
[32m[04/28 17:52:45 d2.evaluation.evaluator]: [0mInference done 6329/8355. 0.1151 s / img. ETA=0:03:56
[32m[04/28 17:52:50 d2.evaluation.evaluator]: [0mInference done 6371/8355. 0.1151 s / img. ETA=0:03:51
[32m[04/28 17:52:55 d2.evaluation.evaluator]: [0mInference done 6414/8355. 0.1151 s / img. ETA=0:03:46
[32m[04/28 17:53:00 d2.evaluation.evaluator]: [0mInference done 6457/8355. 0.1151 s / img. ETA=0:03:41
[32m[04/28 17:53:05 d2.evaluation.evaluator]: [0mInference done 6500/8355. 0.1151 s / img. ETA=0:03:36
[32m[04/28 17:53:10 d2.evaluation.evaluator]: [0mInference done 6543/8355. 0.1151 s / img. ETA=0:03:31
[32m[04/28 17:53:15 d2.evaluation.evaluator]: [0mInference done 6586/8355. 0.1151 s / img. ETA=0:03:26
[32m[04/28 17:53:20 d2.evaluation.evaluator]: [0mInference done 6629/8355. 0.1151 s / img. ETA=0:03:21
[32m[04/28 17:53:25 d2.evaluation.evaluator]: [0mInference done 6673/8355. 0.1151 s / img. ETA=0:03:16
[32m[04/28 17:53:30 d2.evaluation.evaluator]: [0mInference done 6717/8355. 0.1151 s / img. ETA=0:03:11
[32m[04/28 17:53:35 d2.evaluation.evaluator]: [0mInference done 6760/8355. 0.1151 s / img. ETA=0:03:06
[32m[04/28 17:53:40 d2.evaluation.evaluator]: [0mInference done 6803/8355. 0.1151 s / img. ETA=0:03:01
[32m[04/28 17:53:45 d2.evaluation.evaluator]: [0mInference done 6846/8355. 0.1151 s / img. ETA=0:02:56
[32m[04/28 17:53:50 d2.evaluation.evaluator]: [0mInference done 6889/8355. 0.1151 s / img. ETA=0:02:51
[32m[04/28 17:53:55 d2.evaluation.evaluator]: [0mInference done 6932/8355. 0.1151 s / img. ETA=0:02:46
[32m[04/28 17:54:00 d2.evaluation.evaluator]: [0mInference done 6975/8355. 0.1151 s / img. ETA=0:02:41
[32m[04/28 17:54:05 d2.evaluation.evaluator]: [0mInference done 7018/8355. 0.1151 s / img. ETA=0:02:36
[32m[04/28 17:54:10 d2.evaluation.evaluator]: [0mInference done 7061/8355. 0.1151 s / img. ETA=0:02:31
[32m[04/28 17:54:15 d2.evaluation.evaluator]: [0mInference done 7103/8355. 0.1151 s / img. ETA=0:02:26
[32m[04/28 17:54:20 d2.evaluation.evaluator]: [0mInference done 7146/8355. 0.1151 s / img. ETA=0:02:21
[32m[04/28 17:54:26 d2.evaluation.evaluator]: [0mInference done 7189/8355. 0.1151 s / img. ETA=0:02:16
[32m[04/28 17:54:31 d2.evaluation.evaluator]: [0mInference done 7232/8355. 0.1151 s / img. ETA=0:02:11
[32m[04/28 17:54:36 d2.evaluation.evaluator]: [0mInference done 7275/8355. 0.1151 s / img. ETA=0:02:06
[32m[04/28 17:54:41 d2.evaluation.evaluator]: [0mInference done 7317/8355. 0.1152 s / img. ETA=0:02:01
[32m[04/28 17:54:46 d2.evaluation.evaluator]: [0mInference done 7360/8355. 0.1152 s / img. ETA=0:01:56
[32m[04/28 17:54:51 d2.evaluation.evaluator]: [0mInference done 7403/8355. 0.1152 s / img. ETA=0:01:51
[32m[04/28 17:54:56 d2.evaluation.evaluator]: [0mInference done 7446/8355. 0.1152 s / img. ETA=0:01:46
[32m[04/28 17:55:01 d2.evaluation.evaluator]: [0mInference done 7489/8355. 0.1152 s / img. ETA=0:01:41
[32m[04/28 17:55:06 d2.evaluation.evaluator]: [0mInference done 7532/8355. 0.1152 s / img. ETA=0:01:36
[32m[04/28 17:55:11 d2.evaluation.evaluator]: [0mInference done 7575/8355. 0.1152 s / img. ETA=0:01:31
[32m[04/28 17:55:16 d2.evaluation.evaluator]: [0mInference done 7618/8355. 0.1152 s / img. ETA=0:01:26
[32m[04/28 17:55:21 d2.evaluation.evaluator]: [0mInference done 7661/8355. 0.1152 s / img. ETA=0:01:21
[32m[04/28 17:55:26 d2.evaluation.evaluator]: [0mInference done 7704/8355. 0.1152 s / img. ETA=0:01:16
[32m[04/28 17:55:31 d2.evaluation.evaluator]: [0mInference done 7747/8355. 0.1152 s / img. ETA=0:01:11
[32m[04/28 17:55:36 d2.evaluation.evaluator]: [0mInference done 7789/8355. 0.1152 s / img. ETA=0:01:06
[32m[04/28 17:55:42 d2.evaluation.evaluator]: [0mInference done 7832/8355. 0.1152 s / img. ETA=0:01:01
[32m[04/28 17:55:47 d2.evaluation.evaluator]: [0mInference done 7875/8355. 0.1152 s / img. ETA=0:00:56
[32m[04/28 17:55:52 d2.evaluation.evaluator]: [0mInference done 7918/8355. 0.1152 s / img. ETA=0:00:51
[32m[04/28 17:55:57 d2.evaluation.evaluator]: [0mInference done 7960/8355. 0.1153 s / img. ETA=0:00:46
[32m[04/28 17:56:02 d2.evaluation.evaluator]: [0mInference done 8003/8355. 0.1153 s / img. ETA=0:00:41
[32m[04/28 17:56:07 d2.evaluation.evaluator]: [0mInference done 8047/8355. 0.1153 s / img. ETA=0:00:36
[32m[04/28 17:56:12 d2.evaluation.evaluator]: [0mInference done 8091/8355. 0.1152 s / img. ETA=0:00:30
[32m[04/28 17:56:17 d2.evaluation.evaluator]: [0mInference done 8135/8355. 0.1152 s / img. ETA=0:00:25
[32m[04/28 17:56:22 d2.evaluation.evaluator]: [0mInference done 8179/8355. 0.1152 s / img. ETA=0:00:20
[32m[04/28 17:56:27 d2.evaluation.evaluator]: [0mInference done 8222/8355. 0.1152 s / img. ETA=0:00:15
[32m[04/28 17:56:32 d2.evaluation.evaluator]: [0mInference done 8265/8355. 0.1152 s / img. ETA=0:00:10
[32m[04/28 17:56:37 d2.evaluation.evaluator]: [0mInference done 8308/8355. 0.1153 s / img. ETA=0:00:05
[32m[04/28 17:56:42 d2.evaluation.evaluator]: [0mInference done 8351/8355. 0.1153 s / img. ETA=0:00:00
[32m[04/28 17:56:43 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:17.409624 (0.117055 s / img per device, on 1 devices)
[32m[04/28 17:56:43 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:02 (0.115252 s / img per device, on 1 devices)
[32m[04/28 17:56:43 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 17:56:43 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 17:56:43 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.43s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.00s).
Accumulating evaluation results...
DONE (t=2.15s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.523
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.880
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.544
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.414
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.647
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.561
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.580
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.489
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.703
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.832
[32m[04/28 17:57:06 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.264 | 87.952 | 54.448 | 41.362 | 64.711 | 78.246 |
[32m[04/28 17:57:06 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 50.621 | bicycle       | 45.810 | car            | 60.362 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 17:57:06 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 17:57:06 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 17:57:07 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 17:57:08 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1153 s / img. ETA=0:02:25
[32m[04/28 17:57:13 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1149 s / img. ETA=0:02:20
[32m[04/28 17:57:18 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1149 s / img. ETA=0:02:15
[32m[04/28 17:57:23 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1149 s / img. ETA=0:02:10
[32m[04/28 17:57:28 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1149 s / img. ETA=0:02:05
[32m[04/28 17:57:33 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1149 s / img. ETA=0:02:00
[32m[04/28 17:57:38 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1150 s / img. ETA=0:01:55
[32m[04/28 17:57:43 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1150 s / img. ETA=0:01:50
[32m[04/28 17:57:48 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1150 s / img. ETA=0:01:45
[32m[04/28 17:57:53 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1150 s / img. ETA=0:01:40
[32m[04/28 17:57:58 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1149 s / img. ETA=0:01:35
[32m[04/28 17:58:03 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1149 s / img. ETA=0:01:30
[32m[04/28 17:58:08 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1150 s / img. ETA=0:01:25
[32m[04/28 17:58:13 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1150 s / img. ETA=0:01:20
[32m[04/28 17:58:18 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1150 s / img. ETA=0:01:15
[32m[04/28 17:58:23 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1150 s / img. ETA=0:01:10
[32m[04/28 17:58:28 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1150 s / img. ETA=0:01:05
[32m[04/28 17:58:33 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1150 s / img. ETA=0:01:00
[32m[04/28 17:58:38 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1150 s / img. ETA=0:00:55
[32m[04/28 17:58:44 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1151 s / img. ETA=0:00:50
[32m[04/28 17:58:49 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1151 s / img. ETA=0:00:45
[32m[04/28 17:58:54 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1152 s / img. ETA=0:00:40
[32m[04/28 17:58:59 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1152 s / img. ETA=0:00:35
[32m[04/28 17:59:04 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1152 s / img. ETA=0:00:30
[32m[04/28 17:59:09 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1152 s / img. ETA=0:00:25
[32m[04/28 17:59:14 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1152 s / img. ETA=0:00:20
[32m[04/28 17:59:19 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1152 s / img. ETA=0:00:14
[32m[04/28 17:59:24 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1153 s / img. ETA=0:00:09
[32m[04/28 17:59:29 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1153 s / img. ETA=0:00:04
[32m[04/28 17:59:34 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.651712 (0.117134 s / img per device, on 1 devices)
[32m[04/28 17:59:34 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115281 s / img per device, on 1 devices)
[32m[04/28 17:59:34 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 17:59:34 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 17:59:34 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.69s).
Accumulating evaluation results...
DONE (t=0.36s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.754
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.365
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.295
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.462
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.475
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.394
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.528
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664
[32m[04/28 17:59:37 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.231 | 75.359 | 36.463 | 29.507 | 46.187 | 59.316 |
[32m[04/28 17:59:37 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 43.632 | bicycle       | 22.563 | car            | 54.498 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  27  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 17:59:38 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 17:59:38 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 17:59:38 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 17:59:39 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 17:59:39 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 17:59:39 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 17:59:39 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 18:00:00 d2.utils.events]: [0m eta: 0:17:30  iter: 19  total_loss: 0.442  loss_cls: 0.139  loss_box_reg: 0.268  loss_rpn_cls: 0.004  loss_rpn_loc: 0.037  time: 1.0443  data_time: 0.0202  lr: 0.000100  max_mem: 5397M
[32m[04/28 18:00:20 d2.utils.events]: [0m eta: 0:16:43  iter: 39  total_loss: 0.542  loss_cls: 0.166  loss_box_reg: 0.295  loss_rpn_cls: 0.006  loss_rpn_loc: 0.049  time: 1.0296  data_time: 0.0077  lr: 0.000200  max_mem: 5397M
[32m[04/28 18:00:41 d2.utils.events]: [0m eta: 0:16:37  iter: 59  total_loss: 0.502  loss_cls: 0.153  loss_box_reg: 0.301  loss_rpn_cls: 0.006  loss_rpn_loc: 0.044  time: 1.0368  data_time: 0.0078  lr: 0.000300  max_mem: 5397M
[32m[04/28 18:01:02 d2.utils.events]: [0m eta: 0:16:16  iter: 79  total_loss: 0.454  loss_cls: 0.148  loss_box_reg: 0.271  loss_rpn_cls: 0.004  loss_rpn_loc: 0.039  time: 1.0381  data_time: 0.0076  lr: 0.000400  max_mem: 5397M
[32m[04/28 18:01:23 d2.utils.events]: [0m eta: 0:15:48  iter: 99  total_loss: 0.445  loss_cls: 0.136  loss_box_reg: 0.256  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0329  data_time: 0.0075  lr: 0.000500  max_mem: 5397M
[32m[04/28 18:01:43 d2.utils.events]: [0m eta: 0:15:23  iter: 119  total_loss: 0.430  loss_cls: 0.137  loss_box_reg: 0.258  loss_rpn_cls: 0.006  loss_rpn_loc: 0.031  time: 1.0323  data_time: 0.0073  lr: 0.000599  max_mem: 5397M
[32m[04/28 18:02:04 d2.utils.events]: [0m eta: 0:15:00  iter: 139  total_loss: 0.496  loss_cls: 0.148  loss_box_reg: 0.288  loss_rpn_cls: 0.005  loss_rpn_loc: 0.042  time: 1.0328  data_time: 0.0072  lr: 0.000699  max_mem: 5397M
[32m[04/28 18:02:24 d2.utils.events]: [0m eta: 0:14:36  iter: 159  total_loss: 0.500  loss_cls: 0.144  loss_box_reg: 0.283  loss_rpn_cls: 0.005  loss_rpn_loc: 0.039  time: 1.0299  data_time: 0.0071  lr: 0.000799  max_mem: 5397M
[32m[04/28 18:02:45 d2.utils.events]: [0m eta: 0:14:16  iter: 179  total_loss: 0.452  loss_cls: 0.138  loss_box_reg: 0.271  loss_rpn_cls: 0.004  loss_rpn_loc: 0.038  time: 1.0308  data_time: 0.0071  lr: 0.000899  max_mem: 5397M
[32m[04/28 18:03:06 d2.utils.events]: [0m eta: 0:13:56  iter: 199  total_loss: 0.450  loss_cls: 0.134  loss_box_reg: 0.271  loss_rpn_cls: 0.003  loss_rpn_loc: 0.039  time: 1.0316  data_time: 0.0073  lr: 0.000999  max_mem: 5397M
[32m[04/28 18:03:26 d2.utils.events]: [0m eta: 0:13:36  iter: 219  total_loss: 0.469  loss_cls: 0.140  loss_box_reg: 0.285  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0311  data_time: 0.0071  lr: 0.001099  max_mem: 5397M
[32m[04/28 18:03:47 d2.utils.events]: [0m eta: 0:13:16  iter: 239  total_loss: 0.436  loss_cls: 0.131  loss_box_reg: 0.264  loss_rpn_cls: 0.003  loss_rpn_loc: 0.034  time: 1.0316  data_time: 0.0072  lr: 0.001199  max_mem: 5397M
[32m[04/28 18:04:08 d2.utils.events]: [0m eta: 0:12:55  iter: 259  total_loss: 0.406  loss_cls: 0.122  loss_box_reg: 0.236  loss_rpn_cls: 0.004  loss_rpn_loc: 0.039  time: 1.0313  data_time: 0.0071  lr: 0.001299  max_mem: 5397M
[32m[04/28 18:04:29 d2.utils.events]: [0m eta: 0:12:34  iter: 279  total_loss: 0.470  loss_cls: 0.132  loss_box_reg: 0.276  loss_rpn_cls: 0.008  loss_rpn_loc: 0.038  time: 1.0318  data_time: 0.0069  lr: 0.001399  max_mem: 5397M
[32m[04/28 18:04:49 d2.utils.events]: [0m eta: 0:12:11  iter: 299  total_loss: 0.462  loss_cls: 0.137  loss_box_reg: 0.286  loss_rpn_cls: 0.003  loss_rpn_loc: 0.039  time: 1.0306  data_time: 0.0070  lr: 0.001499  max_mem: 5397M
[32m[04/28 18:05:09 d2.utils.events]: [0m eta: 0:11:49  iter: 319  total_loss: 0.439  loss_cls: 0.141  loss_box_reg: 0.267  loss_rpn_cls: 0.005  loss_rpn_loc: 0.038  time: 1.0293  data_time: 0.0071  lr: 0.001598  max_mem: 5397M
[32m[04/28 18:05:29 d2.utils.events]: [0m eta: 0:11:24  iter: 339  total_loss: 0.497  loss_cls: 0.147  loss_box_reg: 0.290  loss_rpn_cls: 0.005  loss_rpn_loc: 0.048  time: 1.0273  data_time: 0.0070  lr: 0.001698  max_mem: 5397M
[32m[04/28 18:05:50 d2.utils.events]: [0m eta: 0:11:05  iter: 359  total_loss: 0.497  loss_cls: 0.160  loss_box_reg: 0.285  loss_rpn_cls: 0.006  loss_rpn_loc: 0.048  time: 1.0281  data_time: 0.0071  lr: 0.001798  max_mem: 5397M
[32m[04/28 18:06:11 d2.utils.events]: [0m eta: 0:10:46  iter: 379  total_loss: 0.501  loss_cls: 0.148  loss_box_reg: 0.293  loss_rpn_cls: 0.005  loss_rpn_loc: 0.048  time: 1.0294  data_time: 0.0076  lr: 0.001898  max_mem: 5397M
[32m[04/28 18:06:32 d2.utils.events]: [0m eta: 0:10:26  iter: 399  total_loss: 0.528  loss_cls: 0.159  loss_box_reg: 0.310  loss_rpn_cls: 0.005  loss_rpn_loc: 0.051  time: 1.0306  data_time: 0.0074  lr: 0.001998  max_mem: 5397M
[32m[04/28 18:06:53 d2.utils.events]: [0m eta: 0:10:06  iter: 419  total_loss: 0.465  loss_cls: 0.144  loss_box_reg: 0.275  loss_rpn_cls: 0.003  loss_rpn_loc: 0.039  time: 1.0314  data_time: 0.0074  lr: 0.002098  max_mem: 5397M
[32m[04/28 18:07:14 d2.utils.events]: [0m eta: 0:09:44  iter: 439  total_loss: 0.469  loss_cls: 0.137  loss_box_reg: 0.285  loss_rpn_cls: 0.004  loss_rpn_loc: 0.041  time: 1.0308  data_time: 0.0074  lr: 0.002198  max_mem: 5397M
[32m[04/28 18:07:34 d2.utils.events]: [0m eta: 0:09:23  iter: 459  total_loss: 0.408  loss_cls: 0.114  loss_box_reg: 0.240  loss_rpn_cls: 0.003  loss_rpn_loc: 0.034  time: 1.0300  data_time: 0.0073  lr: 0.002298  max_mem: 5397M
[32m[04/28 18:07:55 d2.utils.events]: [0m eta: 0:09:02  iter: 479  total_loss: 0.444  loss_cls: 0.131  loss_box_reg: 0.266  loss_rpn_cls: 0.004  loss_rpn_loc: 0.035  time: 1.0301  data_time: 0.0073  lr: 0.002398  max_mem: 5397M
[32m[04/28 18:08:16 d2.utils.events]: [0m eta: 0:08:41  iter: 499  total_loss: 0.510  loss_cls: 0.147  loss_box_reg: 0.290  loss_rpn_cls: 0.006  loss_rpn_loc: 0.055  time: 1.0306  data_time: 0.0072  lr: 0.002498  max_mem: 5397M
[32m[04/28 18:08:36 d2.utils.events]: [0m eta: 0:08:20  iter: 519  total_loss: 0.515  loss_cls: 0.150  loss_box_reg: 0.310  loss_rpn_cls: 0.008  loss_rpn_loc: 0.039  time: 1.0296  data_time: 0.0072  lr: 0.002597  max_mem: 5397M
[32m[04/28 18:08:57 d2.utils.events]: [0m eta: 0:08:00  iter: 539  total_loss: 0.447  loss_cls: 0.137  loss_box_reg: 0.269  loss_rpn_cls: 0.004  loss_rpn_loc: 0.041  time: 1.0302  data_time: 0.0073  lr: 0.002697  max_mem: 5397M
[32m[04/28 18:09:17 d2.utils.events]: [0m eta: 0:07:38  iter: 559  total_loss: 0.452  loss_cls: 0.129  loss_box_reg: 0.265  loss_rpn_cls: 0.004  loss_rpn_loc: 0.039  time: 1.0293  data_time: 0.0072  lr: 0.002797  max_mem: 5397M
[32m[04/28 18:09:37 d2.utils.events]: [0m eta: 0:07:17  iter: 579  total_loss: 0.571  loss_cls: 0.175  loss_box_reg: 0.329  loss_rpn_cls: 0.006  loss_rpn_loc: 0.063  time: 1.0290  data_time: 0.0072  lr: 0.002897  max_mem: 5397M
[32m[04/28 18:09:58 d2.utils.events]: [0m eta: 0:06:57  iter: 599  total_loss: 0.450  loss_cls: 0.140  loss_box_reg: 0.260  loss_rpn_cls: 0.004  loss_rpn_loc: 0.045  time: 1.0296  data_time: 0.0071  lr: 0.002997  max_mem: 5397M
[32m[04/28 18:10:20 d2.utils.events]: [0m eta: 0:06:36  iter: 619  total_loss: 0.463  loss_cls: 0.146  loss_box_reg: 0.284  loss_rpn_cls: 0.006  loss_rpn_loc: 0.037  time: 1.0304  data_time: 0.0073  lr: 0.003097  max_mem: 5397M
[32m[04/28 18:10:40 d2.utils.events]: [0m eta: 0:06:15  iter: 639  total_loss: 0.448  loss_cls: 0.133  loss_box_reg: 0.278  loss_rpn_cls: 0.007  loss_rpn_loc: 0.036  time: 1.0301  data_time: 0.0070  lr: 0.003197  max_mem: 5397M
[32m[04/28 18:11:01 d2.utils.events]: [0m eta: 0:05:54  iter: 659  total_loss: 0.465  loss_cls: 0.138  loss_box_reg: 0.283  loss_rpn_cls: 0.003  loss_rpn_loc: 0.041  time: 1.0302  data_time: 0.0074  lr: 0.003297  max_mem: 5397M
[32m[04/28 18:11:21 d2.utils.events]: [0m eta: 0:05:33  iter: 679  total_loss: 0.498  loss_cls: 0.146  loss_box_reg: 0.286  loss_rpn_cls: 0.005  loss_rpn_loc: 0.047  time: 1.0300  data_time: 0.0072  lr: 0.003397  max_mem: 5397M
[32m[04/28 18:11:41 d2.utils.events]: [0m eta: 0:05:12  iter: 699  total_loss: 0.489  loss_cls: 0.143  loss_box_reg: 0.282  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0294  data_time: 0.0073  lr: 0.003497  max_mem: 5397M
[32m[04/28 18:12:02 d2.utils.events]: [0m eta: 0:04:51  iter: 719  total_loss: 0.514  loss_cls: 0.157  loss_box_reg: 0.294  loss_rpn_cls: 0.006  loss_rpn_loc: 0.052  time: 1.0297  data_time: 0.0074  lr: 0.003596  max_mem: 5397M
[32m[04/28 18:12:23 d2.utils.events]: [0m eta: 0:04:31  iter: 739  total_loss: 0.522  loss_cls: 0.140  loss_box_reg: 0.301  loss_rpn_cls: 0.004  loss_rpn_loc: 0.040  time: 1.0299  data_time: 0.0073  lr: 0.003696  max_mem: 5397M
[32m[04/28 18:12:44 d2.utils.events]: [0m eta: 0:04:10  iter: 759  total_loss: 0.435  loss_cls: 0.138  loss_box_reg: 0.250  loss_rpn_cls: 0.004  loss_rpn_loc: 0.039  time: 1.0301  data_time: 0.0072  lr: 0.003796  max_mem: 5397M
[32m[04/28 18:13:04 d2.utils.events]: [0m eta: 0:03:49  iter: 779  total_loss: 0.547  loss_cls: 0.164  loss_box_reg: 0.301  loss_rpn_cls: 0.008  loss_rpn_loc: 0.060  time: 1.0296  data_time: 0.0071  lr: 0.003896  max_mem: 5397M
[32m[04/28 18:13:25 d2.utils.events]: [0m eta: 0:03:28  iter: 799  total_loss: 0.451  loss_cls: 0.133  loss_box_reg: 0.282  loss_rpn_cls: 0.005  loss_rpn_loc: 0.037  time: 1.0297  data_time: 0.0070  lr: 0.003996  max_mem: 5397M
[32m[04/28 18:13:46 d2.utils.events]: [0m eta: 0:03:08  iter: 819  total_loss: 0.533  loss_cls: 0.158  loss_box_reg: 0.314  loss_rpn_cls: 0.007  loss_rpn_loc: 0.042  time: 1.0299  data_time: 0.0075  lr: 0.004096  max_mem: 5397M
[32m[04/28 18:14:06 d2.utils.events]: [0m eta: 0:02:47  iter: 839  total_loss: 0.562  loss_cls: 0.165  loss_box_reg: 0.321  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0298  data_time: 0.0071  lr: 0.004196  max_mem: 5397M
[32m[04/28 18:14:27 d2.utils.events]: [0m eta: 0:02:26  iter: 859  total_loss: 0.484  loss_cls: 0.142  loss_box_reg: 0.279  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 1.0294  data_time: 0.0072  lr: 0.004296  max_mem: 5397M
[32m[04/28 18:14:47 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.452  loss_cls: 0.138  loss_box_reg: 0.270  loss_rpn_cls: 0.005  loss_rpn_loc: 0.037  time: 1.0290  data_time: 0.0072  lr: 0.004396  max_mem: 5397M
[32m[04/28 18:15:07 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.491  loss_cls: 0.135  loss_box_reg: 0.278  loss_rpn_cls: 0.005  loss_rpn_loc: 0.047  time: 1.0286  data_time: 0.0071  lr: 0.004496  max_mem: 5397M
[32m[04/28 18:15:28 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.504  loss_cls: 0.153  loss_box_reg: 0.300  loss_rpn_cls: 0.007  loss_rpn_loc: 0.040  time: 1.0291  data_time: 0.0075  lr: 0.004595  max_mem: 5397M
[32m[04/28 18:15:49 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.447  loss_cls: 0.138  loss_box_reg: 0.260  loss_rpn_cls: 0.005  loss_rpn_loc: 0.035  time: 1.0287  data_time: 0.0074  lr: 0.004695  max_mem: 5397M
[32m[04/28 18:16:09 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.461  loss_cls: 0.147  loss_box_reg: 0.263  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0285  data_time: 0.0073  lr: 0.004795  max_mem: 5397M
[32m[04/28 18:16:30 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.494  loss_cls: 0.154  loss_box_reg: 0.271  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0293  data_time: 0.0072  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 18:16:54 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 18:16:54 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 18:16:54 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 18:16:54 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.503  loss_cls: 0.156  loss_box_reg: 0.292  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 1.0294  data_time: 0.0073  lr: 0.004995  max_mem: 5397M
[32m[04/28 18:16:54 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:07 (1.0305 s / it)
[32m[04/28 18:16:54 d2.engine.hooks]: [0mTotal training time: 0:17:13 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 18:16:56 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 18:16:56 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 18:16:56 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 18:16:58 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1147 s / img. ETA=0:16:09
[32m[04/28 18:17:03 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1144 s / img. ETA=0:16:02
[32m[04/28 18:17:08 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1141 s / img. ETA=0:15:55
[32m[04/28 18:17:13 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1141 s / img. ETA=0:15:50
[32m[04/28 18:17:18 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1141 s / img. ETA=0:15:45
[32m[04/28 18:17:23 d2.evaluation.evaluator]: [0mInference done 230/8355. 0.1142 s / img. ETA=0:15:40
[32m[04/28 18:17:28 d2.evaluation.evaluator]: [0mInference done 273/8355. 0.1142 s / img. ETA=0:15:36
[32m[04/28 18:17:33 d2.evaluation.evaluator]: [0mInference done 316/8355. 0.1143 s / img. ETA=0:15:32
[32m[04/28 18:17:38 d2.evaluation.evaluator]: [0mInference done 360/8355. 0.1143 s / img. ETA=0:15:27
[32m[04/28 18:17:43 d2.evaluation.evaluator]: [0mInference done 403/8355. 0.1144 s / img. ETA=0:15:22
[32m[04/28 18:17:48 d2.evaluation.evaluator]: [0mInference done 446/8355. 0.1144 s / img. ETA=0:15:18
[32m[04/28 18:17:53 d2.evaluation.evaluator]: [0mInference done 490/8355. 0.1144 s / img. ETA=0:15:12
[32m[04/28 18:17:59 d2.evaluation.evaluator]: [0mInference done 534/8355. 0.1144 s / img. ETA=0:15:07
[32m[04/28 18:18:04 d2.evaluation.evaluator]: [0mInference done 578/8355. 0.1143 s / img. ETA=0:15:02
[32m[04/28 18:18:09 d2.evaluation.evaluator]: [0mInference done 622/8355. 0.1143 s / img. ETA=0:14:56
[32m[04/28 18:18:14 d2.evaluation.evaluator]: [0mInference done 665/8355. 0.1144 s / img. ETA=0:14:52
[32m[04/28 18:18:19 d2.evaluation.evaluator]: [0mInference done 708/8355. 0.1145 s / img. ETA=0:14:47
[32m[04/28 18:18:24 d2.evaluation.evaluator]: [0mInference done 751/8355. 0.1145 s / img. ETA=0:14:42
[32m[04/28 18:18:29 d2.evaluation.evaluator]: [0mInference done 794/8355. 0.1145 s / img. ETA=0:14:38
[32m[04/28 18:18:34 d2.evaluation.evaluator]: [0mInference done 837/8355. 0.1145 s / img. ETA=0:14:33
[32m[04/28 18:18:39 d2.evaluation.evaluator]: [0mInference done 880/8355. 0.1145 s / img. ETA=0:14:28
[32m[04/28 18:18:44 d2.evaluation.evaluator]: [0mInference done 923/8355. 0.1146 s / img. ETA=0:14:24
[32m[04/28 18:18:49 d2.evaluation.evaluator]: [0mInference done 966/8355. 0.1146 s / img. ETA=0:14:19
[32m[04/28 18:18:54 d2.evaluation.evaluator]: [0mInference done 1010/8355. 0.1146 s / img. ETA=0:14:13
[32m[04/28 18:18:59 d2.evaluation.evaluator]: [0mInference done 1053/8355. 0.1147 s / img. ETA=0:14:09
[32m[04/28 18:19:04 d2.evaluation.evaluator]: [0mInference done 1097/8355. 0.1146 s / img. ETA=0:14:03
[32m[04/28 18:19:09 d2.evaluation.evaluator]: [0mInference done 1141/8355. 0.1146 s / img. ETA=0:13:58
[32m[04/28 18:19:14 d2.evaluation.evaluator]: [0mInference done 1185/8355. 0.1146 s / img. ETA=0:13:53
[32m[04/28 18:19:19 d2.evaluation.evaluator]: [0mInference done 1229/8355. 0.1145 s / img. ETA=0:13:47
[32m[04/28 18:19:24 d2.evaluation.evaluator]: [0mInference done 1273/8355. 0.1145 s / img. ETA=0:13:42
[32m[04/28 18:19:30 d2.evaluation.evaluator]: [0mInference done 1317/8355. 0.1145 s / img. ETA=0:13:37
[32m[04/28 18:19:35 d2.evaluation.evaluator]: [0mInference done 1361/8355. 0.1145 s / img. ETA=0:13:32
[32m[04/28 18:19:40 d2.evaluation.evaluator]: [0mInference done 1404/8355. 0.1145 s / img. ETA=0:13:27
[32m[04/28 18:19:45 d2.evaluation.evaluator]: [0mInference done 1448/8355. 0.1145 s / img. ETA=0:13:22
[32m[04/28 18:19:50 d2.evaluation.evaluator]: [0mInference done 1491/8355. 0.1146 s / img. ETA=0:13:17
[32m[04/28 18:19:55 d2.evaluation.evaluator]: [0mInference done 1534/8355. 0.1146 s / img. ETA=0:13:12
[32m[04/28 18:20:00 d2.evaluation.evaluator]: [0mInference done 1577/8355. 0.1146 s / img. ETA=0:13:07
[32m[04/28 18:20:05 d2.evaluation.evaluator]: [0mInference done 1620/8355. 0.1147 s / img. ETA=0:13:03
[32m[04/28 18:20:10 d2.evaluation.evaluator]: [0mInference done 1663/8355. 0.1147 s / img. ETA=0:12:58
[32m[04/28 18:20:15 d2.evaluation.evaluator]: [0mInference done 1706/8355. 0.1147 s / img. ETA=0:12:53
[32m[04/28 18:20:20 d2.evaluation.evaluator]: [0mInference done 1749/8355. 0.1148 s / img. ETA=0:12:48
[32m[04/28 18:20:25 d2.evaluation.evaluator]: [0mInference done 1792/8355. 0.1148 s / img. ETA=0:12:44
[32m[04/28 18:20:30 d2.evaluation.evaluator]: [0mInference done 1835/8355. 0.1148 s / img. ETA=0:12:39
[32m[04/28 18:20:35 d2.evaluation.evaluator]: [0mInference done 1878/8355. 0.1149 s / img. ETA=0:12:34
[32m[04/28 18:20:40 d2.evaluation.evaluator]: [0mInference done 1921/8355. 0.1149 s / img. ETA=0:12:29
[32m[04/28 18:20:45 d2.evaluation.evaluator]: [0mInference done 1964/8355. 0.1149 s / img. ETA=0:12:24
[32m[04/28 18:20:51 d2.evaluation.evaluator]: [0mInference done 2007/8355. 0.1149 s / img. ETA=0:12:20
[32m[04/28 18:20:56 d2.evaluation.evaluator]: [0mInference done 2049/8355. 0.1150 s / img. ETA=0:12:15
[32m[04/28 18:21:01 d2.evaluation.evaluator]: [0mInference done 2092/8355. 0.1150 s / img. ETA=0:12:10
[32m[04/28 18:21:06 d2.evaluation.evaluator]: [0mInference done 2135/8355. 0.1150 s / img. ETA=0:12:05
[32m[04/28 18:21:11 d2.evaluation.evaluator]: [0mInference done 2178/8355. 0.1150 s / img. ETA=0:12:00
[32m[04/28 18:21:16 d2.evaluation.evaluator]: [0mInference done 2221/8355. 0.1150 s / img. ETA=0:11:55
[32m[04/28 18:21:21 d2.evaluation.evaluator]: [0mInference done 2264/8355. 0.1150 s / img. ETA=0:11:50
[32m[04/28 18:21:26 d2.evaluation.evaluator]: [0mInference done 2307/8355. 0.1150 s / img. ETA=0:11:45
[32m[04/28 18:21:31 d2.evaluation.evaluator]: [0mInference done 2350/8355. 0.1151 s / img. ETA=0:11:40
[32m[04/28 18:21:36 d2.evaluation.evaluator]: [0mInference done 2393/8355. 0.1151 s / img. ETA=0:11:35
[32m[04/28 18:21:41 d2.evaluation.evaluator]: [0mInference done 2436/8355. 0.1151 s / img. ETA=0:11:30
[32m[04/28 18:21:46 d2.evaluation.evaluator]: [0mInference done 2479/8355. 0.1151 s / img. ETA=0:11:25
[32m[04/28 18:21:51 d2.evaluation.evaluator]: [0mInference done 2522/8355. 0.1151 s / img. ETA=0:11:21
[32m[04/28 18:21:56 d2.evaluation.evaluator]: [0mInference done 2565/8355. 0.1151 s / img. ETA=0:11:16
[32m[04/28 18:22:01 d2.evaluation.evaluator]: [0mInference done 2608/8355. 0.1151 s / img. ETA=0:11:11
[32m[04/28 18:22:06 d2.evaluation.evaluator]: [0mInference done 2651/8355. 0.1151 s / img. ETA=0:11:06
[32m[04/28 18:22:11 d2.evaluation.evaluator]: [0mInference done 2694/8355. 0.1152 s / img. ETA=0:11:01
[32m[04/28 18:22:16 d2.evaluation.evaluator]: [0mInference done 2737/8355. 0.1152 s / img. ETA=0:10:56
[32m[04/28 18:22:21 d2.evaluation.evaluator]: [0mInference done 2780/8355. 0.1152 s / img. ETA=0:10:51
[32m[04/28 18:22:26 d2.evaluation.evaluator]: [0mInference done 2823/8355. 0.1152 s / img. ETA=0:10:46
[32m[04/28 18:22:31 d2.evaluation.evaluator]: [0mInference done 2866/8355. 0.1152 s / img. ETA=0:10:41
[32m[04/28 18:22:37 d2.evaluation.evaluator]: [0mInference done 2909/8355. 0.1152 s / img. ETA=0:10:36
[32m[04/28 18:22:42 d2.evaluation.evaluator]: [0mInference done 2952/8355. 0.1152 s / img. ETA=0:10:31
[32m[04/28 18:22:47 d2.evaluation.evaluator]: [0mInference done 2995/8355. 0.1152 s / img. ETA=0:10:26
[32m[04/28 18:22:52 d2.evaluation.evaluator]: [0mInference done 3038/8355. 0.1152 s / img. ETA=0:10:21
[32m[04/28 18:22:57 d2.evaluation.evaluator]: [0mInference done 3081/8355. 0.1153 s / img. ETA=0:10:16
[32m[04/28 18:23:02 d2.evaluation.evaluator]: [0mInference done 3124/8355. 0.1153 s / img. ETA=0:10:11
[32m[04/28 18:23:07 d2.evaluation.evaluator]: [0mInference done 3168/8355. 0.1153 s / img. ETA=0:10:06
[32m[04/28 18:23:12 d2.evaluation.evaluator]: [0mInference done 3212/8355. 0.1152 s / img. ETA=0:10:01
[32m[04/28 18:23:17 d2.evaluation.evaluator]: [0mInference done 3256/8355. 0.1152 s / img. ETA=0:09:55
[32m[04/28 18:23:22 d2.evaluation.evaluator]: [0mInference done 3300/8355. 0.1152 s / img. ETA=0:09:50
[32m[04/28 18:23:27 d2.evaluation.evaluator]: [0mInference done 3343/8355. 0.1152 s / img. ETA=0:09:45
[32m[04/28 18:23:32 d2.evaluation.evaluator]: [0mInference done 3386/8355. 0.1152 s / img. ETA=0:09:40
[32m[04/28 18:23:37 d2.evaluation.evaluator]: [0mInference done 3429/8355. 0.1152 s / img. ETA=0:09:35
[32m[04/28 18:23:42 d2.evaluation.evaluator]: [0mInference done 3472/8355. 0.1152 s / img. ETA=0:09:30
[32m[04/28 18:23:47 d2.evaluation.evaluator]: [0mInference done 3515/8355. 0.1152 s / img. ETA=0:09:25
[32m[04/28 18:23:52 d2.evaluation.evaluator]: [0mInference done 3559/8355. 0.1152 s / img. ETA=0:09:20
[32m[04/28 18:23:57 d2.evaluation.evaluator]: [0mInference done 3602/8355. 0.1152 s / img. ETA=0:09:15
[32m[04/28 18:24:02 d2.evaluation.evaluator]: [0mInference done 3645/8355. 0.1152 s / img. ETA=0:09:10
[32m[04/28 18:24:08 d2.evaluation.evaluator]: [0mInference done 3688/8355. 0.1152 s / img. ETA=0:09:05
[32m[04/28 18:24:13 d2.evaluation.evaluator]: [0mInference done 3731/8355. 0.1152 s / img. ETA=0:09:00
[32m[04/28 18:24:18 d2.evaluation.evaluator]: [0mInference done 3774/8355. 0.1152 s / img. ETA=0:08:55
[32m[04/28 18:24:23 d2.evaluation.evaluator]: [0mInference done 3817/8355. 0.1152 s / img. ETA=0:08:50
[32m[04/28 18:24:28 d2.evaluation.evaluator]: [0mInference done 3860/8355. 0.1152 s / img. ETA=0:08:45
[32m[04/28 18:24:33 d2.evaluation.evaluator]: [0mInference done 3904/8355. 0.1152 s / img. ETA=0:08:40
[32m[04/28 18:24:38 d2.evaluation.evaluator]: [0mInference done 3947/8355. 0.1152 s / img. ETA=0:08:35
[32m[04/28 18:24:43 d2.evaluation.evaluator]: [0mInference done 3990/8355. 0.1152 s / img. ETA=0:08:30
[32m[04/28 18:24:48 d2.evaluation.evaluator]: [0mInference done 4033/8355. 0.1152 s / img. ETA=0:08:25
[32m[04/28 18:24:53 d2.evaluation.evaluator]: [0mInference done 4076/8355. 0.1152 s / img. ETA=0:08:20
[32m[04/28 18:24:58 d2.evaluation.evaluator]: [0mInference done 4119/8355. 0.1152 s / img. ETA=0:08:15
[32m[04/28 18:25:03 d2.evaluation.evaluator]: [0mInference done 4162/8355. 0.1152 s / img. ETA=0:08:10
[32m[04/28 18:25:08 d2.evaluation.evaluator]: [0mInference done 4205/8355. 0.1152 s / img. ETA=0:08:05
[32m[04/28 18:25:13 d2.evaluation.evaluator]: [0mInference done 4249/8355. 0.1152 s / img. ETA=0:07:59
[32m[04/28 18:25:18 d2.evaluation.evaluator]: [0mInference done 4293/8355. 0.1152 s / img. ETA=0:07:54
[32m[04/28 18:25:23 d2.evaluation.evaluator]: [0mInference done 4336/8355. 0.1153 s / img. ETA=0:07:49
[32m[04/28 18:25:28 d2.evaluation.evaluator]: [0mInference done 4379/8355. 0.1152 s / img. ETA=0:07:44
[32m[04/28 18:25:34 d2.evaluation.evaluator]: [0mInference done 4422/8355. 0.1153 s / img. ETA=0:07:39
[32m[04/28 18:25:39 d2.evaluation.evaluator]: [0mInference done 4465/8355. 0.1153 s / img. ETA=0:07:34
[32m[04/28 18:25:44 d2.evaluation.evaluator]: [0mInference done 4508/8355. 0.1153 s / img. ETA=0:07:29
[32m[04/28 18:25:49 d2.evaluation.evaluator]: [0mInference done 4551/8355. 0.1153 s / img. ETA=0:07:24
[32m[04/28 18:25:54 d2.evaluation.evaluator]: [0mInference done 4594/8355. 0.1153 s / img. ETA=0:07:19
[32m[04/28 18:25:59 d2.evaluation.evaluator]: [0mInference done 4637/8355. 0.1153 s / img. ETA=0:07:14
[32m[04/28 18:26:04 d2.evaluation.evaluator]: [0mInference done 4679/8355. 0.1153 s / img. ETA=0:07:09
[32m[04/28 18:26:09 d2.evaluation.evaluator]: [0mInference done 4722/8355. 0.1153 s / img. ETA=0:07:04
[32m[04/28 18:26:14 d2.evaluation.evaluator]: [0mInference done 4765/8355. 0.1153 s / img. ETA=0:06:59
[32m[04/28 18:26:19 d2.evaluation.evaluator]: [0mInference done 4808/8355. 0.1153 s / img. ETA=0:06:54
[32m[04/28 18:26:24 d2.evaluation.evaluator]: [0mInference done 4851/8355. 0.1153 s / img. ETA=0:06:49
[32m[04/28 18:26:29 d2.evaluation.evaluator]: [0mInference done 4894/8355. 0.1153 s / img. ETA=0:06:44
[32m[04/28 18:26:34 d2.evaluation.evaluator]: [0mInference done 4937/8355. 0.1153 s / img. ETA=0:06:39
[32m[04/28 18:26:39 d2.evaluation.evaluator]: [0mInference done 4980/8355. 0.1153 s / img. ETA=0:06:34
[32m[04/28 18:26:44 d2.evaluation.evaluator]: [0mInference done 5021/8355. 0.1154 s / img. ETA=0:06:30
[32m[04/28 18:26:49 d2.evaluation.evaluator]: [0mInference done 5064/8355. 0.1154 s / img. ETA=0:06:25
[32m[04/28 18:26:54 d2.evaluation.evaluator]: [0mInference done 5107/8355. 0.1154 s / img. ETA=0:06:20
[32m[04/28 18:26:59 d2.evaluation.evaluator]: [0mInference done 5150/8355. 0.1154 s / img. ETA=0:06:15
[32m[04/28 18:27:04 d2.evaluation.evaluator]: [0mInference done 5193/8355. 0.1154 s / img. ETA=0:06:10
[32m[04/28 18:27:09 d2.evaluation.evaluator]: [0mInference done 5236/8355. 0.1154 s / img. ETA=0:06:05
[32m[04/28 18:27:14 d2.evaluation.evaluator]: [0mInference done 5279/8355. 0.1154 s / img. ETA=0:06:00
[32m[04/28 18:27:19 d2.evaluation.evaluator]: [0mInference done 5322/8355. 0.1154 s / img. ETA=0:05:54
[32m[04/28 18:27:25 d2.evaluation.evaluator]: [0mInference done 5365/8355. 0.1154 s / img. ETA=0:05:49
[32m[04/28 18:27:30 d2.evaluation.evaluator]: [0mInference done 5408/8355. 0.1154 s / img. ETA=0:05:44
[32m[04/28 18:27:35 d2.evaluation.evaluator]: [0mInference done 5451/8355. 0.1154 s / img. ETA=0:05:39
[32m[04/28 18:27:40 d2.evaluation.evaluator]: [0mInference done 5494/8355. 0.1154 s / img. ETA=0:05:34
[32m[04/28 18:27:45 d2.evaluation.evaluator]: [0mInference done 5537/8355. 0.1154 s / img. ETA=0:05:29
[32m[04/28 18:27:50 d2.evaluation.evaluator]: [0mInference done 5581/8355. 0.1154 s / img. ETA=0:05:24
[32m[04/28 18:27:55 d2.evaluation.evaluator]: [0mInference done 5624/8355. 0.1154 s / img. ETA=0:05:19
[32m[04/28 18:28:00 d2.evaluation.evaluator]: [0mInference done 5667/8355. 0.1154 s / img. ETA=0:05:14
[32m[04/28 18:28:05 d2.evaluation.evaluator]: [0mInference done 5710/8355. 0.1154 s / img. ETA=0:05:09
[32m[04/28 18:28:10 d2.evaluation.evaluator]: [0mInference done 5753/8355. 0.1154 s / img. ETA=0:05:04
[32m[04/28 18:28:15 d2.evaluation.evaluator]: [0mInference done 5796/8355. 0.1154 s / img. ETA=0:04:59
[32m[04/28 18:28:20 d2.evaluation.evaluator]: [0mInference done 5839/8355. 0.1154 s / img. ETA=0:04:54
[32m[04/28 18:28:25 d2.evaluation.evaluator]: [0mInference done 5881/8355. 0.1154 s / img. ETA=0:04:49
[32m[04/28 18:28:30 d2.evaluation.evaluator]: [0mInference done 5924/8355. 0.1154 s / img. ETA=0:04:44
[32m[04/28 18:28:35 d2.evaluation.evaluator]: [0mInference done 5967/8355. 0.1154 s / img. ETA=0:04:39
[32m[04/28 18:28:40 d2.evaluation.evaluator]: [0mInference done 6010/8355. 0.1155 s / img. ETA=0:04:34
[32m[04/28 18:28:46 d2.evaluation.evaluator]: [0mInference done 6053/8355. 0.1155 s / img. ETA=0:04:29
[32m[04/28 18:28:51 d2.evaluation.evaluator]: [0mInference done 6096/8355. 0.1155 s / img. ETA=0:04:24
[32m[04/28 18:28:56 d2.evaluation.evaluator]: [0mInference done 6139/8355. 0.1155 s / img. ETA=0:04:19
[32m[04/28 18:29:01 d2.evaluation.evaluator]: [0mInference done 6181/8355. 0.1155 s / img. ETA=0:04:14
[32m[04/28 18:29:06 d2.evaluation.evaluator]: [0mInference done 6224/8355. 0.1155 s / img. ETA=0:04:09
[32m[04/28 18:29:11 d2.evaluation.evaluator]: [0mInference done 6267/8355. 0.1155 s / img. ETA=0:04:04
[32m[04/28 18:29:16 d2.evaluation.evaluator]: [0mInference done 6309/8355. 0.1155 s / img. ETA=0:03:59
[32m[04/28 18:29:21 d2.evaluation.evaluator]: [0mInference done 6352/8355. 0.1155 s / img. ETA=0:03:54
[32m[04/28 18:29:26 d2.evaluation.evaluator]: [0mInference done 6395/8355. 0.1155 s / img. ETA=0:03:49
[32m[04/28 18:29:31 d2.evaluation.evaluator]: [0mInference done 6438/8355. 0.1155 s / img. ETA=0:03:44
[32m[04/28 18:29:36 d2.evaluation.evaluator]: [0mInference done 6481/8355. 0.1155 s / img. ETA=0:03:39
[32m[04/28 18:29:41 d2.evaluation.evaluator]: [0mInference done 6525/8355. 0.1155 s / img. ETA=0:03:34
[32m[04/28 18:29:46 d2.evaluation.evaluator]: [0mInference done 6568/8355. 0.1155 s / img. ETA=0:03:29
[32m[04/28 18:29:51 d2.evaluation.evaluator]: [0mInference done 6611/8355. 0.1155 s / img. ETA=0:03:24
[32m[04/28 18:29:56 d2.evaluation.evaluator]: [0mInference done 6654/8355. 0.1155 s / img. ETA=0:03:19
[32m[04/28 18:30:01 d2.evaluation.evaluator]: [0mInference done 6697/8355. 0.1155 s / img. ETA=0:03:14
[32m[04/28 18:30:07 d2.evaluation.evaluator]: [0mInference done 6741/8355. 0.1155 s / img. ETA=0:03:09
[32m[04/28 18:30:12 d2.evaluation.evaluator]: [0mInference done 6784/8355. 0.1155 s / img. ETA=0:03:04
[32m[04/28 18:30:17 d2.evaluation.evaluator]: [0mInference done 6827/8355. 0.1155 s / img. ETA=0:02:59
[32m[04/28 18:30:22 d2.evaluation.evaluator]: [0mInference done 6870/8355. 0.1155 s / img. ETA=0:02:54
[32m[04/28 18:30:27 d2.evaluation.evaluator]: [0mInference done 6913/8355. 0.1155 s / img. ETA=0:02:48
[32m[04/28 18:30:32 d2.evaluation.evaluator]: [0mInference done 6956/8355. 0.1155 s / img. ETA=0:02:43
[32m[04/28 18:30:37 d2.evaluation.evaluator]: [0mInference done 6999/8355. 0.1155 s / img. ETA=0:02:38
[32m[04/28 18:30:42 d2.evaluation.evaluator]: [0mInference done 7042/8355. 0.1155 s / img. ETA=0:02:33
[32m[04/28 18:30:47 d2.evaluation.evaluator]: [0mInference done 7085/8355. 0.1155 s / img. ETA=0:02:28
[32m[04/28 18:30:52 d2.evaluation.evaluator]: [0mInference done 7127/8355. 0.1155 s / img. ETA=0:02:23
[32m[04/28 18:30:57 d2.evaluation.evaluator]: [0mInference done 7170/8355. 0.1156 s / img. ETA=0:02:18
[32m[04/28 18:31:02 d2.evaluation.evaluator]: [0mInference done 7212/8355. 0.1156 s / img. ETA=0:02:13
[32m[04/28 18:31:07 d2.evaluation.evaluator]: [0mInference done 7255/8355. 0.1156 s / img. ETA=0:02:08
[32m[04/28 18:31:12 d2.evaluation.evaluator]: [0mInference done 7298/8355. 0.1156 s / img. ETA=0:02:03
[32m[04/28 18:31:17 d2.evaluation.evaluator]: [0mInference done 7341/8355. 0.1156 s / img. ETA=0:01:58
[32m[04/28 18:31:22 d2.evaluation.evaluator]: [0mInference done 7384/8355. 0.1156 s / img. ETA=0:01:53
[32m[04/28 18:31:27 d2.evaluation.evaluator]: [0mInference done 7427/8355. 0.1156 s / img. ETA=0:01:48
[32m[04/28 18:31:33 d2.evaluation.evaluator]: [0mInference done 7470/8355. 0.1156 s / img. ETA=0:01:43
[32m[04/28 18:31:38 d2.evaluation.evaluator]: [0mInference done 7513/8355. 0.1156 s / img. ETA=0:01:38
[32m[04/28 18:31:43 d2.evaluation.evaluator]: [0mInference done 7556/8355. 0.1156 s / img. ETA=0:01:33
[32m[04/28 18:31:48 d2.evaluation.evaluator]: [0mInference done 7599/8355. 0.1156 s / img. ETA=0:01:28
[32m[04/28 18:31:53 d2.evaluation.evaluator]: [0mInference done 7642/8355. 0.1156 s / img. ETA=0:01:23
[32m[04/28 18:31:58 d2.evaluation.evaluator]: [0mInference done 7684/8355. 0.1156 s / img. ETA=0:01:18
[32m[04/28 18:32:03 d2.evaluation.evaluator]: [0mInference done 7727/8355. 0.1156 s / img. ETA=0:01:13
[32m[04/28 18:32:08 d2.evaluation.evaluator]: [0mInference done 7770/8355. 0.1156 s / img. ETA=0:01:08
[32m[04/28 18:32:13 d2.evaluation.evaluator]: [0mInference done 7813/8355. 0.1156 s / img. ETA=0:01:03
[32m[04/28 18:32:18 d2.evaluation.evaluator]: [0mInference done 7856/8355. 0.1156 s / img. ETA=0:00:58
[32m[04/28 18:32:23 d2.evaluation.evaluator]: [0mInference done 7899/8355. 0.1156 s / img. ETA=0:00:53
[32m[04/28 18:32:28 d2.evaluation.evaluator]: [0mInference done 7942/8355. 0.1156 s / img. ETA=0:00:48
[32m[04/28 18:32:33 d2.evaluation.evaluator]: [0mInference done 7985/8355. 0.1157 s / img. ETA=0:00:43
[32m[04/28 18:32:38 d2.evaluation.evaluator]: [0mInference done 8028/8355. 0.1156 s / img. ETA=0:00:38
[32m[04/28 18:32:43 d2.evaluation.evaluator]: [0mInference done 8071/8355. 0.1156 s / img. ETA=0:00:33
[32m[04/28 18:32:48 d2.evaluation.evaluator]: [0mInference done 8115/8355. 0.1156 s / img. ETA=0:00:28
[32m[04/28 18:32:53 d2.evaluation.evaluator]: [0mInference done 8158/8355. 0.1156 s / img. ETA=0:00:23
[32m[04/28 18:32:59 d2.evaluation.evaluator]: [0mInference done 8201/8355. 0.1156 s / img. ETA=0:00:18
[32m[04/28 18:33:04 d2.evaluation.evaluator]: [0mInference done 8244/8355. 0.1156 s / img. ETA=0:00:13
[32m[04/28 18:33:09 d2.evaluation.evaluator]: [0mInference done 8287/8355. 0.1156 s / img. ETA=0:00:07
[32m[04/28 18:33:14 d2.evaluation.evaluator]: [0mInference done 8330/8355. 0.1156 s / img. ETA=0:00:02
[32m[04/28 18:33:17 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:19.545915 (0.117311 s / img per device, on 1 devices)
[32m[04/28 18:33:17 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:05 (0.115644 s / img per device, on 1 devices)
[32m[04/28 18:33:17 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 18:33:17 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 18:33:17 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.00s).
Accumulating evaluation results...
DONE (t=2.23s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.504
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.857
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.518
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.394
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.641
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.545
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.563
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.467
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.697
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.778
[32m[04/28 18:33:40 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.442 | 85.691 | 51.841 | 39.413 | 64.094 | 74.193 |
[32m[04/28 18:33:40 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 49.401 | bicycle       | 41.577 | car            | 60.348 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 18:33:40 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 18:33:40 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 18:33:40 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 18:33:42 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1151 s / img. ETA=0:02:25
[32m[04/28 18:33:47 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1149 s / img. ETA=0:02:20
[32m[04/28 18:33:52 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1150 s / img. ETA=0:02:15
[32m[04/28 18:33:57 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1149 s / img. ETA=0:02:10
[32m[04/28 18:34:02 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1150 s / img. ETA=0:02:05
[32m[04/28 18:34:07 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1150 s / img. ETA=0:02:00
[32m[04/28 18:34:12 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1150 s / img. ETA=0:01:55
[32m[04/28 18:34:17 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1150 s / img. ETA=0:01:50
[32m[04/28 18:34:22 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1150 s / img. ETA=0:01:45
[32m[04/28 18:34:27 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1150 s / img. ETA=0:01:40
[32m[04/28 18:34:32 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1150 s / img. ETA=0:01:35
[32m[04/28 18:34:37 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1149 s / img. ETA=0:01:30
[32m[04/28 18:34:42 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1150 s / img. ETA=0:01:25
[32m[04/28 18:34:47 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1150 s / img. ETA=0:01:20
[32m[04/28 18:34:52 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1150 s / img. ETA=0:01:15
[32m[04/28 18:34:57 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1150 s / img. ETA=0:01:10
[32m[04/28 18:35:02 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1150 s / img. ETA=0:01:05
[32m[04/28 18:35:07 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1151 s / img. ETA=0:01:00
[32m[04/28 18:35:12 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1151 s / img. ETA=0:00:55
[32m[04/28 18:35:17 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1151 s / img. ETA=0:00:50
[32m[04/28 18:35:22 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1152 s / img. ETA=0:00:45
[32m[04/28 18:35:27 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1152 s / img. ETA=0:00:40
[32m[04/28 18:35:32 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1152 s / img. ETA=0:00:35
[32m[04/28 18:35:37 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1152 s / img. ETA=0:00:30
[32m[04/28 18:35:43 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1153 s / img. ETA=0:00:25
[32m[04/28 18:35:48 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1153 s / img. ETA=0:00:20
[32m[04/28 18:35:53 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1154 s / img. ETA=0:00:14
[32m[04/28 18:35:58 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1154 s / img. ETA=0:00:09
[32m[04/28 18:36:03 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1154 s / img. ETA=0:00:04
[32m[04/28 18:36:08 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.698925 (0.117172 s / img per device, on 1 devices)
[32m[04/28 18:36:08 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115442 s / img per device, on 1 devices)
[32m[04/28 18:36:08 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 18:36:08 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 18:36:08 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.23s).
Accumulating evaluation results...
DONE (t=0.36s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.727
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.335
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.274
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.434
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.548
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.174
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.442
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.496
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.584
[32m[04/28 18:36:12 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 37.666 | 72.671 | 33.513 | 27.395 | 43.361 | 54.763 |
[32m[04/28 18:36:12 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 40.737 | bicycle       | 17.409 | car            | 54.853 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  28  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 18:36:12 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 18:36:13 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 18:36:13 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 18:36:13 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 18:36:13 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 18:36:13 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 18:36:14 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 18:36:35 d2.utils.events]: [0m eta: 0:17:13  iter: 19  total_loss: 0.537  loss_cls: 0.158  loss_box_reg: 0.309  loss_rpn_cls: 0.010  loss_rpn_loc: 0.058  time: 1.0307  data_time: 0.0186  lr: 0.000100  max_mem: 5397M
[32m[04/28 18:36:55 d2.utils.events]: [0m eta: 0:16:31  iter: 39  total_loss: 0.466  loss_cls: 0.149  loss_box_reg: 0.267  loss_rpn_cls: 0.005  loss_rpn_loc: 0.034  time: 1.0267  data_time: 0.0074  lr: 0.000200  max_mem: 5397M
[32m[04/28 18:37:16 d2.utils.events]: [0m eta: 0:16:03  iter: 59  total_loss: 0.491  loss_cls: 0.145  loss_box_reg: 0.288  loss_rpn_cls: 0.007  loss_rpn_loc: 0.038  time: 1.0241  data_time: 0.0073  lr: 0.000300  max_mem: 5397M
[32m[04/28 18:37:36 d2.utils.events]: [0m eta: 0:15:42  iter: 79  total_loss: 0.463  loss_cls: 0.148  loss_box_reg: 0.273  loss_rpn_cls: 0.004  loss_rpn_loc: 0.034  time: 1.0224  data_time: 0.0072  lr: 0.000400  max_mem: 5397M
[32m[04/28 18:37:57 d2.utils.events]: [0m eta: 0:15:25  iter: 99  total_loss: 0.451  loss_cls: 0.139  loss_box_reg: 0.281  loss_rpn_cls: 0.005  loss_rpn_loc: 0.036  time: 1.0253  data_time: 0.0074  lr: 0.000500  max_mem: 5397M
[32m[04/28 18:38:18 d2.utils.events]: [0m eta: 0:15:07  iter: 119  total_loss: 0.502  loss_cls: 0.148  loss_box_reg: 0.297  loss_rpn_cls: 0.007  loss_rpn_loc: 0.051  time: 1.0265  data_time: 0.0074  lr: 0.000599  max_mem: 5397M
[32m[04/28 18:38:38 d2.utils.events]: [0m eta: 0:14:43  iter: 139  total_loss: 0.505  loss_cls: 0.151  loss_box_reg: 0.307  loss_rpn_cls: 0.004  loss_rpn_loc: 0.046  time: 1.0232  data_time: 0.0073  lr: 0.000699  max_mem: 5397M
[32m[04/28 18:38:59 d2.utils.events]: [0m eta: 0:14:31  iter: 159  total_loss: 0.505  loss_cls: 0.148  loss_box_reg: 0.293  loss_rpn_cls: 0.006  loss_rpn_loc: 0.040  time: 1.0291  data_time: 0.0074  lr: 0.000799  max_mem: 5397M
[32m[04/28 18:39:20 d2.utils.events]: [0m eta: 0:14:15  iter: 179  total_loss: 0.502  loss_cls: 0.153  loss_box_reg: 0.301  loss_rpn_cls: 0.004  loss_rpn_loc: 0.044  time: 1.0309  data_time: 0.0073  lr: 0.000899  max_mem: 5397M
[32m[04/28 18:39:40 d2.utils.events]: [0m eta: 0:13:50  iter: 199  total_loss: 0.457  loss_cls: 0.140  loss_box_reg: 0.274  loss_rpn_cls: 0.003  loss_rpn_loc: 0.037  time: 1.0282  data_time: 0.0072  lr: 0.000999  max_mem: 5397M
[32m[04/28 18:40:01 d2.utils.events]: [0m eta: 0:13:27  iter: 219  total_loss: 0.429  loss_cls: 0.138  loss_box_reg: 0.253  loss_rpn_cls: 0.004  loss_rpn_loc: 0.041  time: 1.0279  data_time: 0.0074  lr: 0.001099  max_mem: 5397M
[32m[04/28 18:40:22 d2.utils.events]: [0m eta: 0:13:08  iter: 239  total_loss: 0.470  loss_cls: 0.142  loss_box_reg: 0.278  loss_rpn_cls: 0.004  loss_rpn_loc: 0.042  time: 1.0292  data_time: 0.0073  lr: 0.001199  max_mem: 5397M
[32m[04/28 18:40:43 d2.utils.events]: [0m eta: 0:12:49  iter: 259  total_loss: 0.472  loss_cls: 0.141  loss_box_reg: 0.276  loss_rpn_cls: 0.004  loss_rpn_loc: 0.046  time: 1.0302  data_time: 0.0073  lr: 0.001299  max_mem: 5397M
[32m[04/28 18:41:04 d2.utils.events]: [0m eta: 0:12:31  iter: 279  total_loss: 0.537  loss_cls: 0.153  loss_box_reg: 0.311  loss_rpn_cls: 0.004  loss_rpn_loc: 0.053  time: 1.0324  data_time: 0.0075  lr: 0.001399  max_mem: 5397M
[32m[04/28 18:41:25 d2.utils.events]: [0m eta: 0:12:08  iter: 299  total_loss: 0.470  loss_cls: 0.145  loss_box_reg: 0.275  loss_rpn_cls: 0.004  loss_rpn_loc: 0.049  time: 1.0319  data_time: 0.0076  lr: 0.001499  max_mem: 5397M
[32m[04/28 18:41:45 d2.utils.events]: [0m eta: 0:11:47  iter: 319  total_loss: 0.398  loss_cls: 0.125  loss_box_reg: 0.237  loss_rpn_cls: 0.003  loss_rpn_loc: 0.041  time: 1.0310  data_time: 0.0072  lr: 0.001598  max_mem: 5397M
[32m[04/28 18:42:05 d2.utils.events]: [0m eta: 0:11:24  iter: 339  total_loss: 0.480  loss_cls: 0.148  loss_box_reg: 0.289  loss_rpn_cls: 0.005  loss_rpn_loc: 0.038  time: 1.0303  data_time: 0.0075  lr: 0.001698  max_mem: 5397M
[32m[04/28 18:42:26 d2.utils.events]: [0m eta: 0:11:05  iter: 359  total_loss: 0.459  loss_cls: 0.150  loss_box_reg: 0.277  loss_rpn_cls: 0.003  loss_rpn_loc: 0.039  time: 1.0313  data_time: 0.0074  lr: 0.001798  max_mem: 5397M
[32m[04/28 18:42:47 d2.utils.events]: [0m eta: 0:10:43  iter: 379  total_loss: 0.437  loss_cls: 0.126  loss_box_reg: 0.255  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0311  data_time: 0.0072  lr: 0.001898  max_mem: 5397M
[32m[04/28 18:43:08 d2.utils.events]: [0m eta: 0:10:21  iter: 399  total_loss: 0.457  loss_cls: 0.139  loss_box_reg: 0.270  loss_rpn_cls: 0.004  loss_rpn_loc: 0.045  time: 1.0310  data_time: 0.0076  lr: 0.001998  max_mem: 5397M
[32m[04/28 18:43:28 d2.utils.events]: [0m eta: 0:09:59  iter: 419  total_loss: 0.505  loss_cls: 0.151  loss_box_reg: 0.295  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 1.0297  data_time: 0.0071  lr: 0.002098  max_mem: 5397M
[32m[04/28 18:43:48 d2.utils.events]: [0m eta: 0:09:39  iter: 439  total_loss: 0.463  loss_cls: 0.133  loss_box_reg: 0.284  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0298  data_time: 0.0074  lr: 0.002198  max_mem: 5397M
[32m[04/28 18:44:09 d2.utils.events]: [0m eta: 0:09:18  iter: 459  total_loss: 0.488  loss_cls: 0.147  loss_box_reg: 0.280  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0293  data_time: 0.0074  lr: 0.002298  max_mem: 5397M
[32m[04/28 18:44:29 d2.utils.events]: [0m eta: 0:08:56  iter: 479  total_loss: 0.484  loss_cls: 0.141  loss_box_reg: 0.264  loss_rpn_cls: 0.007  loss_rpn_loc: 0.045  time: 1.0281  data_time: 0.0075  lr: 0.002398  max_mem: 5397M
[32m[04/28 18:44:50 d2.utils.events]: [0m eta: 0:08:37  iter: 499  total_loss: 0.503  loss_cls: 0.148  loss_box_reg: 0.297  loss_rpn_cls: 0.003  loss_rpn_loc: 0.045  time: 1.0293  data_time: 0.0074  lr: 0.002498  max_mem: 5397M
[32m[04/28 18:45:11 d2.utils.events]: [0m eta: 0:08:17  iter: 519  total_loss: 0.471  loss_cls: 0.141  loss_box_reg: 0.288  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0300  data_time: 0.0075  lr: 0.002597  max_mem: 5397M
[32m[04/28 18:45:32 d2.utils.events]: [0m eta: 0:07:56  iter: 539  total_loss: 0.454  loss_cls: 0.138  loss_box_reg: 0.272  loss_rpn_cls: 0.004  loss_rpn_loc: 0.041  time: 1.0304  data_time: 0.0076  lr: 0.002697  max_mem: 5397M
[32m[04/28 18:45:52 d2.utils.events]: [0m eta: 0:07:35  iter: 559  total_loss: 0.458  loss_cls: 0.138  loss_box_reg: 0.261  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0296  data_time: 0.0071  lr: 0.002797  max_mem: 5397M
[32m[04/28 18:46:13 d2.utils.events]: [0m eta: 0:07:15  iter: 579  total_loss: 0.455  loss_cls: 0.137  loss_box_reg: 0.278  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0298  data_time: 0.0072  lr: 0.002897  max_mem: 5397M
[32m[04/28 18:46:33 d2.utils.events]: [0m eta: 0:06:54  iter: 599  total_loss: 0.505  loss_cls: 0.145  loss_box_reg: 0.278  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0293  data_time: 0.0071  lr: 0.002997  max_mem: 5397M
[32m[04/28 18:46:53 d2.utils.events]: [0m eta: 0:06:32  iter: 619  total_loss: 0.455  loss_cls: 0.131  loss_box_reg: 0.276  loss_rpn_cls: 0.005  loss_rpn_loc: 0.049  time: 1.0282  data_time: 0.0071  lr: 0.003097  max_mem: 5397M
[32m[04/28 18:47:14 d2.utils.events]: [0m eta: 0:06:11  iter: 639  total_loss: 0.463  loss_cls: 0.135  loss_box_reg: 0.272  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0280  data_time: 0.0073  lr: 0.003197  max_mem: 5397M
[32m[04/28 18:47:35 d2.utils.events]: [0m eta: 0:05:51  iter: 659  total_loss: 0.454  loss_cls: 0.142  loss_box_reg: 0.273  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0288  data_time: 0.0077  lr: 0.003297  max_mem: 5397M
[32m[04/28 18:47:56 d2.utils.events]: [0m eta: 0:05:31  iter: 679  total_loss: 0.487  loss_cls: 0.150  loss_box_reg: 0.283  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0293  data_time: 0.0073  lr: 0.003397  max_mem: 5397M
[32m[04/28 18:48:17 d2.utils.events]: [0m eta: 0:05:11  iter: 699  total_loss: 0.477  loss_cls: 0.149  loss_box_reg: 0.291  loss_rpn_cls: 0.006  loss_rpn_loc: 0.050  time: 1.0297  data_time: 0.0072  lr: 0.003497  max_mem: 5397M
[32m[04/28 18:48:38 d2.utils.events]: [0m eta: 0:04:50  iter: 719  total_loss: 0.479  loss_cls: 0.145  loss_box_reg: 0.285  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0300  data_time: 0.0072  lr: 0.003596  max_mem: 5397M
[32m[04/28 18:48:59 d2.utils.events]: [0m eta: 0:04:29  iter: 739  total_loss: 0.500  loss_cls: 0.143  loss_box_reg: 0.304  loss_rpn_cls: 0.008  loss_rpn_loc: 0.043  time: 1.0303  data_time: 0.0073  lr: 0.003696  max_mem: 5397M
[32m[04/28 18:49:19 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.481  loss_cls: 0.148  loss_box_reg: 0.277  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0300  data_time: 0.0073  lr: 0.003796  max_mem: 5397M
[32m[04/28 18:49:40 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.481  loss_cls: 0.135  loss_box_reg: 0.271  loss_rpn_cls: 0.004  loss_rpn_loc: 0.045  time: 1.0300  data_time: 0.0072  lr: 0.003896  max_mem: 5397M
[32m[04/28 18:50:00 d2.utils.events]: [0m eta: 0:03:27  iter: 799  total_loss: 0.475  loss_cls: 0.135  loss_box_reg: 0.274  loss_rpn_cls: 0.005  loss_rpn_loc: 0.046  time: 1.0297  data_time: 0.0074  lr: 0.003996  max_mem: 5397M
[32m[04/28 18:50:21 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.485  loss_cls: 0.145  loss_box_reg: 0.286  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0301  data_time: 0.0072  lr: 0.004096  max_mem: 5397M
[32m[04/28 18:50:42 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.526  loss_cls: 0.162  loss_box_reg: 0.301  loss_rpn_cls: 0.006  loss_rpn_loc: 0.048  time: 1.0302  data_time: 0.0074  lr: 0.004196  max_mem: 5397M
[32m[04/28 18:51:02 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.485  loss_cls: 0.146  loss_box_reg: 0.281  loss_rpn_cls: 0.004  loss_rpn_loc: 0.051  time: 1.0300  data_time: 0.0074  lr: 0.004296  max_mem: 5397M
[32m[04/28 18:51:23 d2.utils.events]: [0m eta: 0:02:04  iter: 879  total_loss: 0.468  loss_cls: 0.148  loss_box_reg: 0.270  loss_rpn_cls: 0.004  loss_rpn_loc: 0.049  time: 1.0298  data_time: 0.0075  lr: 0.004396  max_mem: 5397M
[32m[04/28 18:51:43 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.510  loss_cls: 0.160  loss_box_reg: 0.291  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 1.0296  data_time: 0.0075  lr: 0.004496  max_mem: 5397M
[32m[04/28 18:52:04 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.521  loss_cls: 0.161  loss_box_reg: 0.301  loss_rpn_cls: 0.008  loss_rpn_loc: 0.052  time: 1.0300  data_time: 0.0074  lr: 0.004595  max_mem: 5397M
[32m[04/28 18:52:25 d2.utils.events]: [0m eta: 0:01:02  iter: 939  total_loss: 0.558  loss_cls: 0.167  loss_box_reg: 0.317  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 1.0303  data_time: 0.0071  lr: 0.004695  max_mem: 5397M
[32m[04/28 18:52:46 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.495  loss_cls: 0.141  loss_box_reg: 0.293  loss_rpn_cls: 0.006  loss_rpn_loc: 0.039  time: 1.0300  data_time: 0.0069  lr: 0.004795  max_mem: 5397M
[32m[04/28 18:53:06 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.464  loss_cls: 0.149  loss_box_reg: 0.280  loss_rpn_cls: 0.005  loss_rpn_loc: 0.037  time: 1.0301  data_time: 0.0070  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 18:53:37 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 18:53:37 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 18:53:39 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 18:53:39 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.452  loss_cls: 0.136  loss_box_reg: 0.257  loss_rpn_cls: 0.005  loss_rpn_loc: 0.035  time: 1.0298  data_time: 0.0545  lr: 0.004995  max_mem: 5397M
[32m[04/28 18:53:41 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:07 (1.0309 s / it)
[32m[04/28 18:53:41 d2.engine.hooks]: [0mTotal training time: 0:17:24 (0:00:16 on hooks)
[5m[31mWARNING[0m [32m[04/28 18:53:43 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 18:53:43 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 18:53:44 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 18:53:47 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1143 s / img. ETA=0:20:51
[32m[04/28 18:53:52 d2.evaluation.evaluator]: [0mInference done 44/8355. 0.1153 s / img. ETA=0:21:19
[32m[04/28 18:53:57 d2.evaluation.evaluator]: [0mInference done 75/8355. 0.1147 s / img. ETA=0:21:47
[32m[04/28 18:54:02 d2.evaluation.evaluator]: [0mInference done 107/8355. 0.1145 s / img. ETA=0:21:38
[32m[04/28 18:54:08 d2.evaluation.evaluator]: [0mInference done 132/8355. 0.1144 s / img. ETA=0:22:58
[32m[04/28 18:54:13 d2.evaluation.evaluator]: [0mInference done 152/8355. 0.1143 s / img. ETA=0:24:31
[32m[04/28 18:54:18 d2.evaluation.evaluator]: [0mInference done 172/8355. 0.1142 s / img. ETA=0:25:41
[32m[04/28 18:54:23 d2.evaluation.evaluator]: [0mInference done 206/8355. 0.1141 s / img. ETA=0:24:45
[32m[04/28 18:54:28 d2.evaluation.evaluator]: [0mInference done 237/8355. 0.1141 s / img. ETA=0:24:17
[32m[04/28 18:54:33 d2.evaluation.evaluator]: [0mInference done 278/8355. 0.1142 s / img. ETA=0:23:02
[32m[04/28 18:54:38 d2.evaluation.evaluator]: [0mInference done 309/8355. 0.1142 s / img. ETA=0:22:50
[32m[04/28 18:54:43 d2.evaluation.evaluator]: [0mInference done 344/8355. 0.1142 s / img. ETA=0:22:23
[32m[04/28 18:54:48 d2.evaluation.evaluator]: [0mInference done 387/8355. 0.1143 s / img. ETA=0:21:31
[32m[04/28 18:54:53 d2.evaluation.evaluator]: [0mInference done 419/8355. 0.1143 s / img. ETA=0:21:23
[32m[04/28 18:54:58 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1143 s / img. ETA=0:21:17
[32m[04/28 18:55:04 d2.evaluation.evaluator]: [0mInference done 486/8355. 0.1143 s / img. ETA=0:21:02
[32m[04/28 18:55:09 d2.evaluation.evaluator]: [0mInference done 515/8355. 0.1142 s / img. ETA=0:21:08
[32m[04/28 18:55:14 d2.evaluation.evaluator]: [0mInference done 540/8355. 0.1142 s / img. ETA=0:21:19
[32m[04/28 18:55:19 d2.evaluation.evaluator]: [0mInference done 575/8355. 0.1142 s / img. ETA=0:21:04
[32m[04/28 18:55:24 d2.evaluation.evaluator]: [0mInference done 616/8355. 0.1142 s / img. ETA=0:20:37
[32m[04/28 18:55:29 d2.evaluation.evaluator]: [0mInference done 660/8355. 0.1142 s / img. ETA=0:20:08
[32m[04/28 18:55:34 d2.evaluation.evaluator]: [0mInference done 696/8355. 0.1142 s / img. ETA=0:19:56
[32m[04/28 18:55:39 d2.evaluation.evaluator]: [0mInference done 738/8355. 0.1143 s / img. ETA=0:19:34
[32m[04/28 18:55:44 d2.evaluation.evaluator]: [0mInference done 771/8355. 0.1142 s / img. ETA=0:19:28
[32m[04/28 18:55:49 d2.evaluation.evaluator]: [0mInference done 810/8355. 0.1143 s / img. ETA=0:19:14
[32m[04/28 18:55:55 d2.evaluation.evaluator]: [0mInference done 852/8355. 0.1142 s / img. ETA=0:18:55
[32m[04/28 18:56:00 d2.evaluation.evaluator]: [0mInference done 892/8355. 0.1143 s / img. ETA=0:18:41
[32m[04/28 18:56:05 d2.evaluation.evaluator]: [0mInference done 930/8355. 0.1143 s / img. ETA=0:18:29
[32m[04/28 18:56:10 d2.evaluation.evaluator]: [0mInference done 972/8355. 0.1143 s / img. ETA=0:18:16
[32m[04/28 18:56:15 d2.evaluation.evaluator]: [0mInference done 1012/8355. 0.1143 s / img. ETA=0:18:03
[32m[04/28 18:56:20 d2.evaluation.evaluator]: [0mInference done 1056/8355. 0.1142 s / img. ETA=0:17:47
[32m[04/28 18:56:25 d2.evaluation.evaluator]: [0mInference done 1099/8355. 0.1142 s / img. ETA=0:17:33
[32m[04/28 18:56:30 d2.evaluation.evaluator]: [0mInference done 1141/8355. 0.1142 s / img. ETA=0:17:20
[32m[04/28 18:56:35 d2.evaluation.evaluator]: [0mInference done 1180/8355. 0.1141 s / img. ETA=0:17:12
[32m[04/28 18:56:40 d2.evaluation.evaluator]: [0mInference done 1221/8355. 0.1141 s / img. ETA=0:17:01
[32m[04/28 18:56:46 d2.evaluation.evaluator]: [0mInference done 1265/8355. 0.1141 s / img. ETA=0:16:48
[32m[04/28 18:56:51 d2.evaluation.evaluator]: [0mInference done 1306/8355. 0.1140 s / img. ETA=0:16:38
[32m[04/28 18:56:56 d2.evaluation.evaluator]: [0mInference done 1347/8355. 0.1140 s / img. ETA=0:16:28
[32m[04/28 18:57:01 d2.evaluation.evaluator]: [0mInference done 1391/8355. 0.1140 s / img. ETA=0:16:16
[32m[04/28 18:57:06 d2.evaluation.evaluator]: [0mInference done 1435/8355. 0.1140 s / img. ETA=0:16:05
[32m[04/28 18:57:11 d2.evaluation.evaluator]: [0mInference done 1470/8355. 0.1140 s / img. ETA=0:16:01
[32m[04/28 18:57:16 d2.evaluation.evaluator]: [0mInference done 1512/8355. 0.1141 s / img. ETA=0:15:51
[32m[04/28 18:57:21 d2.evaluation.evaluator]: [0mInference done 1547/8355. 0.1141 s / img. ETA=0:15:47
[32m[04/28 18:57:26 d2.evaluation.evaluator]: [0mInference done 1590/8355. 0.1142 s / img. ETA=0:15:37
[32m[04/28 18:57:31 d2.evaluation.evaluator]: [0mInference done 1629/8355. 0.1142 s / img. ETA=0:15:31
[32m[04/28 18:57:36 d2.evaluation.evaluator]: [0mInference done 1670/8355. 0.1142 s / img. ETA=0:15:23
[32m[04/28 18:57:41 d2.evaluation.evaluator]: [0mInference done 1713/8355. 0.1143 s / img. ETA=0:15:13
[32m[04/28 18:57:46 d2.evaluation.evaluator]: [0mInference done 1756/8355. 0.1143 s / img. ETA=0:15:04
[32m[04/28 18:57:51 d2.evaluation.evaluator]: [0mInference done 1796/8355. 0.1143 s / img. ETA=0:14:57
[32m[04/28 18:57:56 d2.evaluation.evaluator]: [0mInference done 1837/8355. 0.1144 s / img. ETA=0:14:49
[32m[04/28 18:58:02 d2.evaluation.evaluator]: [0mInference done 1880/8355. 0.1144 s / img. ETA=0:14:41
[32m[04/28 18:58:07 d2.evaluation.evaluator]: [0mInference done 1922/8355. 0.1144 s / img. ETA=0:14:33
[32m[04/28 18:58:12 d2.evaluation.evaluator]: [0mInference done 1965/8355. 0.1144 s / img. ETA=0:14:24
[32m[04/28 18:58:17 d2.evaluation.evaluator]: [0mInference done 2008/8355. 0.1145 s / img. ETA=0:14:16
[32m[04/28 18:58:22 d2.evaluation.evaluator]: [0mInference done 2051/8355. 0.1145 s / img. ETA=0:14:08
[32m[04/28 18:58:27 d2.evaluation.evaluator]: [0mInference done 2087/8355. 0.1145 s / img. ETA=0:14:04
[32m[04/28 18:58:32 d2.evaluation.evaluator]: [0mInference done 2114/8355. 0.1145 s / img. ETA=0:14:04
[32m[04/28 18:58:37 d2.evaluation.evaluator]: [0mInference done 2147/8355. 0.1145 s / img. ETA=0:14:02
[32m[04/28 18:58:42 d2.evaluation.evaluator]: [0mInference done 2187/8355. 0.1145 s / img. ETA=0:13:55
[32m[04/28 18:58:47 d2.evaluation.evaluator]: [0mInference done 2227/8355. 0.1145 s / img. ETA=0:13:49
[32m[04/28 18:58:52 d2.evaluation.evaluator]: [0mInference done 2270/8355. 0.1145 s / img. ETA=0:13:41
[32m[04/28 18:58:57 d2.evaluation.evaluator]: [0mInference done 2309/8355. 0.1146 s / img. ETA=0:13:35
[32m[04/28 18:59:02 d2.evaluation.evaluator]: [0mInference done 2337/8355. 0.1146 s / img. ETA=0:13:35
[32m[04/28 18:59:07 d2.evaluation.evaluator]: [0mInference done 2377/8355. 0.1146 s / img. ETA=0:13:29
[32m[04/28 18:59:12 d2.evaluation.evaluator]: [0mInference done 2417/8355. 0.1146 s / img. ETA=0:13:22
[32m[04/28 18:59:18 d2.evaluation.evaluator]: [0mInference done 2457/8355. 0.1146 s / img. ETA=0:13:16
[32m[04/28 18:59:23 d2.evaluation.evaluator]: [0mInference done 2499/8355. 0.1146 s / img. ETA=0:13:09
[32m[04/28 18:59:28 d2.evaluation.evaluator]: [0mInference done 2533/8355. 0.1146 s / img. ETA=0:13:06
[32m[04/28 18:59:33 d2.evaluation.evaluator]: [0mInference done 2571/8355. 0.1146 s / img. ETA=0:13:00
[32m[04/28 18:59:38 d2.evaluation.evaluator]: [0mInference done 2614/8355. 0.1146 s / img. ETA=0:12:53
[32m[04/28 18:59:43 d2.evaluation.evaluator]: [0mInference done 2653/8355. 0.1147 s / img. ETA=0:12:47
[32m[04/28 18:59:48 d2.evaluation.evaluator]: [0mInference done 2696/8355. 0.1147 s / img. ETA=0:12:40
[32m[04/28 18:59:53 d2.evaluation.evaluator]: [0mInference done 2737/8355. 0.1147 s / img. ETA=0:12:34
[32m[04/28 18:59:58 d2.evaluation.evaluator]: [0mInference done 2780/8355. 0.1147 s / img. ETA=0:12:27
[32m[04/28 19:00:03 d2.evaluation.evaluator]: [0mInference done 2815/8355. 0.1147 s / img. ETA=0:12:23
[32m[04/28 19:00:08 d2.evaluation.evaluator]: [0mInference done 2857/8355. 0.1147 s / img. ETA=0:12:16
[32m[04/28 19:00:13 d2.evaluation.evaluator]: [0mInference done 2900/8355. 0.1147 s / img. ETA=0:12:09
[32m[04/28 19:00:18 d2.evaluation.evaluator]: [0mInference done 2943/8355. 0.1148 s / img. ETA=0:12:02
[32m[04/28 19:00:23 d2.evaluation.evaluator]: [0mInference done 2985/8355. 0.1148 s / img. ETA=0:11:55
[32m[04/28 19:00:28 d2.evaluation.evaluator]: [0mInference done 3025/8355. 0.1148 s / img. ETA=0:11:49
[32m[04/28 19:00:34 d2.evaluation.evaluator]: [0mInference done 3068/8355. 0.1148 s / img. ETA=0:11:42
[32m[04/28 19:00:39 d2.evaluation.evaluator]: [0mInference done 3109/8355. 0.1148 s / img. ETA=0:11:36
[32m[04/28 19:00:44 d2.evaluation.evaluator]: [0mInference done 3144/8355. 0.1148 s / img. ETA=0:11:32
[32m[04/28 19:00:49 d2.evaluation.evaluator]: [0mInference done 3187/8355. 0.1148 s / img. ETA=0:11:25
[32m[04/28 19:00:54 d2.evaluation.evaluator]: [0mInference done 3231/8355. 0.1148 s / img. ETA=0:11:18
[32m[04/28 19:00:59 d2.evaluation.evaluator]: [0mInference done 3269/8355. 0.1148 s / img. ETA=0:11:14
[32m[04/28 19:01:04 d2.evaluation.evaluator]: [0mInference done 3307/8355. 0.1148 s / img. ETA=0:11:09
[32m[04/28 19:01:09 d2.evaluation.evaluator]: [0mInference done 3342/8355. 0.1148 s / img. ETA=0:11:05
[32m[04/28 19:01:14 d2.evaluation.evaluator]: [0mInference done 3376/8355. 0.1148 s / img. ETA=0:11:01
[32m[04/28 19:01:19 d2.evaluation.evaluator]: [0mInference done 3412/8355. 0.1148 s / img. ETA=0:10:57
[32m[04/28 19:01:25 d2.evaluation.evaluator]: [0mInference done 3453/8355. 0.1148 s / img. ETA=0:10:51
[32m[04/28 19:01:30 d2.evaluation.evaluator]: [0mInference done 3484/8355. 0.1148 s / img. ETA=0:10:48
[32m[04/28 19:01:35 d2.evaluation.evaluator]: [0mInference done 3515/8355. 0.1148 s / img. ETA=0:10:46
[32m[04/28 19:01:40 d2.evaluation.evaluator]: [0mInference done 3542/8355. 0.1148 s / img. ETA=0:10:44
[32m[04/28 19:01:45 d2.evaluation.evaluator]: [0mInference done 3577/8355. 0.1148 s / img. ETA=0:10:40
[32m[04/28 19:01:50 d2.evaluation.evaluator]: [0mInference done 3603/8355. 0.1148 s / img. ETA=0:10:38
[32m[04/28 19:01:55 d2.evaluation.evaluator]: [0mInference done 3631/8355. 0.1148 s / img. ETA=0:10:36
[32m[04/28 19:02:00 d2.evaluation.evaluator]: [0mInference done 3670/8355. 0.1148 s / img. ETA=0:10:31
[32m[04/28 19:02:05 d2.evaluation.evaluator]: [0mInference done 3714/8355. 0.1148 s / img. ETA=0:10:24
[32m[04/28 19:02:10 d2.evaluation.evaluator]: [0mInference done 3758/8355. 0.1147 s / img. ETA=0:10:17
[32m[04/28 19:02:15 d2.evaluation.evaluator]: [0mInference done 3801/8355. 0.1148 s / img. ETA=0:10:10
[32m[04/28 19:02:20 d2.evaluation.evaluator]: [0mInference done 3844/8355. 0.1148 s / img. ETA=0:10:04
[32m[04/28 19:02:25 d2.evaluation.evaluator]: [0mInference done 3887/8355. 0.1148 s / img. ETA=0:09:57
[32m[04/28 19:02:30 d2.evaluation.evaluator]: [0mInference done 3931/8355. 0.1147 s / img. ETA=0:09:50
[32m[04/28 19:02:36 d2.evaluation.evaluator]: [0mInference done 3975/8355. 0.1147 s / img. ETA=0:09:43
[32m[04/28 19:02:41 d2.evaluation.evaluator]: [0mInference done 4018/8355. 0.1147 s / img. ETA=0:09:37
[32m[04/28 19:02:46 d2.evaluation.evaluator]: [0mInference done 4061/8355. 0.1147 s / img. ETA=0:09:30
[32m[04/28 19:02:51 d2.evaluation.evaluator]: [0mInference done 4104/8355. 0.1148 s / img. ETA=0:09:24
[32m[04/28 19:02:56 d2.evaluation.evaluator]: [0mInference done 4147/8355. 0.1148 s / img. ETA=0:09:18
[32m[04/28 19:03:01 d2.evaluation.evaluator]: [0mInference done 4190/8355. 0.1148 s / img. ETA=0:09:11
[32m[04/28 19:03:06 d2.evaluation.evaluator]: [0mInference done 4233/8355. 0.1148 s / img. ETA=0:09:05
[32m[04/28 19:03:11 d2.evaluation.evaluator]: [0mInference done 4276/8355. 0.1148 s / img. ETA=0:08:59
[32m[04/28 19:03:16 d2.evaluation.evaluator]: [0mInference done 4319/8355. 0.1148 s / img. ETA=0:08:52
[32m[04/28 19:03:21 d2.evaluation.evaluator]: [0mInference done 4362/8355. 0.1148 s / img. ETA=0:08:46
[32m[04/28 19:03:26 d2.evaluation.evaluator]: [0mInference done 4405/8355. 0.1148 s / img. ETA=0:08:40
[32m[04/28 19:03:31 d2.evaluation.evaluator]: [0mInference done 4447/8355. 0.1148 s / img. ETA=0:08:34
[32m[04/28 19:03:36 d2.evaluation.evaluator]: [0mInference done 4490/8355. 0.1148 s / img. ETA=0:08:28
[32m[04/28 19:03:41 d2.evaluation.evaluator]: [0mInference done 4533/8355. 0.1148 s / img. ETA=0:08:21
[32m[04/28 19:03:46 d2.evaluation.evaluator]: [0mInference done 4576/8355. 0.1148 s / img. ETA=0:08:15
[32m[04/28 19:03:51 d2.evaluation.evaluator]: [0mInference done 4619/8355. 0.1148 s / img. ETA=0:08:09
[32m[04/28 19:03:56 d2.evaluation.evaluator]: [0mInference done 4662/8355. 0.1148 s / img. ETA=0:08:03
[32m[04/28 19:04:01 d2.evaluation.evaluator]: [0mInference done 4705/8355. 0.1148 s / img. ETA=0:07:57
[32m[04/28 19:04:06 d2.evaluation.evaluator]: [0mInference done 4748/8355. 0.1148 s / img. ETA=0:07:51
[32m[04/28 19:04:11 d2.evaluation.evaluator]: [0mInference done 4791/8355. 0.1148 s / img. ETA=0:07:45
[32m[04/28 19:04:16 d2.evaluation.evaluator]: [0mInference done 4834/8355. 0.1148 s / img. ETA=0:07:39
[32m[04/28 19:04:21 d2.evaluation.evaluator]: [0mInference done 4877/8355. 0.1149 s / img. ETA=0:07:33
[32m[04/28 19:04:26 d2.evaluation.evaluator]: [0mInference done 4920/8355. 0.1149 s / img. ETA=0:07:27
[32m[04/28 19:04:31 d2.evaluation.evaluator]: [0mInference done 4963/8355. 0.1149 s / img. ETA=0:07:21
[32m[04/28 19:04:36 d2.evaluation.evaluator]: [0mInference done 5006/8355. 0.1149 s / img. ETA=0:07:15
[32m[04/28 19:04:42 d2.evaluation.evaluator]: [0mInference done 5049/8355. 0.1149 s / img. ETA=0:07:09
[32m[04/28 19:04:47 d2.evaluation.evaluator]: [0mInference done 5092/8355. 0.1149 s / img. ETA=0:07:03
[32m[04/28 19:04:52 d2.evaluation.evaluator]: [0mInference done 5135/8355. 0.1149 s / img. ETA=0:06:57
[32m[04/28 19:04:57 d2.evaluation.evaluator]: [0mInference done 5178/8355. 0.1149 s / img. ETA=0:06:51
[32m[04/28 19:05:02 d2.evaluation.evaluator]: [0mInference done 5221/8355. 0.1149 s / img. ETA=0:06:45
[32m[04/28 19:05:07 d2.evaluation.evaluator]: [0mInference done 5264/8355. 0.1149 s / img. ETA=0:06:39
[32m[04/28 19:05:12 d2.evaluation.evaluator]: [0mInference done 5307/8355. 0.1149 s / img. ETA=0:06:34
[32m[04/28 19:05:17 d2.evaluation.evaluator]: [0mInference done 5350/8355. 0.1149 s / img. ETA=0:06:28
[32m[04/28 19:05:22 d2.evaluation.evaluator]: [0mInference done 5393/8355. 0.1149 s / img. ETA=0:06:22
[32m[04/28 19:05:27 d2.evaluation.evaluator]: [0mInference done 5436/8355. 0.1149 s / img. ETA=0:06:16
[32m[04/28 19:05:32 d2.evaluation.evaluator]: [0mInference done 5479/8355. 0.1149 s / img. ETA=0:06:10
[32m[04/28 19:05:37 d2.evaluation.evaluator]: [0mInference done 5522/8355. 0.1149 s / img. ETA=0:06:04
[32m[04/28 19:05:42 d2.evaluation.evaluator]: [0mInference done 5565/8355. 0.1149 s / img. ETA=0:05:59
[32m[04/28 19:05:47 d2.evaluation.evaluator]: [0mInference done 5608/8355. 0.1149 s / img. ETA=0:05:53
[32m[04/28 19:05:52 d2.evaluation.evaluator]: [0mInference done 5651/8355. 0.1149 s / img. ETA=0:05:47
[32m[04/28 19:05:57 d2.evaluation.evaluator]: [0mInference done 5694/8355. 0.1150 s / img. ETA=0:05:41
[32m[04/28 19:06:02 d2.evaluation.evaluator]: [0mInference done 5737/8355. 0.1150 s / img. ETA=0:05:36
[32m[04/28 19:06:07 d2.evaluation.evaluator]: [0mInference done 5780/8355. 0.1150 s / img. ETA=0:05:30
[32m[04/28 19:06:12 d2.evaluation.evaluator]: [0mInference done 5823/8355. 0.1150 s / img. ETA=0:05:24
[32m[04/28 19:06:18 d2.evaluation.evaluator]: [0mInference done 5866/8355. 0.1150 s / img. ETA=0:05:19
[32m[04/28 19:06:23 d2.evaluation.evaluator]: [0mInference done 5909/8355. 0.1150 s / img. ETA=0:05:13
[32m[04/28 19:06:28 d2.evaluation.evaluator]: [0mInference done 5952/8355. 0.1150 s / img. ETA=0:05:07
[32m[04/28 19:06:33 d2.evaluation.evaluator]: [0mInference done 5995/8355. 0.1150 s / img. ETA=0:05:01
[32m[04/28 19:06:38 d2.evaluation.evaluator]: [0mInference done 6038/8355. 0.1150 s / img. ETA=0:04:56
[32m[04/28 19:06:43 d2.evaluation.evaluator]: [0mInference done 6081/8355. 0.1150 s / img. ETA=0:04:50
[32m[04/28 19:06:48 d2.evaluation.evaluator]: [0mInference done 6124/8355. 0.1151 s / img. ETA=0:04:45
[32m[04/28 19:06:53 d2.evaluation.evaluator]: [0mInference done 6167/8355. 0.1151 s / img. ETA=0:04:39
[32m[04/28 19:06:58 d2.evaluation.evaluator]: [0mInference done 6210/8355. 0.1151 s / img. ETA=0:04:33
[32m[04/28 19:07:03 d2.evaluation.evaluator]: [0mInference done 6253/8355. 0.1151 s / img. ETA=0:04:28
[32m[04/28 19:07:08 d2.evaluation.evaluator]: [0mInference done 6296/8355. 0.1151 s / img. ETA=0:04:22
[32m[04/28 19:07:14 d2.evaluation.evaluator]: [0mInference done 6339/8355. 0.1151 s / img. ETA=0:04:16
[32m[04/28 19:07:19 d2.evaluation.evaluator]: [0mInference done 6382/8355. 0.1151 s / img. ETA=0:04:11
[32m[04/28 19:07:24 d2.evaluation.evaluator]: [0mInference done 6425/8355. 0.1151 s / img. ETA=0:04:05
[32m[04/28 19:07:29 d2.evaluation.evaluator]: [0mInference done 6468/8355. 0.1151 s / img. ETA=0:04:00
[32m[04/28 19:07:34 d2.evaluation.evaluator]: [0mInference done 6511/8355. 0.1151 s / img. ETA=0:03:54
[32m[04/28 19:07:39 d2.evaluation.evaluator]: [0mInference done 6554/8355. 0.1151 s / img. ETA=0:03:48
[32m[04/28 19:07:44 d2.evaluation.evaluator]: [0mInference done 6597/8355. 0.1151 s / img. ETA=0:03:43
[32m[04/28 19:07:49 d2.evaluation.evaluator]: [0mInference done 6640/8355. 0.1151 s / img. ETA=0:03:37
[32m[04/28 19:07:54 d2.evaluation.evaluator]: [0mInference done 6684/8355. 0.1151 s / img. ETA=0:03:32
[32m[04/28 19:07:59 d2.evaluation.evaluator]: [0mInference done 6727/8355. 0.1151 s / img. ETA=0:03:26
[32m[04/28 19:08:04 d2.evaluation.evaluator]: [0mInference done 6771/8355. 0.1151 s / img. ETA=0:03:20
[32m[04/28 19:08:09 d2.evaluation.evaluator]: [0mInference done 6814/8355. 0.1151 s / img. ETA=0:03:15
[32m[04/28 19:08:14 d2.evaluation.evaluator]: [0mInference done 6857/8355. 0.1151 s / img. ETA=0:03:09
[32m[04/28 19:08:19 d2.evaluation.evaluator]: [0mInference done 6900/8355. 0.1151 s / img. ETA=0:03:04
[32m[04/28 19:08:24 d2.evaluation.evaluator]: [0mInference done 6943/8355. 0.1151 s / img. ETA=0:02:58
[32m[04/28 19:08:29 d2.evaluation.evaluator]: [0mInference done 6986/8355. 0.1151 s / img. ETA=0:02:53
[32m[04/28 19:08:34 d2.evaluation.evaluator]: [0mInference done 7028/8355. 0.1152 s / img. ETA=0:02:47
[32m[04/28 19:08:39 d2.evaluation.evaluator]: [0mInference done 7071/8355. 0.1152 s / img. ETA=0:02:42
[32m[04/28 19:08:44 d2.evaluation.evaluator]: [0mInference done 7114/8355. 0.1152 s / img. ETA=0:02:36
[32m[04/28 19:08:50 d2.evaluation.evaluator]: [0mInference done 7157/8355. 0.1152 s / img. ETA=0:02:31
[32m[04/28 19:08:55 d2.evaluation.evaluator]: [0mInference done 7200/8355. 0.1152 s / img. ETA=0:02:25
[32m[04/28 19:09:00 d2.evaluation.evaluator]: [0mInference done 7243/8355. 0.1152 s / img. ETA=0:02:20
[32m[04/28 19:09:05 d2.evaluation.evaluator]: [0mInference done 7286/8355. 0.1152 s / img. ETA=0:02:14
[32m[04/28 19:09:10 d2.evaluation.evaluator]: [0mInference done 7329/8355. 0.1152 s / img. ETA=0:02:09
[32m[04/28 19:09:15 d2.evaluation.evaluator]: [0mInference done 7372/8355. 0.1152 s / img. ETA=0:02:03
[32m[04/28 19:09:20 d2.evaluation.evaluator]: [0mInference done 7415/8355. 0.1152 s / img. ETA=0:01:58
[32m[04/28 19:09:25 d2.evaluation.evaluator]: [0mInference done 7458/8355. 0.1152 s / img. ETA=0:01:52
[32m[04/28 19:09:30 d2.evaluation.evaluator]: [0mInference done 7501/8355. 0.1152 s / img. ETA=0:01:47
[32m[04/28 19:09:35 d2.evaluation.evaluator]: [0mInference done 7544/8355. 0.1152 s / img. ETA=0:01:42
[32m[04/28 19:09:40 d2.evaluation.evaluator]: [0mInference done 7587/8355. 0.1152 s / img. ETA=0:01:36
[32m[04/28 19:09:45 d2.evaluation.evaluator]: [0mInference done 7630/8355. 0.1152 s / img. ETA=0:01:31
[32m[04/28 19:09:50 d2.evaluation.evaluator]: [0mInference done 7673/8355. 0.1152 s / img. ETA=0:01:25
[32m[04/28 19:09:56 d2.evaluation.evaluator]: [0mInference done 7716/8355. 0.1153 s / img. ETA=0:01:20
[32m[04/28 19:10:01 d2.evaluation.evaluator]: [0mInference done 7759/8355. 0.1153 s / img. ETA=0:01:14
[32m[04/28 19:10:06 d2.evaluation.evaluator]: [0mInference done 7802/8355. 0.1153 s / img. ETA=0:01:09
[32m[04/28 19:10:11 d2.evaluation.evaluator]: [0mInference done 7845/8355. 0.1153 s / img. ETA=0:01:04
[32m[04/28 19:10:16 d2.evaluation.evaluator]: [0mInference done 7888/8355. 0.1153 s / img. ETA=0:00:58
[32m[04/28 19:10:21 d2.evaluation.evaluator]: [0mInference done 7931/8355. 0.1153 s / img. ETA=0:00:53
[32m[04/28 19:10:26 d2.evaluation.evaluator]: [0mInference done 7974/8355. 0.1153 s / img. ETA=0:00:47
[32m[04/28 19:10:31 d2.evaluation.evaluator]: [0mInference done 8017/8355. 0.1153 s / img. ETA=0:00:42
[32m[04/28 19:10:36 d2.evaluation.evaluator]: [0mInference done 8061/8355. 0.1153 s / img. ETA=0:00:36
[32m[04/28 19:10:41 d2.evaluation.evaluator]: [0mInference done 8104/8355. 0.1153 s / img. ETA=0:00:31
[32m[04/28 19:10:46 d2.evaluation.evaluator]: [0mInference done 8147/8355. 0.1153 s / img. ETA=0:00:26
[32m[04/28 19:10:51 d2.evaluation.evaluator]: [0mInference done 8191/8355. 0.1153 s / img. ETA=0:00:20
[32m[04/28 19:10:56 d2.evaluation.evaluator]: [0mInference done 8234/8355. 0.1153 s / img. ETA=0:00:15
[32m[04/28 19:11:01 d2.evaluation.evaluator]: [0mInference done 8277/8355. 0.1153 s / img. ETA=0:00:09
[32m[04/28 19:11:06 d2.evaluation.evaluator]: [0mInference done 8320/8355. 0.1153 s / img. ETA=0:00:04
[32m[04/28 19:11:10 d2.evaluation.evaluator]: [0mTotal inference time: 0:17:24.069422 (0.125038 s / img per device, on 1 devices)
[32m[04/28 19:11:10 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:02 (0.115276 s / img per device, on 1 devices)
[32m[04/28 19:11:11 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 19:11:11 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 19:11:11 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.15s).
Accumulating evaluation results...
DONE (t=2.22s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.518
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.875
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.539
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.411
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.643
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.557
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.489
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.698
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.793
[32m[04/28 19:11:34 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.801 | 87.471 | 53.943 | 41.068 | 64.346 | 75.285 |
[32m[04/28 19:11:34 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 49.286 | bicycle       | 45.528 | car            | 60.589 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 19:11:34 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 19:11:34 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 19:11:34 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 19:11:36 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1150 s / img. ETA=0:02:25
[32m[04/28 19:11:41 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1149 s / img. ETA=0:02:20
[32m[04/28 19:11:46 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1150 s / img. ETA=0:02:15
[32m[04/28 19:11:51 d2.evaluation.evaluator]: [0mInference done 139/1257. 0.1161 s / img. ETA=0:02:11
[32m[04/28 19:11:56 d2.evaluation.evaluator]: [0mInference done 182/1257. 0.1159 s / img. ETA=0:02:06
[32m[04/28 19:12:01 d2.evaluation.evaluator]: [0mInference done 225/1257. 0.1158 s / img. ETA=0:02:01
[32m[04/28 19:12:06 d2.evaluation.evaluator]: [0mInference done 268/1257. 0.1157 s / img. ETA=0:01:56
[32m[04/28 19:12:11 d2.evaluation.evaluator]: [0mInference done 311/1257. 0.1156 s / img. ETA=0:01:51
[32m[04/28 19:12:16 d2.evaluation.evaluator]: [0mInference done 354/1257. 0.1155 s / img. ETA=0:01:45
[32m[04/28 19:12:21 d2.evaluation.evaluator]: [0mInference done 397/1257. 0.1155 s / img. ETA=0:01:40
[32m[04/28 19:12:26 d2.evaluation.evaluator]: [0mInference done 440/1257. 0.1154 s / img. ETA=0:01:35
[32m[04/28 19:12:31 d2.evaluation.evaluator]: [0mInference done 483/1257. 0.1154 s / img. ETA=0:01:30
[32m[04/28 19:12:36 d2.evaluation.evaluator]: [0mInference done 526/1257. 0.1154 s / img. ETA=0:01:25
[32m[04/28 19:12:41 d2.evaluation.evaluator]: [0mInference done 569/1257. 0.1154 s / img. ETA=0:01:20
[32m[04/28 19:12:46 d2.evaluation.evaluator]: [0mInference done 612/1257. 0.1153 s / img. ETA=0:01:15
[32m[04/28 19:12:51 d2.evaluation.evaluator]: [0mInference done 655/1257. 0.1153 s / img. ETA=0:01:10
[32m[04/28 19:12:56 d2.evaluation.evaluator]: [0mInference done 698/1257. 0.1153 s / img. ETA=0:01:05
[32m[04/28 19:13:01 d2.evaluation.evaluator]: [0mInference done 741/1257. 0.1153 s / img. ETA=0:01:00
[32m[04/28 19:13:06 d2.evaluation.evaluator]: [0mInference done 784/1257. 0.1153 s / img. ETA=0:00:55
[32m[04/28 19:13:11 d2.evaluation.evaluator]: [0mInference done 827/1257. 0.1154 s / img. ETA=0:00:50
[32m[04/28 19:13:16 d2.evaluation.evaluator]: [0mInference done 870/1257. 0.1154 s / img. ETA=0:00:45
[32m[04/28 19:13:22 d2.evaluation.evaluator]: [0mInference done 913/1257. 0.1154 s / img. ETA=0:00:40
[32m[04/28 19:13:27 d2.evaluation.evaluator]: [0mInference done 956/1257. 0.1154 s / img. ETA=0:00:35
[32m[04/28 19:13:32 d2.evaluation.evaluator]: [0mInference done 999/1257. 0.1154 s / img. ETA=0:00:30
[32m[04/28 19:13:37 d2.evaluation.evaluator]: [0mInference done 1042/1257. 0.1154 s / img. ETA=0:00:25
[32m[04/28 19:13:42 d2.evaluation.evaluator]: [0mInference done 1085/1257. 0.1154 s / img. ETA=0:00:20
[32m[04/28 19:13:47 d2.evaluation.evaluator]: [0mInference done 1128/1257. 0.1155 s / img. ETA=0:00:15
[32m[04/28 19:13:52 d2.evaluation.evaluator]: [0mInference done 1171/1257. 0.1155 s / img. ETA=0:00:10
[32m[04/28 19:13:57 d2.evaluation.evaluator]: [0mInference done 1214/1257. 0.1155 s / img. ETA=0:00:05
[32m[04/28 19:14:02 d2.evaluation.evaluator]: [0mInference done 1257/1257. 0.1155 s / img. ETA=0:00:00
[32m[04/28 19:14:02 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.855808 (0.117297 s / img per device, on 1 devices)
[32m[04/28 19:14:02 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115497 s / img per device, on 1 devices)
[32m[04/28 19:14:02 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 19:14:02 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 19:14:02 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.01s).
Accumulating evaluation results...
DONE (t=0.37s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.397
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.759
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.353
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.294
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.555
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.476
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.407
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.527
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.618
[32m[04/28 19:14:06 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.724 | 75.911 | 35.271 | 29.441 | 45.472 | 55.499 |
[32m[04/28 19:14:06 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 40.566 | bicycle       | 23.995 | car            | 54.612 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  29  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 19:14:06 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 19:14:07 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 19:14:07 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 19:14:07 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 19:14:08 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 19:14:08 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 19:14:09 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 19:14:30 d2.utils.events]: [0m eta: 0:17:33  iter: 19  total_loss: 0.502  loss_cls: 0.147  loss_box_reg: 0.294  loss_rpn_cls: 0.005  loss_rpn_loc: 0.052  time: 1.0557  data_time: 0.0227  lr: 0.000100  max_mem: 5397M
[32m[04/28 19:14:50 d2.utils.events]: [0m eta: 0:16:32  iter: 39  total_loss: 0.532  loss_cls: 0.164  loss_box_reg: 0.318  loss_rpn_cls: 0.006  loss_rpn_loc: 0.052  time: 1.0292  data_time: 0.0077  lr: 0.000200  max_mem: 5397M
[32m[04/28 19:15:12 d2.utils.events]: [0m eta: 0:16:31  iter: 59  total_loss: 0.489  loss_cls: 0.152  loss_box_reg: 0.281  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0404  data_time: 0.0076  lr: 0.000300  max_mem: 5397M
[32m[04/28 19:15:32 d2.utils.events]: [0m eta: 0:16:08  iter: 79  total_loss: 0.458  loss_cls: 0.135  loss_box_reg: 0.273  loss_rpn_cls: 0.007  loss_rpn_loc: 0.039  time: 1.0384  data_time: 0.0077  lr: 0.000400  max_mem: 5397M
[32m[04/28 19:15:53 d2.utils.events]: [0m eta: 0:15:43  iter: 99  total_loss: 0.461  loss_cls: 0.147  loss_box_reg: 0.278  loss_rpn_cls: 0.005  loss_rpn_loc: 0.034  time: 1.0321  data_time: 0.0074  lr: 0.000500  max_mem: 5397M
[32m[04/28 19:16:13 d2.utils.events]: [0m eta: 0:15:10  iter: 119  total_loss: 0.435  loss_cls: 0.126  loss_box_reg: 0.248  loss_rpn_cls: 0.003  loss_rpn_loc: 0.040  time: 1.0302  data_time: 0.0076  lr: 0.000599  max_mem: 5397M
[32m[04/28 19:16:34 d2.utils.events]: [0m eta: 0:14:47  iter: 139  total_loss: 0.421  loss_cls: 0.119  loss_box_reg: 0.261  loss_rpn_cls: 0.004  loss_rpn_loc: 0.041  time: 1.0289  data_time: 0.0075  lr: 0.000699  max_mem: 5397M
[32m[04/28 19:16:54 d2.utils.events]: [0m eta: 0:14:26  iter: 159  total_loss: 0.447  loss_cls: 0.134  loss_box_reg: 0.264  loss_rpn_cls: 0.004  loss_rpn_loc: 0.045  time: 1.0279  data_time: 0.0075  lr: 0.000799  max_mem: 5397M
[32m[04/28 19:17:15 d2.utils.events]: [0m eta: 0:14:12  iter: 179  total_loss: 0.424  loss_cls: 0.127  loss_box_reg: 0.239  loss_rpn_cls: 0.004  loss_rpn_loc: 0.039  time: 1.0314  data_time: 0.0075  lr: 0.000899  max_mem: 5397M
[32m[04/28 19:17:36 d2.utils.events]: [0m eta: 0:13:49  iter: 199  total_loss: 0.439  loss_cls: 0.139  loss_box_reg: 0.266  loss_rpn_cls: 0.008  loss_rpn_loc: 0.038  time: 1.0318  data_time: 0.0075  lr: 0.000999  max_mem: 5397M
[32m[04/28 19:17:56 d2.utils.events]: [0m eta: 0:13:25  iter: 219  total_loss: 0.451  loss_cls: 0.126  loss_box_reg: 0.263  loss_rpn_cls: 0.004  loss_rpn_loc: 0.039  time: 1.0297  data_time: 0.0073  lr: 0.001099  max_mem: 5397M
[32m[04/28 19:18:17 d2.utils.events]: [0m eta: 0:13:04  iter: 239  total_loss: 0.484  loss_cls: 0.149  loss_box_reg: 0.279  loss_rpn_cls: 0.005  loss_rpn_loc: 0.046  time: 1.0300  data_time: 0.0074  lr: 0.001199  max_mem: 5397M
[32m[04/28 19:18:37 d2.utils.events]: [0m eta: 0:12:44  iter: 259  total_loss: 0.415  loss_cls: 0.129  loss_box_reg: 0.247  loss_rpn_cls: 0.003  loss_rpn_loc: 0.032  time: 1.0286  data_time: 0.0073  lr: 0.001299  max_mem: 5397M
[32m[04/28 19:18:58 d2.utils.events]: [0m eta: 0:12:24  iter: 279  total_loss: 0.387  loss_cls: 0.106  loss_box_reg: 0.241  loss_rpn_cls: 0.004  loss_rpn_loc: 0.039  time: 1.0287  data_time: 0.0073  lr: 0.001399  max_mem: 5397M
[32m[04/28 19:19:19 d2.utils.events]: [0m eta: 0:12:06  iter: 299  total_loss: 0.459  loss_cls: 0.126  loss_box_reg: 0.272  loss_rpn_cls: 0.005  loss_rpn_loc: 0.046  time: 1.0296  data_time: 0.0080  lr: 0.001499  max_mem: 5397M
[32m[04/28 19:19:39 d2.utils.events]: [0m eta: 0:11:46  iter: 319  total_loss: 0.433  loss_cls: 0.130  loss_box_reg: 0.249  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0295  data_time: 0.0072  lr: 0.001598  max_mem: 5397M
[32m[04/28 19:20:00 d2.utils.events]: [0m eta: 0:11:24  iter: 339  total_loss: 0.455  loss_cls: 0.127  loss_box_reg: 0.277  loss_rpn_cls: 0.007  loss_rpn_loc: 0.037  time: 1.0284  data_time: 0.0073  lr: 0.001698  max_mem: 5397M
[32m[04/28 19:20:21 d2.utils.events]: [0m eta: 0:11:03  iter: 359  total_loss: 0.479  loss_cls: 0.144  loss_box_reg: 0.289  loss_rpn_cls: 0.004  loss_rpn_loc: 0.042  time: 1.0294  data_time: 0.0074  lr: 0.001798  max_mem: 5397M
[32m[04/28 19:20:42 d2.utils.events]: [0m eta: 0:10:44  iter: 379  total_loss: 0.421  loss_cls: 0.137  loss_box_reg: 0.262  loss_rpn_cls: 0.006  loss_rpn_loc: 0.036  time: 1.0306  data_time: 0.0073  lr: 0.001898  max_mem: 5397M
[32m[04/28 19:21:02 d2.utils.events]: [0m eta: 0:10:23  iter: 399  total_loss: 0.441  loss_cls: 0.127  loss_box_reg: 0.268  loss_rpn_cls: 0.004  loss_rpn_loc: 0.036  time: 1.0302  data_time: 0.0073  lr: 0.001998  max_mem: 5397M
[32m[04/28 19:21:23 d2.utils.events]: [0m eta: 0:10:01  iter: 419  total_loss: 0.485  loss_cls: 0.147  loss_box_reg: 0.274  loss_rpn_cls: 0.005  loss_rpn_loc: 0.049  time: 1.0296  data_time: 0.0073  lr: 0.002098  max_mem: 5397M
[32m[04/28 19:21:43 d2.utils.events]: [0m eta: 0:09:41  iter: 439  total_loss: 0.508  loss_cls: 0.159  loss_box_reg: 0.288  loss_rpn_cls: 0.006  loss_rpn_loc: 0.048  time: 1.0296  data_time: 0.0072  lr: 0.002198  max_mem: 5397M
[32m[04/28 19:22:04 d2.utils.events]: [0m eta: 0:09:20  iter: 459  total_loss: 0.389  loss_cls: 0.114  loss_box_reg: 0.241  loss_rpn_cls: 0.006  loss_rpn_loc: 0.035  time: 1.0293  data_time: 0.0074  lr: 0.002298  max_mem: 5397M
[32m[04/28 19:22:25 d2.utils.events]: [0m eta: 0:09:02  iter: 479  total_loss: 0.480  loss_cls: 0.142  loss_box_reg: 0.286  loss_rpn_cls: 0.004  loss_rpn_loc: 0.039  time: 1.0304  data_time: 0.0075  lr: 0.002398  max_mem: 5397M
[32m[04/28 19:22:45 d2.utils.events]: [0m eta: 0:08:40  iter: 499  total_loss: 0.518  loss_cls: 0.145  loss_box_reg: 0.311  loss_rpn_cls: 0.006  loss_rpn_loc: 0.054  time: 1.0297  data_time: 0.0072  lr: 0.002498  max_mem: 5397M
[32m[04/28 19:23:06 d2.utils.events]: [0m eta: 0:08:18  iter: 519  total_loss: 0.520  loss_cls: 0.156  loss_box_reg: 0.307  loss_rpn_cls: 0.005  loss_rpn_loc: 0.053  time: 1.0292  data_time: 0.0072  lr: 0.002597  max_mem: 5397M
[32m[04/28 19:23:26 d2.utils.events]: [0m eta: 0:07:58  iter: 539  total_loss: 0.506  loss_cls: 0.158  loss_box_reg: 0.280  loss_rpn_cls: 0.007  loss_rpn_loc: 0.055  time: 1.0295  data_time: 0.0072  lr: 0.002697  max_mem: 5397M
[32m[04/28 19:23:47 d2.utils.events]: [0m eta: 0:07:38  iter: 559  total_loss: 0.490  loss_cls: 0.155  loss_box_reg: 0.297  loss_rpn_cls: 0.009  loss_rpn_loc: 0.048  time: 1.0300  data_time: 0.0071  lr: 0.002797  max_mem: 5397M
[32m[04/28 19:24:08 d2.utils.events]: [0m eta: 0:07:17  iter: 579  total_loss: 0.480  loss_cls: 0.140  loss_box_reg: 0.288  loss_rpn_cls: 0.008  loss_rpn_loc: 0.047  time: 1.0298  data_time: 0.0071  lr: 0.002897  max_mem: 5397M
[32m[04/28 19:24:28 d2.utils.events]: [0m eta: 0:06:55  iter: 599  total_loss: 0.495  loss_cls: 0.142  loss_box_reg: 0.285  loss_rpn_cls: 0.007  loss_rpn_loc: 0.041  time: 1.0297  data_time: 0.0073  lr: 0.002997  max_mem: 5397M
[32m[04/28 19:24:49 d2.utils.events]: [0m eta: 0:06:34  iter: 619  total_loss: 0.437  loss_cls: 0.137  loss_box_reg: 0.265  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0292  data_time: 0.0072  lr: 0.003097  max_mem: 5397M
[32m[04/28 19:25:09 d2.utils.events]: [0m eta: 0:06:13  iter: 639  total_loss: 0.457  loss_cls: 0.132  loss_box_reg: 0.283  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0291  data_time: 0.0075  lr: 0.003197  max_mem: 5397M
[32m[04/28 19:25:30 d2.utils.events]: [0m eta: 0:05:53  iter: 659  total_loss: 0.449  loss_cls: 0.132  loss_box_reg: 0.262  loss_rpn_cls: 0.005  loss_rpn_loc: 0.037  time: 1.0296  data_time: 0.0073  lr: 0.003297  max_mem: 5397M
[32m[04/28 19:25:51 d2.utils.events]: [0m eta: 0:05:33  iter: 679  total_loss: 0.477  loss_cls: 0.148  loss_box_reg: 0.284  loss_rpn_cls: 0.005  loss_rpn_loc: 0.039  time: 1.0301  data_time: 0.0071  lr: 0.003397  max_mem: 5397M
[32m[04/28 19:26:12 d2.utils.events]: [0m eta: 0:05:11  iter: 699  total_loss: 0.475  loss_cls: 0.140  loss_box_reg: 0.286  loss_rpn_cls: 0.004  loss_rpn_loc: 0.045  time: 1.0298  data_time: 0.0074  lr: 0.003497  max_mem: 5397M
[32m[04/28 19:26:32 d2.utils.events]: [0m eta: 0:04:51  iter: 719  total_loss: 0.473  loss_cls: 0.146  loss_box_reg: 0.293  loss_rpn_cls: 0.005  loss_rpn_loc: 0.038  time: 1.0297  data_time: 0.0082  lr: 0.003596  max_mem: 5397M
[32m[04/28 19:26:53 d2.utils.events]: [0m eta: 0:04:30  iter: 739  total_loss: 0.502  loss_cls: 0.155  loss_box_reg: 0.274  loss_rpn_cls: 0.007  loss_rpn_loc: 0.041  time: 1.0293  data_time: 0.0071  lr: 0.003696  max_mem: 5397M
[32m[04/28 19:27:14 d2.utils.events]: [0m eta: 0:04:10  iter: 759  total_loss: 0.563  loss_cls: 0.171  loss_box_reg: 0.324  loss_rpn_cls: 0.006  loss_rpn_loc: 0.061  time: 1.0295  data_time: 0.0072  lr: 0.003796  max_mem: 5397M
[32m[04/28 19:27:34 d2.utils.events]: [0m eta: 0:03:49  iter: 779  total_loss: 0.475  loss_cls: 0.149  loss_box_reg: 0.267  loss_rpn_cls: 0.006  loss_rpn_loc: 0.052  time: 1.0289  data_time: 0.0069  lr: 0.003896  max_mem: 5397M
[32m[04/28 19:27:55 d2.utils.events]: [0m eta: 0:03:28  iter: 799  total_loss: 0.498  loss_cls: 0.133  loss_box_reg: 0.297  loss_rpn_cls: 0.005  loss_rpn_loc: 0.042  time: 1.0296  data_time: 0.0070  lr: 0.003996  max_mem: 5397M
[32m[04/28 19:28:15 d2.utils.events]: [0m eta: 0:03:08  iter: 819  total_loss: 0.511  loss_cls: 0.154  loss_box_reg: 0.290  loss_rpn_cls: 0.006  loss_rpn_loc: 0.049  time: 1.0294  data_time: 0.0069  lr: 0.004096  max_mem: 5397M
[32m[04/28 19:28:36 d2.utils.events]: [0m eta: 0:02:47  iter: 839  total_loss: 0.495  loss_cls: 0.143  loss_box_reg: 0.305  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0295  data_time: 0.0073  lr: 0.004196  max_mem: 5397M
[32m[04/28 19:28:57 d2.utils.events]: [0m eta: 0:02:26  iter: 859  total_loss: 0.514  loss_cls: 0.143  loss_box_reg: 0.311  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0300  data_time: 0.0074  lr: 0.004296  max_mem: 5397M
[32m[04/28 19:29:18 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.478  loss_cls: 0.151  loss_box_reg: 0.283  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0301  data_time: 0.0074  lr: 0.004396  max_mem: 5397M
[32m[04/28 19:29:38 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.409  loss_cls: 0.127  loss_box_reg: 0.240  loss_rpn_cls: 0.006  loss_rpn_loc: 0.040  time: 1.0300  data_time: 0.0071  lr: 0.004496  max_mem: 5397M
[32m[04/28 19:29:59 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.553  loss_cls: 0.165  loss_box_reg: 0.313  loss_rpn_cls: 0.006  loss_rpn_loc: 0.057  time: 1.0297  data_time: 0.0072  lr: 0.004595  max_mem: 5397M
[32m[04/28 19:30:19 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.490  loss_cls: 0.157  loss_box_reg: 0.293  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0296  data_time: 0.0072  lr: 0.004695  max_mem: 5397M
[32m[04/28 19:30:39 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.504  loss_cls: 0.149  loss_box_reg: 0.285  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0290  data_time: 0.0071  lr: 0.004795  max_mem: 5397M
[32m[04/28 19:30:59 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.479  loss_cls: 0.143  loss_box_reg: 0.295  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0282  data_time: 0.0073  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 19:31:22 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 19:31:22 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 19:31:22 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 19:31:22 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.541  loss_cls: 0.162  loss_box_reg: 0.312  loss_rpn_cls: 0.007  loss_rpn_loc: 0.051  time: 1.0281  data_time: 0.0073  lr: 0.004995  max_mem: 5397M
[32m[04/28 19:31:23 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:06 (1.0291 s / it)
[32m[04/28 19:31:23 d2.engine.hooks]: [0mTotal training time: 0:17:11 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 19:31:24 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 19:31:24 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 19:31:25 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 19:31:26 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1142 s / img. ETA=0:16:04
[32m[04/28 19:31:31 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1138 s / img. ETA=0:15:57
[32m[04/28 19:31:36 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1137 s / img. ETA=0:15:52
[32m[04/28 19:31:41 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1137 s / img. ETA=0:15:46
[32m[04/28 19:31:46 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1137 s / img. ETA=0:15:41
[32m[04/28 19:31:51 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1137 s / img. ETA=0:15:36
[32m[04/28 19:31:57 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1137 s / img. ETA=0:15:32
[32m[04/28 19:32:02 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1138 s / img. ETA=0:15:27
[32m[04/28 19:32:07 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1138 s / img. ETA=0:15:22
[32m[04/28 19:32:12 d2.evaluation.evaluator]: [0mInference done 406/8355. 0.1139 s / img. ETA=0:15:18
[32m[04/28 19:32:17 d2.evaluation.evaluator]: [0mInference done 450/8355. 0.1139 s / img. ETA=0:15:13
[32m[04/28 19:32:22 d2.evaluation.evaluator]: [0mInference done 494/8355. 0.1138 s / img. ETA=0:15:08
[32m[04/28 19:32:27 d2.evaluation.evaluator]: [0mInference done 538/8355. 0.1138 s / img. ETA=0:15:02
[32m[04/28 19:32:32 d2.evaluation.evaluator]: [0mInference done 582/8355. 0.1138 s / img. ETA=0:14:57
[32m[04/28 19:32:37 d2.evaluation.evaluator]: [0mInference done 626/8355. 0.1138 s / img. ETA=0:14:52
[32m[04/28 19:32:42 d2.evaluation.evaluator]: [0mInference done 670/8355. 0.1139 s / img. ETA=0:14:47
[32m[04/28 19:32:47 d2.evaluation.evaluator]: [0mInference done 714/8355. 0.1139 s / img. ETA=0:14:42
[32m[04/28 19:32:52 d2.evaluation.evaluator]: [0mInference done 758/8355. 0.1139 s / img. ETA=0:14:37
[32m[04/28 19:32:57 d2.evaluation.evaluator]: [0mInference done 801/8355. 0.1139 s / img. ETA=0:14:33
[32m[04/28 19:33:02 d2.evaluation.evaluator]: [0mInference done 845/8355. 0.1139 s / img. ETA=0:14:28
[32m[04/28 19:33:08 d2.evaluation.evaluator]: [0mInference done 888/8355. 0.1140 s / img. ETA=0:14:23
[32m[04/28 19:33:13 d2.evaluation.evaluator]: [0mInference done 931/8355. 0.1141 s / img. ETA=0:14:19
[32m[04/28 19:33:18 d2.evaluation.evaluator]: [0mInference done 975/8355. 0.1141 s / img. ETA=0:14:14
[32m[04/28 19:33:23 d2.evaluation.evaluator]: [0mInference done 1019/8355. 0.1141 s / img. ETA=0:14:09
[32m[04/28 19:33:28 d2.evaluation.evaluator]: [0mInference done 1063/8355. 0.1141 s / img. ETA=0:14:04
[32m[04/28 19:33:33 d2.evaluation.evaluator]: [0mInference done 1107/8355. 0.1141 s / img. ETA=0:13:59
[32m[04/28 19:33:38 d2.evaluation.evaluator]: [0mInference done 1151/8355. 0.1141 s / img. ETA=0:13:53
[32m[04/28 19:33:43 d2.evaluation.evaluator]: [0mInference done 1195/8355. 0.1140 s / img. ETA=0:13:48
[32m[04/28 19:33:48 d2.evaluation.evaluator]: [0mInference done 1239/8355. 0.1140 s / img. ETA=0:13:43
[32m[04/28 19:33:53 d2.evaluation.evaluator]: [0mInference done 1283/8355. 0.1140 s / img. ETA=0:13:38
[32m[04/28 19:33:58 d2.evaluation.evaluator]: [0mInference done 1326/8355. 0.1141 s / img. ETA=0:13:33
[32m[04/28 19:34:03 d2.evaluation.evaluator]: [0mInference done 1370/8355. 0.1141 s / img. ETA=0:13:28
[32m[04/28 19:34:08 d2.evaluation.evaluator]: [0mInference done 1414/8355. 0.1141 s / img. ETA=0:13:23
[32m[04/28 19:34:14 d2.evaluation.evaluator]: [0mInference done 1458/8355. 0.1140 s / img. ETA=0:13:18
[32m[04/28 19:34:19 d2.evaluation.evaluator]: [0mInference done 1501/8355. 0.1141 s / img. ETA=0:13:13
[32m[04/28 19:34:24 d2.evaluation.evaluator]: [0mInference done 1544/8355. 0.1142 s / img. ETA=0:13:09
[32m[04/28 19:34:29 d2.evaluation.evaluator]: [0mInference done 1587/8355. 0.1142 s / img. ETA=0:13:04
[32m[04/28 19:34:34 d2.evaluation.evaluator]: [0mInference done 1630/8355. 0.1143 s / img. ETA=0:12:59
[32m[04/28 19:34:39 d2.evaluation.evaluator]: [0mInference done 1673/8355. 0.1143 s / img. ETA=0:12:55
[32m[04/28 19:34:44 d2.evaluation.evaluator]: [0mInference done 1716/8355. 0.1143 s / img. ETA=0:12:50
[32m[04/28 19:34:49 d2.evaluation.evaluator]: [0mInference done 1759/8355. 0.1143 s / img. ETA=0:12:45
[32m[04/28 19:34:54 d2.evaluation.evaluator]: [0mInference done 1802/8355. 0.1144 s / img. ETA=0:12:40
[32m[04/28 19:34:59 d2.evaluation.evaluator]: [0mInference done 1845/8355. 0.1144 s / img. ETA=0:12:36
[32m[04/28 19:35:04 d2.evaluation.evaluator]: [0mInference done 1888/8355. 0.1145 s / img. ETA=0:12:31
[32m[04/28 19:35:09 d2.evaluation.evaluator]: [0mInference done 1931/8355. 0.1145 s / img. ETA=0:12:26
[32m[04/28 19:35:14 d2.evaluation.evaluator]: [0mInference done 1974/8355. 0.1145 s / img. ETA=0:12:21
[32m[04/28 19:35:19 d2.evaluation.evaluator]: [0mInference done 2017/8355. 0.1145 s / img. ETA=0:12:16
[32m[04/28 19:35:24 d2.evaluation.evaluator]: [0mInference done 2060/8355. 0.1146 s / img. ETA=0:12:11
[32m[04/28 19:35:29 d2.evaluation.evaluator]: [0mInference done 2103/8355. 0.1146 s / img. ETA=0:12:06
[32m[04/28 19:35:34 d2.evaluation.evaluator]: [0mInference done 2147/8355. 0.1145 s / img. ETA=0:12:01
[32m[04/28 19:35:39 d2.evaluation.evaluator]: [0mInference done 2190/8355. 0.1146 s / img. ETA=0:11:56
[32m[04/28 19:35:44 d2.evaluation.evaluator]: [0mInference done 2233/8355. 0.1146 s / img. ETA=0:11:51
[32m[04/28 19:35:50 d2.evaluation.evaluator]: [0mInference done 2276/8355. 0.1146 s / img. ETA=0:11:47
[32m[04/28 19:35:55 d2.evaluation.evaluator]: [0mInference done 2319/8355. 0.1146 s / img. ETA=0:11:42
[32m[04/28 19:36:00 d2.evaluation.evaluator]: [0mInference done 2362/8355. 0.1146 s / img. ETA=0:11:37
[32m[04/28 19:36:05 d2.evaluation.evaluator]: [0mInference done 2405/8355. 0.1146 s / img. ETA=0:11:32
[32m[04/28 19:36:10 d2.evaluation.evaluator]: [0mInference done 2448/8355. 0.1146 s / img. ETA=0:11:27
[32m[04/28 19:36:15 d2.evaluation.evaluator]: [0mInference done 2491/8355. 0.1146 s / img. ETA=0:11:22
[32m[04/28 19:36:20 d2.evaluation.evaluator]: [0mInference done 2534/8355. 0.1146 s / img. ETA=0:11:17
[32m[04/28 19:36:25 d2.evaluation.evaluator]: [0mInference done 2577/8355. 0.1147 s / img. ETA=0:11:12
[32m[04/28 19:36:30 d2.evaluation.evaluator]: [0mInference done 2620/8355. 0.1147 s / img. ETA=0:11:07
[32m[04/28 19:36:35 d2.evaluation.evaluator]: [0mInference done 2663/8355. 0.1147 s / img. ETA=0:11:02
[32m[04/28 19:36:40 d2.evaluation.evaluator]: [0mInference done 2706/8355. 0.1147 s / img. ETA=0:10:57
[32m[04/28 19:36:45 d2.evaluation.evaluator]: [0mInference done 2749/8355. 0.1147 s / img. ETA=0:10:52
[32m[04/28 19:36:50 d2.evaluation.evaluator]: [0mInference done 2792/8355. 0.1147 s / img. ETA=0:10:47
[32m[04/28 19:36:55 d2.evaluation.evaluator]: [0mInference done 2835/8355. 0.1147 s / img. ETA=0:10:42
[32m[04/28 19:37:00 d2.evaluation.evaluator]: [0mInference done 2878/8355. 0.1147 s / img. ETA=0:10:37
[32m[04/28 19:37:05 d2.evaluation.evaluator]: [0mInference done 2922/8355. 0.1147 s / img. ETA=0:10:32
[32m[04/28 19:37:10 d2.evaluation.evaluator]: [0mInference done 2965/8355. 0.1148 s / img. ETA=0:10:27
[32m[04/28 19:37:15 d2.evaluation.evaluator]: [0mInference done 3009/8355. 0.1148 s / img. ETA=0:10:22
[32m[04/28 19:37:20 d2.evaluation.evaluator]: [0mInference done 3052/8355. 0.1148 s / img. ETA=0:10:17
[32m[04/28 19:37:25 d2.evaluation.evaluator]: [0mInference done 3095/8355. 0.1148 s / img. ETA=0:10:12
[32m[04/28 19:37:30 d2.evaluation.evaluator]: [0mInference done 3139/8355. 0.1148 s / img. ETA=0:10:07
[32m[04/28 19:37:36 d2.evaluation.evaluator]: [0mInference done 3183/8355. 0.1148 s / img. ETA=0:10:02
[32m[04/28 19:37:41 d2.evaluation.evaluator]: [0mInference done 3227/8355. 0.1147 s / img. ETA=0:09:57
[32m[04/28 19:37:46 d2.evaluation.evaluator]: [0mInference done 3270/8355. 0.1148 s / img. ETA=0:09:52
[32m[04/28 19:37:51 d2.evaluation.evaluator]: [0mInference done 3313/8355. 0.1148 s / img. ETA=0:09:47
[32m[04/28 19:37:56 d2.evaluation.evaluator]: [0mInference done 3357/8355. 0.1147 s / img. ETA=0:09:42
[32m[04/28 19:38:01 d2.evaluation.evaluator]: [0mInference done 3400/8355. 0.1147 s / img. ETA=0:09:37
[32m[04/28 19:38:06 d2.evaluation.evaluator]: [0mInference done 3444/8355. 0.1147 s / img. ETA=0:09:31
[32m[04/28 19:38:11 d2.evaluation.evaluator]: [0mInference done 3488/8355. 0.1147 s / img. ETA=0:09:26
[32m[04/28 19:38:16 d2.evaluation.evaluator]: [0mInference done 3532/8355. 0.1147 s / img. ETA=0:09:21
[32m[04/28 19:38:21 d2.evaluation.evaluator]: [0mInference done 3576/8355. 0.1147 s / img. ETA=0:09:16
[32m[04/28 19:38:26 d2.evaluation.evaluator]: [0mInference done 3619/8355. 0.1147 s / img. ETA=0:09:11
[32m[04/28 19:38:31 d2.evaluation.evaluator]: [0mInference done 3663/8355. 0.1147 s / img. ETA=0:09:06
[32m[04/28 19:38:36 d2.evaluation.evaluator]: [0mInference done 3707/8355. 0.1147 s / img. ETA=0:09:01
[32m[04/28 19:38:41 d2.evaluation.evaluator]: [0mInference done 3750/8355. 0.1147 s / img. ETA=0:08:56
[32m[04/28 19:38:47 d2.evaluation.evaluator]: [0mInference done 3794/8355. 0.1147 s / img. ETA=0:08:51
[32m[04/28 19:38:52 d2.evaluation.evaluator]: [0mInference done 3837/8355. 0.1147 s / img. ETA=0:08:46
[32m[04/28 19:38:57 d2.evaluation.evaluator]: [0mInference done 3880/8355. 0.1147 s / img. ETA=0:08:41
[32m[04/28 19:39:02 d2.evaluation.evaluator]: [0mInference done 3923/8355. 0.1147 s / img. ETA=0:08:36
[32m[04/28 19:39:07 d2.evaluation.evaluator]: [0mInference done 3967/8355. 0.1147 s / img. ETA=0:08:30
[32m[04/28 19:39:12 d2.evaluation.evaluator]: [0mInference done 4011/8355. 0.1147 s / img. ETA=0:08:25
[32m[04/28 19:39:17 d2.evaluation.evaluator]: [0mInference done 4054/8355. 0.1147 s / img. ETA=0:08:20
[32m[04/28 19:39:22 d2.evaluation.evaluator]: [0mInference done 4098/8355. 0.1147 s / img. ETA=0:08:15
[32m[04/28 19:39:27 d2.evaluation.evaluator]: [0mInference done 4141/8355. 0.1147 s / img. ETA=0:08:10
[32m[04/28 19:39:32 d2.evaluation.evaluator]: [0mInference done 4184/8355. 0.1147 s / img. ETA=0:08:05
[32m[04/28 19:39:37 d2.evaluation.evaluator]: [0mInference done 4227/8355. 0.1147 s / img. ETA=0:08:00
[32m[04/28 19:39:42 d2.evaluation.evaluator]: [0mInference done 4271/8355. 0.1147 s / img. ETA=0:07:55
[32m[04/28 19:39:47 d2.evaluation.evaluator]: [0mInference done 4315/8355. 0.1147 s / img. ETA=0:07:50
[32m[04/28 19:39:52 d2.evaluation.evaluator]: [0mInference done 4358/8355. 0.1147 s / img. ETA=0:07:45
[32m[04/28 19:39:57 d2.evaluation.evaluator]: [0mInference done 4401/8355. 0.1147 s / img. ETA=0:07:40
[32m[04/28 19:40:02 d2.evaluation.evaluator]: [0mInference done 4444/8355. 0.1147 s / img. ETA=0:07:35
[32m[04/28 19:40:07 d2.evaluation.evaluator]: [0mInference done 4488/8355. 0.1147 s / img. ETA=0:07:30
[32m[04/28 19:40:12 d2.evaluation.evaluator]: [0mInference done 4531/8355. 0.1147 s / img. ETA=0:07:25
[32m[04/28 19:40:18 d2.evaluation.evaluator]: [0mInference done 4574/8355. 0.1147 s / img. ETA=0:07:20
[32m[04/28 19:40:23 d2.evaluation.evaluator]: [0mInference done 4617/8355. 0.1147 s / img. ETA=0:07:15
[32m[04/28 19:40:28 d2.evaluation.evaluator]: [0mInference done 4660/8355. 0.1147 s / img. ETA=0:07:10
[32m[04/28 19:40:33 d2.evaluation.evaluator]: [0mInference done 4704/8355. 0.1147 s / img. ETA=0:07:05
[32m[04/28 19:40:38 d2.evaluation.evaluator]: [0mInference done 4747/8355. 0.1148 s / img. ETA=0:07:00
[32m[04/28 19:40:43 d2.evaluation.evaluator]: [0mInference done 4790/8355. 0.1148 s / img. ETA=0:06:55
[32m[04/28 19:40:48 d2.evaluation.evaluator]: [0mInference done 4833/8355. 0.1148 s / img. ETA=0:06:50
[32m[04/28 19:40:53 d2.evaluation.evaluator]: [0mInference done 4877/8355. 0.1148 s / img. ETA=0:06:45
[32m[04/28 19:40:58 d2.evaluation.evaluator]: [0mInference done 4920/8355. 0.1148 s / img. ETA=0:06:40
[32m[04/28 19:41:03 d2.evaluation.evaluator]: [0mInference done 4964/8355. 0.1148 s / img. ETA=0:06:35
[32m[04/28 19:41:08 d2.evaluation.evaluator]: [0mInference done 5007/8355. 0.1148 s / img. ETA=0:06:30
[32m[04/28 19:41:13 d2.evaluation.evaluator]: [0mInference done 5050/8355. 0.1148 s / img. ETA=0:06:25
[32m[04/28 19:41:18 d2.evaluation.evaluator]: [0mInference done 5093/8355. 0.1148 s / img. ETA=0:06:20
[32m[04/28 19:41:23 d2.evaluation.evaluator]: [0mInference done 5136/8355. 0.1148 s / img. ETA=0:06:15
[32m[04/28 19:41:28 d2.evaluation.evaluator]: [0mInference done 5179/8355. 0.1148 s / img. ETA=0:06:10
[32m[04/28 19:41:33 d2.evaluation.evaluator]: [0mInference done 5222/8355. 0.1148 s / img. ETA=0:06:05
[32m[04/28 19:41:38 d2.evaluation.evaluator]: [0mInference done 5265/8355. 0.1148 s / img. ETA=0:06:00
[32m[04/28 19:41:43 d2.evaluation.evaluator]: [0mInference done 5308/8355. 0.1148 s / img. ETA=0:05:55
[32m[04/28 19:41:48 d2.evaluation.evaluator]: [0mInference done 5351/8355. 0.1148 s / img. ETA=0:05:50
[32m[04/28 19:41:53 d2.evaluation.evaluator]: [0mInference done 5394/8355. 0.1148 s / img. ETA=0:05:45
[32m[04/28 19:41:58 d2.evaluation.evaluator]: [0mInference done 5437/8355. 0.1148 s / img. ETA=0:05:40
[32m[04/28 19:42:03 d2.evaluation.evaluator]: [0mInference done 5480/8355. 0.1148 s / img. ETA=0:05:35
[32m[04/28 19:42:09 d2.evaluation.evaluator]: [0mInference done 5524/8355. 0.1148 s / img. ETA=0:05:29
[32m[04/28 19:42:14 d2.evaluation.evaluator]: [0mInference done 5567/8355. 0.1148 s / img. ETA=0:05:24
[32m[04/28 19:42:19 d2.evaluation.evaluator]: [0mInference done 5610/8355. 0.1148 s / img. ETA=0:05:19
[32m[04/28 19:42:24 d2.evaluation.evaluator]: [0mInference done 5651/8355. 0.1149 s / img. ETA=0:05:15
[32m[04/28 19:42:29 d2.evaluation.evaluator]: [0mInference done 5694/8355. 0.1149 s / img. ETA=0:05:10
[32m[04/28 19:42:34 d2.evaluation.evaluator]: [0mInference done 5737/8355. 0.1149 s / img. ETA=0:05:05
[32m[04/28 19:42:39 d2.evaluation.evaluator]: [0mInference done 5780/8355. 0.1149 s / img. ETA=0:05:00
[32m[04/28 19:42:44 d2.evaluation.evaluator]: [0mInference done 5823/8355. 0.1149 s / img. ETA=0:04:55
[32m[04/28 19:42:49 d2.evaluation.evaluator]: [0mInference done 5866/8355. 0.1149 s / img. ETA=0:04:50
[32m[04/28 19:42:54 d2.evaluation.evaluator]: [0mInference done 5909/8355. 0.1149 s / img. ETA=0:04:45
[32m[04/28 19:42:59 d2.evaluation.evaluator]: [0mInference done 5952/8355. 0.1149 s / img. ETA=0:04:40
[32m[04/28 19:43:04 d2.evaluation.evaluator]: [0mInference done 5995/8355. 0.1149 s / img. ETA=0:04:35
[32m[04/28 19:43:09 d2.evaluation.evaluator]: [0mInference done 6038/8355. 0.1149 s / img. ETA=0:04:30
[32m[04/28 19:43:14 d2.evaluation.evaluator]: [0mInference done 6081/8355. 0.1149 s / img. ETA=0:04:25
[32m[04/28 19:43:19 d2.evaluation.evaluator]: [0mInference done 6124/8355. 0.1149 s / img. ETA=0:04:20
[32m[04/28 19:43:24 d2.evaluation.evaluator]: [0mInference done 6167/8355. 0.1150 s / img. ETA=0:04:15
[32m[04/28 19:43:29 d2.evaluation.evaluator]: [0mInference done 6210/8355. 0.1150 s / img. ETA=0:04:10
[32m[04/28 19:43:35 d2.evaluation.evaluator]: [0mInference done 6253/8355. 0.1150 s / img. ETA=0:04:05
[32m[04/28 19:43:40 d2.evaluation.evaluator]: [0mInference done 6296/8355. 0.1150 s / img. ETA=0:04:00
[32m[04/28 19:43:45 d2.evaluation.evaluator]: [0mInference done 6339/8355. 0.1150 s / img. ETA=0:03:55
[32m[04/28 19:43:50 d2.evaluation.evaluator]: [0mInference done 6382/8355. 0.1150 s / img. ETA=0:03:50
[32m[04/28 19:43:55 d2.evaluation.evaluator]: [0mInference done 6425/8355. 0.1150 s / img. ETA=0:03:45
[32m[04/28 19:44:00 d2.evaluation.evaluator]: [0mInference done 6468/8355. 0.1150 s / img. ETA=0:03:40
[32m[04/28 19:44:05 d2.evaluation.evaluator]: [0mInference done 6512/8355. 0.1150 s / img. ETA=0:03:35
[32m[04/28 19:44:10 d2.evaluation.evaluator]: [0mInference done 6555/8355. 0.1150 s / img. ETA=0:03:30
[32m[04/28 19:44:15 d2.evaluation.evaluator]: [0mInference done 6598/8355. 0.1150 s / img. ETA=0:03:25
[32m[04/28 19:44:20 d2.evaluation.evaluator]: [0mInference done 6641/8355. 0.1150 s / img. ETA=0:03:20
[32m[04/28 19:44:25 d2.evaluation.evaluator]: [0mInference done 6685/8355. 0.1150 s / img. ETA=0:03:14
[32m[04/28 19:44:30 d2.evaluation.evaluator]: [0mInference done 6729/8355. 0.1150 s / img. ETA=0:03:09
[32m[04/28 19:44:35 d2.evaluation.evaluator]: [0mInference done 6773/8355. 0.1150 s / img. ETA=0:03:04
[32m[04/28 19:44:40 d2.evaluation.evaluator]: [0mInference done 6816/8355. 0.1150 s / img. ETA=0:02:59
[32m[04/28 19:44:45 d2.evaluation.evaluator]: [0mInference done 6859/8355. 0.1150 s / img. ETA=0:02:54
[32m[04/28 19:44:50 d2.evaluation.evaluator]: [0mInference done 6902/8355. 0.1150 s / img. ETA=0:02:49
[32m[04/28 19:44:55 d2.evaluation.evaluator]: [0mInference done 6945/8355. 0.1150 s / img. ETA=0:02:44
[32m[04/28 19:45:01 d2.evaluation.evaluator]: [0mInference done 6988/8355. 0.1150 s / img. ETA=0:02:39
[32m[04/28 19:45:06 d2.evaluation.evaluator]: [0mInference done 7031/8355. 0.1150 s / img. ETA=0:02:34
[32m[04/28 19:45:11 d2.evaluation.evaluator]: [0mInference done 7074/8355. 0.1150 s / img. ETA=0:02:29
[32m[04/28 19:45:16 d2.evaluation.evaluator]: [0mInference done 7117/8355. 0.1150 s / img. ETA=0:02:24
[32m[04/28 19:45:21 d2.evaluation.evaluator]: [0mInference done 7160/8355. 0.1150 s / img. ETA=0:02:19
[32m[04/28 19:45:26 d2.evaluation.evaluator]: [0mInference done 7203/8355. 0.1150 s / img. ETA=0:02:14
[32m[04/28 19:45:31 d2.evaluation.evaluator]: [0mInference done 7246/8355. 0.1150 s / img. ETA=0:02:09
[32m[04/28 19:45:36 d2.evaluation.evaluator]: [0mInference done 7288/8355. 0.1150 s / img. ETA=0:02:04
[32m[04/28 19:45:41 d2.evaluation.evaluator]: [0mInference done 7331/8355. 0.1151 s / img. ETA=0:01:59
[32m[04/28 19:45:46 d2.evaluation.evaluator]: [0mInference done 7374/8355. 0.1151 s / img. ETA=0:01:54
[32m[04/28 19:45:51 d2.evaluation.evaluator]: [0mInference done 7417/8355. 0.1151 s / img. ETA=0:01:49
[32m[04/28 19:45:56 d2.evaluation.evaluator]: [0mInference done 7460/8355. 0.1151 s / img. ETA=0:01:44
[32m[04/28 19:46:01 d2.evaluation.evaluator]: [0mInference done 7503/8355. 0.1151 s / img. ETA=0:01:39
[32m[04/28 19:46:06 d2.evaluation.evaluator]: [0mInference done 7546/8355. 0.1151 s / img. ETA=0:01:34
[32m[04/28 19:46:11 d2.evaluation.evaluator]: [0mInference done 7589/8355. 0.1151 s / img. ETA=0:01:29
[32m[04/28 19:46:17 d2.evaluation.evaluator]: [0mInference done 7632/8355. 0.1151 s / img. ETA=0:01:24
[32m[04/28 19:46:22 d2.evaluation.evaluator]: [0mInference done 7675/8355. 0.1151 s / img. ETA=0:01:19
[32m[04/28 19:46:27 d2.evaluation.evaluator]: [0mInference done 7718/8355. 0.1151 s / img. ETA=0:01:14
[32m[04/28 19:46:32 d2.evaluation.evaluator]: [0mInference done 7761/8355. 0.1151 s / img. ETA=0:01:09
[32m[04/28 19:46:37 d2.evaluation.evaluator]: [0mInference done 7804/8355. 0.1151 s / img. ETA=0:01:04
[32m[04/28 19:46:42 d2.evaluation.evaluator]: [0mInference done 7847/8355. 0.1151 s / img. ETA=0:00:59
[32m[04/28 19:46:47 d2.evaluation.evaluator]: [0mInference done 7890/8355. 0.1151 s / img. ETA=0:00:54
[32m[04/28 19:46:52 d2.evaluation.evaluator]: [0mInference done 7933/8355. 0.1151 s / img. ETA=0:00:49
[32m[04/28 19:46:57 d2.evaluation.evaluator]: [0mInference done 7976/8355. 0.1151 s / img. ETA=0:00:44
[32m[04/28 19:47:02 d2.evaluation.evaluator]: [0mInference done 8019/8355. 0.1151 s / img. ETA=0:00:39
[32m[04/28 19:47:07 d2.evaluation.evaluator]: [0mInference done 8063/8355. 0.1151 s / img. ETA=0:00:34
[32m[04/28 19:47:12 d2.evaluation.evaluator]: [0mInference done 8106/8355. 0.1151 s / img. ETA=0:00:29
[32m[04/28 19:47:17 d2.evaluation.evaluator]: [0mInference done 8149/8355. 0.1151 s / img. ETA=0:00:24
[32m[04/28 19:47:22 d2.evaluation.evaluator]: [0mInference done 8192/8355. 0.1151 s / img. ETA=0:00:19
[32m[04/28 19:47:27 d2.evaluation.evaluator]: [0mInference done 8235/8355. 0.1151 s / img. ETA=0:00:14
[32m[04/28 19:47:32 d2.evaluation.evaluator]: [0mInference done 8278/8355. 0.1151 s / img. ETA=0:00:09
[32m[04/28 19:47:37 d2.evaluation.evaluator]: [0mInference done 8321/8355. 0.1151 s / img. ETA=0:00:03
[32m[04/28 19:47:41 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:16.102644 (0.116899 s / img per device, on 1 devices)
[32m[04/28 19:47:41 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:01 (0.115127 s / img per device, on 1 devices)
[32m[04/28 19:47:42 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 19:47:42 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 19:47:42 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.55s).
Accumulating evaluation results...
DONE (t=2.24s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.507
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.892
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.504
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.409
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.628
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.769
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.553
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.575
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.489
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.692
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.814
[32m[04/28 19:48:05 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.672 | 89.239 | 50.425 | 40.853 | 62.762 | 76.858 |
[32m[04/28 19:48:05 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 49.872 | bicycle       | 42.019 | car            | 60.126 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 19:48:05 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 19:48:05 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 19:48:05 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 19:48:07 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1148 s / img. ETA=0:02:24
[32m[04/28 19:48:12 d2.evaluation.evaluator]: [0mInference done 55/1257. 0.1143 s / img. ETA=0:02:19
[32m[04/28 19:48:17 d2.evaluation.evaluator]: [0mInference done 98/1257. 0.1145 s / img. ETA=0:02:14
[32m[04/28 19:48:22 d2.evaluation.evaluator]: [0mInference done 142/1257. 0.1145 s / img. ETA=0:02:09
[32m[04/28 19:48:27 d2.evaluation.evaluator]: [0mInference done 185/1257. 0.1146 s / img. ETA=0:02:04
[32m[04/28 19:48:32 d2.evaluation.evaluator]: [0mInference done 229/1257. 0.1145 s / img. ETA=0:01:59
[32m[04/28 19:48:37 d2.evaluation.evaluator]: [0mInference done 272/1257. 0.1146 s / img. ETA=0:01:54
[32m[04/28 19:48:43 d2.evaluation.evaluator]: [0mInference done 316/1257. 0.1146 s / img. ETA=0:01:49
[32m[04/28 19:48:48 d2.evaluation.evaluator]: [0mInference done 360/1257. 0.1146 s / img. ETA=0:01:44
[32m[04/28 19:48:53 d2.evaluation.evaluator]: [0mInference done 403/1257. 0.1146 s / img. ETA=0:01:39
[32m[04/28 19:48:58 d2.evaluation.evaluator]: [0mInference done 447/1257. 0.1146 s / img. ETA=0:01:34
[32m[04/28 19:49:03 d2.evaluation.evaluator]: [0mInference done 491/1257. 0.1146 s / img. ETA=0:01:29
[32m[04/28 19:49:08 d2.evaluation.evaluator]: [0mInference done 534/1257. 0.1146 s / img. ETA=0:01:24
[32m[04/28 19:49:13 d2.evaluation.evaluator]: [0mInference done 578/1257. 0.1146 s / img. ETA=0:01:18
[32m[04/28 19:49:18 d2.evaluation.evaluator]: [0mInference done 621/1257. 0.1146 s / img. ETA=0:01:13
[32m[04/28 19:49:23 d2.evaluation.evaluator]: [0mInference done 664/1257. 0.1146 s / img. ETA=0:01:08
[32m[04/28 19:49:28 d2.evaluation.evaluator]: [0mInference done 707/1257. 0.1146 s / img. ETA=0:01:03
[32m[04/28 19:49:33 d2.evaluation.evaluator]: [0mInference done 750/1257. 0.1146 s / img. ETA=0:00:58
[32m[04/28 19:49:38 d2.evaluation.evaluator]: [0mInference done 793/1257. 0.1146 s / img. ETA=0:00:53
[32m[04/28 19:49:43 d2.evaluation.evaluator]: [0mInference done 836/1257. 0.1147 s / img. ETA=0:00:48
[32m[04/28 19:49:48 d2.evaluation.evaluator]: [0mInference done 879/1257. 0.1147 s / img. ETA=0:00:44
[32m[04/28 19:49:53 d2.evaluation.evaluator]: [0mInference done 922/1257. 0.1147 s / img. ETA=0:00:39
[32m[04/28 19:49:58 d2.evaluation.evaluator]: [0mInference done 965/1257. 0.1147 s / img. ETA=0:00:34
[32m[04/28 19:50:03 d2.evaluation.evaluator]: [0mInference done 1008/1257. 0.1148 s / img. ETA=0:00:28
[32m[04/28 19:50:08 d2.evaluation.evaluator]: [0mInference done 1051/1257. 0.1148 s / img. ETA=0:00:23
[32m[04/28 19:50:13 d2.evaluation.evaluator]: [0mInference done 1094/1257. 0.1148 s / img. ETA=0:00:18
[32m[04/28 19:50:18 d2.evaluation.evaluator]: [0mInference done 1137/1257. 0.1148 s / img. ETA=0:00:13
[32m[04/28 19:50:23 d2.evaluation.evaluator]: [0mInference done 1180/1257. 0.1149 s / img. ETA=0:00:08
[32m[04/28 19:50:28 d2.evaluation.evaluator]: [0mInference done 1223/1257. 0.1149 s / img. ETA=0:00:03
[32m[04/28 19:50:32 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:25.986280 (0.116602 s / img per device, on 1 devices)
[32m[04/28 19:50:32 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:23 (0.114882 s / img per device, on 1 devices)
[32m[04/28 19:50:32 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 19:50:32 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 19:50:32 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.08s).
Accumulating evaluation results...
DONE (t=0.37s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.759
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.349
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.288
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.462
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.595
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.471
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.384
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.661
[32m[04/28 19:50:36 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.552 | 75.853 | 34.868 | 28.778 | 46.180 | 59.540 |
[32m[04/28 19:50:36 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 41.107 | bicycle       | 23.729 | car            | 53.819 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  30  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 19:50:37 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 19:50:37 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 19:50:37 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 19:50:37 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 19:50:38 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 19:50:38 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 19:50:38 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 19:50:58 d2.utils.events]: [0m eta: 0:16:33  iter: 19  total_loss: 0.427  loss_cls: 0.125  loss_box_reg: 0.253  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0120  data_time: 0.0220  lr: 0.000100  max_mem: 5397M
[32m[04/28 19:51:19 d2.utils.events]: [0m eta: 0:16:20  iter: 39  total_loss: 0.436  loss_cls: 0.128  loss_box_reg: 0.252  loss_rpn_cls: 0.003  loss_rpn_loc: 0.041  time: 1.0195  data_time: 0.0074  lr: 0.000200  max_mem: 5397M
[32m[04/28 19:51:39 d2.utils.events]: [0m eta: 0:16:09  iter: 59  total_loss: 0.429  loss_cls: 0.130  loss_box_reg: 0.265  loss_rpn_cls: 0.005  loss_rpn_loc: 0.038  time: 1.0212  data_time: 0.0075  lr: 0.000300  max_mem: 5397M
[32m[04/28 19:52:00 d2.utils.events]: [0m eta: 0:15:55  iter: 79  total_loss: 0.469  loss_cls: 0.143  loss_box_reg: 0.280  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0277  data_time: 0.0075  lr: 0.000400  max_mem: 5397M
[32m[04/28 19:52:21 d2.utils.events]: [0m eta: 0:15:34  iter: 99  total_loss: 0.476  loss_cls: 0.136  loss_box_reg: 0.281  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0265  data_time: 0.0074  lr: 0.000500  max_mem: 5397M
[32m[04/28 19:52:41 d2.utils.events]: [0m eta: 0:15:15  iter: 119  total_loss: 0.438  loss_cls: 0.139  loss_box_reg: 0.257  loss_rpn_cls: 0.005  loss_rpn_loc: 0.038  time: 1.0279  data_time: 0.0075  lr: 0.000599  max_mem: 5397M
[32m[04/28 19:53:03 d2.utils.events]: [0m eta: 0:14:58  iter: 139  total_loss: 0.488  loss_cls: 0.145  loss_box_reg: 0.283  loss_rpn_cls: 0.005  loss_rpn_loc: 0.047  time: 1.0315  data_time: 0.0075  lr: 0.000699  max_mem: 5397M
[32m[04/28 19:53:23 d2.utils.events]: [0m eta: 0:14:34  iter: 159  total_loss: 0.441  loss_cls: 0.126  loss_box_reg: 0.259  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0311  data_time: 0.0075  lr: 0.000799  max_mem: 5397M
[32m[04/28 19:53:43 d2.utils.events]: [0m eta: 0:14:13  iter: 179  total_loss: 0.447  loss_cls: 0.135  loss_box_reg: 0.270  loss_rpn_cls: 0.003  loss_rpn_loc: 0.043  time: 1.0286  data_time: 0.0075  lr: 0.000899  max_mem: 5397M
[32m[04/28 19:54:04 d2.utils.events]: [0m eta: 0:13:52  iter: 199  total_loss: 0.456  loss_cls: 0.127  loss_box_reg: 0.275  loss_rpn_cls: 0.004  loss_rpn_loc: 0.036  time: 1.0295  data_time: 0.0076  lr: 0.000999  max_mem: 5397M
[32m[04/28 19:54:25 d2.utils.events]: [0m eta: 0:13:31  iter: 219  total_loss: 0.510  loss_cls: 0.151  loss_box_reg: 0.300  loss_rpn_cls: 0.005  loss_rpn_loc: 0.048  time: 1.0290  data_time: 0.0077  lr: 0.001099  max_mem: 5397M
[32m[04/28 19:54:46 d2.utils.events]: [0m eta: 0:13:11  iter: 239  total_loss: 0.471  loss_cls: 0.128  loss_box_reg: 0.274  loss_rpn_cls: 0.005  loss_rpn_loc: 0.042  time: 1.0310  data_time: 0.0076  lr: 0.001199  max_mem: 5397M
[32m[04/28 19:55:06 d2.utils.events]: [0m eta: 0:12:50  iter: 259  total_loss: 0.414  loss_cls: 0.128  loss_box_reg: 0.243  loss_rpn_cls: 0.004  loss_rpn_loc: 0.040  time: 1.0303  data_time: 0.0075  lr: 0.001299  max_mem: 5397M
[32m[04/28 19:55:27 d2.utils.events]: [0m eta: 0:12:28  iter: 279  total_loss: 0.443  loss_cls: 0.128  loss_box_reg: 0.262  loss_rpn_cls: 0.005  loss_rpn_loc: 0.046  time: 1.0299  data_time: 0.0076  lr: 0.001399  max_mem: 5397M
[32m[04/28 19:55:47 d2.utils.events]: [0m eta: 0:12:08  iter: 299  total_loss: 0.415  loss_cls: 0.127  loss_box_reg: 0.253  loss_rpn_cls: 0.006  loss_rpn_loc: 0.051  time: 1.0295  data_time: 0.0073  lr: 0.001499  max_mem: 5397M
[32m[04/28 19:56:08 d2.utils.events]: [0m eta: 0:11:47  iter: 319  total_loss: 0.507  loss_cls: 0.148  loss_box_reg: 0.289  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0299  data_time: 0.0077  lr: 0.001598  max_mem: 5397M
[32m[04/28 19:56:29 d2.utils.events]: [0m eta: 0:11:27  iter: 339  total_loss: 0.484  loss_cls: 0.143  loss_box_reg: 0.280  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0300  data_time: 0.0076  lr: 0.001698  max_mem: 5397M
[32m[04/28 19:56:50 d2.utils.events]: [0m eta: 0:11:06  iter: 359  total_loss: 0.493  loss_cls: 0.159  loss_box_reg: 0.291  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0303  data_time: 0.0075  lr: 0.001798  max_mem: 5397M
[32m[04/28 19:57:10 d2.utils.events]: [0m eta: 0:10:46  iter: 379  total_loss: 0.485  loss_cls: 0.146  loss_box_reg: 0.288  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0306  data_time: 0.0077  lr: 0.001898  max_mem: 5397M
[32m[04/28 19:57:31 d2.utils.events]: [0m eta: 0:10:25  iter: 399  total_loss: 0.497  loss_cls: 0.145  loss_box_reg: 0.286  loss_rpn_cls: 0.005  loss_rpn_loc: 0.048  time: 1.0306  data_time: 0.0076  lr: 0.001998  max_mem: 5397M
[32m[04/28 19:57:52 d2.utils.events]: [0m eta: 0:10:04  iter: 419  total_loss: 0.479  loss_cls: 0.144  loss_box_reg: 0.273  loss_rpn_cls: 0.006  loss_rpn_loc: 0.048  time: 1.0306  data_time: 0.0073  lr: 0.002098  max_mem: 5397M
[32m[04/28 19:58:12 d2.utils.events]: [0m eta: 0:09:43  iter: 439  total_loss: 0.472  loss_cls: 0.149  loss_box_reg: 0.276  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0307  data_time: 0.0076  lr: 0.002198  max_mem: 5397M
[32m[04/28 19:58:33 d2.utils.events]: [0m eta: 0:09:22  iter: 459  total_loss: 0.474  loss_cls: 0.143  loss_box_reg: 0.278  loss_rpn_cls: 0.006  loss_rpn_loc: 0.044  time: 1.0305  data_time: 0.0075  lr: 0.002298  max_mem: 5397M
[32m[04/28 19:58:53 d2.utils.events]: [0m eta: 0:09:01  iter: 479  total_loss: 0.391  loss_cls: 0.112  loss_box_reg: 0.242  loss_rpn_cls: 0.004  loss_rpn_loc: 0.037  time: 1.0294  data_time: 0.0075  lr: 0.002398  max_mem: 5397M
[32m[04/28 19:59:14 d2.utils.events]: [0m eta: 0:08:40  iter: 499  total_loss: 0.480  loss_cls: 0.152  loss_box_reg: 0.289  loss_rpn_cls: 0.003  loss_rpn_loc: 0.048  time: 1.0295  data_time: 0.0075  lr: 0.002498  max_mem: 5397M
[32m[04/28 19:59:35 d2.utils.events]: [0m eta: 0:08:20  iter: 519  total_loss: 0.463  loss_cls: 0.136  loss_box_reg: 0.284  loss_rpn_cls: 0.004  loss_rpn_loc: 0.039  time: 1.0302  data_time: 0.0078  lr: 0.002597  max_mem: 5397M
[32m[04/28 19:59:55 d2.utils.events]: [0m eta: 0:07:59  iter: 539  total_loss: 0.460  loss_cls: 0.136  loss_box_reg: 0.275  loss_rpn_cls: 0.003  loss_rpn_loc: 0.037  time: 1.0299  data_time: 0.0075  lr: 0.002697  max_mem: 5397M
[32m[04/28 20:00:16 d2.utils.events]: [0m eta: 0:07:38  iter: 559  total_loss: 0.462  loss_cls: 0.136  loss_box_reg: 0.269  loss_rpn_cls: 0.004  loss_rpn_loc: 0.044  time: 1.0301  data_time: 0.0075  lr: 0.002797  max_mem: 5397M
[32m[04/28 20:00:37 d2.utils.events]: [0m eta: 0:07:17  iter: 579  total_loss: 0.437  loss_cls: 0.136  loss_box_reg: 0.270  loss_rpn_cls: 0.004  loss_rpn_loc: 0.041  time: 1.0299  data_time: 0.0076  lr: 0.002897  max_mem: 5397M
[32m[04/28 20:00:57 d2.utils.events]: [0m eta: 0:06:56  iter: 599  total_loss: 0.456  loss_cls: 0.138  loss_box_reg: 0.289  loss_rpn_cls: 0.003  loss_rpn_loc: 0.047  time: 1.0291  data_time: 0.0074  lr: 0.002997  max_mem: 5397M
[32m[04/28 20:01:17 d2.utils.events]: [0m eta: 0:06:35  iter: 619  total_loss: 0.440  loss_cls: 0.130  loss_box_reg: 0.258  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0290  data_time: 0.0076  lr: 0.003097  max_mem: 5397M
[32m[04/28 20:01:38 d2.utils.events]: [0m eta: 0:06:14  iter: 639  total_loss: 0.448  loss_cls: 0.133  loss_box_reg: 0.266  loss_rpn_cls: 0.003  loss_rpn_loc: 0.036  time: 1.0288  data_time: 0.0076  lr: 0.003197  max_mem: 5397M
[32m[04/28 20:01:59 d2.utils.events]: [0m eta: 0:05:53  iter: 659  total_loss: 0.446  loss_cls: 0.126  loss_box_reg: 0.265  loss_rpn_cls: 0.005  loss_rpn_loc: 0.048  time: 1.0289  data_time: 0.0073  lr: 0.003297  max_mem: 5397M
[32m[04/28 20:02:19 d2.utils.events]: [0m eta: 0:05:33  iter: 679  total_loss: 0.470  loss_cls: 0.140  loss_box_reg: 0.287  loss_rpn_cls: 0.004  loss_rpn_loc: 0.037  time: 1.0290  data_time: 0.0075  lr: 0.003397  max_mem: 5397M
[32m[04/28 20:02:40 d2.utils.events]: [0m eta: 0:05:12  iter: 699  total_loss: 0.519  loss_cls: 0.158  loss_box_reg: 0.296  loss_rpn_cls: 0.006  loss_rpn_loc: 0.055  time: 1.0287  data_time: 0.0077  lr: 0.003497  max_mem: 5397M
[32m[04/28 20:03:00 d2.utils.events]: [0m eta: 0:04:51  iter: 719  total_loss: 0.471  loss_cls: 0.133  loss_box_reg: 0.286  loss_rpn_cls: 0.006  loss_rpn_loc: 0.044  time: 1.0285  data_time: 0.0075  lr: 0.003596  max_mem: 5397M
[32m[04/28 20:03:21 d2.utils.events]: [0m eta: 0:04:30  iter: 739  total_loss: 0.476  loss_cls: 0.137  loss_box_reg: 0.282  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0282  data_time: 0.0075  lr: 0.003696  max_mem: 5397M
[32m[04/28 20:03:41 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.469  loss_cls: 0.141  loss_box_reg: 0.286  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0280  data_time: 0.0075  lr: 0.003796  max_mem: 5397M
[32m[04/28 20:04:02 d2.utils.events]: [0m eta: 0:03:49  iter: 779  total_loss: 0.437  loss_cls: 0.125  loss_box_reg: 0.255  loss_rpn_cls: 0.005  loss_rpn_loc: 0.046  time: 1.0286  data_time: 0.0077  lr: 0.003896  max_mem: 5397M
[32m[04/28 20:04:23 d2.utils.events]: [0m eta: 0:03:28  iter: 799  total_loss: 0.561  loss_cls: 0.171  loss_box_reg: 0.332  loss_rpn_cls: 0.006  loss_rpn_loc: 0.050  time: 1.0284  data_time: 0.0076  lr: 0.003996  max_mem: 5397M
[32m[04/28 20:04:44 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.573  loss_cls: 0.165  loss_box_reg: 0.341  loss_rpn_cls: 0.004  loss_rpn_loc: 0.057  time: 1.0288  data_time: 0.0078  lr: 0.004096  max_mem: 5397M
[32m[04/28 20:05:05 d2.utils.events]: [0m eta: 0:02:47  iter: 839  total_loss: 0.481  loss_cls: 0.139  loss_box_reg: 0.289  loss_rpn_cls: 0.003  loss_rpn_loc: 0.041  time: 1.0293  data_time: 0.0076  lr: 0.004196  max_mem: 5397M
[32m[04/28 20:05:25 d2.utils.events]: [0m eta: 0:02:26  iter: 859  total_loss: 0.520  loss_cls: 0.164  loss_box_reg: 0.298  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 1.0292  data_time: 0.0077  lr: 0.004296  max_mem: 5397M
[32m[04/28 20:05:46 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.459  loss_cls: 0.145  loss_box_reg: 0.280  loss_rpn_cls: 0.004  loss_rpn_loc: 0.036  time: 1.0294  data_time: 0.0077  lr: 0.004396  max_mem: 5397M
[32m[04/28 20:06:06 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.528  loss_cls: 0.169  loss_box_reg: 0.323  loss_rpn_cls: 0.008  loss_rpn_loc: 0.053  time: 1.0293  data_time: 0.0076  lr: 0.004496  max_mem: 5397M
[32m[04/28 20:06:27 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.545  loss_cls: 0.161  loss_box_reg: 0.319  loss_rpn_cls: 0.010  loss_rpn_loc: 0.048  time: 1.0291  data_time: 0.0075  lr: 0.004595  max_mem: 5397M
[32m[04/28 20:06:48 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.500  loss_cls: 0.152  loss_box_reg: 0.299  loss_rpn_cls: 0.008  loss_rpn_loc: 0.047  time: 1.0297  data_time: 0.0075  lr: 0.004695  max_mem: 5397M
[32m[04/28 20:07:09 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.493  loss_cls: 0.146  loss_box_reg: 0.273  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0295  data_time: 0.0073  lr: 0.004795  max_mem: 5397M
[32m[04/28 20:07:29 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.497  loss_cls: 0.143  loss_box_reg: 0.292  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0291  data_time: 0.0076  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 20:07:51 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 20:07:51 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 20:07:51 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 20:07:51 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.464  loss_cls: 0.140  loss_box_reg: 0.277  loss_rpn_cls: 0.005  loss_rpn_loc: 0.045  time: 1.0286  data_time: 0.0075  lr: 0.004995  max_mem: 5397M
[32m[04/28 20:07:52 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:06 (1.0297 s / it)
[32m[04/28 20:07:52 d2.engine.hooks]: [0mTotal training time: 0:17:11 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 20:07:53 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 20:07:53 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 20:07:54 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 20:07:55 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1142 s / img. ETA=0:16:04
[32m[04/28 20:08:00 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1140 s / img. ETA=0:16:00
[32m[04/28 20:08:05 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1139 s / img. ETA=0:15:54
[32m[04/28 20:08:10 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1140 s / img. ETA=0:15:49
[32m[04/28 20:08:15 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1139 s / img. ETA=0:15:44
[32m[04/28 20:08:20 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1140 s / img. ETA=0:15:39
[32m[04/28 20:08:26 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1141 s / img. ETA=0:15:35
[32m[04/28 20:08:31 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1141 s / img. ETA=0:15:30
[32m[04/28 20:08:36 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1141 s / img. ETA=0:15:25
[32m[04/28 20:08:41 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1141 s / img. ETA=0:15:20
[32m[04/28 20:08:46 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1142 s / img. ETA=0:15:15
[32m[04/28 20:08:51 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1141 s / img. ETA=0:15:09
[32m[04/28 20:08:56 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1141 s / img. ETA=0:15:04
[32m[04/28 20:09:01 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1141 s / img. ETA=0:14:59
[32m[04/28 20:09:06 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1141 s / img. ETA=0:14:54
[32m[04/28 20:09:11 d2.evaluation.evaluator]: [0mInference done 670/8355. 0.1141 s / img. ETA=0:14:49
[32m[04/28 20:09:16 d2.evaluation.evaluator]: [0mInference done 713/8355. 0.1142 s / img. ETA=0:14:44
[32m[04/28 20:09:21 d2.evaluation.evaluator]: [0mInference done 757/8355. 0.1142 s / img. ETA=0:14:39
[32m[04/28 20:09:26 d2.evaluation.evaluator]: [0mInference done 800/8355. 0.1142 s / img. ETA=0:14:35
[32m[04/28 20:09:32 d2.evaluation.evaluator]: [0mInference done 844/8355. 0.1142 s / img. ETA=0:14:30
[32m[04/28 20:09:37 d2.evaluation.evaluator]: [0mInference done 887/8355. 0.1143 s / img. ETA=0:14:25
[32m[04/28 20:09:42 d2.evaluation.evaluator]: [0mInference done 930/8355. 0.1143 s / img. ETA=0:14:20
[32m[04/28 20:09:47 d2.evaluation.evaluator]: [0mInference done 974/8355. 0.1143 s / img. ETA=0:14:15
[32m[04/28 20:09:52 d2.evaluation.evaluator]: [0mInference done 1017/8355. 0.1143 s / img. ETA=0:14:10
[32m[04/28 20:09:57 d2.evaluation.evaluator]: [0mInference done 1061/8355. 0.1143 s / img. ETA=0:14:05
[32m[04/28 20:10:02 d2.evaluation.evaluator]: [0mInference done 1105/8355. 0.1142 s / img. ETA=0:14:00
[32m[04/28 20:10:07 d2.evaluation.evaluator]: [0mInference done 1149/8355. 0.1142 s / img. ETA=0:13:54
[32m[04/28 20:10:12 d2.evaluation.evaluator]: [0mInference done 1193/8355. 0.1142 s / img. ETA=0:13:49
[32m[04/28 20:10:17 d2.evaluation.evaluator]: [0mInference done 1237/8355. 0.1142 s / img. ETA=0:13:44
[32m[04/28 20:10:22 d2.evaluation.evaluator]: [0mInference done 1281/8355. 0.1142 s / img. ETA=0:13:39
[32m[04/28 20:10:27 d2.evaluation.evaluator]: [0mInference done 1325/8355. 0.1141 s / img. ETA=0:13:34
[32m[04/28 20:10:32 d2.evaluation.evaluator]: [0mInference done 1369/8355. 0.1141 s / img. ETA=0:13:28
[32m[04/28 20:10:37 d2.evaluation.evaluator]: [0mInference done 1412/8355. 0.1142 s / img. ETA=0:13:24
[32m[04/28 20:10:42 d2.evaluation.evaluator]: [0mInference done 1456/8355. 0.1141 s / img. ETA=0:13:18
[32m[04/28 20:10:47 d2.evaluation.evaluator]: [0mInference done 1499/8355. 0.1142 s / img. ETA=0:13:14
[32m[04/28 20:10:52 d2.evaluation.evaluator]: [0mInference done 1542/8355. 0.1142 s / img. ETA=0:13:09
[32m[04/28 20:10:58 d2.evaluation.evaluator]: [0mInference done 1585/8355. 0.1143 s / img. ETA=0:13:05
[32m[04/28 20:11:03 d2.evaluation.evaluator]: [0mInference done 1628/8355. 0.1144 s / img. ETA=0:13:00
[32m[04/28 20:11:08 d2.evaluation.evaluator]: [0mInference done 1671/8355. 0.1144 s / img. ETA=0:12:55
[32m[04/28 20:11:13 d2.evaluation.evaluator]: [0mInference done 1714/8355. 0.1144 s / img. ETA=0:12:51
[32m[04/28 20:11:18 d2.evaluation.evaluator]: [0mInference done 1757/8355. 0.1145 s / img. ETA=0:12:46
[32m[04/28 20:11:23 d2.evaluation.evaluator]: [0mInference done 1800/8355. 0.1145 s / img. ETA=0:12:41
[32m[04/28 20:11:28 d2.evaluation.evaluator]: [0mInference done 1843/8355. 0.1145 s / img. ETA=0:12:36
[32m[04/28 20:11:33 d2.evaluation.evaluator]: [0mInference done 1886/8355. 0.1146 s / img. ETA=0:12:32
[32m[04/28 20:11:38 d2.evaluation.evaluator]: [0mInference done 1929/8355. 0.1146 s / img. ETA=0:12:27
[32m[04/28 20:11:43 d2.evaluation.evaluator]: [0mInference done 1972/8355. 0.1146 s / img. ETA=0:12:22
[32m[04/28 20:11:48 d2.evaluation.evaluator]: [0mInference done 2015/8355. 0.1146 s / img. ETA=0:12:17
[32m[04/28 20:11:53 d2.evaluation.evaluator]: [0mInference done 2058/8355. 0.1146 s / img. ETA=0:12:12
[32m[04/28 20:11:58 d2.evaluation.evaluator]: [0mInference done 2101/8355. 0.1146 s / img. ETA=0:12:07
[32m[04/28 20:12:03 d2.evaluation.evaluator]: [0mInference done 2144/8355. 0.1146 s / img. ETA=0:12:02
[32m[04/28 20:12:08 d2.evaluation.evaluator]: [0mInference done 2187/8355. 0.1147 s / img. ETA=0:11:57
[32m[04/28 20:12:13 d2.evaluation.evaluator]: [0mInference done 2230/8355. 0.1147 s / img. ETA=0:11:52
[32m[04/28 20:12:18 d2.evaluation.evaluator]: [0mInference done 2273/8355. 0.1147 s / img. ETA=0:11:48
[32m[04/28 20:12:23 d2.evaluation.evaluator]: [0mInference done 2316/8355. 0.1148 s / img. ETA=0:11:43
[32m[04/28 20:12:29 d2.evaluation.evaluator]: [0mInference done 2359/8355. 0.1148 s / img. ETA=0:11:38
[32m[04/28 20:12:34 d2.evaluation.evaluator]: [0mInference done 2402/8355. 0.1148 s / img. ETA=0:11:33
[32m[04/28 20:12:39 d2.evaluation.evaluator]: [0mInference done 2445/8355. 0.1148 s / img. ETA=0:11:28
[32m[04/28 20:12:44 d2.evaluation.evaluator]: [0mInference done 2488/8355. 0.1148 s / img. ETA=0:11:23
[32m[04/28 20:12:49 d2.evaluation.evaluator]: [0mInference done 2531/8355. 0.1148 s / img. ETA=0:11:18
[32m[04/28 20:12:54 d2.evaluation.evaluator]: [0mInference done 2574/8355. 0.1148 s / img. ETA=0:11:13
[32m[04/28 20:12:59 d2.evaluation.evaluator]: [0mInference done 2617/8355. 0.1148 s / img. ETA=0:11:08
[32m[04/28 20:13:04 d2.evaluation.evaluator]: [0mInference done 2660/8355. 0.1149 s / img. ETA=0:11:03
[32m[04/28 20:13:09 d2.evaluation.evaluator]: [0mInference done 2703/8355. 0.1149 s / img. ETA=0:10:59
[32m[04/28 20:13:14 d2.evaluation.evaluator]: [0mInference done 2746/8355. 0.1149 s / img. ETA=0:10:54
[32m[04/28 20:13:19 d2.evaluation.evaluator]: [0mInference done 2789/8355. 0.1149 s / img. ETA=0:10:49
[32m[04/28 20:13:24 d2.evaluation.evaluator]: [0mInference done 2832/8355. 0.1149 s / img. ETA=0:10:44
[32m[04/28 20:13:29 d2.evaluation.evaluator]: [0mInference done 2875/8355. 0.1149 s / img. ETA=0:10:39
[32m[04/28 20:13:34 d2.evaluation.evaluator]: [0mInference done 2918/8355. 0.1149 s / img. ETA=0:10:34
[32m[04/28 20:13:39 d2.evaluation.evaluator]: [0mInference done 2961/8355. 0.1150 s / img. ETA=0:10:29
[32m[04/28 20:13:44 d2.evaluation.evaluator]: [0mInference done 3004/8355. 0.1150 s / img. ETA=0:10:24
[32m[04/28 20:13:49 d2.evaluation.evaluator]: [0mInference done 3047/8355. 0.1150 s / img. ETA=0:10:19
[32m[04/28 20:13:54 d2.evaluation.evaluator]: [0mInference done 3090/8355. 0.1150 s / img. ETA=0:10:14
[32m[04/28 20:13:59 d2.evaluation.evaluator]: [0mInference done 3131/8355. 0.1151 s / img. ETA=0:10:10
[32m[04/28 20:14:04 d2.evaluation.evaluator]: [0mInference done 3175/8355. 0.1150 s / img. ETA=0:10:04
[32m[04/28 20:14:10 d2.evaluation.evaluator]: [0mInference done 3219/8355. 0.1150 s / img. ETA=0:09:59
[32m[04/28 20:14:15 d2.evaluation.evaluator]: [0mInference done 3262/8355. 0.1150 s / img. ETA=0:09:54
[32m[04/28 20:14:20 d2.evaluation.evaluator]: [0mInference done 3305/8355. 0.1150 s / img. ETA=0:09:49
[32m[04/28 20:14:25 d2.evaluation.evaluator]: [0mInference done 3349/8355. 0.1150 s / img. ETA=0:09:44
[32m[04/28 20:14:30 d2.evaluation.evaluator]: [0mInference done 3393/8355. 0.1150 s / img. ETA=0:09:39
[32m[04/28 20:14:35 d2.evaluation.evaluator]: [0mInference done 3436/8355. 0.1150 s / img. ETA=0:09:34
[32m[04/28 20:14:40 d2.evaluation.evaluator]: [0mInference done 3479/8355. 0.1150 s / img. ETA=0:09:29
[32m[04/28 20:14:45 d2.evaluation.evaluator]: [0mInference done 3522/8355. 0.1150 s / img. ETA=0:09:24
[32m[04/28 20:14:50 d2.evaluation.evaluator]: [0mInference done 3566/8355. 0.1150 s / img. ETA=0:09:19
[32m[04/28 20:14:55 d2.evaluation.evaluator]: [0mInference done 3609/8355. 0.1150 s / img. ETA=0:09:14
[32m[04/28 20:15:00 d2.evaluation.evaluator]: [0mInference done 3652/8355. 0.1150 s / img. ETA=0:09:08
[32m[04/28 20:15:05 d2.evaluation.evaluator]: [0mInference done 3695/8355. 0.1150 s / img. ETA=0:09:03
[32m[04/28 20:15:10 d2.evaluation.evaluator]: [0mInference done 3738/8355. 0.1150 s / img. ETA=0:08:59
[32m[04/28 20:15:15 d2.evaluation.evaluator]: [0mInference done 3781/8355. 0.1150 s / img. ETA=0:08:53
[32m[04/28 20:15:20 d2.evaluation.evaluator]: [0mInference done 3824/8355. 0.1150 s / img. ETA=0:08:48
[32m[04/28 20:15:25 d2.evaluation.evaluator]: [0mInference done 3867/8355. 0.1150 s / img. ETA=0:08:43
[32m[04/28 20:15:30 d2.evaluation.evaluator]: [0mInference done 3911/8355. 0.1150 s / img. ETA=0:08:38
[32m[04/28 20:15:35 d2.evaluation.evaluator]: [0mInference done 3955/8355. 0.1150 s / img. ETA=0:08:33
[32m[04/28 20:15:40 d2.evaluation.evaluator]: [0mInference done 3998/8355. 0.1150 s / img. ETA=0:08:28
[32m[04/28 20:15:45 d2.evaluation.evaluator]: [0mInference done 4041/8355. 0.1150 s / img. ETA=0:08:23
[32m[04/28 20:15:50 d2.evaluation.evaluator]: [0mInference done 4084/8355. 0.1150 s / img. ETA=0:08:18
[32m[04/28 20:15:55 d2.evaluation.evaluator]: [0mInference done 4127/8355. 0.1150 s / img. ETA=0:08:13
[32m[04/28 20:16:01 d2.evaluation.evaluator]: [0mInference done 4170/8355. 0.1150 s / img. ETA=0:08:08
[32m[04/28 20:16:06 d2.evaluation.evaluator]: [0mInference done 4213/8355. 0.1150 s / img. ETA=0:08:03
[32m[04/28 20:16:11 d2.evaluation.evaluator]: [0mInference done 4257/8355. 0.1150 s / img. ETA=0:07:58
[32m[04/28 20:16:16 d2.evaluation.evaluator]: [0mInference done 4300/8355. 0.1150 s / img. ETA=0:07:53
[32m[04/28 20:16:21 d2.evaluation.evaluator]: [0mInference done 4343/8355. 0.1150 s / img. ETA=0:07:48
[32m[04/28 20:16:26 d2.evaluation.evaluator]: [0mInference done 4387/8355. 0.1150 s / img. ETA=0:07:43
[32m[04/28 20:16:31 d2.evaluation.evaluator]: [0mInference done 4430/8355. 0.1150 s / img. ETA=0:07:38
[32m[04/28 20:16:36 d2.evaluation.evaluator]: [0mInference done 4473/8355. 0.1150 s / img. ETA=0:07:33
[32m[04/28 20:16:41 d2.evaluation.evaluator]: [0mInference done 4516/8355. 0.1150 s / img. ETA=0:07:28
[32m[04/28 20:16:46 d2.evaluation.evaluator]: [0mInference done 4559/8355. 0.1150 s / img. ETA=0:07:23
[32m[04/28 20:16:51 d2.evaluation.evaluator]: [0mInference done 4602/8355. 0.1150 s / img. ETA=0:07:18
[32m[04/28 20:16:56 d2.evaluation.evaluator]: [0mInference done 4645/8355. 0.1150 s / img. ETA=0:07:13
[32m[04/28 20:17:01 d2.evaluation.evaluator]: [0mInference done 4688/8355. 0.1150 s / img. ETA=0:07:08
[32m[04/28 20:17:06 d2.evaluation.evaluator]: [0mInference done 4731/8355. 0.1150 s / img. ETA=0:07:03
[32m[04/28 20:17:11 d2.evaluation.evaluator]: [0mInference done 4773/8355. 0.1150 s / img. ETA=0:06:58
[32m[04/28 20:17:16 d2.evaluation.evaluator]: [0mInference done 4816/8355. 0.1150 s / img. ETA=0:06:53
[32m[04/28 20:17:21 d2.evaluation.evaluator]: [0mInference done 4859/8355. 0.1150 s / img. ETA=0:06:48
[32m[04/28 20:17:26 d2.evaluation.evaluator]: [0mInference done 4902/8355. 0.1150 s / img. ETA=0:06:43
[32m[04/28 20:17:31 d2.evaluation.evaluator]: [0mInference done 4945/8355. 0.1150 s / img. ETA=0:06:38
[32m[04/28 20:17:36 d2.evaluation.evaluator]: [0mInference done 4988/8355. 0.1150 s / img. ETA=0:06:33
[32m[04/28 20:17:41 d2.evaluation.evaluator]: [0mInference done 5031/8355. 0.1150 s / img. ETA=0:06:28
[32m[04/28 20:17:46 d2.evaluation.evaluator]: [0mInference done 5074/8355. 0.1150 s / img. ETA=0:06:23
[32m[04/28 20:17:51 d2.evaluation.evaluator]: [0mInference done 5117/8355. 0.1150 s / img. ETA=0:06:18
[32m[04/28 20:17:56 d2.evaluation.evaluator]: [0mInference done 5160/8355. 0.1150 s / img. ETA=0:06:13
[32m[04/28 20:18:01 d2.evaluation.evaluator]: [0mInference done 5203/8355. 0.1150 s / img. ETA=0:06:08
[32m[04/28 20:18:06 d2.evaluation.evaluator]: [0mInference done 5246/8355. 0.1150 s / img. ETA=0:06:03
[32m[04/28 20:18:11 d2.evaluation.evaluator]: [0mInference done 5289/8355. 0.1150 s / img. ETA=0:05:58
[32m[04/28 20:18:16 d2.evaluation.evaluator]: [0mInference done 5332/8355. 0.1150 s / img. ETA=0:05:53
[32m[04/28 20:18:22 d2.evaluation.evaluator]: [0mInference done 5375/8355. 0.1150 s / img. ETA=0:05:48
[32m[04/28 20:18:27 d2.evaluation.evaluator]: [0mInference done 5418/8355. 0.1150 s / img. ETA=0:05:43
[32m[04/28 20:18:32 d2.evaluation.evaluator]: [0mInference done 5461/8355. 0.1150 s / img. ETA=0:05:37
[32m[04/28 20:18:37 d2.evaluation.evaluator]: [0mInference done 5504/8355. 0.1150 s / img. ETA=0:05:32
[32m[04/28 20:18:42 d2.evaluation.evaluator]: [0mInference done 5548/8355. 0.1150 s / img. ETA=0:05:27
[32m[04/28 20:18:47 d2.evaluation.evaluator]: [0mInference done 5592/8355. 0.1150 s / img. ETA=0:05:22
[32m[04/28 20:18:52 d2.evaluation.evaluator]: [0mInference done 5635/8355. 0.1150 s / img. ETA=0:05:17
[32m[04/28 20:18:57 d2.evaluation.evaluator]: [0mInference done 5678/8355. 0.1150 s / img. ETA=0:05:12
[32m[04/28 20:19:02 d2.evaluation.evaluator]: [0mInference done 5721/8355. 0.1150 s / img. ETA=0:05:07
[32m[04/28 20:19:07 d2.evaluation.evaluator]: [0mInference done 5764/8355. 0.1150 s / img. ETA=0:05:02
[32m[04/28 20:19:12 d2.evaluation.evaluator]: [0mInference done 5807/8355. 0.1150 s / img. ETA=0:04:57
[32m[04/28 20:19:17 d2.evaluation.evaluator]: [0mInference done 5850/8355. 0.1151 s / img. ETA=0:04:52
[32m[04/28 20:19:22 d2.evaluation.evaluator]: [0mInference done 5893/8355. 0.1151 s / img. ETA=0:04:47
[32m[04/28 20:19:27 d2.evaluation.evaluator]: [0mInference done 5936/8355. 0.1151 s / img. ETA=0:04:42
[32m[04/28 20:19:32 d2.evaluation.evaluator]: [0mInference done 5979/8355. 0.1151 s / img. ETA=0:04:37
[32m[04/28 20:19:37 d2.evaluation.evaluator]: [0mInference done 6022/8355. 0.1151 s / img. ETA=0:04:32
[32m[04/28 20:19:42 d2.evaluation.evaluator]: [0mInference done 6065/8355. 0.1151 s / img. ETA=0:04:27
[32m[04/28 20:19:48 d2.evaluation.evaluator]: [0mInference done 6108/8355. 0.1151 s / img. ETA=0:04:22
[32m[04/28 20:19:53 d2.evaluation.evaluator]: [0mInference done 6151/8355. 0.1151 s / img. ETA=0:04:17
[32m[04/28 20:19:58 d2.evaluation.evaluator]: [0mInference done 6194/8355. 0.1151 s / img. ETA=0:04:12
[32m[04/28 20:20:03 d2.evaluation.evaluator]: [0mInference done 6237/8355. 0.1151 s / img. ETA=0:04:07
[32m[04/28 20:20:08 d2.evaluation.evaluator]: [0mInference done 6280/8355. 0.1151 s / img. ETA=0:04:02
[32m[04/28 20:20:13 d2.evaluation.evaluator]: [0mInference done 6323/8355. 0.1152 s / img. ETA=0:03:57
[32m[04/28 20:20:18 d2.evaluation.evaluator]: [0mInference done 6366/8355. 0.1152 s / img. ETA=0:03:52
[32m[04/28 20:20:23 d2.evaluation.evaluator]: [0mInference done 6409/8355. 0.1152 s / img. ETA=0:03:47
[32m[04/28 20:20:28 d2.evaluation.evaluator]: [0mInference done 6451/8355. 0.1152 s / img. ETA=0:03:42
[32m[04/28 20:20:33 d2.evaluation.evaluator]: [0mInference done 6494/8355. 0.1152 s / img. ETA=0:03:37
[32m[04/28 20:20:38 d2.evaluation.evaluator]: [0mInference done 6538/8355. 0.1152 s / img. ETA=0:03:32
[32m[04/28 20:20:43 d2.evaluation.evaluator]: [0mInference done 6581/8355. 0.1152 s / img. ETA=0:03:27
[32m[04/28 20:20:48 d2.evaluation.evaluator]: [0mInference done 6624/8355. 0.1152 s / img. ETA=0:03:22
[32m[04/28 20:20:53 d2.evaluation.evaluator]: [0mInference done 6667/8355. 0.1152 s / img. ETA=0:03:17
[32m[04/28 20:20:58 d2.evaluation.evaluator]: [0mInference done 6711/8355. 0.1152 s / img. ETA=0:03:12
[32m[04/28 20:21:03 d2.evaluation.evaluator]: [0mInference done 6755/8355. 0.1151 s / img. ETA=0:03:07
[32m[04/28 20:21:09 d2.evaluation.evaluator]: [0mInference done 6799/8355. 0.1151 s / img. ETA=0:03:01
[32m[04/28 20:21:14 d2.evaluation.evaluator]: [0mInference done 6842/8355. 0.1151 s / img. ETA=0:02:56
[32m[04/28 20:21:19 d2.evaluation.evaluator]: [0mInference done 6885/8355. 0.1151 s / img. ETA=0:02:51
[32m[04/28 20:21:24 d2.evaluation.evaluator]: [0mInference done 6928/8355. 0.1151 s / img. ETA=0:02:46
[32m[04/28 20:21:29 d2.evaluation.evaluator]: [0mInference done 6971/8355. 0.1151 s / img. ETA=0:02:41
[32m[04/28 20:21:34 d2.evaluation.evaluator]: [0mInference done 7014/8355. 0.1151 s / img. ETA=0:02:36
[32m[04/28 20:21:39 d2.evaluation.evaluator]: [0mInference done 7057/8355. 0.1151 s / img. ETA=0:02:31
[32m[04/28 20:21:44 d2.evaluation.evaluator]: [0mInference done 7100/8355. 0.1151 s / img. ETA=0:02:26
[32m[04/28 20:21:49 d2.evaluation.evaluator]: [0mInference done 7143/8355. 0.1152 s / img. ETA=0:02:21
[32m[04/28 20:21:54 d2.evaluation.evaluator]: [0mInference done 7186/8355. 0.1152 s / img. ETA=0:02:16
[32m[04/28 20:21:59 d2.evaluation.evaluator]: [0mInference done 7229/8355. 0.1152 s / img. ETA=0:02:11
[32m[04/28 20:22:04 d2.evaluation.evaluator]: [0mInference done 7272/8355. 0.1152 s / img. ETA=0:02:06
[32m[04/28 20:22:09 d2.evaluation.evaluator]: [0mInference done 7314/8355. 0.1152 s / img. ETA=0:02:01
[32m[04/28 20:22:14 d2.evaluation.evaluator]: [0mInference done 7357/8355. 0.1152 s / img. ETA=0:01:56
[32m[04/28 20:22:19 d2.evaluation.evaluator]: [0mInference done 7400/8355. 0.1152 s / img. ETA=0:01:51
[32m[04/28 20:22:24 d2.evaluation.evaluator]: [0mInference done 7442/8355. 0.1152 s / img. ETA=0:01:46
[32m[04/28 20:22:29 d2.evaluation.evaluator]: [0mInference done 7485/8355. 0.1152 s / img. ETA=0:01:41
[32m[04/28 20:22:34 d2.evaluation.evaluator]: [0mInference done 7528/8355. 0.1152 s / img. ETA=0:01:36
[32m[04/28 20:22:39 d2.evaluation.evaluator]: [0mInference done 7571/8355. 0.1152 s / img. ETA=0:01:31
[32m[04/28 20:22:45 d2.evaluation.evaluator]: [0mInference done 7614/8355. 0.1152 s / img. ETA=0:01:26
[32m[04/28 20:22:50 d2.evaluation.evaluator]: [0mInference done 7657/8355. 0.1152 s / img. ETA=0:01:21
[32m[04/28 20:22:55 d2.evaluation.evaluator]: [0mInference done 7700/8355. 0.1152 s / img. ETA=0:01:16
[32m[04/28 20:23:00 d2.evaluation.evaluator]: [0mInference done 7743/8355. 0.1152 s / img. ETA=0:01:11
[32m[04/28 20:23:05 d2.evaluation.evaluator]: [0mInference done 7786/8355. 0.1152 s / img. ETA=0:01:06
[32m[04/28 20:23:10 d2.evaluation.evaluator]: [0mInference done 7829/8355. 0.1152 s / img. ETA=0:01:01
[32m[04/28 20:23:15 d2.evaluation.evaluator]: [0mInference done 7872/8355. 0.1152 s / img. ETA=0:00:56
[32m[04/28 20:23:20 d2.evaluation.evaluator]: [0mInference done 7915/8355. 0.1153 s / img. ETA=0:00:51
[32m[04/28 20:23:25 d2.evaluation.evaluator]: [0mInference done 7958/8355. 0.1153 s / img. ETA=0:00:46
[32m[04/28 20:23:30 d2.evaluation.evaluator]: [0mInference done 8001/8355. 0.1153 s / img. ETA=0:00:41
[32m[04/28 20:23:35 d2.evaluation.evaluator]: [0mInference done 8044/8355. 0.1153 s / img. ETA=0:00:36
[32m[04/28 20:23:40 d2.evaluation.evaluator]: [0mInference done 8088/8355. 0.1152 s / img. ETA=0:00:31
[32m[04/28 20:23:45 d2.evaluation.evaluator]: [0mInference done 8131/8355. 0.1152 s / img. ETA=0:00:26
[32m[04/28 20:23:50 d2.evaluation.evaluator]: [0mInference done 8174/8355. 0.1152 s / img. ETA=0:00:21
[32m[04/28 20:23:55 d2.evaluation.evaluator]: [0mInference done 8217/8355. 0.1152 s / img. ETA=0:00:16
[32m[04/28 20:24:00 d2.evaluation.evaluator]: [0mInference done 8260/8355. 0.1152 s / img. ETA=0:00:11
[32m[04/28 20:24:05 d2.evaluation.evaluator]: [0mInference done 8303/8355. 0.1152 s / img. ETA=0:00:06
[32m[04/28 20:24:10 d2.evaluation.evaluator]: [0mInference done 8346/8355. 0.1153 s / img. ETA=0:00:01
[32m[04/28 20:24:11 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:17.139789 (0.117023 s / img per device, on 1 devices)
[32m[04/28 20:24:11 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:02 (0.115255 s / img per device, on 1 devices)
[32m[04/28 20:24:12 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 20:24:12 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 20:24:12 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.28s).
Accumulating evaluation results...
DONE (t=2.20s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.517
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.878
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.535
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.410
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.638
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.557
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.576
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.488
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.696
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.815
[32m[04/28 20:24:35 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.689 | 87.831 | 53.542 | 40.968 | 63.799 | 76.781 |
[32m[04/28 20:24:35 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 51.116 | bicycle       | 45.190 | car            | 58.762 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 20:24:35 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 20:24:35 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 20:24:35 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 20:24:37 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1148 s / img. ETA=0:02:24
[32m[04/28 20:24:42 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1150 s / img. ETA=0:02:20
[32m[04/28 20:24:47 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1149 s / img. ETA=0:02:15
[32m[04/28 20:24:52 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1148 s / img. ETA=0:02:10
[32m[04/28 20:24:57 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1149 s / img. ETA=0:02:05
[32m[04/28 20:25:02 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1148 s / img. ETA=0:02:00
[32m[04/28 20:25:07 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1149 s / img. ETA=0:01:55
[32m[04/28 20:25:12 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1149 s / img. ETA=0:01:50
[32m[04/28 20:25:17 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1149 s / img. ETA=0:01:45
[32m[04/28 20:25:22 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1149 s / img. ETA=0:01:40
[32m[04/28 20:25:27 d2.evaluation.evaluator]: [0mInference done 442/1257. 0.1148 s / img. ETA=0:01:35
[32m[04/28 20:25:32 d2.evaluation.evaluator]: [0mInference done 486/1257. 0.1148 s / img. ETA=0:01:29
[32m[04/28 20:25:37 d2.evaluation.evaluator]: [0mInference done 529/1257. 0.1148 s / img. ETA=0:01:24
[32m[04/28 20:25:42 d2.evaluation.evaluator]: [0mInference done 572/1257. 0.1149 s / img. ETA=0:01:19
[32m[04/28 20:25:47 d2.evaluation.evaluator]: [0mInference done 615/1257. 0.1148 s / img. ETA=0:01:14
[32m[04/28 20:25:52 d2.evaluation.evaluator]: [0mInference done 658/1257. 0.1149 s / img. ETA=0:01:09
[32m[04/28 20:25:57 d2.evaluation.evaluator]: [0mInference done 701/1257. 0.1149 s / img. ETA=0:01:04
[32m[04/28 20:26:02 d2.evaluation.evaluator]: [0mInference done 744/1257. 0.1149 s / img. ETA=0:00:59
[32m[04/28 20:26:07 d2.evaluation.evaluator]: [0mInference done 787/1257. 0.1149 s / img. ETA=0:00:54
[32m[04/28 20:26:12 d2.evaluation.evaluator]: [0mInference done 830/1257. 0.1149 s / img. ETA=0:00:49
[32m[04/28 20:26:17 d2.evaluation.evaluator]: [0mInference done 873/1257. 0.1149 s / img. ETA=0:00:44
[32m[04/28 20:26:22 d2.evaluation.evaluator]: [0mInference done 916/1257. 0.1150 s / img. ETA=0:00:39
[32m[04/28 20:26:27 d2.evaluation.evaluator]: [0mInference done 959/1257. 0.1150 s / img. ETA=0:00:34
[32m[04/28 20:26:32 d2.evaluation.evaluator]: [0mInference done 1002/1257. 0.1150 s / img. ETA=0:00:29
[32m[04/28 20:26:37 d2.evaluation.evaluator]: [0mInference done 1045/1257. 0.1150 s / img. ETA=0:00:24
[32m[04/28 20:26:42 d2.evaluation.evaluator]: [0mInference done 1088/1257. 0.1150 s / img. ETA=0:00:19
[32m[04/28 20:26:47 d2.evaluation.evaluator]: [0mInference done 1131/1257. 0.1151 s / img. ETA=0:00:14
[32m[04/28 20:26:52 d2.evaluation.evaluator]: [0mInference done 1174/1257. 0.1151 s / img. ETA=0:00:09
[32m[04/28 20:26:58 d2.evaluation.evaluator]: [0mInference done 1217/1257. 0.1151 s / img. ETA=0:00:04
[32m[04/28 20:27:02 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.247176 (0.116811 s / img per device, on 1 devices)
[32m[04/28 20:27:02 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115038 s / img per device, on 1 devices)
[32m[04/28 20:27:02 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 20:27:02 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 20:27:02 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.34s).
Accumulating evaluation results...
DONE (t=0.37s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.384
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.740
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.350
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.279
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.437
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.594
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.181
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.452
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.379
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.499
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657
[32m[04/28 20:27:06 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 38.404 | 73.987 | 34.957 | 27.904 | 43.651 | 59.375 |
[32m[04/28 20:27:06 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 44.508 | bicycle       | 19.232 | car            | 51.471 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  31  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 20:27:07 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 20:27:07 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 20:27:07 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 20:27:07 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 20:27:08 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 20:27:08 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 20:27:08 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 20:27:29 d2.utils.events]: [0m eta: 0:17:25  iter: 19  total_loss: 0.596  loss_cls: 0.174  loss_box_reg: 0.328  loss_rpn_cls: 0.010  loss_rpn_loc: 0.055  time: 1.0365  data_time: 0.0201  lr: 0.000100  max_mem: 5397M
[32m[04/28 20:27:48 d2.utils.events]: [0m eta: 0:16:20  iter: 39  total_loss: 0.478  loss_cls: 0.143  loss_box_reg: 0.284  loss_rpn_cls: 0.006  loss_rpn_loc: 0.055  time: 1.0120  data_time: 0.0077  lr: 0.000200  max_mem: 5397M
[32m[04/28 20:28:09 d2.utils.events]: [0m eta: 0:16:09  iter: 59  total_loss: 0.471  loss_cls: 0.148  loss_box_reg: 0.270  loss_rpn_cls: 0.005  loss_rpn_loc: 0.042  time: 1.0201  data_time: 0.0077  lr: 0.000300  max_mem: 5397M
[32m[04/28 20:28:30 d2.utils.events]: [0m eta: 0:15:54  iter: 79  total_loss: 0.456  loss_cls: 0.142  loss_box_reg: 0.272  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0254  data_time: 0.0078  lr: 0.000400  max_mem: 5397M
[32m[04/28 20:28:52 d2.utils.events]: [0m eta: 0:15:51  iter: 99  total_loss: 0.471  loss_cls: 0.139  loss_box_reg: 0.269  loss_rpn_cls: 0.006  loss_rpn_loc: 0.034  time: 1.0338  data_time: 0.0078  lr: 0.000500  max_mem: 5397M
[32m[04/28 20:29:12 d2.utils.events]: [0m eta: 0:15:20  iter: 119  total_loss: 0.487  loss_cls: 0.147  loss_box_reg: 0.290  loss_rpn_cls: 0.005  loss_rpn_loc: 0.047  time: 1.0308  data_time: 0.0077  lr: 0.000599  max_mem: 5397M
[32m[04/28 20:29:32 d2.utils.events]: [0m eta: 0:14:58  iter: 139  total_loss: 0.450  loss_cls: 0.140  loss_box_reg: 0.251  loss_rpn_cls: 0.007  loss_rpn_loc: 0.043  time: 1.0292  data_time: 0.0077  lr: 0.000699  max_mem: 5397M
[32m[04/28 20:29:53 d2.utils.events]: [0m eta: 0:14:40  iter: 159  total_loss: 0.476  loss_cls: 0.142  loss_box_reg: 0.289  loss_rpn_cls: 0.006  loss_rpn_loc: 0.040  time: 1.0320  data_time: 0.0079  lr: 0.000799  max_mem: 5397M
[32m[04/28 20:30:14 d2.utils.events]: [0m eta: 0:14:20  iter: 179  total_loss: 0.504  loss_cls: 0.144  loss_box_reg: 0.285  loss_rpn_cls: 0.004  loss_rpn_loc: 0.050  time: 1.0321  data_time: 0.0077  lr: 0.000899  max_mem: 5397M
[32m[04/28 20:30:35 d2.utils.events]: [0m eta: 0:14:01  iter: 199  total_loss: 0.429  loss_cls: 0.133  loss_box_reg: 0.264  loss_rpn_cls: 0.005  loss_rpn_loc: 0.037  time: 1.0340  data_time: 0.0078  lr: 0.000999  max_mem: 5397M
[32m[04/28 20:30:56 d2.utils.events]: [0m eta: 0:13:38  iter: 219  total_loss: 0.424  loss_cls: 0.120  loss_box_reg: 0.248  loss_rpn_cls: 0.004  loss_rpn_loc: 0.046  time: 1.0324  data_time: 0.0075  lr: 0.001099  max_mem: 5397M
[32m[04/28 20:31:16 d2.utils.events]: [0m eta: 0:13:17  iter: 239  total_loss: 0.483  loss_cls: 0.135  loss_box_reg: 0.295  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0304  data_time: 0.0077  lr: 0.001199  max_mem: 5397M
[32m[04/28 20:31:37 d2.utils.events]: [0m eta: 0:12:57  iter: 259  total_loss: 0.426  loss_cls: 0.128  loss_box_reg: 0.249  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0318  data_time: 0.0077  lr: 0.001299  max_mem: 5397M
[32m[04/28 20:31:57 d2.utils.events]: [0m eta: 0:12:36  iter: 279  total_loss: 0.447  loss_cls: 0.134  loss_box_reg: 0.258  loss_rpn_cls: 0.004  loss_rpn_loc: 0.047  time: 1.0313  data_time: 0.0079  lr: 0.001399  max_mem: 5397M
[32m[04/28 20:32:18 d2.utils.events]: [0m eta: 0:12:16  iter: 299  total_loss: 0.466  loss_cls: 0.144  loss_box_reg: 0.283  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0329  data_time: 0.0078  lr: 0.001499  max_mem: 5397M
[32m[04/28 20:32:39 d2.utils.events]: [0m eta: 0:11:53  iter: 319  total_loss: 0.392  loss_cls: 0.121  loss_box_reg: 0.248  loss_rpn_cls: 0.005  loss_rpn_loc: 0.033  time: 1.0309  data_time: 0.0077  lr: 0.001598  max_mem: 5397M
[32m[04/28 20:32:59 d2.utils.events]: [0m eta: 0:11:32  iter: 339  total_loss: 0.444  loss_cls: 0.140  loss_box_reg: 0.267  loss_rpn_cls: 0.005  loss_rpn_loc: 0.039  time: 1.0300  data_time: 0.0077  lr: 0.001698  max_mem: 5397M
[32m[04/28 20:33:19 d2.utils.events]: [0m eta: 0:11:09  iter: 359  total_loss: 0.530  loss_cls: 0.166  loss_box_reg: 0.308  loss_rpn_cls: 0.004  loss_rpn_loc: 0.046  time: 1.0290  data_time: 0.0077  lr: 0.001798  max_mem: 5397M
[32m[04/28 20:33:40 d2.utils.events]: [0m eta: 0:10:48  iter: 379  total_loss: 0.444  loss_cls: 0.136  loss_box_reg: 0.259  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0293  data_time: 0.0079  lr: 0.001898  max_mem: 5397M
[32m[04/28 20:34:00 d2.utils.events]: [0m eta: 0:10:27  iter: 399  total_loss: 0.465  loss_cls: 0.140  loss_box_reg: 0.277  loss_rpn_cls: 0.004  loss_rpn_loc: 0.039  time: 1.0290  data_time: 0.0078  lr: 0.001998  max_mem: 5397M
[32m[04/28 20:34:22 d2.utils.events]: [0m eta: 0:10:07  iter: 419  total_loss: 0.414  loss_cls: 0.122  loss_box_reg: 0.238  loss_rpn_cls: 0.004  loss_rpn_loc: 0.042  time: 1.0301  data_time: 0.0078  lr: 0.002098  max_mem: 5397M
[32m[04/28 20:34:42 d2.utils.events]: [0m eta: 0:09:46  iter: 439  total_loss: 0.488  loss_cls: 0.146  loss_box_reg: 0.276  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0304  data_time: 0.0076  lr: 0.002198  max_mem: 5397M
[32m[04/28 20:35:03 d2.utils.events]: [0m eta: 0:09:24  iter: 459  total_loss: 0.433  loss_cls: 0.135  loss_box_reg: 0.257  loss_rpn_cls: 0.003  loss_rpn_loc: 0.033  time: 1.0295  data_time: 0.0078  lr: 0.002298  max_mem: 5397M
[32m[04/28 20:35:23 d2.utils.events]: [0m eta: 0:09:03  iter: 479  total_loss: 0.463  loss_cls: 0.133  loss_box_reg: 0.286  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0288  data_time: 0.0077  lr: 0.002398  max_mem: 5397M
[32m[04/28 20:35:44 d2.utils.events]: [0m eta: 0:08:42  iter: 499  total_loss: 0.410  loss_cls: 0.126  loss_box_reg: 0.246  loss_rpn_cls: 0.004  loss_rpn_loc: 0.034  time: 1.0296  data_time: 0.0078  lr: 0.002498  max_mem: 5397M
[32m[04/28 20:36:05 d2.utils.events]: [0m eta: 0:08:21  iter: 519  total_loss: 0.432  loss_cls: 0.123  loss_box_reg: 0.252  loss_rpn_cls: 0.004  loss_rpn_loc: 0.041  time: 1.0296  data_time: 0.0079  lr: 0.002597  max_mem: 5397M
[32m[04/28 20:36:25 d2.utils.events]: [0m eta: 0:08:00  iter: 539  total_loss: 0.530  loss_cls: 0.159  loss_box_reg: 0.309  loss_rpn_cls: 0.004  loss_rpn_loc: 0.053  time: 1.0297  data_time: 0.0079  lr: 0.002697  max_mem: 5397M
[32m[04/28 20:36:47 d2.utils.events]: [0m eta: 0:07:40  iter: 559  total_loss: 0.476  loss_cls: 0.137  loss_box_reg: 0.292  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0310  data_time: 0.0078  lr: 0.002797  max_mem: 5397M
[32m[04/28 20:37:07 d2.utils.events]: [0m eta: 0:07:19  iter: 579  total_loss: 0.471  loss_cls: 0.139  loss_box_reg: 0.275  loss_rpn_cls: 0.004  loss_rpn_loc: 0.052  time: 1.0310  data_time: 0.0078  lr: 0.002897  max_mem: 5397M
[32m[04/28 20:37:28 d2.utils.events]: [0m eta: 0:06:58  iter: 599  total_loss: 0.489  loss_cls: 0.152  loss_box_reg: 0.289  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0310  data_time: 0.0077  lr: 0.002997  max_mem: 5397M
[32m[04/28 20:37:48 d2.utils.events]: [0m eta: 0:06:37  iter: 619  total_loss: 0.465  loss_cls: 0.138  loss_box_reg: 0.281  loss_rpn_cls: 0.004  loss_rpn_loc: 0.044  time: 1.0308  data_time: 0.0079  lr: 0.003097  max_mem: 5397M
[32m[04/28 20:38:09 d2.utils.events]: [0m eta: 0:06:16  iter: 639  total_loss: 0.489  loss_cls: 0.148  loss_box_reg: 0.294  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0309  data_time: 0.0079  lr: 0.003197  max_mem: 5397M
[32m[04/28 20:38:30 d2.utils.events]: [0m eta: 0:05:55  iter: 659  total_loss: 0.489  loss_cls: 0.146  loss_box_reg: 0.282  loss_rpn_cls: 0.009  loss_rpn_loc: 0.047  time: 1.0310  data_time: 0.0075  lr: 0.003297  max_mem: 5397M
[32m[04/28 20:38:51 d2.utils.events]: [0m eta: 0:05:35  iter: 679  total_loss: 0.459  loss_cls: 0.132  loss_box_reg: 0.271  loss_rpn_cls: 0.004  loss_rpn_loc: 0.043  time: 1.0315  data_time: 0.0077  lr: 0.003397  max_mem: 5397M
[32m[04/28 20:39:12 d2.utils.events]: [0m eta: 0:05:14  iter: 699  total_loss: 0.479  loss_cls: 0.152  loss_box_reg: 0.284  loss_rpn_cls: 0.006  loss_rpn_loc: 0.048  time: 1.0318  data_time: 0.0077  lr: 0.003497  max_mem: 5397M
[32m[04/28 20:39:32 d2.utils.events]: [0m eta: 0:04:53  iter: 719  total_loss: 0.477  loss_cls: 0.145  loss_box_reg: 0.270  loss_rpn_cls: 0.004  loss_rpn_loc: 0.040  time: 1.0315  data_time: 0.0080  lr: 0.003596  max_mem: 5397M
[32m[04/28 20:39:54 d2.utils.events]: [0m eta: 0:04:32  iter: 739  total_loss: 0.479  loss_cls: 0.146  loss_box_reg: 0.276  loss_rpn_cls: 0.003  loss_rpn_loc: 0.048  time: 1.0323  data_time: 0.0078  lr: 0.003696  max_mem: 5397M
[32m[04/28 20:40:15 d2.utils.events]: [0m eta: 0:04:11  iter: 759  total_loss: 0.467  loss_cls: 0.148  loss_box_reg: 0.276  loss_rpn_cls: 0.005  loss_rpn_loc: 0.051  time: 1.0328  data_time: 0.0081  lr: 0.003796  max_mem: 5397M
[32m[04/28 20:40:35 d2.utils.events]: [0m eta: 0:03:50  iter: 779  total_loss: 0.504  loss_cls: 0.149  loss_box_reg: 0.296  loss_rpn_cls: 0.004  loss_rpn_loc: 0.051  time: 1.0321  data_time: 0.0076  lr: 0.003896  max_mem: 5397M
[32m[04/28 20:40:56 d2.utils.events]: [0m eta: 0:03:30  iter: 799  total_loss: 0.459  loss_cls: 0.128  loss_box_reg: 0.269  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0326  data_time: 0.0077  lr: 0.003996  max_mem: 5397M
[32m[04/28 20:41:16 d2.utils.events]: [0m eta: 0:03:09  iter: 819  total_loss: 0.506  loss_cls: 0.152  loss_box_reg: 0.304  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0319  data_time: 0.0075  lr: 0.004096  max_mem: 5397M
[32m[04/28 20:41:37 d2.utils.events]: [0m eta: 0:02:48  iter: 839  total_loss: 0.461  loss_cls: 0.146  loss_box_reg: 0.280  loss_rpn_cls: 0.006  loss_rpn_loc: 0.040  time: 1.0322  data_time: 0.0077  lr: 0.004196  max_mem: 5397M
[32m[04/28 20:41:57 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.470  loss_cls: 0.145  loss_box_reg: 0.286  loss_rpn_cls: 0.009  loss_rpn_loc: 0.037  time: 1.0317  data_time: 0.0081  lr: 0.004296  max_mem: 5397M
[32m[04/28 20:42:18 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.388  loss_cls: 0.125  loss_box_reg: 0.244  loss_rpn_cls: 0.004  loss_rpn_loc: 0.033  time: 1.0317  data_time: 0.0077  lr: 0.004396  max_mem: 5397M
[32m[04/28 20:42:38 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.438  loss_cls: 0.139  loss_box_reg: 0.268  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 1.0311  data_time: 0.0079  lr: 0.004496  max_mem: 5397M
[32m[04/28 20:42:59 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.448  loss_cls: 0.140  loss_box_reg: 0.265  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0310  data_time: 0.0076  lr: 0.004595  max_mem: 5397M
[32m[04/28 20:43:20 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.468  loss_cls: 0.140  loss_box_reg: 0.275  loss_rpn_cls: 0.005  loss_rpn_loc: 0.039  time: 1.0312  data_time: 0.0081  lr: 0.004695  max_mem: 5397M
[32m[04/28 20:43:40 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.514  loss_cls: 0.154  loss_box_reg: 0.302  loss_rpn_cls: 0.008  loss_rpn_loc: 0.047  time: 1.0306  data_time: 0.0076  lr: 0.004795  max_mem: 5397M
[32m[04/28 20:44:01 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.435  loss_cls: 0.131  loss_box_reg: 0.261  loss_rpn_cls: 0.005  loss_rpn_loc: 0.042  time: 1.0308  data_time: 0.0076  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 20:44:23 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 20:44:23 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 20:44:23 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 20:44:23 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.453  loss_cls: 0.139  loss_box_reg: 0.263  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0306  data_time: 0.0077  lr: 0.004995  max_mem: 5397M
[32m[04/28 20:44:24 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:08 (1.0316 s / it)
[32m[04/28 20:44:24 d2.engine.hooks]: [0mTotal training time: 0:17:13 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 20:44:25 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 20:44:25 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 20:44:26 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 20:44:27 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1144 s / img. ETA=0:16:05
[32m[04/28 20:44:32 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1139 s / img. ETA=0:15:58
[32m[04/28 20:44:37 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1136 s / img. ETA=0:15:51
[32m[04/28 20:44:42 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1136 s / img. ETA=0:15:45
[32m[04/28 20:44:47 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1136 s / img. ETA=0:15:40
[32m[04/28 20:44:52 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1136 s / img. ETA=0:15:36
[32m[04/28 20:44:57 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1137 s / img. ETA=0:15:31
[32m[04/28 20:45:03 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1138 s / img. ETA=0:15:27
[32m[04/28 20:45:08 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1138 s / img. ETA=0:15:22
[32m[04/28 20:45:13 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1139 s / img. ETA=0:15:18
[32m[04/28 20:45:18 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1139 s / img. ETA=0:15:13
[32m[04/28 20:45:23 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1139 s / img. ETA=0:15:08
[32m[04/28 20:45:28 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1138 s / img. ETA=0:15:02
[32m[04/28 20:45:33 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1138 s / img. ETA=0:14:57
[32m[04/28 20:45:38 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1138 s / img. ETA=0:14:52
[32m[04/28 20:45:43 d2.evaluation.evaluator]: [0mInference done 671/8355. 0.1139 s / img. ETA=0:14:47
[32m[04/28 20:45:48 d2.evaluation.evaluator]: [0mInference done 715/8355. 0.1139 s / img. ETA=0:14:42
[32m[04/28 20:45:53 d2.evaluation.evaluator]: [0mInference done 758/8355. 0.1139 s / img. ETA=0:14:38
[32m[04/28 20:45:58 d2.evaluation.evaluator]: [0mInference done 802/8355. 0.1140 s / img. ETA=0:14:33
[32m[04/28 20:46:04 d2.evaluation.evaluator]: [0mInference done 846/8355. 0.1140 s / img. ETA=0:14:28
[32m[04/28 20:46:09 d2.evaluation.evaluator]: [0mInference done 889/8355. 0.1140 s / img. ETA=0:14:23
[32m[04/28 20:46:14 d2.evaluation.evaluator]: [0mInference done 933/8355. 0.1140 s / img. ETA=0:14:18
[32m[04/28 20:46:19 d2.evaluation.evaluator]: [0mInference done 977/8355. 0.1140 s / img. ETA=0:14:13
[32m[04/28 20:46:24 d2.evaluation.evaluator]: [0mInference done 1021/8355. 0.1140 s / img. ETA=0:14:08
[32m[04/28 20:46:29 d2.evaluation.evaluator]: [0mInference done 1064/8355. 0.1141 s / img. ETA=0:14:03
[32m[04/28 20:46:34 d2.evaluation.evaluator]: [0mInference done 1108/8355. 0.1140 s / img. ETA=0:13:58
[32m[04/28 20:46:39 d2.evaluation.evaluator]: [0mInference done 1152/8355. 0.1140 s / img. ETA=0:13:52
[32m[04/28 20:46:44 d2.evaluation.evaluator]: [0mInference done 1196/8355. 0.1140 s / img. ETA=0:13:47
[32m[04/28 20:46:49 d2.evaluation.evaluator]: [0mInference done 1240/8355. 0.1139 s / img. ETA=0:13:42
[32m[04/28 20:46:54 d2.evaluation.evaluator]: [0mInference done 1284/8355. 0.1139 s / img. ETA=0:13:36
[32m[04/28 20:46:59 d2.evaluation.evaluator]: [0mInference done 1328/8355. 0.1139 s / img. ETA=0:13:31
[32m[04/28 20:47:04 d2.evaluation.evaluator]: [0mInference done 1372/8355. 0.1139 s / img. ETA=0:13:26
[32m[04/28 20:47:09 d2.evaluation.evaluator]: [0mInference done 1416/8355. 0.1139 s / img. ETA=0:13:21
[32m[04/28 20:47:14 d2.evaluation.evaluator]: [0mInference done 1459/8355. 0.1139 s / img. ETA=0:13:16
[32m[04/28 20:47:19 d2.evaluation.evaluator]: [0mInference done 1502/8355. 0.1140 s / img. ETA=0:13:12
[32m[04/28 20:47:24 d2.evaluation.evaluator]: [0mInference done 1545/8355. 0.1140 s / img. ETA=0:13:07
[32m[04/28 20:47:29 d2.evaluation.evaluator]: [0mInference done 1588/8355. 0.1141 s / img. ETA=0:13:03
[32m[04/28 20:47:35 d2.evaluation.evaluator]: [0mInference done 1631/8355. 0.1141 s / img. ETA=0:12:58
[32m[04/28 20:47:40 d2.evaluation.evaluator]: [0mInference done 1674/8355. 0.1142 s / img. ETA=0:12:53
[32m[04/28 20:47:45 d2.evaluation.evaluator]: [0mInference done 1717/8355. 0.1143 s / img. ETA=0:12:49
[32m[04/28 20:47:50 d2.evaluation.evaluator]: [0mInference done 1760/8355. 0.1143 s / img. ETA=0:12:44
[32m[04/28 20:47:55 d2.evaluation.evaluator]: [0mInference done 1803/8355. 0.1143 s / img. ETA=0:12:39
[32m[04/28 20:48:00 d2.evaluation.evaluator]: [0mInference done 1846/8355. 0.1143 s / img. ETA=0:12:34
[32m[04/28 20:48:05 d2.evaluation.evaluator]: [0mInference done 1889/8355. 0.1144 s / img. ETA=0:12:30
[32m[04/28 20:48:10 d2.evaluation.evaluator]: [0mInference done 1932/8355. 0.1144 s / img. ETA=0:12:25
[32m[04/28 20:48:15 d2.evaluation.evaluator]: [0mInference done 1975/8355. 0.1144 s / img. ETA=0:12:20
[32m[04/28 20:48:20 d2.evaluation.evaluator]: [0mInference done 2018/8355. 0.1145 s / img. ETA=0:12:15
[32m[04/28 20:48:25 d2.evaluation.evaluator]: [0mInference done 2061/8355. 0.1145 s / img. ETA=0:12:10
[32m[04/28 20:48:30 d2.evaluation.evaluator]: [0mInference done 2104/8355. 0.1145 s / img. ETA=0:12:05
[32m[04/28 20:48:35 d2.evaluation.evaluator]: [0mInference done 2147/8355. 0.1145 s / img. ETA=0:12:01
[32m[04/28 20:48:40 d2.evaluation.evaluator]: [0mInference done 2190/8355. 0.1145 s / img. ETA=0:11:56
[32m[04/28 20:48:45 d2.evaluation.evaluator]: [0mInference done 2233/8355. 0.1146 s / img. ETA=0:11:51
[32m[04/28 20:48:50 d2.evaluation.evaluator]: [0mInference done 2276/8355. 0.1146 s / img. ETA=0:11:46
[32m[04/28 20:48:55 d2.evaluation.evaluator]: [0mInference done 2319/8355. 0.1146 s / img. ETA=0:11:41
[32m[04/28 20:49:00 d2.evaluation.evaluator]: [0mInference done 2362/8355. 0.1146 s / img. ETA=0:11:36
[32m[04/28 20:49:05 d2.evaluation.evaluator]: [0mInference done 2402/8355. 0.1148 s / img. ETA=0:11:33
[32m[04/28 20:49:10 d2.evaluation.evaluator]: [0mInference done 2445/8355. 0.1148 s / img. ETA=0:11:28
[32m[04/28 20:49:15 d2.evaluation.evaluator]: [0mInference done 2488/8355. 0.1148 s / img. ETA=0:11:23
[32m[04/28 20:49:20 d2.evaluation.evaluator]: [0mInference done 2531/8355. 0.1148 s / img. ETA=0:11:18
[32m[04/28 20:49:26 d2.evaluation.evaluator]: [0mInference done 2574/8355. 0.1148 s / img. ETA=0:11:13
[32m[04/28 20:49:31 d2.evaluation.evaluator]: [0mInference done 2617/8355. 0.1148 s / img. ETA=0:11:08
[32m[04/28 20:49:36 d2.evaluation.evaluator]: [0mInference done 2660/8355. 0.1148 s / img. ETA=0:11:03
[32m[04/28 20:49:41 d2.evaluation.evaluator]: [0mInference done 2703/8355. 0.1149 s / img. ETA=0:10:58
[32m[04/28 20:49:46 d2.evaluation.evaluator]: [0mInference done 2745/8355. 0.1149 s / img. ETA=0:10:53
[32m[04/28 20:49:51 d2.evaluation.evaluator]: [0mInference done 2788/8355. 0.1149 s / img. ETA=0:10:48
[32m[04/28 20:49:56 d2.evaluation.evaluator]: [0mInference done 2831/8355. 0.1149 s / img. ETA=0:10:43
[32m[04/28 20:50:01 d2.evaluation.evaluator]: [0mInference done 2874/8355. 0.1149 s / img. ETA=0:10:39
[32m[04/28 20:50:06 d2.evaluation.evaluator]: [0mInference done 2917/8355. 0.1149 s / img. ETA=0:10:34
[32m[04/28 20:50:11 d2.evaluation.evaluator]: [0mInference done 2960/8355. 0.1149 s / img. ETA=0:10:29
[32m[04/28 20:50:16 d2.evaluation.evaluator]: [0mInference done 3003/8355. 0.1149 s / img. ETA=0:10:24
[32m[04/28 20:50:21 d2.evaluation.evaluator]: [0mInference done 3046/8355. 0.1149 s / img. ETA=0:10:19
[32m[04/28 20:50:26 d2.evaluation.evaluator]: [0mInference done 3089/8355. 0.1150 s / img. ETA=0:10:14
[32m[04/28 20:50:31 d2.evaluation.evaluator]: [0mInference done 3132/8355. 0.1150 s / img. ETA=0:10:09
[32m[04/28 20:50:36 d2.evaluation.evaluator]: [0mInference done 3176/8355. 0.1150 s / img. ETA=0:10:04
[32m[04/28 20:50:41 d2.evaluation.evaluator]: [0mInference done 3220/8355. 0.1149 s / img. ETA=0:09:58
[32m[04/28 20:50:46 d2.evaluation.evaluator]: [0mInference done 3263/8355. 0.1149 s / img. ETA=0:09:53
[32m[04/28 20:50:51 d2.evaluation.evaluator]: [0mInference done 3306/8355. 0.1149 s / img. ETA=0:09:48
[32m[04/28 20:50:56 d2.evaluation.evaluator]: [0mInference done 3350/8355. 0.1149 s / img. ETA=0:09:43
[32m[04/28 20:51:01 d2.evaluation.evaluator]: [0mInference done 3393/8355. 0.1149 s / img. ETA=0:09:38
[32m[04/28 20:51:06 d2.evaluation.evaluator]: [0mInference done 3436/8355. 0.1149 s / img. ETA=0:09:33
[32m[04/28 20:51:11 d2.evaluation.evaluator]: [0mInference done 3479/8355. 0.1149 s / img. ETA=0:09:28
[32m[04/28 20:51:16 d2.evaluation.evaluator]: [0mInference done 3522/8355. 0.1149 s / img. ETA=0:09:23
[32m[04/28 20:51:22 d2.evaluation.evaluator]: [0mInference done 3565/8355. 0.1150 s / img. ETA=0:09:18
[32m[04/28 20:51:27 d2.evaluation.evaluator]: [0mInference done 3608/8355. 0.1150 s / img. ETA=0:09:13
[32m[04/28 20:51:32 d2.evaluation.evaluator]: [0mInference done 3651/8355. 0.1150 s / img. ETA=0:09:08
[32m[04/28 20:51:37 d2.evaluation.evaluator]: [0mInference done 3694/8355. 0.1150 s / img. ETA=0:09:03
[32m[04/28 20:51:42 d2.evaluation.evaluator]: [0mInference done 3737/8355. 0.1149 s / img. ETA=0:08:58
[32m[04/28 20:51:47 d2.evaluation.evaluator]: [0mInference done 3781/8355. 0.1149 s / img. ETA=0:08:53
[32m[04/28 20:51:52 d2.evaluation.evaluator]: [0mInference done 3824/8355. 0.1150 s / img. ETA=0:08:48
[32m[04/28 20:51:57 d2.evaluation.evaluator]: [0mInference done 3867/8355. 0.1150 s / img. ETA=0:08:43
[32m[04/28 20:52:02 d2.evaluation.evaluator]: [0mInference done 3911/8355. 0.1149 s / img. ETA=0:08:38
[32m[04/28 20:52:07 d2.evaluation.evaluator]: [0mInference done 3954/8355. 0.1149 s / img. ETA=0:08:33
[32m[04/28 20:52:12 d2.evaluation.evaluator]: [0mInference done 3998/8355. 0.1149 s / img. ETA=0:08:28
[32m[04/28 20:52:17 d2.evaluation.evaluator]: [0mInference done 4041/8355. 0.1149 s / img. ETA=0:08:23
[32m[04/28 20:52:22 d2.evaluation.evaluator]: [0mInference done 4084/8355. 0.1149 s / img. ETA=0:08:18
[32m[04/28 20:52:27 d2.evaluation.evaluator]: [0mInference done 4127/8355. 0.1149 s / img. ETA=0:08:13
[32m[04/28 20:52:32 d2.evaluation.evaluator]: [0mInference done 4170/8355. 0.1150 s / img. ETA=0:08:08
[32m[04/28 20:52:37 d2.evaluation.evaluator]: [0mInference done 4213/8355. 0.1150 s / img. ETA=0:08:03
[32m[04/28 20:52:42 d2.evaluation.evaluator]: [0mInference done 4257/8355. 0.1149 s / img. ETA=0:07:57
[32m[04/28 20:52:47 d2.evaluation.evaluator]: [0mInference done 4300/8355. 0.1150 s / img. ETA=0:07:53
[32m[04/28 20:52:52 d2.evaluation.evaluator]: [0mInference done 4343/8355. 0.1150 s / img. ETA=0:07:47
[32m[04/28 20:52:57 d2.evaluation.evaluator]: [0mInference done 4387/8355. 0.1149 s / img. ETA=0:07:42
[32m[04/28 20:53:03 d2.evaluation.evaluator]: [0mInference done 4430/8355. 0.1150 s / img. ETA=0:07:37
[32m[04/28 20:53:08 d2.evaluation.evaluator]: [0mInference done 4474/8355. 0.1150 s / img. ETA=0:07:32
[32m[04/28 20:53:13 d2.evaluation.evaluator]: [0mInference done 4517/8355. 0.1150 s / img. ETA=0:07:27
[32m[04/28 20:53:18 d2.evaluation.evaluator]: [0mInference done 4560/8355. 0.1150 s / img. ETA=0:07:22
[32m[04/28 20:53:23 d2.evaluation.evaluator]: [0mInference done 4603/8355. 0.1150 s / img. ETA=0:07:17
[32m[04/28 20:53:28 d2.evaluation.evaluator]: [0mInference done 4646/8355. 0.1150 s / img. ETA=0:07:12
[32m[04/28 20:53:33 d2.evaluation.evaluator]: [0mInference done 4689/8355. 0.1150 s / img. ETA=0:07:07
[32m[04/28 20:53:38 d2.evaluation.evaluator]: [0mInference done 4732/8355. 0.1150 s / img. ETA=0:07:02
[32m[04/28 20:53:43 d2.evaluation.evaluator]: [0mInference done 4775/8355. 0.1150 s / img. ETA=0:06:57
[32m[04/28 20:53:48 d2.evaluation.evaluator]: [0mInference done 4818/8355. 0.1150 s / img. ETA=0:06:52
[32m[04/28 20:53:53 d2.evaluation.evaluator]: [0mInference done 4861/8355. 0.1150 s / img. ETA=0:06:47
[32m[04/28 20:53:58 d2.evaluation.evaluator]: [0mInference done 4904/8355. 0.1150 s / img. ETA=0:06:42
[32m[04/28 20:54:03 d2.evaluation.evaluator]: [0mInference done 4947/8355. 0.1150 s / img. ETA=0:06:37
[32m[04/28 20:54:08 d2.evaluation.evaluator]: [0mInference done 4990/8355. 0.1150 s / img. ETA=0:06:32
[32m[04/28 20:54:13 d2.evaluation.evaluator]: [0mInference done 5033/8355. 0.1150 s / img. ETA=0:06:27
[32m[04/28 20:54:18 d2.evaluation.evaluator]: [0mInference done 5076/8355. 0.1150 s / img. ETA=0:06:22
[32m[04/28 20:54:23 d2.evaluation.evaluator]: [0mInference done 5119/8355. 0.1150 s / img. ETA=0:06:17
[32m[04/28 20:54:28 d2.evaluation.evaluator]: [0mInference done 5161/8355. 0.1150 s / img. ETA=0:06:12
[32m[04/28 20:54:33 d2.evaluation.evaluator]: [0mInference done 5204/8355. 0.1150 s / img. ETA=0:06:07
[32m[04/28 20:54:38 d2.evaluation.evaluator]: [0mInference done 5247/8355. 0.1150 s / img. ETA=0:06:02
[32m[04/28 20:54:43 d2.evaluation.evaluator]: [0mInference done 5290/8355. 0.1150 s / img. ETA=0:05:57
[32m[04/28 20:54:48 d2.evaluation.evaluator]: [0mInference done 5332/8355. 0.1150 s / img. ETA=0:05:52
[32m[04/28 20:54:53 d2.evaluation.evaluator]: [0mInference done 5375/8355. 0.1150 s / img. ETA=0:05:47
[32m[04/28 20:54:58 d2.evaluation.evaluator]: [0mInference done 5418/8355. 0.1150 s / img. ETA=0:05:42
[32m[04/28 20:55:03 d2.evaluation.evaluator]: [0mInference done 5461/8355. 0.1150 s / img. ETA=0:05:37
[32m[04/28 20:55:08 d2.evaluation.evaluator]: [0mInference done 5504/8355. 0.1150 s / img. ETA=0:05:32
[32m[04/28 20:55:13 d2.evaluation.evaluator]: [0mInference done 5548/8355. 0.1150 s / img. ETA=0:05:27
[32m[04/28 20:55:18 d2.evaluation.evaluator]: [0mInference done 5592/8355. 0.1150 s / img. ETA=0:05:22
[32m[04/28 20:55:23 d2.evaluation.evaluator]: [0mInference done 5635/8355. 0.1150 s / img. ETA=0:05:17
[32m[04/28 20:55:29 d2.evaluation.evaluator]: [0mInference done 5678/8355. 0.1150 s / img. ETA=0:05:12
[32m[04/28 20:55:34 d2.evaluation.evaluator]: [0mInference done 5721/8355. 0.1150 s / img. ETA=0:05:07
[32m[04/28 20:55:39 d2.evaluation.evaluator]: [0mInference done 5764/8355. 0.1150 s / img. ETA=0:05:02
[32m[04/28 20:55:44 d2.evaluation.evaluator]: [0mInference done 5807/8355. 0.1150 s / img. ETA=0:04:57
[32m[04/28 20:55:49 d2.evaluation.evaluator]: [0mInference done 5850/8355. 0.1151 s / img. ETA=0:04:52
[32m[04/28 20:55:54 d2.evaluation.evaluator]: [0mInference done 5893/8355. 0.1151 s / img. ETA=0:04:47
[32m[04/28 20:55:59 d2.evaluation.evaluator]: [0mInference done 5936/8355. 0.1151 s / img. ETA=0:04:42
[32m[04/28 20:56:04 d2.evaluation.evaluator]: [0mInference done 5978/8355. 0.1151 s / img. ETA=0:04:37
[32m[04/28 20:56:09 d2.evaluation.evaluator]: [0mInference done 6021/8355. 0.1151 s / img. ETA=0:04:32
[32m[04/28 20:56:14 d2.evaluation.evaluator]: [0mInference done 6064/8355. 0.1151 s / img. ETA=0:04:27
[32m[04/28 20:56:19 d2.evaluation.evaluator]: [0mInference done 6107/8355. 0.1151 s / img. ETA=0:04:22
[32m[04/28 20:56:24 d2.evaluation.evaluator]: [0mInference done 6150/8355. 0.1151 s / img. ETA=0:04:17
[32m[04/28 20:56:29 d2.evaluation.evaluator]: [0mInference done 6193/8355. 0.1151 s / img. ETA=0:04:12
[32m[04/28 20:56:34 d2.evaluation.evaluator]: [0mInference done 6236/8355. 0.1151 s / img. ETA=0:04:07
[32m[04/28 20:56:39 d2.evaluation.evaluator]: [0mInference done 6279/8355. 0.1151 s / img. ETA=0:04:02
[32m[04/28 20:56:44 d2.evaluation.evaluator]: [0mInference done 6322/8355. 0.1152 s / img. ETA=0:03:57
[32m[04/28 20:56:50 d2.evaluation.evaluator]: [0mInference done 6365/8355. 0.1152 s / img. ETA=0:03:52
[32m[04/28 20:56:55 d2.evaluation.evaluator]: [0mInference done 6408/8355. 0.1152 s / img. ETA=0:03:47
[32m[04/28 20:57:00 d2.evaluation.evaluator]: [0mInference done 6451/8355. 0.1152 s / img. ETA=0:03:42
[32m[04/28 20:57:05 d2.evaluation.evaluator]: [0mInference done 6495/8355. 0.1152 s / img. ETA=0:03:37
[32m[04/28 20:57:10 d2.evaluation.evaluator]: [0mInference done 6538/8355. 0.1152 s / img. ETA=0:03:32
[32m[04/28 20:57:15 d2.evaluation.evaluator]: [0mInference done 6581/8355. 0.1152 s / img. ETA=0:03:27
[32m[04/28 20:57:20 d2.evaluation.evaluator]: [0mInference done 6624/8355. 0.1152 s / img. ETA=0:03:22
[32m[04/28 20:57:25 d2.evaluation.evaluator]: [0mInference done 6668/8355. 0.1152 s / img. ETA=0:03:17
[32m[04/28 20:57:30 d2.evaluation.evaluator]: [0mInference done 6712/8355. 0.1151 s / img. ETA=0:03:11
[32m[04/28 20:57:35 d2.evaluation.evaluator]: [0mInference done 6756/8355. 0.1151 s / img. ETA=0:03:06
[32m[04/28 20:57:40 d2.evaluation.evaluator]: [0mInference done 6799/8355. 0.1151 s / img. ETA=0:03:01
[32m[04/28 20:57:45 d2.evaluation.evaluator]: [0mInference done 6842/8355. 0.1151 s / img. ETA=0:02:56
[32m[04/28 20:57:50 d2.evaluation.evaluator]: [0mInference done 6885/8355. 0.1151 s / img. ETA=0:02:51
[32m[04/28 20:57:55 d2.evaluation.evaluator]: [0mInference done 6928/8355. 0.1151 s / img. ETA=0:02:46
[32m[04/28 20:58:00 d2.evaluation.evaluator]: [0mInference done 6971/8355. 0.1151 s / img. ETA=0:02:41
[32m[04/28 20:58:05 d2.evaluation.evaluator]: [0mInference done 7014/8355. 0.1151 s / img. ETA=0:02:36
[32m[04/28 20:58:10 d2.evaluation.evaluator]: [0mInference done 7057/8355. 0.1151 s / img. ETA=0:02:31
[32m[04/28 20:58:15 d2.evaluation.evaluator]: [0mInference done 7100/8355. 0.1152 s / img. ETA=0:02:26
[32m[04/28 20:58:20 d2.evaluation.evaluator]: [0mInference done 7143/8355. 0.1152 s / img. ETA=0:02:21
[32m[04/28 20:58:26 d2.evaluation.evaluator]: [0mInference done 7186/8355. 0.1152 s / img. ETA=0:02:16
[32m[04/28 20:58:31 d2.evaluation.evaluator]: [0mInference done 7229/8355. 0.1152 s / img. ETA=0:02:11
[32m[04/28 20:58:36 d2.evaluation.evaluator]: [0mInference done 7271/8355. 0.1152 s / img. ETA=0:02:06
[32m[04/28 20:58:41 d2.evaluation.evaluator]: [0mInference done 7314/8355. 0.1152 s / img. ETA=0:02:01
[32m[04/28 20:58:46 d2.evaluation.evaluator]: [0mInference done 7357/8355. 0.1152 s / img. ETA=0:01:56
[32m[04/28 20:58:51 d2.evaluation.evaluator]: [0mInference done 7400/8355. 0.1152 s / img. ETA=0:01:51
[32m[04/28 20:58:56 d2.evaluation.evaluator]: [0mInference done 7443/8355. 0.1152 s / img. ETA=0:01:46
[32m[04/28 20:59:01 d2.evaluation.evaluator]: [0mInference done 7486/8355. 0.1152 s / img. ETA=0:01:41
[32m[04/28 20:59:06 d2.evaluation.evaluator]: [0mInference done 7529/8355. 0.1152 s / img. ETA=0:01:36
[32m[04/28 20:59:11 d2.evaluation.evaluator]: [0mInference done 7572/8355. 0.1152 s / img. ETA=0:01:31
[32m[04/28 20:59:16 d2.evaluation.evaluator]: [0mInference done 7615/8355. 0.1152 s / img. ETA=0:01:26
[32m[04/28 20:59:21 d2.evaluation.evaluator]: [0mInference done 7658/8355. 0.1152 s / img. ETA=0:01:21
[32m[04/28 20:59:26 d2.evaluation.evaluator]: [0mInference done 7701/8355. 0.1153 s / img. ETA=0:01:16
[32m[04/28 20:59:31 d2.evaluation.evaluator]: [0mInference done 7744/8355. 0.1153 s / img. ETA=0:01:11
[32m[04/28 20:59:37 d2.evaluation.evaluator]: [0mInference done 7787/8355. 0.1153 s / img. ETA=0:01:06
[32m[04/28 20:59:42 d2.evaluation.evaluator]: [0mInference done 7830/8355. 0.1153 s / img. ETA=0:01:01
[32m[04/28 20:59:47 d2.evaluation.evaluator]: [0mInference done 7873/8355. 0.1153 s / img. ETA=0:00:56
[32m[04/28 20:59:52 d2.evaluation.evaluator]: [0mInference done 7916/8355. 0.1153 s / img. ETA=0:00:51
[32m[04/28 20:59:57 d2.evaluation.evaluator]: [0mInference done 7959/8355. 0.1153 s / img. ETA=0:00:46
[32m[04/28 21:00:02 d2.evaluation.evaluator]: [0mInference done 8002/8355. 0.1153 s / img. ETA=0:00:41
[32m[04/28 21:00:07 d2.evaluation.evaluator]: [0mInference done 8046/8355. 0.1153 s / img. ETA=0:00:36
[32m[04/28 21:00:12 d2.evaluation.evaluator]: [0mInference done 8090/8355. 0.1153 s / img. ETA=0:00:30
[32m[04/28 21:00:17 d2.evaluation.evaluator]: [0mInference done 8134/8355. 0.1153 s / img. ETA=0:00:25
[32m[04/28 21:00:22 d2.evaluation.evaluator]: [0mInference done 8177/8355. 0.1153 s / img. ETA=0:00:20
[32m[04/28 21:00:27 d2.evaluation.evaluator]: [0mInference done 8220/8355. 0.1153 s / img. ETA=0:00:15
[32m[04/28 21:00:32 d2.evaluation.evaluator]: [0mInference done 8263/8355. 0.1153 s / img. ETA=0:00:10
[32m[04/28 21:00:37 d2.evaluation.evaluator]: [0mInference done 8306/8355. 0.1153 s / img. ETA=0:00:05
[32m[04/28 21:00:42 d2.evaluation.evaluator]: [0mInference done 8349/8355. 0.1153 s / img. ETA=0:00:00
[32m[04/28 21:00:43 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:16.839041 (0.116987 s / img per device, on 1 devices)
[32m[04/28 21:00:43 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:02 (0.115274 s / img per device, on 1 devices)
[32m[04/28 21:00:43 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 21:00:43 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 21:00:44 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.65s).
Accumulating evaluation results...
DONE (t=2.25s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.523
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.899
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.531
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.425
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.639
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.567
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.589
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.507
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.696
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.818
[32m[04/28 21:01:07 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.255 | 89.901 | 53.112 | 42.499 | 63.912 | 77.677 |
[32m[04/28 21:01:07 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 51.054 | bicycle       | 44.935 | car            | 60.774 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 21:01:07 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 21:01:07 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 21:01:07 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 21:01:09 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1152 s / img. ETA=0:02:25
[32m[04/28 21:01:14 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1149 s / img. ETA=0:02:20
[32m[04/28 21:01:19 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1149 s / img. ETA=0:02:15
[32m[04/28 21:01:24 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1150 s / img. ETA=0:02:10
[32m[04/28 21:01:29 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1151 s / img. ETA=0:02:05
[32m[04/28 21:01:34 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1150 s / img. ETA=0:02:00
[32m[04/28 21:01:39 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1151 s / img. ETA=0:01:55
[32m[04/28 21:01:44 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1151 s / img. ETA=0:01:50
[32m[04/28 21:01:49 d2.evaluation.evaluator]: [0mInference done 354/1257. 0.1155 s / img. ETA=0:01:46
[32m[04/28 21:01:54 d2.evaluation.evaluator]: [0mInference done 397/1257. 0.1155 s / img. ETA=0:01:40
[32m[04/28 21:01:59 d2.evaluation.evaluator]: [0mInference done 440/1257. 0.1155 s / img. ETA=0:01:35
[32m[04/28 21:02:04 d2.evaluation.evaluator]: [0mInference done 483/1257. 0.1154 s / img. ETA=0:01:30
[32m[04/28 21:02:09 d2.evaluation.evaluator]: [0mInference done 526/1257. 0.1154 s / img. ETA=0:01:25
[32m[04/28 21:02:14 d2.evaluation.evaluator]: [0mInference done 569/1257. 0.1154 s / img. ETA=0:01:20
[32m[04/28 21:02:19 d2.evaluation.evaluator]: [0mInference done 612/1257. 0.1154 s / img. ETA=0:01:15
[32m[04/28 21:02:24 d2.evaluation.evaluator]: [0mInference done 655/1257. 0.1154 s / img. ETA=0:01:10
[32m[04/28 21:02:29 d2.evaluation.evaluator]: [0mInference done 698/1257. 0.1154 s / img. ETA=0:01:05
[32m[04/28 21:02:34 d2.evaluation.evaluator]: [0mInference done 741/1257. 0.1154 s / img. ETA=0:01:00
[32m[04/28 21:02:39 d2.evaluation.evaluator]: [0mInference done 784/1257. 0.1154 s / img. ETA=0:00:55
[32m[04/28 21:02:44 d2.evaluation.evaluator]: [0mInference done 827/1257. 0.1154 s / img. ETA=0:00:50
[32m[04/28 21:02:49 d2.evaluation.evaluator]: [0mInference done 870/1257. 0.1154 s / img. ETA=0:00:45
[32m[04/28 21:02:54 d2.evaluation.evaluator]: [0mInference done 913/1257. 0.1154 s / img. ETA=0:00:40
[32m[04/28 21:02:59 d2.evaluation.evaluator]: [0mInference done 956/1257. 0.1154 s / img. ETA=0:00:35
[32m[04/28 21:03:05 d2.evaluation.evaluator]: [0mInference done 999/1257. 0.1154 s / img. ETA=0:00:30
[32m[04/28 21:03:10 d2.evaluation.evaluator]: [0mInference done 1042/1257. 0.1154 s / img. ETA=0:00:25
[32m[04/28 21:03:15 d2.evaluation.evaluator]: [0mInference done 1085/1257. 0.1154 s / img. ETA=0:00:20
[32m[04/28 21:03:20 d2.evaluation.evaluator]: [0mInference done 1128/1257. 0.1154 s / img. ETA=0:00:15
[32m[04/28 21:03:25 d2.evaluation.evaluator]: [0mInference done 1171/1257. 0.1154 s / img. ETA=0:00:10
[32m[04/28 21:03:30 d2.evaluation.evaluator]: [0mInference done 1214/1257. 0.1154 s / img. ETA=0:00:05
[32m[04/28 21:03:35 d2.evaluation.evaluator]: [0mInference done 1257/1257. 0.1154 s / img. ETA=0:00:00
[32m[04/28 21:03:35 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.910437 (0.117341 s / img per device, on 1 devices)
[32m[04/28 21:03:35 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115434 s / img per device, on 1 devices)
[32m[04/28 21:03:35 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 21:03:35 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 21:03:35 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.14s).
Accumulating evaluation results...
DONE (t=0.39s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.748
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.320
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.284
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.429
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.567
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.450
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.385
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.492
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.620
[32m[04/28 21:03:39 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 37.668 | 74.817 | 32.032 | 28.405 | 42.949 | 56.681 |
[32m[04/28 21:03:39 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 40.519 | bicycle       | 18.726 | car            | 53.759 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  32  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 21:03:39 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 21:03:40 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 21:03:40 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 21:03:40 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 21:03:40 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 21:03:40 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 21:03:40 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 21:04:01 d2.utils.events]: [0m eta: 0:17:06  iter: 19  total_loss: 0.502  loss_cls: 0.148  loss_box_reg: 0.306  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 1.0329  data_time: 0.0205  lr: 0.000100  max_mem: 5397M
[32m[04/28 21:04:22 d2.utils.events]: [0m eta: 0:16:53  iter: 39  total_loss: 0.474  loss_cls: 0.135  loss_box_reg: 0.278  loss_rpn_cls: 0.005  loss_rpn_loc: 0.060  time: 1.0343  data_time: 0.0076  lr: 0.000200  max_mem: 5397M
[32m[04/28 21:04:43 d2.utils.events]: [0m eta: 0:16:32  iter: 59  total_loss: 0.454  loss_cls: 0.129  loss_box_reg: 0.279  loss_rpn_cls: 0.005  loss_rpn_loc: 0.039  time: 1.0390  data_time: 0.0079  lr: 0.000300  max_mem: 5397M
[32m[04/28 21:05:03 d2.utils.events]: [0m eta: 0:16:02  iter: 79  total_loss: 0.457  loss_cls: 0.138  loss_box_reg: 0.269  loss_rpn_cls: 0.006  loss_rpn_loc: 0.039  time: 1.0293  data_time: 0.0076  lr: 0.000400  max_mem: 5397M
[32m[04/28 21:05:23 d2.utils.events]: [0m eta: 0:15:38  iter: 99  total_loss: 0.472  loss_cls: 0.144  loss_box_reg: 0.272  loss_rpn_cls: 0.004  loss_rpn_loc: 0.040  time: 1.0255  data_time: 0.0078  lr: 0.000500  max_mem: 5397M
[32m[04/28 21:05:45 d2.utils.events]: [0m eta: 0:15:20  iter: 119  total_loss: 0.467  loss_cls: 0.145  loss_box_reg: 0.277  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0314  data_time: 0.0078  lr: 0.000599  max_mem: 5397M
[32m[04/28 21:06:05 d2.utils.events]: [0m eta: 0:14:59  iter: 139  total_loss: 0.401  loss_cls: 0.121  loss_box_reg: 0.246  loss_rpn_cls: 0.004  loss_rpn_loc: 0.040  time: 1.0304  data_time: 0.0075  lr: 0.000699  max_mem: 5397M
[32m[04/28 21:06:26 d2.utils.events]: [0m eta: 0:14:38  iter: 159  total_loss: 0.464  loss_cls: 0.140  loss_box_reg: 0.269  loss_rpn_cls: 0.004  loss_rpn_loc: 0.038  time: 1.0300  data_time: 0.0078  lr: 0.000799  max_mem: 5397M
[32m[04/28 21:06:46 d2.utils.events]: [0m eta: 0:14:16  iter: 179  total_loss: 0.470  loss_cls: 0.146  loss_box_reg: 0.273  loss_rpn_cls: 0.009  loss_rpn_loc: 0.042  time: 1.0283  data_time: 0.0076  lr: 0.000899  max_mem: 5397M
[32m[04/28 21:07:07 d2.utils.events]: [0m eta: 0:13:55  iter: 199  total_loss: 0.417  loss_cls: 0.126  loss_box_reg: 0.255  loss_rpn_cls: 0.004  loss_rpn_loc: 0.030  time: 1.0295  data_time: 0.0079  lr: 0.000999  max_mem: 5397M
[32m[04/28 21:07:28 d2.utils.events]: [0m eta: 0:13:34  iter: 219  total_loss: 0.454  loss_cls: 0.143  loss_box_reg: 0.265  loss_rpn_cls: 0.004  loss_rpn_loc: 0.037  time: 1.0296  data_time: 0.0077  lr: 0.001099  max_mem: 5397M
[32m[04/28 21:07:48 d2.utils.events]: [0m eta: 0:13:13  iter: 239  total_loss: 0.437  loss_cls: 0.130  loss_box_reg: 0.270  loss_rpn_cls: 0.005  loss_rpn_loc: 0.037  time: 1.0293  data_time: 0.0076  lr: 0.001199  max_mem: 5397M
[32m[04/28 21:08:09 d2.utils.events]: [0m eta: 0:12:53  iter: 259  total_loss: 0.475  loss_cls: 0.138  loss_box_reg: 0.282  loss_rpn_cls: 0.005  loss_rpn_loc: 0.038  time: 1.0312  data_time: 0.0078  lr: 0.001299  max_mem: 5397M
[32m[04/28 21:08:30 d2.utils.events]: [0m eta: 0:12:33  iter: 279  total_loss: 0.464  loss_cls: 0.137  loss_box_reg: 0.290  loss_rpn_cls: 0.004  loss_rpn_loc: 0.044  time: 1.0324  data_time: 0.0076  lr: 0.001399  max_mem: 5397M
[32m[04/28 21:08:51 d2.utils.events]: [0m eta: 0:12:12  iter: 299  total_loss: 0.451  loss_cls: 0.136  loss_box_reg: 0.272  loss_rpn_cls: 0.004  loss_rpn_loc: 0.046  time: 1.0324  data_time: 0.0080  lr: 0.001499  max_mem: 5397M
[32m[04/28 21:09:12 d2.utils.events]: [0m eta: 0:11:51  iter: 319  total_loss: 0.469  loss_cls: 0.151  loss_box_reg: 0.270  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0320  data_time: 0.0077  lr: 0.001598  max_mem: 5397M
[32m[04/28 21:09:32 d2.utils.events]: [0m eta: 0:11:30  iter: 339  total_loss: 0.474  loss_cls: 0.136  loss_box_reg: 0.286  loss_rpn_cls: 0.003  loss_rpn_loc: 0.042  time: 1.0319  data_time: 0.0079  lr: 0.001698  max_mem: 5397M
[32m[04/28 21:09:53 d2.utils.events]: [0m eta: 0:11:08  iter: 359  total_loss: 0.412  loss_cls: 0.114  loss_box_reg: 0.245  loss_rpn_cls: 0.002  loss_rpn_loc: 0.041  time: 1.0316  data_time: 0.0078  lr: 0.001798  max_mem: 5397M
[32m[04/28 21:10:14 d2.utils.events]: [0m eta: 0:10:48  iter: 379  total_loss: 0.447  loss_cls: 0.134  loss_box_reg: 0.259  loss_rpn_cls: 0.003  loss_rpn_loc: 0.047  time: 1.0320  data_time: 0.0077  lr: 0.001898  max_mem: 5397M
[32m[04/28 21:10:35 d2.utils.events]: [0m eta: 0:10:28  iter: 399  total_loss: 0.363  loss_cls: 0.114  loss_box_reg: 0.223  loss_rpn_cls: 0.003  loss_rpn_loc: 0.037  time: 1.0331  data_time: 0.0080  lr: 0.001998  max_mem: 5397M
[32m[04/28 21:10:55 d2.utils.events]: [0m eta: 0:10:07  iter: 419  total_loss: 0.528  loss_cls: 0.154  loss_box_reg: 0.310  loss_rpn_cls: 0.006  loss_rpn_loc: 0.048  time: 1.0328  data_time: 0.0082  lr: 0.002098  max_mem: 5397M
[32m[04/28 21:11:15 d2.utils.events]: [0m eta: 0:09:44  iter: 439  total_loss: 0.454  loss_cls: 0.137  loss_box_reg: 0.274  loss_rpn_cls: 0.004  loss_rpn_loc: 0.042  time: 1.0312  data_time: 0.0075  lr: 0.002198  max_mem: 5397M
[32m[04/28 21:11:36 d2.utils.events]: [0m eta: 0:09:23  iter: 459  total_loss: 0.443  loss_cls: 0.121  loss_box_reg: 0.266  loss_rpn_cls: 0.003  loss_rpn_loc: 0.043  time: 1.0305  data_time: 0.0076  lr: 0.002298  max_mem: 5397M
[32m[04/28 21:11:57 d2.utils.events]: [0m eta: 0:09:02  iter: 479  total_loss: 0.473  loss_cls: 0.152  loss_box_reg: 0.285  loss_rpn_cls: 0.004  loss_rpn_loc: 0.044  time: 1.0309  data_time: 0.0079  lr: 0.002398  max_mem: 5397M
[32m[04/28 21:12:18 d2.utils.events]: [0m eta: 0:08:42  iter: 499  total_loss: 0.425  loss_cls: 0.131  loss_box_reg: 0.254  loss_rpn_cls: 0.003  loss_rpn_loc: 0.039  time: 1.0320  data_time: 0.0077  lr: 0.002498  max_mem: 5397M
[32m[04/28 21:12:38 d2.utils.events]: [0m eta: 0:08:21  iter: 519  total_loss: 0.448  loss_cls: 0.134  loss_box_reg: 0.268  loss_rpn_cls: 0.006  loss_rpn_loc: 0.039  time: 1.0319  data_time: 0.0078  lr: 0.002597  max_mem: 5397M
[32m[04/28 21:12:59 d2.utils.events]: [0m eta: 0:07:59  iter: 539  total_loss: 0.395  loss_cls: 0.126  loss_box_reg: 0.237  loss_rpn_cls: 0.005  loss_rpn_loc: 0.030  time: 1.0312  data_time: 0.0077  lr: 0.002697  max_mem: 5397M
[32m[04/28 21:13:19 d2.utils.events]: [0m eta: 0:07:39  iter: 559  total_loss: 0.445  loss_cls: 0.132  loss_box_reg: 0.262  loss_rpn_cls: 0.005  loss_rpn_loc: 0.039  time: 1.0313  data_time: 0.0078  lr: 0.002797  max_mem: 5397M
[32m[04/28 21:13:40 d2.utils.events]: [0m eta: 0:07:18  iter: 579  total_loss: 0.399  loss_cls: 0.126  loss_box_reg: 0.251  loss_rpn_cls: 0.004  loss_rpn_loc: 0.033  time: 1.0312  data_time: 0.0080  lr: 0.002897  max_mem: 5397M
[32m[04/28 21:14:01 d2.utils.events]: [0m eta: 0:06:57  iter: 599  total_loss: 0.455  loss_cls: 0.135  loss_box_reg: 0.269  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0314  data_time: 0.0078  lr: 0.002997  max_mem: 5397M
[32m[04/28 21:14:22 d2.utils.events]: [0m eta: 0:06:37  iter: 619  total_loss: 0.507  loss_cls: 0.149  loss_box_reg: 0.294  loss_rpn_cls: 0.005  loss_rpn_loc: 0.046  time: 1.0316  data_time: 0.0079  lr: 0.003097  max_mem: 5397M
[32m[04/28 21:14:42 d2.utils.events]: [0m eta: 0:06:16  iter: 639  total_loss: 0.467  loss_cls: 0.142  loss_box_reg: 0.276  loss_rpn_cls: 0.004  loss_rpn_loc: 0.048  time: 1.0315  data_time: 0.0077  lr: 0.003197  max_mem: 5397M
[32m[04/28 21:15:03 d2.utils.events]: [0m eta: 0:05:55  iter: 659  total_loss: 0.428  loss_cls: 0.133  loss_box_reg: 0.256  loss_rpn_cls: 0.003  loss_rpn_loc: 0.036  time: 1.0318  data_time: 0.0078  lr: 0.003297  max_mem: 5397M
[32m[04/28 21:15:24 d2.utils.events]: [0m eta: 0:05:35  iter: 679  total_loss: 0.521  loss_cls: 0.153  loss_box_reg: 0.302  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0321  data_time: 0.0078  lr: 0.003397  max_mem: 5397M
[32m[04/28 21:15:44 d2.utils.events]: [0m eta: 0:05:14  iter: 699  total_loss: 0.467  loss_cls: 0.136  loss_box_reg: 0.280  loss_rpn_cls: 0.003  loss_rpn_loc: 0.042  time: 1.0318  data_time: 0.0077  lr: 0.003497  max_mem: 5397M
[32m[04/28 21:16:05 d2.utils.events]: [0m eta: 0:04:53  iter: 719  total_loss: 0.411  loss_cls: 0.120  loss_box_reg: 0.247  loss_rpn_cls: 0.003  loss_rpn_loc: 0.039  time: 1.0317  data_time: 0.0077  lr: 0.003596  max_mem: 5397M
[32m[04/28 21:16:26 d2.utils.events]: [0m eta: 0:04:32  iter: 739  total_loss: 0.506  loss_cls: 0.153  loss_box_reg: 0.280  loss_rpn_cls: 0.007  loss_rpn_loc: 0.049  time: 1.0313  data_time: 0.0075  lr: 0.003696  max_mem: 5397M
[32m[04/28 21:16:47 d2.utils.events]: [0m eta: 0:04:11  iter: 759  total_loss: 0.449  loss_cls: 0.128  loss_box_reg: 0.258  loss_rpn_cls: 0.004  loss_rpn_loc: 0.033  time: 1.0323  data_time: 0.0077  lr: 0.003796  max_mem: 5397M
[32m[04/28 21:17:08 d2.utils.events]: [0m eta: 0:03:50  iter: 779  total_loss: 0.425  loss_cls: 0.130  loss_box_reg: 0.254  loss_rpn_cls: 0.004  loss_rpn_loc: 0.028  time: 1.0324  data_time: 0.0078  lr: 0.003896  max_mem: 5397M
[32m[04/28 21:17:28 d2.utils.events]: [0m eta: 0:03:29  iter: 799  total_loss: 0.437  loss_cls: 0.130  loss_box_reg: 0.272  loss_rpn_cls: 0.005  loss_rpn_loc: 0.035  time: 1.0323  data_time: 0.0076  lr: 0.003996  max_mem: 5397M
[32m[04/28 21:17:49 d2.utils.events]: [0m eta: 0:03:08  iter: 819  total_loss: 0.459  loss_cls: 0.136  loss_box_reg: 0.278  loss_rpn_cls: 0.004  loss_rpn_loc: 0.047  time: 1.0323  data_time: 0.0077  lr: 0.004096  max_mem: 5397M
[32m[04/28 21:18:09 d2.utils.events]: [0m eta: 0:02:48  iter: 839  total_loss: 0.526  loss_cls: 0.146  loss_box_reg: 0.317  loss_rpn_cls: 0.003  loss_rpn_loc: 0.053  time: 1.0318  data_time: 0.0076  lr: 0.004196  max_mem: 5397M
[32m[04/28 21:18:30 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.518  loss_cls: 0.158  loss_box_reg: 0.310  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0321  data_time: 0.0077  lr: 0.004296  max_mem: 5397M
[32m[04/28 21:18:52 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.505  loss_cls: 0.148  loss_box_reg: 0.285  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0329  data_time: 0.0079  lr: 0.004396  max_mem: 5397M
[32m[04/28 21:19:12 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.503  loss_cls: 0.159  loss_box_reg: 0.284  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0320  data_time: 0.0077  lr: 0.004496  max_mem: 5397M
[32m[04/28 21:19:32 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.481  loss_cls: 0.140  loss_box_reg: 0.283  loss_rpn_cls: 0.004  loss_rpn_loc: 0.048  time: 1.0320  data_time: 0.0078  lr: 0.004595  max_mem: 5397M
[32m[04/28 21:19:53 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.460  loss_cls: 0.136  loss_box_reg: 0.279  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0321  data_time: 0.0078  lr: 0.004695  max_mem: 5397M
[32m[04/28 21:20:14 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.547  loss_cls: 0.164  loss_box_reg: 0.318  loss_rpn_cls: 0.006  loss_rpn_loc: 0.048  time: 1.0319  data_time: 0.0078  lr: 0.004795  max_mem: 5397M
[32m[04/28 21:20:34 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.544  loss_cls: 0.161  loss_box_reg: 0.305  loss_rpn_cls: 0.008  loss_rpn_loc: 0.049  time: 1.0321  data_time: 0.0077  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 21:20:57 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 21:20:57 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 21:20:57 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 21:20:57 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.493  loss_cls: 0.159  loss_box_reg: 0.295  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0317  data_time: 0.0085  lr: 0.004995  max_mem: 5397M
[32m[04/28 21:20:58 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:09 (1.0327 s / it)
[32m[04/28 21:20:58 d2.engine.hooks]: [0mTotal training time: 0:17:15 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 21:20:59 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 21:20:59 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 21:20:59 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 21:21:01 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1139 s / img. ETA=0:16:02
[32m[04/28 21:21:06 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1140 s / img. ETA=0:16:00
[32m[04/28 21:21:11 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1139 s / img. ETA=0:15:53
[32m[04/28 21:21:16 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1139 s / img. ETA=0:15:49
[32m[04/28 21:21:21 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1138 s / img. ETA=0:15:43
[32m[04/28 21:21:26 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1139 s / img. ETA=0:15:39
[32m[04/28 21:21:31 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1140 s / img. ETA=0:15:34
[32m[04/28 21:21:37 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1140 s / img. ETA=0:15:29
[32m[04/28 21:21:42 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1140 s / img. ETA=0:15:25
[32m[04/28 21:21:47 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1141 s / img. ETA=0:15:20
[32m[04/28 21:21:52 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1141 s / img. ETA=0:15:15
[32m[04/28 21:21:57 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1141 s / img. ETA=0:15:10
[32m[04/28 21:22:02 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1140 s / img. ETA=0:15:04
[32m[04/28 21:22:07 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1140 s / img. ETA=0:14:59
[32m[04/28 21:22:12 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1140 s / img. ETA=0:14:54
[32m[04/28 21:22:17 d2.evaluation.evaluator]: [0mInference done 671/8355. 0.1141 s / img. ETA=0:14:49
[32m[04/28 21:22:22 d2.evaluation.evaluator]: [0mInference done 715/8355. 0.1141 s / img. ETA=0:14:44
[32m[04/28 21:22:28 d2.evaluation.evaluator]: [0mInference done 759/8355. 0.1141 s / img. ETA=0:14:39
[32m[04/28 21:22:33 d2.evaluation.evaluator]: [0mInference done 803/8355. 0.1141 s / img. ETA=0:14:34
[32m[04/28 21:22:38 d2.evaluation.evaluator]: [0mInference done 847/8355. 0.1141 s / img. ETA=0:14:29
[32m[04/28 21:22:43 d2.evaluation.evaluator]: [0mInference done 890/8355. 0.1141 s / img. ETA=0:14:24
[32m[04/28 21:22:48 d2.evaluation.evaluator]: [0mInference done 933/8355. 0.1141 s / img. ETA=0:14:19
[32m[04/28 21:22:53 d2.evaluation.evaluator]: [0mInference done 977/8355. 0.1141 s / img. ETA=0:14:14
[32m[04/28 21:22:58 d2.evaluation.evaluator]: [0mInference done 1020/8355. 0.1142 s / img. ETA=0:14:10
[32m[04/28 21:23:03 d2.evaluation.evaluator]: [0mInference done 1064/8355. 0.1142 s / img. ETA=0:14:04
[32m[04/28 21:23:08 d2.evaluation.evaluator]: [0mInference done 1108/8355. 0.1141 s / img. ETA=0:13:59
[32m[04/28 21:23:13 d2.evaluation.evaluator]: [0mInference done 1152/8355. 0.1141 s / img. ETA=0:13:54
[32m[04/28 21:23:18 d2.evaluation.evaluator]: [0mInference done 1196/8355. 0.1141 s / img. ETA=0:13:49
[32m[04/28 21:23:23 d2.evaluation.evaluator]: [0mInference done 1240/8355. 0.1141 s / img. ETA=0:13:43
[32m[04/28 21:23:28 d2.evaluation.evaluator]: [0mInference done 1284/8355. 0.1140 s / img. ETA=0:13:38
[32m[04/28 21:23:33 d2.evaluation.evaluator]: [0mInference done 1328/8355. 0.1140 s / img. ETA=0:13:33
[32m[04/28 21:23:38 d2.evaluation.evaluator]: [0mInference done 1372/8355. 0.1141 s / img. ETA=0:13:28
[32m[04/28 21:23:43 d2.evaluation.evaluator]: [0mInference done 1415/8355. 0.1141 s / img. ETA=0:13:23
[32m[04/28 21:23:49 d2.evaluation.evaluator]: [0mInference done 1459/8355. 0.1141 s / img. ETA=0:13:18
[32m[04/28 21:23:54 d2.evaluation.evaluator]: [0mInference done 1502/8355. 0.1141 s / img. ETA=0:13:13
[32m[04/28 21:23:59 d2.evaluation.evaluator]: [0mInference done 1544/8355. 0.1142 s / img. ETA=0:13:09
[32m[04/28 21:24:04 d2.evaluation.evaluator]: [0mInference done 1587/8355. 0.1143 s / img. ETA=0:13:04
[32m[04/28 21:24:09 d2.evaluation.evaluator]: [0mInference done 1630/8355. 0.1143 s / img. ETA=0:13:00
[32m[04/28 21:24:14 d2.evaluation.evaluator]: [0mInference done 1673/8355. 0.1144 s / img. ETA=0:12:55
[32m[04/28 21:24:19 d2.evaluation.evaluator]: [0mInference done 1716/8355. 0.1144 s / img. ETA=0:12:50
[32m[04/28 21:24:24 d2.evaluation.evaluator]: [0mInference done 1759/8355. 0.1144 s / img. ETA=0:12:45
[32m[04/28 21:24:29 d2.evaluation.evaluator]: [0mInference done 1802/8355. 0.1144 s / img. ETA=0:12:41
[32m[04/28 21:24:34 d2.evaluation.evaluator]: [0mInference done 1845/8355. 0.1145 s / img. ETA=0:12:36
[32m[04/28 21:24:39 d2.evaluation.evaluator]: [0mInference done 1888/8355. 0.1145 s / img. ETA=0:12:31
[32m[04/28 21:24:44 d2.evaluation.evaluator]: [0mInference done 1931/8355. 0.1145 s / img. ETA=0:12:26
[32m[04/28 21:24:49 d2.evaluation.evaluator]: [0mInference done 1974/8355. 0.1145 s / img. ETA=0:12:21
[32m[04/28 21:24:54 d2.evaluation.evaluator]: [0mInference done 2017/8355. 0.1146 s / img. ETA=0:12:17
[32m[04/28 21:24:59 d2.evaluation.evaluator]: [0mInference done 2060/8355. 0.1146 s / img. ETA=0:12:12
[32m[04/28 21:25:04 d2.evaluation.evaluator]: [0mInference done 2103/8355. 0.1146 s / img. ETA=0:12:07
[32m[04/28 21:25:09 d2.evaluation.evaluator]: [0mInference done 2147/8355. 0.1146 s / img. ETA=0:12:02
[32m[04/28 21:25:14 d2.evaluation.evaluator]: [0mInference done 2190/8355. 0.1146 s / img. ETA=0:11:57
[32m[04/28 21:25:19 d2.evaluation.evaluator]: [0mInference done 2233/8355. 0.1146 s / img. ETA=0:11:52
[32m[04/28 21:25:24 d2.evaluation.evaluator]: [0mInference done 2276/8355. 0.1146 s / img. ETA=0:11:47
[32m[04/28 21:25:30 d2.evaluation.evaluator]: [0mInference done 2319/8355. 0.1146 s / img. ETA=0:11:42
[32m[04/28 21:25:35 d2.evaluation.evaluator]: [0mInference done 2362/8355. 0.1147 s / img. ETA=0:11:37
[32m[04/28 21:25:40 d2.evaluation.evaluator]: [0mInference done 2405/8355. 0.1147 s / img. ETA=0:11:32
[32m[04/28 21:25:45 d2.evaluation.evaluator]: [0mInference done 2448/8355. 0.1147 s / img. ETA=0:11:27
[32m[04/28 21:25:50 d2.evaluation.evaluator]: [0mInference done 2491/8355. 0.1147 s / img. ETA=0:11:22
[32m[04/28 21:25:55 d2.evaluation.evaluator]: [0mInference done 2534/8355. 0.1147 s / img. ETA=0:11:17
[32m[04/28 21:26:00 d2.evaluation.evaluator]: [0mInference done 2577/8355. 0.1147 s / img. ETA=0:11:12
[32m[04/28 21:26:05 d2.evaluation.evaluator]: [0mInference done 2620/8355. 0.1147 s / img. ETA=0:11:07
[32m[04/28 21:26:10 d2.evaluation.evaluator]: [0mInference done 2663/8355. 0.1147 s / img. ETA=0:11:02
[32m[04/28 21:26:15 d2.evaluation.evaluator]: [0mInference done 2706/8355. 0.1147 s / img. ETA=0:10:57
[32m[04/28 21:26:20 d2.evaluation.evaluator]: [0mInference done 2749/8355. 0.1148 s / img. ETA=0:10:53
[32m[04/28 21:26:25 d2.evaluation.evaluator]: [0mInference done 2792/8355. 0.1148 s / img. ETA=0:10:48
[32m[04/28 21:26:30 d2.evaluation.evaluator]: [0mInference done 2835/8355. 0.1148 s / img. ETA=0:10:43
[32m[04/28 21:26:35 d2.evaluation.evaluator]: [0mInference done 2878/8355. 0.1148 s / img. ETA=0:10:38
[32m[04/28 21:26:40 d2.evaluation.evaluator]: [0mInference done 2921/8355. 0.1148 s / img. ETA=0:10:33
[32m[04/28 21:26:45 d2.evaluation.evaluator]: [0mInference done 2964/8355. 0.1148 s / img. ETA=0:10:28
[32m[04/28 21:26:50 d2.evaluation.evaluator]: [0mInference done 3007/8355. 0.1148 s / img. ETA=0:10:23
[32m[04/28 21:26:55 d2.evaluation.evaluator]: [0mInference done 3050/8355. 0.1148 s / img. ETA=0:10:18
[32m[04/28 21:27:00 d2.evaluation.evaluator]: [0mInference done 3093/8355. 0.1148 s / img. ETA=0:10:13
[32m[04/28 21:27:05 d2.evaluation.evaluator]: [0mInference done 3136/8355. 0.1148 s / img. ETA=0:10:08
[32m[04/28 21:27:10 d2.evaluation.evaluator]: [0mInference done 3180/8355. 0.1148 s / img. ETA=0:10:03
[32m[04/28 21:27:15 d2.evaluation.evaluator]: [0mInference done 3224/8355. 0.1148 s / img. ETA=0:09:57
[32m[04/28 21:27:20 d2.evaluation.evaluator]: [0mInference done 3267/8355. 0.1148 s / img. ETA=0:09:52
[32m[04/28 21:27:25 d2.evaluation.evaluator]: [0mInference done 3310/8355. 0.1148 s / img. ETA=0:09:48
[32m[04/28 21:27:31 d2.evaluation.evaluator]: [0mInference done 3354/8355. 0.1148 s / img. ETA=0:09:42
[32m[04/28 21:27:36 d2.evaluation.evaluator]: [0mInference done 3397/8355. 0.1148 s / img. ETA=0:09:37
[32m[04/28 21:27:41 d2.evaluation.evaluator]: [0mInference done 3441/8355. 0.1148 s / img. ETA=0:09:32
[32m[04/28 21:27:46 d2.evaluation.evaluator]: [0mInference done 3484/8355. 0.1148 s / img. ETA=0:09:27
[32m[04/28 21:27:51 d2.evaluation.evaluator]: [0mInference done 3527/8355. 0.1148 s / img. ETA=0:09:22
[32m[04/28 21:27:56 d2.evaluation.evaluator]: [0mInference done 3571/8355. 0.1148 s / img. ETA=0:09:17
[32m[04/28 21:28:01 d2.evaluation.evaluator]: [0mInference done 3614/8355. 0.1148 s / img. ETA=0:09:12
[32m[04/28 21:28:06 d2.evaluation.evaluator]: [0mInference done 3657/8355. 0.1148 s / img. ETA=0:09:07
[32m[04/28 21:28:11 d2.evaluation.evaluator]: [0mInference done 3700/8355. 0.1148 s / img. ETA=0:09:02
[32m[04/28 21:28:16 d2.evaluation.evaluator]: [0mInference done 3743/8355. 0.1148 s / img. ETA=0:08:57
[32m[04/28 21:28:21 d2.evaluation.evaluator]: [0mInference done 3786/8355. 0.1148 s / img. ETA=0:08:52
[32m[04/28 21:28:26 d2.evaluation.evaluator]: [0mInference done 3829/8355. 0.1148 s / img. ETA=0:08:47
[32m[04/28 21:28:31 d2.evaluation.evaluator]: [0mInference done 3872/8355. 0.1148 s / img. ETA=0:08:42
[32m[04/28 21:28:36 d2.evaluation.evaluator]: [0mInference done 3916/8355. 0.1148 s / img. ETA=0:08:37
[32m[04/28 21:28:41 d2.evaluation.evaluator]: [0mInference done 3959/8355. 0.1148 s / img. ETA=0:08:32
[32m[04/28 21:28:46 d2.evaluation.evaluator]: [0mInference done 4002/8355. 0.1148 s / img. ETA=0:08:27
[32m[04/28 21:28:51 d2.evaluation.evaluator]: [0mInference done 4045/8355. 0.1148 s / img. ETA=0:08:22
[32m[04/28 21:28:56 d2.evaluation.evaluator]: [0mInference done 4088/8355. 0.1148 s / img. ETA=0:08:17
[32m[04/28 21:29:01 d2.evaluation.evaluator]: [0mInference done 4131/8355. 0.1148 s / img. ETA=0:08:12
[32m[04/28 21:29:06 d2.evaluation.evaluator]: [0mInference done 4174/8355. 0.1148 s / img. ETA=0:08:07
[32m[04/28 21:29:11 d2.evaluation.evaluator]: [0mInference done 4217/8355. 0.1149 s / img. ETA=0:08:02
[32m[04/28 21:29:16 d2.evaluation.evaluator]: [0mInference done 4261/8355. 0.1148 s / img. ETA=0:07:57
[32m[04/28 21:29:22 d2.evaluation.evaluator]: [0mInference done 4305/8355. 0.1148 s / img. ETA=0:07:52
[32m[04/28 21:29:27 d2.evaluation.evaluator]: [0mInference done 4348/8355. 0.1148 s / img. ETA=0:07:47
[32m[04/28 21:29:32 d2.evaluation.evaluator]: [0mInference done 4391/8355. 0.1149 s / img. ETA=0:07:42
[32m[04/28 21:29:37 d2.evaluation.evaluator]: [0mInference done 4434/8355. 0.1149 s / img. ETA=0:07:37
[32m[04/28 21:29:42 d2.evaluation.evaluator]: [0mInference done 4478/8355. 0.1149 s / img. ETA=0:07:32
[32m[04/28 21:29:47 d2.evaluation.evaluator]: [0mInference done 4521/8355. 0.1149 s / img. ETA=0:07:27
[32m[04/28 21:29:52 d2.evaluation.evaluator]: [0mInference done 4564/8355. 0.1149 s / img. ETA=0:07:22
[32m[04/28 21:29:57 d2.evaluation.evaluator]: [0mInference done 4607/8355. 0.1149 s / img. ETA=0:07:17
[32m[04/28 21:30:02 d2.evaluation.evaluator]: [0mInference done 4650/8355. 0.1149 s / img. ETA=0:07:12
[32m[04/28 21:30:07 d2.evaluation.evaluator]: [0mInference done 4693/8355. 0.1149 s / img. ETA=0:07:07
[32m[04/28 21:30:12 d2.evaluation.evaluator]: [0mInference done 4736/8355. 0.1149 s / img. ETA=0:07:02
[32m[04/28 21:30:17 d2.evaluation.evaluator]: [0mInference done 4779/8355. 0.1149 s / img. ETA=0:06:57
[32m[04/28 21:30:22 d2.evaluation.evaluator]: [0mInference done 4822/8355. 0.1149 s / img. ETA=0:06:52
[32m[04/28 21:30:27 d2.evaluation.evaluator]: [0mInference done 4865/8355. 0.1149 s / img. ETA=0:06:47
[32m[04/28 21:30:32 d2.evaluation.evaluator]: [0mInference done 4908/8355. 0.1149 s / img. ETA=0:06:42
[32m[04/28 21:30:37 d2.evaluation.evaluator]: [0mInference done 4951/8355. 0.1149 s / img. ETA=0:06:37
[32m[04/28 21:30:42 d2.evaluation.evaluator]: [0mInference done 4994/8355. 0.1149 s / img. ETA=0:06:32
[32m[04/28 21:30:47 d2.evaluation.evaluator]: [0mInference done 5037/8355. 0.1149 s / img. ETA=0:06:27
[32m[04/28 21:30:52 d2.evaluation.evaluator]: [0mInference done 5080/8355. 0.1149 s / img. ETA=0:06:22
[32m[04/28 21:30:57 d2.evaluation.evaluator]: [0mInference done 5123/8355. 0.1149 s / img. ETA=0:06:17
[32m[04/28 21:31:02 d2.evaluation.evaluator]: [0mInference done 5166/8355. 0.1149 s / img. ETA=0:06:12
[32m[04/28 21:31:07 d2.evaluation.evaluator]: [0mInference done 5209/8355. 0.1149 s / img. ETA=0:06:07
[32m[04/28 21:31:12 d2.evaluation.evaluator]: [0mInference done 5253/8355. 0.1149 s / img. ETA=0:06:01
[32m[04/28 21:31:17 d2.evaluation.evaluator]: [0mInference done 5296/8355. 0.1149 s / img. ETA=0:05:56
[32m[04/28 21:31:22 d2.evaluation.evaluator]: [0mInference done 5339/8355. 0.1149 s / img. ETA=0:05:51
[32m[04/28 21:31:28 d2.evaluation.evaluator]: [0mInference done 5382/8355. 0.1149 s / img. ETA=0:05:46
[32m[04/28 21:31:33 d2.evaluation.evaluator]: [0mInference done 5425/8355. 0.1149 s / img. ETA=0:05:41
[32m[04/28 21:31:38 d2.evaluation.evaluator]: [0mInference done 5468/8355. 0.1149 s / img. ETA=0:05:36
[32m[04/28 21:31:43 d2.evaluation.evaluator]: [0mInference done 5511/8355. 0.1149 s / img. ETA=0:05:31
[32m[04/28 21:31:48 d2.evaluation.evaluator]: [0mInference done 5554/8355. 0.1149 s / img. ETA=0:05:26
[32m[04/28 21:31:53 d2.evaluation.evaluator]: [0mInference done 5598/8355. 0.1149 s / img. ETA=0:05:21
[32m[04/28 21:31:58 d2.evaluation.evaluator]: [0mInference done 5641/8355. 0.1149 s / img. ETA=0:05:16
[32m[04/28 21:32:03 d2.evaluation.evaluator]: [0mInference done 5684/8355. 0.1149 s / img. ETA=0:05:11
[32m[04/28 21:32:08 d2.evaluation.evaluator]: [0mInference done 5727/8355. 0.1149 s / img. ETA=0:05:06
[32m[04/28 21:32:13 d2.evaluation.evaluator]: [0mInference done 5770/8355. 0.1149 s / img. ETA=0:05:01
[32m[04/28 21:32:18 d2.evaluation.evaluator]: [0mInference done 5813/8355. 0.1149 s / img. ETA=0:04:56
[32m[04/28 21:32:23 d2.evaluation.evaluator]: [0mInference done 5855/8355. 0.1149 s / img. ETA=0:04:51
[32m[04/28 21:32:28 d2.evaluation.evaluator]: [0mInference done 5898/8355. 0.1150 s / img. ETA=0:04:46
[32m[04/28 21:32:33 d2.evaluation.evaluator]: [0mInference done 5941/8355. 0.1150 s / img. ETA=0:04:41
[32m[04/28 21:32:38 d2.evaluation.evaluator]: [0mInference done 5984/8355. 0.1150 s / img. ETA=0:04:36
[32m[04/28 21:32:43 d2.evaluation.evaluator]: [0mInference done 6027/8355. 0.1150 s / img. ETA=0:04:31
[32m[04/28 21:32:48 d2.evaluation.evaluator]: [0mInference done 6069/8355. 0.1150 s / img. ETA=0:04:26
[32m[04/28 21:32:53 d2.evaluation.evaluator]: [0mInference done 6112/8355. 0.1150 s / img. ETA=0:04:21
[32m[04/28 21:32:58 d2.evaluation.evaluator]: [0mInference done 6155/8355. 0.1150 s / img. ETA=0:04:16
[32m[04/28 21:33:03 d2.evaluation.evaluator]: [0mInference done 6198/8355. 0.1150 s / img. ETA=0:04:11
[32m[04/28 21:33:08 d2.evaluation.evaluator]: [0mInference done 6241/8355. 0.1150 s / img. ETA=0:04:06
[32m[04/28 21:33:13 d2.evaluation.evaluator]: [0mInference done 6284/8355. 0.1150 s / img. ETA=0:04:01
[32m[04/28 21:33:19 d2.evaluation.evaluator]: [0mInference done 6327/8355. 0.1150 s / img. ETA=0:03:56
[32m[04/28 21:33:24 d2.evaluation.evaluator]: [0mInference done 6370/8355. 0.1150 s / img. ETA=0:03:51
[32m[04/28 21:33:29 d2.evaluation.evaluator]: [0mInference done 6413/8355. 0.1150 s / img. ETA=0:03:46
[32m[04/28 21:33:34 d2.evaluation.evaluator]: [0mInference done 6456/8355. 0.1150 s / img. ETA=0:03:41
[32m[04/28 21:33:39 d2.evaluation.evaluator]: [0mInference done 6499/8355. 0.1150 s / img. ETA=0:03:36
[32m[04/28 21:33:44 d2.evaluation.evaluator]: [0mInference done 6543/8355. 0.1150 s / img. ETA=0:03:31
[32m[04/28 21:33:49 d2.evaluation.evaluator]: [0mInference done 6586/8355. 0.1150 s / img. ETA=0:03:26
[32m[04/28 21:33:54 d2.evaluation.evaluator]: [0mInference done 6629/8355. 0.1150 s / img. ETA=0:03:21
[32m[04/28 21:33:59 d2.evaluation.evaluator]: [0mInference done 6672/8355. 0.1150 s / img. ETA=0:03:16
[32m[04/28 21:34:04 d2.evaluation.evaluator]: [0mInference done 6716/8355. 0.1150 s / img. ETA=0:03:11
[32m[04/28 21:34:09 d2.evaluation.evaluator]: [0mInference done 6760/8355. 0.1150 s / img. ETA=0:03:06
[32m[04/28 21:34:14 d2.evaluation.evaluator]: [0mInference done 6803/8355. 0.1150 s / img. ETA=0:03:01
[32m[04/28 21:34:19 d2.evaluation.evaluator]: [0mInference done 6846/8355. 0.1150 s / img. ETA=0:02:56
[32m[04/28 21:34:24 d2.evaluation.evaluator]: [0mInference done 6889/8355. 0.1150 s / img. ETA=0:02:51
[32m[04/28 21:34:29 d2.evaluation.evaluator]: [0mInference done 6933/8355. 0.1150 s / img. ETA=0:02:46
[32m[04/28 21:34:34 d2.evaluation.evaluator]: [0mInference done 6976/8355. 0.1150 s / img. ETA=0:02:41
[32m[04/28 21:34:39 d2.evaluation.evaluator]: [0mInference done 7019/8355. 0.1150 s / img. ETA=0:02:36
[32m[04/28 21:34:44 d2.evaluation.evaluator]: [0mInference done 7062/8355. 0.1150 s / img. ETA=0:02:30
[32m[04/28 21:34:49 d2.evaluation.evaluator]: [0mInference done 7105/8355. 0.1150 s / img. ETA=0:02:25
[32m[04/28 21:34:54 d2.evaluation.evaluator]: [0mInference done 7148/8355. 0.1150 s / img. ETA=0:02:20
[32m[04/28 21:35:00 d2.evaluation.evaluator]: [0mInference done 7191/8355. 0.1151 s / img. ETA=0:02:15
[32m[04/28 21:35:05 d2.evaluation.evaluator]: [0mInference done 7234/8355. 0.1151 s / img. ETA=0:02:10
[32m[04/28 21:35:10 d2.evaluation.evaluator]: [0mInference done 7277/8355. 0.1151 s / img. ETA=0:02:05
[32m[04/28 21:35:15 d2.evaluation.evaluator]: [0mInference done 7320/8355. 0.1151 s / img. ETA=0:02:00
[32m[04/28 21:35:20 d2.evaluation.evaluator]: [0mInference done 7362/8355. 0.1151 s / img. ETA=0:01:56
[32m[04/28 21:35:25 d2.evaluation.evaluator]: [0mInference done 7405/8355. 0.1151 s / img. ETA=0:01:51
[32m[04/28 21:35:30 d2.evaluation.evaluator]: [0mInference done 7448/8355. 0.1151 s / img. ETA=0:01:45
[32m[04/28 21:35:35 d2.evaluation.evaluator]: [0mInference done 7491/8355. 0.1151 s / img. ETA=0:01:40
[32m[04/28 21:35:40 d2.evaluation.evaluator]: [0mInference done 7534/8355. 0.1151 s / img. ETA=0:01:35
[32m[04/28 21:35:45 d2.evaluation.evaluator]: [0mInference done 7577/8355. 0.1151 s / img. ETA=0:01:30
[32m[04/28 21:35:50 d2.evaluation.evaluator]: [0mInference done 7620/8355. 0.1151 s / img. ETA=0:01:25
[32m[04/28 21:35:55 d2.evaluation.evaluator]: [0mInference done 7663/8355. 0.1151 s / img. ETA=0:01:20
[32m[04/28 21:36:00 d2.evaluation.evaluator]: [0mInference done 7706/8355. 0.1151 s / img. ETA=0:01:15
[32m[04/28 21:36:05 d2.evaluation.evaluator]: [0mInference done 7749/8355. 0.1151 s / img. ETA=0:01:10
[32m[04/28 21:36:10 d2.evaluation.evaluator]: [0mInference done 7792/8355. 0.1151 s / img. ETA=0:01:05
[32m[04/28 21:36:15 d2.evaluation.evaluator]: [0mInference done 7835/8355. 0.1151 s / img. ETA=0:01:00
[32m[04/28 21:36:20 d2.evaluation.evaluator]: [0mInference done 7878/8355. 0.1151 s / img. ETA=0:00:55
[32m[04/28 21:36:25 d2.evaluation.evaluator]: [0mInference done 7921/8355. 0.1151 s / img. ETA=0:00:50
[32m[04/28 21:36:31 d2.evaluation.evaluator]: [0mInference done 7964/8355. 0.1151 s / img. ETA=0:00:45
[32m[04/28 21:36:36 d2.evaluation.evaluator]: [0mInference done 8004/8355. 0.1152 s / img. ETA=0:00:41
[32m[04/28 21:36:41 d2.evaluation.evaluator]: [0mInference done 8048/8355. 0.1152 s / img. ETA=0:00:35
[32m[04/28 21:36:46 d2.evaluation.evaluator]: [0mInference done 8092/8355. 0.1152 s / img. ETA=0:00:30
[32m[04/28 21:36:51 d2.evaluation.evaluator]: [0mInference done 8135/8355. 0.1152 s / img. ETA=0:00:25
[32m[04/28 21:36:56 d2.evaluation.evaluator]: [0mInference done 8178/8355. 0.1152 s / img. ETA=0:00:20
[32m[04/28 21:37:01 d2.evaluation.evaluator]: [0mInference done 8221/8355. 0.1152 s / img. ETA=0:00:15
[32m[04/28 21:37:06 d2.evaluation.evaluator]: [0mInference done 8264/8355. 0.1152 s / img. ETA=0:00:10
[32m[04/28 21:37:11 d2.evaluation.evaluator]: [0mInference done 8307/8355. 0.1152 s / img. ETA=0:00:05
[32m[04/28 21:37:16 d2.evaluation.evaluator]: [0mInference done 8350/8355. 0.1152 s / img. ETA=0:00:00
[32m[04/28 21:37:17 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:16.314977 (0.116924 s / img per device, on 1 devices)
[32m[04/28 21:37:17 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:01 (0.115175 s / img per device, on 1 devices)
[32m[04/28 21:37:17 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 21:37:17 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 21:37:17 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.90s).
Accumulating evaluation results...
DONE (t=2.26s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.510
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.891
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.508
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.402
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.642
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.553
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.574
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.485
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.696
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.823
[32m[04/28 21:37:40 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.033 | 89.084 | 50.804 | 40.245 | 64.224 | 78.488 |
[32m[04/28 21:37:40 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 48.240 | bicycle       | 44.309 | car            | 60.549 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 21:37:41 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 21:37:41 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 21:37:41 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 21:37:42 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1148 s / img. ETA=0:02:24
[32m[04/28 21:37:48 d2.evaluation.evaluator]: [0mInference done 55/1257. 0.1145 s / img. ETA=0:02:19
[32m[04/28 21:37:53 d2.evaluation.evaluator]: [0mInference done 98/1257. 0.1145 s / img. ETA=0:02:14
[32m[04/28 21:37:58 d2.evaluation.evaluator]: [0mInference done 141/1257. 0.1145 s / img. ETA=0:02:09
[32m[04/28 21:38:03 d2.evaluation.evaluator]: [0mInference done 184/1257. 0.1146 s / img. ETA=0:02:04
[32m[04/28 21:38:08 d2.evaluation.evaluator]: [0mInference done 227/1257. 0.1146 s / img. ETA=0:01:59
[32m[04/28 21:38:13 d2.evaluation.evaluator]: [0mInference done 270/1257. 0.1147 s / img. ETA=0:01:54
[32m[04/28 21:38:18 d2.evaluation.evaluator]: [0mInference done 313/1257. 0.1147 s / img. ETA=0:01:49
[32m[04/28 21:38:23 d2.evaluation.evaluator]: [0mInference done 356/1257. 0.1147 s / img. ETA=0:01:44
[32m[04/28 21:38:28 d2.evaluation.evaluator]: [0mInference done 399/1257. 0.1147 s / img. ETA=0:01:39
[32m[04/28 21:38:33 d2.evaluation.evaluator]: [0mInference done 442/1257. 0.1147 s / img. ETA=0:01:34
[32m[04/28 21:38:38 d2.evaluation.evaluator]: [0mInference done 485/1257. 0.1147 s / img. ETA=0:01:29
[32m[04/28 21:38:43 d2.evaluation.evaluator]: [0mInference done 528/1257. 0.1147 s / img. ETA=0:01:24
[32m[04/28 21:38:48 d2.evaluation.evaluator]: [0mInference done 571/1257. 0.1147 s / img. ETA=0:01:19
[32m[04/28 21:38:53 d2.evaluation.evaluator]: [0mInference done 614/1257. 0.1147 s / img. ETA=0:01:14
[32m[04/28 21:38:58 d2.evaluation.evaluator]: [0mInference done 657/1257. 0.1148 s / img. ETA=0:01:09
[32m[04/28 21:39:03 d2.evaluation.evaluator]: [0mInference done 700/1257. 0.1148 s / img. ETA=0:01:04
[32m[04/28 21:39:08 d2.evaluation.evaluator]: [0mInference done 743/1257. 0.1148 s / img. ETA=0:00:59
[32m[04/28 21:39:13 d2.evaluation.evaluator]: [0mInference done 786/1257. 0.1148 s / img. ETA=0:00:54
[32m[04/28 21:39:18 d2.evaluation.evaluator]: [0mInference done 829/1257. 0.1148 s / img. ETA=0:00:49
[32m[04/28 21:39:23 d2.evaluation.evaluator]: [0mInference done 872/1257. 0.1148 s / img. ETA=0:00:44
[32m[04/28 21:39:28 d2.evaluation.evaluator]: [0mInference done 915/1257. 0.1149 s / img. ETA=0:00:39
[32m[04/28 21:39:33 d2.evaluation.evaluator]: [0mInference done 958/1257. 0.1149 s / img. ETA=0:00:34
[32m[04/28 21:39:38 d2.evaluation.evaluator]: [0mInference done 1001/1257. 0.1149 s / img. ETA=0:00:29
[32m[04/28 21:39:43 d2.evaluation.evaluator]: [0mInference done 1044/1257. 0.1149 s / img. ETA=0:00:24
[32m[04/28 21:39:48 d2.evaluation.evaluator]: [0mInference done 1087/1257. 0.1149 s / img. ETA=0:00:19
[32m[04/28 21:39:53 d2.evaluation.evaluator]: [0mInference done 1130/1257. 0.1149 s / img. ETA=0:00:14
[32m[04/28 21:39:58 d2.evaluation.evaluator]: [0mInference done 1173/1257. 0.1149 s / img. ETA=0:00:09
[32m[04/28 21:40:03 d2.evaluation.evaluator]: [0mInference done 1216/1257. 0.1149 s / img. ETA=0:00:04
[32m[04/28 21:40:08 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.186576 (0.116762 s / img per device, on 1 devices)
[32m[04/28 21:40:08 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:23 (0.114936 s / img per device, on 1 devices)
[32m[04/28 21:40:08 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 21:40:08 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 21:40:08 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.15s).
Accumulating evaluation results...
DONE (t=0.38s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.735
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.314
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.260
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.431
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.179
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.439
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.497
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.681
[32m[04/28 21:40:12 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 36.830 | 73.479 | 31.387 | 26.005 | 43.139 | 60.643 |
[32m[04/28 21:40:12 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 38.182 | bicycle       | 19.586 | car            | 52.723 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  33  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 21:40:12 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 21:40:13 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 21:40:13 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 21:40:13 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 21:40:13 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 21:40:13 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 21:40:13 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 21:40:34 d2.utils.events]: [0m eta: 0:16:34  iter: 19  total_loss: 0.545  loss_cls: 0.160  loss_box_reg: 0.329  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0207  data_time: 0.0204  lr: 0.000100  max_mem: 5397M
[32m[04/28 21:40:55 d2.utils.events]: [0m eta: 0:16:54  iter: 39  total_loss: 0.506  loss_cls: 0.148  loss_box_reg: 0.296  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0394  data_time: 0.0079  lr: 0.000200  max_mem: 5397M
[32m[04/28 21:41:15 d2.utils.events]: [0m eta: 0:16:19  iter: 59  total_loss: 0.485  loss_cls: 0.138  loss_box_reg: 0.268  loss_rpn_cls: 0.006  loss_rpn_loc: 0.051  time: 1.0252  data_time: 0.0078  lr: 0.000300  max_mem: 5397M
[32m[04/28 21:41:36 d2.utils.events]: [0m eta: 0:15:58  iter: 79  total_loss: 0.421  loss_cls: 0.126  loss_box_reg: 0.247  loss_rpn_cls: 0.005  loss_rpn_loc: 0.036  time: 1.0283  data_time: 0.0078  lr: 0.000400  max_mem: 5397M
[32m[04/28 21:41:56 d2.utils.events]: [0m eta: 0:15:39  iter: 99  total_loss: 0.407  loss_cls: 0.123  loss_box_reg: 0.254  loss_rpn_cls: 0.005  loss_rpn_loc: 0.033  time: 1.0275  data_time: 0.0076  lr: 0.000500  max_mem: 5397M
[32m[04/28 21:42:17 d2.utils.events]: [0m eta: 0:15:21  iter: 119  total_loss: 0.461  loss_cls: 0.131  loss_box_reg: 0.280  loss_rpn_cls: 0.005  loss_rpn_loc: 0.045  time: 1.0304  data_time: 0.0077  lr: 0.000599  max_mem: 5397M
[32m[04/28 21:42:38 d2.utils.events]: [0m eta: 0:15:01  iter: 139  total_loss: 0.470  loss_cls: 0.143  loss_box_reg: 0.270  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0329  data_time: 0.0076  lr: 0.000699  max_mem: 5397M
[32m[04/28 21:42:59 d2.utils.events]: [0m eta: 0:14:44  iter: 159  total_loss: 0.504  loss_cls: 0.150  loss_box_reg: 0.295  loss_rpn_cls: 0.005  loss_rpn_loc: 0.049  time: 1.0345  data_time: 0.0076  lr: 0.000799  max_mem: 5397M
[32m[04/28 21:43:20 d2.utils.events]: [0m eta: 0:14:23  iter: 179  total_loss: 0.471  loss_cls: 0.142  loss_box_reg: 0.273  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 1.0343  data_time: 0.0076  lr: 0.000899  max_mem: 5397M
[32m[04/28 21:43:41 d2.utils.events]: [0m eta: 0:14:02  iter: 199  total_loss: 0.442  loss_cls: 0.130  loss_box_reg: 0.269  loss_rpn_cls: 0.003  loss_rpn_loc: 0.036  time: 1.0348  data_time: 0.0076  lr: 0.000999  max_mem: 5397M
[32m[04/28 21:44:02 d2.utils.events]: [0m eta: 0:13:42  iter: 219  total_loss: 0.457  loss_cls: 0.136  loss_box_reg: 0.268  loss_rpn_cls: 0.005  loss_rpn_loc: 0.046  time: 1.0374  data_time: 0.0077  lr: 0.001099  max_mem: 5397M
[32m[04/28 21:44:23 d2.utils.events]: [0m eta: 0:13:21  iter: 239  total_loss: 0.460  loss_cls: 0.133  loss_box_reg: 0.273  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0375  data_time: 0.0076  lr: 0.001199  max_mem: 5397M
[32m[04/28 21:44:43 d2.utils.events]: [0m eta: 0:12:58  iter: 259  total_loss: 0.427  loss_cls: 0.116  loss_box_reg: 0.253  loss_rpn_cls: 0.005  loss_rpn_loc: 0.045  time: 1.0365  data_time: 0.0077  lr: 0.001299  max_mem: 5397M
[32m[04/28 21:45:04 d2.utils.events]: [0m eta: 0:12:38  iter: 279  total_loss: 0.434  loss_cls: 0.128  loss_box_reg: 0.262  loss_rpn_cls: 0.003  loss_rpn_loc: 0.042  time: 1.0368  data_time: 0.0078  lr: 0.001399  max_mem: 5397M
[32m[04/28 21:45:25 d2.utils.events]: [0m eta: 0:12:17  iter: 299  total_loss: 0.475  loss_cls: 0.136  loss_box_reg: 0.291  loss_rpn_cls: 0.004  loss_rpn_loc: 0.037  time: 1.0368  data_time: 0.0077  lr: 0.001499  max_mem: 5397M
[32m[04/28 21:45:45 d2.utils.events]: [0m eta: 0:11:54  iter: 319  total_loss: 0.500  loss_cls: 0.146  loss_box_reg: 0.286  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0348  data_time: 0.0077  lr: 0.001598  max_mem: 5397M
[32m[04/28 21:46:06 d2.utils.events]: [0m eta: 0:11:32  iter: 339  total_loss: 0.453  loss_cls: 0.133  loss_box_reg: 0.277  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0345  data_time: 0.0078  lr: 0.001698  max_mem: 5397M
[32m[04/28 21:46:26 d2.utils.events]: [0m eta: 0:11:10  iter: 359  total_loss: 0.438  loss_cls: 0.120  loss_box_reg: 0.253  loss_rpn_cls: 0.005  loss_rpn_loc: 0.037  time: 1.0336  data_time: 0.0078  lr: 0.001798  max_mem: 5397M
[32m[04/28 21:46:47 d2.utils.events]: [0m eta: 0:10:50  iter: 379  total_loss: 0.467  loss_cls: 0.142  loss_box_reg: 0.281  loss_rpn_cls: 0.004  loss_rpn_loc: 0.046  time: 1.0340  data_time: 0.0078  lr: 0.001898  max_mem: 5397M
[32m[04/28 21:47:08 d2.utils.events]: [0m eta: 0:10:28  iter: 399  total_loss: 0.446  loss_cls: 0.140  loss_box_reg: 0.269  loss_rpn_cls: 0.004  loss_rpn_loc: 0.040  time: 1.0334  data_time: 0.0080  lr: 0.001998  max_mem: 5397M
[32m[04/28 21:47:28 d2.utils.events]: [0m eta: 0:10:07  iter: 419  total_loss: 0.532  loss_cls: 0.149  loss_box_reg: 0.300  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0321  data_time: 0.0077  lr: 0.002098  max_mem: 5397M
[32m[04/28 21:47:48 d2.utils.events]: [0m eta: 0:09:45  iter: 439  total_loss: 0.432  loss_cls: 0.127  loss_box_reg: 0.261  loss_rpn_cls: 0.004  loss_rpn_loc: 0.040  time: 1.0309  data_time: 0.0075  lr: 0.002198  max_mem: 5397M
[32m[04/28 21:48:08 d2.utils.events]: [0m eta: 0:09:22  iter: 459  total_loss: 0.474  loss_cls: 0.136  loss_box_reg: 0.277  loss_rpn_cls: 0.005  loss_rpn_loc: 0.052  time: 1.0287  data_time: 0.0075  lr: 0.002298  max_mem: 5397M
[32m[04/28 21:48:29 d2.utils.events]: [0m eta: 0:09:02  iter: 479  total_loss: 0.474  loss_cls: 0.142  loss_box_reg: 0.275  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 1.0293  data_time: 0.0077  lr: 0.002398  max_mem: 5397M
[32m[04/28 21:48:49 d2.utils.events]: [0m eta: 0:08:41  iter: 499  total_loss: 0.497  loss_cls: 0.144  loss_box_reg: 0.279  loss_rpn_cls: 0.008  loss_rpn_loc: 0.045  time: 1.0296  data_time: 0.0077  lr: 0.002498  max_mem: 5397M
[32m[04/28 21:49:09 d2.utils.events]: [0m eta: 0:08:19  iter: 519  total_loss: 0.445  loss_cls: 0.136  loss_box_reg: 0.263  loss_rpn_cls: 0.003  loss_rpn_loc: 0.045  time: 1.0284  data_time: 0.0078  lr: 0.002597  max_mem: 5397M
[32m[04/28 21:49:29 d2.utils.events]: [0m eta: 0:07:57  iter: 539  total_loss: 0.435  loss_cls: 0.131  loss_box_reg: 0.261  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0271  data_time: 0.0078  lr: 0.002697  max_mem: 5397M
[32m[04/28 21:49:50 d2.utils.events]: [0m eta: 0:07:36  iter: 559  total_loss: 0.466  loss_cls: 0.134  loss_box_reg: 0.290  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0267  data_time: 0.0075  lr: 0.002797  max_mem: 5397M
[32m[04/28 21:50:11 d2.utils.events]: [0m eta: 0:07:17  iter: 579  total_loss: 0.465  loss_cls: 0.137  loss_box_reg: 0.270  loss_rpn_cls: 0.003  loss_rpn_loc: 0.049  time: 1.0278  data_time: 0.0077  lr: 0.002897  max_mem: 5397M
[32m[04/28 21:50:32 d2.utils.events]: [0m eta: 0:06:56  iter: 599  total_loss: 0.461  loss_cls: 0.136  loss_box_reg: 0.262  loss_rpn_cls: 0.007  loss_rpn_loc: 0.038  time: 1.0287  data_time: 0.0077  lr: 0.002997  max_mem: 5397M
[32m[04/28 21:50:53 d2.utils.events]: [0m eta: 0:06:36  iter: 619  total_loss: 0.436  loss_cls: 0.142  loss_box_reg: 0.267  loss_rpn_cls: 0.005  loss_rpn_loc: 0.039  time: 1.0294  data_time: 0.0077  lr: 0.003097  max_mem: 5397M
[32m[04/28 21:51:14 d2.utils.events]: [0m eta: 0:06:16  iter: 639  total_loss: 0.469  loss_cls: 0.133  loss_box_reg: 0.293  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0292  data_time: 0.0076  lr: 0.003197  max_mem: 5397M
[32m[04/28 21:51:34 d2.utils.events]: [0m eta: 0:05:54  iter: 659  total_loss: 0.407  loss_cls: 0.127  loss_box_reg: 0.247  loss_rpn_cls: 0.004  loss_rpn_loc: 0.042  time: 1.0288  data_time: 0.0077  lr: 0.003297  max_mem: 5397M
[32m[04/28 21:51:55 d2.utils.events]: [0m eta: 0:05:33  iter: 679  total_loss: 0.439  loss_cls: 0.137  loss_box_reg: 0.258  loss_rpn_cls: 0.003  loss_rpn_loc: 0.042  time: 1.0290  data_time: 0.0077  lr: 0.003397  max_mem: 5397M
[32m[04/28 21:52:16 d2.utils.events]: [0m eta: 0:05:13  iter: 699  total_loss: 0.487  loss_cls: 0.150  loss_box_reg: 0.274  loss_rpn_cls: 0.006  loss_rpn_loc: 0.047  time: 1.0295  data_time: 0.0077  lr: 0.003497  max_mem: 5397M
[32m[04/28 21:52:36 d2.utils.events]: [0m eta: 0:04:52  iter: 719  total_loss: 0.435  loss_cls: 0.122  loss_box_reg: 0.251  loss_rpn_cls: 0.005  loss_rpn_loc: 0.045  time: 1.0292  data_time: 0.0076  lr: 0.003596  max_mem: 5397M
[32m[04/28 21:52:57 d2.utils.events]: [0m eta: 0:04:31  iter: 739  total_loss: 0.432  loss_cls: 0.134  loss_box_reg: 0.258  loss_rpn_cls: 0.005  loss_rpn_loc: 0.042  time: 1.0291  data_time: 0.0076  lr: 0.003696  max_mem: 5397M
[32m[04/28 21:53:17 d2.utils.events]: [0m eta: 0:04:10  iter: 759  total_loss: 0.440  loss_cls: 0.130  loss_box_reg: 0.266  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0284  data_time: 0.0076  lr: 0.003796  max_mem: 5397M
[32m[04/28 21:53:37 d2.utils.events]: [0m eta: 0:03:49  iter: 779  total_loss: 0.467  loss_cls: 0.131  loss_box_reg: 0.259  loss_rpn_cls: 0.006  loss_rpn_loc: 0.050  time: 1.0280  data_time: 0.0076  lr: 0.003896  max_mem: 5397M
[32m[04/28 21:53:57 d2.utils.events]: [0m eta: 0:03:28  iter: 799  total_loss: 0.487  loss_cls: 0.157  loss_box_reg: 0.292  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0278  data_time: 0.0075  lr: 0.003996  max_mem: 5397M
[32m[04/28 21:54:18 d2.utils.events]: [0m eta: 0:03:08  iter: 819  total_loss: 0.457  loss_cls: 0.126  loss_box_reg: 0.272  loss_rpn_cls: 0.006  loss_rpn_loc: 0.048  time: 1.0283  data_time: 0.0078  lr: 0.004096  max_mem: 5397M
[32m[04/28 21:54:40 d2.utils.events]: [0m eta: 0:02:47  iter: 839  total_loss: 0.485  loss_cls: 0.157  loss_box_reg: 0.280  loss_rpn_cls: 0.005  loss_rpn_loc: 0.046  time: 1.0289  data_time: 0.0078  lr: 0.004196  max_mem: 5397M
[32m[04/28 21:55:00 d2.utils.events]: [0m eta: 0:02:26  iter: 859  total_loss: 0.440  loss_cls: 0.142  loss_box_reg: 0.263  loss_rpn_cls: 0.005  loss_rpn_loc: 0.042  time: 1.0291  data_time: 0.0076  lr: 0.004296  max_mem: 5397M
[32m[04/28 21:55:21 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.447  loss_cls: 0.133  loss_box_reg: 0.267  loss_rpn_cls: 0.003  loss_rpn_loc: 0.035  time: 1.0292  data_time: 0.0076  lr: 0.004396  max_mem: 5397M
[32m[04/28 21:55:41 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.549  loss_cls: 0.154  loss_box_reg: 0.314  loss_rpn_cls: 0.004  loss_rpn_loc: 0.054  time: 1.0287  data_time: 0.0077  lr: 0.004496  max_mem: 5397M
[32m[04/28 21:56:02 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.481  loss_cls: 0.141  loss_box_reg: 0.280  loss_rpn_cls: 0.007  loss_rpn_loc: 0.039  time: 1.0284  data_time: 0.0078  lr: 0.004595  max_mem: 5397M
[32m[04/28 21:56:22 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.530  loss_cls: 0.172  loss_box_reg: 0.296  loss_rpn_cls: 0.004  loss_rpn_loc: 0.050  time: 1.0280  data_time: 0.0079  lr: 0.004695  max_mem: 5397M
[32m[04/28 21:56:42 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.476  loss_cls: 0.138  loss_box_reg: 0.282  loss_rpn_cls: 0.006  loss_rpn_loc: 0.053  time: 1.0274  data_time: 0.0078  lr: 0.004795  max_mem: 5397M
[32m[04/28 21:57:03 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.474  loss_cls: 0.137  loss_box_reg: 0.286  loss_rpn_cls: 0.004  loss_rpn_loc: 0.046  time: 1.0280  data_time: 0.0079  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 21:57:26 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 21:57:26 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 21:57:26 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 21:57:26 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.456  loss_cls: 0.133  loss_box_reg: 0.262  loss_rpn_cls: 0.004  loss_rpn_loc: 0.045  time: 1.0279  data_time: 0.0078  lr: 0.004995  max_mem: 5397M
[32m[04/28 21:57:27 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:05 (1.0290 s / it)
[32m[04/28 21:57:27 d2.engine.hooks]: [0mTotal training time: 0:17:11 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 21:57:28 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 21:57:28 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 21:57:28 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 21:57:30 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1142 s / img. ETA=0:16:04
[32m[04/28 21:57:35 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1145 s / img. ETA=0:16:03
[32m[04/28 21:57:40 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1144 s / img. ETA=0:15:58
[32m[04/28 21:57:45 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1144 s / img. ETA=0:15:52
[32m[04/28 21:57:50 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1144 s / img. ETA=0:15:47
[32m[04/28 21:57:55 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1144 s / img. ETA=0:15:42
[32m[04/28 21:58:00 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1144 s / img. ETA=0:15:37
[32m[04/28 21:58:05 d2.evaluation.evaluator]: [0mInference done 318/8355. 0.1144 s / img. ETA=0:15:33
[32m[04/28 21:58:10 d2.evaluation.evaluator]: [0mInference done 361/8355. 0.1145 s / img. ETA=0:15:28
[32m[04/28 21:58:15 d2.evaluation.evaluator]: [0mInference done 404/8355. 0.1145 s / img. ETA=0:15:23
[32m[04/28 21:58:20 d2.evaluation.evaluator]: [0mInference done 447/8355. 0.1146 s / img. ETA=0:15:19
[32m[04/28 21:58:26 d2.evaluation.evaluator]: [0mInference done 491/8355. 0.1145 s / img. ETA=0:15:13
[32m[04/28 21:58:31 d2.evaluation.evaluator]: [0mInference done 535/8355. 0.1145 s / img. ETA=0:15:08
[32m[04/28 21:58:36 d2.evaluation.evaluator]: [0mInference done 579/8355. 0.1145 s / img. ETA=0:15:03
[32m[04/28 21:58:41 d2.evaluation.evaluator]: [0mInference done 623/8355. 0.1145 s / img. ETA=0:14:58
[32m[04/28 21:58:46 d2.evaluation.evaluator]: [0mInference done 666/8355. 0.1145 s / img. ETA=0:14:53
[32m[04/28 21:58:51 d2.evaluation.evaluator]: [0mInference done 709/8355. 0.1145 s / img. ETA=0:14:48
[32m[04/28 21:58:56 d2.evaluation.evaluator]: [0mInference done 752/8355. 0.1146 s / img. ETA=0:14:44
[32m[04/28 21:59:01 d2.evaluation.evaluator]: [0mInference done 795/8355. 0.1146 s / img. ETA=0:14:39
[32m[04/28 21:59:06 d2.evaluation.evaluator]: [0mInference done 838/8355. 0.1146 s / img. ETA=0:14:34
[32m[04/28 21:59:11 d2.evaluation.evaluator]: [0mInference done 881/8355. 0.1147 s / img. ETA=0:14:29
[32m[04/28 21:59:16 d2.evaluation.evaluator]: [0mInference done 924/8355. 0.1147 s / img. ETA=0:14:24
[32m[04/28 21:59:21 d2.evaluation.evaluator]: [0mInference done 967/8355. 0.1147 s / img. ETA=0:14:19
[32m[04/28 21:59:26 d2.evaluation.evaluator]: [0mInference done 1010/8355. 0.1147 s / img. ETA=0:14:14
[32m[04/28 21:59:31 d2.evaluation.evaluator]: [0mInference done 1053/8355. 0.1147 s / img. ETA=0:14:09
[32m[04/28 21:59:36 d2.evaluation.evaluator]: [0mInference done 1097/8355. 0.1147 s / img. ETA=0:14:04
[32m[04/28 21:59:41 d2.evaluation.evaluator]: [0mInference done 1141/8355. 0.1147 s / img. ETA=0:13:59
[32m[04/28 21:59:46 d2.evaluation.evaluator]: [0mInference done 1185/8355. 0.1147 s / img. ETA=0:13:54
[32m[04/28 21:59:51 d2.evaluation.evaluator]: [0mInference done 1229/8355. 0.1147 s / img. ETA=0:13:48
[32m[04/28 21:59:57 d2.evaluation.evaluator]: [0mInference done 1273/8355. 0.1146 s / img. ETA=0:13:43
[32m[04/28 22:00:02 d2.evaluation.evaluator]: [0mInference done 1317/8355. 0.1146 s / img. ETA=0:13:38
[32m[04/28 22:00:07 d2.evaluation.evaluator]: [0mInference done 1360/8355. 0.1146 s / img. ETA=0:13:33
[32m[04/28 22:00:12 d2.evaluation.evaluator]: [0mInference done 1403/8355. 0.1147 s / img. ETA=0:13:28
[32m[04/28 22:00:17 d2.evaluation.evaluator]: [0mInference done 1446/8355. 0.1147 s / img. ETA=0:13:23
[32m[04/28 22:00:22 d2.evaluation.evaluator]: [0mInference done 1489/8355. 0.1147 s / img. ETA=0:13:18
[32m[04/28 22:00:27 d2.evaluation.evaluator]: [0mInference done 1532/8355. 0.1147 s / img. ETA=0:13:14
[32m[04/28 22:00:32 d2.evaluation.evaluator]: [0mInference done 1574/8355. 0.1148 s / img. ETA=0:13:09
[32m[04/28 22:00:37 d2.evaluation.evaluator]: [0mInference done 1617/8355. 0.1148 s / img. ETA=0:13:04
[32m[04/28 22:00:42 d2.evaluation.evaluator]: [0mInference done 1660/8355. 0.1149 s / img. ETA=0:13:00
[32m[04/28 22:00:47 d2.evaluation.evaluator]: [0mInference done 1703/8355. 0.1149 s / img. ETA=0:12:55
[32m[04/28 22:00:52 d2.evaluation.evaluator]: [0mInference done 1746/8355. 0.1149 s / img. ETA=0:12:50
[32m[04/28 22:00:57 d2.evaluation.evaluator]: [0mInference done 1789/8355. 0.1149 s / img. ETA=0:12:45
[32m[04/28 22:01:02 d2.evaluation.evaluator]: [0mInference done 1832/8355. 0.1150 s / img. ETA=0:12:40
[32m[04/28 22:01:07 d2.evaluation.evaluator]: [0mInference done 1875/8355. 0.1150 s / img. ETA=0:12:36
[32m[04/28 22:01:12 d2.evaluation.evaluator]: [0mInference done 1918/8355. 0.1150 s / img. ETA=0:12:31
[32m[04/28 22:01:17 d2.evaluation.evaluator]: [0mInference done 1961/8355. 0.1150 s / img. ETA=0:12:26
[32m[04/28 22:01:22 d2.evaluation.evaluator]: [0mInference done 2004/8355. 0.1150 s / img. ETA=0:12:21
[32m[04/28 22:01:27 d2.evaluation.evaluator]: [0mInference done 2047/8355. 0.1150 s / img. ETA=0:12:16
[32m[04/28 22:01:32 d2.evaluation.evaluator]: [0mInference done 2090/8355. 0.1150 s / img. ETA=0:12:11
[32m[04/28 22:01:38 d2.evaluation.evaluator]: [0mInference done 2133/8355. 0.1151 s / img. ETA=0:12:06
[32m[04/28 22:01:43 d2.evaluation.evaluator]: [0mInference done 2176/8355. 0.1151 s / img. ETA=0:12:01
[32m[04/28 22:01:48 d2.evaluation.evaluator]: [0mInference done 2219/8355. 0.1151 s / img. ETA=0:11:56
[32m[04/28 22:01:53 d2.evaluation.evaluator]: [0mInference done 2262/8355. 0.1151 s / img. ETA=0:11:51
[32m[04/28 22:01:58 d2.evaluation.evaluator]: [0mInference done 2305/8355. 0.1152 s / img. ETA=0:11:46
[32m[04/28 22:02:03 d2.evaluation.evaluator]: [0mInference done 2348/8355. 0.1152 s / img. ETA=0:11:41
[32m[04/28 22:02:08 d2.evaluation.evaluator]: [0mInference done 2391/8355. 0.1152 s / img. ETA=0:11:36
[32m[04/28 22:02:13 d2.evaluation.evaluator]: [0mInference done 2434/8355. 0.1152 s / img. ETA=0:11:31
[32m[04/28 22:02:18 d2.evaluation.evaluator]: [0mInference done 2476/8355. 0.1152 s / img. ETA=0:11:27
[32m[04/28 22:02:23 d2.evaluation.evaluator]: [0mInference done 2519/8355. 0.1152 s / img. ETA=0:11:22
[32m[04/28 22:02:28 d2.evaluation.evaluator]: [0mInference done 2562/8355. 0.1152 s / img. ETA=0:11:17
[32m[04/28 22:02:33 d2.evaluation.evaluator]: [0mInference done 2605/8355. 0.1152 s / img. ETA=0:11:12
[32m[04/28 22:02:38 d2.evaluation.evaluator]: [0mInference done 2648/8355. 0.1152 s / img. ETA=0:11:07
[32m[04/28 22:02:43 d2.evaluation.evaluator]: [0mInference done 2691/8355. 0.1152 s / img. ETA=0:11:02
[32m[04/28 22:02:48 d2.evaluation.evaluator]: [0mInference done 2734/8355. 0.1153 s / img. ETA=0:10:57
[32m[04/28 22:02:53 d2.evaluation.evaluator]: [0mInference done 2777/8355. 0.1153 s / img. ETA=0:10:52
[32m[04/28 22:02:58 d2.evaluation.evaluator]: [0mInference done 2820/8355. 0.1153 s / img. ETA=0:10:47
[32m[04/28 22:03:03 d2.evaluation.evaluator]: [0mInference done 2863/8355. 0.1153 s / img. ETA=0:10:42
[32m[04/28 22:03:09 d2.evaluation.evaluator]: [0mInference done 2906/8355. 0.1153 s / img. ETA=0:10:37
[32m[04/28 22:03:14 d2.evaluation.evaluator]: [0mInference done 2948/8355. 0.1154 s / img. ETA=0:10:32
[32m[04/28 22:03:19 d2.evaluation.evaluator]: [0mInference done 2991/8355. 0.1154 s / img. ETA=0:10:27
[32m[04/28 22:03:24 d2.evaluation.evaluator]: [0mInference done 3034/8355. 0.1154 s / img. ETA=0:10:22
[32m[04/28 22:03:29 d2.evaluation.evaluator]: [0mInference done 3077/8355. 0.1154 s / img. ETA=0:10:17
[32m[04/28 22:03:34 d2.evaluation.evaluator]: [0mInference done 3120/8355. 0.1154 s / img. ETA=0:10:12
[32m[04/28 22:03:39 d2.evaluation.evaluator]: [0mInference done 3163/8355. 0.1154 s / img. ETA=0:10:07
[32m[04/28 22:03:44 d2.evaluation.evaluator]: [0mInference done 3207/8355. 0.1154 s / img. ETA=0:10:02
[32m[04/28 22:03:49 d2.evaluation.evaluator]: [0mInference done 3250/8355. 0.1154 s / img. ETA=0:09:57
[32m[04/28 22:03:54 d2.evaluation.evaluator]: [0mInference done 3293/8355. 0.1154 s / img. ETA=0:09:52
[32m[04/28 22:03:59 d2.evaluation.evaluator]: [0mInference done 3336/8355. 0.1154 s / img. ETA=0:09:47
[32m[04/28 22:04:04 d2.evaluation.evaluator]: [0mInference done 3380/8355. 0.1154 s / img. ETA=0:09:42
[32m[04/28 22:04:09 d2.evaluation.evaluator]: [0mInference done 3423/8355. 0.1154 s / img. ETA=0:09:37
[32m[04/28 22:04:14 d2.evaluation.evaluator]: [0mInference done 3466/8355. 0.1154 s / img. ETA=0:09:32
[32m[04/28 22:04:19 d2.evaluation.evaluator]: [0mInference done 3509/8355. 0.1154 s / img. ETA=0:09:27
[32m[04/28 22:04:24 d2.evaluation.evaluator]: [0mInference done 3552/8355. 0.1153 s / img. ETA=0:09:22
[32m[04/28 22:04:29 d2.evaluation.evaluator]: [0mInference done 3595/8355. 0.1154 s / img. ETA=0:09:17
[32m[04/28 22:04:34 d2.evaluation.evaluator]: [0mInference done 3637/8355. 0.1154 s / img. ETA=0:09:12
[32m[04/28 22:04:39 d2.evaluation.evaluator]: [0mInference done 3680/8355. 0.1154 s / img. ETA=0:09:07
[32m[04/28 22:04:44 d2.evaluation.evaluator]: [0mInference done 3723/8355. 0.1154 s / img. ETA=0:09:02
[32m[04/28 22:04:49 d2.evaluation.evaluator]: [0mInference done 3766/8355. 0.1154 s / img. ETA=0:08:57
[32m[04/28 22:04:54 d2.evaluation.evaluator]: [0mInference done 3809/8355. 0.1154 s / img. ETA=0:08:52
[32m[04/28 22:04:59 d2.evaluation.evaluator]: [0mInference done 3852/8355. 0.1154 s / img. ETA=0:08:47
[32m[04/28 22:05:04 d2.evaluation.evaluator]: [0mInference done 3895/8355. 0.1154 s / img. ETA=0:08:42
[32m[04/28 22:05:10 d2.evaluation.evaluator]: [0mInference done 3938/8355. 0.1154 s / img. ETA=0:08:37
[32m[04/28 22:05:15 d2.evaluation.evaluator]: [0mInference done 3981/8355. 0.1154 s / img. ETA=0:08:32
[32m[04/28 22:05:20 d2.evaluation.evaluator]: [0mInference done 4024/8355. 0.1154 s / img. ETA=0:08:27
[32m[04/28 22:05:25 d2.evaluation.evaluator]: [0mInference done 4067/8355. 0.1154 s / img. ETA=0:08:22
[32m[04/28 22:05:30 d2.evaluation.evaluator]: [0mInference done 4110/8355. 0.1154 s / img. ETA=0:08:17
[32m[04/28 22:05:35 d2.evaluation.evaluator]: [0mInference done 4153/8355. 0.1154 s / img. ETA=0:08:12
[32m[04/28 22:05:40 d2.evaluation.evaluator]: [0mInference done 4196/8355. 0.1154 s / img. ETA=0:08:07
[32m[04/28 22:05:45 d2.evaluation.evaluator]: [0mInference done 4240/8355. 0.1154 s / img. ETA=0:08:01
[32m[04/28 22:05:50 d2.evaluation.evaluator]: [0mInference done 4283/8355. 0.1154 s / img. ETA=0:07:56
[32m[04/28 22:05:55 d2.evaluation.evaluator]: [0mInference done 4326/8355. 0.1154 s / img. ETA=0:07:51
[32m[04/28 22:06:00 d2.evaluation.evaluator]: [0mInference done 4369/8355. 0.1154 s / img. ETA=0:07:46
[32m[04/28 22:06:05 d2.evaluation.evaluator]: [0mInference done 4412/8355. 0.1154 s / img. ETA=0:07:41
[32m[04/28 22:06:10 d2.evaluation.evaluator]: [0mInference done 4455/8355. 0.1154 s / img. ETA=0:07:36
[32m[04/28 22:06:15 d2.evaluation.evaluator]: [0mInference done 4498/8355. 0.1154 s / img. ETA=0:07:31
[32m[04/28 22:06:20 d2.evaluation.evaluator]: [0mInference done 4541/8355. 0.1154 s / img. ETA=0:07:26
[32m[04/28 22:06:25 d2.evaluation.evaluator]: [0mInference done 4584/8355. 0.1154 s / img. ETA=0:07:21
[32m[04/28 22:06:31 d2.evaluation.evaluator]: [0mInference done 4627/8355. 0.1154 s / img. ETA=0:07:16
[32m[04/28 22:06:36 d2.evaluation.evaluator]: [0mInference done 4670/8355. 0.1154 s / img. ETA=0:07:11
[32m[04/28 22:06:41 d2.evaluation.evaluator]: [0mInference done 4712/8355. 0.1154 s / img. ETA=0:07:06
[32m[04/28 22:06:46 d2.evaluation.evaluator]: [0mInference done 4755/8355. 0.1154 s / img. ETA=0:07:01
[32m[04/28 22:06:51 d2.evaluation.evaluator]: [0mInference done 4798/8355. 0.1154 s / img. ETA=0:06:56
[32m[04/28 22:06:56 d2.evaluation.evaluator]: [0mInference done 4841/8355. 0.1154 s / img. ETA=0:06:51
[32m[04/28 22:07:01 d2.evaluation.evaluator]: [0mInference done 4884/8355. 0.1154 s / img. ETA=0:06:46
[32m[04/28 22:07:06 d2.evaluation.evaluator]: [0mInference done 4927/8355. 0.1154 s / img. ETA=0:06:41
[32m[04/28 22:07:11 d2.evaluation.evaluator]: [0mInference done 4970/8355. 0.1154 s / img. ETA=0:06:36
[32m[04/28 22:07:16 d2.evaluation.evaluator]: [0mInference done 5013/8355. 0.1154 s / img. ETA=0:06:31
[32m[04/28 22:07:21 d2.evaluation.evaluator]: [0mInference done 5056/8355. 0.1154 s / img. ETA=0:06:26
[32m[04/28 22:07:26 d2.evaluation.evaluator]: [0mInference done 5099/8355. 0.1154 s / img. ETA=0:06:21
[32m[04/28 22:07:31 d2.evaluation.evaluator]: [0mInference done 5142/8355. 0.1155 s / img. ETA=0:06:16
[32m[04/28 22:07:36 d2.evaluation.evaluator]: [0mInference done 5185/8355. 0.1155 s / img. ETA=0:06:11
[32m[04/28 22:07:41 d2.evaluation.evaluator]: [0mInference done 5228/8355. 0.1155 s / img. ETA=0:06:06
[32m[04/28 22:07:46 d2.evaluation.evaluator]: [0mInference done 5271/8355. 0.1155 s / img. ETA=0:06:01
[32m[04/28 22:07:51 d2.evaluation.evaluator]: [0mInference done 5314/8355. 0.1155 s / img. ETA=0:05:56
[32m[04/28 22:07:56 d2.evaluation.evaluator]: [0mInference done 5356/8355. 0.1155 s / img. ETA=0:05:51
[32m[04/28 22:08:01 d2.evaluation.evaluator]: [0mInference done 5399/8355. 0.1155 s / img. ETA=0:05:46
[32m[04/28 22:08:06 d2.evaluation.evaluator]: [0mInference done 5442/8355. 0.1155 s / img. ETA=0:05:41
[32m[04/28 22:08:11 d2.evaluation.evaluator]: [0mInference done 5485/8355. 0.1155 s / img. ETA=0:05:36
[32m[04/28 22:08:16 d2.evaluation.evaluator]: [0mInference done 5528/8355. 0.1155 s / img. ETA=0:05:31
[32m[04/28 22:08:21 d2.evaluation.evaluator]: [0mInference done 5571/8355. 0.1155 s / img. ETA=0:05:26
[32m[04/28 22:08:27 d2.evaluation.evaluator]: [0mInference done 5614/8355. 0.1155 s / img. ETA=0:05:21
[32m[04/28 22:08:32 d2.evaluation.evaluator]: [0mInference done 5657/8355. 0.1155 s / img. ETA=0:05:16
[32m[04/28 22:08:37 d2.evaluation.evaluator]: [0mInference done 5700/8355. 0.1155 s / img. ETA=0:05:11
[32m[04/28 22:08:42 d2.evaluation.evaluator]: [0mInference done 5743/8355. 0.1155 s / img. ETA=0:05:06
[32m[04/28 22:08:47 d2.evaluation.evaluator]: [0mInference done 5786/8355. 0.1155 s / img. ETA=0:05:01
[32m[04/28 22:08:52 d2.evaluation.evaluator]: [0mInference done 5829/8355. 0.1155 s / img. ETA=0:04:56
[32m[04/28 22:08:57 d2.evaluation.evaluator]: [0mInference done 5872/8355. 0.1155 s / img. ETA=0:04:51
[32m[04/28 22:09:02 d2.evaluation.evaluator]: [0mInference done 5915/8355. 0.1155 s / img. ETA=0:04:46
[32m[04/28 22:09:07 d2.evaluation.evaluator]: [0mInference done 5958/8355. 0.1155 s / img. ETA=0:04:41
[32m[04/28 22:09:12 d2.evaluation.evaluator]: [0mInference done 6001/8355. 0.1155 s / img. ETA=0:04:36
[32m[04/28 22:09:17 d2.evaluation.evaluator]: [0mInference done 6043/8355. 0.1155 s / img. ETA=0:04:31
[32m[04/28 22:09:22 d2.evaluation.evaluator]: [0mInference done 6086/8355. 0.1155 s / img. ETA=0:04:26
[32m[04/28 22:09:27 d2.evaluation.evaluator]: [0mInference done 6129/8355. 0.1155 s / img. ETA=0:04:21
[32m[04/28 22:09:32 d2.evaluation.evaluator]: [0mInference done 6172/8355. 0.1155 s / img. ETA=0:04:16
[32m[04/28 22:09:37 d2.evaluation.evaluator]: [0mInference done 6215/8355. 0.1156 s / img. ETA=0:04:10
[32m[04/28 22:09:43 d2.evaluation.evaluator]: [0mInference done 6258/8355. 0.1156 s / img. ETA=0:04:05
[32m[04/28 22:09:48 d2.evaluation.evaluator]: [0mInference done 6301/8355. 0.1156 s / img. ETA=0:04:00
[32m[04/28 22:09:53 d2.evaluation.evaluator]: [0mInference done 6344/8355. 0.1156 s / img. ETA=0:03:55
[32m[04/28 22:09:58 d2.evaluation.evaluator]: [0mInference done 6386/8355. 0.1156 s / img. ETA=0:03:51
[32m[04/28 22:10:03 d2.evaluation.evaluator]: [0mInference done 6429/8355. 0.1156 s / img. ETA=0:03:45
[32m[04/28 22:10:08 d2.evaluation.evaluator]: [0mInference done 6472/8355. 0.1156 s / img. ETA=0:03:40
[32m[04/28 22:10:13 d2.evaluation.evaluator]: [0mInference done 6515/8355. 0.1156 s / img. ETA=0:03:35
[32m[04/28 22:10:18 d2.evaluation.evaluator]: [0mInference done 6558/8355. 0.1156 s / img. ETA=0:03:30
[32m[04/28 22:10:23 d2.evaluation.evaluator]: [0mInference done 6601/8355. 0.1156 s / img. ETA=0:03:25
[32m[04/28 22:10:28 d2.evaluation.evaluator]: [0mInference done 6644/8355. 0.1156 s / img. ETA=0:03:20
[32m[04/28 22:10:33 d2.evaluation.evaluator]: [0mInference done 6687/8355. 0.1156 s / img. ETA=0:03:15
[32m[04/28 22:10:38 d2.evaluation.evaluator]: [0mInference done 6730/8355. 0.1156 s / img. ETA=0:03:10
[32m[04/28 22:10:43 d2.evaluation.evaluator]: [0mInference done 6774/8355. 0.1156 s / img. ETA=0:03:05
[32m[04/28 22:10:48 d2.evaluation.evaluator]: [0mInference done 6817/8355. 0.1156 s / img. ETA=0:03:00
[32m[04/28 22:10:53 d2.evaluation.evaluator]: [0mInference done 6860/8355. 0.1156 s / img. ETA=0:02:55
[32m[04/28 22:10:58 d2.evaluation.evaluator]: [0mInference done 6903/8355. 0.1156 s / img. ETA=0:02:50
[32m[04/28 22:11:03 d2.evaluation.evaluator]: [0mInference done 6946/8355. 0.1156 s / img. ETA=0:02:45
[32m[04/28 22:11:08 d2.evaluation.evaluator]: [0mInference done 6989/8355. 0.1156 s / img. ETA=0:02:40
[32m[04/28 22:11:13 d2.evaluation.evaluator]: [0mInference done 7032/8355. 0.1156 s / img. ETA=0:02:35
[32m[04/28 22:11:19 d2.evaluation.evaluator]: [0mInference done 7075/8355. 0.1156 s / img. ETA=0:02:30
[32m[04/28 22:11:24 d2.evaluation.evaluator]: [0mInference done 7118/8355. 0.1156 s / img. ETA=0:02:25
[32m[04/28 22:11:29 d2.evaluation.evaluator]: [0mInference done 7161/8355. 0.1156 s / img. ETA=0:02:20
[32m[04/28 22:11:34 d2.evaluation.evaluator]: [0mInference done 7204/8355. 0.1156 s / img. ETA=0:02:15
[32m[04/28 22:11:39 d2.evaluation.evaluator]: [0mInference done 7247/8355. 0.1156 s / img. ETA=0:02:10
[32m[04/28 22:11:44 d2.evaluation.evaluator]: [0mInference done 7290/8355. 0.1156 s / img. ETA=0:02:04
[32m[04/28 22:11:49 d2.evaluation.evaluator]: [0mInference done 7333/8355. 0.1156 s / img. ETA=0:01:59
[32m[04/28 22:11:54 d2.evaluation.evaluator]: [0mInference done 7376/8355. 0.1156 s / img. ETA=0:01:54
[32m[04/28 22:11:59 d2.evaluation.evaluator]: [0mInference done 7419/8355. 0.1156 s / img. ETA=0:01:49
[32m[04/28 22:12:04 d2.evaluation.evaluator]: [0mInference done 7462/8355. 0.1156 s / img. ETA=0:01:44
[32m[04/28 22:12:09 d2.evaluation.evaluator]: [0mInference done 7505/8355. 0.1156 s / img. ETA=0:01:39
[32m[04/28 22:12:14 d2.evaluation.evaluator]: [0mInference done 7548/8355. 0.1156 s / img. ETA=0:01:34
[32m[04/28 22:12:20 d2.evaluation.evaluator]: [0mInference done 7591/8355. 0.1156 s / img. ETA=0:01:29
[32m[04/28 22:12:25 d2.evaluation.evaluator]: [0mInference done 7633/8355. 0.1157 s / img. ETA=0:01:24
[32m[04/28 22:12:30 d2.evaluation.evaluator]: [0mInference done 7676/8355. 0.1157 s / img. ETA=0:01:19
[32m[04/28 22:12:35 d2.evaluation.evaluator]: [0mInference done 7719/8355. 0.1157 s / img. ETA=0:01:14
[32m[04/28 22:12:40 d2.evaluation.evaluator]: [0mInference done 7762/8355. 0.1157 s / img. ETA=0:01:09
[32m[04/28 22:12:45 d2.evaluation.evaluator]: [0mInference done 7805/8355. 0.1157 s / img. ETA=0:01:04
[32m[04/28 22:12:50 d2.evaluation.evaluator]: [0mInference done 7848/8355. 0.1157 s / img. ETA=0:00:59
[32m[04/28 22:12:55 d2.evaluation.evaluator]: [0mInference done 7891/8355. 0.1157 s / img. ETA=0:00:54
[32m[04/28 22:13:00 d2.evaluation.evaluator]: [0mInference done 7934/8355. 0.1157 s / img. ETA=0:00:49
[32m[04/28 22:13:05 d2.evaluation.evaluator]: [0mInference done 7977/8355. 0.1157 s / img. ETA=0:00:44
[32m[04/28 22:13:10 d2.evaluation.evaluator]: [0mInference done 8020/8355. 0.1157 s / img. ETA=0:00:39
[32m[04/28 22:13:15 d2.evaluation.evaluator]: [0mInference done 8063/8355. 0.1157 s / img. ETA=0:00:34
[32m[04/28 22:13:20 d2.evaluation.evaluator]: [0mInference done 8106/8355. 0.1157 s / img. ETA=0:00:29
[32m[04/28 22:13:25 d2.evaluation.evaluator]: [0mInference done 8149/8355. 0.1157 s / img. ETA=0:00:24
[32m[04/28 22:13:30 d2.evaluation.evaluator]: [0mInference done 8192/8355. 0.1157 s / img. ETA=0:00:19
[32m[04/28 22:13:35 d2.evaluation.evaluator]: [0mInference done 8235/8355. 0.1157 s / img. ETA=0:00:14
[32m[04/28 22:13:41 d2.evaluation.evaluator]: [0mInference done 8278/8355. 0.1157 s / img. ETA=0:00:09
[32m[04/28 22:13:46 d2.evaluation.evaluator]: [0mInference done 8321/8355. 0.1157 s / img. ETA=0:00:03
[32m[04/28 22:13:50 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:20.600413 (0.117437 s / img per device, on 1 devices)
[32m[04/28 22:13:50 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:06 (0.115693 s / img per device, on 1 devices)
[32m[04/28 22:13:50 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 22:13:50 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 22:13:50 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.25s).
Accumulating evaluation results...
DONE (t=2.20s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.535
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.895
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.561
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.432
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.653
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.198
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.574
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.595
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.509
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.710
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.840
[32m[04/28 22:14:13 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.500 | 89.457 | 56.115 | 43.247 | 65.300 | 80.475 |
[32m[04/28 22:14:13 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 50.133 | bicycle       | 48.431 | car            | 61.937 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 22:14:13 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 22:14:13 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 22:14:13 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 22:14:15 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1158 s / img. ETA=0:02:26
[32m[04/28 22:14:20 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1155 s / img. ETA=0:02:21
[32m[04/28 22:14:25 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1154 s / img. ETA=0:02:16
[32m[04/28 22:14:30 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1153 s / img. ETA=0:02:10
[32m[04/28 22:14:35 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1154 s / img. ETA=0:02:05
[32m[04/28 22:14:40 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1153 s / img. ETA=0:02:00
[32m[04/28 22:14:45 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1154 s / img. ETA=0:01:55
[32m[04/28 22:14:50 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1154 s / img. ETA=0:01:50
[32m[04/28 22:14:55 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1153 s / img. ETA=0:01:45
[32m[04/28 22:15:00 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1153 s / img. ETA=0:01:40
[32m[04/28 22:15:05 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1153 s / img. ETA=0:01:35
[32m[04/28 22:15:10 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1153 s / img. ETA=0:01:30
[32m[04/28 22:15:15 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1153 s / img. ETA=0:01:25
[32m[04/28 22:15:20 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1153 s / img. ETA=0:01:20
[32m[04/28 22:15:25 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1153 s / img. ETA=0:01:15
[32m[04/28 22:15:30 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1153 s / img. ETA=0:01:10
[32m[04/28 22:15:36 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1153 s / img. ETA=0:01:05
[32m[04/28 22:15:41 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1153 s / img. ETA=0:01:00
[32m[04/28 22:15:46 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1153 s / img. ETA=0:00:55
[32m[04/28 22:15:51 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1154 s / img. ETA=0:00:50
[32m[04/28 22:15:56 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1154 s / img. ETA=0:00:45
[32m[04/28 22:16:01 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1154 s / img. ETA=0:00:40
[32m[04/28 22:16:06 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1155 s / img. ETA=0:00:35
[32m[04/28 22:16:11 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1155 s / img. ETA=0:00:30
[32m[04/28 22:16:16 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1155 s / img. ETA=0:00:25
[32m[04/28 22:16:21 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1155 s / img. ETA=0:00:20
[32m[04/28 22:16:26 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1155 s / img. ETA=0:00:15
[32m[04/28 22:16:31 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1155 s / img. ETA=0:00:09
[32m[04/28 22:16:36 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1155 s / img. ETA=0:00:04
[32m[04/28 22:16:41 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:27.008169 (0.117419 s / img per device, on 1 devices)
[32m[04/28 22:16:41 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115520 s / img per device, on 1 devices)
[32m[04/28 22:16:41 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 22:16:41 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 22:16:41 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.25s).
Accumulating evaluation results...
DONE (t=0.37s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.399
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.759
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.360
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.294
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.476
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.481
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.393
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.668
[32m[04/28 22:16:45 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.928 | 75.868 | 36.034 | 29.412 | 45.761 | 60.550 |
[32m[04/28 22:16:45 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 42.325 | bicycle       | 22.497 | car            | 54.964 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  34  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 22:16:46 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 22:16:46 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 22:16:46 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 22:16:46 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 22:16:47 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 22:16:47 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 22:16:47 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 22:17:07 d2.utils.events]: [0m eta: 0:17:06  iter: 19  total_loss: 0.439  loss_cls: 0.133  loss_box_reg: 0.273  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0334  data_time: 0.0152  lr: 0.000100  max_mem: 5397M
[32m[04/28 22:17:28 d2.utils.events]: [0m eta: 0:16:40  iter: 39  total_loss: 0.472  loss_cls: 0.137  loss_box_reg: 0.285  loss_rpn_cls: 0.004  loss_rpn_loc: 0.035  time: 1.0280  data_time: 0.0080  lr: 0.000200  max_mem: 5397M
[32m[04/28 22:17:48 d2.utils.events]: [0m eta: 0:15:59  iter: 59  total_loss: 0.469  loss_cls: 0.144  loss_box_reg: 0.278  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 1.0234  data_time: 0.0078  lr: 0.000300  max_mem: 5397M
[32m[04/28 22:18:09 d2.utils.events]: [0m eta: 0:15:40  iter: 79  total_loss: 0.477  loss_cls: 0.141  loss_box_reg: 0.275  loss_rpn_cls: 0.007  loss_rpn_loc: 0.051  time: 1.0253  data_time: 0.0078  lr: 0.000400  max_mem: 5397M
[32m[04/28 22:18:30 d2.utils.events]: [0m eta: 0:15:40  iter: 99  total_loss: 0.430  loss_cls: 0.135  loss_box_reg: 0.245  loss_rpn_cls: 0.004  loss_rpn_loc: 0.036  time: 1.0315  data_time: 0.0078  lr: 0.000500  max_mem: 5397M
[32m[04/28 22:18:51 d2.utils.events]: [0m eta: 0:15:12  iter: 119  total_loss: 0.486  loss_cls: 0.131  loss_box_reg: 0.286  loss_rpn_cls: 0.003  loss_rpn_loc: 0.040  time: 1.0306  data_time: 0.0080  lr: 0.000599  max_mem: 5397M
[32m[04/28 22:19:11 d2.utils.events]: [0m eta: 0:14:54  iter: 139  total_loss: 0.432  loss_cls: 0.128  loss_box_reg: 0.265  loss_rpn_cls: 0.004  loss_rpn_loc: 0.035  time: 1.0297  data_time: 0.0079  lr: 0.000699  max_mem: 5397M
[32m[04/28 22:19:32 d2.utils.events]: [0m eta: 0:14:33  iter: 159  total_loss: 0.434  loss_cls: 0.128  loss_box_reg: 0.267  loss_rpn_cls: 0.004  loss_rpn_loc: 0.031  time: 1.0301  data_time: 0.0078  lr: 0.000799  max_mem: 5397M
[32m[04/28 22:19:52 d2.utils.events]: [0m eta: 0:14:12  iter: 179  total_loss: 0.392  loss_cls: 0.125  loss_box_reg: 0.223  loss_rpn_cls: 0.003  loss_rpn_loc: 0.043  time: 1.0293  data_time: 0.0079  lr: 0.000899  max_mem: 5397M
[32m[04/28 22:20:13 d2.utils.events]: [0m eta: 0:13:47  iter: 199  total_loss: 0.466  loss_cls: 0.140  loss_box_reg: 0.278  loss_rpn_cls: 0.004  loss_rpn_loc: 0.056  time: 1.0274  data_time: 0.0078  lr: 0.000999  max_mem: 5397M
[32m[04/28 22:20:34 d2.utils.events]: [0m eta: 0:13:31  iter: 219  total_loss: 0.423  loss_cls: 0.123  loss_box_reg: 0.252  loss_rpn_cls: 0.003  loss_rpn_loc: 0.036  time: 1.0293  data_time: 0.0077  lr: 0.001099  max_mem: 5397M
[32m[04/28 22:20:55 d2.utils.events]: [0m eta: 0:13:11  iter: 239  total_loss: 0.468  loss_cls: 0.146  loss_box_reg: 0.280  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0305  data_time: 0.0075  lr: 0.001199  max_mem: 5397M
[32m[04/28 22:21:16 d2.utils.events]: [0m eta: 0:12:53  iter: 259  total_loss: 0.415  loss_cls: 0.127  loss_box_reg: 0.243  loss_rpn_cls: 0.002  loss_rpn_loc: 0.041  time: 1.0318  data_time: 0.0079  lr: 0.001299  max_mem: 5397M
[32m[04/28 22:21:36 d2.utils.events]: [0m eta: 0:12:29  iter: 279  total_loss: 0.474  loss_cls: 0.130  loss_box_reg: 0.280  loss_rpn_cls: 0.004  loss_rpn_loc: 0.039  time: 1.0308  data_time: 0.0076  lr: 0.001399  max_mem: 5397M
[32m[04/28 22:21:57 d2.utils.events]: [0m eta: 0:12:08  iter: 299  total_loss: 0.471  loss_cls: 0.140  loss_box_reg: 0.273  loss_rpn_cls: 0.004  loss_rpn_loc: 0.039  time: 1.0305  data_time: 0.0078  lr: 0.001499  max_mem: 5397M
[32m[04/28 22:22:17 d2.utils.events]: [0m eta: 0:11:48  iter: 319  total_loss: 0.421  loss_cls: 0.114  loss_box_reg: 0.249  loss_rpn_cls: 0.003  loss_rpn_loc: 0.043  time: 1.0302  data_time: 0.0078  lr: 0.001598  max_mem: 5397M
[32m[04/28 22:22:38 d2.utils.events]: [0m eta: 0:11:25  iter: 339  total_loss: 0.439  loss_cls: 0.130  loss_box_reg: 0.258  loss_rpn_cls: 0.004  loss_rpn_loc: 0.038  time: 1.0297  data_time: 0.0078  lr: 0.001698  max_mem: 5397M
[32m[04/28 22:22:58 d2.utils.events]: [0m eta: 0:11:04  iter: 359  total_loss: 0.407  loss_cls: 0.124  loss_box_reg: 0.259  loss_rpn_cls: 0.003  loss_rpn_loc: 0.032  time: 1.0294  data_time: 0.0078  lr: 0.001798  max_mem: 5397M
[32m[04/28 22:23:19 d2.utils.events]: [0m eta: 0:10:45  iter: 379  total_loss: 0.458  loss_cls: 0.135  loss_box_reg: 0.265  loss_rpn_cls: 0.005  loss_rpn_loc: 0.043  time: 1.0302  data_time: 0.0078  lr: 0.001898  max_mem: 5397M
[32m[04/28 22:23:40 d2.utils.events]: [0m eta: 0:10:23  iter: 399  total_loss: 0.478  loss_cls: 0.138  loss_box_reg: 0.257  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 1.0298  data_time: 0.0078  lr: 0.001998  max_mem: 5397M
[32m[04/28 22:24:00 d2.utils.events]: [0m eta: 0:10:02  iter: 419  total_loss: 0.436  loss_cls: 0.127  loss_box_reg: 0.254  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0293  data_time: 0.0080  lr: 0.002098  max_mem: 5397M
[32m[04/28 22:24:21 d2.utils.events]: [0m eta: 0:09:41  iter: 439  total_loss: 0.443  loss_cls: 0.136  loss_box_reg: 0.256  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0296  data_time: 0.0078  lr: 0.002198  max_mem: 5397M
[32m[04/28 22:24:42 d2.utils.events]: [0m eta: 0:09:22  iter: 459  total_loss: 0.494  loss_cls: 0.127  loss_box_reg: 0.290  loss_rpn_cls: 0.003  loss_rpn_loc: 0.058  time: 1.0300  data_time: 0.0076  lr: 0.002298  max_mem: 5397M
[32m[04/28 22:25:02 d2.utils.events]: [0m eta: 0:09:00  iter: 479  total_loss: 0.497  loss_cls: 0.147  loss_box_reg: 0.287  loss_rpn_cls: 0.005  loss_rpn_loc: 0.048  time: 1.0301  data_time: 0.0076  lr: 0.002398  max_mem: 5397M
[32m[04/28 22:25:23 d2.utils.events]: [0m eta: 0:08:39  iter: 499  total_loss: 0.432  loss_cls: 0.126  loss_box_reg: 0.260  loss_rpn_cls: 0.003  loss_rpn_loc: 0.033  time: 1.0301  data_time: 0.0079  lr: 0.002498  max_mem: 5397M
[32m[04/28 22:25:44 d2.utils.events]: [0m eta: 0:08:19  iter: 519  total_loss: 0.467  loss_cls: 0.137  loss_box_reg: 0.282  loss_rpn_cls: 0.003  loss_rpn_loc: 0.045  time: 1.0301  data_time: 0.0076  lr: 0.002597  max_mem: 5397M
[32m[04/28 22:26:04 d2.utils.events]: [0m eta: 0:07:58  iter: 539  total_loss: 0.421  loss_cls: 0.132  loss_box_reg: 0.250  loss_rpn_cls: 0.004  loss_rpn_loc: 0.043  time: 1.0299  data_time: 0.0076  lr: 0.002697  max_mem: 5397M
[32m[04/28 22:26:24 d2.utils.events]: [0m eta: 0:07:37  iter: 559  total_loss: 0.454  loss_cls: 0.135  loss_box_reg: 0.267  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0291  data_time: 0.0078  lr: 0.002797  max_mem: 5397M
[32m[04/28 22:26:45 d2.utils.events]: [0m eta: 0:07:15  iter: 579  total_loss: 0.403  loss_cls: 0.125  loss_box_reg: 0.247  loss_rpn_cls: 0.003  loss_rpn_loc: 0.040  time: 1.0288  data_time: 0.0076  lr: 0.002897  max_mem: 5397M
[32m[04/28 22:27:05 d2.utils.events]: [0m eta: 0:06:55  iter: 599  total_loss: 0.407  loss_cls: 0.129  loss_box_reg: 0.245  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0283  data_time: 0.0078  lr: 0.002997  max_mem: 5397M
[32m[04/28 22:27:26 d2.utils.events]: [0m eta: 0:06:34  iter: 619  total_loss: 0.465  loss_cls: 0.130  loss_box_reg: 0.271  loss_rpn_cls: 0.004  loss_rpn_loc: 0.048  time: 1.0286  data_time: 0.0078  lr: 0.003097  max_mem: 5397M
[32m[04/28 22:27:46 d2.utils.events]: [0m eta: 0:06:14  iter: 639  total_loss: 0.459  loss_cls: 0.131  loss_box_reg: 0.275  loss_rpn_cls: 0.004  loss_rpn_loc: 0.033  time: 1.0283  data_time: 0.0077  lr: 0.003197  max_mem: 5397M
[32m[04/28 22:28:08 d2.utils.events]: [0m eta: 0:05:54  iter: 659  total_loss: 0.463  loss_cls: 0.136  loss_box_reg: 0.281  loss_rpn_cls: 0.005  loss_rpn_loc: 0.052  time: 1.0292  data_time: 0.0077  lr: 0.003297  max_mem: 5397M
[32m[04/28 22:28:28 d2.utils.events]: [0m eta: 0:05:33  iter: 679  total_loss: 0.416  loss_cls: 0.125  loss_box_reg: 0.268  loss_rpn_cls: 0.005  loss_rpn_loc: 0.045  time: 1.0293  data_time: 0.0081  lr: 0.003397  max_mem: 5397M
[32m[04/28 22:28:49 d2.utils.events]: [0m eta: 0:05:13  iter: 699  total_loss: 0.450  loss_cls: 0.132  loss_box_reg: 0.265  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0290  data_time: 0.0077  lr: 0.003497  max_mem: 5397M
[32m[04/28 22:29:09 d2.utils.events]: [0m eta: 0:04:52  iter: 719  total_loss: 0.442  loss_cls: 0.144  loss_box_reg: 0.260  loss_rpn_cls: 0.006  loss_rpn_loc: 0.039  time: 1.0290  data_time: 0.0078  lr: 0.003596  max_mem: 5397M
[32m[04/28 22:29:30 d2.utils.events]: [0m eta: 0:04:31  iter: 739  total_loss: 0.513  loss_cls: 0.157  loss_box_reg: 0.301  loss_rpn_cls: 0.005  loss_rpn_loc: 0.036  time: 1.0285  data_time: 0.0077  lr: 0.003696  max_mem: 5397M
[32m[04/28 22:29:50 d2.utils.events]: [0m eta: 0:04:10  iter: 759  total_loss: 0.416  loss_cls: 0.132  loss_box_reg: 0.248  loss_rpn_cls: 0.006  loss_rpn_loc: 0.034  time: 1.0288  data_time: 0.0078  lr: 0.003796  max_mem: 5397M
[32m[04/28 22:30:11 d2.utils.events]: [0m eta: 0:03:49  iter: 779  total_loss: 0.505  loss_cls: 0.150  loss_box_reg: 0.295  loss_rpn_cls: 0.004  loss_rpn_loc: 0.047  time: 1.0289  data_time: 0.0078  lr: 0.003896  max_mem: 5397M
[32m[04/28 22:30:32 d2.utils.events]: [0m eta: 0:03:29  iter: 799  total_loss: 0.405  loss_cls: 0.125  loss_box_reg: 0.248  loss_rpn_cls: 0.005  loss_rpn_loc: 0.034  time: 1.0294  data_time: 0.0078  lr: 0.003996  max_mem: 5397M
[32m[04/28 22:30:52 d2.utils.events]: [0m eta: 0:03:08  iter: 819  total_loss: 0.452  loss_cls: 0.141  loss_box_reg: 0.265  loss_rpn_cls: 0.006  loss_rpn_loc: 0.044  time: 1.0289  data_time: 0.0076  lr: 0.004096  max_mem: 5397M
[32m[04/28 22:31:12 d2.utils.events]: [0m eta: 0:02:47  iter: 839  total_loss: 0.453  loss_cls: 0.132  loss_box_reg: 0.272  loss_rpn_cls: 0.006  loss_rpn_loc: 0.041  time: 1.0282  data_time: 0.0077  lr: 0.004196  max_mem: 5397M
[32m[04/28 22:31:32 d2.utils.events]: [0m eta: 0:02:26  iter: 859  total_loss: 0.459  loss_cls: 0.137  loss_box_reg: 0.257  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0275  data_time: 0.0076  lr: 0.004296  max_mem: 5397M
[32m[04/28 22:31:53 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.526  loss_cls: 0.159  loss_box_reg: 0.311  loss_rpn_cls: 0.007  loss_rpn_loc: 0.041  time: 1.0273  data_time: 0.0078  lr: 0.004396  max_mem: 5397M
[32m[04/28 22:32:13 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.438  loss_cls: 0.137  loss_box_reg: 0.259  loss_rpn_cls: 0.006  loss_rpn_loc: 0.049  time: 1.0272  data_time: 0.0079  lr: 0.004496  max_mem: 5397M
[32m[04/28 22:32:34 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.475  loss_cls: 0.135  loss_box_reg: 0.281  loss_rpn_cls: 0.006  loss_rpn_loc: 0.042  time: 1.0275  data_time: 0.0079  lr: 0.004595  max_mem: 5397M
[32m[04/28 22:32:55 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.490  loss_cls: 0.148  loss_box_reg: 0.291  loss_rpn_cls: 0.007  loss_rpn_loc: 0.048  time: 1.0274  data_time: 0.0077  lr: 0.004695  max_mem: 5397M
[32m[04/28 22:33:16 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.469  loss_cls: 0.149  loss_box_reg: 0.280  loss_rpn_cls: 0.005  loss_rpn_loc: 0.052  time: 1.0283  data_time: 0.0078  lr: 0.004795  max_mem: 5397M
[32m[04/28 22:33:36 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.414  loss_cls: 0.127  loss_box_reg: 0.243  loss_rpn_cls: 0.004  loss_rpn_loc: 0.046  time: 1.0280  data_time: 0.0077  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 22:33:59 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 22:33:59 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 22:34:00 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 22:34:00 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.581  loss_cls: 0.163  loss_box_reg: 0.330  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 1.0281  data_time: 0.0079  lr: 0.004995  max_mem: 5397M
[32m[04/28 22:34:00 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:06 (1.0292 s / it)
[32m[04/28 22:34:00 d2.engine.hooks]: [0mTotal training time: 0:17:11 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 22:34:01 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 22:34:01 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 22:34:02 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 22:34:03 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1143 s / img. ETA=0:16:05
[32m[04/28 22:34:08 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1142 s / img. ETA=0:16:01
[32m[04/28 22:34:14 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1140 s / img. ETA=0:15:55
[32m[04/28 22:34:19 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1140 s / img. ETA=0:15:49
[32m[04/28 22:34:24 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1140 s / img. ETA=0:15:44
[32m[04/28 22:34:29 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1141 s / img. ETA=0:15:40
[32m[04/28 22:34:34 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1142 s / img. ETA=0:15:35
[32m[04/28 22:34:39 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1142 s / img. ETA=0:15:30
[32m[04/28 22:34:44 d2.evaluation.evaluator]: [0mInference done 362/8355. 0.1142 s / img. ETA=0:15:26
[32m[04/28 22:34:49 d2.evaluation.evaluator]: [0mInference done 405/8355. 0.1143 s / img. ETA=0:15:22
[32m[04/28 22:34:54 d2.evaluation.evaluator]: [0mInference done 448/8355. 0.1143 s / img. ETA=0:15:17
[32m[04/28 22:34:59 d2.evaluation.evaluator]: [0mInference done 492/8355. 0.1143 s / img. ETA=0:15:11
[32m[04/28 22:35:04 d2.evaluation.evaluator]: [0mInference done 536/8355. 0.1143 s / img. ETA=0:15:06
[32m[04/28 22:35:09 d2.evaluation.evaluator]: [0mInference done 580/8355. 0.1142 s / img. ETA=0:15:01
[32m[04/28 22:35:14 d2.evaluation.evaluator]: [0mInference done 624/8355. 0.1143 s / img. ETA=0:14:56
[32m[04/28 22:35:19 d2.evaluation.evaluator]: [0mInference done 667/8355. 0.1143 s / img. ETA=0:14:51
[32m[04/28 22:35:25 d2.evaluation.evaluator]: [0mInference done 710/8355. 0.1144 s / img. ETA=0:14:47
[32m[04/28 22:35:30 d2.evaluation.evaluator]: [0mInference done 754/8355. 0.1144 s / img. ETA=0:14:42
[32m[04/28 22:35:35 d2.evaluation.evaluator]: [0mInference done 797/8355. 0.1145 s / img. ETA=0:14:37
[32m[04/28 22:35:40 d2.evaluation.evaluator]: [0mInference done 841/8355. 0.1145 s / img. ETA=0:14:32
[32m[04/28 22:35:45 d2.evaluation.evaluator]: [0mInference done 884/8355. 0.1145 s / img. ETA=0:14:27
[32m[04/28 22:35:50 d2.evaluation.evaluator]: [0mInference done 927/8355. 0.1145 s / img. ETA=0:14:23
[32m[04/28 22:35:55 d2.evaluation.evaluator]: [0mInference done 971/8355. 0.1145 s / img. ETA=0:14:17
[32m[04/28 22:36:00 d2.evaluation.evaluator]: [0mInference done 1014/8355. 0.1145 s / img. ETA=0:14:13
[32m[04/28 22:36:05 d2.evaluation.evaluator]: [0mInference done 1057/8355. 0.1145 s / img. ETA=0:14:08
[32m[04/28 22:36:10 d2.evaluation.evaluator]: [0mInference done 1101/8355. 0.1145 s / img. ETA=0:14:02
[32m[04/28 22:36:15 d2.evaluation.evaluator]: [0mInference done 1145/8355. 0.1145 s / img. ETA=0:13:57
[32m[04/28 22:36:20 d2.evaluation.evaluator]: [0mInference done 1189/8355. 0.1145 s / img. ETA=0:13:52
[32m[04/28 22:36:25 d2.evaluation.evaluator]: [0mInference done 1233/8355. 0.1145 s / img. ETA=0:13:47
[32m[04/28 22:36:30 d2.evaluation.evaluator]: [0mInference done 1276/8355. 0.1145 s / img. ETA=0:13:42
[32m[04/28 22:36:35 d2.evaluation.evaluator]: [0mInference done 1320/8355. 0.1145 s / img. ETA=0:13:37
[32m[04/28 22:36:41 d2.evaluation.evaluator]: [0mInference done 1364/8355. 0.1145 s / img. ETA=0:13:31
[32m[04/28 22:36:46 d2.evaluation.evaluator]: [0mInference done 1408/8355. 0.1145 s / img. ETA=0:13:26
[32m[04/28 22:36:51 d2.evaluation.evaluator]: [0mInference done 1451/8355. 0.1145 s / img. ETA=0:13:22
[32m[04/28 22:36:56 d2.evaluation.evaluator]: [0mInference done 1494/8355. 0.1146 s / img. ETA=0:13:17
[32m[04/28 22:37:01 d2.evaluation.evaluator]: [0mInference done 1537/8355. 0.1146 s / img. ETA=0:13:12
[32m[04/28 22:37:06 d2.evaluation.evaluator]: [0mInference done 1580/8355. 0.1147 s / img. ETA=0:13:08
[32m[04/28 22:37:11 d2.evaluation.evaluator]: [0mInference done 1622/8355. 0.1147 s / img. ETA=0:13:03
[32m[04/28 22:37:16 d2.evaluation.evaluator]: [0mInference done 1665/8355. 0.1148 s / img. ETA=0:12:59
[32m[04/28 22:37:21 d2.evaluation.evaluator]: [0mInference done 1708/8355. 0.1148 s / img. ETA=0:12:54
[32m[04/28 22:37:26 d2.evaluation.evaluator]: [0mInference done 1751/8355. 0.1148 s / img. ETA=0:12:49
[32m[04/28 22:37:31 d2.evaluation.evaluator]: [0mInference done 1794/8355. 0.1149 s / img. ETA=0:12:44
[32m[04/28 22:37:36 d2.evaluation.evaluator]: [0mInference done 1837/8355. 0.1149 s / img. ETA=0:12:39
[32m[04/28 22:37:41 d2.evaluation.evaluator]: [0mInference done 1879/8355. 0.1149 s / img. ETA=0:12:35
[32m[04/28 22:37:46 d2.evaluation.evaluator]: [0mInference done 1922/8355. 0.1150 s / img. ETA=0:12:30
[32m[04/28 22:37:51 d2.evaluation.evaluator]: [0mInference done 1965/8355. 0.1150 s / img. ETA=0:12:25
[32m[04/28 22:37:56 d2.evaluation.evaluator]: [0mInference done 2008/8355. 0.1150 s / img. ETA=0:12:20
[32m[04/28 22:38:01 d2.evaluation.evaluator]: [0mInference done 2051/8355. 0.1150 s / img. ETA=0:12:15
[32m[04/28 22:38:06 d2.evaluation.evaluator]: [0mInference done 2094/8355. 0.1150 s / img. ETA=0:12:10
[32m[04/28 22:38:11 d2.evaluation.evaluator]: [0mInference done 2137/8355. 0.1150 s / img. ETA=0:12:05
[32m[04/28 22:38:17 d2.evaluation.evaluator]: [0mInference done 2180/8355. 0.1150 s / img. ETA=0:12:00
[32m[04/28 22:38:22 d2.evaluation.evaluator]: [0mInference done 2223/8355. 0.1150 s / img. ETA=0:11:55
[32m[04/28 22:38:27 d2.evaluation.evaluator]: [0mInference done 2266/8355. 0.1151 s / img. ETA=0:11:50
[32m[04/28 22:38:32 d2.evaluation.evaluator]: [0mInference done 2309/8355. 0.1151 s / img. ETA=0:11:46
[32m[04/28 22:38:37 d2.evaluation.evaluator]: [0mInference done 2352/8355. 0.1151 s / img. ETA=0:11:41
[32m[04/28 22:38:42 d2.evaluation.evaluator]: [0mInference done 2395/8355. 0.1151 s / img. ETA=0:11:36
[32m[04/28 22:38:47 d2.evaluation.evaluator]: [0mInference done 2438/8355. 0.1152 s / img. ETA=0:11:31
[32m[04/28 22:38:52 d2.evaluation.evaluator]: [0mInference done 2481/8355. 0.1152 s / img. ETA=0:11:26
[32m[04/28 22:38:57 d2.evaluation.evaluator]: [0mInference done 2524/8355. 0.1152 s / img. ETA=0:11:21
[32m[04/28 22:39:02 d2.evaluation.evaluator]: [0mInference done 2567/8355. 0.1152 s / img. ETA=0:11:16
[32m[04/28 22:39:07 d2.evaluation.evaluator]: [0mInference done 2609/8355. 0.1152 s / img. ETA=0:11:11
[32m[04/28 22:39:12 d2.evaluation.evaluator]: [0mInference done 2652/8355. 0.1152 s / img. ETA=0:11:06
[32m[04/28 22:39:17 d2.evaluation.evaluator]: [0mInference done 2695/8355. 0.1152 s / img. ETA=0:11:01
[32m[04/28 22:39:22 d2.evaluation.evaluator]: [0mInference done 2738/8355. 0.1152 s / img. ETA=0:10:56
[32m[04/28 22:39:27 d2.evaluation.evaluator]: [0mInference done 2781/8355. 0.1153 s / img. ETA=0:10:51
[32m[04/28 22:39:32 d2.evaluation.evaluator]: [0mInference done 2824/8355. 0.1153 s / img. ETA=0:10:46
[32m[04/28 22:39:37 d2.evaluation.evaluator]: [0mInference done 2867/8355. 0.1153 s / img. ETA=0:10:42
[32m[04/28 22:39:43 d2.evaluation.evaluator]: [0mInference done 2910/8355. 0.1153 s / img. ETA=0:10:36
[32m[04/28 22:39:48 d2.evaluation.evaluator]: [0mInference done 2953/8355. 0.1153 s / img. ETA=0:10:32
[32m[04/28 22:39:53 d2.evaluation.evaluator]: [0mInference done 2996/8355. 0.1153 s / img. ETA=0:10:26
[32m[04/28 22:39:58 d2.evaluation.evaluator]: [0mInference done 3038/8355. 0.1153 s / img. ETA=0:10:22
[32m[04/28 22:40:03 d2.evaluation.evaluator]: [0mInference done 3081/8355. 0.1153 s / img. ETA=0:10:17
[32m[04/28 22:40:08 d2.evaluation.evaluator]: [0mInference done 3124/8355. 0.1153 s / img. ETA=0:10:12
[32m[04/28 22:40:13 d2.evaluation.evaluator]: [0mInference done 3168/8355. 0.1153 s / img. ETA=0:10:06
[32m[04/28 22:40:18 d2.evaluation.evaluator]: [0mInference done 3212/8355. 0.1153 s / img. ETA=0:10:01
[32m[04/28 22:40:23 d2.evaluation.evaluator]: [0mInference done 3255/8355. 0.1153 s / img. ETA=0:09:56
[32m[04/28 22:40:28 d2.evaluation.evaluator]: [0mInference done 3298/8355. 0.1153 s / img. ETA=0:09:51
[32m[04/28 22:40:33 d2.evaluation.evaluator]: [0mInference done 3342/8355. 0.1153 s / img. ETA=0:09:46
[32m[04/28 22:40:38 d2.evaluation.evaluator]: [0mInference done 3386/8355. 0.1153 s / img. ETA=0:09:41
[32m[04/28 22:40:43 d2.evaluation.evaluator]: [0mInference done 3429/8355. 0.1153 s / img. ETA=0:09:36
[32m[04/28 22:40:48 d2.evaluation.evaluator]: [0mInference done 3472/8355. 0.1153 s / img. ETA=0:09:31
[32m[04/28 22:40:53 d2.evaluation.evaluator]: [0mInference done 3515/8355. 0.1153 s / img. ETA=0:09:26
[32m[04/28 22:40:58 d2.evaluation.evaluator]: [0mInference done 3558/8355. 0.1153 s / img. ETA=0:09:21
[32m[04/28 22:41:03 d2.evaluation.evaluator]: [0mInference done 3601/8355. 0.1153 s / img. ETA=0:09:16
[32m[04/28 22:41:08 d2.evaluation.evaluator]: [0mInference done 3644/8355. 0.1153 s / img. ETA=0:09:11
[32m[04/28 22:41:13 d2.evaluation.evaluator]: [0mInference done 3687/8355. 0.1153 s / img. ETA=0:09:06
[32m[04/28 22:41:18 d2.evaluation.evaluator]: [0mInference done 3730/8355. 0.1153 s / img. ETA=0:09:01
[32m[04/28 22:41:23 d2.evaluation.evaluator]: [0mInference done 3773/8355. 0.1153 s / img. ETA=0:08:55
[32m[04/28 22:41:29 d2.evaluation.evaluator]: [0mInference done 3816/8355. 0.1153 s / img. ETA=0:08:51
[32m[04/28 22:41:34 d2.evaluation.evaluator]: [0mInference done 3859/8355. 0.1153 s / img. ETA=0:08:46
[32m[04/28 22:41:39 d2.evaluation.evaluator]: [0mInference done 3903/8355. 0.1153 s / img. ETA=0:08:40
[32m[04/28 22:41:44 d2.evaluation.evaluator]: [0mInference done 3946/8355. 0.1153 s / img. ETA=0:08:35
[32m[04/28 22:41:49 d2.evaluation.evaluator]: [0mInference done 3989/8355. 0.1153 s / img. ETA=0:08:30
[32m[04/28 22:41:54 d2.evaluation.evaluator]: [0mInference done 4032/8355. 0.1153 s / img. ETA=0:08:25
[32m[04/28 22:41:59 d2.evaluation.evaluator]: [0mInference done 4075/8355. 0.1153 s / img. ETA=0:08:20
[32m[04/28 22:42:04 d2.evaluation.evaluator]: [0mInference done 4118/8355. 0.1153 s / img. ETA=0:08:15
[32m[04/28 22:42:09 d2.evaluation.evaluator]: [0mInference done 4161/8355. 0.1153 s / img. ETA=0:08:10
[32m[04/28 22:42:14 d2.evaluation.evaluator]: [0mInference done 4204/8355. 0.1153 s / img. ETA=0:08:05
[32m[04/28 22:42:19 d2.evaluation.evaluator]: [0mInference done 4247/8355. 0.1153 s / img. ETA=0:08:00
[32m[04/28 22:42:24 d2.evaluation.evaluator]: [0mInference done 4290/8355. 0.1153 s / img. ETA=0:07:55
[32m[04/28 22:42:29 d2.evaluation.evaluator]: [0mInference done 4333/8355. 0.1153 s / img. ETA=0:07:50
[32m[04/28 22:42:34 d2.evaluation.evaluator]: [0mInference done 4377/8355. 0.1153 s / img. ETA=0:07:45
[32m[04/28 22:42:39 d2.evaluation.evaluator]: [0mInference done 4420/8355. 0.1153 s / img. ETA=0:07:40
[32m[04/28 22:42:44 d2.evaluation.evaluator]: [0mInference done 4463/8355. 0.1153 s / img. ETA=0:07:35
[32m[04/28 22:42:49 d2.evaluation.evaluator]: [0mInference done 4506/8355. 0.1153 s / img. ETA=0:07:30
[32m[04/28 22:42:54 d2.evaluation.evaluator]: [0mInference done 4549/8355. 0.1153 s / img. ETA=0:07:25
[32m[04/28 22:42:59 d2.evaluation.evaluator]: [0mInference done 4592/8355. 0.1153 s / img. ETA=0:07:20
[32m[04/28 22:43:04 d2.evaluation.evaluator]: [0mInference done 4635/8355. 0.1153 s / img. ETA=0:07:15
[32m[04/28 22:43:09 d2.evaluation.evaluator]: [0mInference done 4678/8355. 0.1153 s / img. ETA=0:07:10
[32m[04/28 22:43:14 d2.evaluation.evaluator]: [0mInference done 4721/8355. 0.1153 s / img. ETA=0:07:05
[32m[04/28 22:43:19 d2.evaluation.evaluator]: [0mInference done 4764/8355. 0.1153 s / img. ETA=0:07:00
[32m[04/28 22:43:25 d2.evaluation.evaluator]: [0mInference done 4807/8355. 0.1153 s / img. ETA=0:06:55
[32m[04/28 22:43:30 d2.evaluation.evaluator]: [0mInference done 4850/8355. 0.1153 s / img. ETA=0:06:50
[32m[04/28 22:43:35 d2.evaluation.evaluator]: [0mInference done 4893/8355. 0.1153 s / img. ETA=0:06:45
[32m[04/28 22:43:40 d2.evaluation.evaluator]: [0mInference done 4936/8355. 0.1153 s / img. ETA=0:06:40
[32m[04/28 22:43:45 d2.evaluation.evaluator]: [0mInference done 4979/8355. 0.1153 s / img. ETA=0:06:35
[32m[04/28 22:43:50 d2.evaluation.evaluator]: [0mInference done 5022/8355. 0.1153 s / img. ETA=0:06:29
[32m[04/28 22:43:55 d2.evaluation.evaluator]: [0mInference done 5065/8355. 0.1153 s / img. ETA=0:06:24
[32m[04/28 22:44:00 d2.evaluation.evaluator]: [0mInference done 5108/8355. 0.1153 s / img. ETA=0:06:19
[32m[04/28 22:44:05 d2.evaluation.evaluator]: [0mInference done 5151/8355. 0.1153 s / img. ETA=0:06:14
[32m[04/28 22:44:10 d2.evaluation.evaluator]: [0mInference done 5194/8355. 0.1153 s / img. ETA=0:06:09
[32m[04/28 22:44:15 d2.evaluation.evaluator]: [0mInference done 5237/8355. 0.1153 s / img. ETA=0:06:04
[32m[04/28 22:44:20 d2.evaluation.evaluator]: [0mInference done 5280/8355. 0.1153 s / img. ETA=0:05:59
[32m[04/28 22:44:25 d2.evaluation.evaluator]: [0mInference done 5323/8355. 0.1153 s / img. ETA=0:05:54
[32m[04/28 22:44:30 d2.evaluation.evaluator]: [0mInference done 5366/8355. 0.1153 s / img. ETA=0:05:49
[32m[04/28 22:44:35 d2.evaluation.evaluator]: [0mInference done 5409/8355. 0.1153 s / img. ETA=0:05:44
[32m[04/28 22:44:40 d2.evaluation.evaluator]: [0mInference done 5452/8355. 0.1153 s / img. ETA=0:05:39
[32m[04/28 22:44:45 d2.evaluation.evaluator]: [0mInference done 5495/8355. 0.1153 s / img. ETA=0:05:34
[32m[04/28 22:44:50 d2.evaluation.evaluator]: [0mInference done 5538/8355. 0.1153 s / img. ETA=0:05:29
[32m[04/28 22:44:55 d2.evaluation.evaluator]: [0mInference done 5582/8355. 0.1153 s / img. ETA=0:05:24
[32m[04/28 22:45:00 d2.evaluation.evaluator]: [0mInference done 5625/8355. 0.1153 s / img. ETA=0:05:19
[32m[04/28 22:45:05 d2.evaluation.evaluator]: [0mInference done 5668/8355. 0.1153 s / img. ETA=0:05:14
[32m[04/28 22:45:10 d2.evaluation.evaluator]: [0mInference done 5711/8355. 0.1153 s / img. ETA=0:05:09
[32m[04/28 22:45:15 d2.evaluation.evaluator]: [0mInference done 5754/8355. 0.1153 s / img. ETA=0:05:04
[32m[04/28 22:45:21 d2.evaluation.evaluator]: [0mInference done 5797/8355. 0.1153 s / img. ETA=0:04:59
[32m[04/28 22:45:26 d2.evaluation.evaluator]: [0mInference done 5840/8355. 0.1153 s / img. ETA=0:04:54
[32m[04/28 22:45:31 d2.evaluation.evaluator]: [0mInference done 5883/8355. 0.1153 s / img. ETA=0:04:49
[32m[04/28 22:45:36 d2.evaluation.evaluator]: [0mInference done 5926/8355. 0.1153 s / img. ETA=0:04:44
[32m[04/28 22:45:41 d2.evaluation.evaluator]: [0mInference done 5969/8355. 0.1153 s / img. ETA=0:04:39
[32m[04/28 22:45:46 d2.evaluation.evaluator]: [0mInference done 6012/8355. 0.1154 s / img. ETA=0:04:34
[32m[04/28 22:45:51 d2.evaluation.evaluator]: [0mInference done 6055/8355. 0.1154 s / img. ETA=0:04:29
[32m[04/28 22:45:56 d2.evaluation.evaluator]: [0mInference done 6098/8355. 0.1154 s / img. ETA=0:04:24
[32m[04/28 22:46:01 d2.evaluation.evaluator]: [0mInference done 6141/8355. 0.1154 s / img. ETA=0:04:19
[32m[04/28 22:46:06 d2.evaluation.evaluator]: [0mInference done 6184/8355. 0.1154 s / img. ETA=0:04:14
[32m[04/28 22:46:11 d2.evaluation.evaluator]: [0mInference done 6227/8355. 0.1154 s / img. ETA=0:04:09
[32m[04/28 22:46:16 d2.evaluation.evaluator]: [0mInference done 6269/8355. 0.1154 s / img. ETA=0:04:04
[32m[04/28 22:46:21 d2.evaluation.evaluator]: [0mInference done 6312/8355. 0.1154 s / img. ETA=0:03:59
[32m[04/28 22:46:26 d2.evaluation.evaluator]: [0mInference done 6355/8355. 0.1154 s / img. ETA=0:03:54
[32m[04/28 22:46:31 d2.evaluation.evaluator]: [0mInference done 6397/8355. 0.1154 s / img. ETA=0:03:49
[32m[04/28 22:46:37 d2.evaluation.evaluator]: [0mInference done 6440/8355. 0.1154 s / img. ETA=0:03:44
[32m[04/28 22:46:42 d2.evaluation.evaluator]: [0mInference done 6483/8355. 0.1154 s / img. ETA=0:03:39
[32m[04/28 22:46:47 d2.evaluation.evaluator]: [0mInference done 6526/8355. 0.1154 s / img. ETA=0:03:34
[32m[04/28 22:46:52 d2.evaluation.evaluator]: [0mInference done 6570/8355. 0.1154 s / img. ETA=0:03:29
[32m[04/28 22:46:57 d2.evaluation.evaluator]: [0mInference done 6613/8355. 0.1154 s / img. ETA=0:03:24
[32m[04/28 22:47:02 d2.evaluation.evaluator]: [0mInference done 6657/8355. 0.1154 s / img. ETA=0:03:18
[32m[04/28 22:47:07 d2.evaluation.evaluator]: [0mInference done 6701/8355. 0.1154 s / img. ETA=0:03:13
[32m[04/28 22:47:12 d2.evaluation.evaluator]: [0mInference done 6744/8355. 0.1154 s / img. ETA=0:03:08
[32m[04/28 22:47:17 d2.evaluation.evaluator]: [0mInference done 6788/8355. 0.1154 s / img. ETA=0:03:03
[32m[04/28 22:47:22 d2.evaluation.evaluator]: [0mInference done 6832/8355. 0.1154 s / img. ETA=0:02:58
[32m[04/28 22:47:27 d2.evaluation.evaluator]: [0mInference done 6875/8355. 0.1154 s / img. ETA=0:02:53
[32m[04/28 22:47:32 d2.evaluation.evaluator]: [0mInference done 6918/8355. 0.1154 s / img. ETA=0:02:48
[32m[04/28 22:47:37 d2.evaluation.evaluator]: [0mInference done 6961/8355. 0.1154 s / img. ETA=0:02:43
[32m[04/28 22:47:42 d2.evaluation.evaluator]: [0mInference done 7004/8355. 0.1154 s / img. ETA=0:02:38
[32m[04/28 22:47:47 d2.evaluation.evaluator]: [0mInference done 7047/8355. 0.1154 s / img. ETA=0:02:33
[32m[04/28 22:47:52 d2.evaluation.evaluator]: [0mInference done 7090/8355. 0.1154 s / img. ETA=0:02:28
[32m[04/28 22:47:57 d2.evaluation.evaluator]: [0mInference done 7133/8355. 0.1154 s / img. ETA=0:02:23
[32m[04/28 22:48:03 d2.evaluation.evaluator]: [0mInference done 7176/8355. 0.1154 s / img. ETA=0:02:18
[32m[04/28 22:48:08 d2.evaluation.evaluator]: [0mInference done 7219/8355. 0.1154 s / img. ETA=0:02:13
[32m[04/28 22:48:13 d2.evaluation.evaluator]: [0mInference done 7262/8355. 0.1154 s / img. ETA=0:02:08
[32m[04/28 22:48:18 d2.evaluation.evaluator]: [0mInference done 7305/8355. 0.1154 s / img. ETA=0:02:02
[32m[04/28 22:48:23 d2.evaluation.evaluator]: [0mInference done 7348/8355. 0.1154 s / img. ETA=0:01:57
[32m[04/28 22:48:28 d2.evaluation.evaluator]: [0mInference done 7391/8355. 0.1154 s / img. ETA=0:01:52
[32m[04/28 22:48:33 d2.evaluation.evaluator]: [0mInference done 7434/8355. 0.1154 s / img. ETA=0:01:47
[32m[04/28 22:48:38 d2.evaluation.evaluator]: [0mInference done 7477/8355. 0.1155 s / img. ETA=0:01:42
[32m[04/28 22:48:43 d2.evaluation.evaluator]: [0mInference done 7520/8355. 0.1154 s / img. ETA=0:01:37
[32m[04/28 22:48:48 d2.evaluation.evaluator]: [0mInference done 7563/8355. 0.1154 s / img. ETA=0:01:32
[32m[04/28 22:48:53 d2.evaluation.evaluator]: [0mInference done 7606/8355. 0.1154 s / img. ETA=0:01:27
[32m[04/28 22:48:58 d2.evaluation.evaluator]: [0mInference done 7649/8355. 0.1155 s / img. ETA=0:01:22
[32m[04/28 22:49:03 d2.evaluation.evaluator]: [0mInference done 7692/8355. 0.1155 s / img. ETA=0:01:17
[32m[04/28 22:49:09 d2.evaluation.evaluator]: [0mInference done 7735/8355. 0.1155 s / img. ETA=0:01:12
[32m[04/28 22:49:14 d2.evaluation.evaluator]: [0mInference done 7778/8355. 0.1155 s / img. ETA=0:01:07
[32m[04/28 22:49:19 d2.evaluation.evaluator]: [0mInference done 7821/8355. 0.1155 s / img. ETA=0:01:02
[32m[04/28 22:49:24 d2.evaluation.evaluator]: [0mInference done 7864/8355. 0.1155 s / img. ETA=0:00:57
[32m[04/28 22:49:29 d2.evaluation.evaluator]: [0mInference done 7907/8355. 0.1155 s / img. ETA=0:00:52
[32m[04/28 22:49:34 d2.evaluation.evaluator]: [0mInference done 7950/8355. 0.1155 s / img. ETA=0:00:47
[32m[04/28 22:49:39 d2.evaluation.evaluator]: [0mInference done 7993/8355. 0.1155 s / img. ETA=0:00:42
[32m[04/28 22:49:44 d2.evaluation.evaluator]: [0mInference done 8036/8355. 0.1155 s / img. ETA=0:00:37
[32m[04/28 22:49:49 d2.evaluation.evaluator]: [0mInference done 8080/8355. 0.1155 s / img. ETA=0:00:32
[32m[04/28 22:49:54 d2.evaluation.evaluator]: [0mInference done 8124/8355. 0.1155 s / img. ETA=0:00:27
[32m[04/28 22:49:59 d2.evaluation.evaluator]: [0mInference done 8167/8355. 0.1155 s / img. ETA=0:00:22
[32m[04/28 22:50:04 d2.evaluation.evaluator]: [0mInference done 8210/8355. 0.1155 s / img. ETA=0:00:16
[32m[04/28 22:50:09 d2.evaluation.evaluator]: [0mInference done 8253/8355. 0.1155 s / img. ETA=0:00:11
[32m[04/28 22:50:14 d2.evaluation.evaluator]: [0mInference done 8296/8355. 0.1155 s / img. ETA=0:00:06
[32m[04/28 22:50:19 d2.evaluation.evaluator]: [0mInference done 8339/8355. 0.1155 s / img. ETA=0:00:01
[32m[04/28 22:50:21 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:18.638092 (0.117202 s / img per device, on 1 devices)
[32m[04/28 22:50:21 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:04 (0.115477 s / img per device, on 1 devices)
[32m[04/28 22:50:22 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 22:50:22 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 22:50:22 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.44s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.93s).
Accumulating evaluation results...
DONE (t=2.83s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.536
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.894
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.569
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.434
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.658
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.793
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.574
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.595
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.511
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.714
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.827
[32m[04/28 22:50:45 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.605 | 89.389 | 56.877 | 43.398 | 65.768 | 79.315 |
[32m[04/28 22:50:45 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 50.818 | bicycle       | 47.801 | car            | 62.196 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 22:50:46 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 22:50:46 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 22:50:46 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 22:50:47 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1154 s / img. ETA=0:02:25
[32m[04/28 22:50:52 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1149 s / img. ETA=0:02:20
[32m[04/28 22:50:57 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1150 s / img. ETA=0:02:15
[32m[04/28 22:51:02 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1149 s / img. ETA=0:02:10
[32m[04/28 22:51:07 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1149 s / img. ETA=0:02:05
[32m[04/28 22:51:12 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1149 s / img. ETA=0:02:00
[32m[04/28 22:51:17 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1149 s / img. ETA=0:01:55
[32m[04/28 22:51:22 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1149 s / img. ETA=0:01:50
[32m[04/28 22:51:27 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1149 s / img. ETA=0:01:45
[32m[04/28 22:51:32 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1149 s / img. ETA=0:01:40
[32m[04/28 22:51:37 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1149 s / img. ETA=0:01:35
[32m[04/28 22:51:42 d2.evaluation.evaluator]: [0mInference done 485/1257. 0.1149 s / img. ETA=0:01:29
[32m[04/28 22:51:47 d2.evaluation.evaluator]: [0mInference done 528/1257. 0.1149 s / img. ETA=0:01:25
[32m[04/28 22:51:52 d2.evaluation.evaluator]: [0mInference done 571/1257. 0.1149 s / img. ETA=0:01:20
[32m[04/28 22:51:57 d2.evaluation.evaluator]: [0mInference done 614/1257. 0.1149 s / img. ETA=0:01:14
[32m[04/28 22:52:02 d2.evaluation.evaluator]: [0mInference done 657/1257. 0.1150 s / img. ETA=0:01:09
[32m[04/28 22:52:07 d2.evaluation.evaluator]: [0mInference done 700/1257. 0.1150 s / img. ETA=0:01:04
[32m[04/28 22:52:12 d2.evaluation.evaluator]: [0mInference done 743/1257. 0.1150 s / img. ETA=0:00:59
[32m[04/28 22:52:17 d2.evaluation.evaluator]: [0mInference done 786/1257. 0.1150 s / img. ETA=0:00:54
[32m[04/28 22:52:23 d2.evaluation.evaluator]: [0mInference done 829/1257. 0.1150 s / img. ETA=0:00:49
[32m[04/28 22:52:28 d2.evaluation.evaluator]: [0mInference done 872/1257. 0.1151 s / img. ETA=0:00:44
[32m[04/28 22:52:33 d2.evaluation.evaluator]: [0mInference done 915/1257. 0.1151 s / img. ETA=0:00:39
[32m[04/28 22:52:38 d2.evaluation.evaluator]: [0mInference done 958/1257. 0.1151 s / img. ETA=0:00:34
[32m[04/28 22:52:43 d2.evaluation.evaluator]: [0mInference done 1001/1257. 0.1151 s / img. ETA=0:00:29
[32m[04/28 22:52:48 d2.evaluation.evaluator]: [0mInference done 1044/1257. 0.1151 s / img. ETA=0:00:24
[32m[04/28 22:52:53 d2.evaluation.evaluator]: [0mInference done 1087/1257. 0.1151 s / img. ETA=0:00:19
[32m[04/28 22:52:58 d2.evaluation.evaluator]: [0mInference done 1130/1257. 0.1151 s / img. ETA=0:00:14
[32m[04/28 22:53:03 d2.evaluation.evaluator]: [0mInference done 1173/1257. 0.1151 s / img. ETA=0:00:09
[32m[04/28 22:53:08 d2.evaluation.evaluator]: [0mInference done 1216/1257. 0.1152 s / img. ETA=0:00:04
[32m[04/28 22:53:13 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.365977 (0.116906 s / img per device, on 1 devices)
[32m[04/28 22:53:13 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115188 s / img per device, on 1 devices)
[32m[04/28 22:53:13 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 22:53:13 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 22:53:13 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.74s).
Accumulating evaluation results...
DONE (t=0.37s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.754
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.353
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.297
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.445
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.557
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.185
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.464
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.392
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.511
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.633
[32m[04/28 22:53:16 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.404 | 75.391 | 35.281 | 29.677 | 44.468 | 55.713 |
[32m[04/28 22:53:16 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 41.475 | bicycle       | 21.805 | car            | 54.933 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  35  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 22:53:17 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 22:53:17 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 22:53:17 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 22:53:17 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 22:53:18 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 22:53:18 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 22:53:18 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 22:53:38 d2.utils.events]: [0m eta: 0:16:38  iter: 19  total_loss: 0.464  loss_cls: 0.138  loss_box_reg: 0.278  loss_rpn_cls: 0.005  loss_rpn_loc: 0.038  time: 1.0288  data_time: 0.0182  lr: 0.000100  max_mem: 5397M
[32m[04/28 22:53:59 d2.utils.events]: [0m eta: 0:16:16  iter: 39  total_loss: 0.512  loss_cls: 0.157  loss_box_reg: 0.296  loss_rpn_cls: 0.007  loss_rpn_loc: 0.049  time: 1.0235  data_time: 0.0078  lr: 0.000200  max_mem: 5397M
[32m[04/28 22:54:19 d2.utils.events]: [0m eta: 0:15:58  iter: 59  total_loss: 0.445  loss_cls: 0.130  loss_box_reg: 0.253  loss_rpn_cls: 0.003  loss_rpn_loc: 0.040  time: 1.0265  data_time: 0.0079  lr: 0.000300  max_mem: 5397M
[32m[04/28 22:54:40 d2.utils.events]: [0m eta: 0:15:39  iter: 79  total_loss: 0.513  loss_cls: 0.153  loss_box_reg: 0.302  loss_rpn_cls: 0.005  loss_rpn_loc: 0.047  time: 1.0263  data_time: 0.0081  lr: 0.000400  max_mem: 5397M
[32m[04/28 22:55:01 d2.utils.events]: [0m eta: 0:15:27  iter: 99  total_loss: 0.435  loss_cls: 0.135  loss_box_reg: 0.250  loss_rpn_cls: 0.005  loss_rpn_loc: 0.045  time: 1.0313  data_time: 0.0079  lr: 0.000500  max_mem: 5397M
[32m[04/28 22:55:21 d2.utils.events]: [0m eta: 0:14:59  iter: 119  total_loss: 0.433  loss_cls: 0.132  loss_box_reg: 0.265  loss_rpn_cls: 0.006  loss_rpn_loc: 0.039  time: 1.0279  data_time: 0.0075  lr: 0.000599  max_mem: 5397M
[32m[04/28 22:55:42 d2.utils.events]: [0m eta: 0:14:46  iter: 139  total_loss: 0.475  loss_cls: 0.145  loss_box_reg: 0.276  loss_rpn_cls: 0.006  loss_rpn_loc: 0.051  time: 1.0299  data_time: 0.0078  lr: 0.000699  max_mem: 5397M
[32m[04/28 22:56:03 d2.utils.events]: [0m eta: 0:14:28  iter: 159  total_loss: 0.427  loss_cls: 0.133  loss_box_reg: 0.257  loss_rpn_cls: 0.004  loss_rpn_loc: 0.031  time: 1.0288  data_time: 0.0076  lr: 0.000799  max_mem: 5397M
[32m[04/28 22:56:23 d2.utils.events]: [0m eta: 0:14:00  iter: 179  total_loss: 0.408  loss_cls: 0.114  loss_box_reg: 0.256  loss_rpn_cls: 0.005  loss_rpn_loc: 0.034  time: 1.0253  data_time: 0.0078  lr: 0.000899  max_mem: 5397M
[32m[04/28 22:56:43 d2.utils.events]: [0m eta: 0:13:45  iter: 199  total_loss: 0.437  loss_cls: 0.135  loss_box_reg: 0.261  loss_rpn_cls: 0.004  loss_rpn_loc: 0.037  time: 1.0264  data_time: 0.0081  lr: 0.000999  max_mem: 5397M
[32m[04/28 22:57:04 d2.utils.events]: [0m eta: 0:13:27  iter: 219  total_loss: 0.468  loss_cls: 0.130  loss_box_reg: 0.274  loss_rpn_cls: 0.005  loss_rpn_loc: 0.045  time: 1.0274  data_time: 0.0078  lr: 0.001099  max_mem: 5397M
[32m[04/28 22:57:25 d2.utils.events]: [0m eta: 0:13:07  iter: 239  total_loss: 0.450  loss_cls: 0.139  loss_box_reg: 0.262  loss_rpn_cls: 0.005  loss_rpn_loc: 0.045  time: 1.0260  data_time: 0.0077  lr: 0.001199  max_mem: 5397M
[32m[04/28 22:57:45 d2.utils.events]: [0m eta: 0:12:46  iter: 259  total_loss: 0.457  loss_cls: 0.131  loss_box_reg: 0.266  loss_rpn_cls: 0.005  loss_rpn_loc: 0.035  time: 1.0260  data_time: 0.0075  lr: 0.001299  max_mem: 5397M
[32m[04/28 22:58:06 d2.utils.events]: [0m eta: 0:12:27  iter: 279  total_loss: 0.463  loss_cls: 0.142  loss_box_reg: 0.271  loss_rpn_cls: 0.004  loss_rpn_loc: 0.038  time: 1.0275  data_time: 0.0077  lr: 0.001399  max_mem: 5397M
[32m[04/28 22:58:27 d2.utils.events]: [0m eta: 0:12:07  iter: 299  total_loss: 0.454  loss_cls: 0.146  loss_box_reg: 0.262  loss_rpn_cls: 0.004  loss_rpn_loc: 0.041  time: 1.0276  data_time: 0.0077  lr: 0.001499  max_mem: 5397M
[32m[04/28 22:58:47 d2.utils.events]: [0m eta: 0:11:45  iter: 319  total_loss: 0.419  loss_cls: 0.125  loss_box_reg: 0.258  loss_rpn_cls: 0.004  loss_rpn_loc: 0.037  time: 1.0269  data_time: 0.0078  lr: 0.001598  max_mem: 5397M
[32m[04/28 22:59:08 d2.utils.events]: [0m eta: 0:11:25  iter: 339  total_loss: 0.385  loss_cls: 0.111  loss_box_reg: 0.247  loss_rpn_cls: 0.004  loss_rpn_loc: 0.037  time: 1.0276  data_time: 0.0079  lr: 0.001698  max_mem: 5397M
[32m[04/28 22:59:29 d2.utils.events]: [0m eta: 0:11:03  iter: 359  total_loss: 0.437  loss_cls: 0.126  loss_box_reg: 0.256  loss_rpn_cls: 0.004  loss_rpn_loc: 0.036  time: 1.0276  data_time: 0.0077  lr: 0.001798  max_mem: 5397M
[32m[04/28 22:59:49 d2.utils.events]: [0m eta: 0:10:43  iter: 379  total_loss: 0.450  loss_cls: 0.128  loss_box_reg: 0.269  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0278  data_time: 0.0079  lr: 0.001898  max_mem: 5397M
[32m[04/28 23:00:10 d2.utils.events]: [0m eta: 0:10:22  iter: 399  total_loss: 0.444  loss_cls: 0.128  loss_box_reg: 0.258  loss_rpn_cls: 0.005  loss_rpn_loc: 0.036  time: 1.0277  data_time: 0.0080  lr: 0.001998  max_mem: 5397M
[32m[04/28 23:00:30 d2.utils.events]: [0m eta: 0:10:00  iter: 419  total_loss: 0.497  loss_cls: 0.148  loss_box_reg: 0.283  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0265  data_time: 0.0077  lr: 0.002098  max_mem: 5397M
[32m[04/28 23:00:51 d2.utils.events]: [0m eta: 0:09:37  iter: 439  total_loss: 0.461  loss_cls: 0.134  loss_box_reg: 0.271  loss_rpn_cls: 0.003  loss_rpn_loc: 0.041  time: 1.0269  data_time: 0.0079  lr: 0.002198  max_mem: 5397M
[32m[04/28 23:01:11 d2.utils.events]: [0m eta: 0:09:15  iter: 459  total_loss: 0.459  loss_cls: 0.130  loss_box_reg: 0.273  loss_rpn_cls: 0.004  loss_rpn_loc: 0.044  time: 1.0264  data_time: 0.0078  lr: 0.002298  max_mem: 5397M
[32m[04/28 23:01:32 d2.utils.events]: [0m eta: 0:08:56  iter: 479  total_loss: 0.493  loss_cls: 0.147  loss_box_reg: 0.278  loss_rpn_cls: 0.005  loss_rpn_loc: 0.048  time: 1.0277  data_time: 0.0079  lr: 0.002398  max_mem: 5397M
[32m[04/28 23:01:52 d2.utils.events]: [0m eta: 0:08:34  iter: 499  total_loss: 0.369  loss_cls: 0.101  loss_box_reg: 0.217  loss_rpn_cls: 0.003  loss_rpn_loc: 0.037  time: 1.0267  data_time: 0.0076  lr: 0.002498  max_mem: 5397M
[32m[04/28 23:02:13 d2.utils.events]: [0m eta: 0:08:13  iter: 519  total_loss: 0.500  loss_cls: 0.142  loss_box_reg: 0.279  loss_rpn_cls: 0.007  loss_rpn_loc: 0.042  time: 1.0260  data_time: 0.0076  lr: 0.002597  max_mem: 5397M
[32m[04/28 23:02:34 d2.utils.events]: [0m eta: 0:07:56  iter: 539  total_loss: 0.450  loss_cls: 0.127  loss_box_reg: 0.285  loss_rpn_cls: 0.004  loss_rpn_loc: 0.038  time: 1.0272  data_time: 0.0078  lr: 0.002697  max_mem: 5397M
[32m[04/28 23:02:54 d2.utils.events]: [0m eta: 0:07:35  iter: 559  total_loss: 0.487  loss_cls: 0.147  loss_box_reg: 0.290  loss_rpn_cls: 0.006  loss_rpn_loc: 0.044  time: 1.0271  data_time: 0.0080  lr: 0.002797  max_mem: 5397M
[32m[04/28 23:03:15 d2.utils.events]: [0m eta: 0:07:15  iter: 579  total_loss: 0.422  loss_cls: 0.127  loss_box_reg: 0.260  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0278  data_time: 0.0079  lr: 0.002897  max_mem: 5397M
[32m[04/28 23:03:36 d2.utils.events]: [0m eta: 0:06:55  iter: 599  total_loss: 0.510  loss_cls: 0.143  loss_box_reg: 0.288  loss_rpn_cls: 0.006  loss_rpn_loc: 0.055  time: 1.0282  data_time: 0.0079  lr: 0.002997  max_mem: 5397M
[32m[04/28 23:03:57 d2.utils.events]: [0m eta: 0:06:33  iter: 619  total_loss: 0.443  loss_cls: 0.131  loss_box_reg: 0.258  loss_rpn_cls: 0.006  loss_rpn_loc: 0.039  time: 1.0281  data_time: 0.0079  lr: 0.003097  max_mem: 5397M
[32m[04/28 23:04:17 d2.utils.events]: [0m eta: 0:06:13  iter: 639  total_loss: 0.382  loss_cls: 0.108  loss_box_reg: 0.243  loss_rpn_cls: 0.004  loss_rpn_loc: 0.033  time: 1.0281  data_time: 0.0078  lr: 0.003197  max_mem: 5397M
[32m[04/28 23:04:38 d2.utils.events]: [0m eta: 0:05:52  iter: 659  total_loss: 0.434  loss_cls: 0.133  loss_box_reg: 0.256  loss_rpn_cls: 0.004  loss_rpn_loc: 0.033  time: 1.0276  data_time: 0.0077  lr: 0.003297  max_mem: 5397M
[32m[04/28 23:04:58 d2.utils.events]: [0m eta: 0:05:31  iter: 679  total_loss: 0.485  loss_cls: 0.130  loss_box_reg: 0.300  loss_rpn_cls: 0.003  loss_rpn_loc: 0.046  time: 1.0270  data_time: 0.0076  lr: 0.003397  max_mem: 5397M
[32m[04/28 23:05:18 d2.utils.events]: [0m eta: 0:05:10  iter: 699  total_loss: 0.416  loss_cls: 0.121  loss_box_reg: 0.249  loss_rpn_cls: 0.004  loss_rpn_loc: 0.036  time: 1.0269  data_time: 0.0077  lr: 0.003497  max_mem: 5397M
[32m[04/28 23:05:39 d2.utils.events]: [0m eta: 0:04:50  iter: 719  total_loss: 0.460  loss_cls: 0.131  loss_box_reg: 0.270  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0267  data_time: 0.0075  lr: 0.003596  max_mem: 5397M
[32m[04/28 23:06:00 d2.utils.events]: [0m eta: 0:04:29  iter: 739  total_loss: 0.441  loss_cls: 0.133  loss_box_reg: 0.265  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0272  data_time: 0.0076  lr: 0.003696  max_mem: 5397M
[32m[04/28 23:06:20 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.395  loss_cls: 0.120  loss_box_reg: 0.241  loss_rpn_cls: 0.003  loss_rpn_loc: 0.034  time: 1.0266  data_time: 0.0077  lr: 0.003796  max_mem: 5397M
[32m[04/28 23:06:41 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.438  loss_cls: 0.132  loss_box_reg: 0.273  loss_rpn_cls: 0.004  loss_rpn_loc: 0.040  time: 1.0269  data_time: 0.0078  lr: 0.003896  max_mem: 5397M
[32m[04/28 23:07:01 d2.utils.events]: [0m eta: 0:03:27  iter: 799  total_loss: 0.451  loss_cls: 0.135  loss_box_reg: 0.253  loss_rpn_cls: 0.004  loss_rpn_loc: 0.042  time: 1.0267  data_time: 0.0075  lr: 0.003996  max_mem: 5397M
[32m[04/28 23:07:22 d2.utils.events]: [0m eta: 0:03:06  iter: 819  total_loss: 0.407  loss_cls: 0.120  loss_box_reg: 0.259  loss_rpn_cls: 0.005  loss_rpn_loc: 0.042  time: 1.0270  data_time: 0.0078  lr: 0.004096  max_mem: 5397M
[32m[04/28 23:07:43 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.520  loss_cls: 0.159  loss_box_reg: 0.303  loss_rpn_cls: 0.005  loss_rpn_loc: 0.047  time: 1.0271  data_time: 0.0078  lr: 0.004196  max_mem: 5397M
[32m[04/28 23:08:04 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.470  loss_cls: 0.143  loss_box_reg: 0.273  loss_rpn_cls: 0.005  loss_rpn_loc: 0.041  time: 1.0276  data_time: 0.0077  lr: 0.004296  max_mem: 5397M
[32m[04/28 23:08:25 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.476  loss_cls: 0.142  loss_box_reg: 0.265  loss_rpn_cls: 0.006  loss_rpn_loc: 0.055  time: 1.0280  data_time: 0.0078  lr: 0.004396  max_mem: 5397M
[32m[04/28 23:08:45 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.470  loss_cls: 0.133  loss_box_reg: 0.277  loss_rpn_cls: 0.004  loss_rpn_loc: 0.049  time: 1.0273  data_time: 0.0077  lr: 0.004496  max_mem: 5397M
[32m[04/28 23:09:05 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.449  loss_cls: 0.132  loss_box_reg: 0.264  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 1.0272  data_time: 0.0078  lr: 0.004595  max_mem: 5397M
[32m[04/28 23:09:26 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.463  loss_cls: 0.138  loss_box_reg: 0.265  loss_rpn_cls: 0.004  loss_rpn_loc: 0.048  time: 1.0271  data_time: 0.0078  lr: 0.004695  max_mem: 5397M
[32m[04/28 23:09:46 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.397  loss_cls: 0.121  loss_box_reg: 0.238  loss_rpn_cls: 0.006  loss_rpn_loc: 0.038  time: 1.0271  data_time: 0.0078  lr: 0.004795  max_mem: 5397M
[32m[04/28 23:10:06 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.479  loss_cls: 0.146  loss_box_reg: 0.282  loss_rpn_cls: 0.005  loss_rpn_loc: 0.042  time: 1.0266  data_time: 0.0077  lr: 0.004895  max_mem: 5397M
[5m[31mWARNING[0m [32m[04/28 23:10:29 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 23:10:29 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/28 23:10:29 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/28 23:10:29 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.515  loss_cls: 0.155  loss_box_reg: 0.274  loss_rpn_cls: 0.005  loss_rpn_loc: 0.051  time: 1.0268  data_time: 0.0078  lr: 0.004995  max_mem: 5397M
[32m[04/28 23:10:30 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:04 (1.0278 s / it)
[32m[04/28 23:10:30 d2.engine.hooks]: [0mTotal training time: 0:17:10 (0:00:05 on hooks)
[5m[31mWARNING[0m [32m[04/28 23:10:31 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 23:10:31 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 23:10:32 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/28 23:10:33 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1145 s / img. ETA=0:16:07
[32m[04/28 23:10:38 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1139 s / img. ETA=0:15:59
[32m[04/28 23:10:43 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1138 s / img. ETA=0:15:52
[32m[04/28 23:10:48 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1138 s / img. ETA=0:15:47
[32m[04/28 23:10:53 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1137 s / img. ETA=0:15:42
[32m[04/28 23:10:59 d2.evaluation.evaluator]: [0mInference done 231/8355. 0.1138 s / img. ETA=0:15:38
[32m[04/28 23:11:04 d2.evaluation.evaluator]: [0mInference done 275/8355. 0.1139 s / img. ETA=0:15:33
[32m[04/28 23:11:09 d2.evaluation.evaluator]: [0mInference done 319/8355. 0.1139 s / img. ETA=0:15:29
[32m[04/28 23:11:14 d2.evaluation.evaluator]: [0mInference done 363/8355. 0.1139 s / img. ETA=0:15:24
[32m[04/28 23:11:19 d2.evaluation.evaluator]: [0mInference done 407/8355. 0.1140 s / img. ETA=0:15:19
[32m[04/28 23:11:24 d2.evaluation.evaluator]: [0mInference done 451/8355. 0.1140 s / img. ETA=0:15:14
[32m[04/28 23:11:29 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1140 s / img. ETA=0:15:09
[32m[04/28 23:11:34 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1139 s / img. ETA=0:15:03
[32m[04/28 23:11:39 d2.evaluation.evaluator]: [0mInference done 583/8355. 0.1139 s / img. ETA=0:14:58
[32m[04/28 23:11:44 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1139 s / img. ETA=0:14:53
[32m[04/28 23:11:50 d2.evaluation.evaluator]: [0mInference done 671/8355. 0.1139 s / img. ETA=0:14:48
[32m[04/28 23:11:55 d2.evaluation.evaluator]: [0mInference done 715/8355. 0.1139 s / img. ETA=0:14:43
[32m[04/28 23:12:00 d2.evaluation.evaluator]: [0mInference done 759/8355. 0.1139 s / img. ETA=0:14:38
[32m[04/28 23:12:05 d2.evaluation.evaluator]: [0mInference done 802/8355. 0.1140 s / img. ETA=0:14:33
[32m[04/28 23:12:10 d2.evaluation.evaluator]: [0mInference done 845/8355. 0.1141 s / img. ETA=0:14:29
[32m[04/28 23:12:15 d2.evaluation.evaluator]: [0mInference done 888/8355. 0.1141 s / img. ETA=0:14:24
[32m[04/28 23:12:20 d2.evaluation.evaluator]: [0mInference done 931/8355. 0.1141 s / img. ETA=0:14:20
[32m[04/28 23:12:25 d2.evaluation.evaluator]: [0mInference done 974/8355. 0.1142 s / img. ETA=0:14:15
[32m[04/28 23:12:30 d2.evaluation.evaluator]: [0mInference done 1017/8355. 0.1142 s / img. ETA=0:14:10
[32m[04/28 23:12:35 d2.evaluation.evaluator]: [0mInference done 1061/8355. 0.1142 s / img. ETA=0:14:05
[32m[04/28 23:12:40 d2.evaluation.evaluator]: [0mInference done 1105/8355. 0.1141 s / img. ETA=0:13:59
[32m[04/28 23:12:45 d2.evaluation.evaluator]: [0mInference done 1149/8355. 0.1141 s / img. ETA=0:13:54
[32m[04/28 23:12:50 d2.evaluation.evaluator]: [0mInference done 1193/8355. 0.1141 s / img. ETA=0:13:49
[32m[04/28 23:12:55 d2.evaluation.evaluator]: [0mInference done 1237/8355. 0.1141 s / img. ETA=0:13:44
[32m[04/28 23:13:00 d2.evaluation.evaluator]: [0mInference done 1281/8355. 0.1140 s / img. ETA=0:13:38
[32m[04/28 23:13:05 d2.evaluation.evaluator]: [0mInference done 1325/8355. 0.1140 s / img. ETA=0:13:33
[32m[04/28 23:13:10 d2.evaluation.evaluator]: [0mInference done 1369/8355. 0.1140 s / img. ETA=0:13:28
[32m[04/28 23:13:15 d2.evaluation.evaluator]: [0mInference done 1413/8355. 0.1140 s / img. ETA=0:13:23
[32m[04/28 23:13:20 d2.evaluation.evaluator]: [0mInference done 1456/8355. 0.1140 s / img. ETA=0:13:18
[32m[04/28 23:13:25 d2.evaluation.evaluator]: [0mInference done 1499/8355. 0.1141 s / img. ETA=0:13:13
[32m[04/28 23:13:31 d2.evaluation.evaluator]: [0mInference done 1542/8355. 0.1141 s / img. ETA=0:13:09
[32m[04/28 23:13:36 d2.evaluation.evaluator]: [0mInference done 1585/8355. 0.1142 s / img. ETA=0:13:04
[32m[04/28 23:13:41 d2.evaluation.evaluator]: [0mInference done 1628/8355. 0.1143 s / img. ETA=0:13:00
[32m[04/28 23:13:46 d2.evaluation.evaluator]: [0mInference done 1671/8355. 0.1143 s / img. ETA=0:12:55
[32m[04/28 23:13:51 d2.evaluation.evaluator]: [0mInference done 1714/8355. 0.1143 s / img. ETA=0:12:50
[32m[04/28 23:13:56 d2.evaluation.evaluator]: [0mInference done 1757/8355. 0.1144 s / img. ETA=0:12:46
[32m[04/28 23:14:01 d2.evaluation.evaluator]: [0mInference done 1800/8355. 0.1144 s / img. ETA=0:12:41
[32m[04/28 23:14:06 d2.evaluation.evaluator]: [0mInference done 1843/8355. 0.1144 s / img. ETA=0:12:36
[32m[04/28 23:14:11 d2.evaluation.evaluator]: [0mInference done 1886/8355. 0.1145 s / img. ETA=0:12:31
[32m[04/28 23:14:16 d2.evaluation.evaluator]: [0mInference done 1929/8355. 0.1145 s / img. ETA=0:12:26
[32m[04/28 23:14:21 d2.evaluation.evaluator]: [0mInference done 1972/8355. 0.1146 s / img. ETA=0:12:22
[32m[04/28 23:14:26 d2.evaluation.evaluator]: [0mInference done 2015/8355. 0.1146 s / img. ETA=0:12:17
[32m[04/28 23:14:31 d2.evaluation.evaluator]: [0mInference done 2058/8355. 0.1146 s / img. ETA=0:12:12
[32m[04/28 23:14:36 d2.evaluation.evaluator]: [0mInference done 2101/8355. 0.1146 s / img. ETA=0:12:07
[32m[04/28 23:14:41 d2.evaluation.evaluator]: [0mInference done 2145/8355. 0.1146 s / img. ETA=0:12:02
[32m[04/28 23:14:47 d2.evaluation.evaluator]: [0mInference done 2188/8355. 0.1146 s / img. ETA=0:11:57
[32m[04/28 23:14:52 d2.evaluation.evaluator]: [0mInference done 2231/8355. 0.1147 s / img. ETA=0:11:52
[32m[04/28 23:14:57 d2.evaluation.evaluator]: [0mInference done 2274/8355. 0.1147 s / img. ETA=0:11:47
[32m[04/28 23:15:02 d2.evaluation.evaluator]: [0mInference done 2317/8355. 0.1147 s / img. ETA=0:11:43
[32m[04/28 23:15:07 d2.evaluation.evaluator]: [0mInference done 2360/8355. 0.1147 s / img. ETA=0:11:38
[32m[04/28 23:15:12 d2.evaluation.evaluator]: [0mInference done 2403/8355. 0.1148 s / img. ETA=0:11:33
[32m[04/28 23:15:17 d2.evaluation.evaluator]: [0mInference done 2446/8355. 0.1148 s / img. ETA=0:11:28
[32m[04/28 23:15:22 d2.evaluation.evaluator]: [0mInference done 2489/8355. 0.1148 s / img. ETA=0:11:23
[32m[04/28 23:15:27 d2.evaluation.evaluator]: [0mInference done 2532/8355. 0.1148 s / img. ETA=0:11:18
[32m[04/28 23:15:32 d2.evaluation.evaluator]: [0mInference done 2575/8355. 0.1148 s / img. ETA=0:11:13
[32m[04/28 23:15:37 d2.evaluation.evaluator]: [0mInference done 2618/8355. 0.1148 s / img. ETA=0:11:08
[32m[04/28 23:15:42 d2.evaluation.evaluator]: [0mInference done 2661/8355. 0.1149 s / img. ETA=0:11:03
[32m[04/28 23:15:47 d2.evaluation.evaluator]: [0mInference done 2704/8355. 0.1149 s / img. ETA=0:10:58
[32m[04/28 23:15:52 d2.evaluation.evaluator]: [0mInference done 2747/8355. 0.1149 s / img. ETA=0:10:53
[32m[04/28 23:15:57 d2.evaluation.evaluator]: [0mInference done 2789/8355. 0.1149 s / img. ETA=0:10:49
[32m[04/28 23:16:02 d2.evaluation.evaluator]: [0mInference done 2832/8355. 0.1149 s / img. ETA=0:10:44
[32m[04/28 23:16:07 d2.evaluation.evaluator]: [0mInference done 2875/8355. 0.1150 s / img. ETA=0:10:39
[32m[04/28 23:16:12 d2.evaluation.evaluator]: [0mInference done 2918/8355. 0.1150 s / img. ETA=0:10:34
[32m[04/28 23:16:17 d2.evaluation.evaluator]: [0mInference done 2961/8355. 0.1150 s / img. ETA=0:10:29
[32m[04/28 23:16:22 d2.evaluation.evaluator]: [0mInference done 3004/8355. 0.1150 s / img. ETA=0:10:24
[32m[04/28 23:16:27 d2.evaluation.evaluator]: [0mInference done 3047/8355. 0.1150 s / img. ETA=0:10:19
[32m[04/28 23:16:32 d2.evaluation.evaluator]: [0mInference done 3090/8355. 0.1150 s / img. ETA=0:10:14
[32m[04/28 23:16:38 d2.evaluation.evaluator]: [0mInference done 3133/8355. 0.1150 s / img. ETA=0:10:09
[32m[04/28 23:16:43 d2.evaluation.evaluator]: [0mInference done 3176/8355. 0.1150 s / img. ETA=0:10:04
[32m[04/28 23:16:48 d2.evaluation.evaluator]: [0mInference done 3220/8355. 0.1150 s / img. ETA=0:09:59
[32m[04/28 23:16:53 d2.evaluation.evaluator]: [0mInference done 3263/8355. 0.1150 s / img. ETA=0:09:54
[32m[04/28 23:16:58 d2.evaluation.evaluator]: [0mInference done 3306/8355. 0.1150 s / img. ETA=0:09:49
[32m[04/28 23:17:03 d2.evaluation.evaluator]: [0mInference done 3350/8355. 0.1150 s / img. ETA=0:09:43
[32m[04/28 23:17:08 d2.evaluation.evaluator]: [0mInference done 3393/8355. 0.1150 s / img. ETA=0:09:38
[32m[04/28 23:17:13 d2.evaluation.evaluator]: [0mInference done 3436/8355. 0.1150 s / img. ETA=0:09:33
[32m[04/28 23:17:18 d2.evaluation.evaluator]: [0mInference done 3479/8355. 0.1150 s / img. ETA=0:09:28
[32m[04/28 23:17:23 d2.evaluation.evaluator]: [0mInference done 3522/8355. 0.1150 s / img. ETA=0:09:23
[32m[04/28 23:17:28 d2.evaluation.evaluator]: [0mInference done 3565/8355. 0.1150 s / img. ETA=0:09:18
[32m[04/28 23:17:33 d2.evaluation.evaluator]: [0mInference done 3608/8355. 0.1150 s / img. ETA=0:09:13
[32m[04/28 23:17:38 d2.evaluation.evaluator]: [0mInference done 3651/8355. 0.1150 s / img. ETA=0:09:08
[32m[04/28 23:17:43 d2.evaluation.evaluator]: [0mInference done 3694/8355. 0.1150 s / img. ETA=0:09:03
[32m[04/28 23:17:48 d2.evaluation.evaluator]: [0mInference done 3737/8355. 0.1150 s / img. ETA=0:08:58
[32m[04/28 23:17:53 d2.evaluation.evaluator]: [0mInference done 3780/8355. 0.1150 s / img. ETA=0:08:53
[32m[04/28 23:17:58 d2.evaluation.evaluator]: [0mInference done 3823/8355. 0.1150 s / img. ETA=0:08:48
[32m[04/28 23:18:03 d2.evaluation.evaluator]: [0mInference done 3866/8355. 0.1150 s / img. ETA=0:08:43
[32m[04/28 23:18:08 d2.evaluation.evaluator]: [0mInference done 3910/8355. 0.1150 s / img. ETA=0:08:38
[32m[04/28 23:18:13 d2.evaluation.evaluator]: [0mInference done 3954/8355. 0.1150 s / img. ETA=0:08:33
[32m[04/28 23:18:18 d2.evaluation.evaluator]: [0mInference done 3997/8355. 0.1150 s / img. ETA=0:08:28
[32m[04/28 23:18:23 d2.evaluation.evaluator]: [0mInference done 4040/8355. 0.1150 s / img. ETA=0:08:23
[32m[04/28 23:18:28 d2.evaluation.evaluator]: [0mInference done 4083/8355. 0.1150 s / img. ETA=0:08:18
[32m[04/28 23:18:33 d2.evaluation.evaluator]: [0mInference done 4126/8355. 0.1150 s / img. ETA=0:08:13
[32m[04/28 23:18:38 d2.evaluation.evaluator]: [0mInference done 4169/8355. 0.1150 s / img. ETA=0:08:08
[32m[04/28 23:18:43 d2.evaluation.evaluator]: [0mInference done 4212/8355. 0.1150 s / img. ETA=0:08:03
[32m[04/28 23:18:48 d2.evaluation.evaluator]: [0mInference done 4255/8355. 0.1150 s / img. ETA=0:07:58
[32m[04/28 23:18:54 d2.evaluation.evaluator]: [0mInference done 4299/8355. 0.1150 s / img. ETA=0:07:53
[32m[04/28 23:18:59 d2.evaluation.evaluator]: [0mInference done 4342/8355. 0.1150 s / img. ETA=0:07:48
[32m[04/28 23:19:04 d2.evaluation.evaluator]: [0mInference done 4385/8355. 0.1150 s / img. ETA=0:07:43
[32m[04/28 23:19:09 d2.evaluation.evaluator]: [0mInference done 4428/8355. 0.1150 s / img. ETA=0:07:38
[32m[04/28 23:19:14 d2.evaluation.evaluator]: [0mInference done 4471/8355. 0.1150 s / img. ETA=0:07:33
[32m[04/28 23:19:19 d2.evaluation.evaluator]: [0mInference done 4514/8355. 0.1150 s / img. ETA=0:07:28
[32m[04/28 23:19:24 d2.evaluation.evaluator]: [0mInference done 4557/8355. 0.1150 s / img. ETA=0:07:23
[32m[04/28 23:19:29 d2.evaluation.evaluator]: [0mInference done 4600/8355. 0.1150 s / img. ETA=0:07:18
[32m[04/28 23:19:34 d2.evaluation.evaluator]: [0mInference done 4643/8355. 0.1150 s / img. ETA=0:07:13
[32m[04/28 23:19:39 d2.evaluation.evaluator]: [0mInference done 4686/8355. 0.1150 s / img. ETA=0:07:08
[32m[04/28 23:19:44 d2.evaluation.evaluator]: [0mInference done 4730/8355. 0.1150 s / img. ETA=0:07:03
[32m[04/28 23:19:49 d2.evaluation.evaluator]: [0mInference done 4773/8355. 0.1150 s / img. ETA=0:06:58
[32m[04/28 23:19:54 d2.evaluation.evaluator]: [0mInference done 4816/8355. 0.1150 s / img. ETA=0:06:53
[32m[04/28 23:19:59 d2.evaluation.evaluator]: [0mInference done 4859/8355. 0.1150 s / img. ETA=0:06:48
[32m[04/28 23:20:04 d2.evaluation.evaluator]: [0mInference done 4902/8355. 0.1150 s / img. ETA=0:06:43
[32m[04/28 23:20:09 d2.evaluation.evaluator]: [0mInference done 4945/8355. 0.1150 s / img. ETA=0:06:38
[32m[04/28 23:20:14 d2.evaluation.evaluator]: [0mInference done 4988/8355. 0.1150 s / img. ETA=0:06:33
[32m[04/28 23:20:19 d2.evaluation.evaluator]: [0mInference done 5031/8355. 0.1150 s / img. ETA=0:06:28
[32m[04/28 23:20:24 d2.evaluation.evaluator]: [0mInference done 5074/8355. 0.1150 s / img. ETA=0:06:23
[32m[04/28 23:20:29 d2.evaluation.evaluator]: [0mInference done 5117/8355. 0.1151 s / img. ETA=0:06:18
[32m[04/28 23:20:34 d2.evaluation.evaluator]: [0mInference done 5160/8355. 0.1151 s / img. ETA=0:06:13
[32m[04/28 23:20:40 d2.evaluation.evaluator]: [0mInference done 5203/8355. 0.1151 s / img. ETA=0:06:08
[32m[04/28 23:20:45 d2.evaluation.evaluator]: [0mInference done 5246/8355. 0.1151 s / img. ETA=0:06:03
[32m[04/28 23:20:50 d2.evaluation.evaluator]: [0mInference done 5289/8355. 0.1151 s / img. ETA=0:05:58
[32m[04/28 23:20:55 d2.evaluation.evaluator]: [0mInference done 5332/8355. 0.1151 s / img. ETA=0:05:53
[32m[04/28 23:21:00 d2.evaluation.evaluator]: [0mInference done 5375/8355. 0.1151 s / img. ETA=0:05:48
[32m[04/28 23:21:05 d2.evaluation.evaluator]: [0mInference done 5418/8355. 0.1151 s / img. ETA=0:05:43
[32m[04/28 23:21:10 d2.evaluation.evaluator]: [0mInference done 5461/8355. 0.1151 s / img. ETA=0:05:38
[32m[04/28 23:21:15 d2.evaluation.evaluator]: [0mInference done 5505/8355. 0.1151 s / img. ETA=0:05:32
[32m[04/28 23:21:20 d2.evaluation.evaluator]: [0mInference done 5549/8355. 0.1151 s / img. ETA=0:05:27
[32m[04/28 23:21:25 d2.evaluation.evaluator]: [0mInference done 5592/8355. 0.1151 s / img. ETA=0:05:22
[32m[04/28 23:21:30 d2.evaluation.evaluator]: [0mInference done 5635/8355. 0.1151 s / img. ETA=0:05:17
[32m[04/28 23:21:35 d2.evaluation.evaluator]: [0mInference done 5678/8355. 0.1151 s / img. ETA=0:05:12
[32m[04/28 23:21:40 d2.evaluation.evaluator]: [0mInference done 5721/8355. 0.1151 s / img. ETA=0:05:07
[32m[04/28 23:21:45 d2.evaluation.evaluator]: [0mInference done 5764/8355. 0.1151 s / img. ETA=0:05:02
[32m[04/28 23:21:50 d2.evaluation.evaluator]: [0mInference done 5807/8355. 0.1151 s / img. ETA=0:04:57
[32m[04/28 23:21:55 d2.evaluation.evaluator]: [0mInference done 5850/8355. 0.1151 s / img. ETA=0:04:52
[32m[04/28 23:22:00 d2.evaluation.evaluator]: [0mInference done 5893/8355. 0.1151 s / img. ETA=0:04:47
[32m[04/28 23:22:05 d2.evaluation.evaluator]: [0mInference done 5935/8355. 0.1151 s / img. ETA=0:04:42
[32m[04/28 23:22:10 d2.evaluation.evaluator]: [0mInference done 5977/8355. 0.1152 s / img. ETA=0:04:37
[32m[04/28 23:22:16 d2.evaluation.evaluator]: [0mInference done 6020/8355. 0.1152 s / img. ETA=0:04:32
[32m[04/28 23:22:21 d2.evaluation.evaluator]: [0mInference done 6063/8355. 0.1152 s / img. ETA=0:04:27
[32m[04/28 23:22:26 d2.evaluation.evaluator]: [0mInference done 6106/8355. 0.1152 s / img. ETA=0:04:22
[32m[04/28 23:22:31 d2.evaluation.evaluator]: [0mInference done 6149/8355. 0.1152 s / img. ETA=0:04:17
[32m[04/28 23:22:36 d2.evaluation.evaluator]: [0mInference done 6192/8355. 0.1152 s / img. ETA=0:04:12
[32m[04/28 23:22:41 d2.evaluation.evaluator]: [0mInference done 6234/8355. 0.1152 s / img. ETA=0:04:08
[32m[04/28 23:22:46 d2.evaluation.evaluator]: [0mInference done 6277/8355. 0.1152 s / img. ETA=0:04:03
[32m[04/28 23:22:51 d2.evaluation.evaluator]: [0mInference done 6320/8355. 0.1152 s / img. ETA=0:03:58
[32m[04/28 23:22:56 d2.evaluation.evaluator]: [0mInference done 6363/8355. 0.1152 s / img. ETA=0:03:53
[32m[04/28 23:23:01 d2.evaluation.evaluator]: [0mInference done 6406/8355. 0.1152 s / img. ETA=0:03:47
[32m[04/28 23:23:06 d2.evaluation.evaluator]: [0mInference done 6448/8355. 0.1153 s / img. ETA=0:03:43
[32m[04/28 23:23:11 d2.evaluation.evaluator]: [0mInference done 6491/8355. 0.1153 s / img. ETA=0:03:38
[32m[04/28 23:23:16 d2.evaluation.evaluator]: [0mInference done 6535/8355. 0.1153 s / img. ETA=0:03:32
[32m[04/28 23:23:21 d2.evaluation.evaluator]: [0mInference done 6578/8355. 0.1153 s / img. ETA=0:03:27
[32m[04/28 23:23:26 d2.evaluation.evaluator]: [0mInference done 6621/8355. 0.1153 s / img. ETA=0:03:22
[32m[04/28 23:23:32 d2.evaluation.evaluator]: [0mInference done 6665/8355. 0.1152 s / img. ETA=0:03:17
[32m[04/28 23:23:37 d2.evaluation.evaluator]: [0mInference done 6708/8355. 0.1152 s / img. ETA=0:03:12
[32m[04/28 23:23:42 d2.evaluation.evaluator]: [0mInference done 6752/8355. 0.1152 s / img. ETA=0:03:07
[32m[04/28 23:23:47 d2.evaluation.evaluator]: [0mInference done 6796/8355. 0.1152 s / img. ETA=0:03:02
[32m[04/28 23:23:52 d2.evaluation.evaluator]: [0mInference done 6839/8355. 0.1152 s / img. ETA=0:02:57
[32m[04/28 23:23:57 d2.evaluation.evaluator]: [0mInference done 6882/8355. 0.1152 s / img. ETA=0:02:52
[32m[04/28 23:24:02 d2.evaluation.evaluator]: [0mInference done 6925/8355. 0.1152 s / img. ETA=0:02:47
[32m[04/28 23:24:07 d2.evaluation.evaluator]: [0mInference done 6968/8355. 0.1152 s / img. ETA=0:02:42
[32m[04/28 23:24:12 d2.evaluation.evaluator]: [0mInference done 7011/8355. 0.1152 s / img. ETA=0:02:37
[32m[04/28 23:24:17 d2.evaluation.evaluator]: [0mInference done 7054/8355. 0.1152 s / img. ETA=0:02:32
[32m[04/28 23:24:22 d2.evaluation.evaluator]: [0mInference done 7097/8355. 0.1152 s / img. ETA=0:02:27
[32m[04/28 23:24:27 d2.evaluation.evaluator]: [0mInference done 7140/8355. 0.1152 s / img. ETA=0:02:22
[32m[04/28 23:24:32 d2.evaluation.evaluator]: [0mInference done 7183/8355. 0.1153 s / img. ETA=0:02:17
[32m[04/28 23:24:37 d2.evaluation.evaluator]: [0mInference done 7225/8355. 0.1153 s / img. ETA=0:02:12
[32m[04/28 23:24:42 d2.evaluation.evaluator]: [0mInference done 7268/8355. 0.1153 s / img. ETA=0:02:07
[32m[04/28 23:24:47 d2.evaluation.evaluator]: [0mInference done 7311/8355. 0.1153 s / img. ETA=0:02:02
[32m[04/28 23:24:52 d2.evaluation.evaluator]: [0mInference done 7354/8355. 0.1153 s / img. ETA=0:01:57
[32m[04/28 23:24:58 d2.evaluation.evaluator]: [0mInference done 7397/8355. 0.1153 s / img. ETA=0:01:52
[32m[04/28 23:25:03 d2.evaluation.evaluator]: [0mInference done 7440/8355. 0.1153 s / img. ETA=0:01:47
[32m[04/28 23:25:08 d2.evaluation.evaluator]: [0mInference done 7483/8355. 0.1153 s / img. ETA=0:01:42
[32m[04/28 23:25:13 d2.evaluation.evaluator]: [0mInference done 7526/8355. 0.1153 s / img. ETA=0:01:37
[32m[04/28 23:25:18 d2.evaluation.evaluator]: [0mInference done 7569/8355. 0.1153 s / img. ETA=0:01:32
[32m[04/28 23:25:23 d2.evaluation.evaluator]: [0mInference done 7612/8355. 0.1153 s / img. ETA=0:01:26
[32m[04/28 23:25:28 d2.evaluation.evaluator]: [0mInference done 7655/8355. 0.1153 s / img. ETA=0:01:21
[32m[04/28 23:25:33 d2.evaluation.evaluator]: [0mInference done 7698/8355. 0.1153 s / img. ETA=0:01:16
[32m[04/28 23:25:38 d2.evaluation.evaluator]: [0mInference done 7741/8355. 0.1153 s / img. ETA=0:01:11
[32m[04/28 23:25:43 d2.evaluation.evaluator]: [0mInference done 7784/8355. 0.1153 s / img. ETA=0:01:06
[32m[04/28 23:25:48 d2.evaluation.evaluator]: [0mInference done 7827/8355. 0.1153 s / img. ETA=0:01:01
[32m[04/28 23:25:53 d2.evaluation.evaluator]: [0mInference done 7870/8355. 0.1153 s / img. ETA=0:00:56
[32m[04/28 23:25:58 d2.evaluation.evaluator]: [0mInference done 7913/8355. 0.1154 s / img. ETA=0:00:51
[32m[04/28 23:26:03 d2.evaluation.evaluator]: [0mInference done 7955/8355. 0.1154 s / img. ETA=0:00:46
[32m[04/28 23:26:09 d2.evaluation.evaluator]: [0mInference done 7998/8355. 0.1154 s / img. ETA=0:00:41
[32m[04/28 23:26:14 d2.evaluation.evaluator]: [0mInference done 8041/8355. 0.1154 s / img. ETA=0:00:36
[32m[04/28 23:26:19 d2.evaluation.evaluator]: [0mInference done 8085/8355. 0.1154 s / img. ETA=0:00:31
[32m[04/28 23:26:24 d2.evaluation.evaluator]: [0mInference done 8128/8355. 0.1154 s / img. ETA=0:00:26
[32m[04/28 23:26:29 d2.evaluation.evaluator]: [0mInference done 8171/8355. 0.1154 s / img. ETA=0:00:21
[32m[04/28 23:26:34 d2.evaluation.evaluator]: [0mInference done 8214/8355. 0.1153 s / img. ETA=0:00:16
[32m[04/28 23:26:39 d2.evaluation.evaluator]: [0mInference done 8257/8355. 0.1154 s / img. ETA=0:00:11
[32m[04/28 23:26:44 d2.evaluation.evaluator]: [0mInference done 8300/8355. 0.1154 s / img. ETA=0:00:06
[32m[04/28 23:26:49 d2.evaluation.evaluator]: [0mInference done 8343/8355. 0.1154 s / img. ETA=0:00:01
[32m[04/28 23:26:50 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:17.912680 (0.117115 s / img per device, on 1 devices)
[32m[04/28 23:26:50 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:03 (0.115368 s / img per device, on 1 devices)
[32m[04/28 23:26:51 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 23:26:51 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 23:26:51 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.43s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.28s).
Accumulating evaluation results...
DONE (t=2.12s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.491
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.849
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.503
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.384
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.743
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.534
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.549
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.455
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782
[32m[04/28 23:27:13 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.138 | 84.909 | 50.274 | 38.448 | 61.842 | 74.288 |
[32m[04/28 23:27:13 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 48.327 | bicycle       | 42.565 | car            | 56.523 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
[5m[31mWARNING[0m [32m[04/28 23:27:13 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 23:27:13 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 23:27:13 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/28 23:27:15 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1161 s / img. ETA=0:02:26
[32m[04/28 23:27:20 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1152 s / img. ETA=0:02:20
[32m[04/28 23:27:25 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1151 s / img. ETA=0:02:15
[32m[04/28 23:27:30 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1152 s / img. ETA=0:02:10
[32m[04/28 23:27:35 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1152 s / img. ETA=0:02:05
[32m[04/28 23:27:40 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1152 s / img. ETA=0:02:00
[32m[04/28 23:27:45 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1153 s / img. ETA=0:01:55
[32m[04/28 23:27:50 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1153 s / img. ETA=0:01:50
[32m[04/28 23:27:55 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1153 s / img. ETA=0:01:45
[32m[04/28 23:28:00 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1152 s / img. ETA=0:01:40
[32m[04/28 23:28:05 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1152 s / img. ETA=0:01:35
[32m[04/28 23:28:10 d2.evaluation.evaluator]: [0mInference done 484/1257. 0.1152 s / img. ETA=0:01:30
[32m[04/28 23:28:15 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1152 s / img. ETA=0:01:25
[32m[04/28 23:28:20 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1152 s / img. ETA=0:01:20
[32m[04/28 23:28:25 d2.evaluation.evaluator]: [0mInference done 613/1257. 0.1152 s / img. ETA=0:01:15
[32m[04/28 23:28:30 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1152 s / img. ETA=0:01:10
[32m[04/28 23:28:35 d2.evaluation.evaluator]: [0mInference done 699/1257. 0.1153 s / img. ETA=0:01:05
[32m[04/28 23:28:40 d2.evaluation.evaluator]: [0mInference done 742/1257. 0.1153 s / img. ETA=0:01:00
[32m[04/28 23:28:45 d2.evaluation.evaluator]: [0mInference done 785/1257. 0.1153 s / img. ETA=0:00:55
[32m[04/28 23:28:50 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1153 s / img. ETA=0:00:50
[32m[04/28 23:28:55 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1153 s / img. ETA=0:00:45
[32m[04/28 23:29:01 d2.evaluation.evaluator]: [0mInference done 914/1257. 0.1154 s / img. ETA=0:00:40
[32m[04/28 23:29:06 d2.evaluation.evaluator]: [0mInference done 957/1257. 0.1154 s / img. ETA=0:00:35
[32m[04/28 23:29:11 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1154 s / img. ETA=0:00:30
[32m[04/28 23:29:16 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1154 s / img. ETA=0:00:25
[32m[04/28 23:29:21 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1154 s / img. ETA=0:00:20
[32m[04/28 23:29:26 d2.evaluation.evaluator]: [0mInference done 1129/1257. 0.1155 s / img. ETA=0:00:15
[32m[04/28 23:29:31 d2.evaluation.evaluator]: [0mInference done 1172/1257. 0.1155 s / img. ETA=0:00:09
[32m[04/28 23:29:36 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1155 s / img. ETA=0:00:04
[32m[04/28 23:29:41 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:26.824632 (0.117272 s / img per device, on 1 devices)
[32m[04/28 23:29:41 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:24 (0.115490 s / img per device, on 1 devices)
[32m[04/28 23:29:41 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/28 23:29:41 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_RGBT_sum/coco_instances_results.json
[32m[04/28 23:29:41 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.65s).
Accumulating evaluation results...
DONE (t=0.36s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.385
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.716
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.353
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.430
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.548
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.451
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.387
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.492
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.606
[32m[04/28 23:29:44 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 38.460 | 71.620 | 35.315 | 29.219 | 42.991 | 54.800 |
[32m[04/28 23:29:44 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 45.802 | bicycle       | 17.614 | car            | 51.963 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  36  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
4  channel input
[32m[04/28 23:29:45 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=18, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=68, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/28 23:29:45 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/28 23:29:45 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/28 23:29:46 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/28 23:29:46 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/28 23:29:46 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/28 23:29:46 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/28 23:30:06 d2.utils.events]: [0m eta: 0:16:30  iter: 19  total_loss: 0.522  loss_cls: 0.163  loss_box_reg: 0.308  loss_rpn_cls: 0.008  loss_rpn_loc: 0.042  time: 1.0102  data_time: 0.0225  lr: 0.000100  max_mem: 5397M
[32m[04/28 23:30:27 d2.utils.events]: [0m eta: 0:16:21  iter: 39  total_loss: 0.435  loss_cls: 0.141  loss_box_reg: 0.265  loss_rpn_cls: 0.004  loss_rpn_loc: 0.036  time: 1.0226  data_time: 0.0077  lr: 0.000200  max_mem: 5397M
[32m[04/28 23:30:47 d2.utils.events]: [0m eta: 0:16:00  iter: 59  total_loss: 0.486  loss_cls: 0.144  loss_box_reg: 0.286  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 1.0197  data_time: 0.0077  lr: 0.000300  max_mem: 5397M
[32m[04/28 23:31:08 d2.utils.events]: [0m eta: 0:15:40  iter: 79  total_loss: 0.458  loss_cls: 0.134  loss_box_reg: 0.271  loss_rpn_cls: 0.007  loss_rpn_loc: 0.043  time: 1.0182  data_time: 0.0079  lr: 0.000400  max_mem: 5397M
[32m[04/28 23:31:28 d2.utils.events]: [0m eta: 0:15:21  iter: 99  total_loss: 0.493  loss_cls: 0.144  loss_box_reg: 0.286  loss_rpn_cls: 0.006  loss_rpn_loc: 0.045  time: 1.0211  data_time: 0.0078  lr: 0.000500  max_mem: 5397M
[32m[04/28 23:31:49 d2.utils.events]: [0m eta: 0:15:02  iter: 119  total_loss: 0.434  loss_cls: 0.129  loss_box_reg: 0.261  loss_rpn_cls: 0.004  loss_rpn_loc: 0.038  time: 1.0227  data_time: 0.0079  lr: 0.000599  max_mem: 5397M
[32m[04/28 23:32:10 d2.utils.events]: [0m eta: 0:14:45  iter: 139  total_loss: 0.413  loss_cls: 0.122  loss_box_reg: 0.251  loss_rpn_cls: 0.005  loss_rpn_loc: 0.037  time: 1.0246  data_time: 0.0077  lr: 0.000699  max_mem: 5397M
[32m[04/28 23:32:31 d2.utils.events]: [0m eta: 0:14:34  iter: 159  total_loss: 0.472  loss_cls: 0.141  loss_box_reg: 0.266  loss_rpn_cls: 0.004  loss_rpn_loc: 0.047  time: 1.0293  data_time: 0.0078  lr: 0.000799  max_mem: 5397M
[32m[04/28 23:32:52 d2.utils.events]: [0m eta: 0:14:12  iter: 179  total_loss: 0.486  loss_cls: 0.149  loss_box_reg: 0.286  loss_rpn_cls: 0.004  loss_rpn_loc: 0.047  time: 1.0285  data_time: 0.0078  lr: 0.000899  max_mem: 5397M
[32m[04/28 23:33:13 d2.utils.events]: [0m eta: 0:13:55  iter: 199  total_loss: 0.403  loss_cls: 0.130  loss_box_reg: 0.249  loss_rpn_cls: 0.006  loss_rpn_loc: 0.031  time: 1.0314  data_time: 0.0076  lr: 0.000999  max_mem: 5397M
[32m[04/28 23:33:33 d2.utils.events]: [0m eta: 0:13:29  iter: 219  total_loss: 0.461  loss_cls: 0.140  loss_box_reg: 0.277  loss_rpn_cls: 0.003  loss_rpn_loc: 0.045  time: 1.0292  data_time: 0.0077  lr: 0.001099  max_mem: 5397M
[32m[04/28 23:33:53 d2.utils.events]: [0m eta: 0:13:05  iter: 239  total_loss: 0.422  loss_cls: 0.128  loss_box_reg: 0.259  loss_rpn_cls: 0.004  loss_rpn_loc: 0.050  time: 1.0271  data_time: 0.0077  lr: 0.001199  max_mem: 5397M
[32m[04/28 23:34:14 d2.utils.events]: [0m eta: 0:12:46  iter: 259  total_loss: 0.413  loss_cls: 0.132  loss_box_reg: 0.234  loss_rpn_cls: 0.005  loss_rpn_loc: 0.032  time: 1.0275  data_time: 0.0077  lr: 0.001299  max_mem: 5397M
[32m[04/28 23:34:35 d2.utils.events]: [0m eta: 0:12:26  iter: 279  total_loss: 0.450  loss_cls: 0.134  loss_box_reg: 0.253  loss_rpn_cls: 0.006  loss_rpn_loc: 0.046  time: 1.0280  data_time: 0.0078  lr: 0.001399  max_mem: 5397M
[32m[04/28 23:34:56 d2.utils.events]: [0m eta: 0:12:07  iter: 299  total_loss: 0.418  loss_cls: 0.137  loss_box_reg: 0.260  loss_rpn_cls: 0.004  loss_rpn_loc: 0.035  time: 1.0301  data_time: 0.0079  lr: 0.001499  max_mem: 5397M
[32m[04/28 23:35:16 d2.utils.events]: [0m eta: 0:11:46  iter: 319  total_loss: 0.463  loss_cls: 0.127  loss_box_reg: 0.284  loss_rpn_cls: 0.007  loss_rpn_loc: 0.052  time: 1.0301  data_time: 0.0079  lr: 0.001598  max_mem: 5397M
[32m[04/28 23:35:37 d2.utils.events]: [0m eta: 0:11:26  iter: 339  total_loss: 0.402  loss_cls: 0.112  loss_box_reg: 0.249  loss_rpn_cls: 0.003  loss_rpn_loc: 0.032  time: 1.0297  data_time: 0.0078  lr: 0.001698  max_mem: 5397M
[32m[04/28 23:35:57 d2.utils.events]: [0m eta: 0:11:03  iter: 359  total_loss: 0.418  loss_cls: 0.131  loss_box_reg: 0.247  loss_rpn_cls: 0.003  loss_rpn_loc: 0.036  time: 1.0275  data_time: 0.0077  lr: 0.001798  max_mem: 5397M
[32m[04/28 23:36:17 d2.utils.events]: [0m eta: 0:10:42  iter: 379  total_loss: 0.461  loss_cls: 0.137  loss_box_reg: 0.267  loss_rpn_cls: 0.004  loss_rpn_loc: 0.045  time: 1.0273  data_time: 0.0076  lr: 0.001898  max_mem: 5397M
[32m[04/28 23:36:38 d2.utils.events]: [0m eta: 0:10:21  iter: 399  total_loss: 0.400  loss_cls: 0.108  loss_box_reg: 0.251  loss_rpn_cls: 0.004  loss_rpn_loc: 0.043  time: 1.0271  data_time: 0.0076  lr: 0.001998  max_mem: 5397M
[32m[04/28 23:36:58 d2.utils.events]: [0m eta: 0:10:00  iter: 419  total_loss: 0.372  loss_cls: 0.107  loss_box_reg: 0.226  loss_rpn_cls: 0.004  loss_rpn_loc: 0.028  time: 1.0272  data_time: 0.0078  lr: 0.002098  max_mem: 5397M
[32m[04/28 23:37:19 d2.utils.events]: [0m eta: 0:09:39  iter: 439  total_loss: 0.425  loss_cls: 0.125  loss_box_reg: 0.253  loss_rpn_cls: 0.004  loss_rpn_loc: 0.043  time: 1.0266  data_time: 0.0077  lr: 0.002198  max_mem: 5397M
[32m[04/28 23:37:40 d2.utils.events]: [0m eta: 0:09:19  iter: 459  total_loss: 0.425  loss_cls: 0.116  loss_box_reg: 0.265  loss_rpn_cls: 0.005  loss_rpn_loc: 0.039  time: 1.0272  data_time: 0.0078  lr: 0.002298  max_mem: 5397M
[32m[04/28 23:38:01 d2.utils.events]: [0m eta: 0:09:00  iter: 479  total_loss: 0.425  loss_cls: 0.123  loss_box_reg: 0.252  loss_rpn_cls: 0.004  loss_rpn_loc: 0.034  time: 1.0282  data_time: 0.0080  lr: 0.002398  max_mem: 5397M
[32m[04/28 23:38:21 d2.utils.events]: [0m eta: 0:08:38  iter: 499  total_loss: 0.437  loss_cls: 0.133  loss_box_reg: 0.258  loss_rpn_cls: 0.003  loss_rpn_loc: 0.038  time: 1.0276  data_time: 0.0079  lr: 0.002498  max_mem: 5397M
[32m[04/28 23:38:42 d2.utils.events]: [0m eta: 0:08:19  iter: 519  total_loss: 0.427  loss_cls: 0.124  loss_box_reg: 0.249  loss_rpn_cls: 0.003  loss_rpn_loc: 0.032  time: 1.0281  data_time: 0.0077  lr: 0.002597  max_mem: 5397M
[32m[04/28 23:39:03 d2.utils.events]: [0m eta: 0:07:58  iter: 539  total_loss: 0.422  loss_cls: 0.127  loss_box_reg: 0.253  loss_rpn_cls: 0.005  loss_rpn_loc: 0.035  time: 1.0289  data_time: 0.0075  lr: 0.002697  max_mem: 5397M
[32m[04/28 23:39:23 d2.utils.events]: [0m eta: 0:07:38  iter: 559  total_loss: 0.438  loss_cls: 0.115  loss_box_reg: 0.271  loss_rpn_cls: 0.004  loss_rpn_loc: 0.046  time: 1.0288  data_time: 0.0078  lr: 0.002797  max_mem: 5397M
[32m[04/28 23:39:44 d2.utils.events]: [0m eta: 0:07:18  iter: 579  total_loss: 0.457  loss_cls: 0.135  loss_box_reg: 0.259  loss_rpn_cls: 0.005  loss_rpn_loc: 0.046  time: 1.0293  data_time: 0.0076  lr: 0.002897  max_mem: 5397M
[32m[04/28 23:40:05 d2.utils.events]: [0m eta: 0:06:56  iter: 599  total_loss: 0.404  loss_cls: 0.115  loss_box_reg: 0.244  loss_rpn_cls: 0.005  loss_rpn_loc: 0.035  time: 1.0290  data_time: 0.0078  lr: 0.002997  max_mem: 5397M
[32m[04/28 23:40:25 d2.utils.events]: [0m eta: 0:06:35  iter: 619  total_loss: 0.447  loss_cls: 0.122  loss_box_reg: 0.265  loss_rpn_cls: 0.005  loss_rpn_loc: 0.037  time: 1.0284  data_time: 0.0080  lr: 0.003097  max_mem: 5397M
[32m[04/28 23:40:46 d2.utils.events]: [0m eta: 0:06:14  iter: 639  total_loss: 0.451  loss_cls: 0.142  loss_box_reg: 0.265  loss_rpn_cls: 0.005  loss_rpn_loc: 0.044  time: 1.0283  data_time: 0.0078  lr: 0.003197  max_mem: 5397M
[32m[04/28 23:41:06 d2.utils.events]: [0m eta: 0:05:54  iter: 659  total_loss: 0.461  loss_cls: 0.133  loss_box_reg: 0.283  loss_rpn_cls: 0.004  loss_rpn_loc: 0.049  time: 1.0283  data_time: 0.0077  lr: 0.003297  max_mem: 5397M
