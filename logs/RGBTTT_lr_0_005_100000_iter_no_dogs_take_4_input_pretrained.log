../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
3 channel input
Require gradient = False for the first several layers of ResNet
Require gradient = False for the first several layers of ResNet
6  channel input
[32m[04/27 12:58:44 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/27 12:58:44 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 12:58:44 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/27 12:58:44 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/27 12:58:45 d2.data.build]: [0mDistribution of instances among all 79 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 21744        |    bicycle    | 3806         |      car      | 39372        |
|  motorcycle   | 0            |   airplane    | 0            |      bus      | 0            |
|     train     | 0            |     truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant  | 0            |   stop sign   | 0            |
| parking meter | 0            |     bench     | 0            |     bird      | 0            |
|      cat      | 0            |      dog      | 0            |     horse     | 0            |
|     sheep     | 0            |      cow      | 0            |   elephant    | 0            |
|     bear      | 0            |     zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella    | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase    | 0            |    frisbee    | 0            |
|     skis      | 0            |   snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat  | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |   surfboard   | 0            | tennis racket | 0            |
|    bottle     | 0            |  wine glass   | 0            |      cup      | 0            |
|     fork      | 0            |     knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana     | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange     | 0            |   broccoli    | 0            |
|    carrot     | 0            |    hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake      | 0            |     chair     | 0            |
|     couch     | 0            | potted plant  | 0            |      bed      | 0            |
| dining table  | 0            |    toilet     | 0            |      tv       | 0            |
|    laptop     | 0            |     mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone   | 0            |   microwave   | 0            |
|     oven      | 0            |     bike      | 0            |    hydrant    | 0            |
|     motor     | 0            |     rider     | 0            |     light     | 0            |
|     sign      | 0            | motor vehicle | 0            |  human face   | 0            |
|  hair drier   | 0            |               |              |               |              |
|     total     | 64922        |               |              |               |              |[0m
[32m[04/27 12:58:45 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/27 12:58:45 d2.data.build]: [0mUsing training sampler TrainingSampler
layer  0  initialized with 0
============== The  0  *  1000  iterations ============
[32m[04/27 12:58:46 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/27 12:59:09 d2.utils.events]: [0m eta: 0:16:53  iter: 19  total_loss: 1.966  loss_cls: 0.225  loss_box_reg: 0.026  loss_rpn_cls: 1.605  loss_rpn_loc: 0.127  time: 1.0153  data_time: 0.0531  lr: 0.000100  max_mem: 5392M
[32m[04/27 12:59:29 d2.utils.events]: [0m eta: 0:16:24  iter: 39  total_loss: 0.777  loss_cls: 0.187  loss_box_reg: 0.091  loss_rpn_cls: 0.347  loss_rpn_loc: 0.122  time: 1.0101  data_time: 0.0087  lr: 0.000200  max_mem: 5392M
[32m[04/27 12:59:49 d2.utils.events]: [0m eta: 0:16:05  iter: 59  total_loss: 0.591  loss_cls: 0.145  loss_box_reg: 0.058  loss_rpn_cls: 0.255  loss_rpn_loc: 0.107  time: 1.0095  data_time: 0.0090  lr: 0.000300  max_mem: 5392M
[32m[04/27 13:00:10 d2.utils.events]: [0m eta: 0:15:48  iter: 79  total_loss: 0.458  loss_cls: 0.109  loss_box_reg: 0.035  loss_rpn_cls: 0.225  loss_rpn_loc: 0.087  time: 1.0117  data_time: 0.0091  lr: 0.000400  max_mem: 5392M
[32m[04/27 13:00:30 d2.utils.events]: [0m eta: 0:15:27  iter: 99  total_loss: 0.459  loss_cls: 0.116  loss_box_reg: 0.042  loss_rpn_cls: 0.197  loss_rpn_loc: 0.093  time: 1.0115  data_time: 0.0097  lr: 0.000500  max_mem: 5392M
[32m[04/27 13:00:50 d2.utils.events]: [0m eta: 0:15:05  iter: 119  total_loss: 0.505  loss_cls: 0.117  loss_box_reg: 0.039  loss_rpn_cls: 0.236  loss_rpn_loc: 0.113  time: 1.0084  data_time: 0.0091  lr: 0.000599  max_mem: 5392M
[32m[04/27 13:01:10 d2.utils.events]: [0m eta: 0:14:46  iter: 139  total_loss: 0.512  loss_cls: 0.120  loss_box_reg: 0.044  loss_rpn_cls: 0.210  loss_rpn_loc: 0.120  time: 1.0113  data_time: 0.0087  lr: 0.000699  max_mem: 5392M
[32m[04/27 13:01:30 d2.utils.events]: [0m eta: 0:14:15  iter: 159  total_loss: 0.509  loss_cls: 0.137  loss_box_reg: 0.063  loss_rpn_cls: 0.185  loss_rpn_loc: 0.105  time: 1.0045  data_time: 0.0093  lr: 0.000799  max_mem: 5392M
[32m[04/27 13:01:50 d2.utils.events]: [0m eta: 0:13:50  iter: 179  total_loss: 0.473  loss_cls: 0.119  loss_box_reg: 0.042  loss_rpn_cls: 0.208  loss_rpn_loc: 0.107  time: 1.0027  data_time: 0.0089  lr: 0.000899  max_mem: 5392M
[32m[04/27 13:02:10 d2.utils.events]: [0m eta: 0:13:30  iter: 199  total_loss: 0.402  loss_cls: 0.091  loss_box_reg: 0.024  loss_rpn_cls: 0.194  loss_rpn_loc: 0.087  time: 1.0033  data_time: 0.0090  lr: 0.000999  max_mem: 5392M
[32m[04/27 13:02:30 d2.utils.events]: [0m eta: 0:13:09  iter: 219  total_loss: 0.414  loss_cls: 0.067  loss_box_reg: 0.023  loss_rpn_cls: 0.189  loss_rpn_loc: 0.109  time: 1.0033  data_time: 0.0089  lr: 0.001099  max_mem: 5392M
[32m[04/27 13:02:50 d2.utils.events]: [0m eta: 0:12:49  iter: 239  total_loss: 0.606  loss_cls: 0.158  loss_box_reg: 0.042  loss_rpn_cls: 0.249  loss_rpn_loc: 0.107  time: 1.0051  data_time: 0.0090  lr: 0.001199  max_mem: 5392M
[32m[04/27 13:03:11 d2.utils.events]: [0m eta: 0:12:29  iter: 259  total_loss: 0.469  loss_cls: 0.131  loss_box_reg: 0.033  loss_rpn_cls: 0.223  loss_rpn_loc: 0.099  time: 1.0058  data_time: 0.0087  lr: 0.001299  max_mem: 5392M
[32m[04/27 13:03:31 d2.utils.events]: [0m eta: 0:12:12  iter: 279  total_loss: 0.497  loss_cls: 0.120  loss_box_reg: 0.037  loss_rpn_cls: 0.219  loss_rpn_loc: 0.100  time: 1.0070  data_time: 0.0087  lr: 0.001399  max_mem: 5392M
[32m[04/27 13:03:51 d2.utils.events]: [0m eta: 0:11:51  iter: 299  total_loss: 0.487  loss_cls: 0.117  loss_box_reg: 0.030  loss_rpn_cls: 0.206  loss_rpn_loc: 0.117  time: 1.0063  data_time: 0.0096  lr: 0.001499  max_mem: 5392M
[32m[04/27 13:04:12 d2.utils.events]: [0m eta: 0:11:33  iter: 319  total_loss: 0.426  loss_cls: 0.079  loss_box_reg: 0.021  loss_rpn_cls: 0.188  loss_rpn_loc: 0.107  time: 1.0066  data_time: 0.0091  lr: 0.001598  max_mem: 5392M
[32m[04/27 13:04:32 d2.utils.events]: [0m eta: 0:11:12  iter: 339  total_loss: 0.377  loss_cls: 0.074  loss_box_reg: 0.025  loss_rpn_cls: 0.180  loss_rpn_loc: 0.101  time: 1.0068  data_time: 0.0095  lr: 0.001698  max_mem: 5392M
[32m[04/27 13:04:52 d2.utils.events]: [0m eta: 0:10:53  iter: 359  total_loss: 0.464  loss_cls: 0.076  loss_box_reg: 0.032  loss_rpn_cls: 0.216  loss_rpn_loc: 0.108  time: 1.0075  data_time: 0.0087  lr: 0.001798  max_mem: 5392M
[32m[04/27 13:05:12 d2.utils.events]: [0m eta: 0:10:32  iter: 379  total_loss: 0.511  loss_cls: 0.136  loss_box_reg: 0.063  loss_rpn_cls: 0.200  loss_rpn_loc: 0.118  time: 1.0072  data_time: 0.0092  lr: 0.001898  max_mem: 5392M
[32m[04/27 13:05:32 d2.utils.events]: [0m eta: 0:10:08  iter: 399  total_loss: 0.506  loss_cls: 0.138  loss_box_reg: 0.054  loss_rpn_cls: 0.184  loss_rpn_loc: 0.121  time: 1.0056  data_time: 0.0091  lr: 0.001998  max_mem: 5392M
[32m[04/27 13:05:52 d2.utils.events]: [0m eta: 0:09:47  iter: 419  total_loss: 0.441  loss_cls: 0.102  loss_box_reg: 0.038  loss_rpn_cls: 0.173  loss_rpn_loc: 0.092  time: 1.0053  data_time: 0.0090  lr: 0.002098  max_mem: 5392M
[32m[04/27 13:06:12 d2.utils.events]: [0m eta: 0:09:27  iter: 439  total_loss: 0.484  loss_cls: 0.118  loss_box_reg: 0.047  loss_rpn_cls: 0.190  loss_rpn_loc: 0.111  time: 1.0047  data_time: 0.0092  lr: 0.002198  max_mem: 5392M
[32m[04/27 13:06:32 d2.utils.events]: [0m eta: 0:09:06  iter: 459  total_loss: 0.449  loss_cls: 0.110  loss_box_reg: 0.036  loss_rpn_cls: 0.178  loss_rpn_loc: 0.105  time: 1.0037  data_time: 0.0089  lr: 0.002298  max_mem: 5392M
[32m[04/27 13:06:53 d2.utils.events]: [0m eta: 0:08:48  iter: 479  total_loss: 0.417  loss_cls: 0.103  loss_box_reg: 0.029  loss_rpn_cls: 0.185  loss_rpn_loc: 0.091  time: 1.0056  data_time: 0.0091  lr: 0.002398  max_mem: 5392M
[32m[04/27 13:07:13 d2.utils.events]: [0m eta: 0:08:28  iter: 499  total_loss: 0.440  loss_cls: 0.116  loss_box_reg: 0.044  loss_rpn_cls: 0.189  loss_rpn_loc: 0.096  time: 1.0062  data_time: 0.0094  lr: 0.002498  max_mem: 5392M
[32m[04/27 13:07:33 d2.utils.events]: [0m eta: 0:08:07  iter: 519  total_loss: 0.499  loss_cls: 0.118  loss_box_reg: 0.052  loss_rpn_cls: 0.193  loss_rpn_loc: 0.109  time: 1.0063  data_time: 0.0089  lr: 0.002597  max_mem: 5392M
[32m[04/27 13:07:53 d2.utils.events]: [0m eta: 0:07:46  iter: 539  total_loss: 0.476  loss_cls: 0.130  loss_box_reg: 0.048  loss_rpn_cls: 0.192  loss_rpn_loc: 0.115  time: 1.0054  data_time: 0.0088  lr: 0.002697  max_mem: 5392M
[32m[04/27 13:08:13 d2.utils.events]: [0m eta: 0:07:26  iter: 559  total_loss: 0.417  loss_cls: 0.085  loss_box_reg: 0.025  loss_rpn_cls: 0.170  loss_rpn_loc: 0.102  time: 1.0050  data_time: 0.0088  lr: 0.002797  max_mem: 5392M
[32m[04/27 13:08:33 d2.utils.events]: [0m eta: 0:07:05  iter: 579  total_loss: 0.437  loss_cls: 0.099  loss_box_reg: 0.033  loss_rpn_cls: 0.184  loss_rpn_loc: 0.107  time: 1.0052  data_time: 0.0089  lr: 0.002897  max_mem: 5392M
[32m[04/27 13:08:54 d2.utils.events]: [0m eta: 0:06:45  iter: 599  total_loss: 0.466  loss_cls: 0.118  loss_box_reg: 0.041  loss_rpn_cls: 0.201  loss_rpn_loc: 0.108  time: 1.0060  data_time: 0.0089  lr: 0.002997  max_mem: 5392M
[32m[04/27 13:09:15 d2.utils.events]: [0m eta: 0:06:26  iter: 619  total_loss: 0.560  loss_cls: 0.160  loss_box_reg: 0.076  loss_rpn_cls: 0.192  loss_rpn_loc: 0.104  time: 1.0069  data_time: 0.0095  lr: 0.003097  max_mem: 5392M
[32m[04/27 13:09:35 d2.utils.events]: [0m eta: 0:06:05  iter: 639  total_loss: 0.504  loss_cls: 0.117  loss_box_reg: 0.042  loss_rpn_cls: 0.209  loss_rpn_loc: 0.128  time: 1.0068  data_time: 0.0093  lr: 0.003197  max_mem: 5392M
[32m[04/27 13:09:54 d2.utils.events]: [0m eta: 0:05:45  iter: 659  total_loss: 0.472  loss_cls: 0.110  loss_box_reg: 0.050  loss_rpn_cls: 0.183  loss_rpn_loc: 0.104  time: 1.0061  data_time: 0.0085  lr: 0.003297  max_mem: 5392M
[32m[04/27 13:10:15 d2.utils.events]: [0m eta: 0:05:24  iter: 679  total_loss: 0.570  loss_cls: 0.179  loss_box_reg: 0.087  loss_rpn_cls: 0.185  loss_rpn_loc: 0.103  time: 1.0060  data_time: 0.0090  lr: 0.003397  max_mem: 5392M
[32m[04/27 13:10:35 d2.utils.events]: [0m eta: 0:05:04  iter: 699  total_loss: 0.453  loss_cls: 0.099  loss_box_reg: 0.019  loss_rpn_cls: 0.190  loss_rpn_loc: 0.120  time: 1.0058  data_time: 0.0088  lr: 0.003497  max_mem: 5392M
[32m[04/27 13:10:55 d2.utils.events]: [0m eta: 0:04:44  iter: 719  total_loss: 0.502  loss_cls: 0.106  loss_box_reg: 0.038  loss_rpn_cls: 0.209  loss_rpn_loc: 0.135  time: 1.0065  data_time: 0.0090  lr: 0.003596  max_mem: 5392M
[32m[04/27 13:11:16 d2.utils.events]: [0m eta: 0:04:24  iter: 739  total_loss: 0.433  loss_cls: 0.090  loss_box_reg: 0.023  loss_rpn_cls: 0.193  loss_rpn_loc: 0.107  time: 1.0066  data_time: 0.0088  lr: 0.003696  max_mem: 5392M
[32m[04/27 13:11:35 d2.utils.events]: [0m eta: 0:04:04  iter: 759  total_loss: 0.400  loss_cls: 0.072  loss_box_reg: 0.028  loss_rpn_cls: 0.190  loss_rpn_loc: 0.098  time: 1.0063  data_time: 0.0087  lr: 0.003796  max_mem: 5392M
[32m[04/27 13:11:56 d2.utils.events]: [0m eta: 0:03:43  iter: 779  total_loss: 0.513  loss_cls: 0.138  loss_box_reg: 0.042  loss_rpn_cls: 0.201  loss_rpn_loc: 0.101  time: 1.0061  data_time: 0.0085  lr: 0.003896  max_mem: 5392M
[32m[04/27 13:12:16 d2.utils.events]: [0m eta: 0:03:23  iter: 799  total_loss: 0.588  loss_cls: 0.149  loss_box_reg: 0.064  loss_rpn_cls: 0.191  loss_rpn_loc: 0.129  time: 1.0062  data_time: 0.0089  lr: 0.003996  max_mem: 5392M
[32m[04/27 13:12:36 d2.utils.events]: [0m eta: 0:03:03  iter: 819  total_loss: 0.437  loss_cls: 0.102  loss_box_reg: 0.040  loss_rpn_cls: 0.190  loss_rpn_loc: 0.105  time: 1.0063  data_time: 0.0087  lr: 0.004096  max_mem: 5392M
[32m[04/27 13:12:57 d2.utils.events]: [0m eta: 0:02:43  iter: 839  total_loss: 0.450  loss_cls: 0.095  loss_box_reg: 0.042  loss_rpn_cls: 0.196  loss_rpn_loc: 0.091  time: 1.0069  data_time: 0.0089  lr: 0.004196  max_mem: 5392M
[32m[04/27 13:13:17 d2.utils.events]: [0m eta: 0:02:23  iter: 859  total_loss: 0.475  loss_cls: 0.097  loss_box_reg: 0.035  loss_rpn_cls: 0.206  loss_rpn_loc: 0.133  time: 1.0071  data_time: 0.0093  lr: 0.004296  max_mem: 5392M
[32m[04/27 13:13:37 d2.utils.events]: [0m eta: 0:02:02  iter: 879  total_loss: 0.453  loss_cls: 0.116  loss_box_reg: 0.044  loss_rpn_cls: 0.196  loss_rpn_loc: 0.113  time: 1.0067  data_time: 0.0088  lr: 0.004396  max_mem: 5392M
[32m[04/27 13:13:57 d2.utils.events]: [0m eta: 0:01:42  iter: 899  total_loss: 0.514  loss_cls: 0.136  loss_box_reg: 0.050  loss_rpn_cls: 0.201  loss_rpn_loc: 0.101  time: 1.0071  data_time: 0.0087  lr: 0.004496  max_mem: 5392M
[32m[04/27 13:14:18 d2.utils.events]: [0m eta: 0:01:22  iter: 919  total_loss: 0.497  loss_cls: 0.115  loss_box_reg: 0.037  loss_rpn_cls: 0.190  loss_rpn_loc: 0.115  time: 1.0071  data_time: 0.0087  lr: 0.004595  max_mem: 5392M
[32m[04/27 13:14:38 d2.utils.events]: [0m eta: 0:01:01  iter: 939  total_loss: 0.469  loss_cls: 0.123  loss_box_reg: 0.044  loss_rpn_cls: 0.202  loss_rpn_loc: 0.103  time: 1.0074  data_time: 0.0084  lr: 0.004695  max_mem: 5392M
[32m[04/27 13:14:58 d2.utils.events]: [0m eta: 0:00:41  iter: 959  total_loss: 0.496  loss_cls: 0.092  loss_box_reg: 0.029  loss_rpn_cls: 0.216  loss_rpn_loc: 0.115  time: 1.0073  data_time: 0.0087  lr: 0.004795  max_mem: 5392M
[32m[04/27 13:15:19 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.457  loss_cls: 0.107  loss_box_reg: 0.043  loss_rpn_cls: 0.192  loss_rpn_loc: 0.112  time: 1.0075  data_time: 0.0086  lr: 0.004895  max_mem: 5392M
[5m[31mWARNING[0m [32m[04/27 13:15:39 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 13:15:39 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/27 13:15:40 d2.data.build]: [0mDistribution of instances among all 80 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 5406         |    bicycle    | 420          |      car      | 5008         |
|  motorcycle   | 0            |   airplane    | 0            |      bus      | 0            |
|     train     | 0            |     truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant  | 0            |   stop sign   | 0            |
| parking meter | 0            |     bench     | 0            |     bird      | 0            |
|      cat      | 0            |      dog      | 0            |     horse     | 0            |
|     sheep     | 0            |      cow      | 0            |   elephant    | 0            |
|     bear      | 0            |     zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella    | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase    | 0            |    frisbee    | 0            |
|     skis      | 0            |   snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat  | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |   surfboard   | 0            | tennis racket | 0            |
|    bottle     | 0            |  wine glass   | 0            |      cup      | 0            |
|     fork      | 0            |     knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana     | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange     | 0            |   broccoli    | 0            |
|    carrot     | 0            |    hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake      | 0            |     chair     | 0            |
|     couch     | 0            | potted plant  | 0            |      bed      | 0            |
| dining table  | 0            |    toilet     | 0            |      tv       | 0            |
|    laptop     | 0            |     mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone   | 0            |   microwave   | 0            |
|     oven      | 0            |     bike      | 0            |    hydrant    | 0            |
|     motor     | 0            |     rider     | 0            |     light     | 0            |
|     sign      | 0            | motor vehicle | 0            |  human face   | 0            |
|  hair drier   | 0            | license plate | 0            |               |              |
|     total     | 10834        |               |              |               |              |[0m
[5m[31mWARNING[0m [32m[04/27 13:15:40 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/27 13:15:40 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.482  loss_cls: 0.125  loss_box_reg: 0.044  loss_rpn_cls: 0.181  loss_rpn_loc: 0.100  time: 1.0074  data_time: 0.0088  lr: 0.004995  max_mem: 5392M
[32m[04/27 13:15:40 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:16:45 (1.0084 s / it)
[32m[04/27 13:15:40 d2.engine.hooks]: [0mTotal training time: 0:16:48 (0:00:03 on hooks)
Require gradient = False for the first several layers of ResNet
6  channel input
[5m[31mWARNING[0m [32m[04/27 13:15:41 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 13:15:41 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/27 13:15:42 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/27 13:15:44 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1155 s / img. ETA=0:16:18
[32m[04/27 13:15:49 d2.evaluation.evaluator]: [0mInference done 54/8355. 0.1158 s / img. ETA=0:16:19
[32m[04/27 13:15:54 d2.evaluation.evaluator]: [0mInference done 97/8355. 0.1157 s / img. ETA=0:16:13
[32m[04/27 13:15:59 d2.evaluation.evaluator]: [0mInference done 140/8355. 0.1158 s / img. ETA=0:16:09
[32m[04/27 13:16:04 d2.evaluation.evaluator]: [0mInference done 183/8355. 0.1158 s / img. ETA=0:16:04
[32m[04/27 13:16:09 d2.evaluation.evaluator]: [0mInference done 226/8355. 0.1158 s / img. ETA=0:15:59
[32m[04/27 13:16:14 d2.evaluation.evaluator]: [0mInference done 269/8355. 0.1158 s / img. ETA=0:15:54
[32m[04/27 13:16:19 d2.evaluation.evaluator]: [0mInference done 312/8355. 0.1158 s / img. ETA=0:15:49
[32m[04/27 13:16:24 d2.evaluation.evaluator]: [0mInference done 355/8355. 0.1158 s / img. ETA=0:15:43
[32m[04/27 13:16:29 d2.evaluation.evaluator]: [0mInference done 398/8355. 0.1158 s / img. ETA=0:15:38
[32m[04/27 13:16:34 d2.evaluation.evaluator]: [0mInference done 441/8355. 0.1158 s / img. ETA=0:15:33
[32m[04/27 13:16:39 d2.evaluation.evaluator]: [0mInference done 484/8355. 0.1158 s / img. ETA=0:15:28
[32m[04/27 13:16:45 d2.evaluation.evaluator]: [0mInference done 527/8355. 0.1158 s / img. ETA=0:15:23
[32m[04/27 13:16:50 d2.evaluation.evaluator]: [0mInference done 570/8355. 0.1158 s / img. ETA=0:15:18
[32m[04/27 13:16:55 d2.evaluation.evaluator]: [0mInference done 613/8355. 0.1158 s / img. ETA=0:15:13
[32m[04/27 13:17:00 d2.evaluation.evaluator]: [0mInference done 656/8355. 0.1158 s / img. ETA=0:15:08
[32m[04/27 13:17:05 d2.evaluation.evaluator]: [0mInference done 699/8355. 0.1158 s / img. ETA=0:15:03
[32m[04/27 13:17:10 d2.evaluation.evaluator]: [0mInference done 742/8355. 0.1158 s / img. ETA=0:14:58
[32m[04/27 13:17:15 d2.evaluation.evaluator]: [0mInference done 785/8355. 0.1158 s / img. ETA=0:14:53
[32m[04/27 13:17:20 d2.evaluation.evaluator]: [0mInference done 828/8355. 0.1159 s / img. ETA=0:14:48
[32m[04/27 13:17:25 d2.evaluation.evaluator]: [0mInference done 871/8355. 0.1159 s / img. ETA=0:14:43
[32m[04/27 13:17:30 d2.evaluation.evaluator]: [0mInference done 914/8355. 0.1159 s / img. ETA=0:14:38
[32m[04/27 13:17:35 d2.evaluation.evaluator]: [0mInference done 957/8355. 0.1159 s / img. ETA=0:14:33
[32m[04/27 13:17:40 d2.evaluation.evaluator]: [0mInference done 1000/8355. 0.1159 s / img. ETA=0:14:28
[32m[04/27 13:17:46 d2.evaluation.evaluator]: [0mInference done 1043/8355. 0.1159 s / img. ETA=0:14:23
[32m[04/27 13:17:51 d2.evaluation.evaluator]: [0mInference done 1086/8355. 0.1159 s / img. ETA=0:14:18
[32m[04/27 13:17:56 d2.evaluation.evaluator]: [0mInference done 1129/8355. 0.1159 s / img. ETA=0:14:13
[32m[04/27 13:18:01 d2.evaluation.evaluator]: [0mInference done 1172/8355. 0.1159 s / img. ETA=0:14:08
[32m[04/27 13:18:06 d2.evaluation.evaluator]: [0mInference done 1215/8355. 0.1159 s / img. ETA=0:14:03
[32m[04/27 13:18:11 d2.evaluation.evaluator]: [0mInference done 1258/8355. 0.1159 s / img. ETA=0:13:58
[32m[04/27 13:18:16 d2.evaluation.evaluator]: [0mInference done 1301/8355. 0.1159 s / img. ETA=0:13:53
[32m[04/27 13:18:21 d2.evaluation.evaluator]: [0mInference done 1344/8355. 0.1159 s / img. ETA=0:13:47
[32m[04/27 13:18:26 d2.evaluation.evaluator]: [0mInference done 1387/8355. 0.1159 s / img. ETA=0:13:42
[32m[04/27 13:18:31 d2.evaluation.evaluator]: [0mInference done 1430/8355. 0.1159 s / img. ETA=0:13:37
[32m[04/27 13:18:36 d2.evaluation.evaluator]: [0mInference done 1473/8355. 0.1159 s / img. ETA=0:13:32
[32m[04/27 13:18:41 d2.evaluation.evaluator]: [0mInference done 1515/8355. 0.1160 s / img. ETA=0:13:28
[32m[04/27 13:18:46 d2.evaluation.evaluator]: [0mInference done 1558/8355. 0.1160 s / img. ETA=0:13:22
[32m[04/27 13:18:52 d2.evaluation.evaluator]: [0mInference done 1601/8355. 0.1160 s / img. ETA=0:13:17
[32m[04/27 13:18:57 d2.evaluation.evaluator]: [0mInference done 1644/8355. 0.1160 s / img. ETA=0:13:12
[32m[04/27 13:19:02 d2.evaluation.evaluator]: [0mInference done 1687/8355. 0.1160 s / img. ETA=0:13:07
[32m[04/27 13:19:07 d2.evaluation.evaluator]: [0mInference done 1730/8355. 0.1160 s / img. ETA=0:13:02
[32m[04/27 13:19:12 d2.evaluation.evaluator]: [0mInference done 1773/8355. 0.1160 s / img. ETA=0:12:57
[32m[04/27 13:19:17 d2.evaluation.evaluator]: [0mInference done 1816/8355. 0.1160 s / img. ETA=0:12:52
[32m[04/27 13:19:22 d2.evaluation.evaluator]: [0mInference done 1858/8355. 0.1160 s / img. ETA=0:12:47
[32m[04/27 13:19:27 d2.evaluation.evaluator]: [0mInference done 1901/8355. 0.1160 s / img. ETA=0:12:42
[32m[04/27 13:19:32 d2.evaluation.evaluator]: [0mInference done 1944/8355. 0.1160 s / img. ETA=0:12:37
[32m[04/27 13:19:37 d2.evaluation.evaluator]: [0mInference done 1987/8355. 0.1160 s / img. ETA=0:12:32
[32m[04/27 13:19:42 d2.evaluation.evaluator]: [0mInference done 2030/8355. 0.1160 s / img. ETA=0:12:27
[32m[04/27 13:19:47 d2.evaluation.evaluator]: [0mInference done 2073/8355. 0.1160 s / img. ETA=0:12:22
[32m[04/27 13:19:52 d2.evaluation.evaluator]: [0mInference done 2116/8355. 0.1160 s / img. ETA=0:12:17
[32m[04/27 13:19:57 d2.evaluation.evaluator]: [0mInference done 2159/8355. 0.1160 s / img. ETA=0:12:12
[32m[04/27 13:20:03 d2.evaluation.evaluator]: [0mInference done 2202/8355. 0.1160 s / img. ETA=0:12:07
[32m[04/27 13:20:08 d2.evaluation.evaluator]: [0mInference done 2245/8355. 0.1160 s / img. ETA=0:12:02
[32m[04/27 13:20:13 d2.evaluation.evaluator]: [0mInference done 2288/8355. 0.1160 s / img. ETA=0:11:57
[32m[04/27 13:20:18 d2.evaluation.evaluator]: [0mInference done 2331/8355. 0.1160 s / img. ETA=0:11:51
[32m[04/27 13:20:23 d2.evaluation.evaluator]: [0mInference done 2374/8355. 0.1160 s / img. ETA=0:11:46
[32m[04/27 13:20:28 d2.evaluation.evaluator]: [0mInference done 2417/8355. 0.1160 s / img. ETA=0:11:41
[32m[04/27 13:20:33 d2.evaluation.evaluator]: [0mInference done 2460/8355. 0.1160 s / img. ETA=0:11:36
[32m[04/27 13:20:38 d2.evaluation.evaluator]: [0mInference done 2503/8355. 0.1160 s / img. ETA=0:11:31
[32m[04/27 13:20:43 d2.evaluation.evaluator]: [0mInference done 2546/8355. 0.1160 s / img. ETA=0:11:26
[32m[04/27 13:20:48 d2.evaluation.evaluator]: [0mInference done 2588/8355. 0.1161 s / img. ETA=0:11:21
[32m[04/27 13:20:54 d2.evaluation.evaluator]: [0mInference done 2631/8355. 0.1161 s / img. ETA=0:11:16
[32m[04/27 13:20:59 d2.evaluation.evaluator]: [0mInference done 2674/8355. 0.1161 s / img. ETA=0:11:11
[32m[04/27 13:21:04 d2.evaluation.evaluator]: [0mInference done 2717/8355. 0.1161 s / img. ETA=0:11:06
[32m[04/27 13:21:09 d2.evaluation.evaluator]: [0mInference done 2760/8355. 0.1161 s / img. ETA=0:11:01
[32m[04/27 13:21:14 d2.evaluation.evaluator]: [0mInference done 2802/8355. 0.1161 s / img. ETA=0:10:56
[32m[04/27 13:21:19 d2.evaluation.evaluator]: [0mInference done 2845/8355. 0.1161 s / img. ETA=0:10:51
[32m[04/27 13:21:24 d2.evaluation.evaluator]: [0mInference done 2888/8355. 0.1161 s / img. ETA=0:10:46
[32m[04/27 13:21:29 d2.evaluation.evaluator]: [0mInference done 2931/8355. 0.1161 s / img. ETA=0:10:41
[32m[04/27 13:21:34 d2.evaluation.evaluator]: [0mInference done 2974/8355. 0.1161 s / img. ETA=0:10:36
[32m[04/27 13:21:39 d2.evaluation.evaluator]: [0mInference done 3017/8355. 0.1161 s / img. ETA=0:10:31
[32m[04/27 13:21:44 d2.evaluation.evaluator]: [0mInference done 3060/8355. 0.1161 s / img. ETA=0:10:26
[32m[04/27 13:21:50 d2.evaluation.evaluator]: [0mInference done 3103/8355. 0.1161 s / img. ETA=0:10:21
[32m[04/27 13:21:55 d2.evaluation.evaluator]: [0mInference done 3146/8355. 0.1161 s / img. ETA=0:10:16
[32m[04/27 13:22:00 d2.evaluation.evaluator]: [0mInference done 3188/8355. 0.1161 s / img. ETA=0:10:11
[32m[04/27 13:22:05 d2.evaluation.evaluator]: [0mInference done 3231/8355. 0.1162 s / img. ETA=0:10:06
[32m[04/27 13:22:10 d2.evaluation.evaluator]: [0mInference done 3273/8355. 0.1162 s / img. ETA=0:10:01
[32m[04/27 13:22:15 d2.evaluation.evaluator]: [0mInference done 3316/8355. 0.1162 s / img. ETA=0:09:56
[32m[04/27 13:22:20 d2.evaluation.evaluator]: [0mInference done 3359/8355. 0.1162 s / img. ETA=0:09:51
[32m[04/27 13:22:25 d2.evaluation.evaluator]: [0mInference done 3401/8355. 0.1162 s / img. ETA=0:09:46
[32m[04/27 13:22:30 d2.evaluation.evaluator]: [0mInference done 3443/8355. 0.1162 s / img. ETA=0:09:41
[32m[04/27 13:22:35 d2.evaluation.evaluator]: [0mInference done 3486/8355. 0.1162 s / img. ETA=0:09:36
[32m[04/27 13:22:40 d2.evaluation.evaluator]: [0mInference done 3529/8355. 0.1162 s / img. ETA=0:09:31
[32m[04/27 13:22:45 d2.evaluation.evaluator]: [0mInference done 3572/8355. 0.1162 s / img. ETA=0:09:26
[32m[04/27 13:22:50 d2.evaluation.evaluator]: [0mInference done 3615/8355. 0.1162 s / img. ETA=0:09:21
[32m[04/27 13:22:55 d2.evaluation.evaluator]: [0mInference done 3658/8355. 0.1162 s / img. ETA=0:09:16
[32m[04/27 13:23:01 d2.evaluation.evaluator]: [0mInference done 3701/8355. 0.1162 s / img. ETA=0:09:10
[32m[04/27 13:23:06 d2.evaluation.evaluator]: [0mInference done 3743/8355. 0.1162 s / img. ETA=0:09:06
[32m[04/27 13:23:11 d2.evaluation.evaluator]: [0mInference done 3786/8355. 0.1162 s / img. ETA=0:09:00
[32m[04/27 13:23:16 d2.evaluation.evaluator]: [0mInference done 3829/8355. 0.1162 s / img. ETA=0:08:55
[32m[04/27 13:23:21 d2.evaluation.evaluator]: [0mInference done 3872/8355. 0.1162 s / img. ETA=0:08:50
[32m[04/27 13:23:26 d2.evaluation.evaluator]: [0mInference done 3915/8355. 0.1162 s / img. ETA=0:08:45
[32m[04/27 13:23:31 d2.evaluation.evaluator]: [0mInference done 3958/8355. 0.1162 s / img. ETA=0:08:40
[32m[04/27 13:23:36 d2.evaluation.evaluator]: [0mInference done 4001/8355. 0.1162 s / img. ETA=0:08:35
[32m[04/27 13:23:41 d2.evaluation.evaluator]: [0mInference done 4043/8355. 0.1162 s / img. ETA=0:08:30
[32m[04/27 13:23:46 d2.evaluation.evaluator]: [0mInference done 4086/8355. 0.1162 s / img. ETA=0:08:25
[32m[04/27 13:23:51 d2.evaluation.evaluator]: [0mInference done 4129/8355. 0.1162 s / img. ETA=0:08:20
[32m[04/27 13:23:56 d2.evaluation.evaluator]: [0mInference done 4172/8355. 0.1162 s / img. ETA=0:08:15
[32m[04/27 13:24:02 d2.evaluation.evaluator]: [0mInference done 4215/8355. 0.1162 s / img. ETA=0:08:10
[32m[04/27 13:24:07 d2.evaluation.evaluator]: [0mInference done 4257/8355. 0.1162 s / img. ETA=0:08:05
[32m[04/27 13:24:12 d2.evaluation.evaluator]: [0mInference done 4300/8355. 0.1162 s / img. ETA=0:08:00
[32m[04/27 13:24:17 d2.evaluation.evaluator]: [0mInference done 4343/8355. 0.1162 s / img. ETA=0:07:55
[32m[04/27 13:24:22 d2.evaluation.evaluator]: [0mInference done 4385/8355. 0.1163 s / img. ETA=0:07:50
[32m[04/27 13:24:27 d2.evaluation.evaluator]: [0mInference done 4427/8355. 0.1163 s / img. ETA=0:07:45
[32m[04/27 13:24:32 d2.evaluation.evaluator]: [0mInference done 4470/8355. 0.1163 s / img. ETA=0:07:40
[32m[04/27 13:24:37 d2.evaluation.evaluator]: [0mInference done 4513/8355. 0.1163 s / img. ETA=0:07:35
[32m[04/27 13:24:42 d2.evaluation.evaluator]: [0mInference done 4556/8355. 0.1163 s / img. ETA=0:07:30
[32m[04/27 13:24:47 d2.evaluation.evaluator]: [0mInference done 4599/8355. 0.1163 s / img. ETA=0:07:24
[32m[04/27 13:24:52 d2.evaluation.evaluator]: [0mInference done 4641/8355. 0.1163 s / img. ETA=0:07:20
[32m[04/27 13:24:57 d2.evaluation.evaluator]: [0mInference done 4684/8355. 0.1163 s / img. ETA=0:07:14
[32m[04/27 13:25:02 d2.evaluation.evaluator]: [0mInference done 4727/8355. 0.1163 s / img. ETA=0:07:09
[32m[04/27 13:25:07 d2.evaluation.evaluator]: [0mInference done 4769/8355. 0.1163 s / img. ETA=0:07:04
[32m[04/27 13:25:13 d2.evaluation.evaluator]: [0mInference done 4812/8355. 0.1163 s / img. ETA=0:06:59
[32m[04/27 13:25:18 d2.evaluation.evaluator]: [0mInference done 4854/8355. 0.1163 s / img. ETA=0:06:54
[32m[04/27 13:25:23 d2.evaluation.evaluator]: [0mInference done 4897/8355. 0.1163 s / img. ETA=0:06:49
[32m[04/27 13:25:28 d2.evaluation.evaluator]: [0mInference done 4940/8355. 0.1163 s / img. ETA=0:06:44
[32m[04/27 13:25:33 d2.evaluation.evaluator]: [0mInference done 4983/8355. 0.1163 s / img. ETA=0:06:39
[32m[04/27 13:25:38 d2.evaluation.evaluator]: [0mInference done 5025/8355. 0.1163 s / img. ETA=0:06:34
[32m[04/27 13:25:43 d2.evaluation.evaluator]: [0mInference done 5068/8355. 0.1163 s / img. ETA=0:06:29
[32m[04/27 13:25:48 d2.evaluation.evaluator]: [0mInference done 5110/8355. 0.1163 s / img. ETA=0:06:24
[32m[04/27 13:25:53 d2.evaluation.evaluator]: [0mInference done 5152/8355. 0.1163 s / img. ETA=0:06:19
[32m[04/27 13:25:58 d2.evaluation.evaluator]: [0mInference done 5194/8355. 0.1164 s / img. ETA=0:06:14
[32m[04/27 13:26:03 d2.evaluation.evaluator]: [0mInference done 5236/8355. 0.1164 s / img. ETA=0:06:09
[32m[04/27 13:26:08 d2.evaluation.evaluator]: [0mInference done 5279/8355. 0.1164 s / img. ETA=0:06:04
[32m[04/27 13:26:13 d2.evaluation.evaluator]: [0mInference done 5322/8355. 0.1164 s / img. ETA=0:05:59
[32m[04/27 13:26:18 d2.evaluation.evaluator]: [0mInference done 5365/8355. 0.1164 s / img. ETA=0:05:54
[32m[04/27 13:26:24 d2.evaluation.evaluator]: [0mInference done 5407/8355. 0.1164 s / img. ETA=0:05:49
[32m[04/27 13:26:29 d2.evaluation.evaluator]: [0mInference done 5450/8355. 0.1164 s / img. ETA=0:05:44
[32m[04/27 13:26:34 d2.evaluation.evaluator]: [0mInference done 5493/8355. 0.1164 s / img. ETA=0:05:39
[32m[04/27 13:26:39 d2.evaluation.evaluator]: [0mInference done 5535/8355. 0.1164 s / img. ETA=0:05:34
[32m[04/27 13:26:44 d2.evaluation.evaluator]: [0mInference done 5577/8355. 0.1164 s / img. ETA=0:05:29
[32m[04/27 13:26:49 d2.evaluation.evaluator]: [0mInference done 5619/8355. 0.1164 s / img. ETA=0:05:24
[32m[04/27 13:26:54 d2.evaluation.evaluator]: [0mInference done 5662/8355. 0.1164 s / img. ETA=0:05:19
[32m[04/27 13:26:59 d2.evaluation.evaluator]: [0mInference done 5704/8355. 0.1164 s / img. ETA=0:05:14
[32m[04/27 13:27:04 d2.evaluation.evaluator]: [0mInference done 5746/8355. 0.1164 s / img. ETA=0:05:09
[32m[04/27 13:27:09 d2.evaluation.evaluator]: [0mInference done 5788/8355. 0.1165 s / img. ETA=0:05:04
[32m[04/27 13:27:14 d2.evaluation.evaluator]: [0mInference done 5831/8355. 0.1165 s / img. ETA=0:04:59
[32m[04/27 13:27:19 d2.evaluation.evaluator]: [0mInference done 5873/8355. 0.1165 s / img. ETA=0:04:54
[32m[04/27 13:27:24 d2.evaluation.evaluator]: [0mInference done 5916/8355. 0.1165 s / img. ETA=0:04:49
[32m[04/27 13:27:29 d2.evaluation.evaluator]: [0mInference done 5959/8355. 0.1165 s / img. ETA=0:04:44
[32m[04/27 13:27:34 d2.evaluation.evaluator]: [0mInference done 6002/8355. 0.1165 s / img. ETA=0:04:39
[32m[04/27 13:27:39 d2.evaluation.evaluator]: [0mInference done 6044/8355. 0.1165 s / img. ETA=0:04:34
[32m[04/27 13:27:44 d2.evaluation.evaluator]: [0mInference done 6086/8355. 0.1165 s / img. ETA=0:04:29
[32m[04/27 13:27:50 d2.evaluation.evaluator]: [0mInference done 6128/8355. 0.1165 s / img. ETA=0:04:24
[32m[04/27 13:27:55 d2.evaluation.evaluator]: [0mInference done 6171/8355. 0.1165 s / img. ETA=0:04:19
[32m[04/27 13:28:00 d2.evaluation.evaluator]: [0mInference done 6214/8355. 0.1165 s / img. ETA=0:04:14
[32m[04/27 13:28:05 d2.evaluation.evaluator]: [0mInference done 6257/8355. 0.1165 s / img. ETA=0:04:08
[32m[04/27 13:28:10 d2.evaluation.evaluator]: [0mInference done 6300/8355. 0.1165 s / img. ETA=0:04:03
[32m[04/27 13:28:15 d2.evaluation.evaluator]: [0mInference done 6342/8355. 0.1165 s / img. ETA=0:03:58
[32m[04/27 13:28:20 d2.evaluation.evaluator]: [0mInference done 6385/8355. 0.1165 s / img. ETA=0:03:53
[32m[04/27 13:28:25 d2.evaluation.evaluator]: [0mInference done 6428/8355. 0.1165 s / img. ETA=0:03:48
[32m[04/27 13:28:30 d2.evaluation.evaluator]: [0mInference done 6471/8355. 0.1165 s / img. ETA=0:03:43
[32m[04/27 13:28:35 d2.evaluation.evaluator]: [0mInference done 6513/8355. 0.1165 s / img. ETA=0:03:38
[32m[04/27 13:28:40 d2.evaluation.evaluator]: [0mInference done 6556/8355. 0.1165 s / img. ETA=0:03:33
[32m[04/27 13:28:45 d2.evaluation.evaluator]: [0mInference done 6598/8355. 0.1165 s / img. ETA=0:03:28
[32m[04/27 13:28:50 d2.evaluation.evaluator]: [0mInference done 6641/8355. 0.1165 s / img. ETA=0:03:23
[32m[04/27 13:28:56 d2.evaluation.evaluator]: [0mInference done 6684/8355. 0.1165 s / img. ETA=0:03:18
[32m[04/27 13:29:01 d2.evaluation.evaluator]: [0mInference done 6726/8355. 0.1165 s / img. ETA=0:03:13
[32m[04/27 13:29:06 d2.evaluation.evaluator]: [0mInference done 6769/8355. 0.1165 s / img. ETA=0:03:08
[32m[04/27 13:29:11 d2.evaluation.evaluator]: [0mInference done 6811/8355. 0.1165 s / img. ETA=0:03:03
[32m[04/27 13:29:16 d2.evaluation.evaluator]: [0mInference done 6854/8355. 0.1165 s / img. ETA=0:02:58
[32m[04/27 13:29:21 d2.evaluation.evaluator]: [0mInference done 6897/8355. 0.1165 s / img. ETA=0:02:53
[32m[04/27 13:29:26 d2.evaluation.evaluator]: [0mInference done 6940/8355. 0.1165 s / img. ETA=0:02:47
[32m[04/27 13:29:31 d2.evaluation.evaluator]: [0mInference done 6983/8355. 0.1165 s / img. ETA=0:02:42
[32m[04/27 13:29:36 d2.evaluation.evaluator]: [0mInference done 7025/8355. 0.1165 s / img. ETA=0:02:37
[32m[04/27 13:29:41 d2.evaluation.evaluator]: [0mInference done 7067/8355. 0.1165 s / img. ETA=0:02:32
[32m[04/27 13:29:46 d2.evaluation.evaluator]: [0mInference done 7109/8355. 0.1165 s / img. ETA=0:02:27
[32m[04/27 13:29:51 d2.evaluation.evaluator]: [0mInference done 7151/8355. 0.1165 s / img. ETA=0:02:22
[32m[04/27 13:29:56 d2.evaluation.evaluator]: [0mInference done 7193/8355. 0.1165 s / img. ETA=0:02:17
[32m[04/27 13:30:01 d2.evaluation.evaluator]: [0mInference done 7235/8355. 0.1165 s / img. ETA=0:02:12
[32m[04/27 13:30:06 d2.evaluation.evaluator]: [0mInference done 7277/8355. 0.1165 s / img. ETA=0:02:07
[32m[04/27 13:30:11 d2.evaluation.evaluator]: [0mInference done 7319/8355. 0.1165 s / img. ETA=0:02:02
[32m[04/27 13:30:16 d2.evaluation.evaluator]: [0mInference done 7361/8355. 0.1166 s / img. ETA=0:01:58
[32m[04/27 13:30:21 d2.evaluation.evaluator]: [0mInference done 7403/8355. 0.1166 s / img. ETA=0:01:53
[32m[04/27 13:30:26 d2.evaluation.evaluator]: [0mInference done 7445/8355. 0.1166 s / img. ETA=0:01:48
[32m[04/27 13:30:31 d2.evaluation.evaluator]: [0mInference done 7487/8355. 0.1166 s / img. ETA=0:01:43
[32m[04/27 13:30:36 d2.evaluation.evaluator]: [0mInference done 7529/8355. 0.1166 s / img. ETA=0:01:38
[32m[04/27 13:30:42 d2.evaluation.evaluator]: [0mInference done 7571/8355. 0.1166 s / img. ETA=0:01:33
[32m[04/27 13:30:47 d2.evaluation.evaluator]: [0mInference done 7613/8355. 0.1166 s / img. ETA=0:01:28
[32m[04/27 13:30:52 d2.evaluation.evaluator]: [0mInference done 7656/8355. 0.1166 s / img. ETA=0:01:23
[32m[04/27 13:30:57 d2.evaluation.evaluator]: [0mInference done 7698/8355. 0.1166 s / img. ETA=0:01:18
[32m[04/27 13:31:02 d2.evaluation.evaluator]: [0mInference done 7740/8355. 0.1166 s / img. ETA=0:01:13
[32m[04/27 13:31:07 d2.evaluation.evaluator]: [0mInference done 7782/8355. 0.1166 s / img. ETA=0:01:08
[32m[04/27 13:31:12 d2.evaluation.evaluator]: [0mInference done 7824/8355. 0.1166 s / img. ETA=0:01:03
[32m[04/27 13:31:17 d2.evaluation.evaluator]: [0mInference done 7866/8355. 0.1166 s / img. ETA=0:00:58
[32m[04/27 13:31:22 d2.evaluation.evaluator]: [0mInference done 7908/8355. 0.1166 s / img. ETA=0:00:53
[32m[04/27 13:31:27 d2.evaluation.evaluator]: [0mInference done 7950/8355. 0.1166 s / img. ETA=0:00:48
[32m[04/27 13:31:32 d2.evaluation.evaluator]: [0mInference done 7992/8355. 0.1166 s / img. ETA=0:00:43
[32m[04/27 13:31:37 d2.evaluation.evaluator]: [0mInference done 8035/8355. 0.1166 s / img. ETA=0:00:38
[32m[04/27 13:31:42 d2.evaluation.evaluator]: [0mInference done 8078/8355. 0.1166 s / img. ETA=0:00:32
[32m[04/27 13:31:47 d2.evaluation.evaluator]: [0mInference done 8120/8355. 0.1166 s / img. ETA=0:00:27
[32m[04/27 13:31:52 d2.evaluation.evaluator]: [0mInference done 8163/8355. 0.1166 s / img. ETA=0:00:22
[32m[04/27 13:31:57 d2.evaluation.evaluator]: [0mInference done 8205/8355. 0.1166 s / img. ETA=0:00:17
[32m[04/27 13:32:02 d2.evaluation.evaluator]: [0mInference done 8248/8355. 0.1166 s / img. ETA=0:00:12
[32m[04/27 13:32:08 d2.evaluation.evaluator]: [0mInference done 8291/8355. 0.1166 s / img. ETA=0:00:07
[32m[04/27 13:32:13 d2.evaluation.evaluator]: [0mInference done 8334/8355. 0.1166 s / img. ETA=0:00:02
[32m[04/27 13:32:15 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:32.190439 (0.118825 s / img per device, on 1 devices)
[32m[04/27 13:32:15 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:13 (0.116638 s / img per device, on 1 devices)
[32m[04/27 13:32:15 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/27 13:32:15 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel_2/coco_instances_results.json
[32m[04/27 13:32:15 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=7.30s).
Accumulating evaluation results...
DONE (t=1.16s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.012
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.028
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.004
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.032
[32m[04/27 13:32:24 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.777 | 1.221  | 0.910  | 0.273 | 0.608 | 2.830 |
[32m[04/27 13:32:24 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP    | category      | AP    | category       | AP    |
|:--------------|:------|:--------------|:------|:---------------|:------|
| person        | 0.743 | bicycle       | 0.349 | car            | 1.240 |
| motorcycle    | nan   | airplane      | nan   | bus            | nan   |
| train         | nan   | truck         | nan   | boat           | nan   |
| traffic light | nan   | fire hydrant  | nan   | stop sign      | nan   |
| parking meter | nan   | bench         | nan   | bird           | nan   |
| cat           | nan   | dog           | nan   | horse          | nan   |
| sheep         | nan   | cow           | nan   | elephant       | nan   |
| bear          | nan   | zebra         | nan   | giraffe        | nan   |
| backpack      | nan   | umbrella      | nan   | handbag        | nan   |
| tie           | nan   | suitcase      | nan   | frisbee        | nan   |
| skis          | nan   | snowboard     | nan   | sports ball    | nan   |
| kite          | nan   | baseball bat  | nan   | baseball glove | nan   |
| skateboard    | nan   | surfboard     | nan   | tennis racket  | nan   |
| bottle        | nan   | wine glass    | nan   | cup            | nan   |
| fork          | nan   | knife         | nan   | spoon          | nan   |
| bowl          | nan   | banana        | nan   | apple          | nan   |
| sandwich      | nan   | orange        | nan   | broccoli       | nan   |
| carrot        | nan   | hot dog       | nan   | pizza          | nan   |
| donut         | nan   | cake          | nan   | chair          | nan   |
| couch         | nan   | potted plant  | nan   | bed            | nan   |
| dining table  | nan   | toilet        | nan   | tv             | nan   |
| laptop        | nan   | mouse         | nan   | remote         | nan   |
| keyboard      | nan   | cell phone    | nan   | microwave      | nan   |
| oven          | nan   | bike          | nan   | hydrant        | nan   |
| motor         | nan   | rider         | nan   | light          | nan   |
| sign          | nan   | motor vehicle | nan   | human face     | nan   |
| hair drier    | nan   |               |       |                |       |
Require gradient = False for the first several layers of ResNet
6  channel input
[5m[31mWARNING[0m [32m[04/27 13:32:25 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 13:32:25 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/27 13:32:25 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/27 13:32:27 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1187 s / img. ETA=0:02:30
[32m[04/27 13:32:32 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1172 s / img. ETA=0:02:23
[32m[04/27 13:32:37 d2.evaluation.evaluator]: [0mInference done 96/1257. 0.1168 s / img. ETA=0:02:18
[32m[04/27 13:32:42 d2.evaluation.evaluator]: [0mInference done 139/1257. 0.1166 s / img. ETA=0:02:12
[32m[04/27 13:32:47 d2.evaluation.evaluator]: [0mInference done 182/1257. 0.1166 s / img. ETA=0:02:07
[32m[04/27 13:32:52 d2.evaluation.evaluator]: [0mInference done 225/1257. 0.1165 s / img. ETA=0:02:02
[32m[04/27 13:32:57 d2.evaluation.evaluator]: [0mInference done 268/1257. 0.1165 s / img. ETA=0:01:57
[32m[04/27 13:33:02 d2.evaluation.evaluator]: [0mInference done 311/1257. 0.1165 s / img. ETA=0:01:52
[32m[04/27 13:33:07 d2.evaluation.evaluator]: [0mInference done 354/1257. 0.1165 s / img. ETA=0:01:47
[32m[04/27 13:33:12 d2.evaluation.evaluator]: [0mInference done 397/1257. 0.1165 s / img. ETA=0:01:42
[32m[04/27 13:33:17 d2.evaluation.evaluator]: [0mInference done 439/1257. 0.1165 s / img. ETA=0:01:37
[32m[04/27 13:33:22 d2.evaluation.evaluator]: [0mInference done 481/1257. 0.1166 s / img. ETA=0:01:32
[32m[04/27 13:33:27 d2.evaluation.evaluator]: [0mInference done 523/1257. 0.1166 s / img. ETA=0:01:27
[32m[04/27 13:33:32 d2.evaluation.evaluator]: [0mInference done 565/1257. 0.1167 s / img. ETA=0:01:22
[32m[04/27 13:33:38 d2.evaluation.evaluator]: [0mInference done 608/1257. 0.1167 s / img. ETA=0:01:17
[32m[04/27 13:33:43 d2.evaluation.evaluator]: [0mInference done 650/1257. 0.1167 s / img. ETA=0:01:12
[32m[04/27 13:33:48 d2.evaluation.evaluator]: [0mInference done 692/1257. 0.1167 s / img. ETA=0:01:07
[32m[04/27 13:33:53 d2.evaluation.evaluator]: [0mInference done 735/1257. 0.1167 s / img. ETA=0:01:02
[32m[04/27 13:33:58 d2.evaluation.evaluator]: [0mInference done 778/1257. 0.1167 s / img. ETA=0:00:56
[32m[04/27 13:34:03 d2.evaluation.evaluator]: [0mInference done 820/1257. 0.1167 s / img. ETA=0:00:51
[32m[04/27 13:34:08 d2.evaluation.evaluator]: [0mInference done 862/1257. 0.1167 s / img. ETA=0:00:46
[32m[04/27 13:34:13 d2.evaluation.evaluator]: [0mInference done 905/1257. 0.1167 s / img. ETA=0:00:41
[32m[04/27 13:34:18 d2.evaluation.evaluator]: [0mInference done 947/1257. 0.1168 s / img. ETA=0:00:36
[32m[04/27 13:34:23 d2.evaluation.evaluator]: [0mInference done 990/1257. 0.1167 s / img. ETA=0:00:31
[32m[04/27 13:34:28 d2.evaluation.evaluator]: [0mInference done 1033/1257. 0.1167 s / img. ETA=0:00:26
[32m[04/27 13:34:33 d2.evaluation.evaluator]: [0mInference done 1076/1257. 0.1167 s / img. ETA=0:00:21
[32m[04/27 13:34:38 d2.evaluation.evaluator]: [0mInference done 1119/1257. 0.1167 s / img. ETA=0:00:16
[32m[04/27 13:34:43 d2.evaluation.evaluator]: [0mInference done 1161/1257. 0.1168 s / img. ETA=0:00:11
[32m[04/27 13:34:49 d2.evaluation.evaluator]: [0mInference done 1204/1257. 0.1168 s / img. ETA=0:00:06
[32m[04/27 13:34:54 d2.evaluation.evaluator]: [0mInference done 1246/1257. 0.1168 s / img. ETA=0:00:01
[32m[04/27 13:34:55 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:29.039025 (0.119041 s / img per device, on 1 devices)
[32m[04/27 13:34:55 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:26 (0.116793 s / img per device, on 1 devices)
[32m[04/27 13:34:55 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/27 13:34:55 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel_2/coco_instances_results.json
[32m[04/27 13:34:55 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.32s).
Accumulating evaluation results...
DONE (t=0.22s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.021
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.051
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.015
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.021
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.134
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.024
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.032
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.032
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.035
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.169
[32m[04/27 13:34:57 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 2.118 | 5.125  | 1.516  | 0.084 | 2.142 | 13.397 |
[32m[04/27 13:34:57 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP    | category      | AP    | category       | AP    |
|:--------------|:------|:--------------|:------|:---------------|:------|
| person        | 0.414 | bicycle       | 2.302 | car            | 3.638 |
| motorcycle    | nan   | airplane      | nan   | bus            | nan   |
| train         | nan   | truck         | nan   | boat           | nan   |
| traffic light | nan   | fire hydrant  | nan   | stop sign      | nan   |
| parking meter | nan   | bench         | nan   | bird           | nan   |
| cat           | nan   | dog           | nan   | horse          | nan   |
| sheep         | nan   | cow           | nan   | elephant       | nan   |
| bear          | nan   | zebra         | nan   | giraffe        | nan   |
| backpack      | nan   | umbrella      | nan   | handbag        | nan   |
| tie           | nan   | suitcase      | nan   | frisbee        | nan   |
| skis          | nan   | snowboard     | nan   | sports ball    | nan   |
| kite          | nan   | baseball bat  | nan   | baseball glove | nan   |
| skateboard    | nan   | surfboard     | nan   | tennis racket  | nan   |
| bottle        | nan   | wine glass    | nan   | cup            | nan   |
| fork          | nan   | knife         | nan   | spoon          | nan   |
| bowl          | nan   | banana        | nan   | apple          | nan   |
| sandwich      | nan   | orange        | nan   | broccoli       | nan   |
| carrot        | nan   | hot dog       | nan   | pizza          | nan   |
| donut         | nan   | cake          | nan   | chair          | nan   |
| couch         | nan   | potted plant  | nan   | bed            | nan   |
| dining table  | nan   | toilet        | nan   | tv             | nan   |
| laptop        | nan   | mouse         | nan   | remote         | nan   |
| keyboard      | nan   | cell phone    | nan   | microwave      | nan   |
| oven          | nan   | bike          | nan   | hydrant        | nan   |
| motor         | nan   | rider         | nan   | light          | nan   |
| sign          | nan   | motor vehicle | nan   | human face     | nan   |
| hair drier    | nan   | license plate | nan   |                |       |
============== The  1  *  1000  iterations ============
Require gradient = False for the first several layers of ResNet
6  channel input
[32m[04/27 13:34:57 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/27 13:34:58 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 13:34:58 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/27 13:34:58 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/27 13:34:58 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/27 13:34:58 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/27 13:34:58 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/27 13:35:19 d2.utils.events]: [0m eta: 0:16:46  iter: 19  total_loss: 0.419  loss_cls: 0.102  loss_box_reg: 0.036  loss_rpn_cls: 0.172  loss_rpn_loc: 0.113  time: 1.0120  data_time: 0.0388  lr: 0.000100  max_mem: 5404M
[32m[04/27 13:35:39 d2.utils.events]: [0m eta: 0:16:18  iter: 39  total_loss: 0.443  loss_cls: 0.093  loss_box_reg: 0.036  loss_rpn_cls: 0.187  loss_rpn_loc: 0.108  time: 1.0083  data_time: 0.0093  lr: 0.000200  max_mem: 5404M
[32m[04/27 13:35:59 d2.utils.events]: [0m eta: 0:15:54  iter: 59  total_loss: 0.446  loss_cls: 0.121  loss_box_reg: 0.043  loss_rpn_cls: 0.180  loss_rpn_loc: 0.117  time: 1.0057  data_time: 0.0093  lr: 0.000300  max_mem: 5404M
[32m[04/27 13:36:19 d2.utils.events]: [0m eta: 0:15:28  iter: 79  total_loss: 0.453  loss_cls: 0.110  loss_box_reg: 0.038  loss_rpn_cls: 0.196  loss_rpn_loc: 0.122  time: 1.0039  data_time: 0.0094  lr: 0.000400  max_mem: 5404M
[32m[04/27 13:36:40 d2.utils.events]: [0m eta: 0:15:11  iter: 99  total_loss: 0.414  loss_cls: 0.092  loss_box_reg: 0.031  loss_rpn_cls: 0.191  loss_rpn_loc: 0.104  time: 1.0043  data_time: 0.0089  lr: 0.000500  max_mem: 5404M
[32m[04/27 13:36:59 d2.utils.events]: [0m eta: 0:14:44  iter: 119  total_loss: 0.454  loss_cls: 0.095  loss_box_reg: 0.039  loss_rpn_cls: 0.211  loss_rpn_loc: 0.117  time: 0.9998  data_time: 0.0087  lr: 0.000599  max_mem: 5404M
[32m[04/27 13:37:19 d2.utils.events]: [0m eta: 0:14:21  iter: 139  total_loss: 0.401  loss_cls: 0.089  loss_box_reg: 0.033  loss_rpn_cls: 0.177  loss_rpn_loc: 0.100  time: 0.9996  data_time: 0.0090  lr: 0.000699  max_mem: 5404M
[32m[04/27 13:37:40 d2.utils.events]: [0m eta: 0:14:05  iter: 159  total_loss: 0.462  loss_cls: 0.117  loss_box_reg: 0.045  loss_rpn_cls: 0.191  loss_rpn_loc: 0.118  time: 1.0022  data_time: 0.0091  lr: 0.000799  max_mem: 5404M
[32m[04/27 13:38:00 d2.utils.events]: [0m eta: 0:13:46  iter: 179  total_loss: 0.441  loss_cls: 0.100  loss_box_reg: 0.040  loss_rpn_cls: 0.178  loss_rpn_loc: 0.113  time: 1.0030  data_time: 0.0090  lr: 0.000899  max_mem: 5404M
[32m[04/27 13:38:20 d2.utils.events]: [0m eta: 0:13:29  iter: 199  total_loss: 0.397  loss_cls: 0.081  loss_box_reg: 0.033  loss_rpn_cls: 0.179  loss_rpn_loc: 0.116  time: 1.0030  data_time: 0.0096  lr: 0.000999  max_mem: 5404M
[32m[04/27 13:38:40 d2.utils.events]: [0m eta: 0:13:11  iter: 219  total_loss: 0.418  loss_cls: 0.072  loss_box_reg: 0.024  loss_rpn_cls: 0.174  loss_rpn_loc: 0.104  time: 1.0036  data_time: 0.0090  lr: 0.001099  max_mem: 5404M
[32m[04/27 13:39:01 d2.utils.events]: [0m eta: 0:12:52  iter: 239  total_loss: 0.444  loss_cls: 0.061  loss_box_reg: 0.018  loss_rpn_cls: 0.180  loss_rpn_loc: 0.123  time: 1.0047  data_time: 0.0092  lr: 0.001199  max_mem: 5404M
[32m[04/27 13:39:21 d2.utils.events]: [0m eta: 0:12:34  iter: 259  total_loss: 0.381  loss_cls: 0.076  loss_box_reg: 0.030  loss_rpn_cls: 0.184  loss_rpn_loc: 0.107  time: 1.0054  data_time: 0.0093  lr: 0.001299  max_mem: 5404M
[32m[04/27 13:39:42 d2.utils.events]: [0m eta: 0:12:17  iter: 279  total_loss: 0.458  loss_cls: 0.122  loss_box_reg: 0.055  loss_rpn_cls: 0.177  loss_rpn_loc: 0.109  time: 1.0075  data_time: 0.0091  lr: 0.001399  max_mem: 5404M
[32m[04/27 13:40:02 d2.utils.events]: [0m eta: 0:11:55  iter: 299  total_loss: 0.471  loss_cls: 0.118  loss_box_reg: 0.052  loss_rpn_cls: 0.187  loss_rpn_loc: 0.118  time: 1.0068  data_time: 0.0092  lr: 0.001499  max_mem: 5404M
[32m[04/27 13:40:22 d2.utils.events]: [0m eta: 0:11:33  iter: 319  total_loss: 0.428  loss_cls: 0.097  loss_box_reg: 0.051  loss_rpn_cls: 0.176  loss_rpn_loc: 0.091  time: 1.0065  data_time: 0.0099  lr: 0.001598  max_mem: 5404M
[32m[04/27 13:40:42 d2.utils.events]: [0m eta: 0:11:11  iter: 339  total_loss: 0.386  loss_cls: 0.089  loss_box_reg: 0.042  loss_rpn_cls: 0.184  loss_rpn_loc: 0.104  time: 1.0061  data_time: 0.0093  lr: 0.001698  max_mem: 5404M
[32m[04/27 13:41:02 d2.utils.events]: [0m eta: 0:10:52  iter: 359  total_loss: 0.416  loss_cls: 0.079  loss_box_reg: 0.031  loss_rpn_cls: 0.173  loss_rpn_loc: 0.115  time: 1.0069  data_time: 0.0091  lr: 0.001798  max_mem: 5404M
[32m[04/27 13:41:22 d2.utils.events]: [0m eta: 0:10:30  iter: 379  total_loss: 0.457  loss_cls: 0.092  loss_box_reg: 0.042  loss_rpn_cls: 0.170  loss_rpn_loc: 0.113  time: 1.0068  data_time: 0.0091  lr: 0.001898  max_mem: 5404M
[32m[04/27 13:41:43 d2.utils.events]: [0m eta: 0:10:13  iter: 399  total_loss: 0.533  loss_cls: 0.145  loss_box_reg: 0.072  loss_rpn_cls: 0.189  loss_rpn_loc: 0.122  time: 1.0085  data_time: 0.0101  lr: 0.001998  max_mem: 5404M
[32m[04/27 13:42:04 d2.utils.events]: [0m eta: 0:09:53  iter: 419  total_loss: 0.430  loss_cls: 0.102  loss_box_reg: 0.052  loss_rpn_cls: 0.170  loss_rpn_loc: 0.105  time: 1.0088  data_time: 0.0091  lr: 0.002098  max_mem: 5404M
[32m[04/27 13:42:24 d2.utils.events]: [0m eta: 0:09:33  iter: 439  total_loss: 0.354  loss_cls: 0.077  loss_box_reg: 0.025  loss_rpn_cls: 0.162  loss_rpn_loc: 0.091  time: 1.0090  data_time: 0.0093  lr: 0.002198  max_mem: 5404M
[32m[04/27 13:42:44 d2.utils.events]: [0m eta: 0:09:13  iter: 459  total_loss: 0.386  loss_cls: 0.072  loss_box_reg: 0.033  loss_rpn_cls: 0.174  loss_rpn_loc: 0.092  time: 1.0087  data_time: 0.0092  lr: 0.002298  max_mem: 5404M
[32m[04/27 13:43:04 d2.utils.events]: [0m eta: 0:08:52  iter: 479  total_loss: 0.415  loss_cls: 0.090  loss_box_reg: 0.042  loss_rpn_cls: 0.177  loss_rpn_loc: 0.104  time: 1.0087  data_time: 0.0092  lr: 0.002398  max_mem: 5404M
[32m[04/27 13:43:25 d2.utils.events]: [0m eta: 0:08:31  iter: 499  total_loss: 0.415  loss_cls: 0.074  loss_box_reg: 0.023  loss_rpn_cls: 0.172  loss_rpn_loc: 0.120  time: 1.0088  data_time: 0.0093  lr: 0.002498  max_mem: 5404M
[32m[04/27 13:43:44 d2.utils.events]: [0m eta: 0:08:09  iter: 519  total_loss: 0.462  loss_cls: 0.082  loss_box_reg: 0.030  loss_rpn_cls: 0.195  loss_rpn_loc: 0.132  time: 1.0080  data_time: 0.0090  lr: 0.002597  max_mem: 5404M
[32m[04/27 13:44:04 d2.utils.events]: [0m eta: 0:07:48  iter: 539  total_loss: 0.398  loss_cls: 0.079  loss_box_reg: 0.025  loss_rpn_cls: 0.182  loss_rpn_loc: 0.109  time: 1.0078  data_time: 0.0090  lr: 0.002697  max_mem: 5404M
[32m[04/27 13:44:25 d2.utils.events]: [0m eta: 0:07:30  iter: 559  total_loss: 0.379  loss_cls: 0.060  loss_box_reg: 0.014  loss_rpn_cls: 0.186  loss_rpn_loc: 0.100  time: 1.0091  data_time: 0.0094  lr: 0.002797  max_mem: 5404M
[32m[04/27 13:44:45 d2.utils.events]: [0m eta: 0:07:09  iter: 579  total_loss: 0.438  loss_cls: 0.097  loss_box_reg: 0.025  loss_rpn_cls: 0.178  loss_rpn_loc: 0.091  time: 1.0087  data_time: 0.0091  lr: 0.002897  max_mem: 5404M
[32m[04/27 13:45:06 d2.utils.events]: [0m eta: 0:06:48  iter: 599  total_loss: 0.502  loss_cls: 0.103  loss_box_reg: 0.048  loss_rpn_cls: 0.203  loss_rpn_loc: 0.127  time: 1.0087  data_time: 0.0093  lr: 0.002997  max_mem: 5404M
[32m[04/27 13:45:26 d2.utils.events]: [0m eta: 0:06:28  iter: 619  total_loss: 0.485  loss_cls: 0.093  loss_box_reg: 0.034  loss_rpn_cls: 0.213  loss_rpn_loc: 0.134  time: 1.0087  data_time: 0.0093  lr: 0.003097  max_mem: 5404M
[32m[04/27 13:45:46 d2.utils.events]: [0m eta: 0:06:08  iter: 639  total_loss: 0.540  loss_cls: 0.131  loss_box_reg: 0.061  loss_rpn_cls: 0.182  loss_rpn_loc: 0.112  time: 1.0091  data_time: 0.0092  lr: 0.003197  max_mem: 5404M
[32m[04/27 13:46:07 d2.utils.events]: [0m eta: 0:05:48  iter: 659  total_loss: 0.444  loss_cls: 0.093  loss_box_reg: 0.033  loss_rpn_cls: 0.181  loss_rpn_loc: 0.121  time: 1.0096  data_time: 0.0088  lr: 0.003297  max_mem: 5404M
[32m[04/27 13:46:27 d2.utils.events]: [0m eta: 0:05:27  iter: 679  total_loss: 0.476  loss_cls: 0.102  loss_box_reg: 0.034  loss_rpn_cls: 0.197  loss_rpn_loc: 0.124  time: 1.0093  data_time: 0.0090  lr: 0.003397  max_mem: 5404M
[32m[04/27 13:46:48 d2.utils.events]: [0m eta: 0:05:07  iter: 699  total_loss: 0.393  loss_cls: 0.084  loss_box_reg: 0.034  loss_rpn_cls: 0.182  loss_rpn_loc: 0.093  time: 1.0100  data_time: 0.0094  lr: 0.003497  max_mem: 5404M
[32m[04/27 13:47:08 d2.utils.events]: [0m eta: 0:04:47  iter: 719  total_loss: 0.345  loss_cls: 0.074  loss_box_reg: 0.035  loss_rpn_cls: 0.158  loss_rpn_loc: 0.097  time: 1.0098  data_time: 0.0093  lr: 0.003596  max_mem: 5404M
[32m[04/27 13:47:28 d2.utils.events]: [0m eta: 0:04:26  iter: 739  total_loss: 0.470  loss_cls: 0.098  loss_box_reg: 0.044  loss_rpn_cls: 0.196  loss_rpn_loc: 0.124  time: 1.0098  data_time: 0.0093  lr: 0.003696  max_mem: 5404M
[32m[04/27 13:47:48 d2.utils.events]: [0m eta: 0:04:06  iter: 759  total_loss: 0.498  loss_cls: 0.110  loss_box_reg: 0.042  loss_rpn_cls: 0.192  loss_rpn_loc: 0.102  time: 1.0096  data_time: 0.0094  lr: 0.003796  max_mem: 5404M
[32m[04/27 13:48:08 d2.utils.events]: [0m eta: 0:03:45  iter: 779  total_loss: 0.426  loss_cls: 0.122  loss_box_reg: 0.045  loss_rpn_cls: 0.180  loss_rpn_loc: 0.102  time: 1.0098  data_time: 0.0092  lr: 0.003896  max_mem: 5404M
[32m[04/27 13:48:29 d2.utils.events]: [0m eta: 0:03:25  iter: 799  total_loss: 0.419  loss_cls: 0.100  loss_box_reg: 0.040  loss_rpn_cls: 0.178  loss_rpn_loc: 0.110  time: 1.0097  data_time: 0.0092  lr: 0.003996  max_mem: 5404M
[32m[04/27 13:48:49 d2.utils.events]: [0m eta: 0:03:04  iter: 819  total_loss: 0.419  loss_cls: 0.099  loss_box_reg: 0.036  loss_rpn_cls: 0.185  loss_rpn_loc: 0.114  time: 1.0096  data_time: 0.0103  lr: 0.004096  max_mem: 5404M
[32m[04/27 13:49:09 d2.utils.events]: [0m eta: 0:02:44  iter: 839  total_loss: 0.472  loss_cls: 0.108  loss_box_reg: 0.045  loss_rpn_cls: 0.179  loss_rpn_loc: 0.109  time: 1.0096  data_time: 0.0096  lr: 0.004196  max_mem: 5404M
[32m[04/27 13:49:29 d2.utils.events]: [0m eta: 0:02:23  iter: 859  total_loss: 0.444  loss_cls: 0.074  loss_box_reg: 0.027  loss_rpn_cls: 0.208  loss_rpn_loc: 0.107  time: 1.0091  data_time: 0.0092  lr: 0.004296  max_mem: 5404M
[32m[04/27 13:49:49 d2.utils.events]: [0m eta: 0:02:03  iter: 879  total_loss: 0.475  loss_cls: 0.104  loss_box_reg: 0.046  loss_rpn_cls: 0.201  loss_rpn_loc: 0.110  time: 1.0095  data_time: 0.0094  lr: 0.004396  max_mem: 5404M
[32m[04/27 13:50:10 d2.utils.events]: [0m eta: 0:01:43  iter: 899  total_loss: 0.589  loss_cls: 0.167  loss_box_reg: 0.082  loss_rpn_cls: 0.187  loss_rpn_loc: 0.138  time: 1.0097  data_time: 0.0094  lr: 0.004496  max_mem: 5404M
[32m[04/27 13:50:30 d2.utils.events]: [0m eta: 0:01:22  iter: 919  total_loss: 0.428  loss_cls: 0.096  loss_box_reg: 0.037  loss_rpn_cls: 0.178  loss_rpn_loc: 0.104  time: 1.0098  data_time: 0.0096  lr: 0.004595  max_mem: 5404M
[32m[04/27 13:50:50 d2.utils.events]: [0m eta: 0:01:02  iter: 939  total_loss: 0.455  loss_cls: 0.099  loss_box_reg: 0.040  loss_rpn_cls: 0.174  loss_rpn_loc: 0.128  time: 1.0094  data_time: 0.0094  lr: 0.004695  max_mem: 5404M
[32m[04/27 13:51:11 d2.utils.events]: [0m eta: 0:00:41  iter: 959  total_loss: 0.394  loss_cls: 0.083  loss_box_reg: 0.026  loss_rpn_cls: 0.175  loss_rpn_loc: 0.098  time: 1.0102  data_time: 0.0094  lr: 0.004795  max_mem: 5404M
[32m[04/27 13:51:31 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.410  loss_cls: 0.073  loss_box_reg: 0.023  loss_rpn_cls: 0.189  loss_rpn_loc: 0.103  time: 1.0101  data_time: 0.0101  lr: 0.004895  max_mem: 5404M
[5m[31mWARNING[0m [32m[04/27 13:51:54 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 13:51:54 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/27 13:51:54 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/27 13:51:54 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.432  loss_cls: 0.094  loss_box_reg: 0.048  loss_rpn_cls: 0.171  loss_rpn_loc: 0.090  time: 1.0102  data_time: 0.0091  lr: 0.004995  max_mem: 5404M
[32m[04/27 13:51:55 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:16:48 (1.0112 s / it)
[32m[04/27 13:51:55 d2.engine.hooks]: [0mTotal training time: 0:16:53 (0:00:05 on hooks)
Require gradient = False for the first several layers of ResNet
6  channel input
[5m[31mWARNING[0m [32m[04/27 13:51:58 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/27 13:51:58 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/27 13:51:58 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/27 13:52:00 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1118 s / img. ETA=0:15:47
[32m[04/27 13:52:05 d2.evaluation.evaluator]: [0mInference done 55/8355. 0.1117 s / img. ETA=0:15:44
[32m[04/27 13:52:10 d2.evaluation.evaluator]: [0mInference done 99/8355. 0.1117 s / img. ETA=0:15:39
[32m[04/27 13:52:15 d2.evaluation.evaluator]: [0mInference done 143/8355. 0.1117 s / img. ETA=0:15:34
[32m[04/27 13:52:20 d2.evaluation.evaluator]: [0mInference done 187/8355. 0.1117 s / img. ETA=0:15:29
[32m[04/27 13:52:25 d2.evaluation.evaluator]: [0mInference done 232/8355. 0.1116 s / img. ETA=0:15:23
[32m[04/27 13:52:30 d2.evaluation.evaluator]: [0mInference done 277/8355. 0.1116 s / img. ETA=0:15:18
[32m[04/27 13:52:35 d2.evaluation.evaluator]: [0mInference done 321/8355. 0.1116 s / img. ETA=0:15:13
[32m[04/27 13:52:40 d2.evaluation.evaluator]: [0mInference done 366/8355. 0.1116 s / img. ETA=0:15:08
[32m[04/27 13:52:45 d2.evaluation.evaluator]: [0mInference done 410/8355. 0.1116 s / img. ETA=0:15:03
[32m[04/27 13:52:50 d2.evaluation.evaluator]: [0mInference done 455/8355. 0.1116 s / img. ETA=0:14:58
[32m[04/27 13:52:55 d2.evaluation.evaluator]: [0mInference done 499/8355. 0.1116 s / img. ETA=0:14:53
[32m[04/27 13:53:00 d2.evaluation.evaluator]: [0mInference done 544/8355. 0.1116 s / img. ETA=0:14:48
[32m[04/27 13:53:05 d2.evaluation.evaluator]: [0mInference done 588/8355. 0.1116 s / img. ETA=0:14:43
[32m[04/27 13:53:10 d2.evaluation.evaluator]: [0mInference done 633/8355. 0.1115 s / img. ETA=0:14:37
[32m[04/27 13:53:15 d2.evaluation.evaluator]: [0mInference done 678/8355. 0.1115 s / img. ETA=0:14:32
[32m[04/27 13:53:21 d2.evaluation.evaluator]: [0mInference done 723/8355. 0.1115 s / img. ETA=0:14:27
[32m[04/27 13:53:26 d2.evaluation.evaluator]: [0mInference done 767/8355. 0.1115 s / img. ETA=0:14:22
[32m[04/27 13:53:31 d2.evaluation.evaluator]: [0mInference done 812/8355. 0.1115 s / img. ETA=0:14:17
[32m[04/27 13:53:36 d2.evaluation.evaluator]: [0mInference done 857/8355. 0.1115 s / img. ETA=0:14:12
[32m[04/27 13:53:41 d2.evaluation.evaluator]: [0mInference done 902/8355. 0.1115 s / img. ETA=0:14:07
[32m[04/27 13:53:46 d2.evaluation.evaluator]: [0mInference done 947/8355. 0.1115 s / img. ETA=0:14:01
[32m[04/27 13:53:51 d2.evaluation.evaluator]: [0mInference done 992/8355. 0.1115 s / img. ETA=0:13:56
[32m[04/27 13:53:56 d2.evaluation.evaluator]: [0mInference done 1036/8355. 0.1115 s / img. ETA=0:13:51
[32m[04/27 13:54:01 d2.evaluation.evaluator]: [0mInference done 1081/8355. 0.1115 s / img. ETA=0:13:46
[32m[04/27 13:54:06 d2.evaluation.evaluator]: [0mInference done 1125/8355. 0.1115 s / img. ETA=0:13:41
[32m[04/27 13:54:11 d2.evaluation.evaluator]: [0mInference done 1169/8355. 0.1115 s / img. ETA=0:13:36
[32m[04/27 13:54:16 d2.evaluation.evaluator]: [0mInference done 1213/8355. 0.1115 s / img. ETA=0:13:31
[32m[04/27 13:54:21 d2.evaluation.evaluator]: [0mInference done 1257/8355. 0.1115 s / img. ETA=0:13:26
[32m[04/27 13:54:26 d2.evaluation.evaluator]: [0mInference done 1301/8355. 0.1115 s / img. ETA=0:13:21
[32m[04/27 13:54:31 d2.evaluation.evaluator]: [0mInference done 1345/8355. 0.1115 s / img. ETA=0:13:16
[32m[04/27 13:54:36 d2.evaluation.evaluator]: [0mInference done 1390/8355. 0.1115 s / img. ETA=0:13:11
[32m[04/27 13:54:41 d2.evaluation.evaluator]: [0mInference done 1434/8355. 0.1115 s / img. ETA=0:13:06
[32m[04/27 13:54:46 d2.evaluation.evaluator]: [0mInference done 1478/8355. 0.1115 s / img. ETA=0:13:01
[32m[04/27 13:54:51 d2.evaluation.evaluator]: [0mInference done 1522/8355. 0.1115 s / img. ETA=0:12:56
[32m[04/27 13:54:56 d2.evaluation.evaluator]: [0mInference done 1566/8355. 0.1115 s / img. ETA=0:12:51
[32m[04/27 13:55:01 d2.evaluation.evaluator]: [0mInference done 1610/8355. 0.1115 s / img. ETA=0:12:46
[32m[04/27 13:55:06 d2.evaluation.evaluator]: [0mInference done 1654/8355. 0.1115 s / img. ETA=0:12:41
[32m[04/27 13:55:11 d2.evaluation.evaluator]: [0mInference done 1698/8355. 0.1115 s / img. ETA=0:12:36
[32m[04/27 13:55:16 d2.evaluation.evaluator]: [0mInference done 1742/8355. 0.1115 s / img. ETA=0:12:31
[32m[04/27 13:55:21 d2.evaluation.evaluator]: [0mInference done 1786/8355. 0.1115 s / img. ETA=0:12:26
[32m[04/27 13:55:26 d2.evaluation.evaluator]: [0mInference done 1830/8355. 0.1115 s / img. ETA=0:12:21
[32m[04/27 13:55:31 d2.evaluation.evaluator]: [0mInference done 1874/8355. 0.1115 s / img. ETA=0:12:16
