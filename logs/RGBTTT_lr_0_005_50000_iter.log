../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
3 channel input
Require gradient = False for the first several layers of ResNet
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/19 21:33:59 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/19 21:34:00 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 21:34:00 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/19 21:34:00 d2.data.build]: [0mRemoved 889 images with no usable annotations. 7466 images left.
[32m[04/19 21:34:00 d2.data.build]: [0mDistribution of instances among all 79 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 21744        |    bicycle    | 3806         |      car      | 39372        |
|  motorcycle   | 0            |   airplane    | 0            |      bus      | 0            |
|     train     | 0            |     truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant  | 0            |   stop sign   | 0            |
| parking meter | 0            |     bench     | 0            |     bird      | 0            |
|      cat      | 0            |      dog      | 219          |     horse     | 0            |
|     sheep     | 0            |      cow      | 0            |   elephant    | 0            |
|     bear      | 0            |     zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella    | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase    | 0            |    frisbee    | 0            |
|     skis      | 0            |   snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat  | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |   surfboard   | 0            | tennis racket | 0            |
|    bottle     | 0            |  wine glass   | 0            |      cup      | 0            |
|     fork      | 0            |     knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana     | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange     | 0            |   broccoli    | 0            |
|    carrot     | 0            |    hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake      | 0            |     chair     | 0            |
|     couch     | 0            | potted plant  | 0            |      bed      | 0            |
| dining table  | 0            |    toilet     | 0            |      tv       | 0            |
|    laptop     | 0            |     mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone   | 0            |   microwave   | 0            |
|     oven      | 0            |     bike      | 0            |    hydrant    | 0            |
|     motor     | 0            |     rider     | 0            |     light     | 0            |
|     sign      | 0            | motor vehicle | 0            |  human face   | 0            |
|  hair drier   | 0            |               |              |               |              |
|     total     | 65141        |               |              |               |              |[0m
[32m[04/19 21:34:00 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/19 21:34:00 d2.data.build]: [0mUsing training sampler TrainingSampler
============== The  0  *  1000  iterations ============
[32m[04/19 21:34:00 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/19 21:34:12 d2.utils.events]: [0m eta: 0:08:29  iter: 19  total_loss: 1.410  loss_cls: 0.374  loss_box_reg: 0.148  loss_rpn_cls: 0.820  loss_rpn_loc: 0.134  time: 0.5242  data_time: 0.0245  lr: 0.000100  max_mem: 3094M
[32m[04/19 21:34:22 d2.utils.events]: [0m eta: 0:08:14  iter: 39  total_loss: 0.881  loss_cls: 0.277  loss_box_reg: 0.166  loss_rpn_cls: 0.218  loss_rpn_loc: 0.121  time: 0.5133  data_time: 0.0048  lr: 0.000200  max_mem: 3094M
[32m[04/19 21:34:32 d2.utils.events]: [0m eta: 0:08:08  iter: 59  total_loss: 0.695  loss_cls: 0.249  loss_box_reg: 0.194  loss_rpn_cls: 0.155  loss_rpn_loc: 0.103  time: 0.5160  data_time: 0.0049  lr: 0.000300  max_mem: 3094M
[32m[04/19 21:34:43 d2.utils.events]: [0m eta: 0:07:57  iter: 79  total_loss: 0.897  loss_cls: 0.322  loss_box_reg: 0.317  loss_rpn_cls: 0.128  loss_rpn_loc: 0.105  time: 0.5165  data_time: 0.0052  lr: 0.000400  max_mem: 3094M
[32m[04/19 21:34:53 d2.utils.events]: [0m eta: 0:07:48  iter: 99  total_loss: 0.838  loss_cls: 0.306  loss_box_reg: 0.254  loss_rpn_cls: 0.149  loss_rpn_loc: 0.094  time: 0.5173  data_time: 0.0050  lr: 0.000500  max_mem: 3094M
[32m[04/19 21:35:03 d2.utils.events]: [0m eta: 0:07:36  iter: 119  total_loss: 0.849  loss_cls: 0.291  loss_box_reg: 0.266  loss_rpn_cls: 0.111  loss_rpn_loc: 0.095  time: 0.5159  data_time: 0.0050  lr: 0.000599  max_mem: 3094M
[32m[04/19 21:35:14 d2.utils.events]: [0m eta: 0:07:26  iter: 139  total_loss: 0.721  loss_cls: 0.251  loss_box_reg: 0.226  loss_rpn_cls: 0.106  loss_rpn_loc: 0.090  time: 0.5162  data_time: 0.0048  lr: 0.000699  max_mem: 3094M
[32m[04/19 21:35:24 d2.utils.events]: [0m eta: 0:07:14  iter: 159  total_loss: 0.736  loss_cls: 0.263  loss_box_reg: 0.297  loss_rpn_cls: 0.089  loss_rpn_loc: 0.098  time: 0.5160  data_time: 0.0049  lr: 0.000799  max_mem: 3094M
[32m[04/19 21:35:34 d2.utils.events]: [0m eta: 0:07:03  iter: 179  total_loss: 0.880  loss_cls: 0.285  loss_box_reg: 0.305  loss_rpn_cls: 0.103  loss_rpn_loc: 0.104  time: 0.5168  data_time: 0.0050  lr: 0.000899  max_mem: 3094M
[32m[04/19 21:35:45 d2.utils.events]: [0m eta: 0:06:53  iter: 199  total_loss: 0.897  loss_cls: 0.314  loss_box_reg: 0.385  loss_rpn_cls: 0.101  loss_rpn_loc: 0.099  time: 0.5153  data_time: 0.0048  lr: 0.000999  max_mem: 3094M
[32m[04/19 21:35:55 d2.utils.events]: [0m eta: 0:06:44  iter: 219  total_loss: 0.839  loss_cls: 0.300  loss_box_reg: 0.342  loss_rpn_cls: 0.083  loss_rpn_loc: 0.081  time: 0.5153  data_time: 0.0049  lr: 0.001099  max_mem: 3094M
[32m[04/19 21:36:05 d2.utils.events]: [0m eta: 0:06:34  iter: 239  total_loss: 1.000  loss_cls: 0.358  loss_box_reg: 0.423  loss_rpn_cls: 0.094  loss_rpn_loc: 0.110  time: 0.5155  data_time: 0.0053  lr: 0.001199  max_mem: 3094M
[32m[04/19 21:36:16 d2.utils.events]: [0m eta: 0:06:22  iter: 259  total_loss: 0.824  loss_cls: 0.306  loss_box_reg: 0.300  loss_rpn_cls: 0.103  loss_rpn_loc: 0.087  time: 0.5149  data_time: 0.0049  lr: 0.001299  max_mem: 3094M
[32m[04/19 21:36:26 d2.utils.events]: [0m eta: 0:06:13  iter: 279  total_loss: 0.681  loss_cls: 0.246  loss_box_reg: 0.307  loss_rpn_cls: 0.060  loss_rpn_loc: 0.062  time: 0.5155  data_time: 0.0049  lr: 0.001399  max_mem: 3094M
[32m[04/19 21:36:36 d2.utils.events]: [0m eta: 0:06:01  iter: 299  total_loss: 0.855  loss_cls: 0.309  loss_box_reg: 0.397  loss_rpn_cls: 0.064  loss_rpn_loc: 0.080  time: 0.5147  data_time: 0.0050  lr: 0.001499  max_mem: 3094M
[32m[04/19 21:36:47 d2.utils.events]: [0m eta: 0:05:52  iter: 319  total_loss: 0.780  loss_cls: 0.288  loss_box_reg: 0.290  loss_rpn_cls: 0.086  loss_rpn_loc: 0.096  time: 0.5155  data_time: 0.0053  lr: 0.001598  max_mem: 3094M
[32m[04/19 21:36:57 d2.utils.events]: [0m eta: 0:05:42  iter: 339  total_loss: 0.805  loss_cls: 0.285  loss_box_reg: 0.306  loss_rpn_cls: 0.072  loss_rpn_loc: 0.068  time: 0.5157  data_time: 0.0049  lr: 0.001698  max_mem: 3094M
[32m[04/19 21:37:08 d2.utils.events]: [0m eta: 0:05:31  iter: 359  total_loss: 0.894  loss_cls: 0.295  loss_box_reg: 0.373  loss_rpn_cls: 0.088  loss_rpn_loc: 0.080  time: 0.5161  data_time: 0.0049  lr: 0.001798  max_mem: 3094M
[32m[04/19 21:37:18 d2.utils.events]: [0m eta: 0:05:21  iter: 379  total_loss: 1.026  loss_cls: 0.359  loss_box_reg: 0.471  loss_rpn_cls: 0.068  loss_rpn_loc: 0.096  time: 0.5167  data_time: 0.0051  lr: 0.001898  max_mem: 3094M
[32m[04/19 21:37:28 d2.utils.events]: [0m eta: 0:05:11  iter: 399  total_loss: 0.731  loss_cls: 0.272  loss_box_reg: 0.304  loss_rpn_cls: 0.078  loss_rpn_loc: 0.076  time: 0.5161  data_time: 0.0049  lr: 0.001998  max_mem: 3094M
[32m[04/19 21:37:39 d2.utils.events]: [0m eta: 0:05:01  iter: 419  total_loss: 0.740  loss_cls: 0.287  loss_box_reg: 0.327  loss_rpn_cls: 0.063  loss_rpn_loc: 0.074  time: 0.5165  data_time: 0.0052  lr: 0.002098  max_mem: 3094M
[32m[04/19 21:37:50 d2.utils.events]: [0m eta: 0:04:50  iter: 439  total_loss: 0.784  loss_cls: 0.283  loss_box_reg: 0.349  loss_rpn_cls: 0.068  loss_rpn_loc: 0.065  time: 0.5170  data_time: 0.0050  lr: 0.002198  max_mem: 3094M
[32m[04/19 21:38:00 d2.utils.events]: [0m eta: 0:04:40  iter: 459  total_loss: 0.764  loss_cls: 0.289  loss_box_reg: 0.317  loss_rpn_cls: 0.070  loss_rpn_loc: 0.066  time: 0.5170  data_time: 0.0051  lr: 0.002298  max_mem: 3094M
[32m[04/19 21:38:11 d2.utils.events]: [0m eta: 0:04:30  iter: 479  total_loss: 0.840  loss_cls: 0.300  loss_box_reg: 0.330  loss_rpn_cls: 0.065  loss_rpn_loc: 0.072  time: 0.5173  data_time: 0.0051  lr: 0.002398  max_mem: 3094M
[32m[04/19 21:38:21 d2.utils.events]: [0m eta: 0:04:19  iter: 499  total_loss: 0.912  loss_cls: 0.339  loss_box_reg: 0.411  loss_rpn_cls: 0.065  loss_rpn_loc: 0.084  time: 0.5180  data_time: 0.0049  lr: 0.002498  max_mem: 3094M
[32m[04/19 21:38:32 d2.utils.events]: [0m eta: 0:04:09  iter: 519  total_loss: 0.832  loss_cls: 0.305  loss_box_reg: 0.365  loss_rpn_cls: 0.051  loss_rpn_loc: 0.082  time: 0.5185  data_time: 0.0050  lr: 0.002597  max_mem: 3094M
[32m[04/19 21:38:42 d2.utils.events]: [0m eta: 0:03:59  iter: 539  total_loss: 0.824  loss_cls: 0.256  loss_box_reg: 0.362  loss_rpn_cls: 0.047  loss_rpn_loc: 0.072  time: 0.5179  data_time: 0.0047  lr: 0.002697  max_mem: 3094M
[32m[04/19 21:38:53 d2.utils.events]: [0m eta: 0:03:48  iter: 559  total_loss: 0.806  loss_cls: 0.292  loss_box_reg: 0.388  loss_rpn_cls: 0.060  loss_rpn_loc: 0.063  time: 0.5182  data_time: 0.0048  lr: 0.002797  max_mem: 3094M
[32m[04/19 21:39:03 d2.utils.events]: [0m eta: 0:03:38  iter: 579  total_loss: 0.918  loss_cls: 0.338  loss_box_reg: 0.411  loss_rpn_cls: 0.061  loss_rpn_loc: 0.083  time: 0.5176  data_time: 0.0046  lr: 0.002897  max_mem: 3094M
[32m[04/19 21:39:13 d2.utils.events]: [0m eta: 0:03:27  iter: 599  total_loss: 0.891  loss_cls: 0.316  loss_box_reg: 0.444  loss_rpn_cls: 0.048  loss_rpn_loc: 0.080  time: 0.5170  data_time: 0.0050  lr: 0.002997  max_mem: 3094M
[32m[04/19 21:39:23 d2.utils.events]: [0m eta: 0:03:17  iter: 619  total_loss: 0.882  loss_cls: 0.278  loss_box_reg: 0.435  loss_rpn_cls: 0.057  loss_rpn_loc: 0.069  time: 0.5169  data_time: 0.0047  lr: 0.003097  max_mem: 3094M
[32m[04/19 21:39:33 d2.utils.events]: [0m eta: 0:03:06  iter: 639  total_loss: 0.760  loss_cls: 0.293  loss_box_reg: 0.361  loss_rpn_cls: 0.068  loss_rpn_loc: 0.065  time: 0.5169  data_time: 0.0047  lr: 0.003197  max_mem: 3094M
[32m[04/19 21:39:44 d2.utils.events]: [0m eta: 0:02:56  iter: 659  total_loss: 0.685  loss_cls: 0.253  loss_box_reg: 0.309  loss_rpn_cls: 0.055  loss_rpn_loc: 0.070  time: 0.5172  data_time: 0.0048  lr: 0.003297  max_mem: 3094M
[32m[04/19 21:39:55 d2.utils.events]: [0m eta: 0:02:46  iter: 679  total_loss: 1.007  loss_cls: 0.338  loss_box_reg: 0.447  loss_rpn_cls: 0.053  loss_rpn_loc: 0.106  time: 0.5174  data_time: 0.0051  lr: 0.003397  max_mem: 3094M
[32m[04/19 21:40:05 d2.utils.events]: [0m eta: 0:02:36  iter: 699  total_loss: 0.815  loss_cls: 0.272  loss_box_reg: 0.378  loss_rpn_cls: 0.059  loss_rpn_loc: 0.063  time: 0.5175  data_time: 0.0050  lr: 0.003497  max_mem: 3094M
[32m[04/19 21:40:16 d2.utils.events]: [0m eta: 0:02:25  iter: 719  total_loss: 0.756  loss_cls: 0.271  loss_box_reg: 0.340  loss_rpn_cls: 0.062  loss_rpn_loc: 0.075  time: 0.5181  data_time: 0.0050  lr: 0.003596  max_mem: 3094M
[32m[04/19 21:40:26 d2.utils.events]: [0m eta: 0:02:15  iter: 739  total_loss: 0.878  loss_cls: 0.304  loss_box_reg: 0.425  loss_rpn_cls: 0.050  loss_rpn_loc: 0.080  time: 0.5183  data_time: 0.0048  lr: 0.003696  max_mem: 3094M
[32m[04/19 21:40:37 d2.utils.events]: [0m eta: 0:02:04  iter: 759  total_loss: 0.768  loss_cls: 0.276  loss_box_reg: 0.352  loss_rpn_cls: 0.054  loss_rpn_loc: 0.060  time: 0.5181  data_time: 0.0047  lr: 0.003796  max_mem: 3094M
[32m[04/19 21:40:47 d2.utils.events]: [0m eta: 0:01:54  iter: 779  total_loss: 0.742  loss_cls: 0.258  loss_box_reg: 0.302  loss_rpn_cls: 0.066  loss_rpn_loc: 0.058  time: 0.5181  data_time: 0.0048  lr: 0.003896  max_mem: 3094M
[32m[04/19 21:40:58 d2.utils.events]: [0m eta: 0:01:44  iter: 799  total_loss: 0.754  loss_cls: 0.283  loss_box_reg: 0.329  loss_rpn_cls: 0.054  loss_rpn_loc: 0.072  time: 0.5183  data_time: 0.0051  lr: 0.003996  max_mem: 3094M
[32m[04/19 21:41:08 d2.utils.events]: [0m eta: 0:01:33  iter: 819  total_loss: 1.004  loss_cls: 0.343  loss_box_reg: 0.483  loss_rpn_cls: 0.051  loss_rpn_loc: 0.094  time: 0.5186  data_time: 0.0049  lr: 0.004096  max_mem: 3094M
[32m[04/19 21:41:19 d2.utils.events]: [0m eta: 0:01:23  iter: 839  total_loss: 0.632  loss_cls: 0.231  loss_box_reg: 0.289  loss_rpn_cls: 0.042  loss_rpn_loc: 0.059  time: 0.5189  data_time: 0.0046  lr: 0.004196  max_mem: 3094M
[32m[04/19 21:41:29 d2.utils.events]: [0m eta: 0:01:13  iter: 859  total_loss: 0.753  loss_cls: 0.294  loss_box_reg: 0.339  loss_rpn_cls: 0.065  loss_rpn_loc: 0.049  time: 0.5190  data_time: 0.0047  lr: 0.004296  max_mem: 3094M
[32m[04/19 21:41:40 d2.utils.events]: [0m eta: 0:01:02  iter: 879  total_loss: 0.796  loss_cls: 0.314  loss_box_reg: 0.363  loss_rpn_cls: 0.045  loss_rpn_loc: 0.059  time: 0.5193  data_time: 0.0049  lr: 0.004396  max_mem: 3094M
[32m[04/19 21:41:51 d2.utils.events]: [0m eta: 0:00:52  iter: 899  total_loss: 0.821  loss_cls: 0.276  loss_box_reg: 0.371  loss_rpn_cls: 0.061  loss_rpn_loc: 0.060  time: 0.5195  data_time: 0.0048  lr: 0.004496  max_mem: 3094M
[32m[04/19 21:42:01 d2.utils.events]: [0m eta: 0:00:42  iter: 919  total_loss: 0.956  loss_cls: 0.341  loss_box_reg: 0.417  loss_rpn_cls: 0.068  loss_rpn_loc: 0.074  time: 0.5197  data_time: 0.0048  lr: 0.004595  max_mem: 3094M
[32m[04/19 21:42:12 d2.utils.events]: [0m eta: 0:00:31  iter: 939  total_loss: 0.816  loss_cls: 0.271  loss_box_reg: 0.388  loss_rpn_cls: 0.039  loss_rpn_loc: 0.072  time: 0.5198  data_time: 0.0048  lr: 0.004695  max_mem: 3094M
[32m[04/19 21:42:23 d2.utils.events]: [0m eta: 0:00:21  iter: 959  total_loss: 0.823  loss_cls: 0.306  loss_box_reg: 0.399  loss_rpn_cls: 0.048  loss_rpn_loc: 0.078  time: 0.5202  data_time: 0.0051  lr: 0.004795  max_mem: 3094M
[32m[04/19 21:42:33 d2.utils.events]: [0m eta: 0:00:10  iter: 979  total_loss: 0.859  loss_cls: 0.311  loss_box_reg: 0.428  loss_rpn_cls: 0.043  loss_rpn_loc: 0.070  time: 0.5201  data_time: 0.0050  lr: 0.004895  max_mem: 3094M
[5m[31mWARNING[0m [32m[04/19 21:42:44 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 21:42:44 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[32m[04/19 21:42:44 d2.data.build]: [0mDistribution of instances among all 80 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 5406         |    bicycle    | 420          |      car      | 5008         |
|  motorcycle   | 0            |   airplane    | 0            |      bus      | 0            |
|     train     | 0            |     truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant  | 0            |   stop sign   | 0            |
| parking meter | 0            |     bench     | 0            |     bird      | 0            |
|      cat      | 0            |      dog      | 13           |     horse     | 0            |
|     sheep     | 0            |      cow      | 0            |   elephant    | 0            |
|     bear      | 0            |     zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella    | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase    | 0            |    frisbee    | 0            |
|     skis      | 0            |   snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat  | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |   surfboard   | 0            | tennis racket | 0            |
|    bottle     | 0            |  wine glass   | 0            |      cup      | 0            |
|     fork      | 0            |     knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana     | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange     | 0            |   broccoli    | 0            |
|    carrot     | 0            |    hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake      | 0            |     chair     | 0            |
|     couch     | 0            | potted plant  | 0            |      bed      | 0            |
| dining table  | 0            |    toilet     | 0            |      tv       | 0            |
|    laptop     | 0            |     mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone   | 0            |   microwave   | 0            |
|     oven      | 0            |     bike      | 0            |    hydrant    | 0            |
|     motor     | 0            |     rider     | 0            |     light     | 0            |
|     sign      | 0            | motor vehicle | 0            |  human face   | 0            |
|  hair drier   | 0            | license plate | 0            |               |              |
|     total     | 10847        |               |              |               |              |[0m
[5m[31mWARNING[0m [32m[04/19 21:42:44 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/19 21:42:44 d2.utils.events]: [0m eta: 0:00:00  iter: 999  total_loss: 0.812  loss_cls: 0.291  loss_box_reg: 0.376  loss_rpn_cls: 0.047  loss_rpn_loc: 0.082  time: 0.5200  data_time: 0.0046  lr: 0.004995  max_mem: 3094M
[32m[04/19 21:42:44 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:08:38 (0.5205 s / it)
[32m[04/19 21:42:44 d2.engine.hooks]: [0mTotal training time: 0:08:42 (0:00:03 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/19 21:42:47 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 21:42:47 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/19 21:42:48 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/19 21:42:49 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1179 s / img. ETA=0:16:40
[32m[04/19 21:42:55 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1189 s / img. ETA=0:16:49
[32m[04/19 21:43:00 d2.evaluation.evaluator]: [0mInference done 95/8355. 0.1187 s / img. ETA=0:16:43
[32m[04/19 21:43:05 d2.evaluation.evaluator]: [0mInference done 137/8355. 0.1186 s / img. ETA=0:16:37
[32m[04/19 21:43:10 d2.evaluation.evaluator]: [0mInference done 178/8355. 0.1186 s / img. ETA=0:16:34
[32m[04/19 21:43:15 d2.evaluation.evaluator]: [0mInference done 220/8355. 0.1187 s / img. ETA=0:16:30
[32m[04/19 21:43:20 d2.evaluation.evaluator]: [0mInference done 262/8355. 0.1187 s / img. ETA=0:16:24
[32m[04/19 21:43:25 d2.evaluation.evaluator]: [0mInference done 304/8355. 0.1187 s / img. ETA=0:16:19
[32m[04/19 21:43:30 d2.evaluation.evaluator]: [0mInference done 346/8355. 0.1187 s / img. ETA=0:16:14
[32m[04/19 21:43:35 d2.evaluation.evaluator]: [0mInference done 387/8355. 0.1187 s / img. ETA=0:16:09
[32m[04/19 21:43:40 d2.evaluation.evaluator]: [0mInference done 429/8355. 0.1188 s / img. ETA=0:16:04
[32m[04/19 21:43:45 d2.evaluation.evaluator]: [0mInference done 471/8355. 0.1187 s / img. ETA=0:15:59
[32m[04/19 21:43:51 d2.evaluation.evaluator]: [0mInference done 513/8355. 0.1187 s / img. ETA=0:15:54
[32m[04/19 21:43:56 d2.evaluation.evaluator]: [0mInference done 555/8355. 0.1187 s / img. ETA=0:15:48
[32m[04/19 21:44:01 d2.evaluation.evaluator]: [0mInference done 597/8355. 0.1187 s / img. ETA=0:15:43
[32m[04/19 21:44:06 d2.evaluation.evaluator]: [0mInference done 638/8355. 0.1187 s / img. ETA=0:15:38
[32m[04/19 21:44:11 d2.evaluation.evaluator]: [0mInference done 680/8355. 0.1187 s / img. ETA=0:15:33
[32m[04/19 21:44:16 d2.evaluation.evaluator]: [0mInference done 722/8355. 0.1187 s / img. ETA=0:15:28
[32m[04/19 21:44:21 d2.evaluation.evaluator]: [0mInference done 763/8355. 0.1188 s / img. ETA=0:15:23
[32m[04/19 21:44:26 d2.evaluation.evaluator]: [0mInference done 805/8355. 0.1187 s / img. ETA=0:15:18
[32m[04/19 21:44:31 d2.evaluation.evaluator]: [0mInference done 847/8355. 0.1187 s / img. ETA=0:15:12
[32m[04/19 21:44:36 d2.evaluation.evaluator]: [0mInference done 889/8355. 0.1187 s / img. ETA=0:15:07
[32m[04/19 21:44:41 d2.evaluation.evaluator]: [0mInference done 930/8355. 0.1187 s / img. ETA=0:15:03
[32m[04/19 21:44:46 d2.evaluation.evaluator]: [0mInference done 972/8355. 0.1187 s / img. ETA=0:14:58
[32m[04/19 21:44:51 d2.evaluation.evaluator]: [0mInference done 1014/8355. 0.1187 s / img. ETA=0:14:52
[32m[04/19 21:44:57 d2.evaluation.evaluator]: [0mInference done 1056/8355. 0.1187 s / img. ETA=0:14:47
[32m[04/19 21:45:02 d2.evaluation.evaluator]: [0mInference done 1098/8355. 0.1187 s / img. ETA=0:14:42
[32m[04/19 21:45:07 d2.evaluation.evaluator]: [0mInference done 1140/8355. 0.1186 s / img. ETA=0:14:36
[32m[04/19 21:45:12 d2.evaluation.evaluator]: [0mInference done 1182/8355. 0.1186 s / img. ETA=0:14:31
[32m[04/19 21:45:17 d2.evaluation.evaluator]: [0mInference done 1224/8355. 0.1186 s / img. ETA=0:14:26
[32m[04/19 21:45:22 d2.evaluation.evaluator]: [0mInference done 1266/8355. 0.1186 s / img. ETA=0:14:21
[32m[04/19 21:45:27 d2.evaluation.evaluator]: [0mInference done 1308/8355. 0.1186 s / img. ETA=0:14:15
[32m[04/19 21:45:32 d2.evaluation.evaluator]: [0mInference done 1350/8355. 0.1186 s / img. ETA=0:14:10
[32m[04/19 21:45:37 d2.evaluation.evaluator]: [0mInference done 1392/8355. 0.1186 s / img. ETA=0:14:05
[32m[04/19 21:45:42 d2.evaluation.evaluator]: [0mInference done 1434/8355. 0.1186 s / img. ETA=0:13:59
[32m[04/19 21:45:47 d2.evaluation.evaluator]: [0mInference done 1476/8355. 0.1186 s / img. ETA=0:13:54
[32m[04/19 21:45:52 d2.evaluation.evaluator]: [0mInference done 1518/8355. 0.1185 s / img. ETA=0:13:49
[32m[04/19 21:45:57 d2.evaluation.evaluator]: [0mInference done 1560/8355. 0.1185 s / img. ETA=0:13:44
[32m[04/19 21:46:02 d2.evaluation.evaluator]: [0mInference done 1601/8355. 0.1186 s / img. ETA=0:13:39
[32m[04/19 21:46:08 d2.evaluation.evaluator]: [0mInference done 1643/8355. 0.1186 s / img. ETA=0:13:34
[32m[04/19 21:46:13 d2.evaluation.evaluator]: [0mInference done 1685/8355. 0.1186 s / img. ETA=0:13:29
[32m[04/19 21:46:18 d2.evaluation.evaluator]: [0mInference done 1727/8355. 0.1185 s / img. ETA=0:13:24
[32m[04/19 21:46:23 d2.evaluation.evaluator]: [0mInference done 1769/8355. 0.1186 s / img. ETA=0:13:19
[32m[04/19 21:46:28 d2.evaluation.evaluator]: [0mInference done 1811/8355. 0.1186 s / img. ETA=0:13:14
[32m[04/19 21:46:33 d2.evaluation.evaluator]: [0mInference done 1853/8355. 0.1186 s / img. ETA=0:13:08
[32m[04/19 21:46:38 d2.evaluation.evaluator]: [0mInference done 1895/8355. 0.1186 s / img. ETA=0:13:03
[32m[04/19 21:46:43 d2.evaluation.evaluator]: [0mInference done 1937/8355. 0.1186 s / img. ETA=0:12:58
[32m[04/19 21:46:48 d2.evaluation.evaluator]: [0mInference done 1979/8355. 0.1186 s / img. ETA=0:12:53
[32m[04/19 21:46:53 d2.evaluation.evaluator]: [0mInference done 2021/8355. 0.1186 s / img. ETA=0:12:48
[32m[04/19 21:46:59 d2.evaluation.evaluator]: [0mInference done 2063/8355. 0.1186 s / img. ETA=0:12:43
[32m[04/19 21:47:04 d2.evaluation.evaluator]: [0mInference done 2105/8355. 0.1186 s / img. ETA=0:12:38
[32m[04/19 21:47:09 d2.evaluation.evaluator]: [0mInference done 2147/8355. 0.1186 s / img. ETA=0:12:33
[32m[04/19 21:47:14 d2.evaluation.evaluator]: [0mInference done 2189/8355. 0.1186 s / img. ETA=0:12:28
[32m[04/19 21:47:19 d2.evaluation.evaluator]: [0mInference done 2231/8355. 0.1186 s / img. ETA=0:12:23
[32m[04/19 21:47:24 d2.evaluation.evaluator]: [0mInference done 2273/8355. 0.1186 s / img. ETA=0:12:18
[32m[04/19 21:47:29 d2.evaluation.evaluator]: [0mInference done 2315/8355. 0.1186 s / img. ETA=0:12:13
[32m[04/19 21:47:34 d2.evaluation.evaluator]: [0mInference done 2357/8355. 0.1186 s / img. ETA=0:12:08
[32m[04/19 21:47:39 d2.evaluation.evaluator]: [0mInference done 2398/8355. 0.1186 s / img. ETA=0:12:03
[32m[04/19 21:47:44 d2.evaluation.evaluator]: [0mInference done 2440/8355. 0.1186 s / img. ETA=0:11:58
[32m[04/19 21:47:49 d2.evaluation.evaluator]: [0mInference done 2481/8355. 0.1186 s / img. ETA=0:11:53
[32m[04/19 21:47:54 d2.evaluation.evaluator]: [0mInference done 2522/8355. 0.1187 s / img. ETA=0:11:48
[32m[04/19 21:48:00 d2.evaluation.evaluator]: [0mInference done 2564/8355. 0.1187 s / img. ETA=0:11:43
[32m[04/19 21:48:05 d2.evaluation.evaluator]: [0mInference done 2606/8355. 0.1187 s / img. ETA=0:11:38
[32m[04/19 21:48:10 d2.evaluation.evaluator]: [0mInference done 2647/8355. 0.1187 s / img. ETA=0:11:33
[32m[04/19 21:48:15 d2.evaluation.evaluator]: [0mInference done 2688/8355. 0.1187 s / img. ETA=0:11:28
[32m[04/19 21:48:20 d2.evaluation.evaluator]: [0mInference done 2730/8355. 0.1187 s / img. ETA=0:11:23
[32m[04/19 21:48:25 d2.evaluation.evaluator]: [0mInference done 2772/8355. 0.1187 s / img. ETA=0:11:18
[32m[04/19 21:48:30 d2.evaluation.evaluator]: [0mInference done 2814/8355. 0.1187 s / img. ETA=0:11:13
[32m[04/19 21:48:35 d2.evaluation.evaluator]: [0mInference done 2856/8355. 0.1187 s / img. ETA=0:11:07
[32m[04/19 21:48:40 d2.evaluation.evaluator]: [0mInference done 2898/8355. 0.1187 s / img. ETA=0:11:02
[32m[04/19 21:48:45 d2.evaluation.evaluator]: [0mInference done 2939/8355. 0.1187 s / img. ETA=0:10:57
[32m[04/19 21:48:50 d2.evaluation.evaluator]: [0mInference done 2980/8355. 0.1187 s / img. ETA=0:10:52
[32m[04/19 21:48:55 d2.evaluation.evaluator]: [0mInference done 3021/8355. 0.1187 s / img. ETA=0:10:48
[32m[04/19 21:49:00 d2.evaluation.evaluator]: [0mInference done 3062/8355. 0.1187 s / img. ETA=0:10:43
[32m[04/19 21:49:05 d2.evaluation.evaluator]: [0mInference done 3103/8355. 0.1187 s / img. ETA=0:10:38
[32m[04/19 21:49:10 d2.evaluation.evaluator]: [0mInference done 3145/8355. 0.1187 s / img. ETA=0:10:33
[32m[04/19 21:49:15 d2.evaluation.evaluator]: [0mInference done 3187/8355. 0.1187 s / img. ETA=0:10:27
[32m[04/19 21:49:21 d2.evaluation.evaluator]: [0mInference done 3229/8355. 0.1187 s / img. ETA=0:10:22
[32m[04/19 21:49:26 d2.evaluation.evaluator]: [0mInference done 3271/8355. 0.1187 s / img. ETA=0:10:17
[32m[04/19 21:49:31 d2.evaluation.evaluator]: [0mInference done 3312/8355. 0.1187 s / img. ETA=0:10:12
[32m[04/19 21:49:36 d2.evaluation.evaluator]: [0mInference done 3354/8355. 0.1187 s / img. ETA=0:10:07
[32m[04/19 21:49:41 d2.evaluation.evaluator]: [0mInference done 3396/8355. 0.1187 s / img. ETA=0:10:02
[32m[04/19 21:49:46 d2.evaluation.evaluator]: [0mInference done 3438/8355. 0.1187 s / img. ETA=0:09:57
[32m[04/19 21:49:51 d2.evaluation.evaluator]: [0mInference done 3480/8355. 0.1187 s / img. ETA=0:09:52
[32m[04/19 21:49:56 d2.evaluation.evaluator]: [0mInference done 3522/8355. 0.1187 s / img. ETA=0:09:47
[32m[04/19 21:50:01 d2.evaluation.evaluator]: [0mInference done 3564/8355. 0.1187 s / img. ETA=0:09:42
[32m[04/19 21:50:06 d2.evaluation.evaluator]: [0mInference done 3606/8355. 0.1187 s / img. ETA=0:09:37
[32m[04/19 21:50:11 d2.evaluation.evaluator]: [0mInference done 3648/8355. 0.1187 s / img. ETA=0:09:31
[32m[04/19 21:50:16 d2.evaluation.evaluator]: [0mInference done 3690/8355. 0.1187 s / img. ETA=0:09:26
[32m[04/19 21:50:22 d2.evaluation.evaluator]: [0mInference done 3731/8355. 0.1187 s / img. ETA=0:09:21
[32m[04/19 21:50:27 d2.evaluation.evaluator]: [0mInference done 3773/8355. 0.1187 s / img. ETA=0:09:16
[32m[04/19 21:50:32 d2.evaluation.evaluator]: [0mInference done 3815/8355. 0.1187 s / img. ETA=0:09:11
[32m[04/19 21:50:37 d2.evaluation.evaluator]: [0mInference done 3857/8355. 0.1187 s / img. ETA=0:09:06
[32m[04/19 21:50:42 d2.evaluation.evaluator]: [0mInference done 3899/8355. 0.1187 s / img. ETA=0:09:01
[32m[04/19 21:50:47 d2.evaluation.evaluator]: [0mInference done 3941/8355. 0.1187 s / img. ETA=0:08:56
[32m[04/19 21:50:52 d2.evaluation.evaluator]: [0mInference done 3982/8355. 0.1187 s / img. ETA=0:08:51
[32m[04/19 21:50:57 d2.evaluation.evaluator]: [0mInference done 4023/8355. 0.1187 s / img. ETA=0:08:46
[32m[04/19 21:51:02 d2.evaluation.evaluator]: [0mInference done 4064/8355. 0.1187 s / img. ETA=0:08:41
[32m[04/19 21:51:07 d2.evaluation.evaluator]: [0mInference done 4106/8355. 0.1187 s / img. ETA=0:08:36
[32m[04/19 21:51:12 d2.evaluation.evaluator]: [0mInference done 4148/8355. 0.1187 s / img. ETA=0:08:31
[32m[04/19 21:51:17 d2.evaluation.evaluator]: [0mInference done 4189/8355. 0.1187 s / img. ETA=0:08:26
[32m[04/19 21:51:22 d2.evaluation.evaluator]: [0mInference done 4231/8355. 0.1187 s / img. ETA=0:08:21
[32m[04/19 21:51:27 d2.evaluation.evaluator]: [0mInference done 4273/8355. 0.1187 s / img. ETA=0:08:16
[32m[04/19 21:51:33 d2.evaluation.evaluator]: [0mInference done 4315/8355. 0.1187 s / img. ETA=0:08:10
[32m[04/19 21:51:38 d2.evaluation.evaluator]: [0mInference done 4357/8355. 0.1187 s / img. ETA=0:08:05
[32m[04/19 21:51:43 d2.evaluation.evaluator]: [0mInference done 4399/8355. 0.1187 s / img. ETA=0:08:00
[32m[04/19 21:51:48 d2.evaluation.evaluator]: [0mInference done 4441/8355. 0.1188 s / img. ETA=0:07:55
[32m[04/19 21:51:53 d2.evaluation.evaluator]: [0mInference done 4482/8355. 0.1188 s / img. ETA=0:07:50
[32m[04/19 21:51:58 d2.evaluation.evaluator]: [0mInference done 4524/8355. 0.1188 s / img. ETA=0:07:45
[32m[04/19 21:52:03 d2.evaluation.evaluator]: [0mInference done 4566/8355. 0.1188 s / img. ETA=0:07:40
[32m[04/19 21:52:08 d2.evaluation.evaluator]: [0mInference done 4608/8355. 0.1188 s / img. ETA=0:07:35
[32m[04/19 21:52:13 d2.evaluation.evaluator]: [0mInference done 4649/8355. 0.1188 s / img. ETA=0:07:30
[32m[04/19 21:52:18 d2.evaluation.evaluator]: [0mInference done 4691/8355. 0.1188 s / img. ETA=0:07:25
[32m[04/19 21:52:23 d2.evaluation.evaluator]: [0mInference done 4733/8355. 0.1188 s / img. ETA=0:07:20
[32m[04/19 21:52:29 d2.evaluation.evaluator]: [0mInference done 4775/8355. 0.1188 s / img. ETA=0:07:15
[32m[04/19 21:52:34 d2.evaluation.evaluator]: [0mInference done 4817/8355. 0.1188 s / img. ETA=0:07:10
[32m[04/19 21:52:39 d2.evaluation.evaluator]: [0mInference done 4859/8355. 0.1188 s / img. ETA=0:07:04
[32m[04/19 21:52:44 d2.evaluation.evaluator]: [0mInference done 4901/8355. 0.1188 s / img. ETA=0:06:59
[32m[04/19 21:52:49 d2.evaluation.evaluator]: [0mInference done 4943/8355. 0.1188 s / img. ETA=0:06:54
[32m[04/19 21:52:54 d2.evaluation.evaluator]: [0mInference done 4985/8355. 0.1188 s / img. ETA=0:06:49
[32m[04/19 21:52:59 d2.evaluation.evaluator]: [0mInference done 5027/8355. 0.1188 s / img. ETA=0:06:44
[32m[04/19 21:53:04 d2.evaluation.evaluator]: [0mInference done 5068/8355. 0.1188 s / img. ETA=0:06:39
[32m[04/19 21:53:09 d2.evaluation.evaluator]: [0mInference done 5109/8355. 0.1188 s / img. ETA=0:06:34
[32m[04/19 21:53:14 d2.evaluation.evaluator]: [0mInference done 5151/8355. 0.1188 s / img. ETA=0:06:29
[32m[04/19 21:53:19 d2.evaluation.evaluator]: [0mInference done 5193/8355. 0.1188 s / img. ETA=0:06:24
[32m[04/19 21:53:25 d2.evaluation.evaluator]: [0mInference done 5235/8355. 0.1188 s / img. ETA=0:06:19
[32m[04/19 21:53:30 d2.evaluation.evaluator]: [0mInference done 5277/8355. 0.1188 s / img. ETA=0:06:14
[32m[04/19 21:53:35 d2.evaluation.evaluator]: [0mInference done 5319/8355. 0.1188 s / img. ETA=0:06:09
[32m[04/19 21:53:40 d2.evaluation.evaluator]: [0mInference done 5361/8355. 0.1188 s / img. ETA=0:06:03
[32m[04/19 21:53:45 d2.evaluation.evaluator]: [0mInference done 5403/8355. 0.1188 s / img. ETA=0:05:58
[32m[04/19 21:53:50 d2.evaluation.evaluator]: [0mInference done 5445/8355. 0.1188 s / img. ETA=0:05:53
[32m[04/19 21:53:55 d2.evaluation.evaluator]: [0mInference done 5486/8355. 0.1188 s / img. ETA=0:05:48
[32m[04/19 21:54:00 d2.evaluation.evaluator]: [0mInference done 5528/8355. 0.1188 s / img. ETA=0:05:43
[32m[04/19 21:54:05 d2.evaluation.evaluator]: [0mInference done 5569/8355. 0.1188 s / img. ETA=0:05:38
[32m[04/19 21:54:10 d2.evaluation.evaluator]: [0mInference done 5610/8355. 0.1188 s / img. ETA=0:05:33
[32m[04/19 21:54:15 d2.evaluation.evaluator]: [0mInference done 5651/8355. 0.1188 s / img. ETA=0:05:28
[32m[04/19 21:54:20 d2.evaluation.evaluator]: [0mInference done 5692/8355. 0.1188 s / img. ETA=0:05:23
[32m[04/19 21:54:25 d2.evaluation.evaluator]: [0mInference done 5733/8355. 0.1188 s / img. ETA=0:05:18
[32m[04/19 21:54:30 d2.evaluation.evaluator]: [0mInference done 5775/8355. 0.1188 s / img. ETA=0:05:13
[32m[04/19 21:54:36 d2.evaluation.evaluator]: [0mInference done 5817/8355. 0.1188 s / img. ETA=0:05:08
[32m[04/19 21:54:41 d2.evaluation.evaluator]: [0mInference done 5859/8355. 0.1188 s / img. ETA=0:05:03
[32m[04/19 21:54:46 d2.evaluation.evaluator]: [0mInference done 5901/8355. 0.1188 s / img. ETA=0:04:58
[32m[04/19 21:54:51 d2.evaluation.evaluator]: [0mInference done 5943/8355. 0.1188 s / img. ETA=0:04:53
[32m[04/19 21:54:56 d2.evaluation.evaluator]: [0mInference done 5985/8355. 0.1188 s / img. ETA=0:04:48
[32m[04/19 21:55:01 d2.evaluation.evaluator]: [0mInference done 6027/8355. 0.1188 s / img. ETA=0:04:43
[32m[04/19 21:55:06 d2.evaluation.evaluator]: [0mInference done 6069/8355. 0.1188 s / img. ETA=0:04:37
[32m[04/19 21:55:11 d2.evaluation.evaluator]: [0mInference done 6111/8355. 0.1188 s / img. ETA=0:04:32
[32m[04/19 21:55:16 d2.evaluation.evaluator]: [0mInference done 6153/8355. 0.1188 s / img. ETA=0:04:27
[32m[04/19 21:55:21 d2.evaluation.evaluator]: [0mInference done 6194/8355. 0.1188 s / img. ETA=0:04:22
[32m[04/19 21:55:26 d2.evaluation.evaluator]: [0mInference done 6235/8355. 0.1188 s / img. ETA=0:04:17
[32m[04/19 21:55:31 d2.evaluation.evaluator]: [0mInference done 6277/8355. 0.1188 s / img. ETA=0:04:12
[32m[04/19 21:55:36 d2.evaluation.evaluator]: [0mInference done 6319/8355. 0.1188 s / img. ETA=0:04:07
[32m[04/19 21:55:41 d2.evaluation.evaluator]: [0mInference done 6361/8355. 0.1188 s / img. ETA=0:04:02
[32m[04/19 21:55:46 d2.evaluation.evaluator]: [0mInference done 6403/8355. 0.1188 s / img. ETA=0:03:57
[32m[04/19 21:55:52 d2.evaluation.evaluator]: [0mInference done 6445/8355. 0.1188 s / img. ETA=0:03:52
[32m[04/19 21:55:57 d2.evaluation.evaluator]: [0mInference done 6487/8355. 0.1188 s / img. ETA=0:03:47
[32m[04/19 21:56:02 d2.evaluation.evaluator]: [0mInference done 6529/8355. 0.1188 s / img. ETA=0:03:41
[32m[04/19 21:56:07 d2.evaluation.evaluator]: [0mInference done 6571/8355. 0.1188 s / img. ETA=0:03:36
[32m[04/19 21:56:12 d2.evaluation.evaluator]: [0mInference done 6613/8355. 0.1188 s / img. ETA=0:03:31
[32m[04/19 21:56:17 d2.evaluation.evaluator]: [0mInference done 6655/8355. 0.1188 s / img. ETA=0:03:26
[32m[04/19 21:56:22 d2.evaluation.evaluator]: [0mInference done 6697/8355. 0.1188 s / img. ETA=0:03:21
[32m[04/19 21:56:27 d2.evaluation.evaluator]: [0mInference done 6739/8355. 0.1188 s / img. ETA=0:03:16
[32m[04/19 21:56:32 d2.evaluation.evaluator]: [0mInference done 6781/8355. 0.1188 s / img. ETA=0:03:11
[32m[04/19 21:56:37 d2.evaluation.evaluator]: [0mInference done 6823/8355. 0.1188 s / img. ETA=0:03:06
[32m[04/19 21:56:42 d2.evaluation.evaluator]: [0mInference done 6865/8355. 0.1188 s / img. ETA=0:03:01
[32m[04/19 21:56:47 d2.evaluation.evaluator]: [0mInference done 6907/8355. 0.1187 s / img. ETA=0:02:55
[32m[04/19 21:56:52 d2.evaluation.evaluator]: [0mInference done 6949/8355. 0.1187 s / img. ETA=0:02:50
[32m[04/19 21:56:57 d2.evaluation.evaluator]: [0mInference done 6991/8355. 0.1187 s / img. ETA=0:02:45
[32m[04/19 21:57:02 d2.evaluation.evaluator]: [0mInference done 7033/8355. 0.1187 s / img. ETA=0:02:40
[32m[04/19 21:57:07 d2.evaluation.evaluator]: [0mInference done 7075/8355. 0.1187 s / img. ETA=0:02:35
[32m[04/19 21:57:13 d2.evaluation.evaluator]: [0mInference done 7117/8355. 0.1187 s / img. ETA=0:02:30
[32m[04/19 21:57:18 d2.evaluation.evaluator]: [0mInference done 7158/8355. 0.1188 s / img. ETA=0:02:25
[32m[04/19 21:57:23 d2.evaluation.evaluator]: [0mInference done 7200/8355. 0.1187 s / img. ETA=0:02:20
[32m[04/19 21:57:28 d2.evaluation.evaluator]: [0mInference done 7242/8355. 0.1187 s / img. ETA=0:02:15
[32m[04/19 21:57:33 d2.evaluation.evaluator]: [0mInference done 7284/8355. 0.1187 s / img. ETA=0:02:10
[32m[04/19 21:57:38 d2.evaluation.evaluator]: [0mInference done 7326/8355. 0.1187 s / img. ETA=0:02:04
[32m[04/19 21:57:43 d2.evaluation.evaluator]: [0mInference done 7368/8355. 0.1187 s / img. ETA=0:01:59
[32m[04/19 21:57:48 d2.evaluation.evaluator]: [0mInference done 7410/8355. 0.1187 s / img. ETA=0:01:54
[32m[04/19 21:57:53 d2.evaluation.evaluator]: [0mInference done 7452/8355. 0.1187 s / img. ETA=0:01:49
[32m[04/19 21:57:58 d2.evaluation.evaluator]: [0mInference done 7494/8355. 0.1187 s / img. ETA=0:01:44
[32m[04/19 21:58:03 d2.evaluation.evaluator]: [0mInference done 7536/8355. 0.1187 s / img. ETA=0:01:39
[32m[04/19 21:58:08 d2.evaluation.evaluator]: [0mInference done 7577/8355. 0.1187 s / img. ETA=0:01:34
[32m[04/19 21:58:14 d2.evaluation.evaluator]: [0mInference done 7619/8355. 0.1187 s / img. ETA=0:01:29
[32m[04/19 21:58:19 d2.evaluation.evaluator]: [0mInference done 7661/8355. 0.1187 s / img. ETA=0:01:24
[32m[04/19 21:58:24 d2.evaluation.evaluator]: [0mInference done 7703/8355. 0.1187 s / img. ETA=0:01:19
[32m[04/19 21:58:29 d2.evaluation.evaluator]: [0mInference done 7744/8355. 0.1188 s / img. ETA=0:01:14
[32m[04/19 21:58:34 d2.evaluation.evaluator]: [0mInference done 7785/8355. 0.1188 s / img. ETA=0:01:09
[32m[04/19 21:58:39 d2.evaluation.evaluator]: [0mInference done 7827/8355. 0.1188 s / img. ETA=0:01:04
[32m[04/19 21:58:44 d2.evaluation.evaluator]: [0mInference done 7869/8355. 0.1188 s / img. ETA=0:00:59
[32m[04/19 21:58:49 d2.evaluation.evaluator]: [0mInference done 7911/8355. 0.1188 s / img. ETA=0:00:53
[32m[04/19 21:58:54 d2.evaluation.evaluator]: [0mInference done 7953/8355. 0.1188 s / img. ETA=0:00:48
[32m[04/19 21:58:59 d2.evaluation.evaluator]: [0mInference done 7995/8355. 0.1188 s / img. ETA=0:00:43
[32m[04/19 21:59:04 d2.evaluation.evaluator]: [0mInference done 8037/8355. 0.1188 s / img. ETA=0:00:38
[32m[04/19 21:59:09 d2.evaluation.evaluator]: [0mInference done 8079/8355. 0.1188 s / img. ETA=0:00:33
[32m[04/19 21:59:15 d2.evaluation.evaluator]: [0mInference done 8121/8355. 0.1187 s / img. ETA=0:00:28
[32m[04/19 21:59:20 d2.evaluation.evaluator]: [0mInference done 8163/8355. 0.1187 s / img. ETA=0:00:23
[32m[04/19 21:59:25 d2.evaluation.evaluator]: [0mInference done 8205/8355. 0.1187 s / img. ETA=0:00:18
[32m[04/19 21:59:30 d2.evaluation.evaluator]: [0mInference done 8247/8355. 0.1187 s / img. ETA=0:00:13
[32m[04/19 21:59:35 d2.evaluation.evaluator]: [0mInference done 8289/8355. 0.1187 s / img. ETA=0:00:08
[32m[04/19 21:59:40 d2.evaluation.evaluator]: [0mInference done 8331/8355. 0.1187 s / img. ETA=0:00:02
[32m[04/19 21:59:43 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:54.013246 (0.121439 s / img per device, on 1 devices)
[32m[04/19 21:59:43 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:31 (0.118730 s / img per device, on 1 devices)
[32m[04/19 21:59:43 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/19 21:59:43 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/19 21:59:43 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=7.58s).
Accumulating evaluation results...
DONE (t=1.19s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.005
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
[32m[04/19 21:59:52 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.373 | 0.495  | 0.495  | 0.000 | 0.200 | 0.297 |
[32m[04/19 21:59:52 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP    | category      | AP    | category       | AP    |
|:--------------|:------|:--------------|:------|:---------------|:------|
| person        | 0.800 | bicycle       | 0.000 | car            | 0.693 |
| motorcycle    | nan   | airplane      | nan   | bus            | nan   |
| train         | nan   | truck         | nan   | boat           | nan   |
| traffic light | nan   | fire hydrant  | nan   | stop sign      | nan   |
| parking meter | nan   | bench         | nan   | bird           | nan   |
| cat           | nan   | dog           | 0.000 | horse          | nan   |
| sheep         | nan   | cow           | nan   | elephant       | nan   |
| bear          | nan   | zebra         | nan   | giraffe        | nan   |
| backpack      | nan   | umbrella      | nan   | handbag        | nan   |
| tie           | nan   | suitcase      | nan   | frisbee        | nan   |
| skis          | nan   | snowboard     | nan   | sports ball    | nan   |
| kite          | nan   | baseball bat  | nan   | baseball glove | nan   |
| skateboard    | nan   | surfboard     | nan   | tennis racket  | nan   |
| bottle        | nan   | wine glass    | nan   | cup            | nan   |
| fork          | nan   | knife         | nan   | spoon          | nan   |
| bowl          | nan   | banana        | nan   | apple          | nan   |
| sandwich      | nan   | orange        | nan   | broccoli       | nan   |
| carrot        | nan   | hot dog       | nan   | pizza          | nan   |
| donut         | nan   | cake          | nan   | chair          | nan   |
| couch         | nan   | potted plant  | nan   | bed            | nan   |
| dining table  | nan   | toilet        | nan   | tv             | nan   |
| laptop        | nan   | mouse         | nan   | remote         | nan   |
| keyboard      | nan   | cell phone    | nan   | microwave      | nan   |
| oven          | nan   | bike          | nan   | hydrant        | nan   |
| motor         | nan   | rider         | nan   | light          | nan   |
| sign          | nan   | motor vehicle | nan   | human face     | nan   |
| hair drier    | nan   |               |       |                |       |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/19 21:59:53 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 21:59:53 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[32m[04/19 21:59:53 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/19 21:59:55 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1184 s / img. ETA=0:02:30
[32m[04/19 22:00:00 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1184 s / img. ETA=0:02:26
[32m[04/19 22:00:05 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1184 s / img. ETA=0:02:21
[32m[04/19 22:00:10 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1183 s / img. ETA=0:02:15
[32m[04/19 22:00:15 d2.evaluation.evaluator]: [0mInference done 179/1257. 0.1184 s / img. ETA=0:02:10
[32m[04/19 22:00:20 d2.evaluation.evaluator]: [0mInference done 220/1257. 0.1188 s / img. ETA=0:02:06
[32m[04/19 22:00:25 d2.evaluation.evaluator]: [0mInference done 261/1257. 0.1191 s / img. ETA=0:02:01
[32m[04/19 22:00:30 d2.evaluation.evaluator]: [0mInference done 302/1257. 0.1191 s / img. ETA=0:01:56
[32m[04/19 22:00:35 d2.evaluation.evaluator]: [0mInference done 343/1257. 0.1192 s / img. ETA=0:01:51
[32m[04/19 22:00:40 d2.evaluation.evaluator]: [0mInference done 384/1257. 0.1193 s / img. ETA=0:01:46
[32m[04/19 22:00:45 d2.evaluation.evaluator]: [0mInference done 426/1257. 0.1192 s / img. ETA=0:01:41
[32m[04/19 22:00:50 d2.evaluation.evaluator]: [0mInference done 467/1257. 0.1191 s / img. ETA=0:01:36
[32m[04/19 22:00:55 d2.evaluation.evaluator]: [0mInference done 509/1257. 0.1191 s / img. ETA=0:01:31
[32m[04/19 22:01:01 d2.evaluation.evaluator]: [0mInference done 551/1257. 0.1190 s / img. ETA=0:01:26
[32m[04/19 22:01:06 d2.evaluation.evaluator]: [0mInference done 593/1257. 0.1190 s / img. ETA=0:01:20
[32m[04/19 22:01:11 d2.evaluation.evaluator]: [0mInference done 634/1257. 0.1190 s / img. ETA=0:01:15
[32m[04/19 22:01:16 d2.evaluation.evaluator]: [0mInference done 676/1257. 0.1189 s / img. ETA=0:01:10
[32m[04/19 22:01:21 d2.evaluation.evaluator]: [0mInference done 718/1257. 0.1189 s / img. ETA=0:01:05
[32m[04/19 22:01:26 d2.evaluation.evaluator]: [0mInference done 760/1257. 0.1189 s / img. ETA=0:01:00
[32m[04/19 22:01:31 d2.evaluation.evaluator]: [0mInference done 801/1257. 0.1190 s / img. ETA=0:00:55
[32m[04/19 22:01:36 d2.evaluation.evaluator]: [0mInference done 842/1257. 0.1191 s / img. ETA=0:00:50
[32m[04/19 22:01:41 d2.evaluation.evaluator]: [0mInference done 884/1257. 0.1191 s / img. ETA=0:00:45
[32m[04/19 22:01:46 d2.evaluation.evaluator]: [0mInference done 926/1257. 0.1191 s / img. ETA=0:00:40
[32m[04/19 22:01:51 d2.evaluation.evaluator]: [0mInference done 968/1257. 0.1191 s / img. ETA=0:00:35
[32m[04/19 22:01:56 d2.evaluation.evaluator]: [0mInference done 1009/1257. 0.1191 s / img. ETA=0:00:30
[32m[04/19 22:02:02 d2.evaluation.evaluator]: [0mInference done 1051/1257. 0.1191 s / img. ETA=0:00:25
[32m[04/19 22:02:07 d2.evaluation.evaluator]: [0mInference done 1092/1257. 0.1192 s / img. ETA=0:00:20
[32m[04/19 22:02:12 d2.evaluation.evaluator]: [0mInference done 1133/1257. 0.1192 s / img. ETA=0:00:15
[32m[04/19 22:02:17 d2.evaluation.evaluator]: [0mInference done 1174/1257. 0.1192 s / img. ETA=0:00:10
[32m[04/19 22:02:22 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1192 s / img. ETA=0:00:05
[32m[04/19 22:02:27 d2.evaluation.evaluator]: [0mInference done 1257/1257. 0.1192 s / img. ETA=0:00:00
[32m[04/19 22:02:27 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:32.883592 (0.122111 s / img per device, on 1 devices)
[32m[04/19 22:02:27 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:29 (0.119201 s / img per device, on 1 devices)
[32m[04/19 22:02:27 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/19 22:02:27 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/19 22:02:27 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.60s).
Accumulating evaluation results...
DONE (t=0.34s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001
[32m[04/19 22:02:29 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.170 | 0.248  | 0.165  | 0.000 | 0.174 | 0.157 |
[32m[04/19 22:02:29 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP    | category      | AP    | category       | AP    |
|:--------------|:------|:--------------|:------|:---------------|:------|
| person        | 0.681 | bicycle       | 0.000 | car            | 0.000 |
| motorcycle    | nan   | airplane      | nan   | bus            | nan   |
| train         | nan   | truck         | nan   | boat           | nan   |
| traffic light | nan   | fire hydrant  | nan   | stop sign      | nan   |
| parking meter | nan   | bench         | nan   | bird           | nan   |
| cat           | nan   | dog           | 0.000 | horse          | nan   |
| sheep         | nan   | cow           | nan   | elephant       | nan   |
| bear          | nan   | zebra         | nan   | giraffe        | nan   |
| backpack      | nan   | umbrella      | nan   | handbag        | nan   |
| tie           | nan   | suitcase      | nan   | frisbee        | nan   |
| skis          | nan   | snowboard     | nan   | sports ball    | nan   |
| kite          | nan   | baseball bat  | nan   | baseball glove | nan   |
| skateboard    | nan   | surfboard     | nan   | tennis racket  | nan   |
| bottle        | nan   | wine glass    | nan   | cup            | nan   |
| fork          | nan   | knife         | nan   | spoon          | nan   |
| bowl          | nan   | banana        | nan   | apple          | nan   |
| sandwich      | nan   | orange        | nan   | broccoli       | nan   |
| carrot        | nan   | hot dog       | nan   | pizza          | nan   |
| donut         | nan   | cake          | nan   | chair          | nan   |
| couch         | nan   | potted plant  | nan   | bed            | nan   |
| dining table  | nan   | toilet        | nan   | tv             | nan   |
| laptop        | nan   | mouse         | nan   | remote         | nan   |
| keyboard      | nan   | cell phone    | nan   | microwave      | nan   |
| oven          | nan   | bike          | nan   | hydrant        | nan   |
| motor         | nan   | rider         | nan   | light          | nan   |
| sign          | nan   | motor vehicle | nan   | human face     | nan   |
| hair drier    | nan   | license plate | nan   |                |       |
============== The  1  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/19 22:02:30 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/19 22:02:30 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 22:02:30 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/19 22:02:31 d2.data.build]: [0mRemoved 889 images with no usable annotations. 7466 images left.
[32m[04/19 22:02:31 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/19 22:02:31 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/19 22:02:31 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/19 22:02:42 d2.utils.events]: [0m eta: 0:08:29  iter: 19  total_loss: 0.868  loss_cls: 0.309  loss_box_reg: 0.393  loss_rpn_cls: 0.052  loss_rpn_loc: 0.075  time: 0.5241  data_time: 0.0230  lr: 0.000100  max_mem: 3094M
[32m[04/19 22:02:52 d2.utils.events]: [0m eta: 0:08:26  iter: 39  total_loss: 0.837  loss_cls: 0.293  loss_box_reg: 0.356  loss_rpn_cls: 0.043  loss_rpn_loc: 0.090  time: 0.5311  data_time: 0.0050  lr: 0.000200  max_mem: 3094M
[32m[04/19 22:03:03 d2.utils.events]: [0m eta: 0:08:17  iter: 59  total_loss: 0.838  loss_cls: 0.274  loss_box_reg: 0.440  loss_rpn_cls: 0.050  loss_rpn_loc: 0.068  time: 0.5291  data_time: 0.0050  lr: 0.000300  max_mem: 3094M
[32m[04/19 22:03:13 d2.utils.events]: [0m eta: 0:08:05  iter: 79  total_loss: 0.674  loss_cls: 0.255  loss_box_reg: 0.303  loss_rpn_cls: 0.049  loss_rpn_loc: 0.088  time: 0.5239  data_time: 0.0045  lr: 0.000400  max_mem: 3094M
[32m[04/19 22:03:24 d2.utils.events]: [0m eta: 0:07:54  iter: 99  total_loss: 0.814  loss_cls: 0.264  loss_box_reg: 0.393  loss_rpn_cls: 0.038  loss_rpn_loc: 0.078  time: 0.5227  data_time: 0.0047  lr: 0.000500  max_mem: 3094M
[32m[04/19 22:03:34 d2.utils.events]: [0m eta: 0:07:41  iter: 119  total_loss: 0.690  loss_cls: 0.239  loss_box_reg: 0.349  loss_rpn_cls: 0.041  loss_rpn_loc: 0.072  time: 0.5209  data_time: 0.0048  lr: 0.000599  max_mem: 3094M
[32m[04/19 22:03:45 d2.utils.events]: [0m eta: 0:07:32  iter: 139  total_loss: 0.828  loss_cls: 0.293  loss_box_reg: 0.414  loss_rpn_cls: 0.044  loss_rpn_loc: 0.067  time: 0.5216  data_time: 0.0048  lr: 0.000699  max_mem: 3094M
[32m[04/19 22:03:55 d2.utils.events]: [0m eta: 0:07:22  iter: 159  total_loss: 0.817  loss_cls: 0.285  loss_box_reg: 0.410  loss_rpn_cls: 0.041  loss_rpn_loc: 0.070  time: 0.5214  data_time: 0.0048  lr: 0.000799  max_mem: 3094M
[32m[04/19 22:04:05 d2.utils.events]: [0m eta: 0:07:09  iter: 179  total_loss: 0.809  loss_cls: 0.267  loss_box_reg: 0.377  loss_rpn_cls: 0.050  loss_rpn_loc: 0.066  time: 0.5210  data_time: 0.0046  lr: 0.000899  max_mem: 3094M
[32m[04/19 22:04:16 d2.utils.events]: [0m eta: 0:06:58  iter: 199  total_loss: 0.751  loss_cls: 0.255  loss_box_reg: 0.369  loss_rpn_cls: 0.036  loss_rpn_loc: 0.073  time: 0.5206  data_time: 0.0048  lr: 0.000999  max_mem: 3094M
[32m[04/19 22:04:26 d2.utils.events]: [0m eta: 0:06:48  iter: 219  total_loss: 0.656  loss_cls: 0.228  loss_box_reg: 0.311  loss_rpn_cls: 0.041  loss_rpn_loc: 0.055  time: 0.5209  data_time: 0.0048  lr: 0.001099  max_mem: 3094M
[32m[04/19 22:04:37 d2.utils.events]: [0m eta: 0:06:37  iter: 239  total_loss: 0.751  loss_cls: 0.258  loss_box_reg: 0.391  loss_rpn_cls: 0.039  loss_rpn_loc: 0.067  time: 0.5208  data_time: 0.0047  lr: 0.001199  max_mem: 3094M
[32m[04/19 22:04:47 d2.utils.events]: [0m eta: 0:06:26  iter: 259  total_loss: 0.556  loss_cls: 0.199  loss_box_reg: 0.251  loss_rpn_cls: 0.026  loss_rpn_loc: 0.056  time: 0.5207  data_time: 0.0051  lr: 0.001299  max_mem: 3094M
[32m[04/19 22:04:58 d2.utils.events]: [0m eta: 0:06:17  iter: 279  total_loss: 0.933  loss_cls: 0.322  loss_box_reg: 0.435  loss_rpn_cls: 0.054  loss_rpn_loc: 0.090  time: 0.5212  data_time: 0.0051  lr: 0.001399  max_mem: 3094M
[32m[04/19 22:05:08 d2.utils.events]: [0m eta: 0:06:06  iter: 299  total_loss: 0.843  loss_cls: 0.270  loss_box_reg: 0.397  loss_rpn_cls: 0.044  loss_rpn_loc: 0.083  time: 0.5212  data_time: 0.0047  lr: 0.001499  max_mem: 3094M
[32m[04/19 22:05:19 d2.utils.events]: [0m eta: 0:05:56  iter: 319  total_loss: 0.744  loss_cls: 0.248  loss_box_reg: 0.400  loss_rpn_cls: 0.039  loss_rpn_loc: 0.058  time: 0.5222  data_time: 0.0051  lr: 0.001598  max_mem: 3094M
[32m[04/19 22:05:29 d2.utils.events]: [0m eta: 0:05:45  iter: 339  total_loss: 0.713  loss_cls: 0.237  loss_box_reg: 0.367  loss_rpn_cls: 0.037  loss_rpn_loc: 0.069  time: 0.5215  data_time: 0.0047  lr: 0.001698  max_mem: 3094M
[32m[04/19 22:05:40 d2.utils.events]: [0m eta: 0:05:35  iter: 359  total_loss: 0.789  loss_cls: 0.290  loss_box_reg: 0.383  loss_rpn_cls: 0.045  loss_rpn_loc: 0.085  time: 0.5222  data_time: 0.0050  lr: 0.001798  max_mem: 3094M
[32m[04/19 22:05:51 d2.utils.events]: [0m eta: 0:05:25  iter: 379  total_loss: 0.715  loss_cls: 0.242  loss_box_reg: 0.335  loss_rpn_cls: 0.040  loss_rpn_loc: 0.058  time: 0.5225  data_time: 0.0049  lr: 0.001898  max_mem: 3094M
[32m[04/19 22:06:01 d2.utils.events]: [0m eta: 0:05:14  iter: 399  total_loss: 0.916  loss_cls: 0.296  loss_box_reg: 0.432  loss_rpn_cls: 0.048  loss_rpn_loc: 0.091  time: 0.5217  data_time: 0.0045  lr: 0.001998  max_mem: 3094M
[32m[04/19 22:06:11 d2.utils.events]: [0m eta: 0:05:03  iter: 419  total_loss: 0.828  loss_cls: 0.300  loss_box_reg: 0.414  loss_rpn_cls: 0.038  loss_rpn_loc: 0.076  time: 0.5217  data_time: 0.0047  lr: 0.002098  max_mem: 3094M
[32m[04/19 22:06:22 d2.utils.events]: [0m eta: 0:04:53  iter: 439  total_loss: 0.722  loss_cls: 0.241  loss_box_reg: 0.368  loss_rpn_cls: 0.045  loss_rpn_loc: 0.062  time: 0.5219  data_time: 0.0049  lr: 0.002198  max_mem: 3094M
[32m[04/19 22:06:32 d2.utils.events]: [0m eta: 0:04:43  iter: 459  total_loss: 0.718  loss_cls: 0.238  loss_box_reg: 0.365  loss_rpn_cls: 0.036  loss_rpn_loc: 0.059  time: 0.5221  data_time: 0.0047  lr: 0.002298  max_mem: 3094M
[32m[04/19 22:06:42 d2.utils.events]: [0m eta: 0:04:32  iter: 479  total_loss: 0.688  loss_cls: 0.263  loss_box_reg: 0.344  loss_rpn_cls: 0.033  loss_rpn_loc: 0.078  time: 0.5210  data_time: 0.0046  lr: 0.002398  max_mem: 3094M
[32m[04/19 22:06:53 d2.utils.events]: [0m eta: 0:04:21  iter: 499  total_loss: 0.843  loss_cls: 0.282  loss_box_reg: 0.415  loss_rpn_cls: 0.043  loss_rpn_loc: 0.075  time: 0.5211  data_time: 0.0046  lr: 0.002498  max_mem: 3094M
[32m[04/19 22:07:03 d2.utils.events]: [0m eta: 0:04:11  iter: 519  total_loss: 0.834  loss_cls: 0.260  loss_box_reg: 0.458  loss_rpn_cls: 0.036  loss_rpn_loc: 0.075  time: 0.5207  data_time: 0.0048  lr: 0.002597  max_mem: 3094M
[32m[04/19 22:07:14 d2.utils.events]: [0m eta: 0:04:01  iter: 539  total_loss: 0.682  loss_cls: 0.233  loss_box_reg: 0.326  loss_rpn_cls: 0.029  loss_rpn_loc: 0.071  time: 0.5214  data_time: 0.0054  lr: 0.002697  max_mem: 3094M
[32m[04/19 22:07:24 d2.utils.events]: [0m eta: 0:03:50  iter: 559  total_loss: 0.754  loss_cls: 0.265  loss_box_reg: 0.367  loss_rpn_cls: 0.034  loss_rpn_loc: 0.076  time: 0.5210  data_time: 0.0051  lr: 0.002797  max_mem: 3094M
[32m[04/19 22:07:35 d2.utils.events]: [0m eta: 0:03:40  iter: 579  total_loss: 0.853  loss_cls: 0.299  loss_box_reg: 0.450  loss_rpn_cls: 0.043  loss_rpn_loc: 0.066  time: 0.5213  data_time: 0.0052  lr: 0.002897  max_mem: 3094M
[32m[04/19 22:07:45 d2.utils.events]: [0m eta: 0:03:29  iter: 599  total_loss: 0.758  loss_cls: 0.253  loss_box_reg: 0.345  loss_rpn_cls: 0.035  loss_rpn_loc: 0.070  time: 0.5211  data_time: 0.0051  lr: 0.002997  max_mem: 3094M
[32m[04/19 22:07:56 d2.utils.events]: [0m eta: 0:03:19  iter: 619  total_loss: 0.721  loss_cls: 0.269  loss_box_reg: 0.364  loss_rpn_cls: 0.048  loss_rpn_loc: 0.083  time: 0.5211  data_time: 0.0050  lr: 0.003097  max_mem: 3094M
[32m[04/19 22:08:07 d2.utils.events]: [0m eta: 0:03:08  iter: 639  total_loss: 0.783  loss_cls: 0.271  loss_box_reg: 0.423  loss_rpn_cls: 0.039  loss_rpn_loc: 0.068  time: 0.5217  data_time: 0.0050  lr: 0.003197  max_mem: 3094M
[32m[04/19 22:08:17 d2.utils.events]: [0m eta: 0:02:58  iter: 659  total_loss: 0.804  loss_cls: 0.306  loss_box_reg: 0.377  loss_rpn_cls: 0.040  loss_rpn_loc: 0.065  time: 0.5218  data_time: 0.0049  lr: 0.003297  max_mem: 3094M
[32m[04/19 22:08:28 d2.utils.events]: [0m eta: 0:02:47  iter: 679  total_loss: 0.825  loss_cls: 0.276  loss_box_reg: 0.399  loss_rpn_cls: 0.047  loss_rpn_loc: 0.069  time: 0.5218  data_time: 0.0051  lr: 0.003397  max_mem: 3094M
[32m[04/19 22:08:38 d2.utils.events]: [0m eta: 0:02:37  iter: 699  total_loss: 0.755  loss_cls: 0.253  loss_box_reg: 0.375  loss_rpn_cls: 0.046  loss_rpn_loc: 0.058  time: 0.5220  data_time: 0.0054  lr: 0.003497  max_mem: 3094M
[32m[04/19 22:08:49 d2.utils.events]: [0m eta: 0:02:27  iter: 719  total_loss: 0.875  loss_cls: 0.291  loss_box_reg: 0.468  loss_rpn_cls: 0.045  loss_rpn_loc: 0.072  time: 0.5219  data_time: 0.0049  lr: 0.003596  max_mem: 3094M
[32m[04/19 22:09:00 d2.utils.events]: [0m eta: 0:02:16  iter: 739  total_loss: 0.678  loss_cls: 0.250  loss_box_reg: 0.331  loss_rpn_cls: 0.038  loss_rpn_loc: 0.079  time: 0.5225  data_time: 0.0049  lr: 0.003696  max_mem: 3094M
[32m[04/19 22:09:10 d2.utils.events]: [0m eta: 0:02:06  iter: 759  total_loss: 0.686  loss_cls: 0.256  loss_box_reg: 0.337  loss_rpn_cls: 0.039  loss_rpn_loc: 0.049  time: 0.5229  data_time: 0.0051  lr: 0.003796  max_mem: 3094M
[32m[04/19 22:09:21 d2.utils.events]: [0m eta: 0:01:55  iter: 779  total_loss: 0.738  loss_cls: 0.255  loss_box_reg: 0.395  loss_rpn_cls: 0.038  loss_rpn_loc: 0.087  time: 0.5231  data_time: 0.0051  lr: 0.003896  max_mem: 3094M
[32m[04/19 22:09:31 d2.utils.events]: [0m eta: 0:01:45  iter: 799  total_loss: 0.787  loss_cls: 0.270  loss_box_reg: 0.410  loss_rpn_cls: 0.035  loss_rpn_loc: 0.074  time: 0.5229  data_time: 0.0048  lr: 0.003996  max_mem: 3094M
[32m[04/19 22:09:42 d2.utils.events]: [0m eta: 0:01:34  iter: 819  total_loss: 0.714  loss_cls: 0.254  loss_box_reg: 0.356  loss_rpn_cls: 0.039  loss_rpn_loc: 0.065  time: 0.5233  data_time: 0.0048  lr: 0.004096  max_mem: 3094M
[32m[04/19 22:09:53 d2.utils.events]: [0m eta: 0:01:24  iter: 839  total_loss: 0.918  loss_cls: 0.322  loss_box_reg: 0.369  loss_rpn_cls: 0.053  loss_rpn_loc: 0.090  time: 0.5230  data_time: 0.0049  lr: 0.004196  max_mem: 3094M
[32m[04/19 22:10:03 d2.utils.events]: [0m eta: 0:01:13  iter: 859  total_loss: 0.614  loss_cls: 0.226  loss_box_reg: 0.308  loss_rpn_cls: 0.029  loss_rpn_loc: 0.049  time: 0.5230  data_time: 0.0055  lr: 0.004296  max_mem: 3094M
[32m[04/19 22:10:14 d2.utils.events]: [0m eta: 0:01:03  iter: 879  total_loss: 0.873  loss_cls: 0.285  loss_box_reg: 0.407  loss_rpn_cls: 0.044  loss_rpn_loc: 0.061  time: 0.5231  data_time: 0.0049  lr: 0.004396  max_mem: 3094M
[32m[04/19 22:10:24 d2.utils.events]: [0m eta: 0:00:52  iter: 899  total_loss: 0.873  loss_cls: 0.284  loss_box_reg: 0.432  loss_rpn_cls: 0.035  loss_rpn_loc: 0.072  time: 0.5231  data_time: 0.0050  lr: 0.004496  max_mem: 3094M
[32m[04/19 22:10:35 d2.utils.events]: [0m eta: 0:00:42  iter: 919  total_loss: 0.770  loss_cls: 0.277  loss_box_reg: 0.391  loss_rpn_cls: 0.039  loss_rpn_loc: 0.069  time: 0.5232  data_time: 0.0050  lr: 0.004595  max_mem: 3094M
[32m[04/19 22:10:45 d2.utils.events]: [0m eta: 0:00:31  iter: 939  total_loss: 0.672  loss_cls: 0.241  loss_box_reg: 0.341  loss_rpn_cls: 0.039  loss_rpn_loc: 0.075  time: 0.5232  data_time: 0.0049  lr: 0.004695  max_mem: 3094M
[32m[04/19 22:10:56 d2.utils.events]: [0m eta: 0:00:21  iter: 959  total_loss: 0.778  loss_cls: 0.282  loss_box_reg: 0.353  loss_rpn_cls: 0.062  loss_rpn_loc: 0.091  time: 0.5233  data_time: 0.0048  lr: 0.004795  max_mem: 3094M
[32m[04/19 22:11:07 d2.utils.events]: [0m eta: 0:00:11  iter: 979  total_loss: 0.805  loss_cls: 0.266  loss_box_reg: 0.387  loss_rpn_cls: 0.045  loss_rpn_loc: 0.069  time: 0.5235  data_time: 0.0048  lr: 0.004895  max_mem: 3094M
[5m[31mWARNING[0m [32m[04/19 22:11:21 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 22:11:21 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[5m[31mWARNING[0m [32m[04/19 22:11:21 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/19 22:11:21 d2.utils.events]: [0m eta: 0:00:00  iter: 999  total_loss: 0.811  loss_cls: 0.307  loss_box_reg: 0.418  loss_rpn_cls: 0.042  loss_rpn_loc: 0.073  time: 0.5234  data_time: 0.0051  lr: 0.004995  max_mem: 3094M
[32m[04/19 22:11:22 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:08:42 (0.5240 s / it)
[32m[04/19 22:11:22 d2.engine.hooks]: [0mTotal training time: 0:08:49 (0:00:07 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/19 22:11:27 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 22:11:27 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/19 22:11:27 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/19 22:11:29 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1180 s / img. ETA=0:16:47
[32m[04/19 22:11:34 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1176 s / img. ETA=0:16:41
[32m[04/19 22:11:39 d2.evaluation.evaluator]: [0mInference done 95/8355. 0.1173 s / img. ETA=0:16:33
[32m[04/19 22:11:44 d2.evaluation.evaluator]: [0mInference done 137/8355. 0.1174 s / img. ETA=0:16:29
[32m[04/19 22:11:49 d2.evaluation.evaluator]: [0mInference done 179/8355. 0.1174 s / img. ETA=0:16:24
[32m[04/19 22:11:54 d2.evaluation.evaluator]: [0mInference done 221/8355. 0.1174 s / img. ETA=0:16:19
[32m[04/19 22:11:59 d2.evaluation.evaluator]: [0mInference done 263/8355. 0.1174 s / img. ETA=0:16:15
[32m[04/19 22:12:04 d2.evaluation.evaluator]: [0mInference done 305/8355. 0.1174 s / img. ETA=0:16:09
[32m[04/19 22:12:09 d2.evaluation.evaluator]: [0mInference done 347/8355. 0.1174 s / img. ETA=0:16:05
[32m[04/19 22:12:14 d2.evaluation.evaluator]: [0mInference done 389/8355. 0.1174 s / img. ETA=0:15:59
[32m[04/19 22:12:19 d2.evaluation.evaluator]: [0mInference done 431/8355. 0.1175 s / img. ETA=0:15:55
[32m[04/19 22:12:24 d2.evaluation.evaluator]: [0mInference done 473/8355. 0.1175 s / img. ETA=0:15:49
[32m[04/19 22:12:29 d2.evaluation.evaluator]: [0mInference done 515/8355. 0.1175 s / img. ETA=0:15:44
[32m[04/19 22:12:34 d2.evaluation.evaluator]: [0mInference done 557/8355. 0.1175 s / img. ETA=0:15:39
[32m[04/19 22:12:39 d2.evaluation.evaluator]: [0mInference done 599/8355. 0.1174 s / img. ETA=0:15:34
[32m[04/19 22:12:45 d2.evaluation.evaluator]: [0mInference done 641/8355. 0.1175 s / img. ETA=0:15:29
[32m[04/19 22:12:50 d2.evaluation.evaluator]: [0mInference done 683/8355. 0.1175 s / img. ETA=0:15:24
[32m[04/19 22:12:55 d2.evaluation.evaluator]: [0mInference done 725/8355. 0.1175 s / img. ETA=0:15:19
[32m[04/19 22:13:00 d2.evaluation.evaluator]: [0mInference done 767/8355. 0.1175 s / img. ETA=0:15:14
[32m[04/19 22:13:05 d2.evaluation.evaluator]: [0mInference done 809/8355. 0.1175 s / img. ETA=0:15:08
[32m[04/19 22:13:10 d2.evaluation.evaluator]: [0mInference done 851/8355. 0.1175 s / img. ETA=0:15:03
[32m[04/19 22:13:15 d2.evaluation.evaluator]: [0mInference done 893/8355. 0.1175 s / img. ETA=0:14:58
[32m[04/19 22:13:20 d2.evaluation.evaluator]: [0mInference done 935/8355. 0.1175 s / img. ETA=0:14:53
[32m[04/19 22:13:25 d2.evaluation.evaluator]: [0mInference done 977/8355. 0.1175 s / img. ETA=0:14:48
[32m[04/19 22:13:30 d2.evaluation.evaluator]: [0mInference done 1019/8355. 0.1175 s / img. ETA=0:14:43
[32m[04/19 22:13:35 d2.evaluation.evaluator]: [0mInference done 1061/8355. 0.1175 s / img. ETA=0:14:38
[32m[04/19 22:13:40 d2.evaluation.evaluator]: [0mInference done 1103/8355. 0.1175 s / img. ETA=0:14:33
[32m[04/19 22:13:45 d2.evaluation.evaluator]: [0mInference done 1145/8355. 0.1175 s / img. ETA=0:14:28
[32m[04/19 22:13:50 d2.evaluation.evaluator]: [0mInference done 1187/8355. 0.1176 s / img. ETA=0:14:23
[32m[04/19 22:13:55 d2.evaluation.evaluator]: [0mInference done 1229/8355. 0.1176 s / img. ETA=0:14:18
[32m[04/19 22:14:01 d2.evaluation.evaluator]: [0mInference done 1271/8355. 0.1176 s / img. ETA=0:14:14
[32m[04/19 22:14:06 d2.evaluation.evaluator]: [0mInference done 1313/8355. 0.1176 s / img. ETA=0:14:09
[32m[04/19 22:14:11 d2.evaluation.evaluator]: [0mInference done 1355/8355. 0.1176 s / img. ETA=0:14:04
[32m[04/19 22:14:16 d2.evaluation.evaluator]: [0mInference done 1398/8355. 0.1176 s / img. ETA=0:13:58
[32m[04/19 22:14:21 d2.evaluation.evaluator]: [0mInference done 1441/8355. 0.1175 s / img. ETA=0:13:52
[32m[04/19 22:14:26 d2.evaluation.evaluator]: [0mInference done 1483/8355. 0.1175 s / img. ETA=0:13:47
[32m[04/19 22:14:31 d2.evaluation.evaluator]: [0mInference done 1525/8355. 0.1175 s / img. ETA=0:13:42
[32m[04/19 22:14:36 d2.evaluation.evaluator]: [0mInference done 1567/8355. 0.1175 s / img. ETA=0:13:37
[32m[04/19 22:14:41 d2.evaluation.evaluator]: [0mInference done 1609/8355. 0.1175 s / img. ETA=0:13:32
[32m[04/19 22:14:46 d2.evaluation.evaluator]: [0mInference done 1651/8355. 0.1176 s / img. ETA=0:13:27
[32m[04/19 22:14:51 d2.evaluation.evaluator]: [0mInference done 1693/8355. 0.1176 s / img. ETA=0:13:22
[32m[04/19 22:14:56 d2.evaluation.evaluator]: [0mInference done 1735/8355. 0.1176 s / img. ETA=0:13:17
[32m[04/19 22:15:01 d2.evaluation.evaluator]: [0mInference done 1777/8355. 0.1176 s / img. ETA=0:13:12
[32m[04/19 22:15:06 d2.evaluation.evaluator]: [0mInference done 1819/8355. 0.1176 s / img. ETA=0:13:07
[32m[04/19 22:15:11 d2.evaluation.evaluator]: [0mInference done 1861/8355. 0.1176 s / img. ETA=0:13:02
[32m[04/19 22:15:17 d2.evaluation.evaluator]: [0mInference done 1903/8355. 0.1176 s / img. ETA=0:12:57
[32m[04/19 22:15:22 d2.evaluation.evaluator]: [0mInference done 1945/8355. 0.1176 s / img. ETA=0:12:52
[32m[04/19 22:15:27 d2.evaluation.evaluator]: [0mInference done 1987/8355. 0.1176 s / img. ETA=0:12:47
[32m[04/19 22:15:32 d2.evaluation.evaluator]: [0mInference done 2029/8355. 0.1176 s / img. ETA=0:12:42
[32m[04/19 22:15:37 d2.evaluation.evaluator]: [0mInference done 2071/8355. 0.1176 s / img. ETA=0:12:37
[32m[04/19 22:15:42 d2.evaluation.evaluator]: [0mInference done 2113/8355. 0.1176 s / img. ETA=0:12:31
[32m[04/19 22:15:47 d2.evaluation.evaluator]: [0mInference done 2155/8355. 0.1176 s / img. ETA=0:12:26
[32m[04/19 22:15:52 d2.evaluation.evaluator]: [0mInference done 2197/8355. 0.1176 s / img. ETA=0:12:21
[32m[04/19 22:15:57 d2.evaluation.evaluator]: [0mInference done 2239/8355. 0.1176 s / img. ETA=0:12:16
[32m[04/19 22:16:02 d2.evaluation.evaluator]: [0mInference done 2281/8355. 0.1176 s / img. ETA=0:12:11
[32m[04/19 22:16:07 d2.evaluation.evaluator]: [0mInference done 2323/8355. 0.1176 s / img. ETA=0:12:06
[32m[04/19 22:16:12 d2.evaluation.evaluator]: [0mInference done 2365/8355. 0.1176 s / img. ETA=0:12:01
[32m[04/19 22:16:17 d2.evaluation.evaluator]: [0mInference done 2407/8355. 0.1176 s / img. ETA=0:11:56
[32m[04/19 22:16:22 d2.evaluation.evaluator]: [0mInference done 2449/8355. 0.1176 s / img. ETA=0:11:51
[32m[04/19 22:16:27 d2.evaluation.evaluator]: [0mInference done 2491/8355. 0.1176 s / img. ETA=0:11:46
[32m[04/19 22:16:32 d2.evaluation.evaluator]: [0mInference done 2533/8355. 0.1176 s / img. ETA=0:11:40
[32m[04/19 22:16:37 d2.evaluation.evaluator]: [0mInference done 2575/8355. 0.1176 s / img. ETA=0:11:35
[32m[04/19 22:16:42 d2.evaluation.evaluator]: [0mInference done 2617/8355. 0.1176 s / img. ETA=0:11:30
[32m[04/19 22:16:47 d2.evaluation.evaluator]: [0mInference done 2659/8355. 0.1176 s / img. ETA=0:11:25
[32m[04/19 22:16:52 d2.evaluation.evaluator]: [0mInference done 2701/8355. 0.1176 s / img. ETA=0:11:20
[32m[04/19 22:16:58 d2.evaluation.evaluator]: [0mInference done 2743/8355. 0.1176 s / img. ETA=0:11:15
[32m[04/19 22:17:03 d2.evaluation.evaluator]: [0mInference done 2785/8355. 0.1176 s / img. ETA=0:11:10
[32m[04/19 22:17:08 d2.evaluation.evaluator]: [0mInference done 2827/8355. 0.1176 s / img. ETA=0:11:05
[32m[04/19 22:17:13 d2.evaluation.evaluator]: [0mInference done 2869/8355. 0.1176 s / img. ETA=0:11:00
[32m[04/19 22:17:18 d2.evaluation.evaluator]: [0mInference done 2911/8355. 0.1176 s / img. ETA=0:10:55
[32m[04/19 22:17:23 d2.evaluation.evaluator]: [0mInference done 2953/8355. 0.1176 s / img. ETA=0:10:50
[32m[04/19 22:17:28 d2.evaluation.evaluator]: [0mInference done 2995/8355. 0.1176 s / img. ETA=0:10:45
[32m[04/19 22:17:33 d2.evaluation.evaluator]: [0mInference done 3037/8355. 0.1176 s / img. ETA=0:10:40
[32m[04/19 22:17:38 d2.evaluation.evaluator]: [0mInference done 3079/8355. 0.1176 s / img. ETA=0:10:35
[32m[04/19 22:17:43 d2.evaluation.evaluator]: [0mInference done 3121/8355. 0.1176 s / img. ETA=0:10:29
[32m[04/19 22:17:48 d2.evaluation.evaluator]: [0mInference done 3163/8355. 0.1176 s / img. ETA=0:10:24
[32m[04/19 22:17:53 d2.evaluation.evaluator]: [0mInference done 3205/8355. 0.1176 s / img. ETA=0:10:19
[32m[04/19 22:17:58 d2.evaluation.evaluator]: [0mInference done 3247/8355. 0.1176 s / img. ETA=0:10:14
[32m[04/19 22:18:03 d2.evaluation.evaluator]: [0mInference done 3289/8355. 0.1176 s / img. ETA=0:10:09
[32m[04/19 22:18:08 d2.evaluation.evaluator]: [0mInference done 3331/8355. 0.1176 s / img. ETA=0:10:04
[32m[04/19 22:18:13 d2.evaluation.evaluator]: [0mInference done 3373/8355. 0.1176 s / img. ETA=0:09:59
[32m[04/19 22:18:18 d2.evaluation.evaluator]: [0mInference done 3415/8355. 0.1176 s / img. ETA=0:09:54
[32m[04/19 22:18:23 d2.evaluation.evaluator]: [0mInference done 3457/8355. 0.1176 s / img. ETA=0:09:49
[32m[04/19 22:18:28 d2.evaluation.evaluator]: [0mInference done 3499/8355. 0.1176 s / img. ETA=0:09:44
[32m[04/19 22:18:34 d2.evaluation.evaluator]: [0mInference done 3541/8355. 0.1176 s / img. ETA=0:09:39
[32m[04/19 22:18:39 d2.evaluation.evaluator]: [0mInference done 3583/8355. 0.1176 s / img. ETA=0:09:34
[32m[04/19 22:18:44 d2.evaluation.evaluator]: [0mInference done 3625/8355. 0.1176 s / img. ETA=0:09:29
[32m[04/19 22:18:49 d2.evaluation.evaluator]: [0mInference done 3667/8355. 0.1176 s / img. ETA=0:09:24
[32m[04/19 22:18:54 d2.evaluation.evaluator]: [0mInference done 3709/8355. 0.1176 s / img. ETA=0:09:19
[32m[04/19 22:18:59 d2.evaluation.evaluator]: [0mInference done 3751/8355. 0.1176 s / img. ETA=0:09:14
[32m[04/19 22:19:04 d2.evaluation.evaluator]: [0mInference done 3793/8355. 0.1176 s / img. ETA=0:09:09
[32m[04/19 22:19:09 d2.evaluation.evaluator]: [0mInference done 3835/8355. 0.1176 s / img. ETA=0:09:04
[32m[04/19 22:19:14 d2.evaluation.evaluator]: [0mInference done 3877/8355. 0.1176 s / img. ETA=0:08:59
[32m[04/19 22:19:19 d2.evaluation.evaluator]: [0mInference done 3919/8355. 0.1176 s / img. ETA=0:08:53
[32m[04/19 22:19:24 d2.evaluation.evaluator]: [0mInference done 3961/8355. 0.1176 s / img. ETA=0:08:48
[32m[04/19 22:19:29 d2.evaluation.evaluator]: [0mInference done 4003/8355. 0.1176 s / img. ETA=0:08:43
[32m[04/19 22:19:34 d2.evaluation.evaluator]: [0mInference done 4045/8355. 0.1176 s / img. ETA=0:08:38
[32m[04/19 22:19:39 d2.evaluation.evaluator]: [0mInference done 4087/8355. 0.1176 s / img. ETA=0:08:33
[32m[04/19 22:19:44 d2.evaluation.evaluator]: [0mInference done 4129/8355. 0.1176 s / img. ETA=0:08:28
[32m[04/19 22:19:49 d2.evaluation.evaluator]: [0mInference done 4171/8355. 0.1176 s / img. ETA=0:08:23
[32m[04/19 22:19:54 d2.evaluation.evaluator]: [0mInference done 4213/8355. 0.1176 s / img. ETA=0:08:18
[32m[04/19 22:20:00 d2.evaluation.evaluator]: [0mInference done 4256/8355. 0.1176 s / img. ETA=0:08:13
[32m[04/19 22:20:05 d2.evaluation.evaluator]: [0mInference done 4299/8355. 0.1176 s / img. ETA=0:08:08
[32m[04/19 22:20:10 d2.evaluation.evaluator]: [0mInference done 4342/8355. 0.1176 s / img. ETA=0:08:02
[32m[04/19 22:20:15 d2.evaluation.evaluator]: [0mInference done 4385/8355. 0.1176 s / img. ETA=0:07:57
[32m[04/19 22:20:20 d2.evaluation.evaluator]: [0mInference done 4428/8355. 0.1176 s / img. ETA=0:07:52
[32m[04/19 22:20:25 d2.evaluation.evaluator]: [0mInference done 4471/8355. 0.1175 s / img. ETA=0:07:47
[32m[04/19 22:20:30 d2.evaluation.evaluator]: [0mInference done 4513/8355. 0.1175 s / img. ETA=0:07:42
[32m[04/19 22:20:35 d2.evaluation.evaluator]: [0mInference done 4555/8355. 0.1175 s / img. ETA=0:07:37
[32m[04/19 22:20:40 d2.evaluation.evaluator]: [0mInference done 4597/8355. 0.1175 s / img. ETA=0:07:31
[32m[04/19 22:20:45 d2.evaluation.evaluator]: [0mInference done 4639/8355. 0.1175 s / img. ETA=0:07:26
[32m[04/19 22:20:50 d2.evaluation.evaluator]: [0mInference done 4682/8355. 0.1175 s / img. ETA=0:07:21
[32m[04/19 22:20:55 d2.evaluation.evaluator]: [0mInference done 4725/8355. 0.1175 s / img. ETA=0:07:16
[32m[04/19 22:21:00 d2.evaluation.evaluator]: [0mInference done 4767/8355. 0.1175 s / img. ETA=0:07:11
[32m[04/19 22:21:05 d2.evaluation.evaluator]: [0mInference done 4809/8355. 0.1175 s / img. ETA=0:07:06
[32m[04/19 22:21:10 d2.evaluation.evaluator]: [0mInference done 4852/8355. 0.1175 s / img. ETA=0:07:01
[32m[04/19 22:21:16 d2.evaluation.evaluator]: [0mInference done 4895/8355. 0.1175 s / img. ETA=0:06:55
[32m[04/19 22:21:21 d2.evaluation.evaluator]: [0mInference done 4938/8355. 0.1174 s / img. ETA=0:06:50
[32m[04/19 22:21:26 d2.evaluation.evaluator]: [0mInference done 4981/8355. 0.1174 s / img. ETA=0:06:45
[32m[04/19 22:21:31 d2.evaluation.evaluator]: [0mInference done 5024/8355. 0.1174 s / img. ETA=0:06:40
[32m[04/19 22:21:36 d2.evaluation.evaluator]: [0mInference done 5067/8355. 0.1174 s / img. ETA=0:06:34
[32m[04/19 22:21:41 d2.evaluation.evaluator]: [0mInference done 5109/8355. 0.1174 s / img. ETA=0:06:29
[32m[04/19 22:21:46 d2.evaluation.evaluator]: [0mInference done 5151/8355. 0.1174 s / img. ETA=0:06:24
[32m[04/19 22:21:51 d2.evaluation.evaluator]: [0mInference done 5193/8355. 0.1174 s / img. ETA=0:06:19
[32m[04/19 22:21:56 d2.evaluation.evaluator]: [0mInference done 5236/8355. 0.1174 s / img. ETA=0:06:14
[32m[04/19 22:22:01 d2.evaluation.evaluator]: [0mInference done 5278/8355. 0.1174 s / img. ETA=0:06:09
[32m[04/19 22:22:06 d2.evaluation.evaluator]: [0mInference done 5320/8355. 0.1174 s / img. ETA=0:06:04
[32m[04/19 22:22:11 d2.evaluation.evaluator]: [0mInference done 5363/8355. 0.1174 s / img. ETA=0:05:59
[32m[04/19 22:22:16 d2.evaluation.evaluator]: [0mInference done 5405/8355. 0.1174 s / img. ETA=0:05:54
[32m[04/19 22:22:21 d2.evaluation.evaluator]: [0mInference done 5447/8355. 0.1174 s / img. ETA=0:05:49
[32m[04/19 22:22:26 d2.evaluation.evaluator]: [0mInference done 5490/8355. 0.1174 s / img. ETA=0:05:43
[32m[04/19 22:22:32 d2.evaluation.evaluator]: [0mInference done 5533/8355. 0.1174 s / img. ETA=0:05:38
[32m[04/19 22:22:37 d2.evaluation.evaluator]: [0mInference done 5576/8355. 0.1173 s / img. ETA=0:05:33
[32m[04/19 22:22:42 d2.evaluation.evaluator]: [0mInference done 5618/8355. 0.1173 s / img. ETA=0:05:28
[32m[04/19 22:22:47 d2.evaluation.evaluator]: [0mInference done 5660/8355. 0.1173 s / img. ETA=0:05:23
[32m[04/19 22:22:52 d2.evaluation.evaluator]: [0mInference done 5702/8355. 0.1173 s / img. ETA=0:05:18
[32m[04/19 22:22:57 d2.evaluation.evaluator]: [0mInference done 5744/8355. 0.1173 s / img. ETA=0:05:13
[32m[04/19 22:23:02 d2.evaluation.evaluator]: [0mInference done 5786/8355. 0.1173 s / img. ETA=0:05:08
[32m[04/19 22:23:07 d2.evaluation.evaluator]: [0mInference done 5828/8355. 0.1173 s / img. ETA=0:05:03
[32m[04/19 22:23:12 d2.evaluation.evaluator]: [0mInference done 5870/8355. 0.1173 s / img. ETA=0:04:58
[32m[04/19 22:23:17 d2.evaluation.evaluator]: [0mInference done 5912/8355. 0.1173 s / img. ETA=0:04:53
[32m[04/19 22:23:22 d2.evaluation.evaluator]: [0mInference done 5954/8355. 0.1173 s / img. ETA=0:04:48
[32m[04/19 22:23:27 d2.evaluation.evaluator]: [0mInference done 5996/8355. 0.1173 s / img. ETA=0:04:43
[32m[04/19 22:23:32 d2.evaluation.evaluator]: [0mInference done 6038/8355. 0.1173 s / img. ETA=0:04:38
[32m[04/19 22:23:37 d2.evaluation.evaluator]: [0mInference done 6080/8355. 0.1173 s / img. ETA=0:04:33
[32m[04/19 22:23:42 d2.evaluation.evaluator]: [0mInference done 6122/8355. 0.1173 s / img. ETA=0:04:27
[32m[04/19 22:23:47 d2.evaluation.evaluator]: [0mInference done 6164/8355. 0.1173 s / img. ETA=0:04:22
[32m[04/19 22:23:52 d2.evaluation.evaluator]: [0mInference done 6206/8355. 0.1173 s / img. ETA=0:04:17
[32m[04/19 22:23:57 d2.evaluation.evaluator]: [0mInference done 6248/8355. 0.1173 s / img. ETA=0:04:12
[32m[04/19 22:24:02 d2.evaluation.evaluator]: [0mInference done 6290/8355. 0.1173 s / img. ETA=0:04:07
[32m[04/19 22:24:07 d2.evaluation.evaluator]: [0mInference done 6332/8355. 0.1173 s / img. ETA=0:04:02
[32m[04/19 22:24:12 d2.evaluation.evaluator]: [0mInference done 6374/8355. 0.1173 s / img. ETA=0:03:57
[32m[04/19 22:24:17 d2.evaluation.evaluator]: [0mInference done 6416/8355. 0.1173 s / img. ETA=0:03:52
[32m[04/19 22:24:22 d2.evaluation.evaluator]: [0mInference done 6458/8355. 0.1173 s / img. ETA=0:03:47
[32m[04/19 22:24:27 d2.evaluation.evaluator]: [0mInference done 6500/8355. 0.1173 s / img. ETA=0:03:42
[32m[04/19 22:24:32 d2.evaluation.evaluator]: [0mInference done 6543/8355. 0.1173 s / img. ETA=0:03:37
[32m[04/19 22:24:37 d2.evaluation.evaluator]: [0mInference done 6586/8355. 0.1173 s / img. ETA=0:03:32
[32m[04/19 22:24:43 d2.evaluation.evaluator]: [0mInference done 6629/8355. 0.1173 s / img. ETA=0:03:27
[32m[04/19 22:24:48 d2.evaluation.evaluator]: [0mInference done 6671/8355. 0.1173 s / img. ETA=0:03:21
[32m[04/19 22:24:53 d2.evaluation.evaluator]: [0mInference done 6714/8355. 0.1173 s / img. ETA=0:03:16
[32m[04/19 22:24:58 d2.evaluation.evaluator]: [0mInference done 6757/8355. 0.1173 s / img. ETA=0:03:11
[32m[04/19 22:25:03 d2.evaluation.evaluator]: [0mInference done 6800/8355. 0.1173 s / img. ETA=0:03:06
[32m[04/19 22:25:08 d2.evaluation.evaluator]: [0mInference done 6843/8355. 0.1173 s / img. ETA=0:03:01
[32m[04/19 22:25:13 d2.evaluation.evaluator]: [0mInference done 6885/8355. 0.1173 s / img. ETA=0:02:56
[32m[04/19 22:25:18 d2.evaluation.evaluator]: [0mInference done 6927/8355. 0.1173 s / img. ETA=0:02:51
[32m[04/19 22:25:23 d2.evaluation.evaluator]: [0mInference done 6969/8355. 0.1173 s / img. ETA=0:02:46
[32m[04/19 22:25:28 d2.evaluation.evaluator]: [0mInference done 7011/8355. 0.1172 s / img. ETA=0:02:41
[32m[04/19 22:25:33 d2.evaluation.evaluator]: [0mInference done 7053/8355. 0.1172 s / img. ETA=0:02:36
[32m[04/19 22:25:38 d2.evaluation.evaluator]: [0mInference done 7095/8355. 0.1172 s / img. ETA=0:02:31
[32m[04/19 22:25:43 d2.evaluation.evaluator]: [0mInference done 7137/8355. 0.1173 s / img. ETA=0:02:26
[32m[04/19 22:25:48 d2.evaluation.evaluator]: [0mInference done 7179/8355. 0.1173 s / img. ETA=0:02:21
[32m[04/19 22:25:53 d2.evaluation.evaluator]: [0mInference done 7221/8355. 0.1173 s / img. ETA=0:02:15
[32m[04/19 22:25:58 d2.evaluation.evaluator]: [0mInference done 7263/8355. 0.1173 s / img. ETA=0:02:10
[32m[04/19 22:26:03 d2.evaluation.evaluator]: [0mInference done 7305/8355. 0.1173 s / img. ETA=0:02:05
[32m[04/19 22:26:08 d2.evaluation.evaluator]: [0mInference done 7347/8355. 0.1173 s / img. ETA=0:02:00
[32m[04/19 22:26:13 d2.evaluation.evaluator]: [0mInference done 7389/8355. 0.1173 s / img. ETA=0:01:55
[32m[04/19 22:26:18 d2.evaluation.evaluator]: [0mInference done 7431/8355. 0.1173 s / img. ETA=0:01:50
[32m[04/19 22:26:23 d2.evaluation.evaluator]: [0mInference done 7473/8355. 0.1173 s / img. ETA=0:01:45
[32m[04/19 22:26:28 d2.evaluation.evaluator]: [0mInference done 7516/8355. 0.1172 s / img. ETA=0:01:40
[32m[04/19 22:26:33 d2.evaluation.evaluator]: [0mInference done 7558/8355. 0.1172 s / img. ETA=0:01:35
[32m[04/19 22:26:38 d2.evaluation.evaluator]: [0mInference done 7600/8355. 0.1172 s / img. ETA=0:01:30
[32m[04/19 22:26:43 d2.evaluation.evaluator]: [0mInference done 7642/8355. 0.1172 s / img. ETA=0:01:25
[32m[04/19 22:26:49 d2.evaluation.evaluator]: [0mInference done 7684/8355. 0.1172 s / img. ETA=0:01:20
[32m[04/19 22:26:54 d2.evaluation.evaluator]: [0mInference done 7726/8355. 0.1172 s / img. ETA=0:01:15
[32m[04/19 22:26:59 d2.evaluation.evaluator]: [0mInference done 7768/8355. 0.1172 s / img. ETA=0:01:10
[32m[04/19 22:27:04 d2.evaluation.evaluator]: [0mInference done 7810/8355. 0.1172 s / img. ETA=0:01:05
[32m[04/19 22:27:09 d2.evaluation.evaluator]: [0mInference done 7852/8355. 0.1172 s / img. ETA=0:01:00
[32m[04/19 22:27:14 d2.evaluation.evaluator]: [0mInference done 7894/8355. 0.1172 s / img. ETA=0:00:55
[32m[04/19 22:27:19 d2.evaluation.evaluator]: [0mInference done 7936/8355. 0.1172 s / img. ETA=0:00:50
[32m[04/19 22:27:24 d2.evaluation.evaluator]: [0mInference done 7978/8355. 0.1173 s / img. ETA=0:00:45
[32m[04/19 22:27:29 d2.evaluation.evaluator]: [0mInference done 8020/8355. 0.1173 s / img. ETA=0:00:40
[32m[04/19 22:27:34 d2.evaluation.evaluator]: [0mInference done 8063/8355. 0.1172 s / img. ETA=0:00:35
[32m[04/19 22:27:39 d2.evaluation.evaluator]: [0mInference done 8106/8355. 0.1172 s / img. ETA=0:00:29
[32m[04/19 22:27:44 d2.evaluation.evaluator]: [0mInference done 8149/8355. 0.1172 s / img. ETA=0:00:24
[32m[04/19 22:27:49 d2.evaluation.evaluator]: [0mInference done 8192/8355. 0.1172 s / img. ETA=0:00:19
[32m[04/19 22:27:54 d2.evaluation.evaluator]: [0mInference done 8234/8355. 0.1172 s / img. ETA=0:00:14
[32m[04/19 22:27:59 d2.evaluation.evaluator]: [0mInference done 8276/8355. 0.1172 s / img. ETA=0:00:09
[32m[04/19 22:28:04 d2.evaluation.evaluator]: [0mInference done 8318/8355. 0.1172 s / img. ETA=0:00:04
[32m[04/19 22:28:09 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:40.891485 (0.119867 s / img per device, on 1 devices)
[32m[04/19 22:28:09 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:18 (0.117228 s / img per device, on 1 devices)
[32m[04/19 22:28:09 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/19 22:28:09 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/19 22:28:09 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.40s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=15.61s).
Accumulating evaluation results...
DONE (t=1.90s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.124
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.259
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.105
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.196
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.075
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.164
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.165
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.105
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.414
[32m[04/19 22:28:27 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 12.446 | 25.933 | 10.463 | 6.847 | 19.590 | 34.413 |
[32m[04/19 22:28:27 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 20.132 | bicycle       | 4.756 | car            | 23.319 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | 1.578 | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    |               |       |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/19 22:28:28 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 22:28:28 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[32m[04/19 22:28:28 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/19 22:28:30 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1164 s / img. ETA=0:02:27
[32m[04/19 22:28:35 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1164 s / img. ETA=0:02:23
[32m[04/19 22:28:40 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1164 s / img. ETA=0:02:17
[32m[04/19 22:28:45 d2.evaluation.evaluator]: [0mInference done 139/1257. 0.1165 s / img. ETA=0:02:13
[32m[04/19 22:28:50 d2.evaluation.evaluator]: [0mInference done 182/1257. 0.1164 s / img. ETA=0:02:07
[32m[04/19 22:28:55 d2.evaluation.evaluator]: [0mInference done 225/1257. 0.1164 s / img. ETA=0:02:02
[32m[04/19 22:29:00 d2.evaluation.evaluator]: [0mInference done 268/1257. 0.1164 s / img. ETA=0:01:57
[32m[04/19 22:29:05 d2.evaluation.evaluator]: [0mInference done 311/1257. 0.1164 s / img. ETA=0:01:52
[32m[04/19 22:29:11 d2.evaluation.evaluator]: [0mInference done 354/1257. 0.1163 s / img. ETA=0:01:47
[32m[04/19 22:29:16 d2.evaluation.evaluator]: [0mInference done 397/1257. 0.1163 s / img. ETA=0:01:42
[32m[04/19 22:29:21 d2.evaluation.evaluator]: [0mInference done 440/1257. 0.1163 s / img. ETA=0:01:37
[32m[04/19 22:29:26 d2.evaluation.evaluator]: [0mInference done 483/1257. 0.1163 s / img. ETA=0:01:31
[32m[04/19 22:29:31 d2.evaluation.evaluator]: [0mInference done 525/1257. 0.1164 s / img. ETA=0:01:27
[32m[04/19 22:29:36 d2.evaluation.evaluator]: [0mInference done 567/1257. 0.1165 s / img. ETA=0:01:22
[32m[04/19 22:29:41 d2.evaluation.evaluator]: [0mInference done 609/1257. 0.1165 s / img. ETA=0:01:17
[32m[04/19 22:29:46 d2.evaluation.evaluator]: [0mInference done 651/1257. 0.1165 s / img. ETA=0:01:12
[32m[04/19 22:29:51 d2.evaluation.evaluator]: [0mInference done 693/1257. 0.1165 s / img. ETA=0:01:07
[32m[04/19 22:29:56 d2.evaluation.evaluator]: [0mInference done 735/1257. 0.1165 s / img. ETA=0:01:02
[32m[04/19 22:30:01 d2.evaluation.evaluator]: [0mInference done 778/1257. 0.1165 s / img. ETA=0:00:56
[32m[04/19 22:30:06 d2.evaluation.evaluator]: [0mInference done 821/1257. 0.1165 s / img. ETA=0:00:51
[32m[04/19 22:30:11 d2.evaluation.evaluator]: [0mInference done 864/1257. 0.1165 s / img. ETA=0:00:46
[32m[04/19 22:30:16 d2.evaluation.evaluator]: [0mInference done 907/1257. 0.1165 s / img. ETA=0:00:41
[32m[04/19 22:30:22 d2.evaluation.evaluator]: [0mInference done 950/1257. 0.1165 s / img. ETA=0:00:36
[32m[04/19 22:30:27 d2.evaluation.evaluator]: [0mInference done 993/1257. 0.1165 s / img. ETA=0:00:31
[32m[04/19 22:30:32 d2.evaluation.evaluator]: [0mInference done 1036/1257. 0.1165 s / img. ETA=0:00:26
[32m[04/19 22:30:37 d2.evaluation.evaluator]: [0mInference done 1079/1257. 0.1165 s / img. ETA=0:00:21
[32m[04/19 22:30:42 d2.evaluation.evaluator]: [0mInference done 1122/1257. 0.1165 s / img. ETA=0:00:16
[32m[04/19 22:30:47 d2.evaluation.evaluator]: [0mInference done 1165/1257. 0.1165 s / img. ETA=0:00:10
[32m[04/19 22:30:52 d2.evaluation.evaluator]: [0mInference done 1208/1257. 0.1165 s / img. ETA=0:00:05
[32m[04/19 22:30:57 d2.evaluation.evaluator]: [0mInference done 1251/1257. 0.1164 s / img. ETA=0:00:00
[32m[04/19 22:30:58 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:28.942328 (0.118964 s / img per device, on 1 devices)
[32m[04/19 22:30:58 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:25 (0.116441 s / img per device, on 1 devices)
[32m[04/19 22:30:58 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/19 22:30:58 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/19 22:30:58 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.00s).
Accumulating evaluation results...
DONE (t=0.31s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.116
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.229
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.103
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.150
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.307
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.070
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.152
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.152
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.194
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.356
[32m[04/19 22:31:01 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 11.555 | 22.907 | 10.265 | 5.665 | 15.032 | 30.750 |
[32m[04/19 22:31:01 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 15.879 | bicycle       | 2.855 | car            | 27.487 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | 0.000 | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  2  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/19 22:31:01 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/19 22:31:02 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 22:31:02 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/19 22:31:02 d2.data.build]: [0mRemoved 889 images with no usable annotations. 7466 images left.
[32m[04/19 22:31:02 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/19 22:31:02 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/19 22:31:02 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/19 22:31:13 d2.utils.events]: [0m eta: 0:08:32  iter: 19  total_loss: 0.607  loss_cls: 0.241  loss_box_reg: 0.300  loss_rpn_cls: 0.037  loss_rpn_loc: 0.048  time: 0.5166  data_time: 0.0137  lr: 0.000100  max_mem: 3094M
[32m[04/19 22:31:23 d2.utils.events]: [0m eta: 0:08:24  iter: 39  total_loss: 0.816  loss_cls: 0.278  loss_box_reg: 0.417  loss_rpn_cls: 0.049  loss_rpn_loc: 0.095  time: 0.5225  data_time: 0.0046  lr: 0.000200  max_mem: 3094M
[32m[04/19 22:31:34 d2.utils.events]: [0m eta: 0:08:14  iter: 59  total_loss: 0.904  loss_cls: 0.297  loss_box_reg: 0.384  loss_rpn_cls: 0.052  loss_rpn_loc: 0.062  time: 0.5248  data_time: 0.0046  lr: 0.000300  max_mem: 3094M
[32m[04/19 22:31:45 d2.utils.events]: [0m eta: 0:08:04  iter: 79  total_loss: 0.555  loss_cls: 0.194  loss_box_reg: 0.300  loss_rpn_cls: 0.027  loss_rpn_loc: 0.048  time: 0.5271  data_time: 0.0047  lr: 0.000400  max_mem: 3094M
[32m[04/19 22:31:55 d2.utils.events]: [0m eta: 0:07:50  iter: 99  total_loss: 0.735  loss_cls: 0.246  loss_box_reg: 0.403  loss_rpn_cls: 0.038  loss_rpn_loc: 0.052  time: 0.5244  data_time: 0.0049  lr: 0.000500  max_mem: 3094M
[32m[04/19 22:32:05 d2.utils.events]: [0m eta: 0:07:37  iter: 119  total_loss: 0.710  loss_cls: 0.246  loss_box_reg: 0.374  loss_rpn_cls: 0.037  loss_rpn_loc: 0.063  time: 0.5218  data_time: 0.0046  lr: 0.000599  max_mem: 3094M
[32m[04/19 22:32:16 d2.utils.events]: [0m eta: 0:07:25  iter: 139  total_loss: 0.751  loss_cls: 0.258  loss_box_reg: 0.402  loss_rpn_cls: 0.028  loss_rpn_loc: 0.062  time: 0.5206  data_time: 0.0046  lr: 0.000699  max_mem: 3094M
[32m[04/19 22:32:26 d2.utils.events]: [0m eta: 0:07:17  iter: 159  total_loss: 0.832  loss_cls: 0.272  loss_box_reg: 0.389  loss_rpn_cls: 0.040  loss_rpn_loc: 0.096  time: 0.5210  data_time: 0.0051  lr: 0.000799  max_mem: 3094M
[32m[04/19 22:32:37 d2.utils.events]: [0m eta: 0:07:06  iter: 179  total_loss: 0.768  loss_cls: 0.271  loss_box_reg: 0.413  loss_rpn_cls: 0.035  loss_rpn_loc: 0.055  time: 0.5205  data_time: 0.0050  lr: 0.000899  max_mem: 3094M
[32m[04/19 22:32:47 d2.utils.events]: [0m eta: 0:06:55  iter: 199  total_loss: 0.722  loss_cls: 0.251  loss_box_reg: 0.372  loss_rpn_cls: 0.031  loss_rpn_loc: 0.056  time: 0.5189  data_time: 0.0045  lr: 0.000999  max_mem: 3094M
[32m[04/19 22:32:57 d2.utils.events]: [0m eta: 0:06:44  iter: 219  total_loss: 0.812  loss_cls: 0.267  loss_box_reg: 0.390  loss_rpn_cls: 0.034  loss_rpn_loc: 0.070  time: 0.5189  data_time: 0.0046  lr: 0.001099  max_mem: 3094M
[32m[04/19 22:33:08 d2.utils.events]: [0m eta: 0:06:33  iter: 239  total_loss: 0.731  loss_cls: 0.227  loss_box_reg: 0.387  loss_rpn_cls: 0.031  loss_rpn_loc: 0.064  time: 0.5188  data_time: 0.0046  lr: 0.001199  max_mem: 3094M
[32m[04/19 22:33:18 d2.utils.events]: [0m eta: 0:06:25  iter: 259  total_loss: 0.721  loss_cls: 0.239  loss_box_reg: 0.367  loss_rpn_cls: 0.031  loss_rpn_loc: 0.056  time: 0.5200  data_time: 0.0047  lr: 0.001299  max_mem: 3094M
[32m[04/19 22:33:28 d2.utils.events]: [0m eta: 0:06:14  iter: 279  total_loss: 0.683  loss_cls: 0.229  loss_box_reg: 0.379  loss_rpn_cls: 0.029  loss_rpn_loc: 0.057  time: 0.5188  data_time: 0.0044  lr: 0.001399  max_mem: 3094M
[32m[04/19 22:33:39 d2.utils.events]: [0m eta: 0:06:04  iter: 299  total_loss: 0.721  loss_cls: 0.251  loss_box_reg: 0.378  loss_rpn_cls: 0.024  loss_rpn_loc: 0.053  time: 0.5200  data_time: 0.0047  lr: 0.001499  max_mem: 3094M
[32m[04/19 22:33:50 d2.utils.events]: [0m eta: 0:05:54  iter: 319  total_loss: 0.735  loss_cls: 0.236  loss_box_reg: 0.352  loss_rpn_cls: 0.033  loss_rpn_loc: 0.058  time: 0.5196  data_time: 0.0047  lr: 0.001598  max_mem: 3094M
[32m[04/19 22:34:00 d2.utils.events]: [0m eta: 0:05:43  iter: 339  total_loss: 0.690  loss_cls: 0.245  loss_box_reg: 0.333  loss_rpn_cls: 0.031  loss_rpn_loc: 0.052  time: 0.5197  data_time: 0.0047  lr: 0.001698  max_mem: 3094M
[32m[04/19 22:34:11 d2.utils.events]: [0m eta: 0:05:33  iter: 359  total_loss: 0.600  loss_cls: 0.220  loss_box_reg: 0.314  loss_rpn_cls: 0.024  loss_rpn_loc: 0.055  time: 0.5200  data_time: 0.0046  lr: 0.001798  max_mem: 3094M
[32m[04/19 22:34:21 d2.utils.events]: [0m eta: 0:05:23  iter: 379  total_loss: 0.748  loss_cls: 0.239  loss_box_reg: 0.366  loss_rpn_cls: 0.036  loss_rpn_loc: 0.071  time: 0.5201  data_time: 0.0047  lr: 0.001898  max_mem: 3094M
[32m[04/19 22:34:31 d2.utils.events]: [0m eta: 0:05:13  iter: 399  total_loss: 0.695  loss_cls: 0.236  loss_box_reg: 0.371  loss_rpn_cls: 0.031  loss_rpn_loc: 0.073  time: 0.5201  data_time: 0.0047  lr: 0.001998  max_mem: 3094M
[32m[04/19 22:34:41 d2.utils.events]: [0m eta: 0:05:02  iter: 419  total_loss: 0.882  loss_cls: 0.292  loss_box_reg: 0.471  loss_rpn_cls: 0.042  loss_rpn_loc: 0.069  time: 0.5189  data_time: 0.0047  lr: 0.002098  max_mem: 3094M
[32m[04/19 22:34:52 d2.utils.events]: [0m eta: 0:04:51  iter: 439  total_loss: 0.815  loss_cls: 0.270  loss_box_reg: 0.382  loss_rpn_cls: 0.042  loss_rpn_loc: 0.074  time: 0.5185  data_time: 0.0047  lr: 0.002198  max_mem: 3094M
[32m[04/19 22:35:02 d2.utils.events]: [0m eta: 0:04:41  iter: 459  total_loss: 0.743  loss_cls: 0.266  loss_box_reg: 0.365  loss_rpn_cls: 0.041  loss_rpn_loc: 0.049  time: 0.5192  data_time: 0.0052  lr: 0.002298  max_mem: 3094M
[32m[04/19 22:35:13 d2.utils.events]: [0m eta: 0:04:31  iter: 479  total_loss: 0.775  loss_cls: 0.240  loss_box_reg: 0.387  loss_rpn_cls: 0.036  loss_rpn_loc: 0.067  time: 0.5193  data_time: 0.0047  lr: 0.002398  max_mem: 3094M
[32m[04/19 22:35:23 d2.utils.events]: [0m eta: 0:04:20  iter: 499  total_loss: 0.640  loss_cls: 0.227  loss_box_reg: 0.375  loss_rpn_cls: 0.027  loss_rpn_loc: 0.064  time: 0.5190  data_time: 0.0045  lr: 0.002498  max_mem: 3094M
[32m[04/19 22:35:34 d2.utils.events]: [0m eta: 0:04:10  iter: 519  total_loss: 0.821  loss_cls: 0.242  loss_box_reg: 0.442  loss_rpn_cls: 0.033  loss_rpn_loc: 0.071  time: 0.5189  data_time: 0.0046  lr: 0.002597  max_mem: 3094M
[32m[04/19 22:35:44 d2.utils.events]: [0m eta: 0:03:59  iter: 539  total_loss: 0.729  loss_cls: 0.245  loss_box_reg: 0.339  loss_rpn_cls: 0.033  loss_rpn_loc: 0.054  time: 0.5190  data_time: 0.0047  lr: 0.002697  max_mem: 3094M
[32m[04/19 22:35:55 d2.utils.events]: [0m eta: 0:03:49  iter: 559  total_loss: 0.657  loss_cls: 0.254  loss_box_reg: 0.323  loss_rpn_cls: 0.027  loss_rpn_loc: 0.046  time: 0.5189  data_time: 0.0051  lr: 0.002797  max_mem: 3094M
[32m[04/19 22:36:05 d2.utils.events]: [0m eta: 0:03:38  iter: 579  total_loss: 0.776  loss_cls: 0.264  loss_box_reg: 0.400  loss_rpn_cls: 0.029  loss_rpn_loc: 0.052  time: 0.5190  data_time: 0.0045  lr: 0.002897  max_mem: 3094M
[32m[04/19 22:36:15 d2.utils.events]: [0m eta: 0:03:28  iter: 599  total_loss: 0.749  loss_cls: 0.273  loss_box_reg: 0.322  loss_rpn_cls: 0.035  loss_rpn_loc: 0.079  time: 0.5186  data_time: 0.0046  lr: 0.002997  max_mem: 3094M
[32m[04/19 22:36:26 d2.utils.events]: [0m eta: 0:03:17  iter: 619  total_loss: 0.793  loss_cls: 0.262  loss_box_reg: 0.381  loss_rpn_cls: 0.040  loss_rpn_loc: 0.084  time: 0.5186  data_time: 0.0047  lr: 0.003097  max_mem: 3094M
[32m[04/19 22:36:36 d2.utils.events]: [0m eta: 0:03:07  iter: 639  total_loss: 0.532  loss_cls: 0.204  loss_box_reg: 0.296  loss_rpn_cls: 0.026  loss_rpn_loc: 0.043  time: 0.5188  data_time: 0.0047  lr: 0.003197  max_mem: 3094M
[32m[04/19 22:36:46 d2.utils.events]: [0m eta: 0:02:57  iter: 659  total_loss: 0.682  loss_cls: 0.241  loss_box_reg: 0.298  loss_rpn_cls: 0.025  loss_rpn_loc: 0.079  time: 0.5182  data_time: 0.0051  lr: 0.003297  max_mem: 3094M
[32m[04/19 22:36:56 d2.utils.events]: [0m eta: 0:02:46  iter: 679  total_loss: 0.635  loss_cls: 0.207  loss_box_reg: 0.311  loss_rpn_cls: 0.038  loss_rpn_loc: 0.067  time: 0.5173  data_time: 0.0052  lr: 0.003397  max_mem: 3094M
[32m[04/19 22:37:06 d2.utils.events]: [0m eta: 0:02:36  iter: 699  total_loss: 0.734  loss_cls: 0.264  loss_box_reg: 0.351  loss_rpn_cls: 0.037  loss_rpn_loc: 0.072  time: 0.5174  data_time: 0.0045  lr: 0.003497  max_mem: 3094M
[32m[04/19 22:37:17 d2.utils.events]: [0m eta: 0:02:25  iter: 719  total_loss: 0.705  loss_cls: 0.230  loss_box_reg: 0.362  loss_rpn_cls: 0.028  loss_rpn_loc: 0.055  time: 0.5174  data_time: 0.0048  lr: 0.003596  max_mem: 3094M
[32m[04/19 22:37:27 d2.utils.events]: [0m eta: 0:02:15  iter: 739  total_loss: 0.662  loss_cls: 0.241  loss_box_reg: 0.377  loss_rpn_cls: 0.027  loss_rpn_loc: 0.074  time: 0.5174  data_time: 0.0046  lr: 0.003696  max_mem: 3094M
[32m[04/19 22:37:38 d2.utils.events]: [0m eta: 0:02:05  iter: 759  total_loss: 0.665  loss_cls: 0.245  loss_box_reg: 0.345  loss_rpn_cls: 0.030  loss_rpn_loc: 0.059  time: 0.5177  data_time: 0.0048  lr: 0.003796  max_mem: 3094M
[32m[04/19 22:37:48 d2.utils.events]: [0m eta: 0:01:54  iter: 779  total_loss: 0.770  loss_cls: 0.262  loss_box_reg: 0.399  loss_rpn_cls: 0.032  loss_rpn_loc: 0.060  time: 0.5176  data_time: 0.0050  lr: 0.003896  max_mem: 3094M
[32m[04/19 22:37:59 d2.utils.events]: [0m eta: 0:01:44  iter: 799  total_loss: 0.770  loss_cls: 0.264  loss_box_reg: 0.363  loss_rpn_cls: 0.027  loss_rpn_loc: 0.086  time: 0.5183  data_time: 0.0047  lr: 0.003996  max_mem: 3094M
[32m[04/19 22:38:10 d2.utils.events]: [0m eta: 0:01:34  iter: 819  total_loss: 0.644  loss_cls: 0.225  loss_box_reg: 0.284  loss_rpn_cls: 0.036  loss_rpn_loc: 0.068  time: 0.5184  data_time: 0.0046  lr: 0.004096  max_mem: 3094M
[32m[04/19 22:38:20 d2.utils.events]: [0m eta: 0:01:23  iter: 839  total_loss: 0.807  loss_cls: 0.287  loss_box_reg: 0.421  loss_rpn_cls: 0.026  loss_rpn_loc: 0.068  time: 0.5182  data_time: 0.0047  lr: 0.004196  max_mem: 3094M
[32m[04/19 22:38:31 d2.utils.events]: [0m eta: 0:01:13  iter: 859  total_loss: 0.685  loss_cls: 0.208  loss_box_reg: 0.358  loss_rpn_cls: 0.042  loss_rpn_loc: 0.061  time: 0.5185  data_time: 0.0049  lr: 0.004296  max_mem: 3094M
[32m[04/19 22:38:41 d2.utils.events]: [0m eta: 0:01:02  iter: 879  total_loss: 0.760  loss_cls: 0.269  loss_box_reg: 0.399  loss_rpn_cls: 0.048  loss_rpn_loc: 0.062  time: 0.5183  data_time: 0.0049  lr: 0.004396  max_mem: 3094M
[32m[04/19 22:38:51 d2.utils.events]: [0m eta: 0:00:52  iter: 899  total_loss: 0.775  loss_cls: 0.247  loss_box_reg: 0.392  loss_rpn_cls: 0.046  loss_rpn_loc: 0.065  time: 0.5185  data_time: 0.0048  lr: 0.004496  max_mem: 3094M
[32m[04/19 22:39:02 d2.utils.events]: [0m eta: 0:00:42  iter: 919  total_loss: 0.732  loss_cls: 0.265  loss_box_reg: 0.364  loss_rpn_cls: 0.041  loss_rpn_loc: 0.055  time: 0.5184  data_time: 0.0047  lr: 0.004595  max_mem: 3094M
[32m[04/19 22:39:12 d2.utils.events]: [0m eta: 0:00:31  iter: 939  total_loss: 0.895  loss_cls: 0.308  loss_box_reg: 0.447  loss_rpn_cls: 0.033  loss_rpn_loc: 0.095  time: 0.5187  data_time: 0.0049  lr: 0.004695  max_mem: 3094M
[32m[04/19 22:39:23 d2.utils.events]: [0m eta: 0:00:21  iter: 959  total_loss: 0.841  loss_cls: 0.295  loss_box_reg: 0.416  loss_rpn_cls: 0.037  loss_rpn_loc: 0.075  time: 0.5188  data_time: 0.0046  lr: 0.004795  max_mem: 3094M
[32m[04/19 22:39:34 d2.utils.events]: [0m eta: 0:00:10  iter: 979  total_loss: 0.795  loss_cls: 0.276  loss_box_reg: 0.370  loss_rpn_cls: 0.051  loss_rpn_loc: 0.082  time: 0.5192  data_time: 0.0049  lr: 0.004895  max_mem: 3094M
[5m[31mWARNING[0m [32m[04/19 22:39:48 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 22:39:48 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[5m[31mWARNING[0m [32m[04/19 22:39:48 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/19 22:39:48 d2.utils.events]: [0m eta: 0:00:00  iter: 999  total_loss: 0.774  loss_cls: 0.259  loss_box_reg: 0.388  loss_rpn_cls: 0.033  loss_rpn_loc: 0.066  time: 0.5194  data_time: 0.0049  lr: 0.004995  max_mem: 3094M
[32m[04/19 22:39:49 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:08:38 (0.5200 s / it)
[32m[04/19 22:39:49 d2.engine.hooks]: [0mTotal training time: 0:08:45 (0:00:06 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/19 22:39:53 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 22:39:53 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/19 22:39:53 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/19 22:39:55 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1163 s / img. ETA=0:16:25
[32m[04/19 22:40:00 d2.evaluation.evaluator]: [0mInference done 54/8355. 0.1160 s / img. ETA=0:16:20
[32m[04/19 22:40:05 d2.evaluation.evaluator]: [0mInference done 97/8355. 0.1157 s / img. ETA=0:16:12
[32m[04/19 22:40:10 d2.evaluation.evaluator]: [0mInference done 140/8355. 0.1157 s / img. ETA=0:16:07
[32m[04/19 22:40:15 d2.evaluation.evaluator]: [0mInference done 183/8355. 0.1156 s / img. ETA=0:16:01
[32m[04/19 22:40:20 d2.evaluation.evaluator]: [0mInference done 226/8355. 0.1157 s / img. ETA=0:15:57
[32m[04/19 22:40:25 d2.evaluation.evaluator]: [0mInference done 269/8355. 0.1158 s / img. ETA=0:15:52
[32m[04/19 22:40:30 d2.evaluation.evaluator]: [0mInference done 312/8355. 0.1158 s / img. ETA=0:15:48
[32m[04/19 22:40:35 d2.evaluation.evaluator]: [0mInference done 355/8355. 0.1158 s / img. ETA=0:15:42
[32m[04/19 22:40:40 d2.evaluation.evaluator]: [0mInference done 398/8355. 0.1158 s / img. ETA=0:15:37
[32m[04/19 22:40:45 d2.evaluation.evaluator]: [0mInference done 441/8355. 0.1158 s / img. ETA=0:15:32
[32m[04/19 22:40:50 d2.evaluation.evaluator]: [0mInference done 484/8355. 0.1157 s / img. ETA=0:15:27
[32m[04/19 22:40:55 d2.evaluation.evaluator]: [0mInference done 527/8355. 0.1157 s / img. ETA=0:15:22
[32m[04/19 22:41:00 d2.evaluation.evaluator]: [0mInference done 570/8355. 0.1157 s / img. ETA=0:15:17
[32m[04/19 22:41:05 d2.evaluation.evaluator]: [0mInference done 613/8355. 0.1157 s / img. ETA=0:15:12
[32m[04/19 22:41:11 d2.evaluation.evaluator]: [0mInference done 656/8355. 0.1157 s / img. ETA=0:15:07
[32m[04/19 22:41:16 d2.evaluation.evaluator]: [0mInference done 699/8355. 0.1158 s / img. ETA=0:15:02
[32m[04/19 22:41:21 d2.evaluation.evaluator]: [0mInference done 742/8355. 0.1158 s / img. ETA=0:14:57
[32m[04/19 22:41:26 d2.evaluation.evaluator]: [0mInference done 785/8355. 0.1158 s / img. ETA=0:14:52
[32m[04/19 22:41:31 d2.evaluation.evaluator]: [0mInference done 828/8355. 0.1158 s / img. ETA=0:14:47
[32m[04/19 22:41:36 d2.evaluation.evaluator]: [0mInference done 871/8355. 0.1158 s / img. ETA=0:14:42
[32m[04/19 22:41:41 d2.evaluation.evaluator]: [0mInference done 914/8355. 0.1158 s / img. ETA=0:14:37
[32m[04/19 22:41:46 d2.evaluation.evaluator]: [0mInference done 957/8355. 0.1158 s / img. ETA=0:14:32
[32m[04/19 22:41:51 d2.evaluation.evaluator]: [0mInference done 1000/8355. 0.1158 s / img. ETA=0:14:27
[32m[04/19 22:41:56 d2.evaluation.evaluator]: [0mInference done 1043/8355. 0.1158 s / img. ETA=0:14:22
[32m[04/19 22:42:01 d2.evaluation.evaluator]: [0mInference done 1086/8355. 0.1158 s / img. ETA=0:14:17
[32m[04/19 22:42:06 d2.evaluation.evaluator]: [0mInference done 1129/8355. 0.1158 s / img. ETA=0:14:12
[32m[04/19 22:42:11 d2.evaluation.evaluator]: [0mInference done 1172/8355. 0.1157 s / img. ETA=0:14:07
[32m[04/19 22:42:17 d2.evaluation.evaluator]: [0mInference done 1215/8355. 0.1158 s / img. ETA=0:14:02
[32m[04/19 22:42:22 d2.evaluation.evaluator]: [0mInference done 1258/8355. 0.1158 s / img. ETA=0:13:57
[32m[04/19 22:42:27 d2.evaluation.evaluator]: [0mInference done 1301/8355. 0.1158 s / img. ETA=0:13:52
[32m[04/19 22:42:32 d2.evaluation.evaluator]: [0mInference done 1344/8355. 0.1158 s / img. ETA=0:13:47
[32m[04/19 22:42:37 d2.evaluation.evaluator]: [0mInference done 1387/8355. 0.1158 s / img. ETA=0:13:42
[32m[04/19 22:42:42 d2.evaluation.evaluator]: [0mInference done 1430/8355. 0.1158 s / img. ETA=0:13:37
[32m[04/19 22:42:47 d2.evaluation.evaluator]: [0mInference done 1473/8355. 0.1158 s / img. ETA=0:13:32
[32m[04/19 22:42:52 d2.evaluation.evaluator]: [0mInference done 1515/8355. 0.1158 s / img. ETA=0:13:27
[32m[04/19 22:42:57 d2.evaluation.evaluator]: [0mInference done 1557/8355. 0.1159 s / img. ETA=0:13:22
[32m[04/19 22:43:02 d2.evaluation.evaluator]: [0mInference done 1600/8355. 0.1159 s / img. ETA=0:13:17
[32m[04/19 22:43:07 d2.evaluation.evaluator]: [0mInference done 1642/8355. 0.1159 s / img. ETA=0:13:13
[32m[04/19 22:43:12 d2.evaluation.evaluator]: [0mInference done 1684/8355. 0.1159 s / img. ETA=0:13:08
[32m[04/19 22:43:17 d2.evaluation.evaluator]: [0mInference done 1727/8355. 0.1159 s / img. ETA=0:13:03
[32m[04/19 22:43:22 d2.evaluation.evaluator]: [0mInference done 1769/8355. 0.1160 s / img. ETA=0:12:58
[32m[04/19 22:43:27 d2.evaluation.evaluator]: [0mInference done 1812/8355. 0.1160 s / img. ETA=0:12:53
[32m[04/19 22:43:33 d2.evaluation.evaluator]: [0mInference done 1855/8355. 0.1160 s / img. ETA=0:12:48
[32m[04/19 22:43:38 d2.evaluation.evaluator]: [0mInference done 1898/8355. 0.1160 s / img. ETA=0:12:43
[32m[04/19 22:43:43 d2.evaluation.evaluator]: [0mInference done 1941/8355. 0.1160 s / img. ETA=0:12:38
[32m[04/19 22:43:48 d2.evaluation.evaluator]: [0mInference done 1984/8355. 0.1160 s / img. ETA=0:12:33
[32m[04/19 22:43:53 d2.evaluation.evaluator]: [0mInference done 2027/8355. 0.1160 s / img. ETA=0:12:28
[32m[04/19 22:43:58 d2.evaluation.evaluator]: [0mInference done 2070/8355. 0.1160 s / img. ETA=0:12:23
[32m[04/19 22:44:03 d2.evaluation.evaluator]: [0mInference done 2113/8355. 0.1160 s / img. ETA=0:12:18
[32m[04/19 22:44:08 d2.evaluation.evaluator]: [0mInference done 2156/8355. 0.1160 s / img. ETA=0:12:13
[32m[04/19 22:44:13 d2.evaluation.evaluator]: [0mInference done 2199/8355. 0.1160 s / img. ETA=0:12:08
[32m[04/19 22:44:18 d2.evaluation.evaluator]: [0mInference done 2242/8355. 0.1160 s / img. ETA=0:12:03
[32m[04/19 22:44:24 d2.evaluation.evaluator]: [0mInference done 2285/8355. 0.1160 s / img. ETA=0:11:58
[32m[04/19 22:44:29 d2.evaluation.evaluator]: [0mInference done 2328/8355. 0.1161 s / img. ETA=0:11:53
[32m[04/19 22:44:34 d2.evaluation.evaluator]: [0mInference done 2371/8355. 0.1160 s / img. ETA=0:11:47
[32m[04/19 22:44:39 d2.evaluation.evaluator]: [0mInference done 2414/8355. 0.1160 s / img. ETA=0:11:42
[32m[04/19 22:44:44 d2.evaluation.evaluator]: [0mInference done 2457/8355. 0.1160 s / img. ETA=0:11:37
[32m[04/19 22:44:49 d2.evaluation.evaluator]: [0mInference done 2500/8355. 0.1160 s / img. ETA=0:11:32
[32m[04/19 22:44:54 d2.evaluation.evaluator]: [0mInference done 2543/8355. 0.1160 s / img. ETA=0:11:27
[32m[04/19 22:44:59 d2.evaluation.evaluator]: [0mInference done 2586/8355. 0.1160 s / img. ETA=0:11:22
[32m[04/19 22:45:04 d2.evaluation.evaluator]: [0mInference done 2629/8355. 0.1160 s / img. ETA=0:11:17
[32m[04/19 22:45:09 d2.evaluation.evaluator]: [0mInference done 2672/8355. 0.1160 s / img. ETA=0:11:12
[32m[04/19 22:45:14 d2.evaluation.evaluator]: [0mInference done 2715/8355. 0.1160 s / img. ETA=0:11:07
[32m[04/19 22:45:20 d2.evaluation.evaluator]: [0mInference done 2758/8355. 0.1161 s / img. ETA=0:11:02
[32m[04/19 22:45:25 d2.evaluation.evaluator]: [0mInference done 2801/8355. 0.1161 s / img. ETA=0:10:57
[32m[04/19 22:45:30 d2.evaluation.evaluator]: [0mInference done 2843/8355. 0.1161 s / img. ETA=0:10:52
[32m[04/19 22:45:35 d2.evaluation.evaluator]: [0mInference done 2886/8355. 0.1161 s / img. ETA=0:10:47
[32m[04/19 22:45:40 d2.evaluation.evaluator]: [0mInference done 2929/8355. 0.1161 s / img. ETA=0:10:42
[32m[04/19 22:45:45 d2.evaluation.evaluator]: [0mInference done 2972/8355. 0.1161 s / img. ETA=0:10:36
[32m[04/19 22:45:50 d2.evaluation.evaluator]: [0mInference done 3015/8355. 0.1161 s / img. ETA=0:10:31
[32m[04/19 22:45:55 d2.evaluation.evaluator]: [0mInference done 3058/8355. 0.1161 s / img. ETA=0:10:26
[32m[04/19 22:46:00 d2.evaluation.evaluator]: [0mInference done 3101/8355. 0.1161 s / img. ETA=0:10:21
[32m[04/19 22:46:05 d2.evaluation.evaluator]: [0mInference done 3144/8355. 0.1161 s / img. ETA=0:10:16
[32m[04/19 22:46:10 d2.evaluation.evaluator]: [0mInference done 3187/8355. 0.1161 s / img. ETA=0:10:11
[32m[04/19 22:46:15 d2.evaluation.evaluator]: [0mInference done 3230/8355. 0.1161 s / img. ETA=0:10:06
[32m[04/19 22:46:21 d2.evaluation.evaluator]: [0mInference done 3273/8355. 0.1161 s / img. ETA=0:10:01
[32m[04/19 22:46:26 d2.evaluation.evaluator]: [0mInference done 3316/8355. 0.1161 s / img. ETA=0:09:56
[32m[04/19 22:46:31 d2.evaluation.evaluator]: [0mInference done 3359/8355. 0.1161 s / img. ETA=0:09:51
[32m[04/19 22:46:36 d2.evaluation.evaluator]: [0mInference done 3402/8355. 0.1161 s / img. ETA=0:09:46
[32m[04/19 22:46:41 d2.evaluation.evaluator]: [0mInference done 3445/8355. 0.1161 s / img. ETA=0:09:41
[32m[04/19 22:46:46 d2.evaluation.evaluator]: [0mInference done 3488/8355. 0.1161 s / img. ETA=0:09:36
[32m[04/19 22:46:51 d2.evaluation.evaluator]: [0mInference done 3531/8355. 0.1161 s / img. ETA=0:09:30
[32m[04/19 22:46:56 d2.evaluation.evaluator]: [0mInference done 3574/8355. 0.1161 s / img. ETA=0:09:25
[32m[04/19 22:47:01 d2.evaluation.evaluator]: [0mInference done 3617/8355. 0.1161 s / img. ETA=0:09:20
[32m[04/19 22:47:06 d2.evaluation.evaluator]: [0mInference done 3660/8355. 0.1161 s / img. ETA=0:09:15
[32m[04/19 22:47:11 d2.evaluation.evaluator]: [0mInference done 3703/8355. 0.1161 s / img. ETA=0:09:10
[32m[04/19 22:47:17 d2.evaluation.evaluator]: [0mInference done 3746/8355. 0.1161 s / img. ETA=0:09:05
[32m[04/19 22:47:22 d2.evaluation.evaluator]: [0mInference done 3789/8355. 0.1161 s / img. ETA=0:09:00
[32m[04/19 22:47:27 d2.evaluation.evaluator]: [0mInference done 3832/8355. 0.1161 s / img. ETA=0:08:55
[32m[04/19 22:47:32 d2.evaluation.evaluator]: [0mInference done 3875/8355. 0.1161 s / img. ETA=0:08:50
[32m[04/19 22:47:37 d2.evaluation.evaluator]: [0mInference done 3918/8355. 0.1161 s / img. ETA=0:08:45
[32m[04/19 22:47:42 d2.evaluation.evaluator]: [0mInference done 3961/8355. 0.1161 s / img. ETA=0:08:40
[32m[04/19 22:47:47 d2.evaluation.evaluator]: [0mInference done 4004/8355. 0.1161 s / img. ETA=0:08:34
[32m[04/19 22:47:52 d2.evaluation.evaluator]: [0mInference done 4047/8355. 0.1161 s / img. ETA=0:08:29
[32m[04/19 22:47:57 d2.evaluation.evaluator]: [0mInference done 4090/8355. 0.1161 s / img. ETA=0:08:24
[32m[04/19 22:48:02 d2.evaluation.evaluator]: [0mInference done 4133/8355. 0.1161 s / img. ETA=0:08:19
[32m[04/19 22:48:08 d2.evaluation.evaluator]: [0mInference done 4176/8355. 0.1161 s / img. ETA=0:08:14
[32m[04/19 22:48:13 d2.evaluation.evaluator]: [0mInference done 4219/8355. 0.1162 s / img. ETA=0:08:09
[32m[04/19 22:48:18 d2.evaluation.evaluator]: [0mInference done 4262/8355. 0.1161 s / img. ETA=0:08:04
[32m[04/19 22:48:23 d2.evaluation.evaluator]: [0mInference done 4305/8355. 0.1161 s / img. ETA=0:07:59
[32m[04/19 22:48:28 d2.evaluation.evaluator]: [0mInference done 4348/8355. 0.1161 s / img. ETA=0:07:54
[32m[04/19 22:48:33 d2.evaluation.evaluator]: [0mInference done 4391/8355. 0.1161 s / img. ETA=0:07:49
[32m[04/19 22:48:38 d2.evaluation.evaluator]: [0mInference done 4434/8355. 0.1161 s / img. ETA=0:07:44
[32m[04/19 22:48:43 d2.evaluation.evaluator]: [0mInference done 4477/8355. 0.1161 s / img. ETA=0:07:39
[32m[04/19 22:48:48 d2.evaluation.evaluator]: [0mInference done 4519/8355. 0.1162 s / img. ETA=0:07:34
[32m[04/19 22:48:53 d2.evaluation.evaluator]: [0mInference done 4561/8355. 0.1162 s / img. ETA=0:07:29
[32m[04/19 22:48:58 d2.evaluation.evaluator]: [0mInference done 4604/8355. 0.1162 s / img. ETA=0:07:24
[32m[04/19 22:49:03 d2.evaluation.evaluator]: [0mInference done 4647/8355. 0.1162 s / img. ETA=0:07:18
[32m[04/19 22:49:08 d2.evaluation.evaluator]: [0mInference done 4690/8355. 0.1162 s / img. ETA=0:07:13
[32m[04/19 22:49:14 d2.evaluation.evaluator]: [0mInference done 4733/8355. 0.1162 s / img. ETA=0:07:08
[32m[04/19 22:49:19 d2.evaluation.evaluator]: [0mInference done 4776/8355. 0.1162 s / img. ETA=0:07:03
[32m[04/19 22:49:24 d2.evaluation.evaluator]: [0mInference done 4819/8355. 0.1162 s / img. ETA=0:06:58
[32m[04/19 22:49:29 d2.evaluation.evaluator]: [0mInference done 4862/8355. 0.1162 s / img. ETA=0:06:53
[32m[04/19 22:49:34 d2.evaluation.evaluator]: [0mInference done 4904/8355. 0.1162 s / img. ETA=0:06:48
[32m[04/19 22:49:39 d2.evaluation.evaluator]: [0mInference done 4947/8355. 0.1162 s / img. ETA=0:06:43
[32m[04/19 22:49:44 d2.evaluation.evaluator]: [0mInference done 4990/8355. 0.1162 s / img. ETA=0:06:38
[32m[04/19 22:49:49 d2.evaluation.evaluator]: [0mInference done 5033/8355. 0.1162 s / img. ETA=0:06:33
[32m[04/19 22:49:54 d2.evaluation.evaluator]: [0mInference done 5076/8355. 0.1162 s / img. ETA=0:06:28
[32m[04/19 22:49:59 d2.evaluation.evaluator]: [0mInference done 5118/8355. 0.1162 s / img. ETA=0:06:23
[32m[04/19 22:50:04 d2.evaluation.evaluator]: [0mInference done 5160/8355. 0.1162 s / img. ETA=0:06:18
[32m[04/19 22:50:09 d2.evaluation.evaluator]: [0mInference done 5203/8355. 0.1162 s / img. ETA=0:06:13
[32m[04/19 22:50:15 d2.evaluation.evaluator]: [0mInference done 5246/8355. 0.1162 s / img. ETA=0:06:08
[32m[04/19 22:50:20 d2.evaluation.evaluator]: [0mInference done 5288/8355. 0.1162 s / img. ETA=0:06:03
[32m[04/19 22:50:25 d2.evaluation.evaluator]: [0mInference done 5330/8355. 0.1162 s / img. ETA=0:05:58
[32m[04/19 22:50:30 d2.evaluation.evaluator]: [0mInference done 5372/8355. 0.1162 s / img. ETA=0:05:53
[32m[04/19 22:50:35 d2.evaluation.evaluator]: [0mInference done 5414/8355. 0.1162 s / img. ETA=0:05:48
[32m[04/19 22:50:40 d2.evaluation.evaluator]: [0mInference done 5457/8355. 0.1163 s / img. ETA=0:05:43
[32m[04/19 22:50:45 d2.evaluation.evaluator]: [0mInference done 5499/8355. 0.1163 s / img. ETA=0:05:38
[32m[04/19 22:50:50 d2.evaluation.evaluator]: [0mInference done 5542/8355. 0.1163 s / img. ETA=0:05:33
[32m[04/19 22:50:55 d2.evaluation.evaluator]: [0mInference done 5585/8355. 0.1163 s / img. ETA=0:05:28
[32m[04/19 22:51:00 d2.evaluation.evaluator]: [0mInference done 5627/8355. 0.1163 s / img. ETA=0:05:23
[32m[04/19 22:51:05 d2.evaluation.evaluator]: [0mInference done 5669/8355. 0.1163 s / img. ETA=0:05:18
[32m[04/19 22:51:10 d2.evaluation.evaluator]: [0mInference done 5711/8355. 0.1163 s / img. ETA=0:05:13
[32m[04/19 22:51:15 d2.evaluation.evaluator]: [0mInference done 5753/8355. 0.1163 s / img. ETA=0:05:08
[32m[04/19 22:51:20 d2.evaluation.evaluator]: [0mInference done 5795/8355. 0.1163 s / img. ETA=0:05:03
[32m[04/19 22:51:25 d2.evaluation.evaluator]: [0mInference done 5837/8355. 0.1163 s / img. ETA=0:04:58
[32m[04/19 22:51:30 d2.evaluation.evaluator]: [0mInference done 5879/8355. 0.1163 s / img. ETA=0:04:53
[32m[04/19 22:51:35 d2.evaluation.evaluator]: [0mInference done 5921/8355. 0.1163 s / img. ETA=0:04:48
[32m[04/19 22:51:40 d2.evaluation.evaluator]: [0mInference done 5963/8355. 0.1163 s / img. ETA=0:04:43
[32m[04/19 22:51:45 d2.evaluation.evaluator]: [0mInference done 6005/8355. 0.1163 s / img. ETA=0:04:38
[32m[04/19 22:51:50 d2.evaluation.evaluator]: [0mInference done 6044/8355. 0.1164 s / img. ETA=0:04:34
[32m[04/19 22:51:55 d2.evaluation.evaluator]: [0mInference done 6086/8355. 0.1164 s / img. ETA=0:04:29
[32m[04/19 22:52:00 d2.evaluation.evaluator]: [0mInference done 6128/8355. 0.1164 s / img. ETA=0:04:24
[32m[04/19 22:52:05 d2.evaluation.evaluator]: [0mInference done 6170/8355. 0.1164 s / img. ETA=0:04:19
[32m[04/19 22:52:11 d2.evaluation.evaluator]: [0mInference done 6212/8355. 0.1164 s / img. ETA=0:04:14
[32m[04/19 22:52:16 d2.evaluation.evaluator]: [0mInference done 6254/8355. 0.1165 s / img. ETA=0:04:09
[32m[04/19 22:52:21 d2.evaluation.evaluator]: [0mInference done 6296/8355. 0.1165 s / img. ETA=0:04:04
[32m[04/19 22:52:26 d2.evaluation.evaluator]: [0mInference done 6338/8355. 0.1165 s / img. ETA=0:03:59
[32m[04/19 22:52:31 d2.evaluation.evaluator]: [0mInference done 6380/8355. 0.1165 s / img. ETA=0:03:54
[32m[04/19 22:52:36 d2.evaluation.evaluator]: [0mInference done 6422/8355. 0.1165 s / img. ETA=0:03:49
[32m[04/19 22:52:41 d2.evaluation.evaluator]: [0mInference done 6464/8355. 0.1165 s / img. ETA=0:03:44
[32m[04/19 22:52:46 d2.evaluation.evaluator]: [0mInference done 6506/8355. 0.1165 s / img. ETA=0:03:39
[32m[04/19 22:52:51 d2.evaluation.evaluator]: [0mInference done 6549/8355. 0.1165 s / img. ETA=0:03:34
[32m[04/19 22:52:56 d2.evaluation.evaluator]: [0mInference done 6592/8355. 0.1165 s / img. ETA=0:03:29
[32m[04/19 22:53:01 d2.evaluation.evaluator]: [0mInference done 6635/8355. 0.1165 s / img. ETA=0:03:24
[32m[04/19 22:53:06 d2.evaluation.evaluator]: [0mInference done 6678/8355. 0.1165 s / img. ETA=0:03:19
[32m[04/19 22:53:11 d2.evaluation.evaluator]: [0mInference done 6721/8355. 0.1165 s / img. ETA=0:03:14
[32m[04/19 22:53:16 d2.evaluation.evaluator]: [0mInference done 6764/8355. 0.1165 s / img. ETA=0:03:08
[32m[04/19 22:53:21 d2.evaluation.evaluator]: [0mInference done 6806/8355. 0.1165 s / img. ETA=0:03:03
[32m[04/19 22:53:26 d2.evaluation.evaluator]: [0mInference done 6848/8355. 0.1165 s / img. ETA=0:02:58
[32m[04/19 22:53:31 d2.evaluation.evaluator]: [0mInference done 6890/8355. 0.1165 s / img. ETA=0:02:53
[32m[04/19 22:53:36 d2.evaluation.evaluator]: [0mInference done 6932/8355. 0.1165 s / img. ETA=0:02:48
[32m[04/19 22:53:41 d2.evaluation.evaluator]: [0mInference done 6974/8355. 0.1165 s / img. ETA=0:02:44
[32m[04/19 22:53:46 d2.evaluation.evaluator]: [0mInference done 7016/8355. 0.1165 s / img. ETA=0:02:39
[32m[04/19 22:53:51 d2.evaluation.evaluator]: [0mInference done 7058/8355. 0.1165 s / img. ETA=0:02:34
[32m[04/19 22:53:57 d2.evaluation.evaluator]: [0mInference done 7100/8355. 0.1165 s / img. ETA=0:02:29
[32m[04/19 22:54:02 d2.evaluation.evaluator]: [0mInference done 7142/8355. 0.1165 s / img. ETA=0:02:24
[32m[04/19 22:54:07 d2.evaluation.evaluator]: [0mInference done 7184/8355. 0.1165 s / img. ETA=0:02:19
[32m[04/19 22:54:12 d2.evaluation.evaluator]: [0mInference done 7226/8355. 0.1166 s / img. ETA=0:02:14
[32m[04/19 22:54:17 d2.evaluation.evaluator]: [0mInference done 7268/8355. 0.1166 s / img. ETA=0:02:09
[32m[04/19 22:54:22 d2.evaluation.evaluator]: [0mInference done 7310/8355. 0.1166 s / img. ETA=0:02:04
[32m[04/19 22:54:27 d2.evaluation.evaluator]: [0mInference done 7352/8355. 0.1166 s / img. ETA=0:01:59
[32m[04/19 22:54:32 d2.evaluation.evaluator]: [0mInference done 7394/8355. 0.1166 s / img. ETA=0:01:54
[32m[04/19 22:54:37 d2.evaluation.evaluator]: [0mInference done 7436/8355. 0.1166 s / img. ETA=0:01:49
[32m[04/19 22:54:42 d2.evaluation.evaluator]: [0mInference done 7478/8355. 0.1166 s / img. ETA=0:01:44
[32m[04/19 22:54:47 d2.evaluation.evaluator]: [0mInference done 7520/8355. 0.1166 s / img. ETA=0:01:39
[32m[04/19 22:54:52 d2.evaluation.evaluator]: [0mInference done 7562/8355. 0.1166 s / img. ETA=0:01:34
[32m[04/19 22:54:57 d2.evaluation.evaluator]: [0mInference done 7605/8355. 0.1166 s / img. ETA=0:01:29
[32m[04/19 22:55:02 d2.evaluation.evaluator]: [0mInference done 7647/8355. 0.1166 s / img. ETA=0:01:24
[32m[04/19 22:55:07 d2.evaluation.evaluator]: [0mInference done 7689/8355. 0.1166 s / img. ETA=0:01:19
[32m[04/19 22:55:12 d2.evaluation.evaluator]: [0mInference done 7731/8355. 0.1166 s / img. ETA=0:01:14
[32m[04/19 22:55:17 d2.evaluation.evaluator]: [0mInference done 7773/8355. 0.1166 s / img. ETA=0:01:09
[32m[04/19 22:55:22 d2.evaluation.evaluator]: [0mInference done 7815/8355. 0.1166 s / img. ETA=0:01:04
[32m[04/19 22:55:27 d2.evaluation.evaluator]: [0mInference done 7857/8355. 0.1166 s / img. ETA=0:00:59
[32m[04/19 22:55:32 d2.evaluation.evaluator]: [0mInference done 7899/8355. 0.1167 s / img. ETA=0:00:54
[32m[04/19 22:55:37 d2.evaluation.evaluator]: [0mInference done 7941/8355. 0.1167 s / img. ETA=0:00:49
[32m[04/19 22:55:42 d2.evaluation.evaluator]: [0mInference done 7983/8355. 0.1167 s / img. ETA=0:00:44
[32m[04/19 22:55:47 d2.evaluation.evaluator]: [0mInference done 8025/8355. 0.1167 s / img. ETA=0:00:39
[32m[04/19 22:55:52 d2.evaluation.evaluator]: [0mInference done 8067/8355. 0.1167 s / img. ETA=0:00:34
[32m[04/19 22:55:58 d2.evaluation.evaluator]: [0mInference done 8110/8355. 0.1167 s / img. ETA=0:00:29
[32m[04/19 22:56:03 d2.evaluation.evaluator]: [0mInference done 8153/8355. 0.1167 s / img. ETA=0:00:24
[32m[04/19 22:56:08 d2.evaluation.evaluator]: [0mInference done 8196/8355. 0.1167 s / img. ETA=0:00:18
[32m[04/19 22:56:13 d2.evaluation.evaluator]: [0mInference done 8238/8355. 0.1167 s / img. ETA=0:00:13
[32m[04/19 22:56:18 d2.evaluation.evaluator]: [0mInference done 8280/8355. 0.1167 s / img. ETA=0:00:08
[32m[04/19 22:56:23 d2.evaluation.evaluator]: [0mInference done 8322/8355. 0.1167 s / img. ETA=0:00:03
[32m[04/19 22:56:27 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:32.914779 (0.118912 s / img per device, on 1 devices)
[32m[04/19 22:56:27 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:14 (0.116668 s / img per device, on 1 devices)
[32m[04/19 22:56:27 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/19 22:56:27 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/19 22:56:27 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=17.97s).
Accumulating evaluation results...
DONE (t=2.11s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.150
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.300
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.132
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.094
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.218
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.425
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.060
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.178
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.183
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.126
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.256
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.470
[32m[04/19 22:56:47 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 15.047 | 30.044 | 13.227 | 9.401 | 21.767 | 42.458 |
[32m[04/19 22:56:47 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 26.796 | bicycle       | 1.794 | car            | 30.606 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | 0.990 | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    |               |       |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/19 22:56:49 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 22:56:49 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[32m[04/19 22:56:49 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/19 22:56:50 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1167 s / img. ETA=0:02:27
[32m[04/19 22:56:55 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1165 s / img. ETA=0:02:22
[32m[04/19 22:57:00 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1164 s / img. ETA=0:02:17
[32m[04/19 22:57:06 d2.evaluation.evaluator]: [0mInference done 140/1257. 0.1165 s / img. ETA=0:02:12
[32m[04/19 22:57:11 d2.evaluation.evaluator]: [0mInference done 183/1257. 0.1164 s / img. ETA=0:02:07
[32m[04/19 22:57:16 d2.evaluation.evaluator]: [0mInference done 226/1257. 0.1164 s / img. ETA=0:02:02
[32m[04/19 22:57:21 d2.evaluation.evaluator]: [0mInference done 269/1257. 0.1164 s / img. ETA=0:01:57
[32m[04/19 22:57:26 d2.evaluation.evaluator]: [0mInference done 312/1257. 0.1164 s / img. ETA=0:01:52
[32m[04/19 22:57:31 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1164 s / img. ETA=0:01:47
[32m[04/19 22:57:36 d2.evaluation.evaluator]: [0mInference done 398/1257. 0.1164 s / img. ETA=0:01:41
[32m[04/19 22:57:41 d2.evaluation.evaluator]: [0mInference done 441/1257. 0.1164 s / img. ETA=0:01:36
[32m[04/19 22:57:46 d2.evaluation.evaluator]: [0mInference done 483/1257. 0.1165 s / img. ETA=0:01:31
[32m[04/19 22:57:51 d2.evaluation.evaluator]: [0mInference done 525/1257. 0.1165 s / img. ETA=0:01:26
[32m[04/19 22:57:56 d2.evaluation.evaluator]: [0mInference done 567/1257. 0.1166 s / img. ETA=0:01:21
[32m[04/19 22:58:01 d2.evaluation.evaluator]: [0mInference done 609/1257. 0.1166 s / img. ETA=0:01:17
[32m[04/19 22:58:06 d2.evaluation.evaluator]: [0mInference done 651/1257. 0.1166 s / img. ETA=0:01:12
[32m[04/19 22:58:11 d2.evaluation.evaluator]: [0mInference done 693/1257. 0.1167 s / img. ETA=0:01:07
[32m[04/19 22:58:16 d2.evaluation.evaluator]: [0mInference done 735/1257. 0.1167 s / img. ETA=0:01:02
[32m[04/19 22:58:21 d2.evaluation.evaluator]: [0mInference done 778/1257. 0.1167 s / img. ETA=0:00:56
[32m[04/19 22:58:27 d2.evaluation.evaluator]: [0mInference done 820/1257. 0.1167 s / img. ETA=0:00:51
[32m[04/19 22:58:32 d2.evaluation.evaluator]: [0mInference done 863/1257. 0.1167 s / img. ETA=0:00:46
[32m[04/19 22:58:37 d2.evaluation.evaluator]: [0mInference done 906/1257. 0.1167 s / img. ETA=0:00:41
[32m[04/19 22:58:42 d2.evaluation.evaluator]: [0mInference done 948/1257. 0.1167 s / img. ETA=0:00:36
[32m[04/19 22:58:47 d2.evaluation.evaluator]: [0mInference done 990/1257. 0.1167 s / img. ETA=0:00:31
[32m[04/19 22:58:52 d2.evaluation.evaluator]: [0mInference done 1033/1257. 0.1167 s / img. ETA=0:00:26
[32m[04/19 22:58:57 d2.evaluation.evaluator]: [0mInference done 1076/1257. 0.1167 s / img. ETA=0:00:21
[32m[04/19 22:59:02 d2.evaluation.evaluator]: [0mInference done 1119/1257. 0.1167 s / img. ETA=0:00:16
[32m[04/19 22:59:07 d2.evaluation.evaluator]: [0mInference done 1162/1257. 0.1167 s / img. ETA=0:00:11
[32m[04/19 22:59:12 d2.evaluation.evaluator]: [0mInference done 1205/1257. 0.1167 s / img. ETA=0:00:06
[32m[04/19 22:59:17 d2.evaluation.evaluator]: [0mInference done 1248/1257. 0.1167 s / img. ETA=0:00:01
[32m[04/19 22:59:19 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:29.004774 (0.119013 s / img per device, on 1 devices)
[32m[04/19 22:59:19 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:26 (0.116692 s / img per device, on 1 devices)
[32m[04/19 22:59:19 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/19 22:59:19 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/19 22:59:19 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.57s).
Accumulating evaluation results...
DONE (t=0.33s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.140
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.283
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.122
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.170
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.062
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.171
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.172
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.205
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.394
[32m[04/19 22:59:22 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 13.995 | 28.256 | 12.200 | 8.210 | 16.962 | 35.801 |
[32m[04/19 22:59:22 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 23.080 | bicycle       | 0.792 | car            | 32.109 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | 0.000 | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  3  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/19 22:59:22 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/19 22:59:23 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 22:59:23 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/19 22:59:23 d2.data.build]: [0mRemoved 889 images with no usable annotations. 7466 images left.
[32m[04/19 22:59:23 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/19 22:59:23 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/19 22:59:24 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/19 22:59:34 d2.utils.events]: [0m eta: 0:08:39  iter: 19  total_loss: 0.857  loss_cls: 0.299  loss_box_reg: 0.430  loss_rpn_cls: 0.038  loss_rpn_loc: 0.074  time: 0.5298  data_time: 0.0176  lr: 0.000100  max_mem: 3094M
[32m[04/19 22:59:45 d2.utils.events]: [0m eta: 0:08:35  iter: 39  total_loss: 0.716  loss_cls: 0.267  loss_box_reg: 0.367  loss_rpn_cls: 0.031  loss_rpn_loc: 0.078  time: 0.5318  data_time: 0.0048  lr: 0.000200  max_mem: 3094M
[32m[04/19 22:59:55 d2.utils.events]: [0m eta: 0:08:08  iter: 59  total_loss: 0.832  loss_cls: 0.280  loss_box_reg: 0.390  loss_rpn_cls: 0.030  loss_rpn_loc: 0.069  time: 0.5221  data_time: 0.0048  lr: 0.000300  max_mem: 3094M
[32m[04/19 23:00:06 d2.utils.events]: [0m eta: 0:07:58  iter: 79  total_loss: 0.808  loss_cls: 0.264  loss_box_reg: 0.449  loss_rpn_cls: 0.035  loss_rpn_loc: 0.054  time: 0.5224  data_time: 0.0047  lr: 0.000400  max_mem: 3094M
[32m[04/19 23:00:16 d2.utils.events]: [0m eta: 0:07:45  iter: 99  total_loss: 0.768  loss_cls: 0.288  loss_box_reg: 0.406  loss_rpn_cls: 0.031  loss_rpn_loc: 0.061  time: 0.5188  data_time: 0.0050  lr: 0.000500  max_mem: 3094M
[32m[04/19 23:00:26 d2.utils.events]: [0m eta: 0:07:37  iter: 119  total_loss: 0.724  loss_cls: 0.236  loss_box_reg: 0.371  loss_rpn_cls: 0.030  loss_rpn_loc: 0.059  time: 0.5205  data_time: 0.0047  lr: 0.000599  max_mem: 3094M
[32m[04/19 23:00:37 d2.utils.events]: [0m eta: 0:07:29  iter: 139  total_loss: 0.640  loss_cls: 0.222  loss_box_reg: 0.317  loss_rpn_cls: 0.032  loss_rpn_loc: 0.043  time: 0.5214  data_time: 0.0051  lr: 0.000699  max_mem: 3094M
[32m[04/19 23:00:48 d2.utils.events]: [0m eta: 0:07:20  iter: 159  total_loss: 0.659  loss_cls: 0.227  loss_box_reg: 0.350  loss_rpn_cls: 0.031  loss_rpn_loc: 0.045  time: 0.5224  data_time: 0.0049  lr: 0.000799  max_mem: 3094M
[32m[04/19 23:00:58 d2.utils.events]: [0m eta: 0:07:10  iter: 179  total_loss: 0.647  loss_cls: 0.231  loss_box_reg: 0.321  loss_rpn_cls: 0.033  loss_rpn_loc: 0.046  time: 0.5225  data_time: 0.0048  lr: 0.000899  max_mem: 3094M
[32m[04/19 23:01:08 d2.utils.events]: [0m eta: 0:06:59  iter: 199  total_loss: 0.555  loss_cls: 0.189  loss_box_reg: 0.301  loss_rpn_cls: 0.027  loss_rpn_loc: 0.062  time: 0.5208  data_time: 0.0049  lr: 0.000999  max_mem: 3094M
[32m[04/19 23:01:19 d2.utils.events]: [0m eta: 0:06:49  iter: 219  total_loss: 0.776  loss_cls: 0.263  loss_box_reg: 0.397  loss_rpn_cls: 0.031  loss_rpn_loc: 0.058  time: 0.5222  data_time: 0.0050  lr: 0.001099  max_mem: 3094M
[32m[04/19 23:01:29 d2.utils.events]: [0m eta: 0:06:38  iter: 239  total_loss: 0.845  loss_cls: 0.275  loss_box_reg: 0.415  loss_rpn_cls: 0.034  loss_rpn_loc: 0.072  time: 0.5213  data_time: 0.0049  lr: 0.001199  max_mem: 3094M
[32m[04/19 23:01:40 d2.utils.events]: [0m eta: 0:06:27  iter: 259  total_loss: 0.771  loss_cls: 0.277  loss_box_reg: 0.408  loss_rpn_cls: 0.031  loss_rpn_loc: 0.069  time: 0.5212  data_time: 0.0048  lr: 0.001299  max_mem: 3094M
[32m[04/19 23:01:50 d2.utils.events]: [0m eta: 0:06:17  iter: 279  total_loss: 0.773  loss_cls: 0.264  loss_box_reg: 0.397  loss_rpn_cls: 0.029  loss_rpn_loc: 0.059  time: 0.5208  data_time: 0.0051  lr: 0.001399  max_mem: 3094M
[32m[04/19 23:02:01 d2.utils.events]: [0m eta: 0:06:07  iter: 299  total_loss: 0.826  loss_cls: 0.275  loss_box_reg: 0.429  loss_rpn_cls: 0.025  loss_rpn_loc: 0.058  time: 0.5209  data_time: 0.0049  lr: 0.001499  max_mem: 3094M
[32m[04/19 23:02:11 d2.utils.events]: [0m eta: 0:05:57  iter: 319  total_loss: 0.681  loss_cls: 0.238  loss_box_reg: 0.337  loss_rpn_cls: 0.030  loss_rpn_loc: 0.064  time: 0.5210  data_time: 0.0049  lr: 0.001598  max_mem: 3094M
[32m[04/19 23:02:22 d2.utils.events]: [0m eta: 0:05:46  iter: 339  total_loss: 0.620  loss_cls: 0.197  loss_box_reg: 0.328  loss_rpn_cls: 0.035  loss_rpn_loc: 0.054  time: 0.5208  data_time: 0.0047  lr: 0.001698  max_mem: 3094M
[32m[04/19 23:02:32 d2.utils.events]: [0m eta: 0:05:35  iter: 359  total_loss: 0.690  loss_cls: 0.216  loss_box_reg: 0.358  loss_rpn_cls: 0.036  loss_rpn_loc: 0.055  time: 0.5204  data_time: 0.0048  lr: 0.001798  max_mem: 3094M
[32m[04/19 23:02:43 d2.utils.events]: [0m eta: 0:05:25  iter: 379  total_loss: 0.780  loss_cls: 0.240  loss_box_reg: 0.373  loss_rpn_cls: 0.028  loss_rpn_loc: 0.068  time: 0.5205  data_time: 0.0049  lr: 0.001898  max_mem: 3094M
[32m[04/19 23:02:53 d2.utils.events]: [0m eta: 0:05:15  iter: 399  total_loss: 0.813  loss_cls: 0.264  loss_box_reg: 0.374  loss_rpn_cls: 0.030  loss_rpn_loc: 0.072  time: 0.5212  data_time: 0.0047  lr: 0.001998  max_mem: 3094M
[32m[04/19 23:03:04 d2.utils.events]: [0m eta: 0:05:04  iter: 419  total_loss: 0.745  loss_cls: 0.246  loss_box_reg: 0.381  loss_rpn_cls: 0.027  loss_rpn_loc: 0.067  time: 0.5210  data_time: 0.0045  lr: 0.002098  max_mem: 3094M
[32m[04/19 23:03:14 d2.utils.events]: [0m eta: 0:04:53  iter: 439  total_loss: 0.674  loss_cls: 0.236  loss_box_reg: 0.300  loss_rpn_cls: 0.033  loss_rpn_loc: 0.061  time: 0.5201  data_time: 0.0046  lr: 0.002198  max_mem: 3094M
[32m[04/19 23:03:24 d2.utils.events]: [0m eta: 0:04:42  iter: 459  total_loss: 0.744  loss_cls: 0.223  loss_box_reg: 0.375  loss_rpn_cls: 0.033  loss_rpn_loc: 0.077  time: 0.5202  data_time: 0.0052  lr: 0.002298  max_mem: 3094M
[32m[04/19 23:03:35 d2.utils.events]: [0m eta: 0:04:32  iter: 479  total_loss: 0.718  loss_cls: 0.259  loss_box_reg: 0.358  loss_rpn_cls: 0.023  loss_rpn_loc: 0.069  time: 0.5197  data_time: 0.0048  lr: 0.002398  max_mem: 3094M
[32m[04/19 23:03:45 d2.utils.events]: [0m eta: 0:04:21  iter: 499  total_loss: 0.658  loss_cls: 0.227  loss_box_reg: 0.354  loss_rpn_cls: 0.031  loss_rpn_loc: 0.054  time: 0.5198  data_time: 0.0047  lr: 0.002498  max_mem: 3094M
[32m[04/19 23:03:55 d2.utils.events]: [0m eta: 0:04:10  iter: 519  total_loss: 0.840  loss_cls: 0.269  loss_box_reg: 0.406  loss_rpn_cls: 0.033  loss_rpn_loc: 0.088  time: 0.5193  data_time: 0.0047  lr: 0.002597  max_mem: 3094M
[32m[04/19 23:04:05 d2.utils.events]: [0m eta: 0:04:00  iter: 539  total_loss: 0.713  loss_cls: 0.234  loss_box_reg: 0.337  loss_rpn_cls: 0.032  loss_rpn_loc: 0.072  time: 0.5189  data_time: 0.0049  lr: 0.002697  max_mem: 3094M
[32m[04/19 23:04:16 d2.utils.events]: [0m eta: 0:03:50  iter: 559  total_loss: 0.720  loss_cls: 0.258  loss_box_reg: 0.369  loss_rpn_cls: 0.025  loss_rpn_loc: 0.068  time: 0.5191  data_time: 0.0047  lr: 0.002797  max_mem: 3094M
[32m[04/19 23:04:26 d2.utils.events]: [0m eta: 0:03:38  iter: 579  total_loss: 0.669  loss_cls: 0.236  loss_box_reg: 0.330  loss_rpn_cls: 0.027  loss_rpn_loc: 0.047  time: 0.5183  data_time: 0.0045  lr: 0.002897  max_mem: 3094M
[32m[04/19 23:04:37 d2.utils.events]: [0m eta: 0:03:28  iter: 599  total_loss: 0.629  loss_cls: 0.232  loss_box_reg: 0.333  loss_rpn_cls: 0.028  loss_rpn_loc: 0.049  time: 0.5187  data_time: 0.0047  lr: 0.002997  max_mem: 3094M
[32m[04/19 23:04:47 d2.utils.events]: [0m eta: 0:03:18  iter: 619  total_loss: 0.772  loss_cls: 0.258  loss_box_reg: 0.420  loss_rpn_cls: 0.028  loss_rpn_loc: 0.058  time: 0.5186  data_time: 0.0049  lr: 0.003097  max_mem: 3094M
[32m[04/19 23:04:57 d2.utils.events]: [0m eta: 0:03:07  iter: 639  total_loss: 0.734  loss_cls: 0.255  loss_box_reg: 0.365  loss_rpn_cls: 0.036  loss_rpn_loc: 0.066  time: 0.5186  data_time: 0.0048  lr: 0.003197  max_mem: 3094M
[32m[04/19 23:05:08 d2.utils.events]: [0m eta: 0:02:57  iter: 659  total_loss: 0.642  loss_cls: 0.225  loss_box_reg: 0.357  loss_rpn_cls: 0.027  loss_rpn_loc: 0.058  time: 0.5188  data_time: 0.0048  lr: 0.003297  max_mem: 3094M
[32m[04/19 23:05:19 d2.utils.events]: [0m eta: 0:02:47  iter: 679  total_loss: 0.748  loss_cls: 0.248  loss_box_reg: 0.404  loss_rpn_cls: 0.029  loss_rpn_loc: 0.057  time: 0.5192  data_time: 0.0049  lr: 0.003397  max_mem: 3094M
[32m[04/19 23:05:29 d2.utils.events]: [0m eta: 0:02:36  iter: 699  total_loss: 0.643  loss_cls: 0.228  loss_box_reg: 0.343  loss_rpn_cls: 0.026  loss_rpn_loc: 0.055  time: 0.5189  data_time: 0.0051  lr: 0.003497  max_mem: 3094M
[32m[04/19 23:05:39 d2.utils.events]: [0m eta: 0:02:26  iter: 719  total_loss: 0.529  loss_cls: 0.201  loss_box_reg: 0.291  loss_rpn_cls: 0.021  loss_rpn_loc: 0.033  time: 0.5191  data_time: 0.0047  lr: 0.003596  max_mem: 3094M
[32m[04/19 23:05:50 d2.utils.events]: [0m eta: 0:02:15  iter: 739  total_loss: 0.733  loss_cls: 0.237  loss_box_reg: 0.374  loss_rpn_cls: 0.025  loss_rpn_loc: 0.060  time: 0.5190  data_time: 0.0050  lr: 0.003696  max_mem: 3094M
[32m[04/19 23:06:00 d2.utils.events]: [0m eta: 0:02:05  iter: 759  total_loss: 0.542  loss_cls: 0.200  loss_box_reg: 0.281  loss_rpn_cls: 0.030  loss_rpn_loc: 0.034  time: 0.5188  data_time: 0.0048  lr: 0.003796  max_mem: 3094M
[32m[04/19 23:06:11 d2.utils.events]: [0m eta: 0:01:55  iter: 779  total_loss: 0.793  loss_cls: 0.261  loss_box_reg: 0.431  loss_rpn_cls: 0.032  loss_rpn_loc: 0.057  time: 0.5192  data_time: 0.0048  lr: 0.003896  max_mem: 3094M
[32m[04/19 23:06:21 d2.utils.events]: [0m eta: 0:01:44  iter: 799  total_loss: 0.892  loss_cls: 0.279  loss_box_reg: 0.459  loss_rpn_cls: 0.035  loss_rpn_loc: 0.089  time: 0.5193  data_time: 0.0050  lr: 0.003996  max_mem: 3094M
[32m[04/19 23:06:32 d2.utils.events]: [0m eta: 0:01:34  iter: 819  total_loss: 0.644  loss_cls: 0.217  loss_box_reg: 0.362  loss_rpn_cls: 0.028  loss_rpn_loc: 0.044  time: 0.5194  data_time: 0.0048  lr: 0.004096  max_mem: 3094M
[32m[04/19 23:06:42 d2.utils.events]: [0m eta: 0:01:23  iter: 839  total_loss: 0.748  loss_cls: 0.247  loss_box_reg: 0.367  loss_rpn_cls: 0.031  loss_rpn_loc: 0.059  time: 0.5190  data_time: 0.0046  lr: 0.004196  max_mem: 3094M
[32m[04/19 23:06:52 d2.utils.events]: [0m eta: 0:01:13  iter: 859  total_loss: 0.612  loss_cls: 0.205  loss_box_reg: 0.264  loss_rpn_cls: 0.035  loss_rpn_loc: 0.054  time: 0.5191  data_time: 0.0050  lr: 0.004296  max_mem: 3094M
[32m[04/19 23:07:03 d2.utils.events]: [0m eta: 0:01:02  iter: 879  total_loss: 0.716  loss_cls: 0.263  loss_box_reg: 0.378  loss_rpn_cls: 0.047  loss_rpn_loc: 0.066  time: 0.5189  data_time: 0.0053  lr: 0.004396  max_mem: 3094M
[32m[04/19 23:07:13 d2.utils.events]: [0m eta: 0:00:52  iter: 899  total_loss: 0.662  loss_cls: 0.200  loss_box_reg: 0.321  loss_rpn_cls: 0.043  loss_rpn_loc: 0.063  time: 0.5183  data_time: 0.0046  lr: 0.004496  max_mem: 3094M
[32m[04/19 23:07:23 d2.utils.events]: [0m eta: 0:00:42  iter: 919  total_loss: 0.704  loss_cls: 0.276  loss_box_reg: 0.350  loss_rpn_cls: 0.040  loss_rpn_loc: 0.079  time: 0.5182  data_time: 0.0050  lr: 0.004595  max_mem: 3094M
[32m[04/19 23:07:33 d2.utils.events]: [0m eta: 0:00:31  iter: 939  total_loss: 0.579  loss_cls: 0.218  loss_box_reg: 0.286  loss_rpn_cls: 0.032  loss_rpn_loc: 0.050  time: 0.5182  data_time: 0.0049  lr: 0.004695  max_mem: 3094M
[32m[04/19 23:07:44 d2.utils.events]: [0m eta: 0:00:21  iter: 959  total_loss: 0.845  loss_cls: 0.276  loss_box_reg: 0.447  loss_rpn_cls: 0.043  loss_rpn_loc: 0.081  time: 0.5185  data_time: 0.0049  lr: 0.004795  max_mem: 3094M
[32m[04/19 23:07:55 d2.utils.events]: [0m eta: 0:00:10  iter: 979  total_loss: 0.637  loss_cls: 0.206  loss_box_reg: 0.318  loss_rpn_cls: 0.034  loss_rpn_loc: 0.064  time: 0.5186  data_time: 0.0051  lr: 0.004895  max_mem: 3094M
[5m[31mWARNING[0m [32m[04/19 23:08:12 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 23:08:12 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[5m[31mWARNING[0m [32m[04/19 23:08:12 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/19 23:08:12 d2.utils.events]: [0m eta: 0:00:00  iter: 999  total_loss: 0.726  loss_cls: 0.239  loss_box_reg: 0.346  loss_rpn_cls: 0.038  loss_rpn_loc: 0.057  time: 0.5188  data_time: 0.0048  lr: 0.004995  max_mem: 3094M
[32m[04/19 23:08:14 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:08:37 (0.5193 s / it)
[32m[04/19 23:08:14 d2.engine.hooks]: [0mTotal training time: 0:08:49 (0:00:11 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/19 23:08:19 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 23:08:20 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/19 23:08:20 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/19 23:08:22 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1173 s / img. ETA=0:16:35
[32m[04/19 23:08:27 d2.evaluation.evaluator]: [0mInference done 54/8355. 0.1163 s / img. ETA=0:16:26
[32m[04/19 23:08:32 d2.evaluation.evaluator]: [0mInference done 97/8355. 0.1160 s / img. ETA=0:16:17
[32m[04/19 23:08:37 d2.evaluation.evaluator]: [0mInference done 140/8355. 0.1160 s / img. ETA=0:16:11
[32m[04/19 23:08:42 d2.evaluation.evaluator]: [0mInference done 183/8355. 0.1160 s / img. ETA=0:16:07
[32m[04/19 23:08:47 d2.evaluation.evaluator]: [0mInference done 226/8355. 0.1160 s / img. ETA=0:16:02
[32m[04/19 23:08:52 d2.evaluation.evaluator]: [0mInference done 268/8355. 0.1160 s / img. ETA=0:16:00
[32m[04/19 23:08:57 d2.evaluation.evaluator]: [0mInference done 311/8355. 0.1160 s / img. ETA=0:15:55
[32m[04/19 23:09:02 d2.evaluation.evaluator]: [0mInference done 354/8355. 0.1161 s / img. ETA=0:15:50
[32m[04/19 23:09:07 d2.evaluation.evaluator]: [0mInference done 395/8355. 0.1161 s / img. ETA=0:15:48
[32m[04/19 23:09:12 d2.evaluation.evaluator]: [0mInference done 438/8355. 0.1161 s / img. ETA=0:15:43
[32m[04/19 23:09:18 d2.evaluation.evaluator]: [0mInference done 481/8355. 0.1161 s / img. ETA=0:15:37
[32m[04/19 23:09:23 d2.evaluation.evaluator]: [0mInference done 523/8355. 0.1161 s / img. ETA=0:15:33
[32m[04/19 23:09:28 d2.evaluation.evaluator]: [0mInference done 566/8355. 0.1161 s / img. ETA=0:15:28
[32m[04/19 23:09:33 d2.evaluation.evaluator]: [0mInference done 609/8355. 0.1161 s / img. ETA=0:15:22
[32m[04/19 23:09:38 d2.evaluation.evaluator]: [0mInference done 651/8355. 0.1161 s / img. ETA=0:15:17
[32m[04/19 23:09:43 d2.evaluation.evaluator]: [0mInference done 693/8355. 0.1161 s / img. ETA=0:15:12
[32m[04/19 23:09:48 d2.evaluation.evaluator]: [0mInference done 735/8355. 0.1161 s / img. ETA=0:15:07
[32m[04/19 23:09:53 d2.evaluation.evaluator]: [0mInference done 778/8355. 0.1161 s / img. ETA=0:15:02
[32m[04/19 23:09:58 d2.evaluation.evaluator]: [0mInference done 820/8355. 0.1162 s / img. ETA=0:14:57
[32m[04/19 23:10:03 d2.evaluation.evaluator]: [0mInference done 863/8355. 0.1162 s / img. ETA=0:14:52
[32m[04/19 23:10:08 d2.evaluation.evaluator]: [0mInference done 903/8355. 0.1162 s / img. ETA=0:14:49
[32m[04/19 23:10:13 d2.evaluation.evaluator]: [0mInference done 946/8355. 0.1162 s / img. ETA=0:14:44
[32m[04/19 23:10:18 d2.evaluation.evaluator]: [0mInference done 989/8355. 0.1162 s / img. ETA=0:14:38
[32m[04/19 23:10:23 d2.evaluation.evaluator]: [0mInference done 1032/8355. 0.1162 s / img. ETA=0:14:33
[32m[04/19 23:10:28 d2.evaluation.evaluator]: [0mInference done 1075/8355. 0.1162 s / img. ETA=0:14:27
[32m[04/19 23:10:34 d2.evaluation.evaluator]: [0mInference done 1118/8355. 0.1162 s / img. ETA=0:14:22
[32m[04/19 23:10:39 d2.evaluation.evaluator]: [0mInference done 1161/8355. 0.1161 s / img. ETA=0:14:17
[32m[04/19 23:10:44 d2.evaluation.evaluator]: [0mInference done 1204/8355. 0.1161 s / img. ETA=0:14:11
[32m[04/19 23:10:49 d2.evaluation.evaluator]: [0mInference done 1247/8355. 0.1161 s / img. ETA=0:14:06
[32m[04/19 23:10:54 d2.evaluation.evaluator]: [0mInference done 1290/8355. 0.1161 s / img. ETA=0:14:01
[32m[04/19 23:10:59 d2.evaluation.evaluator]: [0mInference done 1333/8355. 0.1161 s / img. ETA=0:13:55
[32m[04/19 23:11:04 d2.evaluation.evaluator]: [0mInference done 1376/8355. 0.1161 s / img. ETA=0:13:50
[32m[04/19 23:11:09 d2.evaluation.evaluator]: [0mInference done 1419/8355. 0.1161 s / img. ETA=0:13:45
[32m[04/19 23:11:14 d2.evaluation.evaluator]: [0mInference done 1462/8355. 0.1161 s / img. ETA=0:13:40
[32m[04/19 23:11:19 d2.evaluation.evaluator]: [0mInference done 1504/8355. 0.1162 s / img. ETA=0:13:35
[32m[04/19 23:11:24 d2.evaluation.evaluator]: [0mInference done 1546/8355. 0.1162 s / img. ETA=0:13:30
[32m[04/19 23:11:29 d2.evaluation.evaluator]: [0mInference done 1588/8355. 0.1162 s / img. ETA=0:13:25
[32m[04/19 23:11:34 d2.evaluation.evaluator]: [0mInference done 1629/8355. 0.1163 s / img. ETA=0:13:21
[32m[04/19 23:11:39 d2.evaluation.evaluator]: [0mInference done 1671/8355. 0.1163 s / img. ETA=0:13:16
[32m[04/19 23:11:44 d2.evaluation.evaluator]: [0mInference done 1713/8355. 0.1163 s / img. ETA=0:13:11
[32m[04/19 23:11:49 d2.evaluation.evaluator]: [0mInference done 1755/8355. 0.1163 s / img. ETA=0:13:06
[32m[04/19 23:11:55 d2.evaluation.evaluator]: [0mInference done 1797/8355. 0.1163 s / img. ETA=0:13:01
[32m[04/19 23:12:00 d2.evaluation.evaluator]: [0mInference done 1839/8355. 0.1163 s / img. ETA=0:12:56
[32m[04/19 23:12:05 d2.evaluation.evaluator]: [0mInference done 1881/8355. 0.1164 s / img. ETA=0:12:52
[32m[04/19 23:12:10 d2.evaluation.evaluator]: [0mInference done 1923/8355. 0.1164 s / img. ETA=0:12:47
[32m[04/19 23:12:15 d2.evaluation.evaluator]: [0mInference done 1966/8355. 0.1164 s / img. ETA=0:12:41
[32m[04/19 23:12:20 d2.evaluation.evaluator]: [0mInference done 2008/8355. 0.1164 s / img. ETA=0:12:37
[32m[04/19 23:12:25 d2.evaluation.evaluator]: [0mInference done 2050/8355. 0.1164 s / img. ETA=0:12:32
[32m[04/19 23:12:30 d2.evaluation.evaluator]: [0mInference done 2092/8355. 0.1164 s / img. ETA=0:12:27
[32m[04/19 23:12:35 d2.evaluation.evaluator]: [0mInference done 2135/8355. 0.1164 s / img. ETA=0:12:21
[32m[04/19 23:12:40 d2.evaluation.evaluator]: [0mInference done 2177/8355. 0.1164 s / img. ETA=0:12:16
[32m[04/19 23:12:45 d2.evaluation.evaluator]: [0mInference done 2219/8355. 0.1164 s / img. ETA=0:12:12
[32m[04/19 23:12:50 d2.evaluation.evaluator]: [0mInference done 2259/8355. 0.1165 s / img. ETA=0:12:08
[32m[04/19 23:12:55 d2.evaluation.evaluator]: [0mInference done 2299/8355. 0.1165 s / img. ETA=0:12:04
[32m[04/19 23:13:00 d2.evaluation.evaluator]: [0mInference done 2339/8355. 0.1165 s / img. ETA=0:12:00
[32m[04/19 23:13:05 d2.evaluation.evaluator]: [0mInference done 2381/8355. 0.1165 s / img. ETA=0:11:55
[32m[04/19 23:13:10 d2.evaluation.evaluator]: [0mInference done 2423/8355. 0.1165 s / img. ETA=0:11:50
[32m[04/19 23:13:15 d2.evaluation.evaluator]: [0mInference done 2465/8355. 0.1165 s / img. ETA=0:11:45
[32m[04/19 23:13:20 d2.evaluation.evaluator]: [0mInference done 2507/8355. 0.1165 s / img. ETA=0:11:40
[32m[04/19 23:13:25 d2.evaluation.evaluator]: [0mInference done 2549/8355. 0.1165 s / img. ETA=0:11:35
[32m[04/19 23:13:30 d2.evaluation.evaluator]: [0mInference done 2591/8355. 0.1166 s / img. ETA=0:11:30
[32m[04/19 23:13:35 d2.evaluation.evaluator]: [0mInference done 2633/8355. 0.1166 s / img. ETA=0:11:25
[32m[04/19 23:13:40 d2.evaluation.evaluator]: [0mInference done 2675/8355. 0.1166 s / img. ETA=0:11:19
[32m[04/19 23:13:46 d2.evaluation.evaluator]: [0mInference done 2717/8355. 0.1166 s / img. ETA=0:11:15
[32m[04/19 23:13:51 d2.evaluation.evaluator]: [0mInference done 2759/8355. 0.1166 s / img. ETA=0:11:09
[32m[04/19 23:13:56 d2.evaluation.evaluator]: [0mInference done 2802/8355. 0.1166 s / img. ETA=0:11:04
[32m[04/19 23:14:01 d2.evaluation.evaluator]: [0mInference done 2842/8355. 0.1166 s / img. ETA=0:11:00
[32m[04/19 23:14:06 d2.evaluation.evaluator]: [0mInference done 2884/8355. 0.1166 s / img. ETA=0:10:55
[32m[04/19 23:14:11 d2.evaluation.evaluator]: [0mInference done 2926/8355. 0.1166 s / img. ETA=0:10:50
[32m[04/19 23:14:16 d2.evaluation.evaluator]: [0mInference done 2968/8355. 0.1166 s / img. ETA=0:10:45
[32m[04/19 23:14:21 d2.evaluation.evaluator]: [0mInference done 3010/8355. 0.1166 s / img. ETA=0:10:40
[32m[04/19 23:14:26 d2.evaluation.evaluator]: [0mInference done 3052/8355. 0.1166 s / img. ETA=0:10:35
[32m[04/19 23:14:31 d2.evaluation.evaluator]: [0mInference done 3094/8355. 0.1166 s / img. ETA=0:10:30
[32m[04/19 23:14:36 d2.evaluation.evaluator]: [0mInference done 3136/8355. 0.1166 s / img. ETA=0:10:25
[32m[04/19 23:14:41 d2.evaluation.evaluator]: [0mInference done 3178/8355. 0.1166 s / img. ETA=0:10:20
[32m[04/19 23:14:46 d2.evaluation.evaluator]: [0mInference done 3221/8355. 0.1166 s / img. ETA=0:10:14
[32m[04/19 23:14:51 d2.evaluation.evaluator]: [0mInference done 3263/8355. 0.1166 s / img. ETA=0:10:09
[32m[04/19 23:14:56 d2.evaluation.evaluator]: [0mInference done 3301/8355. 0.1166 s / img. ETA=0:10:06
[32m[04/19 23:15:01 d2.evaluation.evaluator]: [0mInference done 3342/8355. 0.1166 s / img. ETA=0:10:01
[32m[04/19 23:15:06 d2.evaluation.evaluator]: [0mInference done 3384/8355. 0.1166 s / img. ETA=0:09:56
[32m[04/19 23:15:11 d2.evaluation.evaluator]: [0mInference done 3426/8355. 0.1166 s / img. ETA=0:09:51
[32m[04/19 23:15:16 d2.evaluation.evaluator]: [0mInference done 3467/8355. 0.1167 s / img. ETA=0:09:46
[32m[04/19 23:15:21 d2.evaluation.evaluator]: [0mInference done 3509/8355. 0.1167 s / img. ETA=0:09:41
[32m[04/19 23:15:27 d2.evaluation.evaluator]: [0mInference done 3550/8355. 0.1167 s / img. ETA=0:09:36
[32m[04/19 23:15:32 d2.evaluation.evaluator]: [0mInference done 3589/8355. 0.1167 s / img. ETA=0:09:32
[32m[04/19 23:15:37 d2.evaluation.evaluator]: [0mInference done 3631/8355. 0.1167 s / img. ETA=0:09:27
[32m[04/19 23:15:42 d2.evaluation.evaluator]: [0mInference done 3670/8355. 0.1167 s / img. ETA=0:09:23
[32m[04/19 23:15:47 d2.evaluation.evaluator]: [0mInference done 3712/8355. 0.1167 s / img. ETA=0:09:18
[32m[04/19 23:15:52 d2.evaluation.evaluator]: [0mInference done 3754/8355. 0.1167 s / img. ETA=0:09:13
[32m[04/19 23:15:57 d2.evaluation.evaluator]: [0mInference done 3796/8355. 0.1167 s / img. ETA=0:09:08
[32m[04/19 23:16:02 d2.evaluation.evaluator]: [0mInference done 3838/8355. 0.1167 s / img. ETA=0:09:03
[32m[04/19 23:16:07 d2.evaluation.evaluator]: [0mInference done 3879/8355. 0.1167 s / img. ETA=0:08:58
[32m[04/19 23:16:12 d2.evaluation.evaluator]: [0mInference done 3922/8355. 0.1167 s / img. ETA=0:08:53
[32m[04/19 23:16:17 d2.evaluation.evaluator]: [0mInference done 3965/8355. 0.1167 s / img. ETA=0:08:47
[32m[04/19 23:16:22 d2.evaluation.evaluator]: [0mInference done 4007/8355. 0.1167 s / img. ETA=0:08:42
[32m[04/19 23:16:27 d2.evaluation.evaluator]: [0mInference done 4049/8355. 0.1167 s / img. ETA=0:08:37
[32m[04/19 23:16:32 d2.evaluation.evaluator]: [0mInference done 4091/8355. 0.1167 s / img. ETA=0:08:32
[32m[04/19 23:16:37 d2.evaluation.evaluator]: [0mInference done 4132/8355. 0.1167 s / img. ETA=0:08:27
[32m[04/19 23:16:42 d2.evaluation.evaluator]: [0mInference done 4174/8355. 0.1167 s / img. ETA=0:08:22
[32m[04/19 23:16:47 d2.evaluation.evaluator]: [0mInference done 4216/8355. 0.1167 s / img. ETA=0:08:17
[32m[04/19 23:16:52 d2.evaluation.evaluator]: [0mInference done 4258/8355. 0.1167 s / img. ETA=0:08:12
[32m[04/19 23:16:57 d2.evaluation.evaluator]: [0mInference done 4300/8355. 0.1167 s / img. ETA=0:08:07
[32m[04/19 23:17:02 d2.evaluation.evaluator]: [0mInference done 4342/8355. 0.1167 s / img. ETA=0:08:02
[32m[04/19 23:17:07 d2.evaluation.evaluator]: [0mInference done 4384/8355. 0.1167 s / img. ETA=0:07:57
[32m[04/19 23:17:12 d2.evaluation.evaluator]: [0mInference done 4424/8355. 0.1167 s / img. ETA=0:07:52
[32m[04/19 23:17:17 d2.evaluation.evaluator]: [0mInference done 4466/8355. 0.1167 s / img. ETA=0:07:47
[32m[04/19 23:17:22 d2.evaluation.evaluator]: [0mInference done 4508/8355. 0.1167 s / img. ETA=0:07:42
[32m[04/19 23:17:28 d2.evaluation.evaluator]: [0mInference done 4547/8355. 0.1168 s / img. ETA=0:07:38
[32m[04/19 23:17:33 d2.evaluation.evaluator]: [0mInference done 4585/8355. 0.1168 s / img. ETA=0:07:34
[32m[04/19 23:17:38 d2.evaluation.evaluator]: [0mInference done 4627/8355. 0.1168 s / img. ETA=0:07:29
[32m[04/19 23:17:43 d2.evaluation.evaluator]: [0mInference done 4669/8355. 0.1168 s / img. ETA=0:07:24
[32m[04/19 23:17:48 d2.evaluation.evaluator]: [0mInference done 4711/8355. 0.1168 s / img. ETA=0:07:18
[32m[04/19 23:17:53 d2.evaluation.evaluator]: [0mInference done 4753/8355. 0.1168 s / img. ETA=0:07:13
[32m[04/19 23:17:58 d2.evaluation.evaluator]: [0mInference done 4795/8355. 0.1168 s / img. ETA=0:07:08
[32m[04/19 23:18:03 d2.evaluation.evaluator]: [0mInference done 4833/8355. 0.1168 s / img. ETA=0:07:04
[32m[04/19 23:18:08 d2.evaluation.evaluator]: [0mInference done 4872/8355. 0.1168 s / img. ETA=0:07:00
[32m[04/19 23:18:13 d2.evaluation.evaluator]: [0mInference done 4907/8355. 0.1168 s / img. ETA=0:06:56
[32m[04/19 23:18:18 d2.evaluation.evaluator]: [0mInference done 4949/8355. 0.1168 s / img. ETA=0:06:51
[32m[04/19 23:18:23 d2.evaluation.evaluator]: [0mInference done 4989/8355. 0.1168 s / img. ETA=0:06:46
[32m[04/19 23:18:28 d2.evaluation.evaluator]: [0mInference done 5030/8355. 0.1168 s / img. ETA=0:06:41
[32m[04/19 23:18:33 d2.evaluation.evaluator]: [0mInference done 5071/8355. 0.1168 s / img. ETA=0:06:36
[32m[04/19 23:18:38 d2.evaluation.evaluator]: [0mInference done 5113/8355. 0.1168 s / img. ETA=0:06:31
[32m[04/19 23:18:43 d2.evaluation.evaluator]: [0mInference done 5155/8355. 0.1168 s / img. ETA=0:06:26
[32m[04/19 23:18:48 d2.evaluation.evaluator]: [0mInference done 5197/8355. 0.1168 s / img. ETA=0:06:21
[32m[04/19 23:18:53 d2.evaluation.evaluator]: [0mInference done 5239/8355. 0.1168 s / img. ETA=0:06:16
[32m[04/19 23:18:58 d2.evaluation.evaluator]: [0mInference done 5281/8355. 0.1168 s / img. ETA=0:06:11
[32m[04/19 23:19:03 d2.evaluation.evaluator]: [0mInference done 5323/8355. 0.1168 s / img. ETA=0:06:06
[32m[04/19 23:19:08 d2.evaluation.evaluator]: [0mInference done 5361/8355. 0.1168 s / img. ETA=0:06:01
[32m[04/19 23:19:13 d2.evaluation.evaluator]: [0mInference done 5402/8355. 0.1168 s / img. ETA=0:05:57
[32m[04/19 23:19:18 d2.evaluation.evaluator]: [0mInference done 5443/8355. 0.1168 s / img. ETA=0:05:52
[32m[04/19 23:19:24 d2.evaluation.evaluator]: [0mInference done 5484/8355. 0.1169 s / img. ETA=0:05:47
[32m[04/19 23:19:29 d2.evaluation.evaluator]: [0mInference done 5526/8355. 0.1169 s / img. ETA=0:05:42
[32m[04/19 23:19:34 d2.evaluation.evaluator]: [0mInference done 5567/8355. 0.1169 s / img. ETA=0:05:37
[32m[04/19 23:19:39 d2.evaluation.evaluator]: [0mInference done 5609/8355. 0.1169 s / img. ETA=0:05:32
[32m[04/19 23:19:44 d2.evaluation.evaluator]: [0mInference done 5647/8355. 0.1169 s / img. ETA=0:05:27
[32m[04/19 23:19:49 d2.evaluation.evaluator]: [0mInference done 5689/8355. 0.1169 s / img. ETA=0:05:22
[32m[04/19 23:19:54 d2.evaluation.evaluator]: [0mInference done 5729/8355. 0.1169 s / img. ETA=0:05:17
[32m[04/19 23:19:59 d2.evaluation.evaluator]: [0mInference done 5769/8355. 0.1169 s / img. ETA=0:05:13
[32m[04/19 23:20:04 d2.evaluation.evaluator]: [0mInference done 5808/8355. 0.1169 s / img. ETA=0:05:08
[32m[04/19 23:20:09 d2.evaluation.evaluator]: [0mInference done 5850/8355. 0.1169 s / img. ETA=0:05:03
[32m[04/19 23:20:14 d2.evaluation.evaluator]: [0mInference done 5892/8355. 0.1169 s / img. ETA=0:04:58
[32m[04/19 23:20:19 d2.evaluation.evaluator]: [0mInference done 5934/8355. 0.1169 s / img. ETA=0:04:53
[32m[04/19 23:20:24 d2.evaluation.evaluator]: [0mInference done 5976/8355. 0.1169 s / img. ETA=0:04:48
[32m[04/19 23:20:29 d2.evaluation.evaluator]: [0mInference done 6018/8355. 0.1169 s / img. ETA=0:04:43
[32m[04/19 23:20:34 d2.evaluation.evaluator]: [0mInference done 6060/8355. 0.1169 s / img. ETA=0:04:38
[32m[04/19 23:20:39 d2.evaluation.evaluator]: [0mInference done 6102/8355. 0.1169 s / img. ETA=0:04:32
[32m[04/19 23:20:45 d2.evaluation.evaluator]: [0mInference done 6144/8355. 0.1170 s / img. ETA=0:04:27
[32m[04/19 23:20:50 d2.evaluation.evaluator]: [0mInference done 6186/8355. 0.1170 s / img. ETA=0:04:22
[32m[04/19 23:20:55 d2.evaluation.evaluator]: [0mInference done 6228/8355. 0.1170 s / img. ETA=0:04:17
[32m[04/19 23:21:00 d2.evaluation.evaluator]: [0mInference done 6270/8355. 0.1170 s / img. ETA=0:04:12
[32m[04/19 23:21:05 d2.evaluation.evaluator]: [0mInference done 6312/8355. 0.1170 s / img. ETA=0:04:07
[32m[04/19 23:21:10 d2.evaluation.evaluator]: [0mInference done 6354/8355. 0.1170 s / img. ETA=0:04:02
[32m[04/19 23:21:15 d2.evaluation.evaluator]: [0mInference done 6396/8355. 0.1170 s / img. ETA=0:03:57
[32m[04/19 23:21:20 d2.evaluation.evaluator]: [0mInference done 6438/8355. 0.1170 s / img. ETA=0:03:52
[32m[04/19 23:21:25 d2.evaluation.evaluator]: [0mInference done 6480/8355. 0.1170 s / img. ETA=0:03:47
[32m[04/19 23:21:30 d2.evaluation.evaluator]: [0mInference done 6522/8355. 0.1170 s / img. ETA=0:03:41
[32m[04/19 23:21:35 d2.evaluation.evaluator]: [0mInference done 6562/8355. 0.1170 s / img. ETA=0:03:37
[32m[04/19 23:21:40 d2.evaluation.evaluator]: [0mInference done 6604/8355. 0.1170 s / img. ETA=0:03:32
[32m[04/19 23:21:45 d2.evaluation.evaluator]: [0mInference done 6646/8355. 0.1170 s / img. ETA=0:03:27
[32m[04/19 23:21:50 d2.evaluation.evaluator]: [0mInference done 6688/8355. 0.1170 s / img. ETA=0:03:21
[32m[04/19 23:21:55 d2.evaluation.evaluator]: [0mInference done 6730/8355. 0.1170 s / img. ETA=0:03:16
[32m[04/19 23:22:00 d2.evaluation.evaluator]: [0mInference done 6772/8355. 0.1170 s / img. ETA=0:03:11
[32m[04/19 23:22:05 d2.evaluation.evaluator]: [0mInference done 6814/8355. 0.1170 s / img. ETA=0:03:06
[32m[04/19 23:22:11 d2.evaluation.evaluator]: [0mInference done 6856/8355. 0.1170 s / img. ETA=0:03:01
[32m[04/19 23:22:16 d2.evaluation.evaluator]: [0mInference done 6894/8355. 0.1170 s / img. ETA=0:02:57
[32m[04/19 23:22:21 d2.evaluation.evaluator]: [0mInference done 6934/8355. 0.1170 s / img. ETA=0:02:52
[32m[04/19 23:22:26 d2.evaluation.evaluator]: [0mInference done 6969/8355. 0.1170 s / img. ETA=0:02:48
[32m[04/19 23:22:31 d2.evaluation.evaluator]: [0mInference done 7006/8355. 0.1170 s / img. ETA=0:02:43
[32m[04/19 23:22:36 d2.evaluation.evaluator]: [0mInference done 7047/8355. 0.1170 s / img. ETA=0:02:38
[32m[04/19 23:22:41 d2.evaluation.evaluator]: [0mInference done 7088/8355. 0.1170 s / img. ETA=0:02:33
[32m[04/19 23:22:46 d2.evaluation.evaluator]: [0mInference done 7130/8355. 0.1170 s / img. ETA=0:02:28
[32m[04/19 23:22:51 d2.evaluation.evaluator]: [0mInference done 7171/8355. 0.1170 s / img. ETA=0:02:23
[32m[04/19 23:22:56 d2.evaluation.evaluator]: [0mInference done 7212/8355. 0.1171 s / img. ETA=0:02:18
[32m[04/19 23:23:01 d2.evaluation.evaluator]: [0mInference done 7254/8355. 0.1171 s / img. ETA=0:02:13
[32m[04/19 23:23:06 d2.evaluation.evaluator]: [0mInference done 7296/8355. 0.1171 s / img. ETA=0:02:08
[32m[04/19 23:23:11 d2.evaluation.evaluator]: [0mInference done 7336/8355. 0.1171 s / img. ETA=0:02:03
[32m[04/19 23:23:16 d2.evaluation.evaluator]: [0mInference done 7378/8355. 0.1171 s / img. ETA=0:01:58
[32m[04/19 23:23:21 d2.evaluation.evaluator]: [0mInference done 7420/8355. 0.1171 s / img. ETA=0:01:53
[32m[04/19 23:23:26 d2.evaluation.evaluator]: [0mInference done 7462/8355. 0.1171 s / img. ETA=0:01:48
[32m[04/19 23:23:32 d2.evaluation.evaluator]: [0mInference done 7502/8355. 0.1171 s / img. ETA=0:01:43
[32m[04/19 23:23:37 d2.evaluation.evaluator]: [0mInference done 7539/8355. 0.1171 s / img. ETA=0:01:39
[32m[04/19 23:23:42 d2.evaluation.evaluator]: [0mInference done 7581/8355. 0.1171 s / img. ETA=0:01:34
[32m[04/19 23:23:47 d2.evaluation.evaluator]: [0mInference done 7620/8355. 0.1171 s / img. ETA=0:01:29
[32m[04/19 23:23:52 d2.evaluation.evaluator]: [0mInference done 7654/8355. 0.1171 s / img. ETA=0:01:25
[32m[04/19 23:23:57 d2.evaluation.evaluator]: [0mInference done 7694/8355. 0.1171 s / img. ETA=0:01:20
[32m[04/19 23:24:02 d2.evaluation.evaluator]: [0mInference done 7732/8355. 0.1171 s / img. ETA=0:01:15
[32m[04/19 23:24:07 d2.evaluation.evaluator]: [0mInference done 7772/8355. 0.1171 s / img. ETA=0:01:11
[32m[04/19 23:24:12 d2.evaluation.evaluator]: [0mInference done 7814/8355. 0.1171 s / img. ETA=0:01:05
[32m[04/19 23:24:17 d2.evaluation.evaluator]: [0mInference done 7856/8355. 0.1171 s / img. ETA=0:01:00
[32m[04/19 23:24:22 d2.evaluation.evaluator]: [0mInference done 7896/8355. 0.1171 s / img. ETA=0:00:55
[32m[04/19 23:24:27 d2.evaluation.evaluator]: [0mInference done 7937/8355. 0.1171 s / img. ETA=0:00:50
[32m[04/19 23:24:32 d2.evaluation.evaluator]: [0mInference done 7977/8355. 0.1171 s / img. ETA=0:00:46
[32m[04/19 23:24:37 d2.evaluation.evaluator]: [0mInference done 8015/8355. 0.1171 s / img. ETA=0:00:41
[32m[04/19 23:24:42 d2.evaluation.evaluator]: [0mInference done 8055/8355. 0.1171 s / img. ETA=0:00:36
[32m[04/19 23:24:48 d2.evaluation.evaluator]: [0mInference done 8092/8355. 0.1171 s / img. ETA=0:00:32
[32m[04/19 23:24:53 d2.evaluation.evaluator]: [0mInference done 8133/8355. 0.1171 s / img. ETA=0:00:27
[32m[04/19 23:24:58 d2.evaluation.evaluator]: [0mInference done 8175/8355. 0.1171 s / img. ETA=0:00:21
[32m[04/19 23:25:03 d2.evaluation.evaluator]: [0mInference done 8217/8355. 0.1171 s / img. ETA=0:00:16
[32m[04/19 23:25:08 d2.evaluation.evaluator]: [0mInference done 8259/8355. 0.1171 s / img. ETA=0:00:11
[32m[04/19 23:25:13 d2.evaluation.evaluator]: [0mInference done 8301/8355. 0.1171 s / img. ETA=0:00:06
[32m[04/19 23:25:18 d2.evaluation.evaluator]: [0mInference done 8343/8355. 0.1171 s / img. ETA=0:00:01
[32m[04/19 23:25:19 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:58.317313 (0.121954 s / img per device, on 1 devices)
[32m[04/19 23:25:19 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:18 (0.117143 s / img per device, on 1 devices)
[32m[04/19 23:25:20 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/19 23:25:20 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/19 23:25:20 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.41s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=17.50s).
Accumulating evaluation results...
DONE (t=2.09s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.205
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.430
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.165
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.284
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.115
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.253
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.337
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.541
[32m[04/19 23:25:40 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 20.451 | 42.969 | 16.539 | 13.954 | 28.420 | 49.324 |
[32m[04/19 23:25:40 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 27.886 | bicycle       | 8.039  | car            | 33.055 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | 12.823 | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/19 23:25:41 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 23:25:41 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[32m[04/19 23:25:41 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/19 23:25:43 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1179 s / img. ETA=0:02:29
[32m[04/19 23:25:48 d2.evaluation.evaluator]: [0mInference done 51/1257. 0.1172 s / img. ETA=0:02:31
[32m[04/19 23:25:53 d2.evaluation.evaluator]: [0mInference done 93/1257. 0.1171 s / img. ETA=0:02:22
[32m[04/19 23:25:58 d2.evaluation.evaluator]: [0mInference done 135/1257. 0.1171 s / img. ETA=0:02:16
[32m[04/19 23:26:03 d2.evaluation.evaluator]: [0mInference done 176/1257. 0.1171 s / img. ETA=0:02:12
[32m[04/19 23:26:08 d2.evaluation.evaluator]: [0mInference done 218/1257. 0.1172 s / img. ETA=0:02:06
[32m[04/19 23:26:13 d2.evaluation.evaluator]: [0mInference done 260/1257. 0.1172 s / img. ETA=0:02:01
[32m[04/19 23:26:18 d2.evaluation.evaluator]: [0mInference done 302/1257. 0.1173 s / img. ETA=0:01:55
[32m[04/19 23:26:23 d2.evaluation.evaluator]: [0mInference done 340/1257. 0.1172 s / img. ETA=0:01:52
[32m[04/19 23:26:28 d2.evaluation.evaluator]: [0mInference done 382/1257. 0.1172 s / img. ETA=0:01:46
[32m[04/19 23:26:33 d2.evaluation.evaluator]: [0mInference done 424/1257. 0.1172 s / img. ETA=0:01:41
[32m[04/19 23:26:38 d2.evaluation.evaluator]: [0mInference done 466/1257. 0.1172 s / img. ETA=0:01:36
[32m[04/19 23:26:44 d2.evaluation.evaluator]: [0mInference done 507/1257. 0.1172 s / img. ETA=0:01:31
[32m[04/19 23:26:49 d2.evaluation.evaluator]: [0mInference done 546/1257. 0.1173 s / img. ETA=0:01:27
[32m[04/19 23:26:54 d2.evaluation.evaluator]: [0mInference done 588/1257. 0.1173 s / img. ETA=0:01:21
[32m[04/19 23:26:59 d2.evaluation.evaluator]: [0mInference done 625/1257. 0.1173 s / img. ETA=0:01:17
[32m[04/19 23:27:04 d2.evaluation.evaluator]: [0mInference done 662/1257. 0.1173 s / img. ETA=0:01:13
[32m[04/19 23:27:09 d2.evaluation.evaluator]: [0mInference done 701/1257. 0.1173 s / img. ETA=0:01:09
[32m[04/19 23:27:14 d2.evaluation.evaluator]: [0mInference done 740/1257. 0.1173 s / img. ETA=0:01:04
[32m[04/19 23:27:19 d2.evaluation.evaluator]: [0mInference done 781/1257. 0.1173 s / img. ETA=0:00:59
[32m[04/19 23:27:24 d2.evaluation.evaluator]: [0mInference done 823/1257. 0.1173 s / img. ETA=0:00:53
[32m[04/19 23:27:29 d2.evaluation.evaluator]: [0mInference done 862/1257. 0.1173 s / img. ETA=0:00:49
[32m[04/19 23:27:34 d2.evaluation.evaluator]: [0mInference done 899/1257. 0.1173 s / img. ETA=0:00:44
[32m[04/19 23:27:39 d2.evaluation.evaluator]: [0mInference done 942/1257. 0.1173 s / img. ETA=0:00:39
[32m[04/19 23:27:44 d2.evaluation.evaluator]: [0mInference done 984/1257. 0.1172 s / img. ETA=0:00:33
[32m[04/19 23:27:49 d2.evaluation.evaluator]: [0mInference done 1027/1257. 0.1172 s / img. ETA=0:00:28
[32m[04/19 23:27:54 d2.evaluation.evaluator]: [0mInference done 1069/1257. 0.1172 s / img. ETA=0:00:23
[32m[04/19 23:27:59 d2.evaluation.evaluator]: [0mInference done 1111/1257. 0.1172 s / img. ETA=0:00:18
[32m[04/19 23:28:04 d2.evaluation.evaluator]: [0mInference done 1153/1257. 0.1172 s / img. ETA=0:00:12
[32m[04/19 23:28:10 d2.evaluation.evaluator]: [0mInference done 1196/1257. 0.1171 s / img. ETA=0:00:07
[32m[04/19 23:28:15 d2.evaluation.evaluator]: [0mInference done 1239/1257. 0.1171 s / img. ETA=0:00:02
[32m[04/19 23:28:17 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:34.440363 (0.123355 s / img per device, on 1 devices)
[32m[04/19 23:28:17 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:26 (0.117092 s / img per device, on 1 devices)
[32m[04/19 23:28:17 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/19 23:28:17 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/19 23:28:17 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.25s).
Accumulating evaluation results...
DONE (t=0.33s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.152
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.308
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.136
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.088
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.184
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.396
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.078
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.196
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.196
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.130
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.443
[32m[04/19 23:28:20 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 15.199 | 30.816 | 13.650 | 8.830 | 18.385 | 39.612 |
[32m[04/19 23:28:20 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 23.172 | bicycle       | 2.539 | car            | 35.084 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | 0.000 | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  4  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/19 23:28:20 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/19 23:28:21 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 23:28:21 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/19 23:28:21 d2.data.build]: [0mRemoved 889 images with no usable annotations. 7466 images left.
[32m[04/19 23:28:21 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/19 23:28:21 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/19 23:28:21 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/19 23:28:32 d2.utils.events]: [0m eta: 0:08:41  iter: 19  total_loss: 0.787  loss_cls: 0.246  loss_box_reg: 0.418  loss_rpn_cls: 0.043  loss_rpn_loc: 0.067  time: 0.5285  data_time: 0.0198  lr: 0.000100  max_mem: 3094M
[32m[04/19 23:28:43 d2.utils.events]: [0m eta: 0:08:32  iter: 39  total_loss: 0.819  loss_cls: 0.290  loss_box_reg: 0.443  loss_rpn_cls: 0.032  loss_rpn_loc: 0.086  time: 0.5299  data_time: 0.0050  lr: 0.000200  max_mem: 3094M
[32m[04/19 23:28:53 d2.utils.events]: [0m eta: 0:08:14  iter: 59  total_loss: 0.692  loss_cls: 0.239  loss_box_reg: 0.361  loss_rpn_cls: 0.039  loss_rpn_loc: 0.063  time: 0.5241  data_time: 0.0049  lr: 0.000300  max_mem: 3094M
[32m[04/19 23:29:03 d2.utils.events]: [0m eta: 0:08:01  iter: 79  total_loss: 0.786  loss_cls: 0.273  loss_box_reg: 0.381  loss_rpn_cls: 0.037  loss_rpn_loc: 0.069  time: 0.5199  data_time: 0.0048  lr: 0.000400  max_mem: 3094M
[32m[04/19 23:29:14 d2.utils.events]: [0m eta: 0:07:49  iter: 99  total_loss: 0.622  loss_cls: 0.206  loss_box_reg: 0.352  loss_rpn_cls: 0.029  loss_rpn_loc: 0.051  time: 0.5187  data_time: 0.0048  lr: 0.000500  max_mem: 3094M
[32m[04/19 23:29:24 d2.utils.events]: [0m eta: 0:07:38  iter: 119  total_loss: 0.610  loss_cls: 0.221  loss_box_reg: 0.304  loss_rpn_cls: 0.029  loss_rpn_loc: 0.062  time: 0.5184  data_time: 0.0051  lr: 0.000599  max_mem: 3094M
[32m[04/19 23:29:35 d2.utils.events]: [0m eta: 0:07:28  iter: 139  total_loss: 0.830  loss_cls: 0.276  loss_box_reg: 0.439  loss_rpn_cls: 0.030  loss_rpn_loc: 0.064  time: 0.5195  data_time: 0.0045  lr: 0.000699  max_mem: 3094M
[32m[04/19 23:29:45 d2.utils.events]: [0m eta: 0:07:17  iter: 159  total_loss: 0.810  loss_cls: 0.269  loss_box_reg: 0.436  loss_rpn_cls: 0.033  loss_rpn_loc: 0.079  time: 0.5181  data_time: 0.0045  lr: 0.000799  max_mem: 3094M
[32m[04/19 23:29:56 d2.utils.events]: [0m eta: 0:07:07  iter: 179  total_loss: 0.703  loss_cls: 0.228  loss_box_reg: 0.341  loss_rpn_cls: 0.035  loss_rpn_loc: 0.061  time: 0.5191  data_time: 0.0048  lr: 0.000899  max_mem: 3094M
[32m[04/19 23:30:06 d2.utils.events]: [0m eta: 0:06:55  iter: 199  total_loss: 0.711  loss_cls: 0.225  loss_box_reg: 0.356  loss_rpn_cls: 0.035  loss_rpn_loc: 0.070  time: 0.5175  data_time: 0.0048  lr: 0.000999  max_mem: 3094M
[32m[04/19 23:30:16 d2.utils.events]: [0m eta: 0:06:45  iter: 219  total_loss: 0.677  loss_cls: 0.217  loss_box_reg: 0.379  loss_rpn_cls: 0.025  loss_rpn_loc: 0.054  time: 0.5182  data_time: 0.0048  lr: 0.001099  max_mem: 3094M
[32m[04/19 23:30:27 d2.utils.events]: [0m eta: 0:06:34  iter: 239  total_loss: 0.681  loss_cls: 0.215  loss_box_reg: 0.381  loss_rpn_cls: 0.026  loss_rpn_loc: 0.064  time: 0.5178  data_time: 0.0044  lr: 0.001199  max_mem: 3094M
[32m[04/19 23:30:37 d2.utils.events]: [0m eta: 0:06:25  iter: 259  total_loss: 0.719  loss_cls: 0.250  loss_box_reg: 0.406  loss_rpn_cls: 0.028  loss_rpn_loc: 0.050  time: 0.5190  data_time: 0.0052  lr: 0.001299  max_mem: 3094M
[32m[04/19 23:30:48 d2.utils.events]: [0m eta: 0:06:15  iter: 279  total_loss: 0.712  loss_cls: 0.266  loss_box_reg: 0.359  loss_rpn_cls: 0.031  loss_rpn_loc: 0.053  time: 0.5196  data_time: 0.0049  lr: 0.001399  max_mem: 3094M
[32m[04/19 23:30:58 d2.utils.events]: [0m eta: 0:06:05  iter: 299  total_loss: 0.747  loss_cls: 0.231  loss_box_reg: 0.378  loss_rpn_cls: 0.026  loss_rpn_loc: 0.056  time: 0.5190  data_time: 0.0046  lr: 0.001499  max_mem: 3094M
[32m[04/19 23:31:09 d2.utils.events]: [0m eta: 0:05:54  iter: 319  total_loss: 0.788  loss_cls: 0.290  loss_box_reg: 0.378  loss_rpn_cls: 0.040  loss_rpn_loc: 0.065  time: 0.5196  data_time: 0.0047  lr: 0.001598  max_mem: 3094M
[32m[04/19 23:31:19 d2.utils.events]: [0m eta: 0:05:44  iter: 339  total_loss: 0.737  loss_cls: 0.247  loss_box_reg: 0.413  loss_rpn_cls: 0.030  loss_rpn_loc: 0.071  time: 0.5201  data_time: 0.0047  lr: 0.001698  max_mem: 3094M
[32m[04/19 23:31:30 d2.utils.events]: [0m eta: 0:05:34  iter: 359  total_loss: 0.555  loss_cls: 0.200  loss_box_reg: 0.306  loss_rpn_cls: 0.026  loss_rpn_loc: 0.039  time: 0.5204  data_time: 0.0051  lr: 0.001798  max_mem: 3094M
[32m[04/19 23:31:40 d2.utils.events]: [0m eta: 0:05:24  iter: 379  total_loss: 0.736  loss_cls: 0.244  loss_box_reg: 0.399  loss_rpn_cls: 0.031  loss_rpn_loc: 0.059  time: 0.5204  data_time: 0.0050  lr: 0.001898  max_mem: 3094M
[32m[04/19 23:31:51 d2.utils.events]: [0m eta: 0:05:13  iter: 399  total_loss: 0.720  loss_cls: 0.238  loss_box_reg: 0.365  loss_rpn_cls: 0.031  loss_rpn_loc: 0.074  time: 0.5203  data_time: 0.0050  lr: 0.001998  max_mem: 3094M
[32m[04/19 23:32:01 d2.utils.events]: [0m eta: 0:05:03  iter: 419  total_loss: 0.679  loss_cls: 0.230  loss_box_reg: 0.358  loss_rpn_cls: 0.016  loss_rpn_loc: 0.054  time: 0.5203  data_time: 0.0048  lr: 0.002098  max_mem: 3094M
[32m[04/19 23:32:12 d2.utils.events]: [0m eta: 0:04:52  iter: 439  total_loss: 0.681  loss_cls: 0.240  loss_box_reg: 0.346  loss_rpn_cls: 0.031  loss_rpn_loc: 0.069  time: 0.5196  data_time: 0.0047  lr: 0.002198  max_mem: 3094M
[32m[04/19 23:32:22 d2.utils.events]: [0m eta: 0:04:42  iter: 459  total_loss: 0.744  loss_cls: 0.251  loss_box_reg: 0.378  loss_rpn_cls: 0.026  loss_rpn_loc: 0.070  time: 0.5200  data_time: 0.0048  lr: 0.002298  max_mem: 3094M
[32m[04/19 23:32:32 d2.utils.events]: [0m eta: 0:04:31  iter: 479  total_loss: 0.577  loss_cls: 0.197  loss_box_reg: 0.319  loss_rpn_cls: 0.025  loss_rpn_loc: 0.050  time: 0.5193  data_time: 0.0046  lr: 0.002398  max_mem: 3094M
[32m[04/19 23:32:43 d2.utils.events]: [0m eta: 0:04:21  iter: 499  total_loss: 0.693  loss_cls: 0.238  loss_box_reg: 0.354  loss_rpn_cls: 0.031  loss_rpn_loc: 0.054  time: 0.5196  data_time: 0.0049  lr: 0.002498  max_mem: 3094M
[32m[04/19 23:32:53 d2.utils.events]: [0m eta: 0:04:10  iter: 519  total_loss: 0.663  loss_cls: 0.254  loss_box_reg: 0.333  loss_rpn_cls: 0.023  loss_rpn_loc: 0.058  time: 0.5188  data_time: 0.0047  lr: 0.002597  max_mem: 3094M
[32m[04/19 23:33:04 d2.utils.events]: [0m eta: 0:04:00  iter: 539  total_loss: 0.802  loss_cls: 0.270  loss_box_reg: 0.400  loss_rpn_cls: 0.033  loss_rpn_loc: 0.073  time: 0.5192  data_time: 0.0049  lr: 0.002697  max_mem: 3094M
[32m[04/19 23:33:14 d2.utils.events]: [0m eta: 0:03:49  iter: 559  total_loss: 0.573  loss_cls: 0.204  loss_box_reg: 0.293  loss_rpn_cls: 0.026  loss_rpn_loc: 0.054  time: 0.5195  data_time: 0.0048  lr: 0.002797  max_mem: 3094M
[32m[04/19 23:33:25 d2.utils.events]: [0m eta: 0:03:39  iter: 579  total_loss: 0.690  loss_cls: 0.223  loss_box_reg: 0.302  loss_rpn_cls: 0.028  loss_rpn_loc: 0.065  time: 0.5195  data_time: 0.0051  lr: 0.002897  max_mem: 3094M
[32m[04/19 23:33:35 d2.utils.events]: [0m eta: 0:03:29  iter: 599  total_loss: 0.798  loss_cls: 0.271  loss_box_reg: 0.434  loss_rpn_cls: 0.027  loss_rpn_loc: 0.076  time: 0.5193  data_time: 0.0050  lr: 0.002997  max_mem: 3094M
[32m[04/19 23:33:45 d2.utils.events]: [0m eta: 0:03:18  iter: 619  total_loss: 0.735  loss_cls: 0.240  loss_box_reg: 0.392  loss_rpn_cls: 0.033  loss_rpn_loc: 0.057  time: 0.5192  data_time: 0.0049  lr: 0.003097  max_mem: 3094M
[32m[04/19 23:33:56 d2.utils.events]: [0m eta: 0:03:08  iter: 639  total_loss: 0.673  loss_cls: 0.221  loss_box_reg: 0.363  loss_rpn_cls: 0.037  loss_rpn_loc: 0.061  time: 0.5195  data_time: 0.0050  lr: 0.003197  max_mem: 3094M
[32m[04/19 23:34:06 d2.utils.events]: [0m eta: 0:02:57  iter: 659  total_loss: 0.646  loss_cls: 0.205  loss_box_reg: 0.295  loss_rpn_cls: 0.030  loss_rpn_loc: 0.053  time: 0.5197  data_time: 0.0052  lr: 0.003297  max_mem: 3094M
[32m[04/19 23:34:17 d2.utils.events]: [0m eta: 0:02:47  iter: 679  total_loss: 0.736  loss_cls: 0.264  loss_box_reg: 0.375  loss_rpn_cls: 0.027  loss_rpn_loc: 0.064  time: 0.5197  data_time: 0.0051  lr: 0.003397  max_mem: 3094M
[32m[04/19 23:34:27 d2.utils.events]: [0m eta: 0:02:37  iter: 699  total_loss: 0.558  loss_cls: 0.185  loss_box_reg: 0.305  loss_rpn_cls: 0.028  loss_rpn_loc: 0.050  time: 0.5198  data_time: 0.0052  lr: 0.003497  max_mem: 3094M
[32m[04/19 23:34:38 d2.utils.events]: [0m eta: 0:02:26  iter: 719  total_loss: 0.657  loss_cls: 0.198  loss_box_reg: 0.371  loss_rpn_cls: 0.027  loss_rpn_loc: 0.041  time: 0.5196  data_time: 0.0054  lr: 0.003596  max_mem: 3094M
[32m[04/19 23:34:48 d2.utils.events]: [0m eta: 0:02:16  iter: 739  total_loss: 0.724  loss_cls: 0.242  loss_box_reg: 0.370  loss_rpn_cls: 0.029  loss_rpn_loc: 0.061  time: 0.5195  data_time: 0.0049  lr: 0.003696  max_mem: 3094M
[32m[04/19 23:34:59 d2.utils.events]: [0m eta: 0:02:05  iter: 759  total_loss: 0.755  loss_cls: 0.253  loss_box_reg: 0.401  loss_rpn_cls: 0.023  loss_rpn_loc: 0.084  time: 0.5198  data_time: 0.0047  lr: 0.003796  max_mem: 3094M
[32m[04/19 23:35:09 d2.utils.events]: [0m eta: 0:01:55  iter: 779  total_loss: 0.789  loss_cls: 0.276  loss_box_reg: 0.381  loss_rpn_cls: 0.038  loss_rpn_loc: 0.074  time: 0.5197  data_time: 0.0049  lr: 0.003896  max_mem: 3094M
[32m[04/19 23:35:19 d2.utils.events]: [0m eta: 0:01:44  iter: 799  total_loss: 0.682  loss_cls: 0.242  loss_box_reg: 0.353  loss_rpn_cls: 0.031  loss_rpn_loc: 0.054  time: 0.5195  data_time: 0.0051  lr: 0.003996  max_mem: 3094M
[32m[04/19 23:35:30 d2.utils.events]: [0m eta: 0:01:34  iter: 819  total_loss: 0.691  loss_cls: 0.245  loss_box_reg: 0.341  loss_rpn_cls: 0.025  loss_rpn_loc: 0.049  time: 0.5198  data_time: 0.0050  lr: 0.004096  max_mem: 3094M
[32m[04/19 23:35:40 d2.utils.events]: [0m eta: 0:01:23  iter: 839  total_loss: 0.592  loss_cls: 0.221  loss_box_reg: 0.282  loss_rpn_cls: 0.036  loss_rpn_loc: 0.059  time: 0.5194  data_time: 0.0048  lr: 0.004196  max_mem: 3094M
[32m[04/19 23:35:51 d2.utils.events]: [0m eta: 0:01:13  iter: 859  total_loss: 0.780  loss_cls: 0.266  loss_box_reg: 0.409  loss_rpn_cls: 0.031  loss_rpn_loc: 0.074  time: 0.5196  data_time: 0.0051  lr: 0.004296  max_mem: 3094M
[32m[04/19 23:36:01 d2.utils.events]: [0m eta: 0:01:03  iter: 879  total_loss: 0.661  loss_cls: 0.208  loss_box_reg: 0.329  loss_rpn_cls: 0.027  loss_rpn_loc: 0.060  time: 0.5193  data_time: 0.0048  lr: 0.004396  max_mem: 3094M
[32m[04/19 23:36:12 d2.utils.events]: [0m eta: 0:00:52  iter: 899  total_loss: 0.730  loss_cls: 0.236  loss_box_reg: 0.360  loss_rpn_cls: 0.040  loss_rpn_loc: 0.075  time: 0.5195  data_time: 0.0048  lr: 0.004496  max_mem: 3094M
[32m[04/19 23:36:22 d2.utils.events]: [0m eta: 0:00:42  iter: 919  total_loss: 0.768  loss_cls: 0.275  loss_box_reg: 0.360  loss_rpn_cls: 0.042  loss_rpn_loc: 0.065  time: 0.5191  data_time: 0.0048  lr: 0.004595  max_mem: 3094M
[32m[04/19 23:36:32 d2.utils.events]: [0m eta: 0:00:31  iter: 939  total_loss: 0.607  loss_cls: 0.225  loss_box_reg: 0.323  loss_rpn_cls: 0.032  loss_rpn_loc: 0.072  time: 0.5194  data_time: 0.0048  lr: 0.004695  max_mem: 3094M
[32m[04/19 23:36:43 d2.utils.events]: [0m eta: 0:00:21  iter: 959  total_loss: 0.720  loss_cls: 0.242  loss_box_reg: 0.359  loss_rpn_cls: 0.038  loss_rpn_loc: 0.073  time: 0.5191  data_time: 0.0050  lr: 0.004795  max_mem: 3094M
[32m[04/19 23:36:53 d2.utils.events]: [0m eta: 0:00:10  iter: 979  total_loss: 0.713  loss_cls: 0.245  loss_box_reg: 0.380  loss_rpn_cls: 0.031  loss_rpn_loc: 0.054  time: 0.5189  data_time: 0.0049  lr: 0.004895  max_mem: 3094M
[5m[31mWARNING[0m [32m[04/19 23:37:07 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 23:37:07 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[5m[31mWARNING[0m [32m[04/19 23:37:07 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/19 23:37:07 d2.utils.events]: [0m eta: 0:00:00  iter: 999  total_loss: 0.619  loss_cls: 0.212  loss_box_reg: 0.289  loss_rpn_cls: 0.026  loss_rpn_loc: 0.058  time: 0.5190  data_time: 0.0052  lr: 0.004995  max_mem: 3094M
[32m[04/19 23:37:08 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:08:37 (0.5195 s / it)
[32m[04/19 23:37:08 d2.engine.hooks]: [0mTotal training time: 0:08:45 (0:00:07 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/19 23:37:12 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 23:37:12 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/19 23:37:12 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/19 23:37:14 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1172 s / img. ETA=0:16:34
[32m[04/19 23:37:19 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1176 s / img. ETA=0:16:35
[32m[04/19 23:37:24 d2.evaluation.evaluator]: [0mInference done 95/8355. 0.1174 s / img. ETA=0:16:28
[32m[04/19 23:37:29 d2.evaluation.evaluator]: [0mInference done 137/8355. 0.1174 s / img. ETA=0:16:24
[32m[04/19 23:37:34 d2.evaluation.evaluator]: [0mInference done 179/8355. 0.1174 s / img. ETA=0:16:20
[32m[04/19 23:37:39 d2.evaluation.evaluator]: [0mInference done 221/8355. 0.1175 s / img. ETA=0:16:16
[32m[04/19 23:37:44 d2.evaluation.evaluator]: [0mInference done 263/8355. 0.1175 s / img. ETA=0:16:10
[32m[04/19 23:37:49 d2.evaluation.evaluator]: [0mInference done 305/8355. 0.1176 s / img. ETA=0:16:06
[32m[04/19 23:37:54 d2.evaluation.evaluator]: [0mInference done 347/8355. 0.1175 s / img. ETA=0:16:01
[32m[04/19 23:37:59 d2.evaluation.evaluator]: [0mInference done 389/8355. 0.1176 s / img. ETA=0:15:56
[32m[04/19 23:38:04 d2.evaluation.evaluator]: [0mInference done 431/8355. 0.1176 s / img. ETA=0:15:51
[32m[04/19 23:38:09 d2.evaluation.evaluator]: [0mInference done 473/8355. 0.1176 s / img. ETA=0:15:46
[32m[04/19 23:38:14 d2.evaluation.evaluator]: [0mInference done 515/8355. 0.1176 s / img. ETA=0:15:41
[32m[04/19 23:38:20 d2.evaluation.evaluator]: [0mInference done 557/8355. 0.1176 s / img. ETA=0:15:36
[32m[04/19 23:38:25 d2.evaluation.evaluator]: [0mInference done 599/8355. 0.1176 s / img. ETA=0:15:31
[32m[04/19 23:38:30 d2.evaluation.evaluator]: [0mInference done 641/8355. 0.1176 s / img. ETA=0:15:26
[32m[04/19 23:38:35 d2.evaluation.evaluator]: [0mInference done 683/8355. 0.1176 s / img. ETA=0:15:21
[32m[04/19 23:38:40 d2.evaluation.evaluator]: [0mInference done 725/8355. 0.1176 s / img. ETA=0:15:16
[32m[04/19 23:38:45 d2.evaluation.evaluator]: [0mInference done 767/8355. 0.1176 s / img. ETA=0:15:11
[32m[04/19 23:38:50 d2.evaluation.evaluator]: [0mInference done 809/8355. 0.1177 s / img. ETA=0:15:06
[32m[04/19 23:38:55 d2.evaluation.evaluator]: [0mInference done 851/8355. 0.1177 s / img. ETA=0:15:01
[32m[04/19 23:39:00 d2.evaluation.evaluator]: [0mInference done 893/8355. 0.1177 s / img. ETA=0:14:57
[32m[04/19 23:39:05 d2.evaluation.evaluator]: [0mInference done 935/8355. 0.1177 s / img. ETA=0:14:51
[32m[04/19 23:39:10 d2.evaluation.evaluator]: [0mInference done 977/8355. 0.1177 s / img. ETA=0:14:46
[32m[04/19 23:39:15 d2.evaluation.evaluator]: [0mInference done 1019/8355. 0.1177 s / img. ETA=0:14:41
[32m[04/19 23:39:20 d2.evaluation.evaluator]: [0mInference done 1061/8355. 0.1177 s / img. ETA=0:14:36
[32m[04/19 23:39:25 d2.evaluation.evaluator]: [0mInference done 1103/8355. 0.1177 s / img. ETA=0:14:31
[32m[04/19 23:39:30 d2.evaluation.evaluator]: [0mInference done 1145/8355. 0.1178 s / img. ETA=0:14:27
[32m[04/19 23:39:35 d2.evaluation.evaluator]: [0mInference done 1187/8355. 0.1178 s / img. ETA=0:14:21
[32m[04/19 23:39:40 d2.evaluation.evaluator]: [0mInference done 1229/8355. 0.1178 s / img. ETA=0:14:16
[32m[04/19 23:39:45 d2.evaluation.evaluator]: [0mInference done 1271/8355. 0.1178 s / img. ETA=0:14:11
[32m[04/19 23:39:51 d2.evaluation.evaluator]: [0mInference done 1313/8355. 0.1178 s / img. ETA=0:14:06
[32m[04/19 23:39:56 d2.evaluation.evaluator]: [0mInference done 1355/8355. 0.1178 s / img. ETA=0:14:01
[32m[04/19 23:40:01 d2.evaluation.evaluator]: [0mInference done 1397/8355. 0.1178 s / img. ETA=0:13:56
[32m[04/19 23:40:06 d2.evaluation.evaluator]: [0mInference done 1439/8355. 0.1177 s / img. ETA=0:13:51
[32m[04/19 23:40:11 d2.evaluation.evaluator]: [0mInference done 1481/8355. 0.1178 s / img. ETA=0:13:46
[32m[04/19 23:40:16 d2.evaluation.evaluator]: [0mInference done 1523/8355. 0.1178 s / img. ETA=0:13:41
[32m[04/19 23:40:21 d2.evaluation.evaluator]: [0mInference done 1565/8355. 0.1178 s / img. ETA=0:13:36
[32m[04/19 23:40:26 d2.evaluation.evaluator]: [0mInference done 1607/8355. 0.1178 s / img. ETA=0:13:31
[32m[04/19 23:40:31 d2.evaluation.evaluator]: [0mInference done 1649/8355. 0.1178 s / img. ETA=0:13:26
[32m[04/19 23:40:36 d2.evaluation.evaluator]: [0mInference done 1691/8355. 0.1178 s / img. ETA=0:13:21
[32m[04/19 23:40:41 d2.evaluation.evaluator]: [0mInference done 1733/8355. 0.1178 s / img. ETA=0:13:16
[32m[04/19 23:40:46 d2.evaluation.evaluator]: [0mInference done 1775/8355. 0.1178 s / img. ETA=0:13:11
[32m[04/19 23:40:51 d2.evaluation.evaluator]: [0mInference done 1817/8355. 0.1178 s / img. ETA=0:13:06
[32m[04/19 23:40:56 d2.evaluation.evaluator]: [0mInference done 1859/8355. 0.1179 s / img. ETA=0:13:01
[32m[04/19 23:41:01 d2.evaluation.evaluator]: [0mInference done 1901/8355. 0.1179 s / img. ETA=0:12:56
[32m[04/19 23:41:07 d2.evaluation.evaluator]: [0mInference done 1943/8355. 0.1179 s / img. ETA=0:12:51
[32m[04/19 23:41:12 d2.evaluation.evaluator]: [0mInference done 1985/8355. 0.1179 s / img. ETA=0:12:46
[32m[04/19 23:41:17 d2.evaluation.evaluator]: [0mInference done 2027/8355. 0.1179 s / img. ETA=0:12:41
[32m[04/19 23:41:22 d2.evaluation.evaluator]: [0mInference done 2069/8355. 0.1179 s / img. ETA=0:12:36
[32m[04/19 23:41:27 d2.evaluation.evaluator]: [0mInference done 2111/8355. 0.1179 s / img. ETA=0:12:31
[32m[04/19 23:41:32 d2.evaluation.evaluator]: [0mInference done 2153/8355. 0.1179 s / img. ETA=0:12:26
[32m[04/19 23:41:37 d2.evaluation.evaluator]: [0mInference done 2195/8355. 0.1179 s / img. ETA=0:12:21
[32m[04/19 23:41:42 d2.evaluation.evaluator]: [0mInference done 2237/8355. 0.1179 s / img. ETA=0:12:16
[32m[04/19 23:41:47 d2.evaluation.evaluator]: [0mInference done 2279/8355. 0.1179 s / img. ETA=0:12:11
[32m[04/19 23:41:52 d2.evaluation.evaluator]: [0mInference done 2321/8355. 0.1179 s / img. ETA=0:12:06
[32m[04/19 23:41:57 d2.evaluation.evaluator]: [0mInference done 2363/8355. 0.1179 s / img. ETA=0:12:01
[32m[04/19 23:42:02 d2.evaluation.evaluator]: [0mInference done 2405/8355. 0.1179 s / img. ETA=0:11:56
[32m[04/19 23:42:07 d2.evaluation.evaluator]: [0mInference done 2447/8355. 0.1179 s / img. ETA=0:11:51
[32m[04/19 23:42:12 d2.evaluation.evaluator]: [0mInference done 2489/8355. 0.1179 s / img. ETA=0:11:46
[32m[04/19 23:42:17 d2.evaluation.evaluator]: [0mInference done 2531/8355. 0.1179 s / img. ETA=0:11:41
[32m[04/19 23:42:22 d2.evaluation.evaluator]: [0mInference done 2573/8355. 0.1179 s / img. ETA=0:11:36
[32m[04/19 23:42:28 d2.evaluation.evaluator]: [0mInference done 2615/8355. 0.1179 s / img. ETA=0:11:31
[32m[04/19 23:42:33 d2.evaluation.evaluator]: [0mInference done 2657/8355. 0.1179 s / img. ETA=0:11:26
[32m[04/19 23:42:38 d2.evaluation.evaluator]: [0mInference done 2699/8355. 0.1179 s / img. ETA=0:11:21
[32m[04/19 23:42:43 d2.evaluation.evaluator]: [0mInference done 2741/8355. 0.1179 s / img. ETA=0:11:16
[32m[04/19 23:42:48 d2.evaluation.evaluator]: [0mInference done 2783/8355. 0.1179 s / img. ETA=0:11:11
[32m[04/19 23:42:53 d2.evaluation.evaluator]: [0mInference done 2825/8355. 0.1179 s / img. ETA=0:11:06
[32m[04/19 23:42:58 d2.evaluation.evaluator]: [0mInference done 2867/8355. 0.1179 s / img. ETA=0:11:01
[32m[04/19 23:43:03 d2.evaluation.evaluator]: [0mInference done 2909/8355. 0.1179 s / img. ETA=0:10:56
[32m[04/19 23:43:08 d2.evaluation.evaluator]: [0mInference done 2951/8355. 0.1179 s / img. ETA=0:10:50
[32m[04/19 23:43:13 d2.evaluation.evaluator]: [0mInference done 2993/8355. 0.1179 s / img. ETA=0:10:45
[32m[04/19 23:43:18 d2.evaluation.evaluator]: [0mInference done 3035/8355. 0.1179 s / img. ETA=0:10:40
[32m[04/19 23:43:23 d2.evaluation.evaluator]: [0mInference done 3077/8355. 0.1179 s / img. ETA=0:10:35
[32m[04/19 23:43:28 d2.evaluation.evaluator]: [0mInference done 3119/8355. 0.1179 s / img. ETA=0:10:30
[32m[04/19 23:43:33 d2.evaluation.evaluator]: [0mInference done 3161/8355. 0.1179 s / img. ETA=0:10:25
[32m[04/19 23:43:38 d2.evaluation.evaluator]: [0mInference done 3203/8355. 0.1179 s / img. ETA=0:10:20
[32m[04/19 23:43:44 d2.evaluation.evaluator]: [0mInference done 3245/8355. 0.1179 s / img. ETA=0:10:15
[32m[04/19 23:43:49 d2.evaluation.evaluator]: [0mInference done 3287/8355. 0.1179 s / img. ETA=0:10:10
[32m[04/19 23:43:54 d2.evaluation.evaluator]: [0mInference done 3329/8355. 0.1179 s / img. ETA=0:10:05
[32m[04/19 23:43:59 d2.evaluation.evaluator]: [0mInference done 3371/8355. 0.1179 s / img. ETA=0:10:00
[32m[04/19 23:44:04 d2.evaluation.evaluator]: [0mInference done 3413/8355. 0.1179 s / img. ETA=0:09:55
[32m[04/19 23:44:09 d2.evaluation.evaluator]: [0mInference done 3455/8355. 0.1179 s / img. ETA=0:09:50
[32m[04/19 23:44:14 d2.evaluation.evaluator]: [0mInference done 3497/8355. 0.1179 s / img. ETA=0:09:45
[32m[04/19 23:44:19 d2.evaluation.evaluator]: [0mInference done 3539/8355. 0.1179 s / img. ETA=0:09:40
[32m[04/19 23:44:24 d2.evaluation.evaluator]: [0mInference done 3581/8355. 0.1179 s / img. ETA=0:09:35
[32m[04/19 23:44:29 d2.evaluation.evaluator]: [0mInference done 3623/8355. 0.1179 s / img. ETA=0:09:30
[32m[04/19 23:44:34 d2.evaluation.evaluator]: [0mInference done 3665/8355. 0.1179 s / img. ETA=0:09:25
[32m[04/19 23:44:39 d2.evaluation.evaluator]: [0mInference done 3707/8355. 0.1179 s / img. ETA=0:09:20
[32m[04/19 23:44:44 d2.evaluation.evaluator]: [0mInference done 3749/8355. 0.1179 s / img. ETA=0:09:15
[32m[04/19 23:44:50 d2.evaluation.evaluator]: [0mInference done 3791/8355. 0.1179 s / img. ETA=0:09:10
[32m[04/19 23:44:55 d2.evaluation.evaluator]: [0mInference done 3833/8355. 0.1179 s / img. ETA=0:09:05
[32m[04/19 23:45:00 d2.evaluation.evaluator]: [0mInference done 3875/8355. 0.1179 s / img. ETA=0:08:59
[32m[04/19 23:45:05 d2.evaluation.evaluator]: [0mInference done 3917/8355. 0.1179 s / img. ETA=0:08:54
[32m[04/19 23:45:10 d2.evaluation.evaluator]: [0mInference done 3959/8355. 0.1179 s / img. ETA=0:08:49
[32m[04/19 23:45:15 d2.evaluation.evaluator]: [0mInference done 4001/8355. 0.1179 s / img. ETA=0:08:44
[32m[04/19 23:45:20 d2.evaluation.evaluator]: [0mInference done 4043/8355. 0.1179 s / img. ETA=0:08:39
[32m[04/19 23:45:25 d2.evaluation.evaluator]: [0mInference done 4085/8355. 0.1179 s / img. ETA=0:08:34
[32m[04/19 23:45:30 d2.evaluation.evaluator]: [0mInference done 4127/8355. 0.1179 s / img. ETA=0:08:29
[32m[04/19 23:45:35 d2.evaluation.evaluator]: [0mInference done 4169/8355. 0.1179 s / img. ETA=0:08:24
[32m[04/19 23:45:40 d2.evaluation.evaluator]: [0mInference done 4211/8355. 0.1179 s / img. ETA=0:08:19
[32m[04/19 23:45:45 d2.evaluation.evaluator]: [0mInference done 4253/8355. 0.1179 s / img. ETA=0:08:14
[32m[04/19 23:45:50 d2.evaluation.evaluator]: [0mInference done 4295/8355. 0.1179 s / img. ETA=0:08:09
[32m[04/19 23:45:55 d2.evaluation.evaluator]: [0mInference done 4337/8355. 0.1179 s / img. ETA=0:08:04
[32m[04/19 23:46:00 d2.evaluation.evaluator]: [0mInference done 4379/8355. 0.1179 s / img. ETA=0:07:59
[32m[04/19 23:46:06 d2.evaluation.evaluator]: [0mInference done 4421/8355. 0.1179 s / img. ETA=0:07:54
[32m[04/19 23:46:11 d2.evaluation.evaluator]: [0mInference done 4463/8355. 0.1179 s / img. ETA=0:07:49
[32m[04/19 23:46:16 d2.evaluation.evaluator]: [0mInference done 4505/8355. 0.1179 s / img. ETA=0:07:44
[32m[04/19 23:46:21 d2.evaluation.evaluator]: [0mInference done 4547/8355. 0.1180 s / img. ETA=0:07:39
[32m[04/19 23:46:26 d2.evaluation.evaluator]: [0mInference done 4589/8355. 0.1180 s / img. ETA=0:07:34
[32m[04/19 23:46:31 d2.evaluation.evaluator]: [0mInference done 4631/8355. 0.1180 s / img. ETA=0:07:28
[32m[04/19 23:46:36 d2.evaluation.evaluator]: [0mInference done 4673/8355. 0.1180 s / img. ETA=0:07:23
[32m[04/19 23:46:41 d2.evaluation.evaluator]: [0mInference done 4715/8355. 0.1180 s / img. ETA=0:07:18
[32m[04/19 23:46:46 d2.evaluation.evaluator]: [0mInference done 4757/8355. 0.1180 s / img. ETA=0:07:13
[32m[04/19 23:46:51 d2.evaluation.evaluator]: [0mInference done 4799/8355. 0.1180 s / img. ETA=0:07:08
[32m[04/19 23:46:56 d2.evaluation.evaluator]: [0mInference done 4841/8355. 0.1180 s / img. ETA=0:07:03
[32m[04/19 23:47:01 d2.evaluation.evaluator]: [0mInference done 4883/8355. 0.1180 s / img. ETA=0:06:58
[32m[04/19 23:47:06 d2.evaluation.evaluator]: [0mInference done 4925/8355. 0.1180 s / img. ETA=0:06:53
[32m[04/19 23:47:12 d2.evaluation.evaluator]: [0mInference done 4967/8355. 0.1180 s / img. ETA=0:06:48
[32m[04/19 23:47:17 d2.evaluation.evaluator]: [0mInference done 5009/8355. 0.1180 s / img. ETA=0:06:43
[32m[04/19 23:47:22 d2.evaluation.evaluator]: [0mInference done 5051/8355. 0.1180 s / img. ETA=0:06:38
[32m[04/19 23:47:27 d2.evaluation.evaluator]: [0mInference done 5093/8355. 0.1180 s / img. ETA=0:06:33
[32m[04/19 23:47:32 d2.evaluation.evaluator]: [0mInference done 5135/8355. 0.1180 s / img. ETA=0:06:28
[32m[04/19 23:47:37 d2.evaluation.evaluator]: [0mInference done 5177/8355. 0.1180 s / img. ETA=0:06:23
[32m[04/19 23:47:42 d2.evaluation.evaluator]: [0mInference done 5219/8355. 0.1180 s / img. ETA=0:06:18
[32m[04/19 23:47:47 d2.evaluation.evaluator]: [0mInference done 5261/8355. 0.1180 s / img. ETA=0:06:13
[32m[04/19 23:47:52 d2.evaluation.evaluator]: [0mInference done 5303/8355. 0.1180 s / img. ETA=0:06:08
[32m[04/19 23:47:57 d2.evaluation.evaluator]: [0mInference done 5345/8355. 0.1180 s / img. ETA=0:06:03
[32m[04/19 23:48:02 d2.evaluation.evaluator]: [0mInference done 5387/8355. 0.1180 s / img. ETA=0:05:58
[32m[04/19 23:48:08 d2.evaluation.evaluator]: [0mInference done 5429/8355. 0.1180 s / img. ETA=0:05:52
[32m[04/19 23:48:13 d2.evaluation.evaluator]: [0mInference done 5471/8355. 0.1180 s / img. ETA=0:05:47
[32m[04/19 23:48:18 d2.evaluation.evaluator]: [0mInference done 5513/8355. 0.1180 s / img. ETA=0:05:42
[32m[04/19 23:48:23 d2.evaluation.evaluator]: [0mInference done 5555/8355. 0.1180 s / img. ETA=0:05:37
[32m[04/19 23:48:28 d2.evaluation.evaluator]: [0mInference done 5597/8355. 0.1180 s / img. ETA=0:05:32
[32m[04/19 23:48:33 d2.evaluation.evaluator]: [0mInference done 5636/8355. 0.1181 s / img. ETA=0:05:28
[32m[04/19 23:48:38 d2.evaluation.evaluator]: [0mInference done 5678/8355. 0.1181 s / img. ETA=0:05:23
[32m[04/19 23:48:43 d2.evaluation.evaluator]: [0mInference done 5720/8355. 0.1181 s / img. ETA=0:05:18
[32m[04/19 23:48:48 d2.evaluation.evaluator]: [0mInference done 5762/8355. 0.1181 s / img. ETA=0:05:13
[32m[04/19 23:48:53 d2.evaluation.evaluator]: [0mInference done 5804/8355. 0.1181 s / img. ETA=0:05:07
[32m[04/19 23:48:58 d2.evaluation.evaluator]: [0mInference done 5846/8355. 0.1181 s / img. ETA=0:05:02
[32m[04/19 23:49:03 d2.evaluation.evaluator]: [0mInference done 5888/8355. 0.1181 s / img. ETA=0:04:57
[32m[04/19 23:49:09 d2.evaluation.evaluator]: [0mInference done 5930/8355. 0.1181 s / img. ETA=0:04:52
[32m[04/19 23:49:14 d2.evaluation.evaluator]: [0mInference done 5972/8355. 0.1181 s / img. ETA=0:04:47
[32m[04/19 23:49:19 d2.evaluation.evaluator]: [0mInference done 6014/8355. 0.1181 s / img. ETA=0:04:42
[32m[04/19 23:49:24 d2.evaluation.evaluator]: [0mInference done 6056/8355. 0.1181 s / img. ETA=0:04:37
[32m[04/19 23:49:29 d2.evaluation.evaluator]: [0mInference done 6098/8355. 0.1181 s / img. ETA=0:04:32
[32m[04/19 23:49:34 d2.evaluation.evaluator]: [0mInference done 6140/8355. 0.1181 s / img. ETA=0:04:27
[32m[04/19 23:49:39 d2.evaluation.evaluator]: [0mInference done 6182/8355. 0.1181 s / img. ETA=0:04:22
[32m[04/19 23:49:44 d2.evaluation.evaluator]: [0mInference done 6224/8355. 0.1181 s / img. ETA=0:04:17
[32m[04/19 23:49:49 d2.evaluation.evaluator]: [0mInference done 6266/8355. 0.1181 s / img. ETA=0:04:12
[32m[04/19 23:49:54 d2.evaluation.evaluator]: [0mInference done 6308/8355. 0.1181 s / img. ETA=0:04:07
[32m[04/19 23:49:59 d2.evaluation.evaluator]: [0mInference done 6350/8355. 0.1181 s / img. ETA=0:04:02
[32m[04/19 23:50:04 d2.evaluation.evaluator]: [0mInference done 6392/8355. 0.1181 s / img. ETA=0:03:57
[32m[04/19 23:50:10 d2.evaluation.evaluator]: [0mInference done 6434/8355. 0.1181 s / img. ETA=0:03:51
[32m[04/19 23:50:15 d2.evaluation.evaluator]: [0mInference done 6476/8355. 0.1181 s / img. ETA=0:03:46
[32m[04/19 23:50:20 d2.evaluation.evaluator]: [0mInference done 6518/8355. 0.1181 s / img. ETA=0:03:41
[32m[04/19 23:50:25 d2.evaluation.evaluator]: [0mInference done 6560/8355. 0.1181 s / img. ETA=0:03:36
[32m[04/19 23:50:30 d2.evaluation.evaluator]: [0mInference done 6602/8355. 0.1181 s / img. ETA=0:03:31
[32m[04/19 23:50:35 d2.evaluation.evaluator]: [0mInference done 6644/8355. 0.1181 s / img. ETA=0:03:26
[32m[04/19 23:50:40 d2.evaluation.evaluator]: [0mInference done 6686/8355. 0.1181 s / img. ETA=0:03:21
[32m[04/19 23:50:45 d2.evaluation.evaluator]: [0mInference done 6728/8355. 0.1181 s / img. ETA=0:03:16
[32m[04/19 23:50:50 d2.evaluation.evaluator]: [0mInference done 6770/8355. 0.1181 s / img. ETA=0:03:11
[32m[04/19 23:50:55 d2.evaluation.evaluator]: [0mInference done 6812/8355. 0.1181 s / img. ETA=0:03:06
[32m[04/19 23:51:00 d2.evaluation.evaluator]: [0mInference done 6854/8355. 0.1181 s / img. ETA=0:03:01
[32m[04/19 23:51:05 d2.evaluation.evaluator]: [0mInference done 6896/8355. 0.1181 s / img. ETA=0:02:56
[32m[04/19 23:51:10 d2.evaluation.evaluator]: [0mInference done 6938/8355. 0.1181 s / img. ETA=0:02:51
[32m[04/19 23:51:16 d2.evaluation.evaluator]: [0mInference done 6980/8355. 0.1181 s / img. ETA=0:02:46
[32m[04/19 23:51:21 d2.evaluation.evaluator]: [0mInference done 7022/8355. 0.1181 s / img. ETA=0:02:40
[32m[04/19 23:51:26 d2.evaluation.evaluator]: [0mInference done 7064/8355. 0.1181 s / img. ETA=0:02:35
[32m[04/19 23:51:31 d2.evaluation.evaluator]: [0mInference done 7106/8355. 0.1181 s / img. ETA=0:02:30
[32m[04/19 23:51:36 d2.evaluation.evaluator]: [0mInference done 7148/8355. 0.1182 s / img. ETA=0:02:25
[32m[04/19 23:51:41 d2.evaluation.evaluator]: [0mInference done 7190/8355. 0.1182 s / img. ETA=0:02:20
[32m[04/19 23:51:46 d2.evaluation.evaluator]: [0mInference done 7232/8355. 0.1182 s / img. ETA=0:02:15
[32m[04/19 23:51:51 d2.evaluation.evaluator]: [0mInference done 7274/8355. 0.1182 s / img. ETA=0:02:10
[32m[04/19 23:51:56 d2.evaluation.evaluator]: [0mInference done 7316/8355. 0.1182 s / img. ETA=0:02:05
[32m[04/19 23:52:01 d2.evaluation.evaluator]: [0mInference done 7358/8355. 0.1182 s / img. ETA=0:02:00
[32m[04/19 23:52:06 d2.evaluation.evaluator]: [0mInference done 7399/8355. 0.1182 s / img. ETA=0:01:55
[32m[04/19 23:52:11 d2.evaluation.evaluator]: [0mInference done 7440/8355. 0.1182 s / img. ETA=0:01:50
[32m[04/19 23:52:17 d2.evaluation.evaluator]: [0mInference done 7482/8355. 0.1182 s / img. ETA=0:01:45
[32m[04/19 23:52:22 d2.evaluation.evaluator]: [0mInference done 7524/8355. 0.1182 s / img. ETA=0:01:40
[32m[04/19 23:52:27 d2.evaluation.evaluator]: [0mInference done 7566/8355. 0.1182 s / img. ETA=0:01:35
[32m[04/19 23:52:32 d2.evaluation.evaluator]: [0mInference done 7608/8355. 0.1182 s / img. ETA=0:01:30
[32m[04/19 23:52:37 d2.evaluation.evaluator]: [0mInference done 7650/8355. 0.1182 s / img. ETA=0:01:25
[32m[04/19 23:52:42 d2.evaluation.evaluator]: [0mInference done 7692/8355. 0.1182 s / img. ETA=0:01:20
[32m[04/19 23:52:47 d2.evaluation.evaluator]: [0mInference done 7734/8355. 0.1182 s / img. ETA=0:01:15
[32m[04/19 23:52:52 d2.evaluation.evaluator]: [0mInference done 7776/8355. 0.1182 s / img. ETA=0:01:09
[32m[04/19 23:52:57 d2.evaluation.evaluator]: [0mInference done 7818/8355. 0.1182 s / img. ETA=0:01:04
[32m[04/19 23:53:02 d2.evaluation.evaluator]: [0mInference done 7860/8355. 0.1182 s / img. ETA=0:00:59
[32m[04/19 23:53:08 d2.evaluation.evaluator]: [0mInference done 7902/8355. 0.1182 s / img. ETA=0:00:54
[32m[04/19 23:53:13 d2.evaluation.evaluator]: [0mInference done 7944/8355. 0.1182 s / img. ETA=0:00:49
[32m[04/19 23:53:18 d2.evaluation.evaluator]: [0mInference done 7985/8355. 0.1182 s / img. ETA=0:00:44
[32m[04/19 23:53:23 d2.evaluation.evaluator]: [0mInference done 8027/8355. 0.1182 s / img. ETA=0:00:39
[32m[04/19 23:53:28 d2.evaluation.evaluator]: [0mInference done 8069/8355. 0.1182 s / img. ETA=0:00:34
[32m[04/19 23:53:33 d2.evaluation.evaluator]: [0mInference done 8111/8355. 0.1182 s / img. ETA=0:00:29
[32m[04/19 23:53:38 d2.evaluation.evaluator]: [0mInference done 8153/8355. 0.1182 s / img. ETA=0:00:24
[32m[04/19 23:53:43 d2.evaluation.evaluator]: [0mInference done 8195/8355. 0.1182 s / img. ETA=0:00:19
[32m[04/19 23:53:48 d2.evaluation.evaluator]: [0mInference done 8237/8355. 0.1182 s / img. ETA=0:00:14
[32m[04/19 23:53:53 d2.evaluation.evaluator]: [0mInference done 8279/8355. 0.1182 s / img. ETA=0:00:09
[32m[04/19 23:53:58 d2.evaluation.evaluator]: [0mInference done 8321/8355. 0.1182 s / img. ETA=0:00:04
[32m[04/19 23:54:02 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:49.254529 (0.120869 s / img per device, on 1 devices)
[32m[04/19 23:54:02 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:27 (0.118234 s / img per device, on 1 devices)
[32m[04/19 23:54:03 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/19 23:54:03 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/19 23:54:03 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.84s).
Accumulating evaluation results...
DONE (t=2.34s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.215
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.438
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.179
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.159
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.265
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.105
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.254
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.310
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598
[32m[04/19 23:54:26 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 21.491 | 43.799 | 17.948 | 15.886 | 26.516 | 49.990 |
[32m[04/19 23:54:26 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 30.273 | bicycle       | 8.501  | car            | 34.911 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | 12.278 | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/19 23:54:28 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 23:54:28 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[32m[04/19 23:54:28 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/19 23:54:30 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1174 s / img. ETA=0:02:28
[32m[04/19 23:54:35 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1182 s / img. ETA=0:02:25
[32m[04/19 23:54:40 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1185 s / img. ETA=0:02:20
[32m[04/19 23:54:45 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1186 s / img. ETA=0:02:15
[32m[04/19 23:54:50 d2.evaluation.evaluator]: [0mInference done 179/1257. 0.1185 s / img. ETA=0:02:10
[32m[04/19 23:54:55 d2.evaluation.evaluator]: [0mInference done 221/1257. 0.1185 s / img. ETA=0:02:05
[32m[04/19 23:55:00 d2.evaluation.evaluator]: [0mInference done 263/1257. 0.1186 s / img. ETA=0:02:00
[32m[04/19 23:55:05 d2.evaluation.evaluator]: [0mInference done 305/1257. 0.1186 s / img. ETA=0:01:55
[32m[04/19 23:55:10 d2.evaluation.evaluator]: [0mInference done 347/1257. 0.1185 s / img. ETA=0:01:50
[32m[04/19 23:55:15 d2.evaluation.evaluator]: [0mInference done 389/1257. 0.1185 s / img. ETA=0:01:45
[32m[04/19 23:55:20 d2.evaluation.evaluator]: [0mInference done 431/1257. 0.1185 s / img. ETA=0:01:40
[32m[04/19 23:55:25 d2.evaluation.evaluator]: [0mInference done 472/1257. 0.1186 s / img. ETA=0:01:35
[32m[04/19 23:55:31 d2.evaluation.evaluator]: [0mInference done 514/1257. 0.1185 s / img. ETA=0:01:30
[32m[04/19 23:55:36 d2.evaluation.evaluator]: [0mInference done 556/1257. 0.1185 s / img. ETA=0:01:25
[32m[04/19 23:55:41 d2.evaluation.evaluator]: [0mInference done 598/1257. 0.1185 s / img. ETA=0:01:19
[32m[04/19 23:55:46 d2.evaluation.evaluator]: [0mInference done 640/1257. 0.1185 s / img. ETA=0:01:14
[32m[04/19 23:55:51 d2.evaluation.evaluator]: [0mInference done 682/1257. 0.1185 s / img. ETA=0:01:09
[32m[04/19 23:55:56 d2.evaluation.evaluator]: [0mInference done 724/1257. 0.1184 s / img. ETA=0:01:04
[32m[04/19 23:56:01 d2.evaluation.evaluator]: [0mInference done 766/1257. 0.1184 s / img. ETA=0:00:59
[32m[04/19 23:56:06 d2.evaluation.evaluator]: [0mInference done 808/1257. 0.1184 s / img. ETA=0:00:54
[32m[04/19 23:56:11 d2.evaluation.evaluator]: [0mInference done 850/1257. 0.1184 s / img. ETA=0:00:49
[32m[04/19 23:56:16 d2.evaluation.evaluator]: [0mInference done 892/1257. 0.1184 s / img. ETA=0:00:44
[32m[04/19 23:56:21 d2.evaluation.evaluator]: [0mInference done 934/1257. 0.1183 s / img. ETA=0:00:39
[32m[04/19 23:56:26 d2.evaluation.evaluator]: [0mInference done 976/1257. 0.1183 s / img. ETA=0:00:34
[32m[04/19 23:56:31 d2.evaluation.evaluator]: [0mInference done 1018/1257. 0.1183 s / img. ETA=0:00:28
[32m[04/19 23:56:36 d2.evaluation.evaluator]: [0mInference done 1060/1257. 0.1182 s / img. ETA=0:00:23
[32m[04/19 23:56:41 d2.evaluation.evaluator]: [0mInference done 1102/1257. 0.1182 s / img. ETA=0:00:18
[32m[04/19 23:56:47 d2.evaluation.evaluator]: [0mInference done 1144/1257. 0.1182 s / img. ETA=0:00:13
[32m[04/19 23:56:52 d2.evaluation.evaluator]: [0mInference done 1186/1257. 0.1182 s / img. ETA=0:00:08
[32m[04/19 23:56:57 d2.evaluation.evaluator]: [0mInference done 1228/1257. 0.1182 s / img. ETA=0:00:03
[32m[04/19 23:57:00 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:31.402897 (0.120929 s / img per device, on 1 devices)
[32m[04/19 23:57:00 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:27 (0.118186 s / img per device, on 1 devices)
[32m[04/19 23:57:00 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/19 23:57:00 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/19 23:57:00 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.15s).
Accumulating evaluation results...
DONE (t=0.41s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.170
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.340
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.150
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.109
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.202
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.403
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.081
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.208
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.211
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.238
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.456
[32m[04/19 23:57:04 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 17.031 | 34.034 | 15.003 | 10.911 | 20.197 | 40.298 |
[32m[04/19 23:57:04 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 24.220 | bicycle       | 5.869 | car            | 38.035 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | 0.000 | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  5  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/19 23:57:05 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/19 23:57:05 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/19 23:57:05 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/19 23:57:06 d2.data.build]: [0mRemoved 889 images with no usable annotations. 7466 images left.
[32m[04/19 23:57:06 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/19 23:57:06 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/19 23:57:06 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/19 23:57:17 d2.utils.events]: [0m eta: 0:08:28  iter: 19  total_loss: 0.865  loss_cls: 0.273  loss_box_reg: 0.461  loss_rpn_cls: 0.038  loss_rpn_loc: 0.065  time: 0.5187  data_time: 0.0152  lr: 0.000100  max_mem: 3094M
[32m[04/19 23:57:27 d2.utils.events]: [0m eta: 0:08:21  iter: 39  total_loss: 0.878  loss_cls: 0.273  loss_box_reg: 0.442  loss_rpn_cls: 0.032  loss_rpn_loc: 0.087  time: 0.5183  data_time: 0.0051  lr: 0.000200  max_mem: 3094M
[32m[04/19 23:57:37 d2.utils.events]: [0m eta: 0:08:09  iter: 59  total_loss: 0.624  loss_cls: 0.221  loss_box_reg: 0.324  loss_rpn_cls: 0.028  loss_rpn_loc: 0.076  time: 0.5184  data_time: 0.0052  lr: 0.000300  max_mem: 3094M
[32m[04/19 23:57:48 d2.utils.events]: [0m eta: 0:08:01  iter: 79  total_loss: 0.841  loss_cls: 0.288  loss_box_reg: 0.428  loss_rpn_cls: 0.033  loss_rpn_loc: 0.067  time: 0.5212  data_time: 0.0053  lr: 0.000400  max_mem: 3094M
[32m[04/19 23:57:59 d2.utils.events]: [0m eta: 0:07:50  iter: 99  total_loss: 0.650  loss_cls: 0.213  loss_box_reg: 0.323  loss_rpn_cls: 0.024  loss_rpn_loc: 0.052  time: 0.5209  data_time: 0.0053  lr: 0.000500  max_mem: 3094M
[32m[04/19 23:58:09 d2.utils.events]: [0m eta: 0:07:39  iter: 119  total_loss: 0.725  loss_cls: 0.241  loss_box_reg: 0.377  loss_rpn_cls: 0.034  loss_rpn_loc: 0.055  time: 0.5202  data_time: 0.0054  lr: 0.000599  max_mem: 3094M
[32m[04/19 23:58:19 d2.utils.events]: [0m eta: 0:07:26  iter: 139  total_loss: 0.772  loss_cls: 0.260  loss_box_reg: 0.372  loss_rpn_cls: 0.029  loss_rpn_loc: 0.071  time: 0.5170  data_time: 0.0051  lr: 0.000699  max_mem: 3094M
[32m[04/19 23:58:30 d2.utils.events]: [0m eta: 0:07:15  iter: 159  total_loss: 0.729  loss_cls: 0.251  loss_box_reg: 0.387  loss_rpn_cls: 0.030  loss_rpn_loc: 0.054  time: 0.5189  data_time: 0.0054  lr: 0.000799  max_mem: 3094M
[32m[04/19 23:58:40 d2.utils.events]: [0m eta: 0:07:05  iter: 179  total_loss: 0.734  loss_cls: 0.222  loss_box_reg: 0.394  loss_rpn_cls: 0.036  loss_rpn_loc: 0.061  time: 0.5202  data_time: 0.0053  lr: 0.000899  max_mem: 3094M
[32m[04/19 23:58:51 d2.utils.events]: [0m eta: 0:06:56  iter: 199  total_loss: 0.856  loss_cls: 0.282  loss_box_reg: 0.463  loss_rpn_cls: 0.025  loss_rpn_loc: 0.063  time: 0.5217  data_time: 0.0053  lr: 0.000999  max_mem: 3094M
[32m[04/19 23:59:01 d2.utils.events]: [0m eta: 0:06:46  iter: 219  total_loss: 0.684  loss_cls: 0.229  loss_box_reg: 0.385  loss_rpn_cls: 0.027  loss_rpn_loc: 0.050  time: 0.5213  data_time: 0.0053  lr: 0.001099  max_mem: 3094M
[32m[04/19 23:59:12 d2.utils.events]: [0m eta: 0:06:35  iter: 239  total_loss: 0.710  loss_cls: 0.226  loss_box_reg: 0.368  loss_rpn_cls: 0.032  loss_rpn_loc: 0.059  time: 0.5209  data_time: 0.0049  lr: 0.001199  max_mem: 3094M
[32m[04/19 23:59:22 d2.utils.events]: [0m eta: 0:06:26  iter: 259  total_loss: 0.718  loss_cls: 0.236  loss_box_reg: 0.388  loss_rpn_cls: 0.026  loss_rpn_loc: 0.056  time: 0.5216  data_time: 0.0054  lr: 0.001299  max_mem: 3094M
[32m[04/19 23:59:33 d2.utils.events]: [0m eta: 0:06:14  iter: 279  total_loss: 0.564  loss_cls: 0.201  loss_box_reg: 0.324  loss_rpn_cls: 0.022  loss_rpn_loc: 0.054  time: 0.5209  data_time: 0.0051  lr: 0.001399  max_mem: 3094M
[32m[04/19 23:59:43 d2.utils.events]: [0m eta: 0:06:04  iter: 299  total_loss: 0.732  loss_cls: 0.251  loss_box_reg: 0.377  loss_rpn_cls: 0.023  loss_rpn_loc: 0.050  time: 0.5201  data_time: 0.0050  lr: 0.001499  max_mem: 3094M
[32m[04/19 23:59:54 d2.utils.events]: [0m eta: 0:05:54  iter: 319  total_loss: 0.657  loss_cls: 0.229  loss_box_reg: 0.371  loss_rpn_cls: 0.022  loss_rpn_loc: 0.055  time: 0.5207  data_time: 0.0049  lr: 0.001598  max_mem: 3094M
[32m[04/20 00:00:04 d2.utils.events]: [0m eta: 0:05:44  iter: 339  total_loss: 0.671  loss_cls: 0.219  loss_box_reg: 0.363  loss_rpn_cls: 0.019  loss_rpn_loc: 0.056  time: 0.5206  data_time: 0.0051  lr: 0.001698  max_mem: 3094M
[32m[04/20 00:00:15 d2.utils.events]: [0m eta: 0:05:33  iter: 359  total_loss: 0.679  loss_cls: 0.220  loss_box_reg: 0.352  loss_rpn_cls: 0.021  loss_rpn_loc: 0.066  time: 0.5210  data_time: 0.0051  lr: 0.001798  max_mem: 3094M
[32m[04/20 00:00:25 d2.utils.events]: [0m eta: 0:05:23  iter: 379  total_loss: 0.651  loss_cls: 0.240  loss_box_reg: 0.326  loss_rpn_cls: 0.022  loss_rpn_loc: 0.057  time: 0.5212  data_time: 0.0051  lr: 0.001898  max_mem: 3094M
[32m[04/20 00:00:35 d2.utils.events]: [0m eta: 0:05:12  iter: 399  total_loss: 0.590  loss_cls: 0.204  loss_box_reg: 0.303  loss_rpn_cls: 0.022  loss_rpn_loc: 0.052  time: 0.5205  data_time: 0.0050  lr: 0.001998  max_mem: 3094M
[32m[04/20 00:00:46 d2.utils.events]: [0m eta: 0:05:02  iter: 419  total_loss: 0.645  loss_cls: 0.223  loss_box_reg: 0.335  loss_rpn_cls: 0.020  loss_rpn_loc: 0.055  time: 0.5208  data_time: 0.0052  lr: 0.002098  max_mem: 3094M
[32m[04/20 00:00:56 d2.utils.events]: [0m eta: 0:04:51  iter: 439  total_loss: 0.656  loss_cls: 0.221  loss_box_reg: 0.356  loss_rpn_cls: 0.022  loss_rpn_loc: 0.056  time: 0.5199  data_time: 0.0052  lr: 0.002198  max_mem: 3094M
[32m[04/20 00:01:07 d2.utils.events]: [0m eta: 0:04:41  iter: 459  total_loss: 0.700  loss_cls: 0.245  loss_box_reg: 0.356  loss_rpn_cls: 0.022  loss_rpn_loc: 0.050  time: 0.5200  data_time: 0.0051  lr: 0.002298  max_mem: 3094M
[32m[04/20 00:01:17 d2.utils.events]: [0m eta: 0:04:31  iter: 479  total_loss: 0.735  loss_cls: 0.227  loss_box_reg: 0.381  loss_rpn_cls: 0.031  loss_rpn_loc: 0.056  time: 0.5206  data_time: 0.0051  lr: 0.002398  max_mem: 3094M
[32m[04/20 00:01:28 d2.utils.events]: [0m eta: 0:04:20  iter: 499  total_loss: 0.757  loss_cls: 0.239  loss_box_reg: 0.396  loss_rpn_cls: 0.033  loss_rpn_loc: 0.063  time: 0.5203  data_time: 0.0049  lr: 0.002498  max_mem: 3094M
[32m[04/20 00:01:38 d2.utils.events]: [0m eta: 0:04:10  iter: 519  total_loss: 0.725  loss_cls: 0.238  loss_box_reg: 0.399  loss_rpn_cls: 0.032  loss_rpn_loc: 0.064  time: 0.5203  data_time: 0.0051  lr: 0.002597  max_mem: 3094M
[32m[04/20 00:01:49 d2.utils.events]: [0m eta: 0:04:00  iter: 539  total_loss: 0.664  loss_cls: 0.224  loss_box_reg: 0.356  loss_rpn_cls: 0.025  loss_rpn_loc: 0.060  time: 0.5204  data_time: 0.0052  lr: 0.002697  max_mem: 3094M
[32m[04/20 00:01:59 d2.utils.events]: [0m eta: 0:03:49  iter: 559  total_loss: 0.657  loss_cls: 0.212  loss_box_reg: 0.334  loss_rpn_cls: 0.033  loss_rpn_loc: 0.061  time: 0.5207  data_time: 0.0052  lr: 0.002797  max_mem: 3094M
[32m[04/20 00:02:10 d2.utils.events]: [0m eta: 0:03:39  iter: 579  total_loss: 0.671  loss_cls: 0.211  loss_box_reg: 0.356  loss_rpn_cls: 0.025  loss_rpn_loc: 0.047  time: 0.5207  data_time: 0.0051  lr: 0.002897  max_mem: 3094M
[32m[04/20 00:02:21 d2.utils.events]: [0m eta: 0:03:29  iter: 599  total_loss: 0.613  loss_cls: 0.196  loss_box_reg: 0.341  loss_rpn_cls: 0.025  loss_rpn_loc: 0.044  time: 0.5215  data_time: 0.0050  lr: 0.002997  max_mem: 3094M
[32m[04/20 00:02:31 d2.utils.events]: [0m eta: 0:03:18  iter: 619  total_loss: 0.751  loss_cls: 0.249  loss_box_reg: 0.363  loss_rpn_cls: 0.028  loss_rpn_loc: 0.061  time: 0.5216  data_time: 0.0050  lr: 0.003097  max_mem: 3094M
[32m[04/20 00:02:42 d2.utils.events]: [0m eta: 0:03:08  iter: 639  total_loss: 0.700  loss_cls: 0.220  loss_box_reg: 0.380  loss_rpn_cls: 0.027  loss_rpn_loc: 0.047  time: 0.5219  data_time: 0.0052  lr: 0.003197  max_mem: 3094M
[32m[04/20 00:02:52 d2.utils.events]: [0m eta: 0:02:57  iter: 659  total_loss: 0.668  loss_cls: 0.249  loss_box_reg: 0.340  loss_rpn_cls: 0.025  loss_rpn_loc: 0.050  time: 0.5216  data_time: 0.0051  lr: 0.003297  max_mem: 3094M
[32m[04/20 00:03:03 d2.utils.events]: [0m eta: 0:02:47  iter: 679  total_loss: 0.832  loss_cls: 0.265  loss_box_reg: 0.374  loss_rpn_cls: 0.034  loss_rpn_loc: 0.072  time: 0.5217  data_time: 0.0049  lr: 0.003397  max_mem: 3094M
[32m[04/20 00:03:13 d2.utils.events]: [0m eta: 0:02:37  iter: 699  total_loss: 0.788  loss_cls: 0.264  loss_box_reg: 0.390  loss_rpn_cls: 0.035  loss_rpn_loc: 0.071  time: 0.5217  data_time: 0.0050  lr: 0.003497  max_mem: 3094M
[32m[04/20 00:03:24 d2.utils.events]: [0m eta: 0:02:26  iter: 719  total_loss: 0.763  loss_cls: 0.252  loss_box_reg: 0.378  loss_rpn_cls: 0.031  loss_rpn_loc: 0.064  time: 0.5217  data_time: 0.0051  lr: 0.003596  max_mem: 3094M
[32m[04/20 00:03:34 d2.utils.events]: [0m eta: 0:02:16  iter: 739  total_loss: 0.756  loss_cls: 0.266  loss_box_reg: 0.367  loss_rpn_cls: 0.036  loss_rpn_loc: 0.058  time: 0.5220  data_time: 0.0051  lr: 0.003696  max_mem: 3094M
[32m[04/20 00:03:45 d2.utils.events]: [0m eta: 0:02:05  iter: 759  total_loss: 0.685  loss_cls: 0.229  loss_box_reg: 0.360  loss_rpn_cls: 0.030  loss_rpn_loc: 0.046  time: 0.5220  data_time: 0.0051  lr: 0.003796  max_mem: 3094M
[32m[04/20 00:03:55 d2.utils.events]: [0m eta: 0:01:55  iter: 779  total_loss: 0.681  loss_cls: 0.248  loss_box_reg: 0.346  loss_rpn_cls: 0.026  loss_rpn_loc: 0.060  time: 0.5214  data_time: 0.0048  lr: 0.003896  max_mem: 3094M
[32m[04/20 00:04:06 d2.utils.events]: [0m eta: 0:01:44  iter: 799  total_loss: 0.844  loss_cls: 0.286  loss_box_reg: 0.387  loss_rpn_cls: 0.027  loss_rpn_loc: 0.071  time: 0.5215  data_time: 0.0050  lr: 0.003996  max_mem: 3094M
[32m[04/20 00:04:16 d2.utils.events]: [0m eta: 0:01:34  iter: 819  total_loss: 0.729  loss_cls: 0.272  loss_box_reg: 0.381  loss_rpn_cls: 0.036  loss_rpn_loc: 0.059  time: 0.5216  data_time: 0.0048  lr: 0.004096  max_mem: 3094M
[32m[04/20 00:04:27 d2.utils.events]: [0m eta: 0:01:24  iter: 839  total_loss: 0.695  loss_cls: 0.241  loss_box_reg: 0.327  loss_rpn_cls: 0.037  loss_rpn_loc: 0.061  time: 0.5217  data_time: 0.0052  lr: 0.004196  max_mem: 3094M
[32m[04/20 00:04:37 d2.utils.events]: [0m eta: 0:01:13  iter: 859  total_loss: 0.798  loss_cls: 0.280  loss_box_reg: 0.424  loss_rpn_cls: 0.028  loss_rpn_loc: 0.071  time: 0.5219  data_time: 0.0053  lr: 0.004296  max_mem: 3094M
[32m[04/20 00:04:48 d2.utils.events]: [0m eta: 0:01:03  iter: 879  total_loss: 0.671  loss_cls: 0.224  loss_box_reg: 0.317  loss_rpn_cls: 0.027  loss_rpn_loc: 0.057  time: 0.5222  data_time: 0.0052  lr: 0.004396  max_mem: 3094M
[32m[04/20 00:04:59 d2.utils.events]: [0m eta: 0:00:52  iter: 899  total_loss: 0.676  loss_cls: 0.231  loss_box_reg: 0.342  loss_rpn_cls: 0.027  loss_rpn_loc: 0.088  time: 0.5224  data_time: 0.0052  lr: 0.004496  max_mem: 3094M
[32m[04/20 00:05:09 d2.utils.events]: [0m eta: 0:00:42  iter: 919  total_loss: 0.852  loss_cls: 0.309  loss_box_reg: 0.440  loss_rpn_cls: 0.033  loss_rpn_loc: 0.085  time: 0.5226  data_time: 0.0049  lr: 0.004595  max_mem: 3094M
[32m[04/20 00:05:20 d2.utils.events]: [0m eta: 0:00:31  iter: 939  total_loss: 0.793  loss_cls: 0.275  loss_box_reg: 0.413  loss_rpn_cls: 0.036  loss_rpn_loc: 0.067  time: 0.5225  data_time: 0.0047  lr: 0.004695  max_mem: 3094M
[32m[04/20 00:05:30 d2.utils.events]: [0m eta: 0:00:21  iter: 959  total_loss: 0.700  loss_cls: 0.221  loss_box_reg: 0.383  loss_rpn_cls: 0.034  loss_rpn_loc: 0.065  time: 0.5224  data_time: 0.0050  lr: 0.004795  max_mem: 3094M
[32m[04/20 00:05:41 d2.utils.events]: [0m eta: 0:00:10  iter: 979  total_loss: 0.663  loss_cls: 0.225  loss_box_reg: 0.354  loss_rpn_cls: 0.025  loss_rpn_loc: 0.062  time: 0.5224  data_time: 0.0053  lr: 0.004895  max_mem: 3094M
[5m[31mWARNING[0m [32m[04/20 00:05:54 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 00:05:54 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[5m[31mWARNING[0m [32m[04/20 00:05:54 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 00:05:54 d2.utils.events]: [0m eta: 0:00:00  iter: 999  total_loss: 0.626  loss_cls: 0.215  loss_box_reg: 0.311  loss_rpn_cls: 0.029  loss_rpn_loc: 0.047  time: 0.5223  data_time: 0.0049  lr: 0.004995  max_mem: 3094M
[32m[04/20 00:05:55 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:08:41 (0.5228 s / it)
[32m[04/20 00:05:55 d2.engine.hooks]: [0mTotal training time: 0:08:47 (0:00:06 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 00:05:59 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 00:05:59 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/20 00:05:59 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 00:06:01 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1164 s / img. ETA=0:16:26
[32m[04/20 00:06:06 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1169 s / img. ETA=0:16:30
[32m[04/20 00:06:11 d2.evaluation.evaluator]: [0mInference done 96/8355. 0.1167 s / img. ETA=0:16:23
[32m[04/20 00:06:16 d2.evaluation.evaluator]: [0mInference done 139/8355. 0.1165 s / img. ETA=0:16:16
[32m[04/20 00:06:21 d2.evaluation.evaluator]: [0mInference done 182/8355. 0.1164 s / img. ETA=0:16:10
[32m[04/20 00:06:26 d2.evaluation.evaluator]: [0mInference done 224/8355. 0.1165 s / img. ETA=0:16:06
[32m[04/20 00:06:31 d2.evaluation.evaluator]: [0mInference done 266/8355. 0.1165 s / img. ETA=0:16:02
[32m[04/20 00:06:36 d2.evaluation.evaluator]: [0mInference done 308/8355. 0.1166 s / img. ETA=0:15:57
[32m[04/20 00:06:41 d2.evaluation.evaluator]: [0mInference done 350/8355. 0.1167 s / img. ETA=0:15:53
[32m[04/20 00:06:46 d2.evaluation.evaluator]: [0mInference done 392/8355. 0.1168 s / img. ETA=0:15:49
[32m[04/20 00:06:51 d2.evaluation.evaluator]: [0mInference done 434/8355. 0.1168 s / img. ETA=0:15:44
[32m[04/20 00:06:56 d2.evaluation.evaluator]: [0mInference done 476/8355. 0.1168 s / img. ETA=0:15:39
[32m[04/20 00:07:02 d2.evaluation.evaluator]: [0mInference done 519/8355. 0.1167 s / img. ETA=0:15:33
[32m[04/20 00:07:07 d2.evaluation.evaluator]: [0mInference done 562/8355. 0.1167 s / img. ETA=0:15:28
[32m[04/20 00:07:12 d2.evaluation.evaluator]: [0mInference done 604/8355. 0.1167 s / img. ETA=0:15:23
[32m[04/20 00:07:17 d2.evaluation.evaluator]: [0mInference done 646/8355. 0.1167 s / img. ETA=0:15:18
[32m[04/20 00:07:22 d2.evaluation.evaluator]: [0mInference done 688/8355. 0.1167 s / img. ETA=0:15:13
[32m[04/20 00:07:27 d2.evaluation.evaluator]: [0mInference done 730/8355. 0.1167 s / img. ETA=0:15:08
[32m[04/20 00:07:32 d2.evaluation.evaluator]: [0mInference done 773/8355. 0.1167 s / img. ETA=0:15:03
[32m[04/20 00:07:37 d2.evaluation.evaluator]: [0mInference done 815/8355. 0.1167 s / img. ETA=0:14:58
[32m[04/20 00:07:42 d2.evaluation.evaluator]: [0mInference done 857/8355. 0.1167 s / img. ETA=0:14:53
[32m[04/20 00:07:47 d2.evaluation.evaluator]: [0mInference done 899/8355. 0.1167 s / img. ETA=0:14:48
[32m[04/20 00:07:52 d2.evaluation.evaluator]: [0mInference done 941/8355. 0.1168 s / img. ETA=0:14:44
[32m[04/20 00:07:57 d2.evaluation.evaluator]: [0mInference done 984/8355. 0.1168 s / img. ETA=0:14:38
[32m[04/20 00:08:02 d2.evaluation.evaluator]: [0mInference done 1027/8355. 0.1167 s / img. ETA=0:14:33
[32m[04/20 00:08:07 d2.evaluation.evaluator]: [0mInference done 1069/8355. 0.1167 s / img. ETA=0:14:28
[32m[04/20 00:08:12 d2.evaluation.evaluator]: [0mInference done 1112/8355. 0.1167 s / img. ETA=0:14:23
[32m[04/20 00:08:17 d2.evaluation.evaluator]: [0mInference done 1155/8355. 0.1167 s / img. ETA=0:14:17
[32m[04/20 00:08:22 d2.evaluation.evaluator]: [0mInference done 1198/8355. 0.1167 s / img. ETA=0:14:12
[32m[04/20 00:08:27 d2.evaluation.evaluator]: [0mInference done 1240/8355. 0.1167 s / img. ETA=0:14:07
[32m[04/20 00:08:32 d2.evaluation.evaluator]: [0mInference done 1282/8355. 0.1167 s / img. ETA=0:14:02
[32m[04/20 00:08:37 d2.evaluation.evaluator]: [0mInference done 1324/8355. 0.1167 s / img. ETA=0:13:57
[32m[04/20 00:08:42 d2.evaluation.evaluator]: [0mInference done 1367/8355. 0.1166 s / img. ETA=0:13:52
[32m[04/20 00:08:48 d2.evaluation.evaluator]: [0mInference done 1410/8355. 0.1166 s / img. ETA=0:13:47
[32m[04/20 00:08:53 d2.evaluation.evaluator]: [0mInference done 1452/8355. 0.1166 s / img. ETA=0:13:42
[32m[04/20 00:08:58 d2.evaluation.evaluator]: [0mInference done 1494/8355. 0.1167 s / img. ETA=0:13:37
[32m[04/20 00:09:03 d2.evaluation.evaluator]: [0mInference done 1536/8355. 0.1167 s / img. ETA=0:13:32
[32m[04/20 00:09:08 d2.evaluation.evaluator]: [0mInference done 1578/8355. 0.1167 s / img. ETA=0:13:27
[32m[04/20 00:09:13 d2.evaluation.evaluator]: [0mInference done 1620/8355. 0.1168 s / img. ETA=0:13:23
[32m[04/20 00:09:18 d2.evaluation.evaluator]: [0mInference done 1662/8355. 0.1168 s / img. ETA=0:13:18
[32m[04/20 00:09:23 d2.evaluation.evaluator]: [0mInference done 1704/8355. 0.1168 s / img. ETA=0:13:13
[32m[04/20 00:09:28 d2.evaluation.evaluator]: [0mInference done 1746/8355. 0.1169 s / img. ETA=0:13:08
[32m[04/20 00:09:33 d2.evaluation.evaluator]: [0mInference done 1788/8355. 0.1169 s / img. ETA=0:13:03
[32m[04/20 00:09:38 d2.evaluation.evaluator]: [0mInference done 1830/8355. 0.1169 s / img. ETA=0:12:59
[32m[04/20 00:09:43 d2.evaluation.evaluator]: [0mInference done 1872/8355. 0.1170 s / img. ETA=0:12:54
[32m[04/20 00:09:48 d2.evaluation.evaluator]: [0mInference done 1914/8355. 0.1170 s / img. ETA=0:12:49
[32m[04/20 00:09:53 d2.evaluation.evaluator]: [0mInference done 1956/8355. 0.1170 s / img. ETA=0:12:44
[32m[04/20 00:09:58 d2.evaluation.evaluator]: [0mInference done 1998/8355. 0.1170 s / img. ETA=0:12:39
[32m[04/20 00:10:04 d2.evaluation.evaluator]: [0mInference done 2040/8355. 0.1170 s / img. ETA=0:12:34
[32m[04/20 00:10:09 d2.evaluation.evaluator]: [0mInference done 2082/8355. 0.1171 s / img. ETA=0:12:29
[32m[04/20 00:10:14 d2.evaluation.evaluator]: [0mInference done 2124/8355. 0.1171 s / img. ETA=0:12:24
[32m[04/20 00:10:19 d2.evaluation.evaluator]: [0mInference done 2166/8355. 0.1171 s / img. ETA=0:12:20
[32m[04/20 00:10:24 d2.evaluation.evaluator]: [0mInference done 2208/8355. 0.1171 s / img. ETA=0:12:15
[32m[04/20 00:10:29 d2.evaluation.evaluator]: [0mInference done 2250/8355. 0.1171 s / img. ETA=0:12:10
[32m[04/20 00:10:34 d2.evaluation.evaluator]: [0mInference done 2292/8355. 0.1171 s / img. ETA=0:12:05
[32m[04/20 00:10:39 d2.evaluation.evaluator]: [0mInference done 2334/8355. 0.1171 s / img. ETA=0:12:00
[32m[04/20 00:10:44 d2.evaluation.evaluator]: [0mInference done 2376/8355. 0.1171 s / img. ETA=0:11:55
[32m[04/20 00:10:49 d2.evaluation.evaluator]: [0mInference done 2418/8355. 0.1172 s / img. ETA=0:11:50
[32m[04/20 00:10:54 d2.evaluation.evaluator]: [0mInference done 2460/8355. 0.1172 s / img. ETA=0:11:45
[32m[04/20 00:10:59 d2.evaluation.evaluator]: [0mInference done 2502/8355. 0.1172 s / img. ETA=0:11:40
[32m[04/20 00:11:04 d2.evaluation.evaluator]: [0mInference done 2544/8355. 0.1172 s / img. ETA=0:11:35
[32m[04/20 00:11:09 d2.evaluation.evaluator]: [0mInference done 2586/8355. 0.1172 s / img. ETA=0:11:30
[32m[04/20 00:11:14 d2.evaluation.evaluator]: [0mInference done 2628/8355. 0.1172 s / img. ETA=0:11:25
[32m[04/20 00:11:19 d2.evaluation.evaluator]: [0mInference done 2670/8355. 0.1172 s / img. ETA=0:11:20
[32m[04/20 00:11:25 d2.evaluation.evaluator]: [0mInference done 2712/8355. 0.1173 s / img. ETA=0:11:15
[32m[04/20 00:11:30 d2.evaluation.evaluator]: [0mInference done 2754/8355. 0.1173 s / img. ETA=0:11:10
[32m[04/20 00:11:35 d2.evaluation.evaluator]: [0mInference done 2796/8355. 0.1173 s / img. ETA=0:11:05
[32m[04/20 00:11:40 d2.evaluation.evaluator]: [0mInference done 2838/8355. 0.1173 s / img. ETA=0:11:00
[32m[04/20 00:11:45 d2.evaluation.evaluator]: [0mInference done 2880/8355. 0.1173 s / img. ETA=0:10:56
[32m[04/20 00:11:50 d2.evaluation.evaluator]: [0mInference done 2922/8355. 0.1173 s / img. ETA=0:10:51
[32m[04/20 00:11:55 d2.evaluation.evaluator]: [0mInference done 2963/8355. 0.1173 s / img. ETA=0:10:46
[32m[04/20 00:12:00 d2.evaluation.evaluator]: [0mInference done 3005/8355. 0.1173 s / img. ETA=0:10:41
[32m[04/20 00:12:05 d2.evaluation.evaluator]: [0mInference done 3047/8355. 0.1174 s / img. ETA=0:10:36
[32m[04/20 00:12:10 d2.evaluation.evaluator]: [0mInference done 3089/8355. 0.1174 s / img. ETA=0:10:31
[32m[04/20 00:12:15 d2.evaluation.evaluator]: [0mInference done 3131/8355. 0.1174 s / img. ETA=0:10:26
[32m[04/20 00:12:20 d2.evaluation.evaluator]: [0mInference done 3173/8355. 0.1174 s / img. ETA=0:10:21
[32m[04/20 00:12:25 d2.evaluation.evaluator]: [0mInference done 3214/8355. 0.1174 s / img. ETA=0:10:16
[32m[04/20 00:12:30 d2.evaluation.evaluator]: [0mInference done 3256/8355. 0.1174 s / img. ETA=0:10:11
[32m[04/20 00:12:35 d2.evaluation.evaluator]: [0mInference done 3298/8355. 0.1174 s / img. ETA=0:10:06
[32m[04/20 00:12:41 d2.evaluation.evaluator]: [0mInference done 3340/8355. 0.1174 s / img. ETA=0:10:01
[32m[04/20 00:12:46 d2.evaluation.evaluator]: [0mInference done 3382/8355. 0.1174 s / img. ETA=0:09:57
[32m[04/20 00:12:51 d2.evaluation.evaluator]: [0mInference done 3424/8355. 0.1174 s / img. ETA=0:09:52
[32m[04/20 00:12:56 d2.evaluation.evaluator]: [0mInference done 3466/8355. 0.1175 s / img. ETA=0:09:47
[32m[04/20 00:13:01 d2.evaluation.evaluator]: [0mInference done 3508/8355. 0.1175 s / img. ETA=0:09:42
[32m[04/20 00:13:06 d2.evaluation.evaluator]: [0mInference done 3550/8355. 0.1175 s / img. ETA=0:09:37
[32m[04/20 00:13:11 d2.evaluation.evaluator]: [0mInference done 3592/8355. 0.1175 s / img. ETA=0:09:32
[32m[04/20 00:13:16 d2.evaluation.evaluator]: [0mInference done 3634/8355. 0.1175 s / img. ETA=0:09:27
[32m[04/20 00:13:21 d2.evaluation.evaluator]: [0mInference done 3676/8355. 0.1175 s / img. ETA=0:09:22
[32m[04/20 00:13:26 d2.evaluation.evaluator]: [0mInference done 3718/8355. 0.1175 s / img. ETA=0:09:17
[32m[04/20 00:13:31 d2.evaluation.evaluator]: [0mInference done 3760/8355. 0.1175 s / img. ETA=0:09:12
[32m[04/20 00:13:37 d2.evaluation.evaluator]: [0mInference done 3802/8355. 0.1175 s / img. ETA=0:09:07
[32m[04/20 00:13:42 d2.evaluation.evaluator]: [0mInference done 3843/8355. 0.1175 s / img. ETA=0:09:02
[32m[04/20 00:13:47 d2.evaluation.evaluator]: [0mInference done 3885/8355. 0.1175 s / img. ETA=0:08:57
[32m[04/20 00:13:52 d2.evaluation.evaluator]: [0mInference done 3927/8355. 0.1175 s / img. ETA=0:08:52
[32m[04/20 00:13:57 d2.evaluation.evaluator]: [0mInference done 3969/8355. 0.1176 s / img. ETA=0:08:47
[32m[04/20 00:14:02 d2.evaluation.evaluator]: [0mInference done 4011/8355. 0.1176 s / img. ETA=0:08:42
[32m[04/20 00:14:07 d2.evaluation.evaluator]: [0mInference done 4048/8355. 0.1176 s / img. ETA=0:08:38
[32m[04/20 00:14:12 d2.evaluation.evaluator]: [0mInference done 4089/8355. 0.1176 s / img. ETA=0:08:33
[32m[04/20 00:14:17 d2.evaluation.evaluator]: [0mInference done 4128/8355. 0.1176 s / img. ETA=0:08:29
[32m[04/20 00:14:22 d2.evaluation.evaluator]: [0mInference done 4169/8355. 0.1176 s / img. ETA=0:08:24
[32m[04/20 00:14:27 d2.evaluation.evaluator]: [0mInference done 4204/8355. 0.1176 s / img. ETA=0:08:20
[32m[04/20 00:14:32 d2.evaluation.evaluator]: [0mInference done 4245/8355. 0.1176 s / img. ETA=0:08:16
[32m[04/20 00:14:37 d2.evaluation.evaluator]: [0mInference done 4287/8355. 0.1176 s / img. ETA=0:08:11
[32m[04/20 00:14:42 d2.evaluation.evaluator]: [0mInference done 4328/8355. 0.1177 s / img. ETA=0:08:06
[32m[04/20 00:14:47 d2.evaluation.evaluator]: [0mInference done 4370/8355. 0.1177 s / img. ETA=0:08:01
[32m[04/20 00:14:52 d2.evaluation.evaluator]: [0mInference done 4411/8355. 0.1177 s / img. ETA=0:07:56
[32m[04/20 00:14:57 d2.evaluation.evaluator]: [0mInference done 4452/8355. 0.1177 s / img. ETA=0:07:51
[32m[04/20 00:15:02 d2.evaluation.evaluator]: [0mInference done 4488/8355. 0.1177 s / img. ETA=0:07:47
[32m[04/20 00:15:07 d2.evaluation.evaluator]: [0mInference done 4529/8355. 0.1177 s / img. ETA=0:07:42
[32m[04/20 00:15:12 d2.evaluation.evaluator]: [0mInference done 4570/8355. 0.1177 s / img. ETA=0:07:37
[32m[04/20 00:15:18 d2.evaluation.evaluator]: [0mInference done 4611/8355. 0.1178 s / img. ETA=0:07:32
[32m[04/20 00:15:23 d2.evaluation.evaluator]: [0mInference done 4653/8355. 0.1178 s / img. ETA=0:07:27
[32m[04/20 00:15:28 d2.evaluation.evaluator]: [0mInference done 4695/8355. 0.1178 s / img. ETA=0:07:22
[32m[04/20 00:15:33 d2.evaluation.evaluator]: [0mInference done 4737/8355. 0.1178 s / img. ETA=0:07:17
[32m[04/20 00:15:38 d2.evaluation.evaluator]: [0mInference done 4771/8355. 0.1178 s / img. ETA=0:07:14
[32m[04/20 00:15:43 d2.evaluation.evaluator]: [0mInference done 4812/8355. 0.1178 s / img. ETA=0:07:09
[32m[04/20 00:15:48 d2.evaluation.evaluator]: [0mInference done 4854/8355. 0.1178 s / img. ETA=0:07:04
[32m[04/20 00:15:53 d2.evaluation.evaluator]: [0mInference done 4896/8355. 0.1178 s / img. ETA=0:06:59
[32m[04/20 00:15:58 d2.evaluation.evaluator]: [0mInference done 4936/8355. 0.1178 s / img. ETA=0:06:54
[32m[04/20 00:16:03 d2.evaluation.evaluator]: [0mInference done 4975/8355. 0.1178 s / img. ETA=0:06:50
[32m[04/20 00:16:08 d2.evaluation.evaluator]: [0mInference done 5014/8355. 0.1178 s / img. ETA=0:06:45
[32m[04/20 00:16:13 d2.evaluation.evaluator]: [0mInference done 5053/8355. 0.1178 s / img. ETA=0:06:41
[32m[04/20 00:16:18 d2.evaluation.evaluator]: [0mInference done 5094/8355. 0.1179 s / img. ETA=0:06:36
[32m[04/20 00:16:24 d2.evaluation.evaluator]: [0mInference done 5135/8355. 0.1179 s / img. ETA=0:06:31
[32m[04/20 00:16:29 d2.evaluation.evaluator]: [0mInference done 5176/8355. 0.1179 s / img. ETA=0:06:26
[32m[04/20 00:16:34 d2.evaluation.evaluator]: [0mInference done 5217/8355. 0.1179 s / img. ETA=0:06:21
[32m[04/20 00:16:39 d2.evaluation.evaluator]: [0mInference done 5258/8355. 0.1179 s / img. ETA=0:06:16
[32m[04/20 00:16:44 d2.evaluation.evaluator]: [0mInference done 5299/8355. 0.1179 s / img. ETA=0:06:11
[32m[04/20 00:16:49 d2.evaluation.evaluator]: [0mInference done 5340/8355. 0.1179 s / img. ETA=0:06:06
[32m[04/20 00:16:54 d2.evaluation.evaluator]: [0mInference done 5381/8355. 0.1180 s / img. ETA=0:06:01
[32m[04/20 00:16:59 d2.evaluation.evaluator]: [0mInference done 5422/8355. 0.1180 s / img. ETA=0:05:56
[32m[04/20 00:17:04 d2.evaluation.evaluator]: [0mInference done 5463/8355. 0.1180 s / img. ETA=0:05:51
[32m[04/20 00:17:09 d2.evaluation.evaluator]: [0mInference done 5504/8355. 0.1180 s / img. ETA=0:05:46
[32m[04/20 00:17:14 d2.evaluation.evaluator]: [0mInference done 5546/8355. 0.1180 s / img. ETA=0:05:41
[32m[04/20 00:17:19 d2.evaluation.evaluator]: [0mInference done 5588/8355. 0.1180 s / img. ETA=0:05:36
[32m[04/20 00:17:24 d2.evaluation.evaluator]: [0mInference done 5629/8355. 0.1180 s / img. ETA=0:05:31
[32m[04/20 00:17:29 d2.evaluation.evaluator]: [0mInference done 5670/8355. 0.1180 s / img. ETA=0:05:26
[32m[04/20 00:17:34 d2.evaluation.evaluator]: [0mInference done 5711/8355. 0.1180 s / img. ETA=0:05:21
[32m[04/20 00:17:39 d2.evaluation.evaluator]: [0mInference done 5753/8355. 0.1180 s / img. ETA=0:05:16
[32m[04/20 00:17:44 d2.evaluation.evaluator]: [0mInference done 5794/8355. 0.1181 s / img. ETA=0:05:11
[32m[04/20 00:17:49 d2.evaluation.evaluator]: [0mInference done 5836/8355. 0.1180 s / img. ETA=0:05:06
[32m[04/20 00:17:54 d2.evaluation.evaluator]: [0mInference done 5878/8355. 0.1181 s / img. ETA=0:05:01
[32m[04/20 00:17:59 d2.evaluation.evaluator]: [0mInference done 5920/8355. 0.1181 s / img. ETA=0:04:56
[32m[04/20 00:18:05 d2.evaluation.evaluator]: [0mInference done 5962/8355. 0.1181 s / img. ETA=0:04:50
[32m[04/20 00:18:10 d2.evaluation.evaluator]: [0mInference done 6003/8355. 0.1181 s / img. ETA=0:04:45
[32m[04/20 00:18:15 d2.evaluation.evaluator]: [0mInference done 6044/8355. 0.1181 s / img. ETA=0:04:41
[32m[04/20 00:18:20 d2.evaluation.evaluator]: [0mInference done 6085/8355. 0.1181 s / img. ETA=0:04:36
[32m[04/20 00:18:25 d2.evaluation.evaluator]: [0mInference done 6126/8355. 0.1181 s / img. ETA=0:04:31
[32m[04/20 00:18:30 d2.evaluation.evaluator]: [0mInference done 6167/8355. 0.1181 s / img. ETA=0:04:26
[32m[04/20 00:18:35 d2.evaluation.evaluator]: [0mInference done 6209/8355. 0.1181 s / img. ETA=0:04:20
[32m[04/20 00:18:40 d2.evaluation.evaluator]: [0mInference done 6251/8355. 0.1181 s / img. ETA=0:04:15
[32m[04/20 00:18:45 d2.evaluation.evaluator]: [0mInference done 6292/8355. 0.1181 s / img. ETA=0:04:10
[32m[04/20 00:18:50 d2.evaluation.evaluator]: [0mInference done 6333/8355. 0.1181 s / img. ETA=0:04:05
[32m[04/20 00:18:55 d2.evaluation.evaluator]: [0mInference done 6375/8355. 0.1181 s / img. ETA=0:04:00
[32m[04/20 00:19:00 d2.evaluation.evaluator]: [0mInference done 6417/8355. 0.1181 s / img. ETA=0:03:55
[32m[04/20 00:19:05 d2.evaluation.evaluator]: [0mInference done 6459/8355. 0.1181 s / img. ETA=0:03:50
[32m[04/20 00:19:10 d2.evaluation.evaluator]: [0mInference done 6501/8355. 0.1181 s / img. ETA=0:03:45
[32m[04/20 00:19:15 d2.evaluation.evaluator]: [0mInference done 6543/8355. 0.1181 s / img. ETA=0:03:40
[32m[04/20 00:19:21 d2.evaluation.evaluator]: [0mInference done 6585/8355. 0.1181 s / img. ETA=0:03:35
[32m[04/20 00:19:26 d2.evaluation.evaluator]: [0mInference done 6626/8355. 0.1181 s / img. ETA=0:03:30
[32m[04/20 00:19:31 d2.evaluation.evaluator]: [0mInference done 6668/8355. 0.1182 s / img. ETA=0:03:25
[32m[04/20 00:19:36 d2.evaluation.evaluator]: [0mInference done 6710/8355. 0.1182 s / img. ETA=0:03:20
[32m[04/20 00:19:41 d2.evaluation.evaluator]: [0mInference done 6752/8355. 0.1182 s / img. ETA=0:03:14
[32m[04/20 00:19:46 d2.evaluation.evaluator]: [0mInference done 6794/8355. 0.1182 s / img. ETA=0:03:09
[32m[04/20 00:19:51 d2.evaluation.evaluator]: [0mInference done 6836/8355. 0.1182 s / img. ETA=0:03:04
[32m[04/20 00:19:56 d2.evaluation.evaluator]: [0mInference done 6878/8355. 0.1182 s / img. ETA=0:02:59
[32m[04/20 00:20:01 d2.evaluation.evaluator]: [0mInference done 6920/8355. 0.1182 s / img. ETA=0:02:54
[32m[04/20 00:20:06 d2.evaluation.evaluator]: [0mInference done 6962/8355. 0.1182 s / img. ETA=0:02:49
[32m[04/20 00:20:11 d2.evaluation.evaluator]: [0mInference done 7003/8355. 0.1182 s / img. ETA=0:02:44
[32m[04/20 00:20:16 d2.evaluation.evaluator]: [0mInference done 7044/8355. 0.1182 s / img. ETA=0:02:39
[32m[04/20 00:20:21 d2.evaluation.evaluator]: [0mInference done 7085/8355. 0.1182 s / img. ETA=0:02:34
[32m[04/20 00:20:26 d2.evaluation.evaluator]: [0mInference done 7126/8355. 0.1182 s / img. ETA=0:02:29
[32m[04/20 00:20:31 d2.evaluation.evaluator]: [0mInference done 7167/8355. 0.1182 s / img. ETA=0:02:24
[32m[04/20 00:20:37 d2.evaluation.evaluator]: [0mInference done 7208/8355. 0.1182 s / img. ETA=0:02:19
[32m[04/20 00:20:42 d2.evaluation.evaluator]: [0mInference done 7249/8355. 0.1182 s / img. ETA=0:02:14
[32m[04/20 00:20:47 d2.evaluation.evaluator]: [0mInference done 7290/8355. 0.1182 s / img. ETA=0:02:09
[32m[04/20 00:20:52 d2.evaluation.evaluator]: [0mInference done 7331/8355. 0.1182 s / img. ETA=0:02:04
[32m[04/20 00:20:57 d2.evaluation.evaluator]: [0mInference done 7372/8355. 0.1183 s / img. ETA=0:01:59
[32m[04/20 00:21:02 d2.evaluation.evaluator]: [0mInference done 7413/8355. 0.1183 s / img. ETA=0:01:54
[32m[04/20 00:21:07 d2.evaluation.evaluator]: [0mInference done 7454/8355. 0.1183 s / img. ETA=0:01:49
[32m[04/20 00:21:12 d2.evaluation.evaluator]: [0mInference done 7495/8355. 0.1183 s / img. ETA=0:01:44
[32m[04/20 00:21:17 d2.evaluation.evaluator]: [0mInference done 7537/8355. 0.1183 s / img. ETA=0:01:39
[32m[04/20 00:21:22 d2.evaluation.evaluator]: [0mInference done 7579/8355. 0.1183 s / img. ETA=0:01:34
[32m[04/20 00:21:27 d2.evaluation.evaluator]: [0mInference done 7620/8355. 0.1183 s / img. ETA=0:01:29
[32m[04/20 00:21:32 d2.evaluation.evaluator]: [0mInference done 7662/8355. 0.1183 s / img. ETA=0:01:24
[32m[04/20 00:21:37 d2.evaluation.evaluator]: [0mInference done 7703/8355. 0.1183 s / img. ETA=0:01:19
[32m[04/20 00:21:42 d2.evaluation.evaluator]: [0mInference done 7745/8355. 0.1183 s / img. ETA=0:01:14
[32m[04/20 00:21:47 d2.evaluation.evaluator]: [0mInference done 7786/8355. 0.1183 s / img. ETA=0:01:09
[32m[04/20 00:21:52 d2.evaluation.evaluator]: [0mInference done 7827/8355. 0.1183 s / img. ETA=0:01:04
[32m[04/20 00:21:57 d2.evaluation.evaluator]: [0mInference done 7868/8355. 0.1183 s / img. ETA=0:00:59
[32m[04/20 00:22:02 d2.evaluation.evaluator]: [0mInference done 7909/8355. 0.1183 s / img. ETA=0:00:54
[32m[04/20 00:22:07 d2.evaluation.evaluator]: [0mInference done 7950/8355. 0.1183 s / img. ETA=0:00:49
[32m[04/20 00:22:12 d2.evaluation.evaluator]: [0mInference done 7992/8355. 0.1183 s / img. ETA=0:00:44
[32m[04/20 00:22:18 d2.evaluation.evaluator]: [0mInference done 8034/8355. 0.1183 s / img. ETA=0:00:39
[32m[04/20 00:22:23 d2.evaluation.evaluator]: [0mInference done 8076/8355. 0.1183 s / img. ETA=0:00:33
[32m[04/20 00:22:28 d2.evaluation.evaluator]: [0mInference done 8118/8355. 0.1183 s / img. ETA=0:00:28
[32m[04/20 00:22:33 d2.evaluation.evaluator]: [0mInference done 8160/8355. 0.1183 s / img. ETA=0:00:23
[32m[04/20 00:22:38 d2.evaluation.evaluator]: [0mInference done 8202/8355. 0.1183 s / img. ETA=0:00:18
[32m[04/20 00:22:43 d2.evaluation.evaluator]: [0mInference done 8244/8355. 0.1183 s / img. ETA=0:00:13
[32m[04/20 00:22:48 d2.evaluation.evaluator]: [0mInference done 8286/8355. 0.1183 s / img. ETA=0:00:08
[32m[04/20 00:22:53 d2.evaluation.evaluator]: [0mInference done 8328/8355. 0.1183 s / img. ETA=0:00:03
[32m[04/20 00:22:57 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:56.266240 (0.121709 s / img per device, on 1 devices)
[32m[04/20 00:22:57 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:28 (0.118344 s / img per device, on 1 devices)
[32m[04/20 00:22:57 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 00:22:57 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 00:22:57 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.09s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=21.76s).
Accumulating evaluation results...
DONE (t=2.53s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.471
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.176
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.307
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.125
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.282
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.377
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540
[32m[04/20 00:23:22 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 22.499 | 47.070 | 17.608 | 16.168 | 30.683 | 50.015 |
[32m[04/20 00:23:22 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 28.812 | bicycle       | 12.364 | car            | 35.203 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | 13.618 | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 00:23:25 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 00:23:25 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[32m[04/20 00:23:25 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 00:23:27 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1213 s / img. ETA=0:02:34
[32m[04/20 00:23:33 d2.evaluation.evaluator]: [0mInference done 52/1257. 0.1210 s / img. ETA=0:02:30
[32m[04/20 00:23:38 d2.evaluation.evaluator]: [0mInference done 93/1257. 0.1204 s / img. ETA=0:02:24
[32m[04/20 00:23:43 d2.evaluation.evaluator]: [0mInference done 134/1257. 0.1201 s / img. ETA=0:02:18
[32m[04/20 00:23:48 d2.evaluation.evaluator]: [0mInference done 176/1257. 0.1196 s / img. ETA=0:02:12
[32m[04/20 00:23:53 d2.evaluation.evaluator]: [0mInference done 217/1257. 0.1196 s / img. ETA=0:02:07
[32m[04/20 00:23:58 d2.evaluation.evaluator]: [0mInference done 258/1257. 0.1197 s / img. ETA=0:02:02
[32m[04/20 00:24:03 d2.evaluation.evaluator]: [0mInference done 299/1257. 0.1197 s / img. ETA=0:01:57
[32m[04/20 00:24:08 d2.evaluation.evaluator]: [0mInference done 341/1257. 0.1195 s / img. ETA=0:01:52
[32m[04/20 00:24:13 d2.evaluation.evaluator]: [0mInference done 383/1257. 0.1194 s / img. ETA=0:01:47
[32m[04/20 00:24:18 d2.evaluation.evaluator]: [0mInference done 425/1257. 0.1193 s / img. ETA=0:01:41
[32m[04/20 00:24:23 d2.evaluation.evaluator]: [0mInference done 466/1257. 0.1193 s / img. ETA=0:01:36
[32m[04/20 00:24:28 d2.evaluation.evaluator]: [0mInference done 507/1257. 0.1193 s / img. ETA=0:01:31
[32m[04/20 00:24:33 d2.evaluation.evaluator]: [0mInference done 548/1257. 0.1195 s / img. ETA=0:01:27
[32m[04/20 00:24:38 d2.evaluation.evaluator]: [0mInference done 589/1257. 0.1195 s / img. ETA=0:01:21
[32m[04/20 00:24:43 d2.evaluation.evaluator]: [0mInference done 630/1257. 0.1196 s / img. ETA=0:01:16
[32m[04/20 00:24:48 d2.evaluation.evaluator]: [0mInference done 671/1257. 0.1196 s / img. ETA=0:01:11
[32m[04/20 00:24:54 d2.evaluation.evaluator]: [0mInference done 713/1257. 0.1195 s / img. ETA=0:01:06
[32m[04/20 00:24:59 d2.evaluation.evaluator]: [0mInference done 755/1257. 0.1195 s / img. ETA=0:01:01
[32m[04/20 00:25:04 d2.evaluation.evaluator]: [0mInference done 797/1257. 0.1194 s / img. ETA=0:00:56
[32m[04/20 00:25:09 d2.evaluation.evaluator]: [0mInference done 838/1257. 0.1194 s / img. ETA=0:00:51
[32m[04/20 00:25:14 d2.evaluation.evaluator]: [0mInference done 880/1257. 0.1194 s / img. ETA=0:00:46
[32m[04/20 00:25:19 d2.evaluation.evaluator]: [0mInference done 921/1257. 0.1194 s / img. ETA=0:00:41
[32m[04/20 00:25:24 d2.evaluation.evaluator]: [0mInference done 962/1257. 0.1194 s / img. ETA=0:00:36
[32m[04/20 00:25:29 d2.evaluation.evaluator]: [0mInference done 1003/1257. 0.1194 s / img. ETA=0:00:31
[32m[04/20 00:25:34 d2.evaluation.evaluator]: [0mInference done 1045/1257. 0.1194 s / img. ETA=0:00:25
[32m[04/20 00:25:39 d2.evaluation.evaluator]: [0mInference done 1086/1257. 0.1194 s / img. ETA=0:00:20
[32m[04/20 00:25:44 d2.evaluation.evaluator]: [0mInference done 1127/1257. 0.1194 s / img. ETA=0:00:15
[32m[04/20 00:25:49 d2.evaluation.evaluator]: [0mInference done 1168/1257. 0.1194 s / img. ETA=0:00:10
[32m[04/20 00:25:54 d2.evaluation.evaluator]: [0mInference done 1209/1257. 0.1194 s / img. ETA=0:00:05
[32m[04/20 00:25:59 d2.evaluation.evaluator]: [0mInference done 1250/1257. 0.1194 s / img. ETA=0:00:00
[32m[04/20 00:26:00 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:33.460815 (0.122573 s / img per device, on 1 devices)
[32m[04/20 00:26:00 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:29 (0.119411 s / img per device, on 1 devices)
[32m[04/20 00:26:00 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 00:26:00 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 00:26:00 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.35s).
Accumulating evaluation results...
DONE (t=0.42s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.353
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.130
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.098
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.207
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.389
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.087
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.210
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.212
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.258
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.422
[32m[04/20 00:26:04 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 16.408 | 35.301 | 12.983 | 9.798 | 20.729 | 38.922 |
[32m[04/20 00:26:04 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 23.027 | bicycle       | 7.487 | car            | 35.119 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | 0.000 | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  6  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 00:26:05 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 00:26:06 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 00:26:06 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/20 00:26:06 d2.data.build]: [0mRemoved 889 images with no usable annotations. 7466 images left.
[32m[04/20 00:26:06 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 00:26:06 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 00:26:09 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 00:26:21 d2.utils.events]: [0m eta: 0:08:34  iter: 19  total_loss: 0.512  loss_cls: 0.166  loss_box_reg: 0.276  loss_rpn_cls: 0.030  loss_rpn_loc: 0.080  time: 0.5229  data_time: 0.0338  lr: 0.000100  max_mem: 3094M
[32m[04/20 00:26:31 d2.utils.events]: [0m eta: 0:08:16  iter: 39  total_loss: 0.618  loss_cls: 0.199  loss_box_reg: 0.344  loss_rpn_cls: 0.032  loss_rpn_loc: 0.040  time: 0.5197  data_time: 0.0053  lr: 0.000200  max_mem: 3094M
[32m[04/20 00:26:42 d2.utils.events]: [0m eta: 0:08:03  iter: 59  total_loss: 0.678  loss_cls: 0.247  loss_box_reg: 0.370  loss_rpn_cls: 0.042  loss_rpn_loc: 0.057  time: 0.5135  data_time: 0.0047  lr: 0.000300  max_mem: 3094M
[32m[04/20 00:26:52 d2.utils.events]: [0m eta: 0:07:57  iter: 79  total_loss: 0.719  loss_cls: 0.241  loss_box_reg: 0.376  loss_rpn_cls: 0.023  loss_rpn_loc: 0.048  time: 0.5175  data_time: 0.0051  lr: 0.000400  max_mem: 3094M
[32m[04/20 00:27:02 d2.utils.events]: [0m eta: 0:07:46  iter: 99  total_loss: 0.670  loss_cls: 0.217  loss_box_reg: 0.326  loss_rpn_cls: 0.031  loss_rpn_loc: 0.047  time: 0.5156  data_time: 0.0051  lr: 0.000500  max_mem: 3094M
[32m[04/20 00:27:13 d2.utils.events]: [0m eta: 0:07:35  iter: 119  total_loss: 0.663  loss_cls: 0.220  loss_box_reg: 0.346  loss_rpn_cls: 0.026  loss_rpn_loc: 0.051  time: 0.5171  data_time: 0.0052  lr: 0.000599  max_mem: 3094M
[32m[04/20 00:27:23 d2.utils.events]: [0m eta: 0:07:25  iter: 139  total_loss: 0.712  loss_cls: 0.214  loss_box_reg: 0.347  loss_rpn_cls: 0.018  loss_rpn_loc: 0.062  time: 0.5180  data_time: 0.0052  lr: 0.000699  max_mem: 3094M
[32m[04/20 00:27:34 d2.utils.events]: [0m eta: 0:07:18  iter: 159  total_loss: 0.626  loss_cls: 0.219  loss_box_reg: 0.326  loss_rpn_cls: 0.025  loss_rpn_loc: 0.061  time: 0.5199  data_time: 0.0054  lr: 0.000799  max_mem: 3094M
[32m[04/20 00:27:44 d2.utils.events]: [0m eta: 0:07:05  iter: 179  total_loss: 0.699  loss_cls: 0.247  loss_box_reg: 0.381  loss_rpn_cls: 0.025  loss_rpn_loc: 0.066  time: 0.5178  data_time: 0.0054  lr: 0.000899  max_mem: 3094M
[32m[04/20 00:27:55 d2.utils.events]: [0m eta: 0:06:58  iter: 199  total_loss: 0.685  loss_cls: 0.232  loss_box_reg: 0.362  loss_rpn_cls: 0.026  loss_rpn_loc: 0.061  time: 0.5209  data_time: 0.0054  lr: 0.000999  max_mem: 3094M
[32m[04/20 00:28:05 d2.utils.events]: [0m eta: 0:06:46  iter: 219  total_loss: 0.774  loss_cls: 0.235  loss_box_reg: 0.418  loss_rpn_cls: 0.029  loss_rpn_loc: 0.060  time: 0.5201  data_time: 0.0051  lr: 0.001099  max_mem: 3094M
[32m[04/20 00:28:16 d2.utils.events]: [0m eta: 0:06:36  iter: 239  total_loss: 0.602  loss_cls: 0.201  loss_box_reg: 0.306  loss_rpn_cls: 0.022  loss_rpn_loc: 0.054  time: 0.5201  data_time: 0.0053  lr: 0.001199  max_mem: 3094M
[32m[04/20 00:28:26 d2.utils.events]: [0m eta: 0:06:25  iter: 259  total_loss: 0.682  loss_cls: 0.243  loss_box_reg: 0.360  loss_rpn_cls: 0.027  loss_rpn_loc: 0.060  time: 0.5193  data_time: 0.0055  lr: 0.001299  max_mem: 3094M
[32m[04/20 00:28:37 d2.utils.events]: [0m eta: 0:06:15  iter: 279  total_loss: 0.744  loss_cls: 0.248  loss_box_reg: 0.415  loss_rpn_cls: 0.037  loss_rpn_loc: 0.067  time: 0.5193  data_time: 0.0052  lr: 0.001399  max_mem: 3094M
[32m[04/20 00:28:47 d2.utils.events]: [0m eta: 0:06:05  iter: 299  total_loss: 0.733  loss_cls: 0.257  loss_box_reg: 0.407  loss_rpn_cls: 0.031  loss_rpn_loc: 0.067  time: 0.5194  data_time: 0.0053  lr: 0.001499  max_mem: 3094M
[32m[04/20 00:28:58 d2.utils.events]: [0m eta: 0:05:56  iter: 319  total_loss: 0.897  loss_cls: 0.295  loss_box_reg: 0.435  loss_rpn_cls: 0.043  loss_rpn_loc: 0.076  time: 0.5198  data_time: 0.0052  lr: 0.001598  max_mem: 3094M
[32m[04/20 00:29:08 d2.utils.events]: [0m eta: 0:05:46  iter: 339  total_loss: 0.710  loss_cls: 0.241  loss_box_reg: 0.386  loss_rpn_cls: 0.023  loss_rpn_loc: 0.043  time: 0.5208  data_time: 0.0055  lr: 0.001698  max_mem: 3094M
[32m[04/20 00:29:19 d2.utils.events]: [0m eta: 0:05:35  iter: 359  total_loss: 0.612  loss_cls: 0.209  loss_box_reg: 0.324  loss_rpn_cls: 0.029  loss_rpn_loc: 0.054  time: 0.5208  data_time: 0.0053  lr: 0.001798  max_mem: 3094M
[32m[04/20 00:29:29 d2.utils.events]: [0m eta: 0:05:25  iter: 379  total_loss: 0.714  loss_cls: 0.244  loss_box_reg: 0.380  loss_rpn_cls: 0.022  loss_rpn_loc: 0.069  time: 0.5211  data_time: 0.0050  lr: 0.001898  max_mem: 3094M
[32m[04/20 00:29:40 d2.utils.events]: [0m eta: 0:05:14  iter: 399  total_loss: 0.710  loss_cls: 0.242  loss_box_reg: 0.345  loss_rpn_cls: 0.024  loss_rpn_loc: 0.061  time: 0.5209  data_time: 0.0050  lr: 0.001998  max_mem: 3094M
[32m[04/20 00:29:51 d2.utils.events]: [0m eta: 0:05:04  iter: 419  total_loss: 0.774  loss_cls: 0.249  loss_box_reg: 0.416  loss_rpn_cls: 0.029  loss_rpn_loc: 0.063  time: 0.5215  data_time: 0.0052  lr: 0.002098  max_mem: 3094M
[32m[04/20 00:30:01 d2.utils.events]: [0m eta: 0:04:53  iter: 439  total_loss: 0.513  loss_cls: 0.200  loss_box_reg: 0.231  loss_rpn_cls: 0.027  loss_rpn_loc: 0.038  time: 0.5211  data_time: 0.0049  lr: 0.002198  max_mem: 3094M
[32m[04/20 00:30:11 d2.utils.events]: [0m eta: 0:04:43  iter: 459  total_loss: 0.640  loss_cls: 0.229  loss_box_reg: 0.331  loss_rpn_cls: 0.018  loss_rpn_loc: 0.064  time: 0.5211  data_time: 0.0051  lr: 0.002298  max_mem: 3094M
[32m[04/20 00:30:22 d2.utils.events]: [0m eta: 0:04:32  iter: 479  total_loss: 0.593  loss_cls: 0.207  loss_box_reg: 0.289  loss_rpn_cls: 0.018  loss_rpn_loc: 0.043  time: 0.5211  data_time: 0.0048  lr: 0.002398  max_mem: 3094M
[32m[04/20 00:30:32 d2.utils.events]: [0m eta: 0:04:21  iter: 499  total_loss: 0.707  loss_cls: 0.232  loss_box_reg: 0.357  loss_rpn_cls: 0.027  loss_rpn_loc: 0.066  time: 0.5211  data_time: 0.0055  lr: 0.002498  max_mem: 3094M
[32m[04/20 00:30:43 d2.utils.events]: [0m eta: 0:04:11  iter: 519  total_loss: 0.796  loss_cls: 0.290  loss_box_reg: 0.393  loss_rpn_cls: 0.043  loss_rpn_loc: 0.065  time: 0.5212  data_time: 0.0054  lr: 0.002597  max_mem: 3094M
[32m[04/20 00:30:54 d2.utils.events]: [0m eta: 0:04:01  iter: 539  total_loss: 0.695  loss_cls: 0.215  loss_box_reg: 0.369  loss_rpn_cls: 0.015  loss_rpn_loc: 0.064  time: 0.5222  data_time: 0.0052  lr: 0.002697  max_mem: 3094M
[32m[04/20 00:31:05 d2.utils.events]: [0m eta: 0:03:50  iter: 559  total_loss: 0.677  loss_cls: 0.229  loss_box_reg: 0.333  loss_rpn_cls: 0.024  loss_rpn_loc: 0.049  time: 0.5225  data_time: 0.0055  lr: 0.002797  max_mem: 3094M
[32m[04/20 00:31:15 d2.utils.events]: [0m eta: 0:03:40  iter: 579  total_loss: 0.698  loss_cls: 0.213  loss_box_reg: 0.340  loss_rpn_cls: 0.035  loss_rpn_loc: 0.072  time: 0.5228  data_time: 0.0052  lr: 0.002897  max_mem: 3094M
[32m[04/20 00:31:26 d2.utils.events]: [0m eta: 0:03:30  iter: 599  total_loss: 0.797  loss_cls: 0.281  loss_box_reg: 0.420  loss_rpn_cls: 0.027  loss_rpn_loc: 0.055  time: 0.5228  data_time: 0.0054  lr: 0.002997  max_mem: 3094M
[32m[04/20 00:31:36 d2.utils.events]: [0m eta: 0:03:19  iter: 619  total_loss: 0.574  loss_cls: 0.195  loss_box_reg: 0.286  loss_rpn_cls: 0.030  loss_rpn_loc: 0.053  time: 0.5225  data_time: 0.0052  lr: 0.003097  max_mem: 3094M
[32m[04/20 00:31:47 d2.utils.events]: [0m eta: 0:03:09  iter: 639  total_loss: 0.690  loss_cls: 0.227  loss_box_reg: 0.374  loss_rpn_cls: 0.033  loss_rpn_loc: 0.071  time: 0.5228  data_time: 0.0051  lr: 0.003197  max_mem: 3094M
[32m[04/20 00:31:57 d2.utils.events]: [0m eta: 0:02:58  iter: 659  total_loss: 0.746  loss_cls: 0.262  loss_box_reg: 0.350  loss_rpn_cls: 0.029  loss_rpn_loc: 0.069  time: 0.5230  data_time: 0.0049  lr: 0.003297  max_mem: 3094M
[32m[04/20 00:32:08 d2.utils.events]: [0m eta: 0:02:48  iter: 679  total_loss: 0.737  loss_cls: 0.239  loss_box_reg: 0.376  loss_rpn_cls: 0.040  loss_rpn_loc: 0.072  time: 0.5227  data_time: 0.0048  lr: 0.003397  max_mem: 3094M
[32m[04/20 00:32:18 d2.utils.events]: [0m eta: 0:02:37  iter: 699  total_loss: 0.733  loss_cls: 0.251  loss_box_reg: 0.411  loss_rpn_cls: 0.027  loss_rpn_loc: 0.055  time: 0.5225  data_time: 0.0048  lr: 0.003497  max_mem: 3094M
[32m[04/20 00:32:28 d2.utils.events]: [0m eta: 0:02:27  iter: 719  total_loss: 0.729  loss_cls: 0.251  loss_box_reg: 0.394  loss_rpn_cls: 0.021  loss_rpn_loc: 0.055  time: 0.5223  data_time: 0.0051  lr: 0.003596  max_mem: 3094M
[32m[04/20 00:32:39 d2.utils.events]: [0m eta: 0:02:16  iter: 739  total_loss: 0.680  loss_cls: 0.249  loss_box_reg: 0.341  loss_rpn_cls: 0.029  loss_rpn_loc: 0.060  time: 0.5221  data_time: 0.0051  lr: 0.003696  max_mem: 3094M
[32m[04/20 00:32:49 d2.utils.events]: [0m eta: 0:02:05  iter: 759  total_loss: 0.805  loss_cls: 0.252  loss_box_reg: 0.428  loss_rpn_cls: 0.032  loss_rpn_loc: 0.064  time: 0.5219  data_time: 0.0051  lr: 0.003796  max_mem: 3094M
[32m[04/20 00:33:00 d2.utils.events]: [0m eta: 0:01:55  iter: 779  total_loss: 0.741  loss_cls: 0.241  loss_box_reg: 0.361  loss_rpn_cls: 0.030  loss_rpn_loc: 0.064  time: 0.5219  data_time: 0.0048  lr: 0.003896  max_mem: 3094M
[32m[04/20 00:33:10 d2.utils.events]: [0m eta: 0:01:44  iter: 799  total_loss: 0.723  loss_cls: 0.238  loss_box_reg: 0.390  loss_rpn_cls: 0.038  loss_rpn_loc: 0.060  time: 0.5217  data_time: 0.0051  lr: 0.003996  max_mem: 3094M
[32m[04/20 00:33:20 d2.utils.events]: [0m eta: 0:01:34  iter: 819  total_loss: 0.751  loss_cls: 0.226  loss_box_reg: 0.391  loss_rpn_cls: 0.031  loss_rpn_loc: 0.066  time: 0.5216  data_time: 0.0051  lr: 0.004096  max_mem: 3094M
[32m[04/20 00:33:31 d2.utils.events]: [0m eta: 0:01:24  iter: 839  total_loss: 0.734  loss_cls: 0.239  loss_box_reg: 0.404  loss_rpn_cls: 0.030  loss_rpn_loc: 0.087  time: 0.5217  data_time: 0.0048  lr: 0.004196  max_mem: 3094M
[32m[04/20 00:33:41 d2.utils.events]: [0m eta: 0:01:13  iter: 859  total_loss: 0.652  loss_cls: 0.218  loss_box_reg: 0.364  loss_rpn_cls: 0.026  loss_rpn_loc: 0.055  time: 0.5215  data_time: 0.0053  lr: 0.004296  max_mem: 3094M
[32m[04/20 00:33:52 d2.utils.events]: [0m eta: 0:01:03  iter: 879  total_loss: 0.633  loss_cls: 0.217  loss_box_reg: 0.315  loss_rpn_cls: 0.024  loss_rpn_loc: 0.055  time: 0.5217  data_time: 0.0054  lr: 0.004396  max_mem: 3094M
[32m[04/20 00:34:03 d2.utils.events]: [0m eta: 0:00:52  iter: 899  total_loss: 0.665  loss_cls: 0.231  loss_box_reg: 0.362  loss_rpn_cls: 0.029  loss_rpn_loc: 0.044  time: 0.5220  data_time: 0.0050  lr: 0.004496  max_mem: 3094M
[32m[04/20 00:34:13 d2.utils.events]: [0m eta: 0:00:42  iter: 919  total_loss: 0.671  loss_cls: 0.212  loss_box_reg: 0.338  loss_rpn_cls: 0.029  loss_rpn_loc: 0.070  time: 0.5220  data_time: 0.0053  lr: 0.004595  max_mem: 3094M
[32m[04/20 00:34:24 d2.utils.events]: [0m eta: 0:00:31  iter: 939  total_loss: 0.671  loss_cls: 0.195  loss_box_reg: 0.327  loss_rpn_cls: 0.026  loss_rpn_loc: 0.056  time: 0.5221  data_time: 0.0051  lr: 0.004695  max_mem: 3094M
[32m[04/20 00:34:34 d2.utils.events]: [0m eta: 0:00:21  iter: 959  total_loss: 0.784  loss_cls: 0.256  loss_box_reg: 0.362  loss_rpn_cls: 0.034  loss_rpn_loc: 0.082  time: 0.5219  data_time: 0.0050  lr: 0.004795  max_mem: 3094M
[32m[04/20 00:34:45 d2.utils.events]: [0m eta: 0:00:10  iter: 979  total_loss: 0.602  loss_cls: 0.208  loss_box_reg: 0.307  loss_rpn_cls: 0.038  loss_rpn_loc: 0.048  time: 0.5220  data_time: 0.0051  lr: 0.004895  max_mem: 3094M
[5m[31mWARNING[0m [32m[04/20 00:34:59 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 00:34:59 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[5m[31mWARNING[0m [32m[04/20 00:34:59 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 00:34:59 d2.utils.events]: [0m eta: 0:00:00  iter: 999  total_loss: 0.748  loss_cls: 0.260  loss_box_reg: 0.395  loss_rpn_cls: 0.037  loss_rpn_loc: 0.071  time: 0.5221  data_time: 0.0052  lr: 0.004995  max_mem: 3094M
[32m[04/20 00:35:00 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:08:41 (0.5227 s / it)
[32m[04/20 00:35:00 d2.engine.hooks]: [0mTotal training time: 0:08:48 (0:00:07 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 00:35:04 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 00:35:04 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/20 00:35:05 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 00:35:06 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1173 s / img. ETA=0:16:37
[32m[04/20 00:35:11 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1175 s / img. ETA=0:16:36
[32m[04/20 00:35:16 d2.evaluation.evaluator]: [0mInference done 95/8355. 0.1171 s / img. ETA=0:16:28
[32m[04/20 00:35:22 d2.evaluation.evaluator]: [0mInference done 137/8355. 0.1171 s / img. ETA=0:16:23
[32m[04/20 00:35:27 d2.evaluation.evaluator]: [0mInference done 179/8355. 0.1170 s / img. ETA=0:16:18
[32m[04/20 00:35:32 d2.evaluation.evaluator]: [0mInference done 221/8355. 0.1170 s / img. ETA=0:16:13
[32m[04/20 00:35:37 d2.evaluation.evaluator]: [0mInference done 263/8355. 0.1171 s / img. ETA=0:16:08
[32m[04/20 00:35:42 d2.evaluation.evaluator]: [0mInference done 305/8355. 0.1171 s / img. ETA=0:16:04
[32m[04/20 00:35:47 d2.evaluation.evaluator]: [0mInference done 347/8355. 0.1171 s / img. ETA=0:15:59
[32m[04/20 00:35:52 d2.evaluation.evaluator]: [0mInference done 389/8355. 0.1171 s / img. ETA=0:15:54
[32m[04/20 00:35:57 d2.evaluation.evaluator]: [0mInference done 431/8355. 0.1171 s / img. ETA=0:15:49
[32m[04/20 00:36:02 d2.evaluation.evaluator]: [0mInference done 473/8355. 0.1171 s / img. ETA=0:15:44
[32m[04/20 00:36:07 d2.evaluation.evaluator]: [0mInference done 515/8355. 0.1170 s / img. ETA=0:15:38
[32m[04/20 00:36:12 d2.evaluation.evaluator]: [0mInference done 557/8355. 0.1170 s / img. ETA=0:15:33
[32m[04/20 00:36:17 d2.evaluation.evaluator]: [0mInference done 599/8355. 0.1170 s / img. ETA=0:15:28
[32m[04/20 00:36:22 d2.evaluation.evaluator]: [0mInference done 641/8355. 0.1170 s / img. ETA=0:15:23
[32m[04/20 00:36:27 d2.evaluation.evaluator]: [0mInference done 683/8355. 0.1171 s / img. ETA=0:15:19
[32m[04/20 00:36:32 d2.evaluation.evaluator]: [0mInference done 725/8355. 0.1171 s / img. ETA=0:15:14
[32m[04/20 00:36:37 d2.evaluation.evaluator]: [0mInference done 767/8355. 0.1171 s / img. ETA=0:15:09
[32m[04/20 00:36:42 d2.evaluation.evaluator]: [0mInference done 809/8355. 0.1171 s / img. ETA=0:15:04
[32m[04/20 00:36:47 d2.evaluation.evaluator]: [0mInference done 851/8355. 0.1170 s / img. ETA=0:14:58
[32m[04/20 00:36:52 d2.evaluation.evaluator]: [0mInference done 893/8355. 0.1171 s / img. ETA=0:14:54
[32m[04/20 00:36:57 d2.evaluation.evaluator]: [0mInference done 935/8355. 0.1171 s / img. ETA=0:14:49
[32m[04/20 00:37:02 d2.evaluation.evaluator]: [0mInference done 977/8355. 0.1171 s / img. ETA=0:14:44
[32m[04/20 00:37:07 d2.evaluation.evaluator]: [0mInference done 1019/8355. 0.1171 s / img. ETA=0:14:39
[32m[04/20 00:37:12 d2.evaluation.evaluator]: [0mInference done 1061/8355. 0.1171 s / img. ETA=0:14:33
[32m[04/20 00:37:17 d2.evaluation.evaluator]: [0mInference done 1103/8355. 0.1171 s / img. ETA=0:14:28
[32m[04/20 00:37:22 d2.evaluation.evaluator]: [0mInference done 1145/8355. 0.1171 s / img. ETA=0:14:23
[32m[04/20 00:37:27 d2.evaluation.evaluator]: [0mInference done 1187/8355. 0.1171 s / img. ETA=0:14:18
[32m[04/20 00:37:32 d2.evaluation.evaluator]: [0mInference done 1229/8355. 0.1170 s / img. ETA=0:14:13
[32m[04/20 00:37:37 d2.evaluation.evaluator]: [0mInference done 1271/8355. 0.1170 s / img. ETA=0:14:08
[32m[04/20 00:37:42 d2.evaluation.evaluator]: [0mInference done 1313/8355. 0.1170 s / img. ETA=0:14:03
[32m[04/20 00:37:47 d2.evaluation.evaluator]: [0mInference done 1356/8355. 0.1170 s / img. ETA=0:13:57
[32m[04/20 00:37:53 d2.evaluation.evaluator]: [0mInference done 1399/8355. 0.1170 s / img. ETA=0:13:52
[32m[04/20 00:37:58 d2.evaluation.evaluator]: [0mInference done 1442/8355. 0.1170 s / img. ETA=0:13:47
[32m[04/20 00:38:03 d2.evaluation.evaluator]: [0mInference done 1484/8355. 0.1170 s / img. ETA=0:13:42
[32m[04/20 00:38:08 d2.evaluation.evaluator]: [0mInference done 1526/8355. 0.1170 s / img. ETA=0:13:37
[32m[04/20 00:38:13 d2.evaluation.evaluator]: [0mInference done 1568/8355. 0.1170 s / img. ETA=0:13:32
[32m[04/20 00:38:18 d2.evaluation.evaluator]: [0mInference done 1610/8355. 0.1170 s / img. ETA=0:13:27
[32m[04/20 00:38:23 d2.evaluation.evaluator]: [0mInference done 1652/8355. 0.1171 s / img. ETA=0:13:22
[32m[04/20 00:38:28 d2.evaluation.evaluator]: [0mInference done 1694/8355. 0.1171 s / img. ETA=0:13:17
[32m[04/20 00:38:33 d2.evaluation.evaluator]: [0mInference done 1736/8355. 0.1171 s / img. ETA=0:13:12
[32m[04/20 00:38:38 d2.evaluation.evaluator]: [0mInference done 1778/8355. 0.1171 s / img. ETA=0:13:07
[32m[04/20 00:38:43 d2.evaluation.evaluator]: [0mInference done 1820/8355. 0.1171 s / img. ETA=0:13:02
[32m[04/20 00:38:48 d2.evaluation.evaluator]: [0mInference done 1862/8355. 0.1171 s / img. ETA=0:12:57
[32m[04/20 00:38:53 d2.evaluation.evaluator]: [0mInference done 1904/8355. 0.1172 s / img. ETA=0:12:52
[32m[04/20 00:38:58 d2.evaluation.evaluator]: [0mInference done 1946/8355. 0.1171 s / img. ETA=0:12:47
[32m[04/20 00:39:03 d2.evaluation.evaluator]: [0mInference done 1988/8355. 0.1171 s / img. ETA=0:12:42
[32m[04/20 00:39:08 d2.evaluation.evaluator]: [0mInference done 2030/8355. 0.1172 s / img. ETA=0:12:37
[32m[04/20 00:39:13 d2.evaluation.evaluator]: [0mInference done 2072/8355. 0.1172 s / img. ETA=0:12:32
[32m[04/20 00:39:18 d2.evaluation.evaluator]: [0mInference done 2114/8355. 0.1172 s / img. ETA=0:12:27
[32m[04/20 00:39:23 d2.evaluation.evaluator]: [0mInference done 2156/8355. 0.1172 s / img. ETA=0:12:22
[32m[04/20 00:39:29 d2.evaluation.evaluator]: [0mInference done 2198/8355. 0.1172 s / img. ETA=0:12:17
[32m[04/20 00:39:34 d2.evaluation.evaluator]: [0mInference done 2238/8355. 0.1173 s / img. ETA=0:12:13
[32m[04/20 00:39:39 d2.evaluation.evaluator]: [0mInference done 2280/8355. 0.1173 s / img. ETA=0:12:08
[32m[04/20 00:39:44 d2.evaluation.evaluator]: [0mInference done 2322/8355. 0.1174 s / img. ETA=0:12:03
[32m[04/20 00:39:49 d2.evaluation.evaluator]: [0mInference done 2364/8355. 0.1174 s / img. ETA=0:11:59
[32m[04/20 00:39:54 d2.evaluation.evaluator]: [0mInference done 2406/8355. 0.1174 s / img. ETA=0:11:53
[32m[04/20 00:39:59 d2.evaluation.evaluator]: [0mInference done 2448/8355. 0.1174 s / img. ETA=0:11:49
[32m[04/20 00:40:04 d2.evaluation.evaluator]: [0mInference done 2490/8355. 0.1174 s / img. ETA=0:11:44
[32m[04/20 00:40:09 d2.evaluation.evaluator]: [0mInference done 2532/8355. 0.1174 s / img. ETA=0:11:38
[32m[04/20 00:40:14 d2.evaluation.evaluator]: [0mInference done 2574/8355. 0.1174 s / img. ETA=0:11:33
[32m[04/20 00:40:19 d2.evaluation.evaluator]: [0mInference done 2616/8355. 0.1174 s / img. ETA=0:11:28
[32m[04/20 00:40:24 d2.evaluation.evaluator]: [0mInference done 2658/8355. 0.1174 s / img. ETA=0:11:23
[32m[04/20 00:40:29 d2.evaluation.evaluator]: [0mInference done 2700/8355. 0.1174 s / img. ETA=0:11:18
[32m[04/20 00:40:34 d2.evaluation.evaluator]: [0mInference done 2742/8355. 0.1174 s / img. ETA=0:11:13
[32m[04/20 00:40:39 d2.evaluation.evaluator]: [0mInference done 2784/8355. 0.1174 s / img. ETA=0:11:08
[32m[04/20 00:40:44 d2.evaluation.evaluator]: [0mInference done 2826/8355. 0.1174 s / img. ETA=0:11:03
[32m[04/20 00:40:50 d2.evaluation.evaluator]: [0mInference done 2868/8355. 0.1174 s / img. ETA=0:10:58
[32m[04/20 00:40:55 d2.evaluation.evaluator]: [0mInference done 2910/8355. 0.1174 s / img. ETA=0:10:53
[32m[04/20 00:41:00 d2.evaluation.evaluator]: [0mInference done 2952/8355. 0.1174 s / img. ETA=0:10:48
[32m[04/20 00:41:05 d2.evaluation.evaluator]: [0mInference done 2994/8355. 0.1174 s / img. ETA=0:10:43
[32m[04/20 00:41:10 d2.evaluation.evaluator]: [0mInference done 3036/8355. 0.1175 s / img. ETA=0:10:38
[32m[04/20 00:41:15 d2.evaluation.evaluator]: [0mInference done 3078/8355. 0.1175 s / img. ETA=0:10:33
[32m[04/20 00:41:20 d2.evaluation.evaluator]: [0mInference done 3120/8355. 0.1175 s / img. ETA=0:10:28
[32m[04/20 00:41:25 d2.evaluation.evaluator]: [0mInference done 3162/8355. 0.1175 s / img. ETA=0:10:23
[32m[04/20 00:41:30 d2.evaluation.evaluator]: [0mInference done 3204/8355. 0.1175 s / img. ETA=0:10:18
[32m[04/20 00:41:35 d2.evaluation.evaluator]: [0mInference done 3246/8355. 0.1175 s / img. ETA=0:10:13
[32m[04/20 00:41:40 d2.evaluation.evaluator]: [0mInference done 3288/8355. 0.1175 s / img. ETA=0:10:08
[32m[04/20 00:41:45 d2.evaluation.evaluator]: [0mInference done 3330/8355. 0.1175 s / img. ETA=0:10:03
[32m[04/20 00:41:50 d2.evaluation.evaluator]: [0mInference done 3372/8355. 0.1175 s / img. ETA=0:09:58
[32m[04/20 00:41:55 d2.evaluation.evaluator]: [0mInference done 3414/8355. 0.1175 s / img. ETA=0:09:53
[32m[04/20 00:42:00 d2.evaluation.evaluator]: [0mInference done 3456/8355. 0.1175 s / img. ETA=0:09:48
[32m[04/20 00:42:05 d2.evaluation.evaluator]: [0mInference done 3498/8355. 0.1175 s / img. ETA=0:09:43
[32m[04/20 00:42:11 d2.evaluation.evaluator]: [0mInference done 3540/8355. 0.1175 s / img. ETA=0:09:38
[32m[04/20 00:42:16 d2.evaluation.evaluator]: [0mInference done 3581/8355. 0.1175 s / img. ETA=0:09:33
[32m[04/20 00:42:21 d2.evaluation.evaluator]: [0mInference done 3622/8355. 0.1176 s / img. ETA=0:09:29
[32m[04/20 00:42:26 d2.evaluation.evaluator]: [0mInference done 3664/8355. 0.1176 s / img. ETA=0:09:24
[32m[04/20 00:42:31 d2.evaluation.evaluator]: [0mInference done 3706/8355. 0.1176 s / img. ETA=0:09:19
[32m[04/20 00:42:36 d2.evaluation.evaluator]: [0mInference done 3748/8355. 0.1176 s / img. ETA=0:09:14
[32m[04/20 00:42:41 d2.evaluation.evaluator]: [0mInference done 3790/8355. 0.1176 s / img. ETA=0:09:09
[32m[04/20 00:42:46 d2.evaluation.evaluator]: [0mInference done 3832/8355. 0.1176 s / img. ETA=0:09:04
[32m[04/20 00:42:51 d2.evaluation.evaluator]: [0mInference done 3874/8355. 0.1176 s / img. ETA=0:08:59
[32m[04/20 00:42:56 d2.evaluation.evaluator]: [0mInference done 3916/8355. 0.1176 s / img. ETA=0:08:54
[32m[04/20 00:43:01 d2.evaluation.evaluator]: [0mInference done 3958/8355. 0.1176 s / img. ETA=0:08:49
[32m[04/20 00:43:06 d2.evaluation.evaluator]: [0mInference done 4000/8355. 0.1176 s / img. ETA=0:08:43
[32m[04/20 00:43:12 d2.evaluation.evaluator]: [0mInference done 4042/8355. 0.1176 s / img. ETA=0:08:38
[32m[04/20 00:43:17 d2.evaluation.evaluator]: [0mInference done 4084/8355. 0.1176 s / img. ETA=0:08:33
[32m[04/20 00:43:22 d2.evaluation.evaluator]: [0mInference done 4126/8355. 0.1176 s / img. ETA=0:08:28
[32m[04/20 00:43:27 d2.evaluation.evaluator]: [0mInference done 4167/8355. 0.1176 s / img. ETA=0:08:24
[32m[04/20 00:43:32 d2.evaluation.evaluator]: [0mInference done 4209/8355. 0.1176 s / img. ETA=0:08:19
[32m[04/20 00:43:37 d2.evaluation.evaluator]: [0mInference done 4251/8355. 0.1176 s / img. ETA=0:08:14
[32m[04/20 00:43:42 d2.evaluation.evaluator]: [0mInference done 4293/8355. 0.1176 s / img. ETA=0:08:08
[32m[04/20 00:43:47 d2.evaluation.evaluator]: [0mInference done 4335/8355. 0.1176 s / img. ETA=0:08:03
[32m[04/20 00:43:52 d2.evaluation.evaluator]: [0mInference done 4377/8355. 0.1176 s / img. ETA=0:07:58
[32m[04/20 00:43:57 d2.evaluation.evaluator]: [0mInference done 4419/8355. 0.1176 s / img. ETA=0:07:53
[32m[04/20 00:44:02 d2.evaluation.evaluator]: [0mInference done 4461/8355. 0.1176 s / img. ETA=0:07:48
[32m[04/20 00:44:07 d2.evaluation.evaluator]: [0mInference done 4503/8355. 0.1176 s / img. ETA=0:07:43
[32m[04/20 00:44:12 d2.evaluation.evaluator]: [0mInference done 4545/8355. 0.1176 s / img. ETA=0:07:38
[32m[04/20 00:44:17 d2.evaluation.evaluator]: [0mInference done 4587/8355. 0.1177 s / img. ETA=0:07:33
[32m[04/20 00:44:22 d2.evaluation.evaluator]: [0mInference done 4629/8355. 0.1177 s / img. ETA=0:07:28
[32m[04/20 00:44:27 d2.evaluation.evaluator]: [0mInference done 4671/8355. 0.1177 s / img. ETA=0:07:23
[32m[04/20 00:44:33 d2.evaluation.evaluator]: [0mInference done 4713/8355. 0.1177 s / img. ETA=0:07:18
[32m[04/20 00:44:38 d2.evaluation.evaluator]: [0mInference done 4755/8355. 0.1177 s / img. ETA=0:07:13
[32m[04/20 00:44:43 d2.evaluation.evaluator]: [0mInference done 4797/8355. 0.1177 s / img. ETA=0:07:08
[32m[04/20 00:44:48 d2.evaluation.evaluator]: [0mInference done 4839/8355. 0.1177 s / img. ETA=0:07:03
[32m[04/20 00:44:53 d2.evaluation.evaluator]: [0mInference done 4881/8355. 0.1177 s / img. ETA=0:06:58
[32m[04/20 00:44:58 d2.evaluation.evaluator]: [0mInference done 4923/8355. 0.1177 s / img. ETA=0:06:53
[32m[04/20 00:45:03 d2.evaluation.evaluator]: [0mInference done 4965/8355. 0.1177 s / img. ETA=0:06:48
[32m[04/20 00:45:08 d2.evaluation.evaluator]: [0mInference done 5007/8355. 0.1177 s / img. ETA=0:06:43
[32m[04/20 00:45:13 d2.evaluation.evaluator]: [0mInference done 5049/8355. 0.1177 s / img. ETA=0:06:38
[32m[04/20 00:45:18 d2.evaluation.evaluator]: [0mInference done 5091/8355. 0.1177 s / img. ETA=0:06:33
[32m[04/20 00:45:23 d2.evaluation.evaluator]: [0mInference done 5132/8355. 0.1177 s / img. ETA=0:06:28
[32m[04/20 00:45:28 d2.evaluation.evaluator]: [0mInference done 5174/8355. 0.1177 s / img. ETA=0:06:23
[32m[04/20 00:45:33 d2.evaluation.evaluator]: [0mInference done 5216/8355. 0.1177 s / img. ETA=0:06:18
[32m[04/20 00:45:38 d2.evaluation.evaluator]: [0mInference done 5258/8355. 0.1177 s / img. ETA=0:06:12
[32m[04/20 00:45:43 d2.evaluation.evaluator]: [0mInference done 5300/8355. 0.1177 s / img. ETA=0:06:07
[32m[04/20 00:45:49 d2.evaluation.evaluator]: [0mInference done 5341/8355. 0.1177 s / img. ETA=0:06:03
[32m[04/20 00:45:54 d2.evaluation.evaluator]: [0mInference done 5383/8355. 0.1177 s / img. ETA=0:05:58
[32m[04/20 00:45:59 d2.evaluation.evaluator]: [0mInference done 5425/8355. 0.1177 s / img. ETA=0:05:52
[32m[04/20 00:46:04 d2.evaluation.evaluator]: [0mInference done 5467/8355. 0.1177 s / img. ETA=0:05:47
[32m[04/20 00:46:09 d2.evaluation.evaluator]: [0mInference done 5509/8355. 0.1177 s / img. ETA=0:05:42
[32m[04/20 00:46:14 d2.evaluation.evaluator]: [0mInference done 5551/8355. 0.1177 s / img. ETA=0:05:37
[32m[04/20 00:46:19 d2.evaluation.evaluator]: [0mInference done 5593/8355. 0.1177 s / img. ETA=0:05:32
[32m[04/20 00:46:24 d2.evaluation.evaluator]: [0mInference done 5635/8355. 0.1177 s / img. ETA=0:05:27
[32m[04/20 00:46:29 d2.evaluation.evaluator]: [0mInference done 5677/8355. 0.1177 s / img. ETA=0:05:22
[32m[04/20 00:46:34 d2.evaluation.evaluator]: [0mInference done 5719/8355. 0.1178 s / img. ETA=0:05:17
[32m[04/20 00:46:39 d2.evaluation.evaluator]: [0mInference done 5761/8355. 0.1178 s / img. ETA=0:05:12
[32m[04/20 00:46:44 d2.evaluation.evaluator]: [0mInference done 5803/8355. 0.1178 s / img. ETA=0:05:07
[32m[04/20 00:46:50 d2.evaluation.evaluator]: [0mInference done 5845/8355. 0.1178 s / img. ETA=0:05:02
[32m[04/20 00:46:55 d2.evaluation.evaluator]: [0mInference done 5886/8355. 0.1178 s / img. ETA=0:04:57
[32m[04/20 00:47:00 d2.evaluation.evaluator]: [0mInference done 5928/8355. 0.1178 s / img. ETA=0:04:52
[32m[04/20 00:47:05 d2.evaluation.evaluator]: [0mInference done 5970/8355. 0.1178 s / img. ETA=0:04:47
[32m[04/20 00:47:10 d2.evaluation.evaluator]: [0mInference done 6012/8355. 0.1178 s / img. ETA=0:04:42
[32m[04/20 00:47:15 d2.evaluation.evaluator]: [0mInference done 6054/8355. 0.1178 s / img. ETA=0:04:37
[32m[04/20 00:47:20 d2.evaluation.evaluator]: [0mInference done 6096/8355. 0.1178 s / img. ETA=0:04:32
[32m[04/20 00:47:25 d2.evaluation.evaluator]: [0mInference done 6138/8355. 0.1178 s / img. ETA=0:04:27
[32m[04/20 00:47:30 d2.evaluation.evaluator]: [0mInference done 6180/8355. 0.1178 s / img. ETA=0:04:22
[32m[04/20 00:47:35 d2.evaluation.evaluator]: [0mInference done 6221/8355. 0.1179 s / img. ETA=0:04:17
[32m[04/20 00:47:40 d2.evaluation.evaluator]: [0mInference done 6263/8355. 0.1179 s / img. ETA=0:04:12
[32m[04/20 00:47:46 d2.evaluation.evaluator]: [0mInference done 6305/8355. 0.1179 s / img. ETA=0:04:07
[32m[04/20 00:47:51 d2.evaluation.evaluator]: [0mInference done 6347/8355. 0.1179 s / img. ETA=0:04:02
[32m[04/20 00:47:56 d2.evaluation.evaluator]: [0mInference done 6389/8355. 0.1179 s / img. ETA=0:03:57
[32m[04/20 00:48:01 d2.evaluation.evaluator]: [0mInference done 6431/8355. 0.1179 s / img. ETA=0:03:52
[32m[04/20 00:48:06 d2.evaluation.evaluator]: [0mInference done 6473/8355. 0.1179 s / img. ETA=0:03:46
[32m[04/20 00:48:11 d2.evaluation.evaluator]: [0mInference done 6515/8355. 0.1179 s / img. ETA=0:03:41
[32m[04/20 00:48:16 d2.evaluation.evaluator]: [0mInference done 6557/8355. 0.1179 s / img. ETA=0:03:36
[32m[04/20 00:48:21 d2.evaluation.evaluator]: [0mInference done 6599/8355. 0.1179 s / img. ETA=0:03:31
[32m[04/20 00:48:26 d2.evaluation.evaluator]: [0mInference done 6641/8355. 0.1179 s / img. ETA=0:03:26
[32m[04/20 00:48:31 d2.evaluation.evaluator]: [0mInference done 6683/8355. 0.1179 s / img. ETA=0:03:21
[32m[04/20 00:48:36 d2.evaluation.evaluator]: [0mInference done 6725/8355. 0.1179 s / img. ETA=0:03:16
[32m[04/20 00:48:41 d2.evaluation.evaluator]: [0mInference done 6767/8355. 0.1179 s / img. ETA=0:03:11
[32m[04/20 00:48:46 d2.evaluation.evaluator]: [0mInference done 6809/8355. 0.1179 s / img. ETA=0:03:06
[32m[04/20 00:48:51 d2.evaluation.evaluator]: [0mInference done 6851/8355. 0.1179 s / img. ETA=0:03:01
[32m[04/20 00:48:56 d2.evaluation.evaluator]: [0mInference done 6893/8355. 0.1179 s / img. ETA=0:02:56
[32m[04/20 00:49:01 d2.evaluation.evaluator]: [0mInference done 6935/8355. 0.1179 s / img. ETA=0:02:51
[32m[04/20 00:49:07 d2.evaluation.evaluator]: [0mInference done 6977/8355. 0.1179 s / img. ETA=0:02:46
[32m[04/20 00:49:12 d2.evaluation.evaluator]: [0mInference done 7019/8355. 0.1179 s / img. ETA=0:02:41
[32m[04/20 00:49:17 d2.evaluation.evaluator]: [0mInference done 7061/8355. 0.1179 s / img. ETA=0:02:36
[32m[04/20 00:49:22 d2.evaluation.evaluator]: [0mInference done 7103/8355. 0.1179 s / img. ETA=0:02:31
[32m[04/20 00:49:27 d2.evaluation.evaluator]: [0mInference done 7145/8355. 0.1179 s / img. ETA=0:02:25
[32m[04/20 00:49:32 d2.evaluation.evaluator]: [0mInference done 7186/8355. 0.1179 s / img. ETA=0:02:21
[32m[04/20 00:49:37 d2.evaluation.evaluator]: [0mInference done 7228/8355. 0.1179 s / img. ETA=0:02:15
[32m[04/20 00:49:42 d2.evaluation.evaluator]: [0mInference done 7269/8355. 0.1179 s / img. ETA=0:02:11
[32m[04/20 00:49:47 d2.evaluation.evaluator]: [0mInference done 7311/8355. 0.1179 s / img. ETA=0:02:05
[32m[04/20 00:49:52 d2.evaluation.evaluator]: [0mInference done 7352/8355. 0.1179 s / img. ETA=0:02:01
[32m[04/20 00:49:57 d2.evaluation.evaluator]: [0mInference done 7393/8355. 0.1179 s / img. ETA=0:01:56
[32m[04/20 00:50:02 d2.evaluation.evaluator]: [0mInference done 7434/8355. 0.1180 s / img. ETA=0:01:51
[32m[04/20 00:50:07 d2.evaluation.evaluator]: [0mInference done 7475/8355. 0.1180 s / img. ETA=0:01:46
[32m[04/20 00:50:12 d2.evaluation.evaluator]: [0mInference done 7516/8355. 0.1180 s / img. ETA=0:01:41
[32m[04/20 00:50:17 d2.evaluation.evaluator]: [0mInference done 7558/8355. 0.1180 s / img. ETA=0:01:36
[32m[04/20 00:50:23 d2.evaluation.evaluator]: [0mInference done 7600/8355. 0.1180 s / img. ETA=0:01:31
[32m[04/20 00:50:28 d2.evaluation.evaluator]: [0mInference done 7641/8355. 0.1180 s / img. ETA=0:01:26
[32m[04/20 00:50:33 d2.evaluation.evaluator]: [0mInference done 7683/8355. 0.1180 s / img. ETA=0:01:21
[32m[04/20 00:50:38 d2.evaluation.evaluator]: [0mInference done 7724/8355. 0.1180 s / img. ETA=0:01:16
[32m[04/20 00:50:43 d2.evaluation.evaluator]: [0mInference done 7766/8355. 0.1180 s / img. ETA=0:01:11
[32m[04/20 00:50:48 d2.evaluation.evaluator]: [0mInference done 7808/8355. 0.1180 s / img. ETA=0:01:06
[32m[04/20 00:50:53 d2.evaluation.evaluator]: [0mInference done 7849/8355. 0.1180 s / img. ETA=0:01:01
[32m[04/20 00:50:58 d2.evaluation.evaluator]: [0mInference done 7890/8355. 0.1180 s / img. ETA=0:00:56
[32m[04/20 00:51:03 d2.evaluation.evaluator]: [0mInference done 7932/8355. 0.1180 s / img. ETA=0:00:51
[32m[04/20 00:51:08 d2.evaluation.evaluator]: [0mInference done 7974/8355. 0.1180 s / img. ETA=0:00:46
[32m[04/20 00:51:13 d2.evaluation.evaluator]: [0mInference done 8016/8355. 0.1180 s / img. ETA=0:00:40
[32m[04/20 00:51:18 d2.evaluation.evaluator]: [0mInference done 8058/8355. 0.1180 s / img. ETA=0:00:35
[32m[04/20 00:51:23 d2.evaluation.evaluator]: [0mInference done 8100/8355. 0.1180 s / img. ETA=0:00:30
[32m[04/20 00:51:28 d2.evaluation.evaluator]: [0mInference done 8142/8355. 0.1180 s / img. ETA=0:00:25
[32m[04/20 00:51:33 d2.evaluation.evaluator]: [0mInference done 8184/8355. 0.1180 s / img. ETA=0:00:20
[32m[04/20 00:51:38 d2.evaluation.evaluator]: [0mInference done 8226/8355. 0.1180 s / img. ETA=0:00:15
[32m[04/20 00:51:43 d2.evaluation.evaluator]: [0mInference done 8268/8355. 0.1180 s / img. ETA=0:00:10
[32m[04/20 00:51:49 d2.evaluation.evaluator]: [0mInference done 8310/8355. 0.1180 s / img. ETA=0:00:05
[32m[04/20 00:51:54 d2.evaluation.evaluator]: [0mInference done 8352/8355. 0.1180 s / img. ETA=0:00:00
[32m[04/20 00:51:54 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:48.280311 (0.120752 s / img per device, on 1 devices)
[32m[04/20 00:51:54 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:25 (0.118030 s / img per device, on 1 devices)
[32m[04/20 00:51:54 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 00:51:54 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 00:51:55 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=21.48s).
Accumulating evaluation results...
DONE (t=2.49s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.236
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.500
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.184
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.504
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.128
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.299
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.235
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.390
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.563
[32m[04/20 00:52:19 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 23.563 | 49.989 | 18.403 | 17.042 | 33.322 | 50.405 |
[32m[04/20 00:52:19 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 31.429 | bicycle       | 13.486 | car            | 37.037 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | 12.299 | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 00:52:20 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 00:52:20 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[32m[04/20 00:52:20 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 00:52:22 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1166 s / img. ETA=0:02:28
[32m[04/20 00:52:27 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1176 s / img. ETA=0:02:24
[32m[04/20 00:52:32 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1180 s / img. ETA=0:02:20
[32m[04/20 00:52:37 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1179 s / img. ETA=0:02:15
[32m[04/20 00:52:42 d2.evaluation.evaluator]: [0mInference done 179/1257. 0.1177 s / img. ETA=0:02:09
[32m[04/20 00:52:47 d2.evaluation.evaluator]: [0mInference done 221/1257. 0.1175 s / img. ETA=0:02:04
[32m[04/20 00:52:52 d2.evaluation.evaluator]: [0mInference done 263/1257. 0.1175 s / img. ETA=0:01:59
[32m[04/20 00:52:57 d2.evaluation.evaluator]: [0mInference done 305/1257. 0.1175 s / img. ETA=0:01:54
[32m[04/20 00:53:02 d2.evaluation.evaluator]: [0mInference done 347/1257. 0.1175 s / img. ETA=0:01:49
[32m[04/20 00:53:07 d2.evaluation.evaluator]: [0mInference done 389/1257. 0.1174 s / img. ETA=0:01:44
[32m[04/20 00:53:12 d2.evaluation.evaluator]: [0mInference done 431/1257. 0.1174 s / img. ETA=0:01:39
[32m[04/20 00:53:17 d2.evaluation.evaluator]: [0mInference done 473/1257. 0.1174 s / img. ETA=0:01:34
[32m[04/20 00:53:22 d2.evaluation.evaluator]: [0mInference done 515/1257. 0.1175 s / img. ETA=0:01:29
[32m[04/20 00:53:27 d2.evaluation.evaluator]: [0mInference done 557/1257. 0.1175 s / img. ETA=0:01:24
[32m[04/20 00:53:33 d2.evaluation.evaluator]: [0mInference done 599/1257. 0.1175 s / img. ETA=0:01:19
[32m[04/20 00:53:38 d2.evaluation.evaluator]: [0mInference done 641/1257. 0.1176 s / img. ETA=0:01:14
[32m[04/20 00:53:43 d2.evaluation.evaluator]: [0mInference done 683/1257. 0.1176 s / img. ETA=0:01:09
[32m[04/20 00:53:48 d2.evaluation.evaluator]: [0mInference done 725/1257. 0.1176 s / img. ETA=0:01:03
[32m[04/20 00:53:53 d2.evaluation.evaluator]: [0mInference done 767/1257. 0.1176 s / img. ETA=0:00:58
[32m[04/20 00:53:58 d2.evaluation.evaluator]: [0mInference done 809/1257. 0.1176 s / img. ETA=0:00:53
[32m[04/20 00:54:03 d2.evaluation.evaluator]: [0mInference done 851/1257. 0.1176 s / img. ETA=0:00:48
[32m[04/20 00:54:08 d2.evaluation.evaluator]: [0mInference done 893/1257. 0.1176 s / img. ETA=0:00:43
[32m[04/20 00:54:13 d2.evaluation.evaluator]: [0mInference done 935/1257. 0.1176 s / img. ETA=0:00:38
[32m[04/20 00:54:18 d2.evaluation.evaluator]: [0mInference done 977/1257. 0.1176 s / img. ETA=0:00:33
[32m[04/20 00:54:23 d2.evaluation.evaluator]: [0mInference done 1019/1257. 0.1176 s / img. ETA=0:00:28
[32m[04/20 00:54:28 d2.evaluation.evaluator]: [0mInference done 1061/1257. 0.1176 s / img. ETA=0:00:23
[32m[04/20 00:54:33 d2.evaluation.evaluator]: [0mInference done 1103/1257. 0.1176 s / img. ETA=0:00:18
[32m[04/20 00:54:38 d2.evaluation.evaluator]: [0mInference done 1145/1257. 0.1176 s / img. ETA=0:00:13
[32m[04/20 00:54:43 d2.evaluation.evaluator]: [0mInference done 1187/1257. 0.1176 s / img. ETA=0:00:08
[32m[04/20 00:54:48 d2.evaluation.evaluator]: [0mInference done 1229/1257. 0.1176 s / img. ETA=0:00:03
[32m[04/20 00:54:52 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:30.586166 (0.120276 s / img per device, on 1 devices)
[32m[04/20 00:54:52 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:27 (0.117591 s / img per device, on 1 devices)
[32m[04/20 00:54:52 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 00:54:52 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 00:54:52 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.93s).
Accumulating evaluation results...
DONE (t=0.39s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.161
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.326
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.146
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.104
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.198
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.083
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.210
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.238
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.412
[32m[04/20 00:54:55 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 16.094 | 32.550 | 14.572 | 10.353 | 19.832 | 36.867 |
[32m[04/20 00:54:55 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 22.567 | bicycle       | 4.447 | car            | 37.362 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | 0.000 | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  7  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 00:54:56 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 00:54:57 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 00:54:57 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/20 00:54:57 d2.data.build]: [0mRemoved 889 images with no usable annotations. 7466 images left.
[32m[04/20 00:54:57 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 00:54:57 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 00:54:58 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 00:55:09 d2.utils.events]: [0m eta: 0:08:38  iter: 19  total_loss: 0.834  loss_cls: 0.270  loss_box_reg: 0.432  loss_rpn_cls: 0.035  loss_rpn_loc: 0.058  time: 0.5248  data_time: 0.0220  lr: 0.000100  max_mem: 3094M
[32m[04/20 00:55:19 d2.utils.events]: [0m eta: 0:08:23  iter: 39  total_loss: 0.654  loss_cls: 0.217  loss_box_reg: 0.339  loss_rpn_cls: 0.026  loss_rpn_loc: 0.048  time: 0.5235  data_time: 0.0053  lr: 0.000200  max_mem: 3094M
[32m[04/20 00:55:30 d2.utils.events]: [0m eta: 0:08:13  iter: 59  total_loss: 0.684  loss_cls: 0.213  loss_box_reg: 0.388  loss_rpn_cls: 0.020  loss_rpn_loc: 0.056  time: 0.5241  data_time: 0.0052  lr: 0.000300  max_mem: 3094M
[32m[04/20 00:55:41 d2.utils.events]: [0m eta: 0:08:04  iter: 79  total_loss: 0.730  loss_cls: 0.251  loss_box_reg: 0.374  loss_rpn_cls: 0.028  loss_rpn_loc: 0.074  time: 0.5257  data_time: 0.0055  lr: 0.000400  max_mem: 3094M
[32m[04/20 00:55:51 d2.utils.events]: [0m eta: 0:07:52  iter: 99  total_loss: 0.728  loss_cls: 0.241  loss_box_reg: 0.328  loss_rpn_cls: 0.030  loss_rpn_loc: 0.056  time: 0.5251  data_time: 0.0052  lr: 0.000500  max_mem: 3094M
[32m[04/20 00:56:01 d2.utils.events]: [0m eta: 0:07:41  iter: 119  total_loss: 0.628  loss_cls: 0.212  loss_box_reg: 0.358  loss_rpn_cls: 0.035  loss_rpn_loc: 0.082  time: 0.5231  data_time: 0.0053  lr: 0.000599  max_mem: 3094M
[32m[04/20 00:56:12 d2.utils.events]: [0m eta: 0:07:32  iter: 139  total_loss: 0.720  loss_cls: 0.247  loss_box_reg: 0.405  loss_rpn_cls: 0.030  loss_rpn_loc: 0.071  time: 0.5235  data_time: 0.0051  lr: 0.000699  max_mem: 3094M
[32m[04/20 00:56:22 d2.utils.events]: [0m eta: 0:07:20  iter: 159  total_loss: 0.692  loss_cls: 0.212  loss_box_reg: 0.356  loss_rpn_cls: 0.024  loss_rpn_loc: 0.046  time: 0.5205  data_time: 0.0051  lr: 0.000799  max_mem: 3094M
[32m[04/20 00:56:33 d2.utils.events]: [0m eta: 0:07:10  iter: 179  total_loss: 0.628  loss_cls: 0.222  loss_box_reg: 0.354  loss_rpn_cls: 0.020  loss_rpn_loc: 0.047  time: 0.5213  data_time: 0.0052  lr: 0.000899  max_mem: 3094M
[32m[04/20 00:56:43 d2.utils.events]: [0m eta: 0:06:59  iter: 199  total_loss: 0.683  loss_cls: 0.227  loss_box_reg: 0.358  loss_rpn_cls: 0.020  loss_rpn_loc: 0.059  time: 0.5201  data_time: 0.0051  lr: 0.000999  max_mem: 3094M
[32m[04/20 00:56:53 d2.utils.events]: [0m eta: 0:06:48  iter: 219  total_loss: 0.616  loss_cls: 0.191  loss_box_reg: 0.350  loss_rpn_cls: 0.023  loss_rpn_loc: 0.058  time: 0.5199  data_time: 0.0048  lr: 0.001099  max_mem: 3094M
[32m[04/20 00:57:04 d2.utils.events]: [0m eta: 0:06:39  iter: 239  total_loss: 0.726  loss_cls: 0.239  loss_box_reg: 0.397  loss_rpn_cls: 0.021  loss_rpn_loc: 0.058  time: 0.5221  data_time: 0.0050  lr: 0.001199  max_mem: 3094M
[32m[04/20 00:57:15 d2.utils.events]: [0m eta: 0:06:28  iter: 259  total_loss: 0.671  loss_cls: 0.221  loss_box_reg: 0.363  loss_rpn_cls: 0.022  loss_rpn_loc: 0.068  time: 0.5229  data_time: 0.0054  lr: 0.001299  max_mem: 3094M
[32m[04/20 00:57:26 d2.utils.events]: [0m eta: 0:06:18  iter: 279  total_loss: 0.673  loss_cls: 0.223  loss_box_reg: 0.365  loss_rpn_cls: 0.028  loss_rpn_loc: 0.059  time: 0.5234  data_time: 0.0054  lr: 0.001399  max_mem: 3094M
[32m[04/20 00:57:36 d2.utils.events]: [0m eta: 0:06:07  iter: 299  total_loss: 0.681  loss_cls: 0.205  loss_box_reg: 0.351  loss_rpn_cls: 0.033  loss_rpn_loc: 0.077  time: 0.5229  data_time: 0.0051  lr: 0.001499  max_mem: 3094M
[32m[04/20 00:57:46 d2.utils.events]: [0m eta: 0:05:56  iter: 319  total_loss: 0.658  loss_cls: 0.221  loss_box_reg: 0.373  loss_rpn_cls: 0.022  loss_rpn_loc: 0.044  time: 0.5228  data_time: 0.0053  lr: 0.001598  max_mem: 3094M
[32m[04/20 00:57:57 d2.utils.events]: [0m eta: 0:05:46  iter: 339  total_loss: 0.672  loss_cls: 0.209  loss_box_reg: 0.346  loss_rpn_cls: 0.021  loss_rpn_loc: 0.066  time: 0.5239  data_time: 0.0053  lr: 0.001698  max_mem: 3094M
[32m[04/20 00:58:08 d2.utils.events]: [0m eta: 0:05:36  iter: 359  total_loss: 0.577  loss_cls: 0.205  loss_box_reg: 0.277  loss_rpn_cls: 0.022  loss_rpn_loc: 0.038  time: 0.5239  data_time: 0.0053  lr: 0.001798  max_mem: 3094M
[32m[04/20 00:58:19 d2.utils.events]: [0m eta: 0:05:26  iter: 379  total_loss: 0.683  loss_cls: 0.218  loss_box_reg: 0.334  loss_rpn_cls: 0.023  loss_rpn_loc: 0.055  time: 0.5245  data_time: 0.0054  lr: 0.001898  max_mem: 3094M
[32m[04/20 00:58:29 d2.utils.events]: [0m eta: 0:05:16  iter: 399  total_loss: 0.543  loss_cls: 0.189  loss_box_reg: 0.301  loss_rpn_cls: 0.030  loss_rpn_loc: 0.045  time: 0.5247  data_time: 0.0050  lr: 0.001998  max_mem: 3094M
[32m[04/20 00:58:40 d2.utils.events]: [0m eta: 0:05:06  iter: 419  total_loss: 0.671  loss_cls: 0.217  loss_box_reg: 0.376  loss_rpn_cls: 0.022  loss_rpn_loc: 0.056  time: 0.5250  data_time: 0.0052  lr: 0.002098  max_mem: 3094M
[32m[04/20 00:58:50 d2.utils.events]: [0m eta: 0:04:55  iter: 439  total_loss: 0.736  loss_cls: 0.228  loss_box_reg: 0.406  loss_rpn_cls: 0.029  loss_rpn_loc: 0.066  time: 0.5251  data_time: 0.0053  lr: 0.002198  max_mem: 3094M
[32m[04/20 00:59:01 d2.utils.events]: [0m eta: 0:04:45  iter: 459  total_loss: 0.586  loss_cls: 0.183  loss_box_reg: 0.313  loss_rpn_cls: 0.025  loss_rpn_loc: 0.042  time: 0.5250  data_time: 0.0053  lr: 0.002298  max_mem: 3094M
[32m[04/20 00:59:11 d2.utils.events]: [0m eta: 0:04:34  iter: 479  total_loss: 0.689  loss_cls: 0.207  loss_box_reg: 0.360  loss_rpn_cls: 0.016  loss_rpn_loc: 0.059  time: 0.5242  data_time: 0.0053  lr: 0.002398  max_mem: 3094M
[32m[04/20 00:59:22 d2.utils.events]: [0m eta: 0:04:24  iter: 499  total_loss: 0.630  loss_cls: 0.199  loss_box_reg: 0.344  loss_rpn_cls: 0.019  loss_rpn_loc: 0.058  time: 0.5243  data_time: 0.0054  lr: 0.002498  max_mem: 3094M
[32m[04/20 00:59:32 d2.utils.events]: [0m eta: 0:04:13  iter: 519  total_loss: 0.833  loss_cls: 0.253  loss_box_reg: 0.436  loss_rpn_cls: 0.034  loss_rpn_loc: 0.078  time: 0.5245  data_time: 0.0053  lr: 0.002597  max_mem: 3094M
[32m[04/20 00:59:43 d2.utils.events]: [0m eta: 0:04:02  iter: 539  total_loss: 0.601  loss_cls: 0.195  loss_box_reg: 0.335  loss_rpn_cls: 0.021  loss_rpn_loc: 0.050  time: 0.5240  data_time: 0.0052  lr: 0.002697  max_mem: 3094M
[32m[04/20 00:59:53 d2.utils.events]: [0m eta: 0:03:52  iter: 559  total_loss: 0.685  loss_cls: 0.233  loss_box_reg: 0.356  loss_rpn_cls: 0.025  loss_rpn_loc: 0.057  time: 0.5243  data_time: 0.0053  lr: 0.002797  max_mem: 3094M
[32m[04/20 01:00:04 d2.utils.events]: [0m eta: 0:03:41  iter: 579  total_loss: 0.669  loss_cls: 0.221  loss_box_reg: 0.330  loss_rpn_cls: 0.020  loss_rpn_loc: 0.050  time: 0.5238  data_time: 0.0053  lr: 0.002897  max_mem: 3094M
[32m[04/20 01:00:14 d2.utils.events]: [0m eta: 0:03:30  iter: 599  total_loss: 0.676  loss_cls: 0.219  loss_box_reg: 0.325  loss_rpn_cls: 0.023  loss_rpn_loc: 0.041  time: 0.5237  data_time: 0.0048  lr: 0.002997  max_mem: 3094M
[32m[04/20 01:00:24 d2.utils.events]: [0m eta: 0:03:20  iter: 619  total_loss: 0.617  loss_cls: 0.207  loss_box_reg: 0.339  loss_rpn_cls: 0.019  loss_rpn_loc: 0.054  time: 0.5234  data_time: 0.0051  lr: 0.003097  max_mem: 3094M
[32m[04/20 01:00:35 d2.utils.events]: [0m eta: 0:03:09  iter: 639  total_loss: 0.730  loss_cls: 0.253  loss_box_reg: 0.378  loss_rpn_cls: 0.023  loss_rpn_loc: 0.057  time: 0.5242  data_time: 0.0051  lr: 0.003197  max_mem: 3094M
[32m[04/20 01:00:46 d2.utils.events]: [0m eta: 0:02:59  iter: 659  total_loss: 0.629  loss_cls: 0.232  loss_box_reg: 0.322  loss_rpn_cls: 0.022  loss_rpn_loc: 0.045  time: 0.5241  data_time: 0.0054  lr: 0.003297  max_mem: 3094M
[32m[04/20 01:00:56 d2.utils.events]: [0m eta: 0:02:48  iter: 679  total_loss: 0.711  loss_cls: 0.242  loss_box_reg: 0.377  loss_rpn_cls: 0.026  loss_rpn_loc: 0.073  time: 0.5239  data_time: 0.0052  lr: 0.003397  max_mem: 3094M
[32m[04/20 01:01:07 d2.utils.events]: [0m eta: 0:02:38  iter: 699  total_loss: 0.657  loss_cls: 0.217  loss_box_reg: 0.383  loss_rpn_cls: 0.023  loss_rpn_loc: 0.045  time: 0.5242  data_time: 0.0049  lr: 0.003497  max_mem: 3094M
[32m[04/20 01:01:18 d2.utils.events]: [0m eta: 0:02:27  iter: 719  total_loss: 0.745  loss_cls: 0.237  loss_box_reg: 0.405  loss_rpn_cls: 0.027  loss_rpn_loc: 0.062  time: 0.5246  data_time: 0.0052  lr: 0.003596  max_mem: 3094M
[32m[04/20 01:01:28 d2.utils.events]: [0m eta: 0:02:17  iter: 739  total_loss: 0.682  loss_cls: 0.238  loss_box_reg: 0.357  loss_rpn_cls: 0.024  loss_rpn_loc: 0.053  time: 0.5243  data_time: 0.0050  lr: 0.003696  max_mem: 3094M
[32m[04/20 01:01:39 d2.utils.events]: [0m eta: 0:02:06  iter: 759  total_loss: 0.607  loss_cls: 0.231  loss_box_reg: 0.325  loss_rpn_cls: 0.025  loss_rpn_loc: 0.055  time: 0.5243  data_time: 0.0055  lr: 0.003796  max_mem: 3094M
[32m[04/20 01:01:49 d2.utils.events]: [0m eta: 0:01:56  iter: 779  total_loss: 0.788  loss_cls: 0.247  loss_box_reg: 0.428  loss_rpn_cls: 0.024  loss_rpn_loc: 0.067  time: 0.5240  data_time: 0.0048  lr: 0.003896  max_mem: 3094M
[32m[04/20 01:01:59 d2.utils.events]: [0m eta: 0:01:45  iter: 799  total_loss: 0.649  loss_cls: 0.244  loss_box_reg: 0.312  loss_rpn_cls: 0.032  loss_rpn_loc: 0.068  time: 0.5235  data_time: 0.0050  lr: 0.003996  max_mem: 3094M
[32m[04/20 01:02:09 d2.utils.events]: [0m eta: 0:01:34  iter: 819  total_loss: 0.685  loss_cls: 0.239  loss_box_reg: 0.352  loss_rpn_cls: 0.044  loss_rpn_loc: 0.052  time: 0.5230  data_time: 0.0048  lr: 0.004096  max_mem: 3094M
[32m[04/20 01:02:20 d2.utils.events]: [0m eta: 0:01:24  iter: 839  total_loss: 0.681  loss_cls: 0.226  loss_box_reg: 0.341  loss_rpn_cls: 0.018  loss_rpn_loc: 0.059  time: 0.5231  data_time: 0.0055  lr: 0.004196  max_mem: 3094M
[32m[04/20 01:02:30 d2.utils.events]: [0m eta: 0:01:13  iter: 859  total_loss: 0.713  loss_cls: 0.250  loss_box_reg: 0.322  loss_rpn_cls: 0.020  loss_rpn_loc: 0.067  time: 0.5225  data_time: 0.0049  lr: 0.004296  max_mem: 3094M
[32m[04/20 01:02:40 d2.utils.events]: [0m eta: 0:01:03  iter: 879  total_loss: 0.737  loss_cls: 0.242  loss_box_reg: 0.384  loss_rpn_cls: 0.028  loss_rpn_loc: 0.063  time: 0.5224  data_time: 0.0048  lr: 0.004396  max_mem: 3094M
[32m[04/20 01:02:51 d2.utils.events]: [0m eta: 0:00:52  iter: 899  total_loss: 0.711  loss_cls: 0.230  loss_box_reg: 0.357  loss_rpn_cls: 0.034  loss_rpn_loc: 0.062  time: 0.5225  data_time: 0.0047  lr: 0.004496  max_mem: 3094M
[32m[04/20 01:03:01 d2.utils.events]: [0m eta: 0:00:42  iter: 919  total_loss: 0.745  loss_cls: 0.269  loss_box_reg: 0.392  loss_rpn_cls: 0.026  loss_rpn_loc: 0.058  time: 0.5222  data_time: 0.0045  lr: 0.004595  max_mem: 3094M
[32m[04/20 01:03:12 d2.utils.events]: [0m eta: 0:00:31  iter: 939  total_loss: 0.784  loss_cls: 0.263  loss_box_reg: 0.391  loss_rpn_cls: 0.040  loss_rpn_loc: 0.071  time: 0.5221  data_time: 0.0048  lr: 0.004695  max_mem: 3094M
[32m[04/20 01:03:22 d2.utils.events]: [0m eta: 0:00:21  iter: 959  total_loss: 0.683  loss_cls: 0.233  loss_box_reg: 0.381  loss_rpn_cls: 0.025  loss_rpn_loc: 0.057  time: 0.5221  data_time: 0.0053  lr: 0.004795  max_mem: 3094M
[32m[04/20 01:03:32 d2.utils.events]: [0m eta: 0:00:11  iter: 979  total_loss: 0.691  loss_cls: 0.219  loss_box_reg: 0.319  loss_rpn_cls: 0.023  loss_rpn_loc: 0.064  time: 0.5219  data_time: 0.0048  lr: 0.004895  max_mem: 3094M
[5m[31mWARNING[0m [32m[04/20 01:03:51 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 01:03:51 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[5m[31mWARNING[0m [32m[04/20 01:03:51 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 01:03:51 d2.utils.events]: [0m eta: 0:00:00  iter: 999  total_loss: 0.692  loss_cls: 0.249  loss_box_reg: 0.350  loss_rpn_cls: 0.025  loss_rpn_loc: 0.058  time: 0.5222  data_time: 0.0057  lr: 0.004995  max_mem: 3094M
[32m[04/20 01:03:53 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:08:41 (0.5228 s / it)
[32m[04/20 01:03:53 d2.engine.hooks]: [0mTotal training time: 0:08:53 (0:00:12 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 01:03:58 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 01:03:58 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/20 01:03:58 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 01:04:00 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1169 s / img. ETA=0:16:33
[32m[04/20 01:04:05 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1172 s / img. ETA=0:16:34
[32m[04/20 01:04:10 d2.evaluation.evaluator]: [0mInference done 95/8355. 0.1172 s / img. ETA=0:16:30
[32m[04/20 01:04:15 d2.evaluation.evaluator]: [0mInference done 137/8355. 0.1171 s / img. ETA=0:16:25
[32m[04/20 01:04:20 d2.evaluation.evaluator]: [0mInference done 179/8355. 0.1171 s / img. ETA=0:16:20
[32m[04/20 01:04:25 d2.evaluation.evaluator]: [0mInference done 221/8355. 0.1171 s / img. ETA=0:16:14
[32m[04/20 01:04:30 d2.evaluation.evaluator]: [0mInference done 263/8355. 0.1170 s / img. ETA=0:16:09
[32m[04/20 01:04:35 d2.evaluation.evaluator]: [0mInference done 305/8355. 0.1171 s / img. ETA=0:16:05
[32m[04/20 01:04:40 d2.evaluation.evaluator]: [0mInference done 347/8355. 0.1171 s / img. ETA=0:15:59
[32m[04/20 01:04:45 d2.evaluation.evaluator]: [0mInference done 389/8355. 0.1171 s / img. ETA=0:15:55
[32m[04/20 01:04:50 d2.evaluation.evaluator]: [0mInference done 431/8355. 0.1171 s / img. ETA=0:15:50
[32m[04/20 01:04:55 d2.evaluation.evaluator]: [0mInference done 473/8355. 0.1172 s / img. ETA=0:15:45
[32m[04/20 01:05:00 d2.evaluation.evaluator]: [0mInference done 515/8355. 0.1171 s / img. ETA=0:15:40
[32m[04/20 01:05:05 d2.evaluation.evaluator]: [0mInference done 557/8355. 0.1171 s / img. ETA=0:15:34
[32m[04/20 01:05:11 d2.evaluation.evaluator]: [0mInference done 599/8355. 0.1171 s / img. ETA=0:15:30
[32m[04/20 01:05:16 d2.evaluation.evaluator]: [0mInference done 641/8355. 0.1172 s / img. ETA=0:15:25
[32m[04/20 01:05:21 d2.evaluation.evaluator]: [0mInference done 683/8355. 0.1172 s / img. ETA=0:15:20
[32m[04/20 01:05:26 d2.evaluation.evaluator]: [0mInference done 725/8355. 0.1172 s / img. ETA=0:15:15
[32m[04/20 01:05:31 d2.evaluation.evaluator]: [0mInference done 767/8355. 0.1172 s / img. ETA=0:15:10
[32m[04/20 01:05:36 d2.evaluation.evaluator]: [0mInference done 809/8355. 0.1172 s / img. ETA=0:15:05
[32m[04/20 01:05:41 d2.evaluation.evaluator]: [0mInference done 851/8355. 0.1172 s / img. ETA=0:15:00
[32m[04/20 01:05:46 d2.evaluation.evaluator]: [0mInference done 893/8355. 0.1172 s / img. ETA=0:14:55
[32m[04/20 01:05:51 d2.evaluation.evaluator]: [0mInference done 935/8355. 0.1172 s / img. ETA=0:14:50
[32m[04/20 01:05:56 d2.evaluation.evaluator]: [0mInference done 977/8355. 0.1172 s / img. ETA=0:14:45
[32m[04/20 01:06:01 d2.evaluation.evaluator]: [0mInference done 1019/8355. 0.1172 s / img. ETA=0:14:40
[32m[04/20 01:06:06 d2.evaluation.evaluator]: [0mInference done 1061/8355. 0.1172 s / img. ETA=0:14:35
[32m[04/20 01:06:11 d2.evaluation.evaluator]: [0mInference done 1103/8355. 0.1172 s / img. ETA=0:14:30
[32m[04/20 01:06:16 d2.evaluation.evaluator]: [0mInference done 1145/8355. 0.1172 s / img. ETA=0:14:24
[32m[04/20 01:06:21 d2.evaluation.evaluator]: [0mInference done 1187/8355. 0.1172 s / img. ETA=0:14:19
[32m[04/20 01:06:26 d2.evaluation.evaluator]: [0mInference done 1229/8355. 0.1172 s / img. ETA=0:14:14
[32m[04/20 01:06:31 d2.evaluation.evaluator]: [0mInference done 1271/8355. 0.1172 s / img. ETA=0:14:09
[32m[04/20 01:06:36 d2.evaluation.evaluator]: [0mInference done 1313/8355. 0.1172 s / img. ETA=0:14:04
[32m[04/20 01:06:41 d2.evaluation.evaluator]: [0mInference done 1355/8355. 0.1172 s / img. ETA=0:13:59
[32m[04/20 01:06:46 d2.evaluation.evaluator]: [0mInference done 1397/8355. 0.1172 s / img. ETA=0:13:54
[32m[04/20 01:06:51 d2.evaluation.evaluator]: [0mInference done 1440/8355. 0.1171 s / img. ETA=0:13:49
[32m[04/20 01:06:56 d2.evaluation.evaluator]: [0mInference done 1482/8355. 0.1172 s / img. ETA=0:13:44
[32m[04/20 01:07:01 d2.evaluation.evaluator]: [0mInference done 1524/8355. 0.1172 s / img. ETA=0:13:39
[32m[04/20 01:07:07 d2.evaluation.evaluator]: [0mInference done 1566/8355. 0.1172 s / img. ETA=0:13:34
[32m[04/20 01:07:12 d2.evaluation.evaluator]: [0mInference done 1608/8355. 0.1172 s / img. ETA=0:13:29
[32m[04/20 01:07:17 d2.evaluation.evaluator]: [0mInference done 1650/8355. 0.1172 s / img. ETA=0:13:24
[32m[04/20 01:07:22 d2.evaluation.evaluator]: [0mInference done 1692/8355. 0.1172 s / img. ETA=0:13:19
[32m[04/20 01:07:27 d2.evaluation.evaluator]: [0mInference done 1734/8355. 0.1173 s / img. ETA=0:13:14
[32m[04/20 01:07:32 d2.evaluation.evaluator]: [0mInference done 1776/8355. 0.1173 s / img. ETA=0:13:09
[32m[04/20 01:07:37 d2.evaluation.evaluator]: [0mInference done 1818/8355. 0.1173 s / img. ETA=0:13:04
[32m[04/20 01:07:42 d2.evaluation.evaluator]: [0mInference done 1860/8355. 0.1173 s / img. ETA=0:12:59
[32m[04/20 01:07:47 d2.evaluation.evaluator]: [0mInference done 1902/8355. 0.1173 s / img. ETA=0:12:54
[32m[04/20 01:07:52 d2.evaluation.evaluator]: [0mInference done 1944/8355. 0.1173 s / img. ETA=0:12:49
[32m[04/20 01:07:57 d2.evaluation.evaluator]: [0mInference done 1986/8355. 0.1173 s / img. ETA=0:12:44
[32m[04/20 01:08:02 d2.evaluation.evaluator]: [0mInference done 2028/8355. 0.1173 s / img. ETA=0:12:39
[32m[04/20 01:08:07 d2.evaluation.evaluator]: [0mInference done 2070/8355. 0.1173 s / img. ETA=0:12:34
[32m[04/20 01:08:12 d2.evaluation.evaluator]: [0mInference done 2112/8355. 0.1173 s / img. ETA=0:12:29
[32m[04/20 01:08:17 d2.evaluation.evaluator]: [0mInference done 2154/8355. 0.1173 s / img. ETA=0:12:24
[32m[04/20 01:08:22 d2.evaluation.evaluator]: [0mInference done 2196/8355. 0.1174 s / img. ETA=0:12:19
[32m[04/20 01:08:28 d2.evaluation.evaluator]: [0mInference done 2238/8355. 0.1174 s / img. ETA=0:12:14
[32m[04/20 01:08:33 d2.evaluation.evaluator]: [0mInference done 2280/8355. 0.1174 s / img. ETA=0:12:09
[32m[04/20 01:08:38 d2.evaluation.evaluator]: [0mInference done 2322/8355. 0.1174 s / img. ETA=0:12:04
[32m[04/20 01:08:43 d2.evaluation.evaluator]: [0mInference done 2364/8355. 0.1174 s / img. ETA=0:11:59
[32m[04/20 01:08:48 d2.evaluation.evaluator]: [0mInference done 2406/8355. 0.1174 s / img. ETA=0:11:55
[32m[04/20 01:08:53 d2.evaluation.evaluator]: [0mInference done 2448/8355. 0.1174 s / img. ETA=0:11:50
[32m[04/20 01:08:58 d2.evaluation.evaluator]: [0mInference done 2490/8355. 0.1174 s / img. ETA=0:11:45
[32m[04/20 01:09:03 d2.evaluation.evaluator]: [0mInference done 2532/8355. 0.1174 s / img. ETA=0:11:40
[32m[04/20 01:09:08 d2.evaluation.evaluator]: [0mInference done 2574/8355. 0.1174 s / img. ETA=0:11:34
[32m[04/20 01:09:13 d2.evaluation.evaluator]: [0mInference done 2616/8355. 0.1174 s / img. ETA=0:11:29
[32m[04/20 01:09:18 d2.evaluation.evaluator]: [0mInference done 2658/8355. 0.1174 s / img. ETA=0:11:24
[32m[04/20 01:09:23 d2.evaluation.evaluator]: [0mInference done 2700/8355. 0.1174 s / img. ETA=0:11:19
[32m[04/20 01:09:28 d2.evaluation.evaluator]: [0mInference done 2742/8355. 0.1174 s / img. ETA=0:11:14
[32m[04/20 01:09:33 d2.evaluation.evaluator]: [0mInference done 2784/8355. 0.1174 s / img. ETA=0:11:09
[32m[04/20 01:09:38 d2.evaluation.evaluator]: [0mInference done 2826/8355. 0.1175 s / img. ETA=0:11:04
[32m[04/20 01:09:43 d2.evaluation.evaluator]: [0mInference done 2868/8355. 0.1175 s / img. ETA=0:10:59
[32m[04/20 01:09:49 d2.evaluation.evaluator]: [0mInference done 2910/8355. 0.1175 s / img. ETA=0:10:54
[32m[04/20 01:09:54 d2.evaluation.evaluator]: [0mInference done 2952/8355. 0.1175 s / img. ETA=0:10:49
[32m[04/20 01:09:59 d2.evaluation.evaluator]: [0mInference done 2994/8355. 0.1175 s / img. ETA=0:10:44
[32m[04/20 01:10:04 d2.evaluation.evaluator]: [0mInference done 3036/8355. 0.1175 s / img. ETA=0:10:39
[32m[04/20 01:10:09 d2.evaluation.evaluator]: [0mInference done 3078/8355. 0.1175 s / img. ETA=0:10:34
[32m[04/20 01:10:14 d2.evaluation.evaluator]: [0mInference done 3120/8355. 0.1175 s / img. ETA=0:10:29
[32m[04/20 01:10:19 d2.evaluation.evaluator]: [0mInference done 3162/8355. 0.1176 s / img. ETA=0:10:24
[32m[04/20 01:10:24 d2.evaluation.evaluator]: [0mInference done 3204/8355. 0.1176 s / img. ETA=0:10:19
[32m[04/20 01:10:29 d2.evaluation.evaluator]: [0mInference done 3246/8355. 0.1176 s / img. ETA=0:10:14
[32m[04/20 01:10:34 d2.evaluation.evaluator]: [0mInference done 3287/8355. 0.1176 s / img. ETA=0:10:09
[32m[04/20 01:10:39 d2.evaluation.evaluator]: [0mInference done 3329/8355. 0.1176 s / img. ETA=0:10:04
[32m[04/20 01:10:44 d2.evaluation.evaluator]: [0mInference done 3371/8355. 0.1176 s / img. ETA=0:09:59
[32m[04/20 01:10:49 d2.evaluation.evaluator]: [0mInference done 3413/8355. 0.1176 s / img. ETA=0:09:54
[32m[04/20 01:10:54 d2.evaluation.evaluator]: [0mInference done 3455/8355. 0.1176 s / img. ETA=0:09:49
[32m[04/20 01:11:00 d2.evaluation.evaluator]: [0mInference done 3497/8355. 0.1176 s / img. ETA=0:09:44
[32m[04/20 01:11:05 d2.evaluation.evaluator]: [0mInference done 3539/8355. 0.1176 s / img. ETA=0:09:39
[32m[04/20 01:11:10 d2.evaluation.evaluator]: [0mInference done 3581/8355. 0.1176 s / img. ETA=0:09:34
[32m[04/20 01:11:15 d2.evaluation.evaluator]: [0mInference done 3623/8355. 0.1176 s / img. ETA=0:09:29
[32m[04/20 01:11:20 d2.evaluation.evaluator]: [0mInference done 3665/8355. 0.1177 s / img. ETA=0:09:24
[32m[04/20 01:11:25 d2.evaluation.evaluator]: [0mInference done 3707/8355. 0.1176 s / img. ETA=0:09:19
[32m[04/20 01:11:30 d2.evaluation.evaluator]: [0mInference done 3748/8355. 0.1177 s / img. ETA=0:09:14
[32m[04/20 01:11:35 d2.evaluation.evaluator]: [0mInference done 3790/8355. 0.1177 s / img. ETA=0:09:09
[32m[04/20 01:11:40 d2.evaluation.evaluator]: [0mInference done 3831/8355. 0.1177 s / img. ETA=0:09:04
[32m[04/20 01:11:45 d2.evaluation.evaluator]: [0mInference done 3873/8355. 0.1177 s / img. ETA=0:08:59
[32m[04/20 01:11:50 d2.evaluation.evaluator]: [0mInference done 3915/8355. 0.1177 s / img. ETA=0:08:54
[32m[04/20 01:11:55 d2.evaluation.evaluator]: [0mInference done 3957/8355. 0.1177 s / img. ETA=0:08:49
[32m[04/20 01:12:00 d2.evaluation.evaluator]: [0mInference done 3999/8355. 0.1177 s / img. ETA=0:08:44
[32m[04/20 01:12:05 d2.evaluation.evaluator]: [0mInference done 4041/8355. 0.1177 s / img. ETA=0:08:39
[32m[04/20 01:12:11 d2.evaluation.evaluator]: [0mInference done 4083/8355. 0.1177 s / img. ETA=0:08:34
[32m[04/20 01:12:16 d2.evaluation.evaluator]: [0mInference done 4124/8355. 0.1178 s / img. ETA=0:08:29
[32m[04/20 01:12:21 d2.evaluation.evaluator]: [0mInference done 4166/8355. 0.1178 s / img. ETA=0:08:24
[32m[04/20 01:12:26 d2.evaluation.evaluator]: [0mInference done 4208/8355. 0.1178 s / img. ETA=0:08:19
[32m[04/20 01:12:31 d2.evaluation.evaluator]: [0mInference done 4250/8355. 0.1178 s / img. ETA=0:08:14
[32m[04/20 01:12:36 d2.evaluation.evaluator]: [0mInference done 4292/8355. 0.1178 s / img. ETA=0:08:09
[32m[04/20 01:12:41 d2.evaluation.evaluator]: [0mInference done 4334/8355. 0.1178 s / img. ETA=0:08:04
[32m[04/20 01:12:46 d2.evaluation.evaluator]: [0mInference done 4376/8355. 0.1178 s / img. ETA=0:07:59
[32m[04/20 01:12:51 d2.evaluation.evaluator]: [0mInference done 4418/8355. 0.1178 s / img. ETA=0:07:54
[32m[04/20 01:12:56 d2.evaluation.evaluator]: [0mInference done 4460/8355. 0.1178 s / img. ETA=0:07:49
[32m[04/20 01:13:01 d2.evaluation.evaluator]: [0mInference done 4502/8355. 0.1178 s / img. ETA=0:07:44
[32m[04/20 01:13:06 d2.evaluation.evaluator]: [0mInference done 4544/8355. 0.1178 s / img. ETA=0:07:39
[32m[04/20 01:13:11 d2.evaluation.evaluator]: [0mInference done 4586/8355. 0.1178 s / img. ETA=0:07:34
[32m[04/20 01:13:17 d2.evaluation.evaluator]: [0mInference done 4628/8355. 0.1178 s / img. ETA=0:07:29
[32m[04/20 01:13:22 d2.evaluation.evaluator]: [0mInference done 4670/8355. 0.1178 s / img. ETA=0:07:24
[32m[04/20 01:13:27 d2.evaluation.evaluator]: [0mInference done 4712/8355. 0.1178 s / img. ETA=0:07:19
[32m[04/20 01:13:32 d2.evaluation.evaluator]: [0mInference done 4754/8355. 0.1178 s / img. ETA=0:07:14
[32m[04/20 01:13:37 d2.evaluation.evaluator]: [0mInference done 4796/8355. 0.1178 s / img. ETA=0:07:09
[32m[04/20 01:13:42 d2.evaluation.evaluator]: [0mInference done 4838/8355. 0.1178 s / img. ETA=0:07:04
[32m[04/20 01:13:47 d2.evaluation.evaluator]: [0mInference done 4880/8355. 0.1178 s / img. ETA=0:06:58
[32m[04/20 01:13:52 d2.evaluation.evaluator]: [0mInference done 4922/8355. 0.1178 s / img. ETA=0:06:53
[32m[04/20 01:13:57 d2.evaluation.evaluator]: [0mInference done 4964/8355. 0.1178 s / img. ETA=0:06:48
[32m[04/20 01:14:02 d2.evaluation.evaluator]: [0mInference done 5006/8355. 0.1178 s / img. ETA=0:06:43
[32m[04/20 01:14:07 d2.evaluation.evaluator]: [0mInference done 5048/8355. 0.1178 s / img. ETA=0:06:38
[32m[04/20 01:14:12 d2.evaluation.evaluator]: [0mInference done 5090/8355. 0.1178 s / img. ETA=0:06:33
[32m[04/20 01:14:18 d2.evaluation.evaluator]: [0mInference done 5132/8355. 0.1178 s / img. ETA=0:06:28
[32m[04/20 01:14:23 d2.evaluation.evaluator]: [0mInference done 5174/8355. 0.1179 s / img. ETA=0:06:23
[32m[04/20 01:14:28 d2.evaluation.evaluator]: [0mInference done 5216/8355. 0.1179 s / img. ETA=0:06:18
[32m[04/20 01:14:33 d2.evaluation.evaluator]: [0mInference done 5258/8355. 0.1179 s / img. ETA=0:06:13
[32m[04/20 01:14:38 d2.evaluation.evaluator]: [0mInference done 5300/8355. 0.1179 s / img. ETA=0:06:08
[32m[04/20 01:14:43 d2.evaluation.evaluator]: [0mInference done 5342/8355. 0.1179 s / img. ETA=0:06:03
[32m[04/20 01:14:48 d2.evaluation.evaluator]: [0mInference done 5384/8355. 0.1179 s / img. ETA=0:05:58
[32m[04/20 01:14:53 d2.evaluation.evaluator]: [0mInference done 5425/8355. 0.1179 s / img. ETA=0:05:53
[32m[04/20 01:14:58 d2.evaluation.evaluator]: [0mInference done 5466/8355. 0.1179 s / img. ETA=0:05:48
[32m[04/20 01:15:03 d2.evaluation.evaluator]: [0mInference done 5508/8355. 0.1179 s / img. ETA=0:05:43
[32m[04/20 01:15:08 d2.evaluation.evaluator]: [0mInference done 5550/8355. 0.1179 s / img. ETA=0:05:38
[32m[04/20 01:15:13 d2.evaluation.evaluator]: [0mInference done 5592/8355. 0.1179 s / img. ETA=0:05:33
[32m[04/20 01:15:18 d2.evaluation.evaluator]: [0mInference done 5633/8355. 0.1179 s / img. ETA=0:05:28
[32m[04/20 01:15:24 d2.evaluation.evaluator]: [0mInference done 5675/8355. 0.1179 s / img. ETA=0:05:23
[32m[04/20 01:15:29 d2.evaluation.evaluator]: [0mInference done 5717/8355. 0.1179 s / img. ETA=0:05:18
[32m[04/20 01:15:34 d2.evaluation.evaluator]: [0mInference done 5759/8355. 0.1179 s / img. ETA=0:05:13
[32m[04/20 01:15:39 d2.evaluation.evaluator]: [0mInference done 5801/8355. 0.1179 s / img. ETA=0:05:08
[32m[04/20 01:15:44 d2.evaluation.evaluator]: [0mInference done 5843/8355. 0.1180 s / img. ETA=0:05:03
[32m[04/20 01:15:49 d2.evaluation.evaluator]: [0mInference done 5884/8355. 0.1180 s / img. ETA=0:04:58
[32m[04/20 01:15:54 d2.evaluation.evaluator]: [0mInference done 5926/8355. 0.1180 s / img. ETA=0:04:53
[32m[04/20 01:15:59 d2.evaluation.evaluator]: [0mInference done 5968/8355. 0.1180 s / img. ETA=0:04:48
[32m[04/20 01:16:04 d2.evaluation.evaluator]: [0mInference done 6009/8355. 0.1180 s / img. ETA=0:04:43
[32m[04/20 01:16:09 d2.evaluation.evaluator]: [0mInference done 6051/8355. 0.1180 s / img. ETA=0:04:38
[32m[04/20 01:16:14 d2.evaluation.evaluator]: [0mInference done 6093/8355. 0.1180 s / img. ETA=0:04:33
[32m[04/20 01:16:19 d2.evaluation.evaluator]: [0mInference done 6135/8355. 0.1180 s / img. ETA=0:04:28
[32m[04/20 01:16:25 d2.evaluation.evaluator]: [0mInference done 6177/8355. 0.1180 s / img. ETA=0:04:22
[32m[04/20 01:16:30 d2.evaluation.evaluator]: [0mInference done 6218/8355. 0.1180 s / img. ETA=0:04:18
[32m[04/20 01:16:35 d2.evaluation.evaluator]: [0mInference done 6260/8355. 0.1180 s / img. ETA=0:04:13
[32m[04/20 01:16:40 d2.evaluation.evaluator]: [0mInference done 6302/8355. 0.1180 s / img. ETA=0:04:07
[32m[04/20 01:16:45 d2.evaluation.evaluator]: [0mInference done 6344/8355. 0.1180 s / img. ETA=0:04:02
[32m[04/20 01:16:50 d2.evaluation.evaluator]: [0mInference done 6386/8355. 0.1180 s / img. ETA=0:03:57
[32m[04/20 01:16:55 d2.evaluation.evaluator]: [0mInference done 6427/8355. 0.1180 s / img. ETA=0:03:52
[32m[04/20 01:17:00 d2.evaluation.evaluator]: [0mInference done 6469/8355. 0.1180 s / img. ETA=0:03:47
[32m[04/20 01:17:05 d2.evaluation.evaluator]: [0mInference done 6511/8355. 0.1180 s / img. ETA=0:03:42
[32m[04/20 01:17:10 d2.evaluation.evaluator]: [0mInference done 6553/8355. 0.1180 s / img. ETA=0:03:37
[32m[04/20 01:17:15 d2.evaluation.evaluator]: [0mInference done 6595/8355. 0.1180 s / img. ETA=0:03:32
[32m[04/20 01:17:20 d2.evaluation.evaluator]: [0mInference done 6637/8355. 0.1180 s / img. ETA=0:03:27
[32m[04/20 01:17:25 d2.evaluation.evaluator]: [0mInference done 6679/8355. 0.1180 s / img. ETA=0:03:22
[32m[04/20 01:17:30 d2.evaluation.evaluator]: [0mInference done 6721/8355. 0.1180 s / img. ETA=0:03:17
[32m[04/20 01:17:36 d2.evaluation.evaluator]: [0mInference done 6763/8355. 0.1180 s / img. ETA=0:03:12
[32m[04/20 01:17:41 d2.evaluation.evaluator]: [0mInference done 6805/8355. 0.1180 s / img. ETA=0:03:07
[32m[04/20 01:17:46 d2.evaluation.evaluator]: [0mInference done 6847/8355. 0.1180 s / img. ETA=0:03:02
[32m[04/20 01:17:51 d2.evaluation.evaluator]: [0mInference done 6889/8355. 0.1180 s / img. ETA=0:02:57
[32m[04/20 01:17:56 d2.evaluation.evaluator]: [0mInference done 6931/8355. 0.1180 s / img. ETA=0:02:51
[32m[04/20 01:18:01 d2.evaluation.evaluator]: [0mInference done 6973/8355. 0.1180 s / img. ETA=0:02:46
[32m[04/20 01:18:06 d2.evaluation.evaluator]: [0mInference done 7014/8355. 0.1180 s / img. ETA=0:02:41
[32m[04/20 01:18:11 d2.evaluation.evaluator]: [0mInference done 7056/8355. 0.1181 s / img. ETA=0:02:36
[32m[04/20 01:18:16 d2.evaluation.evaluator]: [0mInference done 7097/8355. 0.1181 s / img. ETA=0:02:31
[32m[04/20 01:18:21 d2.evaluation.evaluator]: [0mInference done 7138/8355. 0.1181 s / img. ETA=0:02:27
[32m[04/20 01:18:26 d2.evaluation.evaluator]: [0mInference done 7179/8355. 0.1181 s / img. ETA=0:02:22
[32m[04/20 01:18:31 d2.evaluation.evaluator]: [0mInference done 7220/8355. 0.1181 s / img. ETA=0:02:17
[32m[04/20 01:18:36 d2.evaluation.evaluator]: [0mInference done 7261/8355. 0.1181 s / img. ETA=0:02:12
[32m[04/20 01:18:41 d2.evaluation.evaluator]: [0mInference done 7303/8355. 0.1181 s / img. ETA=0:02:07
[32m[04/20 01:18:46 d2.evaluation.evaluator]: [0mInference done 7345/8355. 0.1181 s / img. ETA=0:02:02
[32m[04/20 01:18:51 d2.evaluation.evaluator]: [0mInference done 7386/8355. 0.1181 s / img. ETA=0:01:57
[32m[04/20 01:18:56 d2.evaluation.evaluator]: [0mInference done 7427/8355. 0.1181 s / img. ETA=0:01:52
[32m[04/20 01:19:01 d2.evaluation.evaluator]: [0mInference done 7468/8355. 0.1181 s / img. ETA=0:01:47
[32m[04/20 01:19:06 d2.evaluation.evaluator]: [0mInference done 7509/8355. 0.1181 s / img. ETA=0:01:42
[32m[04/20 01:19:11 d2.evaluation.evaluator]: [0mInference done 7550/8355. 0.1181 s / img. ETA=0:01:37
[32m[04/20 01:19:16 d2.evaluation.evaluator]: [0mInference done 7591/8355. 0.1182 s / img. ETA=0:01:32
[32m[04/20 01:19:21 d2.evaluation.evaluator]: [0mInference done 7632/8355. 0.1182 s / img. ETA=0:01:27
[32m[04/20 01:19:27 d2.evaluation.evaluator]: [0mInference done 7673/8355. 0.1182 s / img. ETA=0:01:22
[32m[04/20 01:19:32 d2.evaluation.evaluator]: [0mInference done 7714/8355. 0.1182 s / img. ETA=0:01:17
[32m[04/20 01:19:37 d2.evaluation.evaluator]: [0mInference done 7754/8355. 0.1182 s / img. ETA=0:01:12
[32m[04/20 01:19:42 d2.evaluation.evaluator]: [0mInference done 7796/8355. 0.1182 s / img. ETA=0:01:07
[32m[04/20 01:19:47 d2.evaluation.evaluator]: [0mInference done 7837/8355. 0.1182 s / img. ETA=0:01:02
[32m[04/20 01:19:52 d2.evaluation.evaluator]: [0mInference done 7878/8355. 0.1182 s / img. ETA=0:00:57
[32m[04/20 01:19:57 d2.evaluation.evaluator]: [0mInference done 7919/8355. 0.1182 s / img. ETA=0:00:52
[32m[04/20 01:20:02 d2.evaluation.evaluator]: [0mInference done 7960/8355. 0.1182 s / img. ETA=0:00:47
[32m[04/20 01:20:07 d2.evaluation.evaluator]: [0mInference done 7999/8355. 0.1182 s / img. ETA=0:00:43
[32m[04/20 01:20:12 d2.evaluation.evaluator]: [0mInference done 8041/8355. 0.1182 s / img. ETA=0:00:38
[32m[04/20 01:20:17 d2.evaluation.evaluator]: [0mInference done 8083/8355. 0.1182 s / img. ETA=0:00:32
[32m[04/20 01:20:22 d2.evaluation.evaluator]: [0mInference done 8124/8355. 0.1182 s / img. ETA=0:00:27
[32m[04/20 01:20:27 d2.evaluation.evaluator]: [0mInference done 8166/8355. 0.1182 s / img. ETA=0:00:22
[32m[04/20 01:20:32 d2.evaluation.evaluator]: [0mInference done 8208/8355. 0.1182 s / img. ETA=0:00:17
[32m[04/20 01:20:37 d2.evaluation.evaluator]: [0mInference done 8250/8355. 0.1182 s / img. ETA=0:00:12
[32m[04/20 01:20:42 d2.evaluation.evaluator]: [0mInference done 8291/8355. 0.1182 s / img. ETA=0:00:07
[32m[04/20 01:20:48 d2.evaluation.evaluator]: [0mInference done 8333/8355. 0.1182 s / img. ETA=0:00:02
[32m[04/20 01:20:50 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:50.952701 (0.121072 s / img per device, on 1 devices)
[32m[04/20 01:20:50 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:27 (0.118220 s / img per device, on 1 devices)
[32m[04/20 01:20:51 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 01:20:51 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 01:20:51 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.55s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=22.29s).
Accumulating evaluation results...
DONE (t=3.30s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.266
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.546
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.218
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.366
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.561
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.157
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.258
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.447
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621
[32m[04/20 01:21:17 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 26.616 | 54.649 | 21.817 | 19.214 | 36.554 | 56.086 |
[32m[04/20 01:21:17 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 31.406 | bicycle       | 14.719 | car            | 39.624 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | 20.713 | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 01:21:18 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 01:21:18 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[32m[04/20 01:21:18 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 01:21:20 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1193 s / img. ETA=0:02:31
[32m[04/20 01:21:25 d2.evaluation.evaluator]: [0mInference done 40/1257. 0.1186 s / img. ETA=0:03:20
[32m[04/20 01:21:30 d2.evaluation.evaluator]: [0mInference done 82/1257. 0.1183 s / img. ETA=0:02:45
[32m[04/20 01:21:35 d2.evaluation.evaluator]: [0mInference done 124/1257. 0.1184 s / img. ETA=0:02:31
[32m[04/20 01:21:40 d2.evaluation.evaluator]: [0mInference done 166/1257. 0.1183 s / img. ETA=0:02:22
[32m[04/20 01:21:46 d2.evaluation.evaluator]: [0mInference done 208/1257. 0.1181 s / img. ETA=0:02:14
[32m[04/20 01:21:51 d2.evaluation.evaluator]: [0mInference done 250/1257. 0.1181 s / img. ETA=0:02:08
[32m[04/20 01:21:56 d2.evaluation.evaluator]: [0mInference done 292/1257. 0.1181 s / img. ETA=0:02:01
[32m[04/20 01:22:01 d2.evaluation.evaluator]: [0mInference done 334/1257. 0.1180 s / img. ETA=0:01:55
[32m[04/20 01:22:06 d2.evaluation.evaluator]: [0mInference done 376/1257. 0.1180 s / img. ETA=0:01:50
[32m[04/20 01:22:11 d2.evaluation.evaluator]: [0mInference done 418/1257. 0.1179 s / img. ETA=0:01:44
[32m[04/20 01:22:16 d2.evaluation.evaluator]: [0mInference done 460/1257. 0.1180 s / img. ETA=0:01:38
[32m[04/20 01:22:21 d2.evaluation.evaluator]: [0mInference done 502/1257. 0.1180 s / img. ETA=0:01:33
[32m[04/20 01:22:26 d2.evaluation.evaluator]: [0mInference done 544/1257. 0.1181 s / img. ETA=0:01:28
[32m[04/20 01:22:31 d2.evaluation.evaluator]: [0mInference done 586/1257. 0.1180 s / img. ETA=0:01:22
[32m[04/20 01:22:36 d2.evaluation.evaluator]: [0mInference done 628/1257. 0.1180 s / img. ETA=0:01:17
[32m[04/20 01:22:41 d2.evaluation.evaluator]: [0mInference done 670/1257. 0.1181 s / img. ETA=0:01:12
[32m[04/20 01:22:47 d2.evaluation.evaluator]: [0mInference done 712/1257. 0.1181 s / img. ETA=0:01:07
[32m[04/20 01:22:52 d2.evaluation.evaluator]: [0mInference done 754/1257. 0.1181 s / img. ETA=0:01:01
[32m[04/20 01:22:57 d2.evaluation.evaluator]: [0mInference done 796/1257. 0.1182 s / img. ETA=0:00:56
[32m[04/20 01:23:02 d2.evaluation.evaluator]: [0mInference done 838/1257. 0.1182 s / img. ETA=0:00:51
[32m[04/20 01:23:07 d2.evaluation.evaluator]: [0mInference done 880/1257. 0.1182 s / img. ETA=0:00:46
[32m[04/20 01:23:12 d2.evaluation.evaluator]: [0mInference done 922/1257. 0.1182 s / img. ETA=0:00:41
[32m[04/20 01:23:17 d2.evaluation.evaluator]: [0mInference done 964/1257. 0.1182 s / img. ETA=0:00:35
[32m[04/20 01:23:22 d2.evaluation.evaluator]: [0mInference done 1006/1257. 0.1182 s / img. ETA=0:00:30
[32m[04/20 01:23:27 d2.evaluation.evaluator]: [0mInference done 1048/1257. 0.1182 s / img. ETA=0:00:25
[32m[04/20 01:23:32 d2.evaluation.evaluator]: [0mInference done 1090/1257. 0.1182 s / img. ETA=0:00:20
[32m[04/20 01:23:37 d2.evaluation.evaluator]: [0mInference done 1132/1257. 0.1182 s / img. ETA=0:00:15
[32m[04/20 01:23:42 d2.evaluation.evaluator]: [0mInference done 1174/1257. 0.1182 s / img. ETA=0:00:10
[32m[04/20 01:23:48 d2.evaluation.evaluator]: [0mInference done 1216/1257. 0.1182 s / img. ETA=0:00:05
[32m[04/20 01:23:53 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:33.108557 (0.122291 s / img per device, on 1 devices)
[32m[04/20 01:23:53 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:27 (0.118180 s / img per device, on 1 devices)
[32m[04/20 01:23:53 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 01:23:53 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 01:23:53 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.96s).
Accumulating evaluation results...
DONE (t=0.40s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.194
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.386
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.175
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.116
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.237
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.469
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.098
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.240
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.243
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.168
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.288
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540
[32m[04/20 01:23:56 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 19.430 | 38.634 | 17.488 | 11.631 | 23.701 | 46.923 |
[32m[04/20 01:23:56 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 26.990 | bicycle       | 9.918 | car            | 40.811 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | 0.000 | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  8  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 01:23:57 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 01:23:57 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 01:23:57 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/20 01:23:58 d2.data.build]: [0mRemoved 889 images with no usable annotations. 7466 images left.
[32m[04/20 01:23:58 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 01:23:58 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 01:24:00 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 01:24:11 d2.utils.events]: [0m eta: 0:08:42  iter: 19  total_loss: 0.696  loss_cls: 0.224  loss_box_reg: 0.382  loss_rpn_cls: 0.027  loss_rpn_loc: 0.061  time: 0.5314  data_time: 0.0183  lr: 0.000100  max_mem: 3094M
[32m[04/20 01:24:21 d2.utils.events]: [0m eta: 0:08:28  iter: 39  total_loss: 0.701  loss_cls: 0.226  loss_box_reg: 0.349  loss_rpn_cls: 0.034  loss_rpn_loc: 0.063  time: 0.5228  data_time: 0.0052  lr: 0.000200  max_mem: 3094M
[32m[04/20 01:24:31 d2.utils.events]: [0m eta: 0:08:09  iter: 59  total_loss: 0.791  loss_cls: 0.271  loss_box_reg: 0.418  loss_rpn_cls: 0.028  loss_rpn_loc: 0.068  time: 0.5188  data_time: 0.0052  lr: 0.000300  max_mem: 3094M
[32m[04/20 01:24:42 d2.utils.events]: [0m eta: 0:07:59  iter: 79  total_loss: 0.619  loss_cls: 0.208  loss_box_reg: 0.334  loss_rpn_cls: 0.026  loss_rpn_loc: 0.051  time: 0.5199  data_time: 0.0052  lr: 0.000400  max_mem: 3094M
[32m[04/20 01:24:52 d2.utils.events]: [0m eta: 0:07:51  iter: 99  total_loss: 0.735  loss_cls: 0.228  loss_box_reg: 0.419  loss_rpn_cls: 0.025  loss_rpn_loc: 0.072  time: 0.5225  data_time: 0.0121  lr: 0.000500  max_mem: 3094M
[32m[04/20 01:25:03 d2.utils.events]: [0m eta: 0:07:39  iter: 119  total_loss: 0.682  loss_cls: 0.242  loss_box_reg: 0.379  loss_rpn_cls: 0.028  loss_rpn_loc: 0.039  time: 0.5219  data_time: 0.0054  lr: 0.000599  max_mem: 3094M
[32m[04/20 01:25:13 d2.utils.events]: [0m eta: 0:07:30  iter: 139  total_loss: 0.598  loss_cls: 0.212  loss_box_reg: 0.312  loss_rpn_cls: 0.022  loss_rpn_loc: 0.047  time: 0.5226  data_time: 0.0053  lr: 0.000699  max_mem: 3094M
[32m[04/20 01:25:24 d2.utils.events]: [0m eta: 0:07:19  iter: 159  total_loss: 0.629  loss_cls: 0.203  loss_box_reg: 0.323  loss_rpn_cls: 0.033  loss_rpn_loc: 0.063  time: 0.5217  data_time: 0.0052  lr: 0.000799  max_mem: 3094M
[32m[04/20 01:25:34 d2.utils.events]: [0m eta: 0:07:08  iter: 179  total_loss: 0.599  loss_cls: 0.211  loss_box_reg: 0.316  loss_rpn_cls: 0.020  loss_rpn_loc: 0.057  time: 0.5210  data_time: 0.0052  lr: 0.000899  max_mem: 3094M
[32m[04/20 01:25:45 d2.utils.events]: [0m eta: 0:06:59  iter: 199  total_loss: 0.609  loss_cls: 0.223  loss_box_reg: 0.335  loss_rpn_cls: 0.019  loss_rpn_loc: 0.051  time: 0.5216  data_time: 0.0053  lr: 0.000999  max_mem: 3094M
[32m[04/20 01:25:55 d2.utils.events]: [0m eta: 0:06:48  iter: 219  total_loss: 0.603  loss_cls: 0.211  loss_box_reg: 0.297  loss_rpn_cls: 0.016  loss_rpn_loc: 0.056  time: 0.5216  data_time: 0.0053  lr: 0.001099  max_mem: 3094M
[32m[04/20 01:26:05 d2.utils.events]: [0m eta: 0:06:36  iter: 239  total_loss: 0.556  loss_cls: 0.177  loss_box_reg: 0.280  loss_rpn_cls: 0.019  loss_rpn_loc: 0.046  time: 0.5208  data_time: 0.0052  lr: 0.001199  max_mem: 3094M
[32m[04/20 01:26:16 d2.utils.events]: [0m eta: 0:06:27  iter: 259  total_loss: 0.735  loss_cls: 0.261  loss_box_reg: 0.386  loss_rpn_cls: 0.039  loss_rpn_loc: 0.056  time: 0.5220  data_time: 0.0054  lr: 0.001299  max_mem: 3094M
[32m[04/20 01:26:26 d2.utils.events]: [0m eta: 0:06:15  iter: 279  total_loss: 0.638  loss_cls: 0.227  loss_box_reg: 0.351  loss_rpn_cls: 0.034  loss_rpn_loc: 0.066  time: 0.5203  data_time: 0.0053  lr: 0.001399  max_mem: 3094M
[32m[04/20 01:26:37 d2.utils.events]: [0m eta: 0:06:06  iter: 299  total_loss: 0.625  loss_cls: 0.197  loss_box_reg: 0.355  loss_rpn_cls: 0.020  loss_rpn_loc: 0.042  time: 0.5207  data_time: 0.0052  lr: 0.001499  max_mem: 3094M
[32m[04/20 01:26:48 d2.utils.events]: [0m eta: 0:05:56  iter: 319  total_loss: 0.741  loss_cls: 0.223  loss_box_reg: 0.415  loss_rpn_cls: 0.022  loss_rpn_loc: 0.065  time: 0.5214  data_time: 0.0052  lr: 0.001598  max_mem: 3094M
[32m[04/20 01:26:58 d2.utils.events]: [0m eta: 0:05:46  iter: 339  total_loss: 0.649  loss_cls: 0.221  loss_box_reg: 0.333  loss_rpn_cls: 0.018  loss_rpn_loc: 0.055  time: 0.5221  data_time: 0.0056  lr: 0.001698  max_mem: 3094M
[32m[04/20 01:27:09 d2.utils.events]: [0m eta: 0:05:36  iter: 359  total_loss: 0.707  loss_cls: 0.236  loss_box_reg: 0.378  loss_rpn_cls: 0.023  loss_rpn_loc: 0.070  time: 0.5229  data_time: 0.0054  lr: 0.001798  max_mem: 3094M
[32m[04/20 01:27:19 d2.utils.events]: [0m eta: 0:05:25  iter: 379  total_loss: 0.640  loss_cls: 0.220  loss_box_reg: 0.358  loss_rpn_cls: 0.023  loss_rpn_loc: 0.052  time: 0.5216  data_time: 0.0049  lr: 0.001898  max_mem: 3094M
[32m[04/20 01:27:30 d2.utils.events]: [0m eta: 0:05:14  iter: 399  total_loss: 0.595  loss_cls: 0.196  loss_box_reg: 0.321  loss_rpn_cls: 0.014  loss_rpn_loc: 0.050  time: 0.5221  data_time: 0.0050  lr: 0.001998  max_mem: 3094M
[32m[04/20 01:27:41 d2.utils.events]: [0m eta: 0:05:04  iter: 419  total_loss: 0.604  loss_cls: 0.204  loss_box_reg: 0.312  loss_rpn_cls: 0.021  loss_rpn_loc: 0.047  time: 0.5227  data_time: 0.0053  lr: 0.002098  max_mem: 3094M
[32m[04/20 01:27:51 d2.utils.events]: [0m eta: 0:04:53  iter: 439  total_loss: 0.667  loss_cls: 0.242  loss_box_reg: 0.370  loss_rpn_cls: 0.018  loss_rpn_loc: 0.057  time: 0.5224  data_time: 0.0052  lr: 0.002198  max_mem: 3094M
[32m[04/20 01:28:02 d2.utils.events]: [0m eta: 0:04:43  iter: 459  total_loss: 0.737  loss_cls: 0.223  loss_box_reg: 0.389  loss_rpn_cls: 0.018  loss_rpn_loc: 0.081  time: 0.5228  data_time: 0.0055  lr: 0.002298  max_mem: 3094M
[32m[04/20 01:28:12 d2.utils.events]: [0m eta: 0:04:32  iter: 479  total_loss: 0.614  loss_cls: 0.217  loss_box_reg: 0.337  loss_rpn_cls: 0.020  loss_rpn_loc: 0.056  time: 0.5224  data_time: 0.0054  lr: 0.002398  max_mem: 3094M
[32m[04/20 01:28:22 d2.utils.events]: [0m eta: 0:04:22  iter: 499  total_loss: 0.743  loss_cls: 0.240  loss_box_reg: 0.409  loss_rpn_cls: 0.030  loss_rpn_loc: 0.065  time: 0.5220  data_time: 0.0054  lr: 0.002498  max_mem: 3094M
[32m[04/20 01:28:33 d2.utils.events]: [0m eta: 0:04:11  iter: 519  total_loss: 0.681  loss_cls: 0.235  loss_box_reg: 0.376  loss_rpn_cls: 0.022  loss_rpn_loc: 0.060  time: 0.5220  data_time: 0.0053  lr: 0.002597  max_mem: 3094M
[32m[04/20 01:28:43 d2.utils.events]: [0m eta: 0:04:01  iter: 539  total_loss: 0.650  loss_cls: 0.210  loss_box_reg: 0.342  loss_rpn_cls: 0.022  loss_rpn_loc: 0.049  time: 0.5224  data_time: 0.0056  lr: 0.002697  max_mem: 3094M
[32m[04/20 01:28:54 d2.utils.events]: [0m eta: 0:03:51  iter: 559  total_loss: 0.651  loss_cls: 0.225  loss_box_reg: 0.335  loss_rpn_cls: 0.026  loss_rpn_loc: 0.057  time: 0.5221  data_time: 0.0052  lr: 0.002797  max_mem: 3094M
[32m[04/20 01:29:04 d2.utils.events]: [0m eta: 0:03:40  iter: 579  total_loss: 0.601  loss_cls: 0.211  loss_box_reg: 0.275  loss_rpn_cls: 0.028  loss_rpn_loc: 0.029  time: 0.5220  data_time: 0.0053  lr: 0.002897  max_mem: 3094M
[32m[04/20 01:29:15 d2.utils.events]: [0m eta: 0:03:29  iter: 599  total_loss: 0.758  loss_cls: 0.244  loss_box_reg: 0.414  loss_rpn_cls: 0.024  loss_rpn_loc: 0.053  time: 0.5219  data_time: 0.0054  lr: 0.002997  max_mem: 3094M
[32m[04/20 01:29:25 d2.utils.events]: [0m eta: 0:03:19  iter: 619  total_loss: 0.792  loss_cls: 0.254  loss_box_reg: 0.413  loss_rpn_cls: 0.025  loss_rpn_loc: 0.055  time: 0.5222  data_time: 0.0054  lr: 0.003097  max_mem: 3094M
[32m[04/20 01:29:36 d2.utils.events]: [0m eta: 0:03:09  iter: 639  total_loss: 0.787  loss_cls: 0.255  loss_box_reg: 0.425  loss_rpn_cls: 0.028  loss_rpn_loc: 0.068  time: 0.5222  data_time: 0.0053  lr: 0.003197  max_mem: 3094M
[32m[04/20 01:29:46 d2.utils.events]: [0m eta: 0:02:58  iter: 659  total_loss: 0.734  loss_cls: 0.252  loss_box_reg: 0.406  loss_rpn_cls: 0.033  loss_rpn_loc: 0.064  time: 0.5224  data_time: 0.0051  lr: 0.003297  max_mem: 3094M
[32m[04/20 01:29:57 d2.utils.events]: [0m eta: 0:02:48  iter: 679  total_loss: 0.731  loss_cls: 0.246  loss_box_reg: 0.390  loss_rpn_cls: 0.028  loss_rpn_loc: 0.057  time: 0.5225  data_time: 0.0053  lr: 0.003397  max_mem: 3094M
[32m[04/20 01:30:07 d2.utils.events]: [0m eta: 0:02:37  iter: 699  total_loss: 0.712  loss_cls: 0.230  loss_box_reg: 0.398  loss_rpn_cls: 0.027  loss_rpn_loc: 0.055  time: 0.5224  data_time: 0.0050  lr: 0.003497  max_mem: 3094M
[32m[04/20 01:30:18 d2.utils.events]: [0m eta: 0:02:27  iter: 719  total_loss: 0.634  loss_cls: 0.193  loss_box_reg: 0.318  loss_rpn_cls: 0.026  loss_rpn_loc: 0.049  time: 0.5222  data_time: 0.0049  lr: 0.003596  max_mem: 3094M
[32m[04/20 01:30:28 d2.utils.events]: [0m eta: 0:02:16  iter: 739  total_loss: 0.723  loss_cls: 0.232  loss_box_reg: 0.375  loss_rpn_cls: 0.037  loss_rpn_loc: 0.058  time: 0.5216  data_time: 0.0051  lr: 0.003696  max_mem: 3094M
[32m[04/20 01:30:38 d2.utils.events]: [0m eta: 0:02:06  iter: 759  total_loss: 0.715  loss_cls: 0.256  loss_box_reg: 0.369  loss_rpn_cls: 0.023  loss_rpn_loc: 0.064  time: 0.5216  data_time: 0.0051  lr: 0.003796  max_mem: 3094M
[32m[04/20 01:30:49 d2.utils.events]: [0m eta: 0:01:55  iter: 779  total_loss: 0.620  loss_cls: 0.201  loss_box_reg: 0.334  loss_rpn_cls: 0.030  loss_rpn_loc: 0.059  time: 0.5217  data_time: 0.0053  lr: 0.003896  max_mem: 3094M
[32m[04/20 01:30:59 d2.utils.events]: [0m eta: 0:01:45  iter: 799  total_loss: 0.786  loss_cls: 0.244  loss_box_reg: 0.415  loss_rpn_cls: 0.026  loss_rpn_loc: 0.088  time: 0.5214  data_time: 0.0052  lr: 0.003996  max_mem: 3094M
[32m[04/20 01:31:10 d2.utils.events]: [0m eta: 0:01:34  iter: 819  total_loss: 0.608  loss_cls: 0.199  loss_box_reg: 0.291  loss_rpn_cls: 0.025  loss_rpn_loc: 0.064  time: 0.5216  data_time: 0.0049  lr: 0.004096  max_mem: 3094M
[32m[04/20 01:31:20 d2.utils.events]: [0m eta: 0:01:24  iter: 839  total_loss: 0.701  loss_cls: 0.236  loss_box_reg: 0.367  loss_rpn_cls: 0.028  loss_rpn_loc: 0.051  time: 0.5214  data_time: 0.0050  lr: 0.004196  max_mem: 3094M
[32m[04/20 01:31:31 d2.utils.events]: [0m eta: 0:01:13  iter: 859  total_loss: 0.710  loss_cls: 0.232  loss_box_reg: 0.352  loss_rpn_cls: 0.027  loss_rpn_loc: 0.053  time: 0.5218  data_time: 0.0054  lr: 0.004296  max_mem: 3094M
[32m[04/20 01:31:41 d2.utils.events]: [0m eta: 0:01:03  iter: 879  total_loss: 0.596  loss_cls: 0.210  loss_box_reg: 0.334  loss_rpn_cls: 0.032  loss_rpn_loc: 0.042  time: 0.5216  data_time: 0.0052  lr: 0.004396  max_mem: 3094M
[32m[04/20 01:31:52 d2.utils.events]: [0m eta: 0:00:52  iter: 899  total_loss: 0.718  loss_cls: 0.235  loss_box_reg: 0.375  loss_rpn_cls: 0.027  loss_rpn_loc: 0.064  time: 0.5216  data_time: 0.0050  lr: 0.004496  max_mem: 3094M
[32m[04/20 01:32:02 d2.utils.events]: [0m eta: 0:00:42  iter: 919  total_loss: 0.574  loss_cls: 0.196  loss_box_reg: 0.318  loss_rpn_cls: 0.021  loss_rpn_loc: 0.051  time: 0.5218  data_time: 0.0051  lr: 0.004595  max_mem: 3094M
[32m[04/20 01:32:13 d2.utils.events]: [0m eta: 0:00:31  iter: 939  total_loss: 0.703  loss_cls: 0.239  loss_box_reg: 0.368  loss_rpn_cls: 0.027  loss_rpn_loc: 0.077  time: 0.5218  data_time: 0.0054  lr: 0.004695  max_mem: 3094M
[32m[04/20 01:32:23 d2.utils.events]: [0m eta: 0:00:21  iter: 959  total_loss: 0.734  loss_cls: 0.244  loss_box_reg: 0.359  loss_rpn_cls: 0.030  loss_rpn_loc: 0.074  time: 0.5215  data_time: 0.0049  lr: 0.004795  max_mem: 3094M
[32m[04/20 01:32:34 d2.utils.events]: [0m eta: 0:00:10  iter: 979  total_loss: 0.803  loss_cls: 0.274  loss_box_reg: 0.409  loss_rpn_cls: 0.033  loss_rpn_loc: 0.074  time: 0.5217  data_time: 0.0051  lr: 0.004895  max_mem: 3094M
[5m[31mWARNING[0m [32m[04/20 01:32:47 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 01:32:47 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[5m[31mWARNING[0m [32m[04/20 01:32:47 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 01:32:47 d2.utils.events]: [0m eta: 0:00:00  iter: 999  total_loss: 0.708  loss_cls: 0.246  loss_box_reg: 0.374  loss_rpn_cls: 0.024  loss_rpn_loc: 0.068  time: 0.5215  data_time: 0.0048  lr: 0.004995  max_mem: 3094M
[32m[04/20 01:32:48 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:08:40 (0.5220 s / it)
[32m[04/20 01:32:48 d2.engine.hooks]: [0mTotal training time: 0:08:47 (0:00:06 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 01:32:50 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 01:32:50 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/20 01:32:51 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 01:32:53 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1166 s / img. ETA=0:16:29
[32m[04/20 01:32:58 d2.evaluation.evaluator]: [0mInference done 54/8355. 0.1165 s / img. ETA=0:16:26
[32m[04/20 01:33:03 d2.evaluation.evaluator]: [0mInference done 96/8355. 0.1165 s / img. ETA=0:16:22
[32m[04/20 01:33:08 d2.evaluation.evaluator]: [0mInference done 139/8355. 0.1163 s / img. ETA=0:16:16
[32m[04/20 01:33:13 d2.evaluation.evaluator]: [0mInference done 182/8355. 0.1162 s / img. ETA=0:16:10
[32m[04/20 01:33:18 d2.evaluation.evaluator]: [0mInference done 225/8355. 0.1162 s / img. ETA=0:16:05
[32m[04/20 01:33:23 d2.evaluation.evaluator]: [0mInference done 268/8355. 0.1163 s / img. ETA=0:16:00
[32m[04/20 01:33:28 d2.evaluation.evaluator]: [0mInference done 310/8355. 0.1163 s / img. ETA=0:15:56
[32m[04/20 01:33:33 d2.evaluation.evaluator]: [0mInference done 353/8355. 0.1163 s / img. ETA=0:15:51
[32m[04/20 01:33:38 d2.evaluation.evaluator]: [0mInference done 395/8355. 0.1164 s / img. ETA=0:15:47
[32m[04/20 01:33:43 d2.evaluation.evaluator]: [0mInference done 437/8355. 0.1165 s / img. ETA=0:15:42
[32m[04/20 01:33:48 d2.evaluation.evaluator]: [0mInference done 480/8355. 0.1164 s / img. ETA=0:15:37
[32m[04/20 01:33:54 d2.evaluation.evaluator]: [0mInference done 523/8355. 0.1164 s / img. ETA=0:15:32
[32m[04/20 01:33:59 d2.evaluation.evaluator]: [0mInference done 565/8355. 0.1164 s / img. ETA=0:15:27
[32m[04/20 01:34:04 d2.evaluation.evaluator]: [0mInference done 607/8355. 0.1164 s / img. ETA=0:15:22
[32m[04/20 01:34:09 d2.evaluation.evaluator]: [0mInference done 649/8355. 0.1164 s / img. ETA=0:15:17
[32m[04/20 01:34:14 d2.evaluation.evaluator]: [0mInference done 691/8355. 0.1164 s / img. ETA=0:15:12
[32m[04/20 01:34:19 d2.evaluation.evaluator]: [0mInference done 733/8355. 0.1165 s / img. ETA=0:15:07
[32m[04/20 01:34:24 d2.evaluation.evaluator]: [0mInference done 776/8355. 0.1164 s / img. ETA=0:15:02
[32m[04/20 01:34:29 d2.evaluation.evaluator]: [0mInference done 818/8355. 0.1165 s / img. ETA=0:14:57
[32m[04/20 01:34:34 d2.evaluation.evaluator]: [0mInference done 860/8355. 0.1165 s / img. ETA=0:14:52
[32m[04/20 01:34:39 d2.evaluation.evaluator]: [0mInference done 902/8355. 0.1165 s / img. ETA=0:14:47
[32m[04/20 01:34:44 d2.evaluation.evaluator]: [0mInference done 944/8355. 0.1165 s / img. ETA=0:14:42
[32m[04/20 01:34:49 d2.evaluation.evaluator]: [0mInference done 987/8355. 0.1165 s / img. ETA=0:14:37
[32m[04/20 01:34:54 d2.evaluation.evaluator]: [0mInference done 1029/8355. 0.1165 s / img. ETA=0:14:32
[32m[04/20 01:34:59 d2.evaluation.evaluator]: [0mInference done 1071/8355. 0.1165 s / img. ETA=0:14:28
[32m[04/20 01:35:04 d2.evaluation.evaluator]: [0mInference done 1114/8355. 0.1165 s / img. ETA=0:14:22
[32m[04/20 01:35:09 d2.evaluation.evaluator]: [0mInference done 1157/8355. 0.1165 s / img. ETA=0:14:17
[32m[04/20 01:35:14 d2.evaluation.evaluator]: [0mInference done 1199/8355. 0.1165 s / img. ETA=0:14:12
[32m[04/20 01:35:19 d2.evaluation.evaluator]: [0mInference done 1241/8355. 0.1165 s / img. ETA=0:14:07
[32m[04/20 01:35:24 d2.evaluation.evaluator]: [0mInference done 1284/8355. 0.1165 s / img. ETA=0:14:02
[32m[04/20 01:35:29 d2.evaluation.evaluator]: [0mInference done 1326/8355. 0.1165 s / img. ETA=0:13:57
[32m[04/20 01:35:34 d2.evaluation.evaluator]: [0mInference done 1369/8355. 0.1165 s / img. ETA=0:13:52
[32m[04/20 01:35:40 d2.evaluation.evaluator]: [0mInference done 1412/8355. 0.1165 s / img. ETA=0:13:46
[32m[04/20 01:35:45 d2.evaluation.evaluator]: [0mInference done 1455/8355. 0.1164 s / img. ETA=0:13:41
[32m[04/20 01:35:50 d2.evaluation.evaluator]: [0mInference done 1497/8355. 0.1165 s / img. ETA=0:13:36
[32m[04/20 01:35:55 d2.evaluation.evaluator]: [0mInference done 1539/8355. 0.1165 s / img. ETA=0:13:32
[32m[04/20 01:36:00 d2.evaluation.evaluator]: [0mInference done 1581/8355. 0.1165 s / img. ETA=0:13:27
[32m[04/20 01:36:05 d2.evaluation.evaluator]: [0mInference done 1623/8355. 0.1166 s / img. ETA=0:13:22
[32m[04/20 01:36:10 d2.evaluation.evaluator]: [0mInference done 1665/8355. 0.1166 s / img. ETA=0:13:17
[32m[04/20 01:36:15 d2.evaluation.evaluator]: [0mInference done 1707/8355. 0.1166 s / img. ETA=0:13:12
[32m[04/20 01:36:20 d2.evaluation.evaluator]: [0mInference done 1749/8355. 0.1166 s / img. ETA=0:13:07
[32m[04/20 01:36:25 d2.evaluation.evaluator]: [0mInference done 1791/8355. 0.1166 s / img. ETA=0:13:03
[32m[04/20 01:36:30 d2.evaluation.evaluator]: [0mInference done 1833/8355. 0.1167 s / img. ETA=0:12:58
[32m[04/20 01:36:35 d2.evaluation.evaluator]: [0mInference done 1875/8355. 0.1167 s / img. ETA=0:12:53
[32m[04/20 01:36:40 d2.evaluation.evaluator]: [0mInference done 1917/8355. 0.1167 s / img. ETA=0:12:48
[32m[04/20 01:36:45 d2.evaluation.evaluator]: [0mInference done 1959/8355. 0.1167 s / img. ETA=0:12:43
[32m[04/20 01:36:50 d2.evaluation.evaluator]: [0mInference done 2001/8355. 0.1167 s / img. ETA=0:12:38
[32m[04/20 01:36:55 d2.evaluation.evaluator]: [0mInference done 2043/8355. 0.1168 s / img. ETA=0:12:33
[32m[04/20 01:37:00 d2.evaluation.evaluator]: [0mInference done 2085/8355. 0.1168 s / img. ETA=0:12:28
[32m[04/20 01:37:05 d2.evaluation.evaluator]: [0mInference done 2128/8355. 0.1168 s / img. ETA=0:12:23
[32m[04/20 01:37:10 d2.evaluation.evaluator]: [0mInference done 2170/8355. 0.1168 s / img. ETA=0:12:18
[32m[04/20 01:37:16 d2.evaluation.evaluator]: [0mInference done 2212/8355. 0.1168 s / img. ETA=0:12:13
[32m[04/20 01:37:21 d2.evaluation.evaluator]: [0mInference done 2254/8355. 0.1168 s / img. ETA=0:12:08
[32m[04/20 01:37:26 d2.evaluation.evaluator]: [0mInference done 2296/8355. 0.1168 s / img. ETA=0:12:03
[32m[04/20 01:37:31 d2.evaluation.evaluator]: [0mInference done 2338/8355. 0.1168 s / img. ETA=0:11:58
[32m[04/20 01:37:36 d2.evaluation.evaluator]: [0mInference done 2380/8355. 0.1168 s / img. ETA=0:11:53
[32m[04/20 01:37:41 d2.evaluation.evaluator]: [0mInference done 2422/8355. 0.1168 s / img. ETA=0:11:49
[32m[04/20 01:37:46 d2.evaluation.evaluator]: [0mInference done 2464/8355. 0.1168 s / img. ETA=0:11:44
[32m[04/20 01:37:51 d2.evaluation.evaluator]: [0mInference done 2506/8355. 0.1168 s / img. ETA=0:11:38
[32m[04/20 01:37:56 d2.evaluation.evaluator]: [0mInference done 2548/8355. 0.1169 s / img. ETA=0:11:34
[32m[04/20 01:38:01 d2.evaluation.evaluator]: [0mInference done 2590/8355. 0.1169 s / img. ETA=0:11:29
[32m[04/20 01:38:06 d2.evaluation.evaluator]: [0mInference done 2632/8355. 0.1169 s / img. ETA=0:11:24
[32m[04/20 01:38:11 d2.evaluation.evaluator]: [0mInference done 2674/8355. 0.1169 s / img. ETA=0:11:19
[32m[04/20 01:38:16 d2.evaluation.evaluator]: [0mInference done 2716/8355. 0.1169 s / img. ETA=0:11:14
[32m[04/20 01:38:21 d2.evaluation.evaluator]: [0mInference done 2758/8355. 0.1169 s / img. ETA=0:11:09
[32m[04/20 01:38:26 d2.evaluation.evaluator]: [0mInference done 2800/8355. 0.1169 s / img. ETA=0:11:04
[32m[04/20 01:38:31 d2.evaluation.evaluator]: [0mInference done 2842/8355. 0.1169 s / img. ETA=0:10:59
[32m[04/20 01:38:36 d2.evaluation.evaluator]: [0mInference done 2884/8355. 0.1169 s / img. ETA=0:10:54
[32m[04/20 01:38:41 d2.evaluation.evaluator]: [0mInference done 2926/8355. 0.1169 s / img. ETA=0:10:49
[32m[04/20 01:38:46 d2.evaluation.evaluator]: [0mInference done 2968/8355. 0.1170 s / img. ETA=0:10:44
[32m[04/20 01:38:51 d2.evaluation.evaluator]: [0mInference done 3010/8355. 0.1170 s / img. ETA=0:10:39
[32m[04/20 01:38:57 d2.evaluation.evaluator]: [0mInference done 3052/8355. 0.1170 s / img. ETA=0:10:34
[32m[04/20 01:39:02 d2.evaluation.evaluator]: [0mInference done 3094/8355. 0.1170 s / img. ETA=0:10:29
[32m[04/20 01:39:07 d2.evaluation.evaluator]: [0mInference done 3136/8355. 0.1170 s / img. ETA=0:10:24
[32m[04/20 01:39:12 d2.evaluation.evaluator]: [0mInference done 3178/8355. 0.1170 s / img. ETA=0:10:19
[32m[04/20 01:39:17 d2.evaluation.evaluator]: [0mInference done 3220/8355. 0.1170 s / img. ETA=0:10:14
[32m[04/20 01:39:22 d2.evaluation.evaluator]: [0mInference done 3262/8355. 0.1170 s / img. ETA=0:10:09
[32m[04/20 01:39:27 d2.evaluation.evaluator]: [0mInference done 3305/8355. 0.1170 s / img. ETA=0:10:04
[32m[04/20 01:39:32 d2.evaluation.evaluator]: [0mInference done 3348/8355. 0.1170 s / img. ETA=0:09:59
[32m[04/20 01:39:37 d2.evaluation.evaluator]: [0mInference done 3390/8355. 0.1170 s / img. ETA=0:09:54
[32m[04/20 01:39:42 d2.evaluation.evaluator]: [0mInference done 3432/8355. 0.1170 s / img. ETA=0:09:49
[32m[04/20 01:39:47 d2.evaluation.evaluator]: [0mInference done 3474/8355. 0.1170 s / img. ETA=0:09:44
[32m[04/20 01:39:52 d2.evaluation.evaluator]: [0mInference done 3516/8355. 0.1170 s / img. ETA=0:09:39
[32m[04/20 01:39:57 d2.evaluation.evaluator]: [0mInference done 3558/8355. 0.1170 s / img. ETA=0:09:34
[32m[04/20 01:40:02 d2.evaluation.evaluator]: [0mInference done 3600/8355. 0.1170 s / img. ETA=0:09:29
[32m[04/20 01:40:07 d2.evaluation.evaluator]: [0mInference done 3642/8355. 0.1170 s / img. ETA=0:09:24
[32m[04/20 01:40:12 d2.evaluation.evaluator]: [0mInference done 3684/8355. 0.1170 s / img. ETA=0:09:19
[32m[04/20 01:40:17 d2.evaluation.evaluator]: [0mInference done 3726/8355. 0.1170 s / img. ETA=0:09:14
[32m[04/20 01:40:23 d2.evaluation.evaluator]: [0mInference done 3768/8355. 0.1171 s / img. ETA=0:09:09
[32m[04/20 01:40:28 d2.evaluation.evaluator]: [0mInference done 3810/8355. 0.1171 s / img. ETA=0:09:04
[32m[04/20 01:40:33 d2.evaluation.evaluator]: [0mInference done 3852/8355. 0.1171 s / img. ETA=0:08:59
[32m[04/20 01:40:38 d2.evaluation.evaluator]: [0mInference done 3894/8355. 0.1171 s / img. ETA=0:08:54
[32m[04/20 01:40:43 d2.evaluation.evaluator]: [0mInference done 3936/8355. 0.1171 s / img. ETA=0:08:49
[32m[04/20 01:40:48 d2.evaluation.evaluator]: [0mInference done 3978/8355. 0.1171 s / img. ETA=0:08:44
[32m[04/20 01:40:53 d2.evaluation.evaluator]: [0mInference done 4020/8355. 0.1171 s / img. ETA=0:08:39
[32m[04/20 01:40:58 d2.evaluation.evaluator]: [0mInference done 4062/8355. 0.1171 s / img. ETA=0:08:34
[32m[04/20 01:41:03 d2.evaluation.evaluator]: [0mInference done 4104/8355. 0.1171 s / img. ETA=0:08:29
[32m[04/20 01:41:08 d2.evaluation.evaluator]: [0mInference done 4146/8355. 0.1171 s / img. ETA=0:08:24
[32m[04/20 01:41:13 d2.evaluation.evaluator]: [0mInference done 4188/8355. 0.1171 s / img. ETA=0:08:19
[32m[04/20 01:41:18 d2.evaluation.evaluator]: [0mInference done 4230/8355. 0.1171 s / img. ETA=0:08:14
[32m[04/20 01:41:23 d2.evaluation.evaluator]: [0mInference done 4272/8355. 0.1171 s / img. ETA=0:08:09
[32m[04/20 01:41:28 d2.evaluation.evaluator]: [0mInference done 4314/8355. 0.1171 s / img. ETA=0:08:04
[32m[04/20 01:41:33 d2.evaluation.evaluator]: [0mInference done 4356/8355. 0.1171 s / img. ETA=0:07:59
[32m[04/20 01:41:38 d2.evaluation.evaluator]: [0mInference done 4398/8355. 0.1171 s / img. ETA=0:07:54
[32m[04/20 01:41:43 d2.evaluation.evaluator]: [0mInference done 4440/8355. 0.1171 s / img. ETA=0:07:49
[32m[04/20 01:41:48 d2.evaluation.evaluator]: [0mInference done 4482/8355. 0.1171 s / img. ETA=0:07:44
[32m[04/20 01:41:53 d2.evaluation.evaluator]: [0mInference done 4524/8355. 0.1171 s / img. ETA=0:07:39
[32m[04/20 01:41:58 d2.evaluation.evaluator]: [0mInference done 4566/8355. 0.1172 s / img. ETA=0:07:34
[32m[04/20 01:42:04 d2.evaluation.evaluator]: [0mInference done 4608/8355. 0.1172 s / img. ETA=0:07:29
[32m[04/20 01:42:09 d2.evaluation.evaluator]: [0mInference done 4650/8355. 0.1172 s / img. ETA=0:07:24
[32m[04/20 01:42:14 d2.evaluation.evaluator]: [0mInference done 4692/8355. 0.1172 s / img. ETA=0:07:18
[32m[04/20 01:42:19 d2.evaluation.evaluator]: [0mInference done 4734/8355. 0.1172 s / img. ETA=0:07:13
[32m[04/20 01:42:24 d2.evaluation.evaluator]: [0mInference done 4776/8355. 0.1172 s / img. ETA=0:07:08
[32m[04/20 01:42:29 d2.evaluation.evaluator]: [0mInference done 4818/8355. 0.1172 s / img. ETA=0:07:03
[32m[04/20 01:42:34 d2.evaluation.evaluator]: [0mInference done 4860/8355. 0.1172 s / img. ETA=0:06:58
[32m[04/20 01:42:39 d2.evaluation.evaluator]: [0mInference done 4902/8355. 0.1172 s / img. ETA=0:06:53
[32m[04/20 01:42:44 d2.evaluation.evaluator]: [0mInference done 4944/8355. 0.1172 s / img. ETA=0:06:48
[32m[04/20 01:42:49 d2.evaluation.evaluator]: [0mInference done 4986/8355. 0.1172 s / img. ETA=0:06:43
[32m[04/20 01:42:54 d2.evaluation.evaluator]: [0mInference done 5028/8355. 0.1172 s / img. ETA=0:06:38
[32m[04/20 01:42:59 d2.evaluation.evaluator]: [0mInference done 5070/8355. 0.1172 s / img. ETA=0:06:33
[32m[04/20 01:43:04 d2.evaluation.evaluator]: [0mInference done 5112/8355. 0.1172 s / img. ETA=0:06:28
[32m[04/20 01:43:09 d2.evaluation.evaluator]: [0mInference done 5154/8355. 0.1172 s / img. ETA=0:06:23
[32m[04/20 01:43:14 d2.evaluation.evaluator]: [0mInference done 5196/8355. 0.1172 s / img. ETA=0:06:18
[32m[04/20 01:43:19 d2.evaluation.evaluator]: [0mInference done 5238/8355. 0.1172 s / img. ETA=0:06:13
[32m[04/20 01:43:24 d2.evaluation.evaluator]: [0mInference done 5280/8355. 0.1172 s / img. ETA=0:06:08
[32m[04/20 01:43:29 d2.evaluation.evaluator]: [0mInference done 5322/8355. 0.1172 s / img. ETA=0:06:03
[32m[04/20 01:43:35 d2.evaluation.evaluator]: [0mInference done 5364/8355. 0.1172 s / img. ETA=0:05:58
[32m[04/20 01:43:40 d2.evaluation.evaluator]: [0mInference done 5406/8355. 0.1173 s / img. ETA=0:05:53
[32m[04/20 01:43:45 d2.evaluation.evaluator]: [0mInference done 5448/8355. 0.1173 s / img. ETA=0:05:48
[32m[04/20 01:43:50 d2.evaluation.evaluator]: [0mInference done 5490/8355. 0.1173 s / img. ETA=0:05:43
[32m[04/20 01:43:55 d2.evaluation.evaluator]: [0mInference done 5532/8355. 0.1173 s / img. ETA=0:05:38
[32m[04/20 01:44:00 d2.evaluation.evaluator]: [0mInference done 5574/8355. 0.1173 s / img. ETA=0:05:33
[32m[04/20 01:44:05 d2.evaluation.evaluator]: [0mInference done 5616/8355. 0.1173 s / img. ETA=0:05:28
[32m[04/20 01:44:10 d2.evaluation.evaluator]: [0mInference done 5658/8355. 0.1173 s / img. ETA=0:05:23
[32m[04/20 01:44:15 d2.evaluation.evaluator]: [0mInference done 5700/8355. 0.1173 s / img. ETA=0:05:18
[32m[04/20 01:44:20 d2.evaluation.evaluator]: [0mInference done 5742/8355. 0.1173 s / img. ETA=0:05:13
[32m[04/20 01:44:25 d2.evaluation.evaluator]: [0mInference done 5784/8355. 0.1173 s / img. ETA=0:05:08
[32m[04/20 01:44:30 d2.evaluation.evaluator]: [0mInference done 5826/8355. 0.1173 s / img. ETA=0:05:03
[32m[04/20 01:44:35 d2.evaluation.evaluator]: [0mInference done 5868/8355. 0.1173 s / img. ETA=0:04:58
[32m[04/20 01:44:41 d2.evaluation.evaluator]: [0mInference done 5910/8355. 0.1173 s / img. ETA=0:04:53
[32m[04/20 01:44:46 d2.evaluation.evaluator]: [0mInference done 5952/8355. 0.1173 s / img. ETA=0:04:48
[32m[04/20 01:44:51 d2.evaluation.evaluator]: [0mInference done 5994/8355. 0.1173 s / img. ETA=0:04:43
[32m[04/20 01:44:56 d2.evaluation.evaluator]: [0mInference done 6036/8355. 0.1174 s / img. ETA=0:04:38
[32m[04/20 01:45:01 d2.evaluation.evaluator]: [0mInference done 6078/8355. 0.1174 s / img. ETA=0:04:33
[32m[04/20 01:45:06 d2.evaluation.evaluator]: [0mInference done 6120/8355. 0.1174 s / img. ETA=0:04:28
[32m[04/20 01:45:11 d2.evaluation.evaluator]: [0mInference done 6162/8355. 0.1174 s / img. ETA=0:04:23
[32m[04/20 01:45:16 d2.evaluation.evaluator]: [0mInference done 6204/8355. 0.1174 s / img. ETA=0:04:18
[32m[04/20 01:45:21 d2.evaluation.evaluator]: [0mInference done 6246/8355. 0.1174 s / img. ETA=0:04:13
[32m[04/20 01:45:26 d2.evaluation.evaluator]: [0mInference done 6288/8355. 0.1174 s / img. ETA=0:04:08
[32m[04/20 01:45:31 d2.evaluation.evaluator]: [0mInference done 6330/8355. 0.1174 s / img. ETA=0:04:03
[32m[04/20 01:45:37 d2.evaluation.evaluator]: [0mInference done 6372/8355. 0.1174 s / img. ETA=0:03:58
[32m[04/20 01:45:42 d2.evaluation.evaluator]: [0mInference done 6414/8355. 0.1174 s / img. ETA=0:03:53
[32m[04/20 01:45:47 d2.evaluation.evaluator]: [0mInference done 6456/8355. 0.1174 s / img. ETA=0:03:48
[32m[04/20 01:45:52 d2.evaluation.evaluator]: [0mInference done 6497/8355. 0.1174 s / img. ETA=0:03:43
[32m[04/20 01:45:57 d2.evaluation.evaluator]: [0mInference done 6539/8355. 0.1174 s / img. ETA=0:03:38
[32m[04/20 01:46:02 d2.evaluation.evaluator]: [0mInference done 6581/8355. 0.1174 s / img. ETA=0:03:33
[32m[04/20 01:46:07 d2.evaluation.evaluator]: [0mInference done 6623/8355. 0.1174 s / img. ETA=0:03:28
[32m[04/20 01:46:12 d2.evaluation.evaluator]: [0mInference done 6665/8355. 0.1174 s / img. ETA=0:03:22
[32m[04/20 01:46:17 d2.evaluation.evaluator]: [0mInference done 6707/8355. 0.1174 s / img. ETA=0:03:17
[32m[04/20 01:46:22 d2.evaluation.evaluator]: [0mInference done 6749/8355. 0.1174 s / img. ETA=0:03:12
[32m[04/20 01:46:27 d2.evaluation.evaluator]: [0mInference done 6791/8355. 0.1174 s / img. ETA=0:03:07
[32m[04/20 01:46:32 d2.evaluation.evaluator]: [0mInference done 6833/8355. 0.1174 s / img. ETA=0:03:02
[32m[04/20 01:46:37 d2.evaluation.evaluator]: [0mInference done 6875/8355. 0.1174 s / img. ETA=0:02:57
[32m[04/20 01:46:42 d2.evaluation.evaluator]: [0mInference done 6917/8355. 0.1175 s / img. ETA=0:02:52
[32m[04/20 01:46:47 d2.evaluation.evaluator]: [0mInference done 6959/8355. 0.1175 s / img. ETA=0:02:47
[32m[04/20 01:46:52 d2.evaluation.evaluator]: [0mInference done 7001/8355. 0.1175 s / img. ETA=0:02:42
[32m[04/20 01:46:57 d2.evaluation.evaluator]: [0mInference done 7043/8355. 0.1175 s / img. ETA=0:02:37
[32m[04/20 01:47:03 d2.evaluation.evaluator]: [0mInference done 7085/8355. 0.1175 s / img. ETA=0:02:32
[32m[04/20 01:47:08 d2.evaluation.evaluator]: [0mInference done 7127/8355. 0.1175 s / img. ETA=0:02:27
[32m[04/20 01:47:13 d2.evaluation.evaluator]: [0mInference done 7169/8355. 0.1175 s / img. ETA=0:02:22
[32m[04/20 01:47:18 d2.evaluation.evaluator]: [0mInference done 7211/8355. 0.1175 s / img. ETA=0:02:17
[32m[04/20 01:47:23 d2.evaluation.evaluator]: [0mInference done 7253/8355. 0.1175 s / img. ETA=0:02:12
[32m[04/20 01:47:28 d2.evaluation.evaluator]: [0mInference done 7295/8355. 0.1175 s / img. ETA=0:02:07
[32m[04/20 01:47:33 d2.evaluation.evaluator]: [0mInference done 7337/8355. 0.1175 s / img. ETA=0:02:02
[32m[04/20 01:47:38 d2.evaluation.evaluator]: [0mInference done 7378/8355. 0.1175 s / img. ETA=0:01:57
[32m[04/20 01:47:43 d2.evaluation.evaluator]: [0mInference done 7420/8355. 0.1175 s / img. ETA=0:01:52
[32m[04/20 01:47:48 d2.evaluation.evaluator]: [0mInference done 7461/8355. 0.1175 s / img. ETA=0:01:47
[32m[04/20 01:47:53 d2.evaluation.evaluator]: [0mInference done 7502/8355. 0.1176 s / img. ETA=0:01:42
[32m[04/20 01:47:58 d2.evaluation.evaluator]: [0mInference done 7544/8355. 0.1176 s / img. ETA=0:01:37
[32m[04/20 01:48:04 d2.evaluation.evaluator]: [0mInference done 7586/8355. 0.1176 s / img. ETA=0:01:32
[32m[04/20 01:48:09 d2.evaluation.evaluator]: [0mInference done 7628/8355. 0.1176 s / img. ETA=0:01:27
[32m[04/20 01:48:14 d2.evaluation.evaluator]: [0mInference done 7670/8355. 0.1176 s / img. ETA=0:01:22
[32m[04/20 01:48:19 d2.evaluation.evaluator]: [0mInference done 7711/8355. 0.1176 s / img. ETA=0:01:17
[32m[04/20 01:48:24 d2.evaluation.evaluator]: [0mInference done 7752/8355. 0.1176 s / img. ETA=0:01:12
[32m[04/20 01:48:29 d2.evaluation.evaluator]: [0mInference done 7794/8355. 0.1176 s / img. ETA=0:01:07
[32m[04/20 01:48:34 d2.evaluation.evaluator]: [0mInference done 7836/8355. 0.1176 s / img. ETA=0:01:02
[32m[04/20 01:48:39 d2.evaluation.evaluator]: [0mInference done 7878/8355. 0.1176 s / img. ETA=0:00:57
[32m[04/20 01:48:44 d2.evaluation.evaluator]: [0mInference done 7920/8355. 0.1176 s / img. ETA=0:00:52
[32m[04/20 01:48:49 d2.evaluation.evaluator]: [0mInference done 7961/8355. 0.1176 s / img. ETA=0:00:47
[32m[04/20 01:48:54 d2.evaluation.evaluator]: [0mInference done 8002/8355. 0.1176 s / img. ETA=0:00:42
[32m[04/20 01:48:59 d2.evaluation.evaluator]: [0mInference done 8044/8355. 0.1176 s / img. ETA=0:00:37
[32m[04/20 01:49:04 d2.evaluation.evaluator]: [0mInference done 8086/8355. 0.1176 s / img. ETA=0:00:32
[32m[04/20 01:49:09 d2.evaluation.evaluator]: [0mInference done 8128/8355. 0.1176 s / img. ETA=0:00:27
[32m[04/20 01:49:14 d2.evaluation.evaluator]: [0mInference done 8170/8355. 0.1176 s / img. ETA=0:00:22
[32m[04/20 01:49:19 d2.evaluation.evaluator]: [0mInference done 8212/8355. 0.1177 s / img. ETA=0:00:17
[32m[04/20 01:49:25 d2.evaluation.evaluator]: [0mInference done 8254/8355. 0.1177 s / img. ETA=0:00:12
[32m[04/20 01:49:30 d2.evaluation.evaluator]: [0mInference done 8296/8355. 0.1177 s / img. ETA=0:00:07
[32m[04/20 01:49:35 d2.evaluation.evaluator]: [0mInference done 8338/8355. 0.1177 s / img. ETA=0:00:02
[32m[04/20 01:49:37 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:44.884348 (0.120345 s / img per device, on 1 devices)
[32m[04/20 01:49:37 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:22 (0.117658 s / img per device, on 1 devices)
[32m[04/20 01:49:37 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 01:49:37 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 01:49:37 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.15s).
Accumulating evaluation results...
DONE (t=2.19s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.249
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.501
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.210
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.318
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.526
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.137
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.293
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.299
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.366
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.558
[32m[04/20 01:50:00 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 24.884 | 50.082 | 20.964 | 18.558 | 31.800 | 52.612 |
[32m[04/20 01:50:00 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 30.246 | bicycle       | 13.397 | car            | 37.901 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | 17.993 | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 01:50:02 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 01:50:02 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[32m[04/20 01:50:02 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 01:50:03 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1178 s / img. ETA=0:02:29
[32m[04/20 01:50:08 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1178 s / img. ETA=0:02:25
[32m[04/20 01:50:13 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1180 s / img. ETA=0:02:20
[32m[04/20 01:50:18 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1180 s / img. ETA=0:02:15
[32m[04/20 01:50:23 d2.evaluation.evaluator]: [0mInference done 179/1257. 0.1180 s / img. ETA=0:02:10
[32m[04/20 01:50:29 d2.evaluation.evaluator]: [0mInference done 221/1257. 0.1180 s / img. ETA=0:02:05
[32m[04/20 01:50:34 d2.evaluation.evaluator]: [0mInference done 263/1257. 0.1180 s / img. ETA=0:02:00
[32m[04/20 01:50:39 d2.evaluation.evaluator]: [0mInference done 305/1257. 0.1181 s / img. ETA=0:01:55
[32m[04/20 01:50:44 d2.evaluation.evaluator]: [0mInference done 347/1257. 0.1181 s / img. ETA=0:01:49
[32m[04/20 01:50:49 d2.evaluation.evaluator]: [0mInference done 389/1257. 0.1180 s / img. ETA=0:01:44
[32m[04/20 01:50:54 d2.evaluation.evaluator]: [0mInference done 431/1257. 0.1180 s / img. ETA=0:01:39
[32m[04/20 01:50:59 d2.evaluation.evaluator]: [0mInference done 473/1257. 0.1181 s / img. ETA=0:01:34
[32m[04/20 01:51:04 d2.evaluation.evaluator]: [0mInference done 515/1257. 0.1180 s / img. ETA=0:01:29
[32m[04/20 01:51:09 d2.evaluation.evaluator]: [0mInference done 557/1257. 0.1180 s / img. ETA=0:01:24
[32m[04/20 01:51:14 d2.evaluation.evaluator]: [0mInference done 599/1257. 0.1180 s / img. ETA=0:01:19
[32m[04/20 01:51:19 d2.evaluation.evaluator]: [0mInference done 641/1257. 0.1180 s / img. ETA=0:01:14
[32m[04/20 01:51:24 d2.evaluation.evaluator]: [0mInference done 683/1257. 0.1181 s / img. ETA=0:01:09
[32m[04/20 01:51:29 d2.evaluation.evaluator]: [0mInference done 725/1257. 0.1181 s / img. ETA=0:01:04
[32m[04/20 01:51:34 d2.evaluation.evaluator]: [0mInference done 767/1257. 0.1181 s / img. ETA=0:00:59
[32m[04/20 01:51:40 d2.evaluation.evaluator]: [0mInference done 809/1257. 0.1181 s / img. ETA=0:00:54
[32m[04/20 01:51:45 d2.evaluation.evaluator]: [0mInference done 851/1257. 0.1181 s / img. ETA=0:00:49
[32m[04/20 01:51:50 d2.evaluation.evaluator]: [0mInference done 893/1257. 0.1181 s / img. ETA=0:00:43
[32m[04/20 01:51:55 d2.evaluation.evaluator]: [0mInference done 935/1257. 0.1181 s / img. ETA=0:00:38
[32m[04/20 01:52:00 d2.evaluation.evaluator]: [0mInference done 977/1257. 0.1181 s / img. ETA=0:00:33
[32m[04/20 01:52:05 d2.evaluation.evaluator]: [0mInference done 1019/1257. 0.1181 s / img. ETA=0:00:28
[32m[04/20 01:52:10 d2.evaluation.evaluator]: [0mInference done 1061/1257. 0.1181 s / img. ETA=0:00:23
[32m[04/20 01:52:15 d2.evaluation.evaluator]: [0mInference done 1103/1257. 0.1181 s / img. ETA=0:00:18
[32m[04/20 01:52:20 d2.evaluation.evaluator]: [0mInference done 1145/1257. 0.1181 s / img. ETA=0:00:13
[32m[04/20 01:52:25 d2.evaluation.evaluator]: [0mInference done 1187/1257. 0.1181 s / img. ETA=0:00:08
[32m[04/20 01:52:30 d2.evaluation.evaluator]: [0mInference done 1229/1257. 0.1181 s / img. ETA=0:00:03
[32m[04/20 01:52:34 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:31.328048 (0.120869 s / img per device, on 1 devices)
[32m[04/20 01:52:34 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:27 (0.118086 s / img per device, on 1 devices)
[32m[04/20 01:52:34 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 01:52:34 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 01:52:34 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.47s).
Accumulating evaluation results...
DONE (t=0.38s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.165
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.321
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.145
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.094
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.204
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.392
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.078
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.196
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.197
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.128
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.238
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.424
[32m[04/20 01:52:37 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 16.455 | 32.133 | 14.462 | 9.372 | 20.422 | 39.237 |
[32m[04/20 01:52:37 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 22.872 | bicycle       | 5.057 | car            | 37.891 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | 0.000 | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  9  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 01:52:38 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 01:52:38 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 01:52:38 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/20 01:52:38 d2.data.build]: [0mRemoved 889 images with no usable annotations. 7466 images left.
[32m[04/20 01:52:39 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 01:52:39 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 01:52:39 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 01:52:50 d2.utils.events]: [0m eta: 0:08:53  iter: 19  total_loss: 0.644  loss_cls: 0.227  loss_box_reg: 0.363  loss_rpn_cls: 0.029  loss_rpn_loc: 0.053  time: 0.5373  data_time: 0.0201  lr: 0.000100  max_mem: 3094M
[32m[04/20 01:53:01 d2.utils.events]: [0m eta: 0:08:24  iter: 39  total_loss: 0.793  loss_cls: 0.230  loss_box_reg: 0.389  loss_rpn_cls: 0.026  loss_rpn_loc: 0.079  time: 0.5231  data_time: 0.0052  lr: 0.000200  max_mem: 3094M
[32m[04/20 01:53:11 d2.utils.events]: [0m eta: 0:08:08  iter: 59  total_loss: 0.595  loss_cls: 0.211  loss_box_reg: 0.304  loss_rpn_cls: 0.020  loss_rpn_loc: 0.054  time: 0.5190  data_time: 0.0051  lr: 0.000300  max_mem: 3094M
[32m[04/20 01:53:21 d2.utils.events]: [0m eta: 0:07:58  iter: 79  total_loss: 0.719  loss_cls: 0.235  loss_box_reg: 0.338  loss_rpn_cls: 0.023  loss_rpn_loc: 0.064  time: 0.5216  data_time: 0.0053  lr: 0.000400  max_mem: 3094M
[32m[04/20 01:53:32 d2.utils.events]: [0m eta: 0:07:51  iter: 99  total_loss: 0.742  loss_cls: 0.242  loss_box_reg: 0.416  loss_rpn_cls: 0.027  loss_rpn_loc: 0.059  time: 0.5211  data_time: 0.0053  lr: 0.000500  max_mem: 3094M
[32m[04/20 01:53:42 d2.utils.events]: [0m eta: 0:07:38  iter: 119  total_loss: 0.657  loss_cls: 0.217  loss_box_reg: 0.354  loss_rpn_cls: 0.021  loss_rpn_loc: 0.052  time: 0.5206  data_time: 0.0051  lr: 0.000599  max_mem: 3094M
[32m[04/20 01:53:53 d2.utils.events]: [0m eta: 0:07:30  iter: 139  total_loss: 0.540  loss_cls: 0.201  loss_box_reg: 0.292  loss_rpn_cls: 0.024  loss_rpn_loc: 0.050  time: 0.5224  data_time: 0.0054  lr: 0.000699  max_mem: 3094M
[32m[04/20 01:54:03 d2.utils.events]: [0m eta: 0:07:20  iter: 159  total_loss: 0.687  loss_cls: 0.216  loss_box_reg: 0.363  loss_rpn_cls: 0.027  loss_rpn_loc: 0.048  time: 0.5213  data_time: 0.0050  lr: 0.000799  max_mem: 3094M
[32m[04/20 01:54:14 d2.utils.events]: [0m eta: 0:07:09  iter: 179  total_loss: 0.555  loss_cls: 0.190  loss_box_reg: 0.273  loss_rpn_cls: 0.017  loss_rpn_loc: 0.048  time: 0.5214  data_time: 0.0057  lr: 0.000899  max_mem: 3094M
[32m[04/20 01:54:25 d2.utils.events]: [0m eta: 0:06:59  iter: 199  total_loss: 0.778  loss_cls: 0.238  loss_box_reg: 0.384  loss_rpn_cls: 0.026  loss_rpn_loc: 0.066  time: 0.5224  data_time: 0.0052  lr: 0.000999  max_mem: 3094M
[32m[04/20 01:54:35 d2.utils.events]: [0m eta: 0:06:48  iter: 219  total_loss: 0.732  loss_cls: 0.253  loss_box_reg: 0.390  loss_rpn_cls: 0.026  loss_rpn_loc: 0.061  time: 0.5215  data_time: 0.0051  lr: 0.001099  max_mem: 3094M
[32m[04/20 01:54:45 d2.utils.events]: [0m eta: 0:06:37  iter: 239  total_loss: 0.686  loss_cls: 0.205  loss_box_reg: 0.317  loss_rpn_cls: 0.022  loss_rpn_loc: 0.056  time: 0.5212  data_time: 0.0053  lr: 0.001199  max_mem: 3094M
[32m[04/20 01:54:56 d2.utils.events]: [0m eta: 0:06:27  iter: 259  total_loss: 0.664  loss_cls: 0.222  loss_box_reg: 0.361  loss_rpn_cls: 0.018  loss_rpn_loc: 0.054  time: 0.5220  data_time: 0.0052  lr: 0.001299  max_mem: 3094M
[32m[04/20 01:55:07 d2.utils.events]: [0m eta: 0:06:17  iter: 279  total_loss: 0.567  loss_cls: 0.192  loss_box_reg: 0.291  loss_rpn_cls: 0.021  loss_rpn_loc: 0.045  time: 0.5229  data_time: 0.0053  lr: 0.001399  max_mem: 3094M
[32m[04/20 01:55:17 d2.utils.events]: [0m eta: 0:06:07  iter: 299  total_loss: 0.693  loss_cls: 0.229  loss_box_reg: 0.403  loss_rpn_cls: 0.024  loss_rpn_loc: 0.055  time: 0.5223  data_time: 0.0054  lr: 0.001499  max_mem: 3094M
[32m[04/20 01:55:27 d2.utils.events]: [0m eta: 0:05:55  iter: 319  total_loss: 0.703  loss_cls: 0.243  loss_box_reg: 0.369  loss_rpn_cls: 0.028  loss_rpn_loc: 0.060  time: 0.5214  data_time: 0.0051  lr: 0.001598  max_mem: 3094M
[32m[04/20 01:55:38 d2.utils.events]: [0m eta: 0:05:45  iter: 339  total_loss: 0.692  loss_cls: 0.220  loss_box_reg: 0.373  loss_rpn_cls: 0.028  loss_rpn_loc: 0.062  time: 0.5210  data_time: 0.0051  lr: 0.001698  max_mem: 3094M
[32m[04/20 01:55:48 d2.utils.events]: [0m eta: 0:05:34  iter: 359  total_loss: 0.804  loss_cls: 0.248  loss_box_reg: 0.418  loss_rpn_cls: 0.018  loss_rpn_loc: 0.063  time: 0.5216  data_time: 0.0054  lr: 0.001798  max_mem: 3094M
[32m[04/20 01:55:59 d2.utils.events]: [0m eta: 0:05:24  iter: 379  total_loss: 0.750  loss_cls: 0.251  loss_box_reg: 0.407  loss_rpn_cls: 0.022  loss_rpn_loc: 0.054  time: 0.5222  data_time: 0.0054  lr: 0.001898  max_mem: 3094M
[32m[04/20 01:56:10 d2.utils.events]: [0m eta: 0:05:14  iter: 399  total_loss: 0.626  loss_cls: 0.214  loss_box_reg: 0.329  loss_rpn_cls: 0.021  loss_rpn_loc: 0.047  time: 0.5224  data_time: 0.0053  lr: 0.001998  max_mem: 3094M
[32m[04/20 01:56:20 d2.utils.events]: [0m eta: 0:05:04  iter: 419  total_loss: 0.633  loss_cls: 0.204  loss_box_reg: 0.342  loss_rpn_cls: 0.019  loss_rpn_loc: 0.058  time: 0.5228  data_time: 0.0052  lr: 0.002098  max_mem: 3094M
[32m[04/20 01:56:30 d2.utils.events]: [0m eta: 0:04:53  iter: 439  total_loss: 0.704  loss_cls: 0.239  loss_box_reg: 0.341  loss_rpn_cls: 0.028  loss_rpn_loc: 0.066  time: 0.5222  data_time: 0.0052  lr: 0.002198  max_mem: 3094M
[32m[04/20 01:56:41 d2.utils.events]: [0m eta: 0:04:42  iter: 459  total_loss: 0.625  loss_cls: 0.206  loss_box_reg: 0.330  loss_rpn_cls: 0.031  loss_rpn_loc: 0.063  time: 0.5213  data_time: 0.0052  lr: 0.002298  max_mem: 3094M
[32m[04/20 01:56:51 d2.utils.events]: [0m eta: 0:04:32  iter: 479  total_loss: 0.587  loss_cls: 0.211  loss_box_reg: 0.310  loss_rpn_cls: 0.025  loss_rpn_loc: 0.045  time: 0.5212  data_time: 0.0051  lr: 0.002398  max_mem: 3094M
[32m[04/20 01:57:02 d2.utils.events]: [0m eta: 0:04:22  iter: 499  total_loss: 0.769  loss_cls: 0.261  loss_box_reg: 0.419  loss_rpn_cls: 0.024  loss_rpn_loc: 0.061  time: 0.5218  data_time: 0.0054  lr: 0.002498  max_mem: 3094M
[32m[04/20 01:57:13 d2.utils.events]: [0m eta: 0:04:11  iter: 519  total_loss: 0.610  loss_cls: 0.213  loss_box_reg: 0.331  loss_rpn_cls: 0.021  loss_rpn_loc: 0.058  time: 0.5223  data_time: 0.0055  lr: 0.002597  max_mem: 3094M
[32m[04/20 01:57:23 d2.utils.events]: [0m eta: 0:04:01  iter: 539  total_loss: 0.660  loss_cls: 0.224  loss_box_reg: 0.368  loss_rpn_cls: 0.022  loss_rpn_loc: 0.059  time: 0.5226  data_time: 0.0051  lr: 0.002697  max_mem: 3094M
[32m[04/20 01:57:34 d2.utils.events]: [0m eta: 0:03:51  iter: 559  total_loss: 0.737  loss_cls: 0.245  loss_box_reg: 0.371  loss_rpn_cls: 0.031  loss_rpn_loc: 0.058  time: 0.5230  data_time: 0.0047  lr: 0.002797  max_mem: 3094M
[32m[04/20 01:57:45 d2.utils.events]: [0m eta: 0:03:40  iter: 579  total_loss: 0.767  loss_cls: 0.235  loss_box_reg: 0.438  loss_rpn_cls: 0.020  loss_rpn_loc: 0.052  time: 0.5235  data_time: 0.0052  lr: 0.002897  max_mem: 3094M
[32m[04/20 01:57:55 d2.utils.events]: [0m eta: 0:03:30  iter: 599  total_loss: 0.710  loss_cls: 0.248  loss_box_reg: 0.413  loss_rpn_cls: 0.027  loss_rpn_loc: 0.060  time: 0.5238  data_time: 0.0053  lr: 0.002997  max_mem: 3094M
[32m[04/20 01:58:06 d2.utils.events]: [0m eta: 0:03:20  iter: 619  total_loss: 0.719  loss_cls: 0.230  loss_box_reg: 0.397  loss_rpn_cls: 0.026  loss_rpn_loc: 0.047  time: 0.5237  data_time: 0.0053  lr: 0.003097  max_mem: 3094M
[32m[04/20 01:58:16 d2.utils.events]: [0m eta: 0:03:09  iter: 639  total_loss: 0.737  loss_cls: 0.244  loss_box_reg: 0.395  loss_rpn_cls: 0.028  loss_rpn_loc: 0.075  time: 0.5237  data_time: 0.0056  lr: 0.003197  max_mem: 3094M
[32m[04/20 01:58:27 d2.utils.events]: [0m eta: 0:02:59  iter: 659  total_loss: 0.642  loss_cls: 0.223  loss_box_reg: 0.322  loss_rpn_cls: 0.020  loss_rpn_loc: 0.053  time: 0.5235  data_time: 0.0051  lr: 0.003297  max_mem: 3094M
[32m[04/20 01:58:37 d2.utils.events]: [0m eta: 0:02:48  iter: 679  total_loss: 0.556  loss_cls: 0.195  loss_box_reg: 0.299  loss_rpn_cls: 0.020  loss_rpn_loc: 0.043  time: 0.5233  data_time: 0.0051  lr: 0.003397  max_mem: 3094M
[32m[04/20 01:58:48 d2.utils.events]: [0m eta: 0:02:38  iter: 699  total_loss: 0.732  loss_cls: 0.248  loss_box_reg: 0.388  loss_rpn_cls: 0.027  loss_rpn_loc: 0.076  time: 0.5232  data_time: 0.0051  lr: 0.003497  max_mem: 3094M
[32m[04/20 01:58:58 d2.utils.events]: [0m eta: 0:02:27  iter: 719  total_loss: 0.721  loss_cls: 0.227  loss_box_reg: 0.376  loss_rpn_cls: 0.023  loss_rpn_loc: 0.061  time: 0.5227  data_time: 0.0051  lr: 0.003596  max_mem: 3094M
[32m[04/20 01:59:08 d2.utils.events]: [0m eta: 0:02:16  iter: 739  total_loss: 0.761  loss_cls: 0.262  loss_box_reg: 0.403  loss_rpn_cls: 0.023  loss_rpn_loc: 0.051  time: 0.5226  data_time: 0.0050  lr: 0.003696  max_mem: 3094M
[32m[04/20 01:59:19 d2.utils.events]: [0m eta: 0:02:06  iter: 759  total_loss: 0.642  loss_cls: 0.207  loss_box_reg: 0.352  loss_rpn_cls: 0.023  loss_rpn_loc: 0.052  time: 0.5231  data_time: 0.0050  lr: 0.003796  max_mem: 3094M
[32m[04/20 01:59:29 d2.utils.events]: [0m eta: 0:01:55  iter: 779  total_loss: 0.757  loss_cls: 0.250  loss_box_reg: 0.387  loss_rpn_cls: 0.036  loss_rpn_loc: 0.091  time: 0.5227  data_time: 0.0050  lr: 0.003896  max_mem: 3094M
[32m[04/20 01:59:40 d2.utils.events]: [0m eta: 0:01:45  iter: 799  total_loss: 0.735  loss_cls: 0.267  loss_box_reg: 0.407  loss_rpn_cls: 0.028  loss_rpn_loc: 0.071  time: 0.5226  data_time: 0.0049  lr: 0.003996  max_mem: 3094M
[32m[04/20 01:59:50 d2.utils.events]: [0m eta: 0:01:34  iter: 819  total_loss: 0.738  loss_cls: 0.265  loss_box_reg: 0.399  loss_rpn_cls: 0.023  loss_rpn_loc: 0.057  time: 0.5229  data_time: 0.0048  lr: 0.004096  max_mem: 3094M
[32m[04/20 02:00:01 d2.utils.events]: [0m eta: 0:01:24  iter: 839  total_loss: 0.763  loss_cls: 0.246  loss_box_reg: 0.379  loss_rpn_cls: 0.034  loss_rpn_loc: 0.081  time: 0.5231  data_time: 0.0053  lr: 0.004196  max_mem: 3094M
[32m[04/20 02:00:12 d2.utils.events]: [0m eta: 0:01:13  iter: 859  total_loss: 0.756  loss_cls: 0.255  loss_box_reg: 0.377  loss_rpn_cls: 0.031  loss_rpn_loc: 0.083  time: 0.5233  data_time: 0.0050  lr: 0.004296  max_mem: 3094M
[32m[04/20 02:00:22 d2.utils.events]: [0m eta: 0:01:03  iter: 879  total_loss: 0.658  loss_cls: 0.230  loss_box_reg: 0.323  loss_rpn_cls: 0.028  loss_rpn_loc: 0.051  time: 0.5231  data_time: 0.0049  lr: 0.004396  max_mem: 3094M
[32m[04/20 02:00:33 d2.utils.events]: [0m eta: 0:00:52  iter: 899  total_loss: 0.896  loss_cls: 0.297  loss_box_reg: 0.452  loss_rpn_cls: 0.028  loss_rpn_loc: 0.086  time: 0.5233  data_time: 0.0052  lr: 0.004496  max_mem: 3094M
[32m[04/20 02:00:44 d2.utils.events]: [0m eta: 0:00:42  iter: 919  total_loss: 0.692  loss_cls: 0.225  loss_box_reg: 0.380  loss_rpn_cls: 0.027  loss_rpn_loc: 0.079  time: 0.5237  data_time: 0.0053  lr: 0.004595  max_mem: 3094M
[32m[04/20 02:00:54 d2.utils.events]: [0m eta: 0:00:32  iter: 939  total_loss: 0.830  loss_cls: 0.260  loss_box_reg: 0.416  loss_rpn_cls: 0.026  loss_rpn_loc: 0.080  time: 0.5235  data_time: 0.0051  lr: 0.004695  max_mem: 3094M
[32m[04/20 02:01:04 d2.utils.events]: [0m eta: 0:00:21  iter: 959  total_loss: 0.831  loss_cls: 0.267  loss_box_reg: 0.412  loss_rpn_cls: 0.038  loss_rpn_loc: 0.079  time: 0.5233  data_time: 0.0050  lr: 0.004795  max_mem: 3094M
[32m[04/20 02:01:15 d2.utils.events]: [0m eta: 0:00:11  iter: 979  total_loss: 0.707  loss_cls: 0.237  loss_box_reg: 0.347  loss_rpn_cls: 0.030  loss_rpn_loc: 0.079  time: 0.5232  data_time: 0.0050  lr: 0.004895  max_mem: 3094M
[5m[31mWARNING[0m [32m[04/20 02:01:39 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 02:01:39 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[5m[31mWARNING[0m [32m[04/20 02:01:39 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 02:01:39 d2.utils.events]: [0m eta: 0:00:00  iter: 999  total_loss: 0.753  loss_cls: 0.252  loss_box_reg: 0.367  loss_rpn_cls: 0.033  loss_rpn_loc: 0.062  time: 0.5228  data_time: 0.0052  lr: 0.004995  max_mem: 3094M
[32m[04/20 02:01:39 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:08:41 (0.5233 s / it)
[32m[04/20 02:01:39 d2.engine.hooks]: [0mTotal training time: 0:08:58 (0:00:16 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 02:01:45 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 02:01:45 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/20 02:01:45 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 02:01:47 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1186 s / img. ETA=0:16:46
[32m[04/20 02:01:52 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1180 s / img. ETA=0:16:38
[32m[04/20 02:01:57 d2.evaluation.evaluator]: [0mInference done 95/8355. 0.1177 s / img. ETA=0:16:32
[32m[04/20 02:02:02 d2.evaluation.evaluator]: [0mInference done 137/8355. 0.1177 s / img. ETA=0:16:27
[32m[04/20 02:02:07 d2.evaluation.evaluator]: [0mInference done 179/8355. 0.1177 s / img. ETA=0:16:22
[32m[04/20 02:02:12 d2.evaluation.evaluator]: [0mInference done 221/8355. 0.1177 s / img. ETA=0:16:17
[32m[04/20 02:02:17 d2.evaluation.evaluator]: [0mInference done 263/8355. 0.1176 s / img. ETA=0:16:11
[32m[04/20 02:02:22 d2.evaluation.evaluator]: [0mInference done 305/8355. 0.1176 s / img. ETA=0:16:06
[32m[04/20 02:02:27 d2.evaluation.evaluator]: [0mInference done 347/8355. 0.1176 s / img. ETA=0:16:01
[32m[04/20 02:02:32 d2.evaluation.evaluator]: [0mInference done 389/8355. 0.1176 s / img. ETA=0:15:56
[32m[04/20 02:02:37 d2.evaluation.evaluator]: [0mInference done 431/8355. 0.1177 s / img. ETA=0:15:52
[32m[04/20 02:02:42 d2.evaluation.evaluator]: [0mInference done 473/8355. 0.1176 s / img. ETA=0:15:46
[32m[04/20 02:02:47 d2.evaluation.evaluator]: [0mInference done 515/8355. 0.1176 s / img. ETA=0:15:41
[32m[04/20 02:02:52 d2.evaluation.evaluator]: [0mInference done 557/8355. 0.1176 s / img. ETA=0:15:36
[32m[04/20 02:02:57 d2.evaluation.evaluator]: [0mInference done 599/8355. 0.1176 s / img. ETA=0:15:31
[32m[04/20 02:03:02 d2.evaluation.evaluator]: [0mInference done 641/8355. 0.1176 s / img. ETA=0:15:26
[32m[04/20 02:03:07 d2.evaluation.evaluator]: [0mInference done 683/8355. 0.1177 s / img. ETA=0:15:21
[32m[04/20 02:03:12 d2.evaluation.evaluator]: [0mInference done 725/8355. 0.1177 s / img. ETA=0:15:16
[32m[04/20 02:03:17 d2.evaluation.evaluator]: [0mInference done 767/8355. 0.1176 s / img. ETA=0:15:11
[32m[04/20 02:03:23 d2.evaluation.evaluator]: [0mInference done 809/8355. 0.1177 s / img. ETA=0:15:06
[32m[04/20 02:03:28 d2.evaluation.evaluator]: [0mInference done 851/8355. 0.1177 s / img. ETA=0:15:01
[32m[04/20 02:03:33 d2.evaluation.evaluator]: [0mInference done 893/8355. 0.1177 s / img. ETA=0:14:56
[32m[04/20 02:03:38 d2.evaluation.evaluator]: [0mInference done 935/8355. 0.1177 s / img. ETA=0:14:51
[32m[04/20 02:03:43 d2.evaluation.evaluator]: [0mInference done 977/8355. 0.1177 s / img. ETA=0:14:46
[32m[04/20 02:03:48 d2.evaluation.evaluator]: [0mInference done 1019/8355. 0.1177 s / img. ETA=0:14:41
[32m[04/20 02:03:53 d2.evaluation.evaluator]: [0mInference done 1061/8355. 0.1177 s / img. ETA=0:14:36
[32m[04/20 02:03:58 d2.evaluation.evaluator]: [0mInference done 1103/8355. 0.1176 s / img. ETA=0:14:31
[32m[04/20 02:04:03 d2.evaluation.evaluator]: [0mInference done 1145/8355. 0.1176 s / img. ETA=0:14:26
[32m[04/20 02:04:08 d2.evaluation.evaluator]: [0mInference done 1187/8355. 0.1176 s / img. ETA=0:14:21
[32m[04/20 02:04:13 d2.evaluation.evaluator]: [0mInference done 1229/8355. 0.1177 s / img. ETA=0:14:16
[32m[04/20 02:04:18 d2.evaluation.evaluator]: [0mInference done 1271/8355. 0.1177 s / img. ETA=0:14:11
[32m[04/20 02:04:23 d2.evaluation.evaluator]: [0mInference done 1313/8355. 0.1177 s / img. ETA=0:14:06
[32m[04/20 02:04:28 d2.evaluation.evaluator]: [0mInference done 1355/8355. 0.1177 s / img. ETA=0:14:01
[32m[04/20 02:04:33 d2.evaluation.evaluator]: [0mInference done 1397/8355. 0.1176 s / img. ETA=0:13:55
[32m[04/20 02:04:38 d2.evaluation.evaluator]: [0mInference done 1439/8355. 0.1176 s / img. ETA=0:13:50
[32m[04/20 02:04:43 d2.evaluation.evaluator]: [0mInference done 1481/8355. 0.1176 s / img. ETA=0:13:45
[32m[04/20 02:04:48 d2.evaluation.evaluator]: [0mInference done 1523/8355. 0.1176 s / img. ETA=0:13:40
[32m[04/20 02:04:53 d2.evaluation.evaluator]: [0mInference done 1565/8355. 0.1177 s / img. ETA=0:13:36
[32m[04/20 02:04:59 d2.evaluation.evaluator]: [0mInference done 1607/8355. 0.1177 s / img. ETA=0:13:31
[32m[04/20 02:05:04 d2.evaluation.evaluator]: [0mInference done 1649/8355. 0.1177 s / img. ETA=0:13:26
[32m[04/20 02:05:09 d2.evaluation.evaluator]: [0mInference done 1691/8355. 0.1177 s / img. ETA=0:13:21
[32m[04/20 02:05:14 d2.evaluation.evaluator]: [0mInference done 1733/8355. 0.1177 s / img. ETA=0:13:16
[32m[04/20 02:05:19 d2.evaluation.evaluator]: [0mInference done 1775/8355. 0.1178 s / img. ETA=0:13:11
[32m[04/20 02:05:24 d2.evaluation.evaluator]: [0mInference done 1817/8355. 0.1178 s / img. ETA=0:13:06
[32m[04/20 02:05:29 d2.evaluation.evaluator]: [0mInference done 1859/8355. 0.1178 s / img. ETA=0:13:01
[32m[04/20 02:05:34 d2.evaluation.evaluator]: [0mInference done 1901/8355. 0.1178 s / img. ETA=0:12:56
[32m[04/20 02:05:39 d2.evaluation.evaluator]: [0mInference done 1943/8355. 0.1178 s / img. ETA=0:12:51
[32m[04/20 02:05:44 d2.evaluation.evaluator]: [0mInference done 1985/8355. 0.1178 s / img. ETA=0:12:46
[32m[04/20 02:05:49 d2.evaluation.evaluator]: [0mInference done 2027/8355. 0.1178 s / img. ETA=0:12:41
[32m[04/20 02:05:54 d2.evaluation.evaluator]: [0mInference done 2069/8355. 0.1178 s / img. ETA=0:12:36
[32m[04/20 02:05:59 d2.evaluation.evaluator]: [0mInference done 2111/8355. 0.1178 s / img. ETA=0:12:31
[32m[04/20 02:06:04 d2.evaluation.evaluator]: [0mInference done 2153/8355. 0.1178 s / img. ETA=0:12:26
[32m[04/20 02:06:09 d2.evaluation.evaluator]: [0mInference done 2195/8355. 0.1178 s / img. ETA=0:12:21
[32m[04/20 02:06:15 d2.evaluation.evaluator]: [0mInference done 2237/8355. 0.1178 s / img. ETA=0:12:16
[32m[04/20 02:06:20 d2.evaluation.evaluator]: [0mInference done 2279/8355. 0.1178 s / img. ETA=0:12:11
[32m[04/20 02:06:25 d2.evaluation.evaluator]: [0mInference done 2321/8355. 0.1178 s / img. ETA=0:12:06
[32m[04/20 02:06:30 d2.evaluation.evaluator]: [0mInference done 2363/8355. 0.1179 s / img. ETA=0:12:01
[32m[04/20 02:06:35 d2.evaluation.evaluator]: [0mInference done 2405/8355. 0.1179 s / img. ETA=0:11:56
[32m[04/20 02:06:40 d2.evaluation.evaluator]: [0mInference done 2447/8355. 0.1179 s / img. ETA=0:11:51
[32m[04/20 02:06:45 d2.evaluation.evaluator]: [0mInference done 2489/8355. 0.1179 s / img. ETA=0:11:46
[32m[04/20 02:06:50 d2.evaluation.evaluator]: [0mInference done 2531/8355. 0.1179 s / img. ETA=0:11:41
[32m[04/20 02:06:55 d2.evaluation.evaluator]: [0mInference done 2573/8355. 0.1179 s / img. ETA=0:11:36
[32m[04/20 02:07:00 d2.evaluation.evaluator]: [0mInference done 2615/8355. 0.1179 s / img. ETA=0:11:31
[32m[04/20 02:07:05 d2.evaluation.evaluator]: [0mInference done 2656/8355. 0.1179 s / img. ETA=0:11:26
[32m[04/20 02:07:10 d2.evaluation.evaluator]: [0mInference done 2698/8355. 0.1179 s / img. ETA=0:11:21
[32m[04/20 02:07:15 d2.evaluation.evaluator]: [0mInference done 2740/8355. 0.1179 s / img. ETA=0:11:16
[32m[04/20 02:07:20 d2.evaluation.evaluator]: [0mInference done 2780/8355. 0.1180 s / img. ETA=0:11:11
[32m[04/20 02:07:26 d2.evaluation.evaluator]: [0mInference done 2822/8355. 0.1180 s / img. ETA=0:11:06
[32m[04/20 02:07:31 d2.evaluation.evaluator]: [0mInference done 2864/8355. 0.1180 s / img. ETA=0:11:01
[32m[04/20 02:07:36 d2.evaluation.evaluator]: [0mInference done 2906/8355. 0.1180 s / img. ETA=0:10:56
[32m[04/20 02:07:41 d2.evaluation.evaluator]: [0mInference done 2948/8355. 0.1180 s / img. ETA=0:10:51
[32m[04/20 02:07:46 d2.evaluation.evaluator]: [0mInference done 2990/8355. 0.1180 s / img. ETA=0:10:46
[32m[04/20 02:07:51 d2.evaluation.evaluator]: [0mInference done 3032/8355. 0.1180 s / img. ETA=0:10:41
[32m[04/20 02:07:56 d2.evaluation.evaluator]: [0mInference done 3074/8355. 0.1180 s / img. ETA=0:10:36
[32m[04/20 02:08:01 d2.evaluation.evaluator]: [0mInference done 3116/8355. 0.1180 s / img. ETA=0:10:31
[32m[04/20 02:08:06 d2.evaluation.evaluator]: [0mInference done 3158/8355. 0.1180 s / img. ETA=0:10:26
[32m[04/20 02:08:11 d2.evaluation.evaluator]: [0mInference done 3200/8355. 0.1180 s / img. ETA=0:10:21
[32m[04/20 02:08:16 d2.evaluation.evaluator]: [0mInference done 3242/8355. 0.1180 s / img. ETA=0:10:16
[32m[04/20 02:08:21 d2.evaluation.evaluator]: [0mInference done 3284/8355. 0.1180 s / img. ETA=0:10:11
[32m[04/20 02:08:26 d2.evaluation.evaluator]: [0mInference done 3326/8355. 0.1180 s / img. ETA=0:10:06
[32m[04/20 02:08:31 d2.evaluation.evaluator]: [0mInference done 3368/8355. 0.1180 s / img. ETA=0:10:00
[32m[04/20 02:08:36 d2.evaluation.evaluator]: [0mInference done 3410/8355. 0.1180 s / img. ETA=0:09:55
[32m[04/20 02:08:41 d2.evaluation.evaluator]: [0mInference done 3452/8355. 0.1180 s / img. ETA=0:09:50
[32m[04/20 02:08:46 d2.evaluation.evaluator]: [0mInference done 3494/8355. 0.1180 s / img. ETA=0:09:45
[32m[04/20 02:08:51 d2.evaluation.evaluator]: [0mInference done 3536/8355. 0.1180 s / img. ETA=0:09:40
[32m[04/20 02:08:56 d2.evaluation.evaluator]: [0mInference done 3578/8355. 0.1180 s / img. ETA=0:09:35
[32m[04/20 02:09:02 d2.evaluation.evaluator]: [0mInference done 3620/8355. 0.1180 s / img. ETA=0:09:30
[32m[04/20 02:09:07 d2.evaluation.evaluator]: [0mInference done 3662/8355. 0.1180 s / img. ETA=0:09:25
[32m[04/20 02:09:12 d2.evaluation.evaluator]: [0mInference done 3704/8355. 0.1180 s / img. ETA=0:09:20
[32m[04/20 02:09:17 d2.evaluation.evaluator]: [0mInference done 3746/8355. 0.1180 s / img. ETA=0:09:15
[32m[04/20 02:09:22 d2.evaluation.evaluator]: [0mInference done 3788/8355. 0.1180 s / img. ETA=0:09:10
[32m[04/20 02:09:27 d2.evaluation.evaluator]: [0mInference done 3830/8355. 0.1180 s / img. ETA=0:09:05
[32m[04/20 02:09:32 d2.evaluation.evaluator]: [0mInference done 3872/8355. 0.1180 s / img. ETA=0:09:00
[32m[04/20 02:09:37 d2.evaluation.evaluator]: [0mInference done 3914/8355. 0.1180 s / img. ETA=0:08:55
[32m[04/20 02:09:42 d2.evaluation.evaluator]: [0mInference done 3956/8355. 0.1180 s / img. ETA=0:08:49
[32m[04/20 02:09:47 d2.evaluation.evaluator]: [0mInference done 3998/8355. 0.1179 s / img. ETA=0:08:44
[32m[04/20 02:09:52 d2.evaluation.evaluator]: [0mInference done 4040/8355. 0.1179 s / img. ETA=0:08:39
[32m[04/20 02:09:57 d2.evaluation.evaluator]: [0mInference done 4082/8355. 0.1179 s / img. ETA=0:08:34
[32m[04/20 02:10:02 d2.evaluation.evaluator]: [0mInference done 4124/8355. 0.1179 s / img. ETA=0:08:29
[32m[04/20 02:10:07 d2.evaluation.evaluator]: [0mInference done 4166/8355. 0.1179 s / img. ETA=0:08:24
[32m[04/20 02:10:12 d2.evaluation.evaluator]: [0mInference done 4208/8355. 0.1179 s / img. ETA=0:08:19
[32m[04/20 02:10:17 d2.evaluation.evaluator]: [0mInference done 4250/8355. 0.1179 s / img. ETA=0:08:14
[32m[04/20 02:10:22 d2.evaluation.evaluator]: [0mInference done 4292/8355. 0.1179 s / img. ETA=0:08:09
[32m[04/20 02:10:27 d2.evaluation.evaluator]: [0mInference done 4334/8355. 0.1179 s / img. ETA=0:08:04
[32m[04/20 02:10:32 d2.evaluation.evaluator]: [0mInference done 4376/8355. 0.1179 s / img. ETA=0:07:59
[32m[04/20 02:10:37 d2.evaluation.evaluator]: [0mInference done 4418/8355. 0.1179 s / img. ETA=0:07:54
[32m[04/20 02:10:43 d2.evaluation.evaluator]: [0mInference done 4460/8355. 0.1179 s / img. ETA=0:07:49
[32m[04/20 02:10:48 d2.evaluation.evaluator]: [0mInference done 4502/8355. 0.1179 s / img. ETA=0:07:44
[32m[04/20 02:10:53 d2.evaluation.evaluator]: [0mInference done 4544/8355. 0.1179 s / img. ETA=0:07:39
[32m[04/20 02:10:58 d2.evaluation.evaluator]: [0mInference done 4586/8355. 0.1180 s / img. ETA=0:07:34
[32m[04/20 02:11:03 d2.evaluation.evaluator]: [0mInference done 4628/8355. 0.1180 s / img. ETA=0:07:29
[32m[04/20 02:11:08 d2.evaluation.evaluator]: [0mInference done 4670/8355. 0.1180 s / img. ETA=0:07:23
[32m[04/20 02:11:13 d2.evaluation.evaluator]: [0mInference done 4712/8355. 0.1180 s / img. ETA=0:07:18
[32m[04/20 02:11:18 d2.evaluation.evaluator]: [0mInference done 4754/8355. 0.1180 s / img. ETA=0:07:13
[32m[04/20 02:11:23 d2.evaluation.evaluator]: [0mInference done 4796/8355. 0.1180 s / img. ETA=0:07:08
[32m[04/20 02:11:28 d2.evaluation.evaluator]: [0mInference done 4838/8355. 0.1180 s / img. ETA=0:07:03
[32m[04/20 02:11:33 d2.evaluation.evaluator]: [0mInference done 4880/8355. 0.1180 s / img. ETA=0:06:58
[32m[04/20 02:11:38 d2.evaluation.evaluator]: [0mInference done 4922/8355. 0.1180 s / img. ETA=0:06:53
[32m[04/20 02:11:44 d2.evaluation.evaluator]: [0mInference done 4964/8355. 0.1180 s / img. ETA=0:06:48
[32m[04/20 02:11:49 d2.evaluation.evaluator]: [0mInference done 5006/8355. 0.1180 s / img. ETA=0:06:43
[32m[04/20 02:11:54 d2.evaluation.evaluator]: [0mInference done 5048/8355. 0.1180 s / img. ETA=0:06:38
[32m[04/20 02:11:59 d2.evaluation.evaluator]: [0mInference done 5090/8355. 0.1180 s / img. ETA=0:06:33
[32m[04/20 02:12:04 d2.evaluation.evaluator]: [0mInference done 5132/8355. 0.1180 s / img. ETA=0:06:28
[32m[04/20 02:12:09 d2.evaluation.evaluator]: [0mInference done 5174/8355. 0.1180 s / img. ETA=0:06:23
[32m[04/20 02:12:14 d2.evaluation.evaluator]: [0mInference done 5216/8355. 0.1180 s / img. ETA=0:06:18
[32m[04/20 02:12:19 d2.evaluation.evaluator]: [0mInference done 5257/8355. 0.1180 s / img. ETA=0:06:13
[32m[04/20 02:12:24 d2.evaluation.evaluator]: [0mInference done 5299/8355. 0.1180 s / img. ETA=0:06:08
[32m[04/20 02:12:29 d2.evaluation.evaluator]: [0mInference done 5341/8355. 0.1180 s / img. ETA=0:06:03
[32m[04/20 02:12:34 d2.evaluation.evaluator]: [0mInference done 5382/8355. 0.1181 s / img. ETA=0:05:58
[32m[04/20 02:12:40 d2.evaluation.evaluator]: [0mInference done 5424/8355. 0.1181 s / img. ETA=0:05:53
[32m[04/20 02:12:45 d2.evaluation.evaluator]: [0mInference done 5466/8355. 0.1181 s / img. ETA=0:05:48
[32m[04/20 02:12:50 d2.evaluation.evaluator]: [0mInference done 5508/8355. 0.1181 s / img. ETA=0:05:43
[32m[04/20 02:12:55 d2.evaluation.evaluator]: [0mInference done 5550/8355. 0.1181 s / img. ETA=0:05:38
[32m[04/20 02:13:00 d2.evaluation.evaluator]: [0mInference done 5592/8355. 0.1181 s / img. ETA=0:05:33
[32m[04/20 02:13:05 d2.evaluation.evaluator]: [0mInference done 5634/8355. 0.1181 s / img. ETA=0:05:28
[32m[04/20 02:13:10 d2.evaluation.evaluator]: [0mInference done 5675/8355. 0.1181 s / img. ETA=0:05:23
[32m[04/20 02:13:15 d2.evaluation.evaluator]: [0mInference done 5717/8355. 0.1181 s / img. ETA=0:05:18
[32m[04/20 02:13:20 d2.evaluation.evaluator]: [0mInference done 5759/8355. 0.1181 s / img. ETA=0:05:13
[32m[04/20 02:13:25 d2.evaluation.evaluator]: [0mInference done 5801/8355. 0.1181 s / img. ETA=0:05:08
[32m[04/20 02:13:30 d2.evaluation.evaluator]: [0mInference done 5843/8355. 0.1181 s / img. ETA=0:05:03
[32m[04/20 02:13:35 d2.evaluation.evaluator]: [0mInference done 5884/8355. 0.1181 s / img. ETA=0:04:58
[32m[04/20 02:13:40 d2.evaluation.evaluator]: [0mInference done 5926/8355. 0.1181 s / img. ETA=0:04:53
[32m[04/20 02:13:46 d2.evaluation.evaluator]: [0mInference done 5968/8355. 0.1181 s / img. ETA=0:04:48
[32m[04/20 02:13:51 d2.evaluation.evaluator]: [0mInference done 6010/8355. 0.1181 s / img. ETA=0:04:43
[32m[04/20 02:13:56 d2.evaluation.evaluator]: [0mInference done 6052/8355. 0.1182 s / img. ETA=0:04:37
[32m[04/20 02:14:01 d2.evaluation.evaluator]: [0mInference done 6093/8355. 0.1182 s / img. ETA=0:04:33
[32m[04/20 02:14:06 d2.evaluation.evaluator]: [0mInference done 6135/8355. 0.1182 s / img. ETA=0:04:27
[32m[04/20 02:14:11 d2.evaluation.evaluator]: [0mInference done 6177/8355. 0.1182 s / img. ETA=0:04:22
[32m[04/20 02:14:16 d2.evaluation.evaluator]: [0mInference done 6219/8355. 0.1182 s / img. ETA=0:04:17
[32m[04/20 02:14:21 d2.evaluation.evaluator]: [0mInference done 6260/8355. 0.1182 s / img. ETA=0:04:12
[32m[04/20 02:14:26 d2.evaluation.evaluator]: [0mInference done 6301/8355. 0.1182 s / img. ETA=0:04:07
[32m[04/20 02:14:31 d2.evaluation.evaluator]: [0mInference done 6343/8355. 0.1182 s / img. ETA=0:04:02
[32m[04/20 02:14:36 d2.evaluation.evaluator]: [0mInference done 6385/8355. 0.1182 s / img. ETA=0:03:57
[32m[04/20 02:14:41 d2.evaluation.evaluator]: [0mInference done 6427/8355. 0.1182 s / img. ETA=0:03:52
[32m[04/20 02:14:46 d2.evaluation.evaluator]: [0mInference done 6469/8355. 0.1182 s / img. ETA=0:03:47
[32m[04/20 02:14:52 d2.evaluation.evaluator]: [0mInference done 6511/8355. 0.1182 s / img. ETA=0:03:42
[32m[04/20 02:14:57 d2.evaluation.evaluator]: [0mInference done 6553/8355. 0.1182 s / img. ETA=0:03:37
[32m[04/20 02:15:02 d2.evaluation.evaluator]: [0mInference done 6595/8355. 0.1182 s / img. ETA=0:03:32
[32m[04/20 02:15:07 d2.evaluation.evaluator]: [0mInference done 6637/8355. 0.1182 s / img. ETA=0:03:27
[32m[04/20 02:15:12 d2.evaluation.evaluator]: [0mInference done 6679/8355. 0.1182 s / img. ETA=0:03:22
[32m[04/20 02:15:17 d2.evaluation.evaluator]: [0mInference done 6721/8355. 0.1182 s / img. ETA=0:03:17
[32m[04/20 02:15:22 d2.evaluation.evaluator]: [0mInference done 6763/8355. 0.1182 s / img. ETA=0:03:12
[32m[04/20 02:15:27 d2.evaluation.evaluator]: [0mInference done 6805/8355. 0.1182 s / img. ETA=0:03:07
[32m[04/20 02:15:32 d2.evaluation.evaluator]: [0mInference done 6847/8355. 0.1182 s / img. ETA=0:03:02
[32m[04/20 02:15:37 d2.evaluation.evaluator]: [0mInference done 6889/8355. 0.1182 s / img. ETA=0:02:57
[32m[04/20 02:15:42 d2.evaluation.evaluator]: [0mInference done 6931/8355. 0.1182 s / img. ETA=0:02:51
[32m[04/20 02:15:47 d2.evaluation.evaluator]: [0mInference done 6972/8355. 0.1182 s / img. ETA=0:02:47
[32m[04/20 02:15:52 d2.evaluation.evaluator]: [0mInference done 7013/8355. 0.1182 s / img. ETA=0:02:42
[32m[04/20 02:15:57 d2.evaluation.evaluator]: [0mInference done 7055/8355. 0.1182 s / img. ETA=0:02:37
[32m[04/20 02:16:02 d2.evaluation.evaluator]: [0mInference done 7096/8355. 0.1182 s / img. ETA=0:02:32
[32m[04/20 02:16:08 d2.evaluation.evaluator]: [0mInference done 7138/8355. 0.1183 s / img. ETA=0:02:27
[32m[04/20 02:16:13 d2.evaluation.evaluator]: [0mInference done 7180/8355. 0.1183 s / img. ETA=0:02:21
[32m[04/20 02:16:18 d2.evaluation.evaluator]: [0mInference done 7221/8355. 0.1183 s / img. ETA=0:02:17
[32m[04/20 02:16:23 d2.evaluation.evaluator]: [0mInference done 7263/8355. 0.1183 s / img. ETA=0:02:11
[32m[04/20 02:16:28 d2.evaluation.evaluator]: [0mInference done 7304/8355. 0.1183 s / img. ETA=0:02:07
[32m[04/20 02:16:33 d2.evaluation.evaluator]: [0mInference done 7345/8355. 0.1183 s / img. ETA=0:02:02
[32m[04/20 02:16:38 d2.evaluation.evaluator]: [0mInference done 7386/8355. 0.1183 s / img. ETA=0:01:57
[32m[04/20 02:16:43 d2.evaluation.evaluator]: [0mInference done 7427/8355. 0.1183 s / img. ETA=0:01:52
[32m[04/20 02:16:48 d2.evaluation.evaluator]: [0mInference done 7468/8355. 0.1183 s / img. ETA=0:01:47
[32m[04/20 02:16:53 d2.evaluation.evaluator]: [0mInference done 7510/8355. 0.1183 s / img. ETA=0:01:42
[32m[04/20 02:16:58 d2.evaluation.evaluator]: [0mInference done 7552/8355. 0.1183 s / img. ETA=0:01:37
[32m[04/20 02:17:03 d2.evaluation.evaluator]: [0mInference done 7594/8355. 0.1183 s / img. ETA=0:01:31
[32m[04/20 02:17:08 d2.evaluation.evaluator]: [0mInference done 7636/8355. 0.1183 s / img. ETA=0:01:26
[32m[04/20 02:17:13 d2.evaluation.evaluator]: [0mInference done 7677/8355. 0.1183 s / img. ETA=0:01:21
[32m[04/20 02:17:19 d2.evaluation.evaluator]: [0mInference done 7719/8355. 0.1183 s / img. ETA=0:01:16
[32m[04/20 02:17:24 d2.evaluation.evaluator]: [0mInference done 7760/8355. 0.1183 s / img. ETA=0:01:11
[32m[04/20 02:17:29 d2.evaluation.evaluator]: [0mInference done 7801/8355. 0.1184 s / img. ETA=0:01:06
[32m[04/20 02:17:34 d2.evaluation.evaluator]: [0mInference done 7843/8355. 0.1184 s / img. ETA=0:01:01
[32m[04/20 02:17:39 d2.evaluation.evaluator]: [0mInference done 7884/8355. 0.1184 s / img. ETA=0:00:56
[32m[04/20 02:17:44 d2.evaluation.evaluator]: [0mInference done 7926/8355. 0.1184 s / img. ETA=0:00:51
[32m[04/20 02:17:49 d2.evaluation.evaluator]: [0mInference done 7968/8355. 0.1184 s / img. ETA=0:00:46
[32m[04/20 02:17:54 d2.evaluation.evaluator]: [0mInference done 8009/8355. 0.1184 s / img. ETA=0:00:41
[32m[04/20 02:17:59 d2.evaluation.evaluator]: [0mInference done 8051/8355. 0.1184 s / img. ETA=0:00:36
[32m[04/20 02:18:04 d2.evaluation.evaluator]: [0mInference done 8093/8355. 0.1184 s / img. ETA=0:00:31
[32m[04/20 02:18:09 d2.evaluation.evaluator]: [0mInference done 8135/8355. 0.1184 s / img. ETA=0:00:26
[32m[04/20 02:18:14 d2.evaluation.evaluator]: [0mInference done 8177/8355. 0.1184 s / img. ETA=0:00:21
[32m[04/20 02:18:19 d2.evaluation.evaluator]: [0mInference done 8219/8355. 0.1184 s / img. ETA=0:00:16
[32m[04/20 02:18:24 d2.evaluation.evaluator]: [0mInference done 8261/8355. 0.1184 s / img. ETA=0:00:11
[32m[04/20 02:18:29 d2.evaluation.evaluator]: [0mInference done 8303/8355. 0.1184 s / img. ETA=0:00:06
[32m[04/20 02:18:35 d2.evaluation.evaluator]: [0mInference done 8345/8355. 0.1184 s / img. ETA=0:00:01
[32m[04/20 02:18:36 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:49.935397 (0.120950 s / img per device, on 1 devices)
[32m[04/20 02:18:36 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:28 (0.118360 s / img per device, on 1 devices)
[32m[04/20 02:18:36 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 02:18:36 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 02:18:36 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.09s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=21.87s).
Accumulating evaluation results...
DONE (t=2.48s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.283
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.575
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.231
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.392
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.159
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.340
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.348
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.269
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.469
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.643
[32m[04/20 02:19:01 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 28.260 | 57.517 | 23.107 | 20.677 | 39.169 | 59.853 |
[32m[04/20 02:19:01 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 33.629 | bicycle       | 17.586 | car            | 40.483 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | 21.341 | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 02:19:02 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 02:19:02 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[32m[04/20 02:19:02 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 02:19:04 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1177 s / img. ETA=0:02:29
[32m[04/20 02:19:09 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1176 s / img. ETA=0:02:24
[32m[04/20 02:19:14 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1179 s / img. ETA=0:02:20
[32m[04/20 02:19:19 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1181 s / img. ETA=0:02:15
[32m[04/20 02:19:24 d2.evaluation.evaluator]: [0mInference done 179/1257. 0.1180 s / img. ETA=0:02:10
[32m[04/20 02:19:29 d2.evaluation.evaluator]: [0mInference done 221/1257. 0.1182 s / img. ETA=0:02:05
[32m[04/20 02:19:34 d2.evaluation.evaluator]: [0mInference done 263/1257. 0.1183 s / img. ETA=0:02:00
[32m[04/20 02:19:39 d2.evaluation.evaluator]: [0mInference done 305/1257. 0.1183 s / img. ETA=0:01:55
[32m[04/20 02:19:45 d2.evaluation.evaluator]: [0mInference done 347/1257. 0.1183 s / img. ETA=0:01:50
[32m[04/20 02:19:50 d2.evaluation.evaluator]: [0mInference done 389/1257. 0.1183 s / img. ETA=0:01:45
[32m[04/20 02:19:55 d2.evaluation.evaluator]: [0mInference done 431/1257. 0.1183 s / img. ETA=0:01:40
[32m[04/20 02:20:00 d2.evaluation.evaluator]: [0mInference done 473/1257. 0.1183 s / img. ETA=0:01:34
[32m[04/20 02:20:05 d2.evaluation.evaluator]: [0mInference done 515/1257. 0.1183 s / img. ETA=0:01:29
[32m[04/20 02:20:10 d2.evaluation.evaluator]: [0mInference done 557/1257. 0.1184 s / img. ETA=0:01:24
[32m[04/20 02:20:15 d2.evaluation.evaluator]: [0mInference done 599/1257. 0.1184 s / img. ETA=0:01:19
[32m[04/20 02:20:20 d2.evaluation.evaluator]: [0mInference done 641/1257. 0.1184 s / img. ETA=0:01:14
[32m[04/20 02:20:25 d2.evaluation.evaluator]: [0mInference done 682/1257. 0.1185 s / img. ETA=0:01:09
[32m[04/20 02:20:30 d2.evaluation.evaluator]: [0mInference done 723/1257. 0.1186 s / img. ETA=0:01:04
[32m[04/20 02:20:35 d2.evaluation.evaluator]: [0mInference done 764/1257. 0.1186 s / img. ETA=0:00:59
[32m[04/20 02:20:40 d2.evaluation.evaluator]: [0mInference done 805/1257. 0.1187 s / img. ETA=0:00:54
[32m[04/20 02:20:45 d2.evaluation.evaluator]: [0mInference done 846/1257. 0.1187 s / img. ETA=0:00:49
[32m[04/20 02:20:50 d2.evaluation.evaluator]: [0mInference done 887/1257. 0.1188 s / img. ETA=0:00:45
[32m[04/20 02:20:55 d2.evaluation.evaluator]: [0mInference done 928/1257. 0.1188 s / img. ETA=0:00:40
[32m[04/20 02:21:00 d2.evaluation.evaluator]: [0mInference done 969/1257. 0.1189 s / img. ETA=0:00:35
[32m[04/20 02:21:06 d2.evaluation.evaluator]: [0mInference done 1010/1257. 0.1190 s / img. ETA=0:00:30
[32m[04/20 02:21:11 d2.evaluation.evaluator]: [0mInference done 1051/1257. 0.1190 s / img. ETA=0:00:25
[32m[04/20 02:21:16 d2.evaluation.evaluator]: [0mInference done 1092/1257. 0.1190 s / img. ETA=0:00:20
[32m[04/20 02:21:21 d2.evaluation.evaluator]: [0mInference done 1133/1257. 0.1191 s / img. ETA=0:00:15
[32m[04/20 02:21:26 d2.evaluation.evaluator]: [0mInference done 1174/1257. 0.1191 s / img. ETA=0:00:10
[32m[04/20 02:21:31 d2.evaluation.evaluator]: [0mInference done 1215/1257. 0.1192 s / img. ETA=0:00:05
[32m[04/20 02:21:36 d2.evaluation.evaluator]: [0mInference done 1256/1257. 0.1192 s / img. ETA=0:00:00
[32m[04/20 02:21:36 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:32.969757 (0.122180 s / img per device, on 1 devices)
[32m[04/20 02:21:36 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:29 (0.119222 s / img per device, on 1 devices)
[32m[04/20 02:21:36 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 02:21:36 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 02:21:36 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.32s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.18s).
Accumulating evaluation results...
DONE (t=0.41s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.204
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.432
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.166
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.118
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.253
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.122
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.269
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.272
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498
[32m[04/20 02:21:40 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 20.394 | 43.226 | 16.562 | 11.834 | 25.322 | 42.990 |
[32m[04/20 02:21:40 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 27.691 | bicycle       | 10.002 | car            | 39.451 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | 4.433  | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  10  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 02:21:41 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 02:21:41 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 02:21:41 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/20 02:21:42 d2.data.build]: [0mRemoved 889 images with no usable annotations. 7466 images left.
[32m[04/20 02:21:42 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 02:21:42 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 02:21:42 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 02:21:52 d2.utils.events]: [0m eta: 0:08:04  iter: 19  total_loss: 0.736  loss_cls: 0.265  loss_box_reg: 0.363  loss_rpn_cls: 0.027  loss_rpn_loc: 0.085  time: 0.5041  data_time: 0.0157  lr: 0.000100  max_mem: 3094M
[32m[04/20 02:22:03 d2.utils.events]: [0m eta: 0:08:27  iter: 39  total_loss: 0.569  loss_cls: 0.186  loss_box_reg: 0.297  loss_rpn_cls: 0.018  loss_rpn_loc: 0.057  time: 0.5218  data_time: 0.0059  lr: 0.000200  max_mem: 3094M
[32m[04/20 02:22:14 d2.utils.events]: [0m eta: 0:08:12  iter: 59  total_loss: 0.810  loss_cls: 0.271  loss_box_reg: 0.415  loss_rpn_cls: 0.031  loss_rpn_loc: 0.080  time: 0.5208  data_time: 0.0054  lr: 0.000300  max_mem: 3094M
[32m[04/20 02:22:24 d2.utils.events]: [0m eta: 0:07:59  iter: 79  total_loss: 0.766  loss_cls: 0.236  loss_box_reg: 0.412  loss_rpn_cls: 0.028  loss_rpn_loc: 0.071  time: 0.5173  data_time: 0.0057  lr: 0.000400  max_mem: 3094M
[32m[04/20 02:22:35 d2.utils.events]: [0m eta: 0:07:49  iter: 99  total_loss: 0.535  loss_cls: 0.190  loss_box_reg: 0.276  loss_rpn_cls: 0.020  loss_rpn_loc: 0.049  time: 0.5202  data_time: 0.0054  lr: 0.000500  max_mem: 3094M
[32m[04/20 02:22:45 d2.utils.events]: [0m eta: 0:07:40  iter: 119  total_loss: 0.746  loss_cls: 0.236  loss_box_reg: 0.373  loss_rpn_cls: 0.027  loss_rpn_loc: 0.068  time: 0.5211  data_time: 0.0054  lr: 0.000599  max_mem: 3094M
[32m[04/20 02:22:56 d2.utils.events]: [0m eta: 0:07:29  iter: 139  total_loss: 0.615  loss_cls: 0.197  loss_box_reg: 0.340  loss_rpn_cls: 0.020  loss_rpn_loc: 0.067  time: 0.5216  data_time: 0.0055  lr: 0.000699  max_mem: 3094M
[32m[04/20 02:23:06 d2.utils.events]: [0m eta: 0:07:19  iter: 159  total_loss: 0.665  loss_cls: 0.225  loss_box_reg: 0.366  loss_rpn_cls: 0.030  loss_rpn_loc: 0.054  time: 0.5214  data_time: 0.0057  lr: 0.000799  max_mem: 3094M
[32m[04/20 02:23:17 d2.utils.events]: [0m eta: 0:07:11  iter: 179  total_loss: 0.770  loss_cls: 0.244  loss_box_reg: 0.433  loss_rpn_cls: 0.015  loss_rpn_loc: 0.054  time: 0.5233  data_time: 0.0119  lr: 0.000899  max_mem: 3094M
[32m[04/20 02:23:27 d2.utils.events]: [0m eta: 0:06:59  iter: 199  total_loss: 0.642  loss_cls: 0.197  loss_box_reg: 0.350  loss_rpn_cls: 0.017  loss_rpn_loc: 0.061  time: 0.5222  data_time: 0.0053  lr: 0.000999  max_mem: 3094M
[32m[04/20 02:23:38 d2.utils.events]: [0m eta: 0:06:50  iter: 219  total_loss: 0.765  loss_cls: 0.236  loss_box_reg: 0.423  loss_rpn_cls: 0.017  loss_rpn_loc: 0.069  time: 0.5241  data_time: 0.0058  lr: 0.001099  max_mem: 3094M
[32m[04/20 02:23:49 d2.utils.events]: [0m eta: 0:06:41  iter: 239  total_loss: 0.651  loss_cls: 0.209  loss_box_reg: 0.370  loss_rpn_cls: 0.019  loss_rpn_loc: 0.052  time: 0.5257  data_time: 0.0056  lr: 0.001199  max_mem: 3094M
[32m[04/20 02:24:00 d2.utils.events]: [0m eta: 0:06:31  iter: 259  total_loss: 0.815  loss_cls: 0.245  loss_box_reg: 0.451  loss_rpn_cls: 0.020  loss_rpn_loc: 0.078  time: 0.5266  data_time: 0.0061  lr: 0.001299  max_mem: 3094M
[32m[04/20 02:24:10 d2.utils.events]: [0m eta: 0:06:21  iter: 279  total_loss: 0.706  loss_cls: 0.215  loss_box_reg: 0.368  loss_rpn_cls: 0.020  loss_rpn_loc: 0.062  time: 0.5264  data_time: 0.0061  lr: 0.001399  max_mem: 3094M
[32m[04/20 02:24:21 d2.utils.events]: [0m eta: 0:06:10  iter: 299  total_loss: 0.649  loss_cls: 0.211  loss_box_reg: 0.337  loss_rpn_cls: 0.024  loss_rpn_loc: 0.048  time: 0.5266  data_time: 0.0059  lr: 0.001499  max_mem: 3094M
[32m[04/20 02:24:32 d2.utils.events]: [0m eta: 0:06:00  iter: 319  total_loss: 0.660  loss_cls: 0.233  loss_box_reg: 0.348  loss_rpn_cls: 0.018  loss_rpn_loc: 0.055  time: 0.5269  data_time: 0.0054  lr: 0.001598  max_mem: 3094M
[32m[04/20 02:24:43 d2.utils.events]: [0m eta: 0:05:50  iter: 339  total_loss: 0.674  loss_cls: 0.229  loss_box_reg: 0.374  loss_rpn_cls: 0.020  loss_rpn_loc: 0.043  time: 0.5274  data_time: 0.0059  lr: 0.001698  max_mem: 3094M
[32m[04/20 02:24:54 d2.utils.events]: [0m eta: 0:05:40  iter: 359  total_loss: 0.624  loss_cls: 0.228  loss_box_reg: 0.335  loss_rpn_cls: 0.020  loss_rpn_loc: 0.049  time: 0.5286  data_time: 0.0061  lr: 0.001798  max_mem: 3094M
[32m[04/20 02:25:04 d2.utils.events]: [0m eta: 0:05:29  iter: 379  total_loss: 0.553  loss_cls: 0.188  loss_box_reg: 0.287  loss_rpn_cls: 0.022  loss_rpn_loc: 0.035  time: 0.5292  data_time: 0.0064  lr: 0.001898  max_mem: 3094M
[32m[04/20 02:25:15 d2.utils.events]: [0m eta: 0:05:18  iter: 399  total_loss: 0.716  loss_cls: 0.230  loss_box_reg: 0.373  loss_rpn_cls: 0.024  loss_rpn_loc: 0.060  time: 0.5288  data_time: 0.0056  lr: 0.001998  max_mem: 3094M
[32m[04/20 02:25:26 d2.utils.events]: [0m eta: 0:05:08  iter: 419  total_loss: 0.662  loss_cls: 0.235  loss_box_reg: 0.359  loss_rpn_cls: 0.020  loss_rpn_loc: 0.060  time: 0.5290  data_time: 0.0060  lr: 0.002098  max_mem: 3094M
[32m[04/20 02:25:36 d2.utils.events]: [0m eta: 0:04:57  iter: 439  total_loss: 0.521  loss_cls: 0.180  loss_box_reg: 0.284  loss_rpn_cls: 0.021  loss_rpn_loc: 0.039  time: 0.5288  data_time: 0.0056  lr: 0.002198  max_mem: 3094M
[32m[04/20 02:25:47 d2.utils.events]: [0m eta: 0:04:47  iter: 459  total_loss: 0.723  loss_cls: 0.245  loss_box_reg: 0.409  loss_rpn_cls: 0.029  loss_rpn_loc: 0.061  time: 0.5295  data_time: 0.0063  lr: 0.002298  max_mem: 3094M
[32m[04/20 02:25:58 d2.utils.events]: [0m eta: 0:04:36  iter: 479  total_loss: 0.733  loss_cls: 0.248  loss_box_reg: 0.398  loss_rpn_cls: 0.025  loss_rpn_loc: 0.060  time: 0.5298  data_time: 0.0066  lr: 0.002398  max_mem: 3094M
[32m[04/20 02:26:09 d2.utils.events]: [0m eta: 0:04:26  iter: 499  total_loss: 0.801  loss_cls: 0.253  loss_box_reg: 0.399  loss_rpn_cls: 0.027  loss_rpn_loc: 0.097  time: 0.5298  data_time: 0.0060  lr: 0.002498  max_mem: 3094M
[32m[04/20 02:26:19 d2.utils.events]: [0m eta: 0:04:15  iter: 519  total_loss: 0.616  loss_cls: 0.197  loss_box_reg: 0.314  loss_rpn_cls: 0.024  loss_rpn_loc: 0.045  time: 0.5299  data_time: 0.0063  lr: 0.002597  max_mem: 3094M
[32m[04/20 02:26:30 d2.utils.events]: [0m eta: 0:04:04  iter: 539  total_loss: 0.710  loss_cls: 0.226  loss_box_reg: 0.350  loss_rpn_cls: 0.025  loss_rpn_loc: 0.061  time: 0.5296  data_time: 0.0057  lr: 0.002697  max_mem: 3094M
[32m[04/20 02:26:40 d2.utils.events]: [0m eta: 0:03:54  iter: 559  total_loss: 0.587  loss_cls: 0.206  loss_box_reg: 0.317  loss_rpn_cls: 0.022  loss_rpn_loc: 0.044  time: 0.5292  data_time: 0.0063  lr: 0.002797  max_mem: 3094M
[32m[04/20 02:26:51 d2.utils.events]: [0m eta: 0:03:43  iter: 579  total_loss: 0.673  loss_cls: 0.235  loss_box_reg: 0.358  loss_rpn_cls: 0.021  loss_rpn_loc: 0.064  time: 0.5293  data_time: 0.0060  lr: 0.002897  max_mem: 3094M
[32m[04/20 02:27:01 d2.utils.events]: [0m eta: 0:03:32  iter: 599  total_loss: 0.699  loss_cls: 0.221  loss_box_reg: 0.362  loss_rpn_cls: 0.020  loss_rpn_loc: 0.085  time: 0.5290  data_time: 0.0059  lr: 0.002997  max_mem: 3094M
[32m[04/20 02:27:12 d2.utils.events]: [0m eta: 0:03:22  iter: 619  total_loss: 0.526  loss_cls: 0.170  loss_box_reg: 0.295  loss_rpn_cls: 0.013  loss_rpn_loc: 0.042  time: 0.5290  data_time: 0.0063  lr: 0.003097  max_mem: 3094M
[32m[04/20 02:27:23 d2.utils.events]: [0m eta: 0:03:11  iter: 639  total_loss: 0.562  loss_cls: 0.191  loss_box_reg: 0.312  loss_rpn_cls: 0.015  loss_rpn_loc: 0.051  time: 0.5292  data_time: 0.0061  lr: 0.003197  max_mem: 3094M
[32m[04/20 02:27:33 d2.utils.events]: [0m eta: 0:03:00  iter: 659  total_loss: 0.626  loss_cls: 0.193  loss_box_reg: 0.350  loss_rpn_cls: 0.016  loss_rpn_loc: 0.065  time: 0.5288  data_time: 0.0063  lr: 0.003297  max_mem: 3094M
[32m[04/20 02:27:44 d2.utils.events]: [0m eta: 0:02:50  iter: 679  total_loss: 0.694  loss_cls: 0.225  loss_box_reg: 0.329  loss_rpn_cls: 0.028  loss_rpn_loc: 0.077  time: 0.5288  data_time: 0.0061  lr: 0.003397  max_mem: 3094M
[32m[04/20 02:27:55 d2.utils.events]: [0m eta: 0:02:39  iter: 699  total_loss: 0.655  loss_cls: 0.230  loss_box_reg: 0.340  loss_rpn_cls: 0.026  loss_rpn_loc: 0.050  time: 0.5291  data_time: 0.0063  lr: 0.003497  max_mem: 3094M
[32m[04/20 02:28:05 d2.utils.events]: [0m eta: 0:02:28  iter: 719  total_loss: 0.791  loss_cls: 0.243  loss_box_reg: 0.397  loss_rpn_cls: 0.026  loss_rpn_loc: 0.070  time: 0.5288  data_time: 0.0060  lr: 0.003596  max_mem: 3094M
[32m[04/20 02:28:16 d2.utils.events]: [0m eta: 0:02:18  iter: 739  total_loss: 0.701  loss_cls: 0.233  loss_box_reg: 0.376  loss_rpn_cls: 0.024  loss_rpn_loc: 0.064  time: 0.5291  data_time: 0.0060  lr: 0.003696  max_mem: 3094M
[32m[04/20 02:28:27 d2.utils.events]: [0m eta: 0:02:07  iter: 759  total_loss: 0.722  loss_cls: 0.241  loss_box_reg: 0.361  loss_rpn_cls: 0.022  loss_rpn_loc: 0.049  time: 0.5291  data_time: 0.0057  lr: 0.003796  max_mem: 3094M
[32m[04/20 02:28:37 d2.utils.events]: [0m eta: 0:01:57  iter: 779  total_loss: 0.639  loss_cls: 0.203  loss_box_reg: 0.334  loss_rpn_cls: 0.020  loss_rpn_loc: 0.051  time: 0.5290  data_time: 0.0062  lr: 0.003896  max_mem: 3094M
[32m[04/20 02:28:48 d2.utils.events]: [0m eta: 0:01:46  iter: 799  total_loss: 0.765  loss_cls: 0.240  loss_box_reg: 0.394  loss_rpn_cls: 0.029  loss_rpn_loc: 0.059  time: 0.5290  data_time: 0.0061  lr: 0.003996  max_mem: 3094M
[32m[04/20 02:28:58 d2.utils.events]: [0m eta: 0:01:35  iter: 819  total_loss: 0.806  loss_cls: 0.267  loss_box_reg: 0.447  loss_rpn_cls: 0.028  loss_rpn_loc: 0.076  time: 0.5291  data_time: 0.0066  lr: 0.004096  max_mem: 3094M
[32m[04/20 02:29:09 d2.utils.events]: [0m eta: 0:01:25  iter: 839  total_loss: 0.603  loss_cls: 0.215  loss_box_reg: 0.313  loss_rpn_cls: 0.019  loss_rpn_loc: 0.053  time: 0.5287  data_time: 0.0056  lr: 0.004196  max_mem: 3094M
[32m[04/20 02:29:19 d2.utils.events]: [0m eta: 0:01:14  iter: 859  total_loss: 0.686  loss_cls: 0.244  loss_box_reg: 0.342  loss_rpn_cls: 0.034  loss_rpn_loc: 0.061  time: 0.5288  data_time: 0.0059  lr: 0.004296  max_mem: 3094M
[32m[04/20 02:29:30 d2.utils.events]: [0m eta: 0:01:04  iter: 879  total_loss: 0.555  loss_cls: 0.192  loss_box_reg: 0.284  loss_rpn_cls: 0.022  loss_rpn_loc: 0.057  time: 0.5293  data_time: 0.0061  lr: 0.004396  max_mem: 3094M
[32m[04/20 02:29:41 d2.utils.events]: [0m eta: 0:00:53  iter: 899  total_loss: 0.707  loss_cls: 0.239  loss_box_reg: 0.383  loss_rpn_cls: 0.022  loss_rpn_loc: 0.068  time: 0.5292  data_time: 0.0062  lr: 0.004496  max_mem: 3094M
[32m[04/20 02:29:52 d2.utils.events]: [0m eta: 0:00:42  iter: 919  total_loss: 0.698  loss_cls: 0.233  loss_box_reg: 0.350  loss_rpn_cls: 0.026  loss_rpn_loc: 0.057  time: 0.5290  data_time: 0.0059  lr: 0.004595  max_mem: 3094M
[32m[04/20 02:30:02 d2.utils.events]: [0m eta: 0:00:32  iter: 939  total_loss: 0.705  loss_cls: 0.231  loss_box_reg: 0.334  loss_rpn_cls: 0.028  loss_rpn_loc: 0.070  time: 0.5289  data_time: 0.0062  lr: 0.004695  max_mem: 3094M
[32m[04/20 02:30:13 d2.utils.events]: [0m eta: 0:00:21  iter: 959  total_loss: 0.770  loss_cls: 0.244  loss_box_reg: 0.387  loss_rpn_cls: 0.020  loss_rpn_loc: 0.088  time: 0.5288  data_time: 0.0057  lr: 0.004795  max_mem: 3094M
[32m[04/20 02:30:23 d2.utils.events]: [0m eta: 0:00:11  iter: 979  total_loss: 0.769  loss_cls: 0.240  loss_box_reg: 0.402  loss_rpn_cls: 0.028  loss_rpn_loc: 0.078  time: 0.5285  data_time: 0.0056  lr: 0.004895  max_mem: 3094M
[5m[31mWARNING[0m [32m[04/20 02:30:37 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 02:30:37 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[5m[31mWARNING[0m [32m[04/20 02:30:37 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 02:30:37 d2.utils.events]: [0m eta: 0:00:00  iter: 999  total_loss: 0.626  loss_cls: 0.211  loss_box_reg: 0.302  loss_rpn_cls: 0.026  loss_rpn_loc: 0.056  time: 0.5284  data_time: 0.0058  lr: 0.004995  max_mem: 3094M
[32m[04/20 02:30:38 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:08:47 (0.5289 s / it)
[32m[04/20 02:30:38 d2.engine.hooks]: [0mTotal training time: 0:08:54 (0:00:07 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 02:30:42 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 02:30:42 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/20 02:30:43 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 02:30:44 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1185 s / img. ETA=0:16:47
[32m[04/20 02:30:50 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1188 s / img. ETA=0:16:51
[32m[04/20 02:30:55 d2.evaluation.evaluator]: [0mInference done 95/8355. 0.1187 s / img. ETA=0:16:45
[32m[04/20 02:31:00 d2.evaluation.evaluator]: [0mInference done 137/8355. 0.1184 s / img. ETA=0:16:38
[32m[04/20 02:31:05 d2.evaluation.evaluator]: [0mInference done 179/8355. 0.1183 s / img. ETA=0:16:32
[32m[04/20 02:31:10 d2.evaluation.evaluator]: [0mInference done 221/8355. 0.1183 s / img. ETA=0:16:26
[32m[04/20 02:31:15 d2.evaluation.evaluator]: [0mInference done 263/8355. 0.1183 s / img. ETA=0:16:21
[32m[04/20 02:31:20 d2.evaluation.evaluator]: [0mInference done 305/8355. 0.1183 s / img. ETA=0:16:16
[32m[04/20 02:31:25 d2.evaluation.evaluator]: [0mInference done 346/8355. 0.1184 s / img. ETA=0:16:13
[32m[04/20 02:31:30 d2.evaluation.evaluator]: [0mInference done 387/8355. 0.1185 s / img. ETA=0:16:09
[32m[04/20 02:31:35 d2.evaluation.evaluator]: [0mInference done 429/8355. 0.1185 s / img. ETA=0:16:04
[32m[04/20 02:31:40 d2.evaluation.evaluator]: [0mInference done 470/8355. 0.1186 s / img. ETA=0:15:59
[32m[04/20 02:31:45 d2.evaluation.evaluator]: [0mInference done 512/8355. 0.1185 s / img. ETA=0:15:54
[32m[04/20 02:31:51 d2.evaluation.evaluator]: [0mInference done 554/8355. 0.1185 s / img. ETA=0:15:49
[32m[04/20 02:31:56 d2.evaluation.evaluator]: [0mInference done 596/8355. 0.1185 s / img. ETA=0:15:43
[32m[04/20 02:32:01 d2.evaluation.evaluator]: [0mInference done 638/8355. 0.1184 s / img. ETA=0:15:38
[32m[04/20 02:32:06 d2.evaluation.evaluator]: [0mInference done 679/8355. 0.1185 s / img. ETA=0:15:34
[32m[04/20 02:32:11 d2.evaluation.evaluator]: [0mInference done 720/8355. 0.1187 s / img. ETA=0:15:30
[32m[04/20 02:32:16 d2.evaluation.evaluator]: [0mInference done 762/8355. 0.1186 s / img. ETA=0:15:24
[32m[04/20 02:32:21 d2.evaluation.evaluator]: [0mInference done 804/8355. 0.1186 s / img. ETA=0:15:19
[32m[04/20 02:32:26 d2.evaluation.evaluator]: [0mInference done 846/8355. 0.1186 s / img. ETA=0:15:14
[32m[04/20 02:32:31 d2.evaluation.evaluator]: [0mInference done 887/8355. 0.1186 s / img. ETA=0:15:09
[32m[04/20 02:32:36 d2.evaluation.evaluator]: [0mInference done 929/8355. 0.1186 s / img. ETA=0:15:04
[32m[04/20 02:32:41 d2.evaluation.evaluator]: [0mInference done 971/8355. 0.1186 s / img. ETA=0:14:59
[32m[04/20 02:32:46 d2.evaluation.evaluator]: [0mInference done 1012/8355. 0.1186 s / img. ETA=0:14:54
[32m[04/20 02:32:51 d2.evaluation.evaluator]: [0mInference done 1053/8355. 0.1186 s / img. ETA=0:14:49
[32m[04/20 02:32:57 d2.evaluation.evaluator]: [0mInference done 1095/8355. 0.1186 s / img. ETA=0:14:44
[32m[04/20 02:33:02 d2.evaluation.evaluator]: [0mInference done 1137/8355. 0.1186 s / img. ETA=0:14:38
[32m[04/20 02:33:07 d2.evaluation.evaluator]: [0mInference done 1179/8355. 0.1186 s / img. ETA=0:14:33
[32m[04/20 02:33:12 d2.evaluation.evaluator]: [0mInference done 1221/8355. 0.1186 s / img. ETA=0:14:28
[32m[04/20 02:33:17 d2.evaluation.evaluator]: [0mInference done 1263/8355. 0.1186 s / img. ETA=0:14:23
[32m[04/20 02:33:22 d2.evaluation.evaluator]: [0mInference done 1305/8355. 0.1186 s / img. ETA=0:14:18
[32m[04/20 02:33:27 d2.evaluation.evaluator]: [0mInference done 1346/8355. 0.1186 s / img. ETA=0:14:13
[32m[04/20 02:33:32 d2.evaluation.evaluator]: [0mInference done 1388/8355. 0.1185 s / img. ETA=0:14:08
[32m[04/20 02:33:37 d2.evaluation.evaluator]: [0mInference done 1430/8355. 0.1185 s / img. ETA=0:14:02
[32m[04/20 02:33:42 d2.evaluation.evaluator]: [0mInference done 1472/8355. 0.1185 s / img. ETA=0:13:57
[32m[04/20 02:33:47 d2.evaluation.evaluator]: [0mInference done 1513/8355. 0.1185 s / img. ETA=0:13:52
[32m[04/20 02:33:52 d2.evaluation.evaluator]: [0mInference done 1554/8355. 0.1186 s / img. ETA=0:13:48
[32m[04/20 02:33:57 d2.evaluation.evaluator]: [0mInference done 1595/8355. 0.1186 s / img. ETA=0:13:43
[32m[04/20 02:34:02 d2.evaluation.evaluator]: [0mInference done 1636/8355. 0.1186 s / img. ETA=0:13:38
[32m[04/20 02:34:07 d2.evaluation.evaluator]: [0mInference done 1677/8355. 0.1186 s / img. ETA=0:13:33
[32m[04/20 02:34:12 d2.evaluation.evaluator]: [0mInference done 1718/8355. 0.1186 s / img. ETA=0:13:28
[32m[04/20 02:34:18 d2.evaluation.evaluator]: [0mInference done 1759/8355. 0.1187 s / img. ETA=0:13:24
[32m[04/20 02:34:23 d2.evaluation.evaluator]: [0mInference done 1801/8355. 0.1187 s / img. ETA=0:13:18
[32m[04/20 02:34:28 d2.evaluation.evaluator]: [0mInference done 1843/8355. 0.1187 s / img. ETA=0:13:13
[32m[04/20 02:34:33 d2.evaluation.evaluator]: [0mInference done 1884/8355. 0.1187 s / img. ETA=0:13:08
[32m[04/20 02:34:38 d2.evaluation.evaluator]: [0mInference done 1925/8355. 0.1187 s / img. ETA=0:13:03
[32m[04/20 02:34:43 d2.evaluation.evaluator]: [0mInference done 1966/8355. 0.1187 s / img. ETA=0:12:59
[32m[04/20 02:34:48 d2.evaluation.evaluator]: [0mInference done 2008/8355. 0.1187 s / img. ETA=0:12:53
[32m[04/20 02:34:53 d2.evaluation.evaluator]: [0mInference done 2049/8355. 0.1187 s / img. ETA=0:12:49
[32m[04/20 02:34:58 d2.evaluation.evaluator]: [0mInference done 2091/8355. 0.1187 s / img. ETA=0:12:43
[32m[04/20 02:35:03 d2.evaluation.evaluator]: [0mInference done 2133/8355. 0.1187 s / img. ETA=0:12:38
[32m[04/20 02:35:08 d2.evaluation.evaluator]: [0mInference done 2175/8355. 0.1187 s / img. ETA=0:12:33
[32m[04/20 02:35:13 d2.evaluation.evaluator]: [0mInference done 2216/8355. 0.1187 s / img. ETA=0:12:28
[32m[04/20 02:35:18 d2.evaluation.evaluator]: [0mInference done 2257/8355. 0.1187 s / img. ETA=0:12:23
[32m[04/20 02:35:23 d2.evaluation.evaluator]: [0mInference done 2298/8355. 0.1187 s / img. ETA=0:12:18
[32m[04/20 02:35:28 d2.evaluation.evaluator]: [0mInference done 2339/8355. 0.1187 s / img. ETA=0:12:13
[32m[04/20 02:35:33 d2.evaluation.evaluator]: [0mInference done 2380/8355. 0.1187 s / img. ETA=0:12:08
[32m[04/20 02:35:38 d2.evaluation.evaluator]: [0mInference done 2421/8355. 0.1187 s / img. ETA=0:12:03
[32m[04/20 02:35:44 d2.evaluation.evaluator]: [0mInference done 2463/8355. 0.1187 s / img. ETA=0:11:58
[32m[04/20 02:35:49 d2.evaluation.evaluator]: [0mInference done 2504/8355. 0.1188 s / img. ETA=0:11:53
[32m[04/20 02:35:54 d2.evaluation.evaluator]: [0mInference done 2545/8355. 0.1188 s / img. ETA=0:11:48
[32m[04/20 02:35:59 d2.evaluation.evaluator]: [0mInference done 2586/8355. 0.1188 s / img. ETA=0:11:44
[32m[04/20 02:36:04 d2.evaluation.evaluator]: [0mInference done 2627/8355. 0.1188 s / img. ETA=0:11:39
[32m[04/20 02:36:09 d2.evaluation.evaluator]: [0mInference done 2668/8355. 0.1188 s / img. ETA=0:11:34
[32m[04/20 02:36:14 d2.evaluation.evaluator]: [0mInference done 2709/8355. 0.1188 s / img. ETA=0:11:29
[32m[04/20 02:36:19 d2.evaluation.evaluator]: [0mInference done 2750/8355. 0.1189 s / img. ETA=0:11:24
[32m[04/20 02:36:24 d2.evaluation.evaluator]: [0mInference done 2791/8355. 0.1189 s / img. ETA=0:11:19
[32m[04/20 02:36:29 d2.evaluation.evaluator]: [0mInference done 2832/8355. 0.1189 s / img. ETA=0:11:15
[32m[04/20 02:36:34 d2.evaluation.evaluator]: [0mInference done 2872/8355. 0.1190 s / img. ETA=0:11:10
[32m[04/20 02:36:39 d2.evaluation.evaluator]: [0mInference done 2912/8355. 0.1190 s / img. ETA=0:11:05
[32m[04/20 02:36:44 d2.evaluation.evaluator]: [0mInference done 2953/8355. 0.1190 s / img. ETA=0:11:00
[32m[04/20 02:36:49 d2.evaluation.evaluator]: [0mInference done 2994/8355. 0.1190 s / img. ETA=0:10:55
[32m[04/20 02:36:55 d2.evaluation.evaluator]: [0mInference done 3035/8355. 0.1190 s / img. ETA=0:10:50
[32m[04/20 02:37:00 d2.evaluation.evaluator]: [0mInference done 3076/8355. 0.1190 s / img. ETA=0:10:46
[32m[04/20 02:37:05 d2.evaluation.evaluator]: [0mInference done 3116/8355. 0.1191 s / img. ETA=0:10:41
[32m[04/20 02:37:10 d2.evaluation.evaluator]: [0mInference done 3156/8355. 0.1191 s / img. ETA=0:10:36
[32m[04/20 02:37:15 d2.evaluation.evaluator]: [0mInference done 3197/8355. 0.1191 s / img. ETA=0:10:31
[32m[04/20 02:37:20 d2.evaluation.evaluator]: [0mInference done 3238/8355. 0.1191 s / img. ETA=0:10:26
[32m[04/20 02:37:25 d2.evaluation.evaluator]: [0mInference done 3279/8355. 0.1191 s / img. ETA=0:10:21
[32m[04/20 02:37:30 d2.evaluation.evaluator]: [0mInference done 3320/8355. 0.1191 s / img. ETA=0:10:16
[32m[04/20 02:37:35 d2.evaluation.evaluator]: [0mInference done 3361/8355. 0.1191 s / img. ETA=0:10:11
[32m[04/20 02:37:40 d2.evaluation.evaluator]: [0mInference done 3402/8355. 0.1191 s / img. ETA=0:10:06
[32m[04/20 02:37:45 d2.evaluation.evaluator]: [0mInference done 3443/8355. 0.1191 s / img. ETA=0:10:01
[32m[04/20 02:37:50 d2.evaluation.evaluator]: [0mInference done 3484/8355. 0.1192 s / img. ETA=0:09:56
[32m[04/20 02:37:55 d2.evaluation.evaluator]: [0mInference done 3525/8355. 0.1192 s / img. ETA=0:09:52
[32m[04/20 02:38:00 d2.evaluation.evaluator]: [0mInference done 3565/8355. 0.1192 s / img. ETA=0:09:47
[32m[04/20 02:38:05 d2.evaluation.evaluator]: [0mInference done 3606/8355. 0.1192 s / img. ETA=0:09:42
[32m[04/20 02:38:10 d2.evaluation.evaluator]: [0mInference done 3647/8355. 0.1192 s / img. ETA=0:09:37
[32m[04/20 02:38:15 d2.evaluation.evaluator]: [0mInference done 3688/8355. 0.1192 s / img. ETA=0:09:32
[32m[04/20 02:38:21 d2.evaluation.evaluator]: [0mInference done 3729/8355. 0.1192 s / img. ETA=0:09:27
[32m[04/20 02:38:26 d2.evaluation.evaluator]: [0mInference done 3770/8355. 0.1192 s / img. ETA=0:09:22
[32m[04/20 02:38:31 d2.evaluation.evaluator]: [0mInference done 3811/8355. 0.1192 s / img. ETA=0:09:17
[32m[04/20 02:38:36 d2.evaluation.evaluator]: [0mInference done 3851/8355. 0.1193 s / img. ETA=0:09:12
[32m[04/20 02:38:41 d2.evaluation.evaluator]: [0mInference done 3892/8355. 0.1193 s / img. ETA=0:09:07
[32m[04/20 02:38:46 d2.evaluation.evaluator]: [0mInference done 3933/8355. 0.1193 s / img. ETA=0:09:02
[32m[04/20 02:38:51 d2.evaluation.evaluator]: [0mInference done 3974/8355. 0.1193 s / img. ETA=0:08:57
[32m[04/20 02:38:56 d2.evaluation.evaluator]: [0mInference done 4015/8355. 0.1193 s / img. ETA=0:08:52
[32m[04/20 02:39:01 d2.evaluation.evaluator]: [0mInference done 4056/8355. 0.1193 s / img. ETA=0:08:47
[32m[04/20 02:39:06 d2.evaluation.evaluator]: [0mInference done 4097/8355. 0.1193 s / img. ETA=0:08:42
[32m[04/20 02:39:11 d2.evaluation.evaluator]: [0mInference done 4138/8355. 0.1193 s / img. ETA=0:08:37
[32m[04/20 02:39:16 d2.evaluation.evaluator]: [0mInference done 4179/8355. 0.1193 s / img. ETA=0:08:32
[32m[04/20 02:39:21 d2.evaluation.evaluator]: [0mInference done 4220/8355. 0.1193 s / img. ETA=0:08:27
[32m[04/20 02:39:26 d2.evaluation.evaluator]: [0mInference done 4260/8355. 0.1193 s / img. ETA=0:08:22
[32m[04/20 02:39:31 d2.evaluation.evaluator]: [0mInference done 4301/8355. 0.1193 s / img. ETA=0:08:17
[32m[04/20 02:39:36 d2.evaluation.evaluator]: [0mInference done 4342/8355. 0.1193 s / img. ETA=0:08:12
[32m[04/20 02:39:41 d2.evaluation.evaluator]: [0mInference done 4384/8355. 0.1193 s / img. ETA=0:08:07
[32m[04/20 02:39:46 d2.evaluation.evaluator]: [0mInference done 4425/8355. 0.1193 s / img. ETA=0:08:02
[32m[04/20 02:39:51 d2.evaluation.evaluator]: [0mInference done 4467/8355. 0.1193 s / img. ETA=0:07:57
[32m[04/20 02:39:56 d2.evaluation.evaluator]: [0mInference done 4508/8355. 0.1193 s / img. ETA=0:07:52
[32m[04/20 02:40:02 d2.evaluation.evaluator]: [0mInference done 4549/8355. 0.1193 s / img. ETA=0:07:47
[32m[04/20 02:40:07 d2.evaluation.evaluator]: [0mInference done 4590/8355. 0.1193 s / img. ETA=0:07:42
[32m[04/20 02:40:12 d2.evaluation.evaluator]: [0mInference done 4632/8355. 0.1193 s / img. ETA=0:07:36
[32m[04/20 02:40:17 d2.evaluation.evaluator]: [0mInference done 4674/8355. 0.1193 s / img. ETA=0:07:31
[32m[04/20 02:40:22 d2.evaluation.evaluator]: [0mInference done 4716/8355. 0.1193 s / img. ETA=0:07:26
[32m[04/20 02:40:27 d2.evaluation.evaluator]: [0mInference done 4757/8355. 0.1193 s / img. ETA=0:07:21
[32m[04/20 02:40:32 d2.evaluation.evaluator]: [0mInference done 4798/8355. 0.1193 s / img. ETA=0:07:16
[32m[04/20 02:40:37 d2.evaluation.evaluator]: [0mInference done 4840/8355. 0.1193 s / img. ETA=0:07:11
[32m[04/20 02:40:42 d2.evaluation.evaluator]: [0mInference done 4882/8355. 0.1193 s / img. ETA=0:07:06
[32m[04/20 02:40:47 d2.evaluation.evaluator]: [0mInference done 4924/8355. 0.1192 s / img. ETA=0:07:00
[32m[04/20 02:40:52 d2.evaluation.evaluator]: [0mInference done 4966/8355. 0.1192 s / img. ETA=0:06:55
[32m[04/20 02:40:57 d2.evaluation.evaluator]: [0mInference done 5007/8355. 0.1192 s / img. ETA=0:06:50
[32m[04/20 02:41:02 d2.evaluation.evaluator]: [0mInference done 5048/8355. 0.1192 s / img. ETA=0:06:45
[32m[04/20 02:41:07 d2.evaluation.evaluator]: [0mInference done 5089/8355. 0.1192 s / img. ETA=0:06:40
[32m[04/20 02:41:12 d2.evaluation.evaluator]: [0mInference done 5130/8355. 0.1192 s / img. ETA=0:06:35
[32m[04/20 02:41:17 d2.evaluation.evaluator]: [0mInference done 5171/8355. 0.1192 s / img. ETA=0:06:30
[32m[04/20 02:41:22 d2.evaluation.evaluator]: [0mInference done 5212/8355. 0.1192 s / img. ETA=0:06:25
[32m[04/20 02:41:27 d2.evaluation.evaluator]: [0mInference done 5253/8355. 0.1192 s / img. ETA=0:06:20
[32m[04/20 02:41:33 d2.evaluation.evaluator]: [0mInference done 5294/8355. 0.1192 s / img. ETA=0:06:15
[32m[04/20 02:41:38 d2.evaluation.evaluator]: [0mInference done 5335/8355. 0.1192 s / img. ETA=0:06:10
[32m[04/20 02:41:43 d2.evaluation.evaluator]: [0mInference done 5375/8355. 0.1192 s / img. ETA=0:06:05
[32m[04/20 02:41:48 d2.evaluation.evaluator]: [0mInference done 5416/8355. 0.1192 s / img. ETA=0:06:00
[32m[04/20 02:41:53 d2.evaluation.evaluator]: [0mInference done 5457/8355. 0.1193 s / img. ETA=0:05:55
[32m[04/20 02:41:58 d2.evaluation.evaluator]: [0mInference done 5498/8355. 0.1193 s / img. ETA=0:05:50
[32m[04/20 02:42:03 d2.evaluation.evaluator]: [0mInference done 5539/8355. 0.1193 s / img. ETA=0:05:45
[32m[04/20 02:42:08 d2.evaluation.evaluator]: [0mInference done 5580/8355. 0.1193 s / img. ETA=0:05:40
[32m[04/20 02:42:13 d2.evaluation.evaluator]: [0mInference done 5621/8355. 0.1193 s / img. ETA=0:05:35
[32m[04/20 02:42:18 d2.evaluation.evaluator]: [0mInference done 5662/8355. 0.1193 s / img. ETA=0:05:30
[32m[04/20 02:42:23 d2.evaluation.evaluator]: [0mInference done 5703/8355. 0.1193 s / img. ETA=0:05:25
[32m[04/20 02:42:28 d2.evaluation.evaluator]: [0mInference done 5744/8355. 0.1193 s / img. ETA=0:05:20
[32m[04/20 02:42:33 d2.evaluation.evaluator]: [0mInference done 5785/8355. 0.1193 s / img. ETA=0:05:15
[32m[04/20 02:42:38 d2.evaluation.evaluator]: [0mInference done 5826/8355. 0.1193 s / img. ETA=0:05:10
[32m[04/20 02:42:43 d2.evaluation.evaluator]: [0mInference done 5868/8355. 0.1193 s / img. ETA=0:05:05
[32m[04/20 02:42:48 d2.evaluation.evaluator]: [0mInference done 5910/8355. 0.1193 s / img. ETA=0:05:00
[32m[04/20 02:42:54 d2.evaluation.evaluator]: [0mInference done 5952/8355. 0.1193 s / img. ETA=0:04:54
[32m[04/20 02:42:59 d2.evaluation.evaluator]: [0mInference done 5993/8355. 0.1193 s / img. ETA=0:04:49
[32m[04/20 02:43:04 d2.evaluation.evaluator]: [0mInference done 6034/8355. 0.1193 s / img. ETA=0:04:44
[32m[04/20 02:43:09 d2.evaluation.evaluator]: [0mInference done 6076/8355. 0.1193 s / img. ETA=0:04:39
[32m[04/20 02:43:14 d2.evaluation.evaluator]: [0mInference done 6117/8355. 0.1193 s / img. ETA=0:04:34
[32m[04/20 02:43:19 d2.evaluation.evaluator]: [0mInference done 6158/8355. 0.1193 s / img. ETA=0:04:29
[32m[04/20 02:43:24 d2.evaluation.evaluator]: [0mInference done 6199/8355. 0.1193 s / img. ETA=0:04:24
[32m[04/20 02:43:29 d2.evaluation.evaluator]: [0mInference done 6240/8355. 0.1193 s / img. ETA=0:04:19
[32m[04/20 02:43:34 d2.evaluation.evaluator]: [0mInference done 6281/8355. 0.1193 s / img. ETA=0:04:14
[32m[04/20 02:43:39 d2.evaluation.evaluator]: [0mInference done 6322/8355. 0.1193 s / img. ETA=0:04:09
[32m[04/20 02:43:44 d2.evaluation.evaluator]: [0mInference done 6364/8355. 0.1193 s / img. ETA=0:04:04
[32m[04/20 02:43:49 d2.evaluation.evaluator]: [0mInference done 6406/8355. 0.1193 s / img. ETA=0:03:59
[32m[04/20 02:43:54 d2.evaluation.evaluator]: [0mInference done 6447/8355. 0.1193 s / img. ETA=0:03:54
[32m[04/20 02:43:59 d2.evaluation.evaluator]: [0mInference done 6488/8355. 0.1193 s / img. ETA=0:03:49
[32m[04/20 02:44:04 d2.evaluation.evaluator]: [0mInference done 6529/8355. 0.1193 s / img. ETA=0:03:44
[32m[04/20 02:44:09 d2.evaluation.evaluator]: [0mInference done 6570/8355. 0.1193 s / img. ETA=0:03:39
[32m[04/20 02:44:15 d2.evaluation.evaluator]: [0mInference done 6611/8355. 0.1193 s / img. ETA=0:03:34
[32m[04/20 02:44:20 d2.evaluation.evaluator]: [0mInference done 6652/8355. 0.1193 s / img. ETA=0:03:29
[32m[04/20 02:44:25 d2.evaluation.evaluator]: [0mInference done 6694/8355. 0.1193 s / img. ETA=0:03:23
[32m[04/20 02:44:30 d2.evaluation.evaluator]: [0mInference done 6736/8355. 0.1193 s / img. ETA=0:03:18
[32m[04/20 02:44:35 d2.evaluation.evaluator]: [0mInference done 6778/8355. 0.1193 s / img. ETA=0:03:13
[32m[04/20 02:44:40 d2.evaluation.evaluator]: [0mInference done 6820/8355. 0.1193 s / img. ETA=0:03:08
[32m[04/20 02:44:45 d2.evaluation.evaluator]: [0mInference done 6862/8355. 0.1193 s / img. ETA=0:03:03
[32m[04/20 02:44:50 d2.evaluation.evaluator]: [0mInference done 6904/8355. 0.1193 s / img. ETA=0:02:57
[32m[04/20 02:44:55 d2.evaluation.evaluator]: [0mInference done 6945/8355. 0.1193 s / img. ETA=0:02:52
[32m[04/20 02:45:00 d2.evaluation.evaluator]: [0mInference done 6986/8355. 0.1193 s / img. ETA=0:02:47
[32m[04/20 02:45:05 d2.evaluation.evaluator]: [0mInference done 7027/8355. 0.1193 s / img. ETA=0:02:42
[32m[04/20 02:45:10 d2.evaluation.evaluator]: [0mInference done 7068/8355. 0.1193 s / img. ETA=0:02:37
[32m[04/20 02:45:15 d2.evaluation.evaluator]: [0mInference done 7109/8355. 0.1193 s / img. ETA=0:02:32
[32m[04/20 02:45:20 d2.evaluation.evaluator]: [0mInference done 7149/8355. 0.1193 s / img. ETA=0:02:27
[32m[04/20 02:45:25 d2.evaluation.evaluator]: [0mInference done 7190/8355. 0.1193 s / img. ETA=0:02:22
[32m[04/20 02:45:30 d2.evaluation.evaluator]: [0mInference done 7231/8355. 0.1193 s / img. ETA=0:02:17
[32m[04/20 02:45:35 d2.evaluation.evaluator]: [0mInference done 7272/8355. 0.1193 s / img. ETA=0:02:12
[32m[04/20 02:45:40 d2.evaluation.evaluator]: [0mInference done 7313/8355. 0.1193 s / img. ETA=0:02:07
[32m[04/20 02:45:45 d2.evaluation.evaluator]: [0mInference done 7354/8355. 0.1193 s / img. ETA=0:02:02
[32m[04/20 02:45:50 d2.evaluation.evaluator]: [0mInference done 7395/8355. 0.1193 s / img. ETA=0:01:57
[32m[04/20 02:45:55 d2.evaluation.evaluator]: [0mInference done 7436/8355. 0.1193 s / img. ETA=0:01:52
[32m[04/20 02:46:00 d2.evaluation.evaluator]: [0mInference done 7477/8355. 0.1193 s / img. ETA=0:01:47
[32m[04/20 02:46:05 d2.evaluation.evaluator]: [0mInference done 7518/8355. 0.1193 s / img. ETA=0:01:42
[32m[04/20 02:46:11 d2.evaluation.evaluator]: [0mInference done 7559/8355. 0.1193 s / img. ETA=0:01:37
[32m[04/20 02:46:16 d2.evaluation.evaluator]: [0mInference done 7601/8355. 0.1193 s / img. ETA=0:01:32
[32m[04/20 02:46:21 d2.evaluation.evaluator]: [0mInference done 7643/8355. 0.1193 s / img. ETA=0:01:27
[32m[04/20 02:46:26 d2.evaluation.evaluator]: [0mInference done 7684/8355. 0.1193 s / img. ETA=0:01:22
[32m[04/20 02:46:31 d2.evaluation.evaluator]: [0mInference done 7725/8355. 0.1193 s / img. ETA=0:01:17
[32m[04/20 02:46:36 d2.evaluation.evaluator]: [0mInference done 7766/8355. 0.1193 s / img. ETA=0:01:12
[32m[04/20 02:46:41 d2.evaluation.evaluator]: [0mInference done 7807/8355. 0.1193 s / img. ETA=0:01:07
[32m[04/20 02:46:46 d2.evaluation.evaluator]: [0mInference done 7848/8355. 0.1193 s / img. ETA=0:01:02
[32m[04/20 02:46:51 d2.evaluation.evaluator]: [0mInference done 7889/8355. 0.1193 s / img. ETA=0:00:57
[32m[04/20 02:46:56 d2.evaluation.evaluator]: [0mInference done 7930/8355. 0.1193 s / img. ETA=0:00:52
[32m[04/20 02:47:01 d2.evaluation.evaluator]: [0mInference done 7971/8355. 0.1193 s / img. ETA=0:00:47
[32m[04/20 02:47:06 d2.evaluation.evaluator]: [0mInference done 8012/8355. 0.1193 s / img. ETA=0:00:42
[32m[04/20 02:47:11 d2.evaluation.evaluator]: [0mInference done 8054/8355. 0.1193 s / img. ETA=0:00:36
[32m[04/20 02:47:16 d2.evaluation.evaluator]: [0mInference done 8096/8355. 0.1193 s / img. ETA=0:00:31
[32m[04/20 02:47:21 d2.evaluation.evaluator]: [0mInference done 8138/8355. 0.1193 s / img. ETA=0:00:26
[32m[04/20 02:47:27 d2.evaluation.evaluator]: [0mInference done 8180/8355. 0.1193 s / img. ETA=0:00:21
[32m[04/20 02:47:32 d2.evaluation.evaluator]: [0mInference done 8222/8355. 0.1193 s / img. ETA=0:00:16
[32m[04/20 02:47:37 d2.evaluation.evaluator]: [0mInference done 8263/8355. 0.1193 s / img. ETA=0:00:11
[32m[04/20 02:47:42 d2.evaluation.evaluator]: [0mInference done 8305/8355. 0.1193 s / img. ETA=0:00:06
[32m[04/20 02:47:47 d2.evaluation.evaluator]: [0mInference done 8346/8355. 0.1193 s / img. ETA=0:00:01
[32m[04/20 02:47:48 d2.evaluation.evaluator]: [0mTotal inference time: 0:17:04.402727 (0.122683 s / img per device, on 1 devices)
[32m[04/20 02:47:48 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:36 (0.119313 s / img per device, on 1 devices)
[32m[04/20 02:47:48 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 02:47:48 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 02:47:49 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=24.70s).
Accumulating evaluation results...
DONE (t=2.89s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.282
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.547
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.242
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.202
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.387
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.157
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.332
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.259
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.451
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.634
[32m[04/20 02:48:16 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 28.153 | 54.659 | 24.210 | 20.193 | 38.662 | 59.111 |
[32m[04/20 02:48:16 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 33.362 | bicycle       | 21.019 | car            | 39.361 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | 18.870 | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 02:48:18 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 02:48:18 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[32m[04/20 02:48:18 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 02:48:20 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1191 s / img. ETA=0:02:31
[32m[04/20 02:48:25 d2.evaluation.evaluator]: [0mInference done 52/1257. 0.1200 s / img. ETA=0:02:28
[32m[04/20 02:48:30 d2.evaluation.evaluator]: [0mInference done 93/1257. 0.1202 s / img. ETA=0:02:23
[32m[04/20 02:48:35 d2.evaluation.evaluator]: [0mInference done 134/1257. 0.1200 s / img. ETA=0:02:18
[32m[04/20 02:48:40 d2.evaluation.evaluator]: [0mInference done 175/1257. 0.1202 s / img. ETA=0:02:13
[32m[04/20 02:48:45 d2.evaluation.evaluator]: [0mInference done 216/1257. 0.1202 s / img. ETA=0:02:08
[32m[04/20 02:48:50 d2.evaluation.evaluator]: [0mInference done 257/1257. 0.1203 s / img. ETA=0:02:03
[32m[04/20 02:48:55 d2.evaluation.evaluator]: [0mInference done 298/1257. 0.1203 s / img. ETA=0:01:58
[32m[04/20 02:49:01 d2.evaluation.evaluator]: [0mInference done 338/1257. 0.1205 s / img. ETA=0:01:54
[32m[04/20 02:49:06 d2.evaluation.evaluator]: [0mInference done 379/1257. 0.1205 s / img. ETA=0:01:49
[32m[04/20 02:49:11 d2.evaluation.evaluator]: [0mInference done 419/1257. 0.1206 s / img. ETA=0:01:44
[32m[04/20 02:49:16 d2.evaluation.evaluator]: [0mInference done 460/1257. 0.1206 s / img. ETA=0:01:39
[32m[04/20 02:49:21 d2.evaluation.evaluator]: [0mInference done 501/1257. 0.1206 s / img. ETA=0:01:34
[32m[04/20 02:49:26 d2.evaluation.evaluator]: [0mInference done 542/1257. 0.1205 s / img. ETA=0:01:28
[32m[04/20 02:49:31 d2.evaluation.evaluator]: [0mInference done 583/1257. 0.1206 s / img. ETA=0:01:23
[32m[04/20 02:49:36 d2.evaluation.evaluator]: [0mInference done 624/1257. 0.1206 s / img. ETA=0:01:18
[32m[04/20 02:49:41 d2.evaluation.evaluator]: [0mInference done 665/1257. 0.1205 s / img. ETA=0:01:13
[32m[04/20 02:49:46 d2.evaluation.evaluator]: [0mInference done 706/1257. 0.1205 s / img. ETA=0:01:08
[32m[04/20 02:49:51 d2.evaluation.evaluator]: [0mInference done 746/1257. 0.1206 s / img. ETA=0:01:03
[32m[04/20 02:49:56 d2.evaluation.evaluator]: [0mInference done 787/1257. 0.1206 s / img. ETA=0:00:58
[32m[04/20 02:50:02 d2.evaluation.evaluator]: [0mInference done 828/1257. 0.1206 s / img. ETA=0:00:53
[32m[04/20 02:50:07 d2.evaluation.evaluator]: [0mInference done 869/1257. 0.1205 s / img. ETA=0:00:48
[32m[04/20 02:50:12 d2.evaluation.evaluator]: [0mInference done 910/1257. 0.1206 s / img. ETA=0:00:43
[32m[04/20 02:50:17 d2.evaluation.evaluator]: [0mInference done 951/1257. 0.1205 s / img. ETA=0:00:38
[32m[04/20 02:50:22 d2.evaluation.evaluator]: [0mInference done 992/1257. 0.1205 s / img. ETA=0:00:32
[32m[04/20 02:50:27 d2.evaluation.evaluator]: [0mInference done 1032/1257. 0.1205 s / img. ETA=0:00:27
[32m[04/20 02:50:32 d2.evaluation.evaluator]: [0mInference done 1073/1257. 0.1205 s / img. ETA=0:00:22
[32m[04/20 02:50:37 d2.evaluation.evaluator]: [0mInference done 1114/1257. 0.1205 s / img. ETA=0:00:17
[32m[04/20 02:50:42 d2.evaluation.evaluator]: [0mInference done 1155/1257. 0.1205 s / img. ETA=0:00:12
[32m[04/20 02:50:47 d2.evaluation.evaluator]: [0mInference done 1195/1257. 0.1205 s / img. ETA=0:00:07
[32m[04/20 02:50:52 d2.evaluation.evaluator]: [0mInference done 1236/1257. 0.1205 s / img. ETA=0:00:02
[32m[04/20 02:50:55 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:35.624825 (0.124301 s / img per device, on 1 devices)
[32m[04/20 02:50:55 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:30 (0.120476 s / img per device, on 1 devices)
[32m[04/20 02:50:55 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 02:50:55 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 02:50:55 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.86s).
Accumulating evaluation results...
DONE (t=0.40s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.197
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.389
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.173
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.240
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.476
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.111
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.249
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.295
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.536
[32m[04/20 02:50:59 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 19.749 | 38.866 | 17.290 | 12.048 | 24.050 | 47.606 |
[32m[04/20 02:50:59 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 27.484 | bicycle       | 12.292 | car            | 39.218 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | 0.000  | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  11  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 02:51:00 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 02:51:01 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 02:51:01 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/20 02:51:01 d2.data.build]: [0mRemoved 889 images with no usable annotations. 7466 images left.
[32m[04/20 02:51:02 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 02:51:02 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 02:51:02 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 02:51:13 d2.utils.events]: [0m eta: 0:08:59  iter: 19  total_loss: 0.698  loss_cls: 0.241  loss_box_reg: 0.372  loss_rpn_cls: 0.021  loss_rpn_loc: 0.053  time: 0.5512  data_time: 0.0215  lr: 0.000100  max_mem: 3094M
[32m[04/20 02:51:24 d2.utils.events]: [0m eta: 0:08:37  iter: 39  total_loss: 0.684  loss_cls: 0.235  loss_box_reg: 0.376  loss_rpn_cls: 0.022  loss_rpn_loc: 0.051  time: 0.5421  data_time: 0.0076  lr: 0.000200  max_mem: 3094M
[32m[04/20 02:51:34 d2.utils.events]: [0m eta: 0:08:25  iter: 59  total_loss: 0.748  loss_cls: 0.237  loss_box_reg: 0.389  loss_rpn_cls: 0.026  loss_rpn_loc: 0.063  time: 0.5406  data_time: 0.0073  lr: 0.000300  max_mem: 3094M
[32m[04/20 02:51:45 d2.utils.events]: [0m eta: 0:08:14  iter: 79  total_loss: 0.680  loss_cls: 0.223  loss_box_reg: 0.386  loss_rpn_cls: 0.021  loss_rpn_loc: 0.055  time: 0.5430  data_time: 0.0071  lr: 0.000400  max_mem: 3094M
[32m[04/20 02:51:56 d2.utils.events]: [0m eta: 0:08:03  iter: 99  total_loss: 0.677  loss_cls: 0.222  loss_box_reg: 0.357  loss_rpn_cls: 0.021  loss_rpn_loc: 0.052  time: 0.5404  data_time: 0.0064  lr: 0.000500  max_mem: 3094M
[32m[04/20 02:52:07 d2.utils.events]: [0m eta: 0:07:52  iter: 119  total_loss: 0.546  loss_cls: 0.193  loss_box_reg: 0.288  loss_rpn_cls: 0.021  loss_rpn_loc: 0.050  time: 0.5403  data_time: 0.0069  lr: 0.000599  max_mem: 3094M
[32m[04/20 02:52:17 d2.utils.events]: [0m eta: 0:07:41  iter: 139  total_loss: 0.829  loss_cls: 0.263  loss_box_reg: 0.396  loss_rpn_cls: 0.028  loss_rpn_loc: 0.073  time: 0.5370  data_time: 0.0060  lr: 0.000699  max_mem: 3094M
[32m[04/20 02:52:30 d2.utils.events]: [0m eta: 0:07:29  iter: 159  total_loss: 0.698  loss_cls: 0.219  loss_box_reg: 0.405  loss_rpn_cls: 0.020  loss_rpn_loc: 0.056  time: 0.5357  data_time: 0.0071  lr: 0.000799  max_mem: 3094M
[32m[04/20 02:52:40 d2.utils.events]: [0m eta: 0:07:16  iter: 179  total_loss: 0.558  loss_cls: 0.188  loss_box_reg: 0.312  loss_rpn_cls: 0.023  loss_rpn_loc: 0.050  time: 0.5345  data_time: 0.0057  lr: 0.000899  max_mem: 3094M
[32m[04/20 02:52:51 d2.utils.events]: [0m eta: 0:07:06  iter: 199  total_loss: 0.585  loss_cls: 0.180  loss_box_reg: 0.314  loss_rpn_cls: 0.020  loss_rpn_loc: 0.053  time: 0.5341  data_time: 0.0069  lr: 0.000999  max_mem: 3094M
[32m[04/20 02:53:02 d2.utils.events]: [0m eta: 0:06:55  iter: 219  total_loss: 0.633  loss_cls: 0.207  loss_box_reg: 0.336  loss_rpn_cls: 0.025  loss_rpn_loc: 0.071  time: 0.5342  data_time: 0.0073  lr: 0.001099  max_mem: 3094M
[32m[04/20 02:53:13 d2.utils.events]: [0m eta: 0:06:47  iter: 239  total_loss: 0.590  loss_cls: 0.194  loss_box_reg: 0.304  loss_rpn_cls: 0.020  loss_rpn_loc: 0.054  time: 0.5356  data_time: 0.0074  lr: 0.001199  max_mem: 3094M
[32m[04/20 02:53:23 d2.utils.events]: [0m eta: 0:06:36  iter: 259  total_loss: 0.680  loss_cls: 0.214  loss_box_reg: 0.363  loss_rpn_cls: 0.022  loss_rpn_loc: 0.052  time: 0.5348  data_time: 0.0067  lr: 0.001299  max_mem: 3094M
[32m[04/20 02:53:34 d2.utils.events]: [0m eta: 0:06:25  iter: 279  total_loss: 0.754  loss_cls: 0.228  loss_box_reg: 0.351  loss_rpn_cls: 0.024  loss_rpn_loc: 0.075  time: 0.5343  data_time: 0.0068  lr: 0.001399  max_mem: 3094M
[32m[04/20 02:53:45 d2.utils.events]: [0m eta: 0:06:13  iter: 299  total_loss: 0.653  loss_cls: 0.209  loss_box_reg: 0.341  loss_rpn_cls: 0.023  loss_rpn_loc: 0.065  time: 0.5332  data_time: 0.0060  lr: 0.001499  max_mem: 3094M
[32m[04/20 02:53:55 d2.utils.events]: [0m eta: 0:06:03  iter: 319  total_loss: 0.645  loss_cls: 0.214  loss_box_reg: 0.340  loss_rpn_cls: 0.022  loss_rpn_loc: 0.052  time: 0.5336  data_time: 0.0065  lr: 0.001598  max_mem: 3094M
[32m[04/20 02:54:06 d2.utils.events]: [0m eta: 0:05:52  iter: 339  total_loss: 0.596  loss_cls: 0.172  loss_box_reg: 0.334  loss_rpn_cls: 0.020  loss_rpn_loc: 0.048  time: 0.5329  data_time: 0.0063  lr: 0.001698  max_mem: 3094M
[32m[04/20 02:54:17 d2.utils.events]: [0m eta: 0:05:41  iter: 359  total_loss: 0.752  loss_cls: 0.230  loss_box_reg: 0.387  loss_rpn_cls: 0.021  loss_rpn_loc: 0.069  time: 0.5328  data_time: 0.0066  lr: 0.001798  max_mem: 3094M
[32m[04/20 02:54:27 d2.utils.events]: [0m eta: 0:05:30  iter: 379  total_loss: 0.612  loss_cls: 0.196  loss_box_reg: 0.319  loss_rpn_cls: 0.019  loss_rpn_loc: 0.047  time: 0.5334  data_time: 0.0069  lr: 0.001898  max_mem: 3094M
[32m[04/20 02:54:38 d2.utils.events]: [0m eta: 0:05:20  iter: 399  total_loss: 0.624  loss_cls: 0.223  loss_box_reg: 0.329  loss_rpn_cls: 0.022  loss_rpn_loc: 0.054  time: 0.5331  data_time: 0.0060  lr: 0.001998  max_mem: 3094M
[32m[04/20 02:54:49 d2.utils.events]: [0m eta: 0:05:09  iter: 419  total_loss: 0.676  loss_cls: 0.216  loss_box_reg: 0.371  loss_rpn_cls: 0.023  loss_rpn_loc: 0.056  time: 0.5332  data_time: 0.0085  lr: 0.002098  max_mem: 3094M
[32m[04/20 02:55:00 d2.utils.events]: [0m eta: 0:04:58  iter: 439  total_loss: 0.599  loss_cls: 0.190  loss_box_reg: 0.274  loss_rpn_cls: 0.019  loss_rpn_loc: 0.057  time: 0.5335  data_time: 0.0075  lr: 0.002198  max_mem: 3094M
[32m[04/20 02:55:10 d2.utils.events]: [0m eta: 0:04:48  iter: 459  total_loss: 0.562  loss_cls: 0.189  loss_box_reg: 0.295  loss_rpn_cls: 0.018  loss_rpn_loc: 0.057  time: 0.5336  data_time: 0.0092  lr: 0.002298  max_mem: 3094M
[32m[04/20 02:55:21 d2.utils.events]: [0m eta: 0:04:37  iter: 479  total_loss: 0.748  loss_cls: 0.248  loss_box_reg: 0.369  loss_rpn_cls: 0.026  loss_rpn_loc: 0.073  time: 0.5334  data_time: 0.0078  lr: 0.002398  max_mem: 3094M
[32m[04/20 02:55:32 d2.utils.events]: [0m eta: 0:04:26  iter: 499  total_loss: 0.602  loss_cls: 0.187  loss_box_reg: 0.346  loss_rpn_cls: 0.025  loss_rpn_loc: 0.050  time: 0.5328  data_time: 0.0076  lr: 0.002498  max_mem: 3094M
[32m[04/20 02:55:42 d2.utils.events]: [0m eta: 0:04:16  iter: 519  total_loss: 0.678  loss_cls: 0.206  loss_box_reg: 0.370  loss_rpn_cls: 0.013  loss_rpn_loc: 0.040  time: 0.5330  data_time: 0.0077  lr: 0.002597  max_mem: 3094M
[32m[04/20 02:55:53 d2.utils.events]: [0m eta: 0:04:05  iter: 539  total_loss: 0.606  loss_cls: 0.189  loss_box_reg: 0.325  loss_rpn_cls: 0.015  loss_rpn_loc: 0.045  time: 0.5331  data_time: 0.0085  lr: 0.002697  max_mem: 3094M
[32m[04/20 02:56:04 d2.utils.events]: [0m eta: 0:03:54  iter: 559  total_loss: 0.596  loss_cls: 0.205  loss_box_reg: 0.323  loss_rpn_cls: 0.020  loss_rpn_loc: 0.063  time: 0.5331  data_time: 0.0077  lr: 0.002797  max_mem: 3094M
[32m[04/20 02:56:14 d2.utils.events]: [0m eta: 0:03:44  iter: 579  total_loss: 0.675  loss_cls: 0.211  loss_box_reg: 0.341  loss_rpn_cls: 0.021  loss_rpn_loc: 0.056  time: 0.5326  data_time: 0.0065  lr: 0.002897  max_mem: 3094M
[32m[04/20 02:56:25 d2.utils.events]: [0m eta: 0:03:33  iter: 599  total_loss: 0.665  loss_cls: 0.215  loss_box_reg: 0.373  loss_rpn_cls: 0.021  loss_rpn_loc: 0.055  time: 0.5330  data_time: 0.0068  lr: 0.002997  max_mem: 3094M
[32m[04/20 02:56:36 d2.utils.events]: [0m eta: 0:03:22  iter: 619  total_loss: 0.829  loss_cls: 0.249  loss_box_reg: 0.457  loss_rpn_cls: 0.026  loss_rpn_loc: 0.081  time: 0.5329  data_time: 0.0078  lr: 0.003097  max_mem: 3094M
[32m[04/20 02:56:46 d2.utils.events]: [0m eta: 0:03:12  iter: 639  total_loss: 0.593  loss_cls: 0.197  loss_box_reg: 0.308  loss_rpn_cls: 0.020  loss_rpn_loc: 0.042  time: 0.5327  data_time: 0.0101  lr: 0.003197  max_mem: 3094M
[32m[04/20 02:56:57 d2.utils.events]: [0m eta: 0:03:01  iter: 659  total_loss: 0.814  loss_cls: 0.258  loss_box_reg: 0.440  loss_rpn_cls: 0.024  loss_rpn_loc: 0.047  time: 0.5327  data_time: 0.0067  lr: 0.003297  max_mem: 3094M
[32m[04/20 02:57:08 d2.utils.events]: [0m eta: 0:02:51  iter: 679  total_loss: 0.635  loss_cls: 0.234  loss_box_reg: 0.336  loss_rpn_cls: 0.026  loss_rpn_loc: 0.051  time: 0.5329  data_time: 0.0069  lr: 0.003397  max_mem: 3094M
[32m[04/20 02:57:19 d2.utils.events]: [0m eta: 0:02:40  iter: 699  total_loss: 0.756  loss_cls: 0.237  loss_box_reg: 0.391  loss_rpn_cls: 0.029  loss_rpn_loc: 0.059  time: 0.5328  data_time: 0.0079  lr: 0.003497  max_mem: 3094M
[32m[04/20 02:57:30 d2.utils.events]: [0m eta: 0:02:29  iter: 719  total_loss: 0.787  loss_cls: 0.237  loss_box_reg: 0.425  loss_rpn_cls: 0.025  loss_rpn_loc: 0.074  time: 0.5333  data_time: 0.0076  lr: 0.003596  max_mem: 3094M
[32m[04/20 02:57:40 d2.utils.events]: [0m eta: 0:02:19  iter: 739  total_loss: 0.725  loss_cls: 0.226  loss_box_reg: 0.374  loss_rpn_cls: 0.026  loss_rpn_loc: 0.062  time: 0.5333  data_time: 0.0059  lr: 0.003696  max_mem: 3094M
[32m[04/20 02:57:51 d2.utils.events]: [0m eta: 0:02:08  iter: 759  total_loss: 0.636  loss_cls: 0.252  loss_box_reg: 0.321  loss_rpn_cls: 0.020  loss_rpn_loc: 0.051  time: 0.5330  data_time: 0.0072  lr: 0.003796  max_mem: 3094M
[32m[04/20 02:58:01 d2.utils.events]: [0m eta: 0:01:57  iter: 779  total_loss: 0.696  loss_cls: 0.227  loss_box_reg: 0.328  loss_rpn_cls: 0.024  loss_rpn_loc: 0.065  time: 0.5326  data_time: 0.0070  lr: 0.003896  max_mem: 3094M
[32m[04/20 02:58:12 d2.utils.events]: [0m eta: 0:01:47  iter: 799  total_loss: 0.678  loss_cls: 0.192  loss_box_reg: 0.342  loss_rpn_cls: 0.030  loss_rpn_loc: 0.062  time: 0.5326  data_time: 0.0089  lr: 0.003996  max_mem: 3094M
[32m[04/20 02:58:23 d2.utils.events]: [0m eta: 0:01:36  iter: 819  total_loss: 0.736  loss_cls: 0.245  loss_box_reg: 0.386  loss_rpn_cls: 0.029  loss_rpn_loc: 0.065  time: 0.5327  data_time: 0.0076  lr: 0.004096  max_mem: 3094M
[32m[04/20 02:58:34 d2.utils.events]: [0m eta: 0:01:25  iter: 839  total_loss: 0.684  loss_cls: 0.204  loss_box_reg: 0.354  loss_rpn_cls: 0.024  loss_rpn_loc: 0.050  time: 0.5329  data_time: 0.0075  lr: 0.004196  max_mem: 3094M
[32m[04/20 02:58:45 d2.utils.events]: [0m eta: 0:01:15  iter: 859  total_loss: 0.819  loss_cls: 0.266  loss_box_reg: 0.419  loss_rpn_cls: 0.028  loss_rpn_loc: 0.062  time: 0.5332  data_time: 0.0069  lr: 0.004296  max_mem: 3094M
[32m[04/20 02:58:55 d2.utils.events]: [0m eta: 0:01:04  iter: 879  total_loss: 0.658  loss_cls: 0.229  loss_box_reg: 0.373  loss_rpn_cls: 0.020  loss_rpn_loc: 0.058  time: 0.5328  data_time: 0.0063  lr: 0.004396  max_mem: 3094M
[32m[04/20 02:59:06 d2.utils.events]: [0m eta: 0:00:53  iter: 899  total_loss: 0.636  loss_cls: 0.203  loss_box_reg: 0.332  loss_rpn_cls: 0.035  loss_rpn_loc: 0.043  time: 0.5328  data_time: 0.0068  lr: 0.004496  max_mem: 3094M
[32m[04/20 02:59:17 d2.utils.events]: [0m eta: 0:00:43  iter: 919  total_loss: 0.803  loss_cls: 0.248  loss_box_reg: 0.382  loss_rpn_cls: 0.028  loss_rpn_loc: 0.085  time: 0.5329  data_time: 0.0070  lr: 0.004595  max_mem: 3094M
[32m[04/20 02:59:27 d2.utils.events]: [0m eta: 0:00:32  iter: 939  total_loss: 0.661  loss_cls: 0.201  loss_box_reg: 0.349  loss_rpn_cls: 0.021  loss_rpn_loc: 0.059  time: 0.5328  data_time: 0.0065  lr: 0.004695  max_mem: 3094M
[32m[04/20 02:59:38 d2.utils.events]: [0m eta: 0:00:21  iter: 959  total_loss: 0.850  loss_cls: 0.283  loss_box_reg: 0.447  loss_rpn_cls: 0.030  loss_rpn_loc: 0.065  time: 0.5328  data_time: 0.0065  lr: 0.004795  max_mem: 3094M
[32m[04/20 02:59:49 d2.utils.events]: [0m eta: 0:00:11  iter: 979  total_loss: 0.730  loss_cls: 0.237  loss_box_reg: 0.414  loss_rpn_cls: 0.025  loss_rpn_loc: 0.061  time: 0.5330  data_time: 0.0078  lr: 0.004895  max_mem: 3094M
[5m[31mWARNING[0m [32m[04/20 03:00:03 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 03:00:03 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[5m[31mWARNING[0m [32m[04/20 03:00:03 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 03:00:03 d2.utils.events]: [0m eta: 0:00:00  iter: 999  total_loss: 0.763  loss_cls: 0.235  loss_box_reg: 0.375  loss_rpn_cls: 0.022  loss_rpn_loc: 0.063  time: 0.5332  data_time: 0.0061  lr: 0.004995  max_mem: 3094M
[32m[04/20 03:00:04 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:08:52 (0.5337 s / it)
[32m[04/20 03:00:04 d2.engine.hooks]: [0mTotal training time: 0:09:01 (0:00:09 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 03:00:09 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 03:00:09 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/20 03:00:10 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 03:00:11 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1262 s / img. ETA=0:18:04
[32m[04/20 03:00:16 d2.evaluation.evaluator]: [0mInference done 51/8355. 0.1221 s / img. ETA=0:17:25
[32m[04/20 03:00:21 d2.evaluation.evaluator]: [0mInference done 92/8355. 0.1215 s / img. ETA=0:17:16
[32m[04/20 03:00:27 d2.evaluation.evaluator]: [0mInference done 132/8355. 0.1220 s / img. ETA=0:17:17
[32m[04/20 03:00:32 d2.evaluation.evaluator]: [0mInference done 173/8355. 0.1216 s / img. ETA=0:17:09
[32m[04/20 03:00:37 d2.evaluation.evaluator]: [0mInference done 214/8355. 0.1213 s / img. ETA=0:17:00
[32m[04/20 03:00:42 d2.evaluation.evaluator]: [0mInference done 255/8355. 0.1211 s / img. ETA=0:16:55
[32m[04/20 03:00:47 d2.evaluation.evaluator]: [0mInference done 296/8355. 0.1208 s / img. ETA=0:16:46
[32m[04/20 03:00:52 d2.evaluation.evaluator]: [0mInference done 337/8355. 0.1207 s / img. ETA=0:16:40
[32m[04/20 03:00:57 d2.evaluation.evaluator]: [0mInference done 377/8355. 0.1207 s / img. ETA=0:16:35
[32m[04/20 03:01:02 d2.evaluation.evaluator]: [0mInference done 418/8355. 0.1208 s / img. ETA=0:16:30
[32m[04/20 03:01:07 d2.evaluation.evaluator]: [0mInference done 459/8355. 0.1208 s / img. ETA=0:16:25
[32m[04/20 03:01:12 d2.evaluation.evaluator]: [0mInference done 500/8355. 0.1206 s / img. ETA=0:16:18
[32m[04/20 03:01:17 d2.evaluation.evaluator]: [0mInference done 541/8355. 0.1205 s / img. ETA=0:16:12
[32m[04/20 03:01:22 d2.evaluation.evaluator]: [0mInference done 581/8355. 0.1206 s / img. ETA=0:16:08
[32m[04/20 03:01:27 d2.evaluation.evaluator]: [0mInference done 622/8355. 0.1206 s / img. ETA=0:16:03
[32m[04/20 03:01:32 d2.evaluation.evaluator]: [0mInference done 662/8355. 0.1207 s / img. ETA=0:15:59
[32m[04/20 03:01:37 d2.evaluation.evaluator]: [0mInference done 703/8355. 0.1206 s / img. ETA=0:15:53
[32m[04/20 03:01:43 d2.evaluation.evaluator]: [0mInference done 744/8355. 0.1206 s / img. ETA=0:15:47
[32m[04/20 03:01:48 d2.evaluation.evaluator]: [0mInference done 784/8355. 0.1206 s / img. ETA=0:15:42
[32m[04/20 03:01:53 d2.evaluation.evaluator]: [0mInference done 825/8355. 0.1206 s / img. ETA=0:15:37
[32m[04/20 03:01:58 d2.evaluation.evaluator]: [0mInference done 866/8355. 0.1206 s / img. ETA=0:15:32
[32m[04/20 03:02:03 d2.evaluation.evaluator]: [0mInference done 907/8355. 0.1206 s / img. ETA=0:15:27
[32m[04/20 03:02:08 d2.evaluation.evaluator]: [0mInference done 947/8355. 0.1206 s / img. ETA=0:15:22
[32m[04/20 03:02:13 d2.evaluation.evaluator]: [0mInference done 988/8355. 0.1206 s / img. ETA=0:15:16
[32m[04/20 03:02:18 d2.evaluation.evaluator]: [0mInference done 1029/8355. 0.1206 s / img. ETA=0:15:11
[32m[04/20 03:02:23 d2.evaluation.evaluator]: [0mInference done 1070/8355. 0.1205 s / img. ETA=0:15:06
[32m[04/20 03:02:28 d2.evaluation.evaluator]: [0mInference done 1111/8355. 0.1205 s / img. ETA=0:15:01
[32m[04/20 03:02:33 d2.evaluation.evaluator]: [0mInference done 1152/8355. 0.1204 s / img. ETA=0:14:55
[32m[04/20 03:02:38 d2.evaluation.evaluator]: [0mInference done 1193/8355. 0.1204 s / img. ETA=0:14:50
[32m[04/20 03:02:43 d2.evaluation.evaluator]: [0mInference done 1234/8355. 0.1203 s / img. ETA=0:14:44
[32m[04/20 03:02:48 d2.evaluation.evaluator]: [0mInference done 1274/8355. 0.1203 s / img. ETA=0:14:40
[32m[04/20 03:02:53 d2.evaluation.evaluator]: [0mInference done 1315/8355. 0.1203 s / img. ETA=0:14:34
[32m[04/20 03:02:58 d2.evaluation.evaluator]: [0mInference done 1357/8355. 0.1203 s / img. ETA=0:14:29
[32m[04/20 03:03:03 d2.evaluation.evaluator]: [0mInference done 1398/8355. 0.1202 s / img. ETA=0:14:23
[32m[04/20 03:03:08 d2.evaluation.evaluator]: [0mInference done 1439/8355. 0.1202 s / img. ETA=0:14:18
[32m[04/20 03:03:14 d2.evaluation.evaluator]: [0mInference done 1480/8355. 0.1202 s / img. ETA=0:14:12
[32m[04/20 03:03:19 d2.evaluation.evaluator]: [0mInference done 1520/8355. 0.1202 s / img. ETA=0:14:08
[32m[04/20 03:03:24 d2.evaluation.evaluator]: [0mInference done 1560/8355. 0.1203 s / img. ETA=0:14:04
[32m[04/20 03:03:29 d2.evaluation.evaluator]: [0mInference done 1600/8355. 0.1204 s / img. ETA=0:13:59
[32m[04/20 03:03:34 d2.evaluation.evaluator]: [0mInference done 1640/8355. 0.1204 s / img. ETA=0:13:55
[32m[04/20 03:03:39 d2.evaluation.evaluator]: [0mInference done 1680/8355. 0.1205 s / img. ETA=0:13:50
[32m[04/20 03:03:44 d2.evaluation.evaluator]: [0mInference done 1721/8355. 0.1205 s / img. ETA=0:13:45
[32m[04/20 03:03:49 d2.evaluation.evaluator]: [0mInference done 1761/8355. 0.1205 s / img. ETA=0:13:40
[32m[04/20 03:03:54 d2.evaluation.evaluator]: [0mInference done 1801/8355. 0.1206 s / img. ETA=0:13:35
[32m[04/20 03:03:59 d2.evaluation.evaluator]: [0mInference done 1842/8355. 0.1206 s / img. ETA=0:13:30
[32m[04/20 03:04:04 d2.evaluation.evaluator]: [0mInference done 1882/8355. 0.1206 s / img. ETA=0:13:26
[32m[04/20 03:04:09 d2.evaluation.evaluator]: [0mInference done 1922/8355. 0.1207 s / img. ETA=0:13:21
[32m[04/20 03:04:14 d2.evaluation.evaluator]: [0mInference done 1962/8355. 0.1207 s / img. ETA=0:13:16
[32m[04/20 03:04:19 d2.evaluation.evaluator]: [0mInference done 2002/8355. 0.1207 s / img. ETA=0:13:11
[32m[04/20 03:04:25 d2.evaluation.evaluator]: [0mInference done 2042/8355. 0.1208 s / img. ETA=0:13:07
[32m[04/20 03:04:30 d2.evaluation.evaluator]: [0mInference done 2083/8355. 0.1208 s / img. ETA=0:13:01
[32m[04/20 03:04:35 d2.evaluation.evaluator]: [0mInference done 2123/8355. 0.1208 s / img. ETA=0:12:57
[32m[04/20 03:04:40 d2.evaluation.evaluator]: [0mInference done 2163/8355. 0.1208 s / img. ETA=0:12:52
[32m[04/20 03:04:45 d2.evaluation.evaluator]: [0mInference done 2203/8355. 0.1208 s / img. ETA=0:12:47
[32m[04/20 03:04:50 d2.evaluation.evaluator]: [0mInference done 2243/8355. 0.1208 s / img. ETA=0:12:42
[32m[04/20 03:04:55 d2.evaluation.evaluator]: [0mInference done 2282/8355. 0.1209 s / img. ETA=0:12:38
[32m[04/20 03:05:00 d2.evaluation.evaluator]: [0mInference done 2322/8355. 0.1209 s / img. ETA=0:12:33
[32m[04/20 03:05:05 d2.evaluation.evaluator]: [0mInference done 2362/8355. 0.1209 s / img. ETA=0:12:28
[32m[04/20 03:05:10 d2.evaluation.evaluator]: [0mInference done 2402/8355. 0.1210 s / img. ETA=0:12:23
[32m[04/20 03:05:15 d2.evaluation.evaluator]: [0mInference done 2442/8355. 0.1210 s / img. ETA=0:12:18
[32m[04/20 03:05:20 d2.evaluation.evaluator]: [0mInference done 2482/8355. 0.1210 s / img. ETA=0:12:13
[32m[04/20 03:05:25 d2.evaluation.evaluator]: [0mInference done 2522/8355. 0.1210 s / img. ETA=0:12:08
[32m[04/20 03:05:30 d2.evaluation.evaluator]: [0mInference done 2562/8355. 0.1210 s / img. ETA=0:12:03
[32m[04/20 03:05:35 d2.evaluation.evaluator]: [0mInference done 2602/8355. 0.1210 s / img. ETA=0:11:59
[32m[04/20 03:05:40 d2.evaluation.evaluator]: [0mInference done 2642/8355. 0.1210 s / img. ETA=0:11:54
[32m[04/20 03:05:45 d2.evaluation.evaluator]: [0mInference done 2683/8355. 0.1210 s / img. ETA=0:11:48
[32m[04/20 03:05:50 d2.evaluation.evaluator]: [0mInference done 2723/8355. 0.1210 s / img. ETA=0:11:44
[32m[04/20 03:05:55 d2.evaluation.evaluator]: [0mInference done 2763/8355. 0.1210 s / img. ETA=0:11:39
[32m[04/20 03:06:00 d2.evaluation.evaluator]: [0mInference done 2803/8355. 0.1211 s / img. ETA=0:11:34
[32m[04/20 03:06:05 d2.evaluation.evaluator]: [0mInference done 2842/8355. 0.1211 s / img. ETA=0:11:29
[32m[04/20 03:06:10 d2.evaluation.evaluator]: [0mInference done 2882/8355. 0.1211 s / img. ETA=0:11:24
[32m[04/20 03:06:15 d2.evaluation.evaluator]: [0mInference done 2922/8355. 0.1211 s / img. ETA=0:11:19
[32m[04/20 03:06:21 d2.evaluation.evaluator]: [0mInference done 2962/8355. 0.1211 s / img. ETA=0:11:14
[32m[04/20 03:06:26 d2.evaluation.evaluator]: [0mInference done 3002/8355. 0.1211 s / img. ETA=0:11:09
[32m[04/20 03:06:31 d2.evaluation.evaluator]: [0mInference done 3042/8355. 0.1211 s / img. ETA=0:11:04
[32m[04/20 03:06:36 d2.evaluation.evaluator]: [0mInference done 3082/8355. 0.1212 s / img. ETA=0:11:00
[32m[04/20 03:06:41 d2.evaluation.evaluator]: [0mInference done 3123/8355. 0.1211 s / img. ETA=0:10:54
[32m[04/20 03:06:46 d2.evaluation.evaluator]: [0mInference done 3163/8355. 0.1212 s / img. ETA=0:10:49
[32m[04/20 03:06:51 d2.evaluation.evaluator]: [0mInference done 3203/8355. 0.1212 s / img. ETA=0:10:44
[32m[04/20 03:06:56 d2.evaluation.evaluator]: [0mInference done 3244/8355. 0.1212 s / img. ETA=0:10:39
[32m[04/20 03:07:01 d2.evaluation.evaluator]: [0mInference done 3284/8355. 0.1212 s / img. ETA=0:10:34
[32m[04/20 03:07:06 d2.evaluation.evaluator]: [0mInference done 3325/8355. 0.1212 s / img. ETA=0:10:29
[32m[04/20 03:07:11 d2.evaluation.evaluator]: [0mInference done 3366/8355. 0.1212 s / img. ETA=0:10:24
[32m[04/20 03:07:16 d2.evaluation.evaluator]: [0mInference done 3407/8355. 0.1211 s / img. ETA=0:10:19
[32m[04/20 03:07:21 d2.evaluation.evaluator]: [0mInference done 3447/8355. 0.1212 s / img. ETA=0:10:14
[32m[04/20 03:07:26 d2.evaluation.evaluator]: [0mInference done 3488/8355. 0.1211 s / img. ETA=0:10:09
[32m[04/20 03:07:31 d2.evaluation.evaluator]: [0mInference done 3528/8355. 0.1211 s / img. ETA=0:10:04
[32m[04/20 03:07:36 d2.evaluation.evaluator]: [0mInference done 3568/8355. 0.1211 s / img. ETA=0:09:59
[32m[04/20 03:07:42 d2.evaluation.evaluator]: [0mInference done 3608/8355. 0.1212 s / img. ETA=0:09:54
[32m[04/20 03:07:47 d2.evaluation.evaluator]: [0mInference done 3648/8355. 0.1212 s / img. ETA=0:09:49
[32m[04/20 03:07:52 d2.evaluation.evaluator]: [0mInference done 3689/8355. 0.1212 s / img. ETA=0:09:44
[32m[04/20 03:07:57 d2.evaluation.evaluator]: [0mInference done 3730/8355. 0.1212 s / img. ETA=0:09:38
[32m[04/20 03:08:02 d2.evaluation.evaluator]: [0mInference done 3770/8355. 0.1212 s / img. ETA=0:09:33
[32m[04/20 03:08:07 d2.evaluation.evaluator]: [0mInference done 3809/8355. 0.1212 s / img. ETA=0:09:29
[32m[04/20 03:08:12 d2.evaluation.evaluator]: [0mInference done 3849/8355. 0.1212 s / img. ETA=0:09:24
[32m[04/20 03:08:17 d2.evaluation.evaluator]: [0mInference done 3890/8355. 0.1212 s / img. ETA=0:09:19
[32m[04/20 03:08:22 d2.evaluation.evaluator]: [0mInference done 3931/8355. 0.1212 s / img. ETA=0:09:13
[32m[04/20 03:08:27 d2.evaluation.evaluator]: [0mInference done 3972/8355. 0.1212 s / img. ETA=0:09:08
[32m[04/20 03:08:32 d2.evaluation.evaluator]: [0mInference done 4012/8355. 0.1212 s / img. ETA=0:09:03
[32m[04/20 03:08:37 d2.evaluation.evaluator]: [0mInference done 4052/8355. 0.1212 s / img. ETA=0:08:58
[32m[04/20 03:08:42 d2.evaluation.evaluator]: [0mInference done 4092/8355. 0.1212 s / img. ETA=0:08:53
[32m[04/20 03:08:47 d2.evaluation.evaluator]: [0mInference done 4132/8355. 0.1212 s / img. ETA=0:08:48
[32m[04/20 03:08:52 d2.evaluation.evaluator]: [0mInference done 4172/8355. 0.1212 s / img. ETA=0:08:43
[32m[04/20 03:08:58 d2.evaluation.evaluator]: [0mInference done 4212/8355. 0.1212 s / img. ETA=0:08:38
[32m[04/20 03:09:03 d2.evaluation.evaluator]: [0mInference done 4253/8355. 0.1212 s / img. ETA=0:08:33
[32m[04/20 03:09:08 d2.evaluation.evaluator]: [0mInference done 4293/8355. 0.1212 s / img. ETA=0:08:28
[32m[04/20 03:09:13 d2.evaluation.evaluator]: [0mInference done 4333/8355. 0.1212 s / img. ETA=0:08:23
[32m[04/20 03:09:18 d2.evaluation.evaluator]: [0mInference done 4373/8355. 0.1212 s / img. ETA=0:08:18
[32m[04/20 03:09:23 d2.evaluation.evaluator]: [0mInference done 4414/8355. 0.1212 s / img. ETA=0:08:13
[32m[04/20 03:09:28 d2.evaluation.evaluator]: [0mInference done 4454/8355. 0.1212 s / img. ETA=0:08:08
[32m[04/20 03:09:33 d2.evaluation.evaluator]: [0mInference done 4494/8355. 0.1212 s / img. ETA=0:08:03
[32m[04/20 03:09:38 d2.evaluation.evaluator]: [0mInference done 4534/8355. 0.1212 s / img. ETA=0:07:58
[32m[04/20 03:09:43 d2.evaluation.evaluator]: [0mInference done 4574/8355. 0.1212 s / img. ETA=0:07:53
[32m[04/20 03:09:48 d2.evaluation.evaluator]: [0mInference done 4614/8355. 0.1212 s / img. ETA=0:07:48
[32m[04/20 03:09:53 d2.evaluation.evaluator]: [0mInference done 4654/8355. 0.1212 s / img. ETA=0:07:43
[32m[04/20 03:09:58 d2.evaluation.evaluator]: [0mInference done 4695/8355. 0.1212 s / img. ETA=0:07:38
[32m[04/20 03:10:03 d2.evaluation.evaluator]: [0mInference done 4735/8355. 0.1212 s / img. ETA=0:07:33
[32m[04/20 03:10:08 d2.evaluation.evaluator]: [0mInference done 4775/8355. 0.1213 s / img. ETA=0:07:28
[32m[04/20 03:10:13 d2.evaluation.evaluator]: [0mInference done 4815/8355. 0.1213 s / img. ETA=0:07:23
[32m[04/20 03:10:19 d2.evaluation.evaluator]: [0mInference done 4855/8355. 0.1213 s / img. ETA=0:07:18
[32m[04/20 03:10:24 d2.evaluation.evaluator]: [0mInference done 4896/8355. 0.1213 s / img. ETA=0:07:13
[32m[04/20 03:10:29 d2.evaluation.evaluator]: [0mInference done 4936/8355. 0.1213 s / img. ETA=0:07:08
[32m[04/20 03:10:34 d2.evaluation.evaluator]: [0mInference done 4976/8355. 0.1213 s / img. ETA=0:07:03
[32m[04/20 03:10:39 d2.evaluation.evaluator]: [0mInference done 5017/8355. 0.1213 s / img. ETA=0:06:58
[32m[04/20 03:10:44 d2.evaluation.evaluator]: [0mInference done 5057/8355. 0.1213 s / img. ETA=0:06:53
[32m[04/20 03:10:49 d2.evaluation.evaluator]: [0mInference done 5097/8355. 0.1213 s / img. ETA=0:06:48
[32m[04/20 03:10:54 d2.evaluation.evaluator]: [0mInference done 5137/8355. 0.1213 s / img. ETA=0:06:43
[32m[04/20 03:10:59 d2.evaluation.evaluator]: [0mInference done 5177/8355. 0.1213 s / img. ETA=0:06:38
[32m[04/20 03:11:04 d2.evaluation.evaluator]: [0mInference done 5217/8355. 0.1213 s / img. ETA=0:06:33
[32m[04/20 03:11:09 d2.evaluation.evaluator]: [0mInference done 5258/8355. 0.1213 s / img. ETA=0:06:28
[32m[04/20 03:11:14 d2.evaluation.evaluator]: [0mInference done 5298/8355. 0.1213 s / img. ETA=0:06:23
[32m[04/20 03:11:19 d2.evaluation.evaluator]: [0mInference done 5337/8355. 0.1213 s / img. ETA=0:06:18
[32m[04/20 03:11:24 d2.evaluation.evaluator]: [0mInference done 5377/8355. 0.1213 s / img. ETA=0:06:13
[32m[04/20 03:11:29 d2.evaluation.evaluator]: [0mInference done 5410/8355. 0.1213 s / img. ETA=0:06:09
[32m[04/20 03:11:35 d2.evaluation.evaluator]: [0mInference done 5448/8355. 0.1213 s / img. ETA=0:06:05
[32m[04/20 03:11:40 d2.evaluation.evaluator]: [0mInference done 5488/8355. 0.1213 s / img. ETA=0:06:00
[32m[04/20 03:11:45 d2.evaluation.evaluator]: [0mInference done 5528/8355. 0.1213 s / img. ETA=0:05:55
[32m[04/20 03:11:50 d2.evaluation.evaluator]: [0mInference done 5569/8355. 0.1213 s / img. ETA=0:05:50
[32m[04/20 03:11:55 d2.evaluation.evaluator]: [0mInference done 5609/8355. 0.1213 s / img. ETA=0:05:45
[32m[04/20 03:12:00 d2.evaluation.evaluator]: [0mInference done 5649/8355. 0.1213 s / img. ETA=0:05:40
[32m[04/20 03:12:05 d2.evaluation.evaluator]: [0mInference done 5689/8355. 0.1214 s / img. ETA=0:05:35
[32m[04/20 03:12:10 d2.evaluation.evaluator]: [0mInference done 5728/8355. 0.1214 s / img. ETA=0:05:30
[32m[04/20 03:12:15 d2.evaluation.evaluator]: [0mInference done 5767/8355. 0.1214 s / img. ETA=0:05:25
[32m[04/20 03:12:20 d2.evaluation.evaluator]: [0mInference done 5807/8355. 0.1214 s / img. ETA=0:05:20
[32m[04/20 03:12:25 d2.evaluation.evaluator]: [0mInference done 5847/8355. 0.1214 s / img. ETA=0:05:15
[32m[04/20 03:12:30 d2.evaluation.evaluator]: [0mInference done 5887/8355. 0.1214 s / img. ETA=0:05:10
[32m[04/20 03:12:35 d2.evaluation.evaluator]: [0mInference done 5928/8355. 0.1214 s / img. ETA=0:05:05
[32m[04/20 03:12:40 d2.evaluation.evaluator]: [0mInference done 5969/8355. 0.1214 s / img. ETA=0:04:59
[32m[04/20 03:12:45 d2.evaluation.evaluator]: [0mInference done 6010/8355. 0.1214 s / img. ETA=0:04:54
[32m[04/20 03:12:51 d2.evaluation.evaluator]: [0mInference done 6051/8355. 0.1214 s / img. ETA=0:04:49
[32m[04/20 03:12:56 d2.evaluation.evaluator]: [0mInference done 6091/8355. 0.1214 s / img. ETA=0:04:44
[32m[04/20 03:13:01 d2.evaluation.evaluator]: [0mInference done 6131/8355. 0.1214 s / img. ETA=0:04:39
[32m[04/20 03:13:06 d2.evaluation.evaluator]: [0mInference done 6171/8355. 0.1214 s / img. ETA=0:04:34
[32m[04/20 03:13:11 d2.evaluation.evaluator]: [0mInference done 6211/8355. 0.1214 s / img. ETA=0:04:29
[32m[04/20 03:13:16 d2.evaluation.evaluator]: [0mInference done 6251/8355. 0.1214 s / img. ETA=0:04:24
[32m[04/20 03:13:21 d2.evaluation.evaluator]: [0mInference done 6291/8355. 0.1214 s / img. ETA=0:04:19
[32m[04/20 03:13:26 d2.evaluation.evaluator]: [0mInference done 6330/8355. 0.1214 s / img. ETA=0:04:14
[32m[04/20 03:13:31 d2.evaluation.evaluator]: [0mInference done 6371/8355. 0.1214 s / img. ETA=0:04:09
[32m[04/20 03:13:36 d2.evaluation.evaluator]: [0mInference done 6412/8355. 0.1214 s / img. ETA=0:04:04
[32m[04/20 03:13:41 d2.evaluation.evaluator]: [0mInference done 6453/8355. 0.1214 s / img. ETA=0:03:59
[32m[04/20 03:13:46 d2.evaluation.evaluator]: [0mInference done 6494/8355. 0.1214 s / img. ETA=0:03:53
[32m[04/20 03:13:51 d2.evaluation.evaluator]: [0mInference done 6535/8355. 0.1214 s / img. ETA=0:03:48
[32m[04/20 03:13:56 d2.evaluation.evaluator]: [0mInference done 6576/8355. 0.1214 s / img. ETA=0:03:43
[32m[04/20 03:14:01 d2.evaluation.evaluator]: [0mInference done 6616/8355. 0.1214 s / img. ETA=0:03:38
[32m[04/20 03:14:06 d2.evaluation.evaluator]: [0mInference done 6657/8355. 0.1214 s / img. ETA=0:03:33
[32m[04/20 03:14:12 d2.evaluation.evaluator]: [0mInference done 6698/8355. 0.1214 s / img. ETA=0:03:28
[32m[04/20 03:14:17 d2.evaluation.evaluator]: [0mInference done 6739/8355. 0.1214 s / img. ETA=0:03:23
[32m[04/20 03:14:22 d2.evaluation.evaluator]: [0mInference done 6780/8355. 0.1214 s / img. ETA=0:03:17
[32m[04/20 03:14:27 d2.evaluation.evaluator]: [0mInference done 6821/8355. 0.1214 s / img. ETA=0:03:12
[32m[04/20 03:14:32 d2.evaluation.evaluator]: [0mInference done 6861/8355. 0.1214 s / img. ETA=0:03:07
[32m[04/20 03:14:37 d2.evaluation.evaluator]: [0mInference done 6902/8355. 0.1214 s / img. ETA=0:03:02
[32m[04/20 03:14:42 d2.evaluation.evaluator]: [0mInference done 6943/8355. 0.1214 s / img. ETA=0:02:57
[32m[04/20 03:14:47 d2.evaluation.evaluator]: [0mInference done 6983/8355. 0.1214 s / img. ETA=0:02:52
[32m[04/20 03:14:52 d2.evaluation.evaluator]: [0mInference done 7023/8355. 0.1214 s / img. ETA=0:02:47
[32m[04/20 03:14:57 d2.evaluation.evaluator]: [0mInference done 7063/8355. 0.1214 s / img. ETA=0:02:42
[32m[04/20 03:15:02 d2.evaluation.evaluator]: [0mInference done 7102/8355. 0.1214 s / img. ETA=0:02:37
[32m[04/20 03:15:07 d2.evaluation.evaluator]: [0mInference done 7142/8355. 0.1214 s / img. ETA=0:02:32
[32m[04/20 03:15:12 d2.evaluation.evaluator]: [0mInference done 7181/8355. 0.1214 s / img. ETA=0:02:27
[32m[04/20 03:15:18 d2.evaluation.evaluator]: [0mInference done 7221/8355. 0.1214 s / img. ETA=0:02:22
[32m[04/20 03:15:23 d2.evaluation.evaluator]: [0mInference done 7260/8355. 0.1214 s / img. ETA=0:02:17
[32m[04/20 03:15:28 d2.evaluation.evaluator]: [0mInference done 7301/8355. 0.1214 s / img. ETA=0:02:12
[32m[04/20 03:15:33 d2.evaluation.evaluator]: [0mInference done 7340/8355. 0.1214 s / img. ETA=0:02:07
[32m[04/20 03:15:38 d2.evaluation.evaluator]: [0mInference done 7380/8355. 0.1215 s / img. ETA=0:02:02
[32m[04/20 03:15:43 d2.evaluation.evaluator]: [0mInference done 7420/8355. 0.1215 s / img. ETA=0:01:57
[32m[04/20 03:15:48 d2.evaluation.evaluator]: [0mInference done 7459/8355. 0.1215 s / img. ETA=0:01:52
[32m[04/20 03:15:53 d2.evaluation.evaluator]: [0mInference done 7498/8355. 0.1215 s / img. ETA=0:01:47
[32m[04/20 03:15:58 d2.evaluation.evaluator]: [0mInference done 7538/8355. 0.1215 s / img. ETA=0:01:42
[32m[04/20 03:16:03 d2.evaluation.evaluator]: [0mInference done 7578/8355. 0.1215 s / img. ETA=0:01:37
[32m[04/20 03:16:08 d2.evaluation.evaluator]: [0mInference done 7618/8355. 0.1215 s / img. ETA=0:01:32
[32m[04/20 03:16:13 d2.evaluation.evaluator]: [0mInference done 7658/8355. 0.1215 s / img. ETA=0:01:27
[32m[04/20 03:16:18 d2.evaluation.evaluator]: [0mInference done 7698/8355. 0.1215 s / img. ETA=0:01:22
[32m[04/20 03:16:23 d2.evaluation.evaluator]: [0mInference done 7737/8355. 0.1215 s / img. ETA=0:01:17
[32m[04/20 03:16:28 d2.evaluation.evaluator]: [0mInference done 7777/8355. 0.1215 s / img. ETA=0:01:12
[32m[04/20 03:16:33 d2.evaluation.evaluator]: [0mInference done 7817/8355. 0.1215 s / img. ETA=0:01:07
[32m[04/20 03:16:38 d2.evaluation.evaluator]: [0mInference done 7857/8355. 0.1215 s / img. ETA=0:01:02
[32m[04/20 03:16:44 d2.evaluation.evaluator]: [0mInference done 7897/8355. 0.1215 s / img. ETA=0:00:57
[32m[04/20 03:16:49 d2.evaluation.evaluator]: [0mInference done 7937/8355. 0.1216 s / img. ETA=0:00:52
[32m[04/20 03:16:54 d2.evaluation.evaluator]: [0mInference done 7977/8355. 0.1216 s / img. ETA=0:00:47
[32m[04/20 03:16:59 d2.evaluation.evaluator]: [0mInference done 8018/8355. 0.1215 s / img. ETA=0:00:42
[32m[04/20 03:17:04 d2.evaluation.evaluator]: [0mInference done 8058/8355. 0.1215 s / img. ETA=0:00:37
[32m[04/20 03:17:09 d2.evaluation.evaluator]: [0mInference done 8098/8355. 0.1216 s / img. ETA=0:00:32
[32m[04/20 03:17:14 d2.evaluation.evaluator]: [0mInference done 8139/8355. 0.1215 s / img. ETA=0:00:27
[32m[04/20 03:17:19 d2.evaluation.evaluator]: [0mInference done 8180/8355. 0.1215 s / img. ETA=0:00:22
[32m[04/20 03:17:24 d2.evaluation.evaluator]: [0mInference done 8221/8355. 0.1215 s / img. ETA=0:00:16
[32m[04/20 03:17:29 d2.evaluation.evaluator]: [0mInference done 8261/8355. 0.1215 s / img. ETA=0:00:11
[32m[04/20 03:17:34 d2.evaluation.evaluator]: [0mInference done 8302/8355. 0.1215 s / img. ETA=0:00:06
[32m[04/20 03:17:39 d2.evaluation.evaluator]: [0mInference done 8343/8355. 0.1215 s / img. ETA=0:00:01
[32m[04/20 03:17:41 d2.evaluation.evaluator]: [0mTotal inference time: 0:17:30.429242 (0.125800 s / img per device, on 1 devices)
[32m[04/20 03:17:41 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:54 (0.121520 s / img per device, on 1 devices)
[32m[04/20 03:17:41 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 03:17:41 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 03:17:42 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.54s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=30.14s).
Accumulating evaluation results...
DONE (t=3.15s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.286
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.561
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.244
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.402
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.574
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.339
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.261
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.609
[32m[04/20 03:18:16 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 28.647 | 56.066 | 24.445 | 20.469 | 40.199 | 57.358 |
[32m[04/20 03:18:16 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 32.369 | bicycle       | 16.633 | car            | 41.944 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | 23.640 | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 03:18:17 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 03:18:17 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[32m[04/20 03:18:17 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 03:18:19 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1207 s / img. ETA=0:02:53
[32m[04/20 03:18:24 d2.evaluation.evaluator]: [0mInference done 50/1257. 0.1236 s / img. ETA=0:02:36
[32m[04/20 03:18:29 d2.evaluation.evaluator]: [0mInference done 90/1257. 0.1225 s / img. ETA=0:02:29
[32m[04/20 03:18:34 d2.evaluation.evaluator]: [0mInference done 129/1257. 0.1229 s / img. ETA=0:02:24
[32m[04/20 03:18:39 d2.evaluation.evaluator]: [0mInference done 169/1257. 0.1226 s / img. ETA=0:02:19
[32m[04/20 03:18:44 d2.evaluation.evaluator]: [0mInference done 210/1257. 0.1222 s / img. ETA=0:02:13
[32m[04/20 03:18:49 d2.evaluation.evaluator]: [0mInference done 250/1257. 0.1220 s / img. ETA=0:02:07
[32m[04/20 03:18:54 d2.evaluation.evaluator]: [0mInference done 289/1257. 0.1226 s / img. ETA=0:02:03
[32m[04/20 03:18:59 d2.evaluation.evaluator]: [0mInference done 329/1257. 0.1225 s / img. ETA=0:01:58
[32m[04/20 03:19:04 d2.evaluation.evaluator]: [0mInference done 369/1257. 0.1226 s / img. ETA=0:01:53
[32m[04/20 03:19:10 d2.evaluation.evaluator]: [0mInference done 409/1257. 0.1226 s / img. ETA=0:01:47
[32m[04/20 03:19:15 d2.evaluation.evaluator]: [0mInference done 449/1257. 0.1227 s / img. ETA=0:01:42
[32m[04/20 03:19:20 d2.evaluation.evaluator]: [0mInference done 489/1257. 0.1226 s / img. ETA=0:01:37
[32m[04/20 03:19:25 d2.evaluation.evaluator]: [0mInference done 530/1257. 0.1224 s / img. ETA=0:01:32
[32m[04/20 03:19:30 d2.evaluation.evaluator]: [0mInference done 570/1257. 0.1225 s / img. ETA=0:01:27
[32m[04/20 03:19:35 d2.evaluation.evaluator]: [0mInference done 610/1257. 0.1225 s / img. ETA=0:01:22
[32m[04/20 03:19:40 d2.evaluation.evaluator]: [0mInference done 651/1257. 0.1225 s / img. ETA=0:01:16
[32m[04/20 03:19:45 d2.evaluation.evaluator]: [0mInference done 692/1257. 0.1224 s / img. ETA=0:01:11
[32m[04/20 03:19:50 d2.evaluation.evaluator]: [0mInference done 732/1257. 0.1224 s / img. ETA=0:01:06
[32m[04/20 03:19:55 d2.evaluation.evaluator]: [0mInference done 772/1257. 0.1224 s / img. ETA=0:01:01
[32m[04/20 03:20:00 d2.evaluation.evaluator]: [0mInference done 812/1257. 0.1223 s / img. ETA=0:00:56
[32m[04/20 03:20:05 d2.evaluation.evaluator]: [0mInference done 852/1257. 0.1223 s / img. ETA=0:00:51
[32m[04/20 03:20:11 d2.evaluation.evaluator]: [0mInference done 892/1257. 0.1224 s / img. ETA=0:00:46
[32m[04/20 03:20:16 d2.evaluation.evaluator]: [0mInference done 932/1257. 0.1224 s / img. ETA=0:00:41
[32m[04/20 03:20:21 d2.evaluation.evaluator]: [0mInference done 973/1257. 0.1223 s / img. ETA=0:00:35
[32m[04/20 03:20:26 d2.evaluation.evaluator]: [0mInference done 1013/1257. 0.1223 s / img. ETA=0:00:30
[32m[04/20 03:20:31 d2.evaluation.evaluator]: [0mInference done 1053/1257. 0.1223 s / img. ETA=0:00:25
[32m[04/20 03:20:36 d2.evaluation.evaluator]: [0mInference done 1093/1257. 0.1223 s / img. ETA=0:00:20
[32m[04/20 03:20:41 d2.evaluation.evaluator]: [0mInference done 1134/1257. 0.1223 s / img. ETA=0:00:15
[32m[04/20 03:20:46 d2.evaluation.evaluator]: [0mInference done 1174/1257. 0.1223 s / img. ETA=0:00:10
[32m[04/20 03:20:51 d2.evaluation.evaluator]: [0mInference done 1214/1257. 0.1223 s / img. ETA=0:00:05
[32m[04/20 03:20:56 d2.evaluation.evaluator]: [0mInference done 1254/1257. 0.1223 s / img. ETA=0:00:00
[32m[04/20 03:20:57 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:38.504388 (0.126601 s / img per device, on 1 devices)
[32m[04/20 03:20:57 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:33 (0.122249 s / img per device, on 1 devices)
[32m[04/20 03:20:57 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 03:20:57 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 03:20:57 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.49s).
Accumulating evaluation results...
DONE (t=0.44s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.185
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.364
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.166
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.108
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.231
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.450
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.092
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.222
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.224
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.274
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.487
[32m[04/20 03:21:01 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 18.537 | 36.415 | 16.589 | 10.760 | 23.073 | 44.962 |
[32m[04/20 03:21:01 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 26.055 | bicycle       | 6.843 | car            | 41.252 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | 0.000 | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  12  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 03:21:02 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 03:21:02 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 03:21:02 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/20 03:21:03 d2.data.build]: [0mRemoved 889 images with no usable annotations. 7466 images left.
[32m[04/20 03:21:03 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 03:21:03 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 03:21:03 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 03:21:15 d2.utils.events]: [0m eta: 0:09:05  iter: 19  total_loss: 0.844  loss_cls: 0.278  loss_box_reg: 0.462  loss_rpn_cls: 0.029  loss_rpn_loc: 0.077  time: 0.5594  data_time: 0.0297  lr: 0.000100  max_mem: 3094M
[32m[04/20 03:21:25 d2.utils.events]: [0m eta: 0:08:38  iter: 39  total_loss: 0.753  loss_cls: 0.252  loss_box_reg: 0.408  loss_rpn_cls: 0.039  loss_rpn_loc: 0.075  time: 0.5403  data_time: 0.0067  lr: 0.000200  max_mem: 3094M
[32m[04/20 03:21:36 d2.utils.events]: [0m eta: 0:08:27  iter: 59  total_loss: 0.775  loss_cls: 0.244  loss_box_reg: 0.386  loss_rpn_cls: 0.022  loss_rpn_loc: 0.061  time: 0.5397  data_time: 0.0062  lr: 0.000300  max_mem: 3094M
[32m[04/20 03:21:47 d2.utils.events]: [0m eta: 0:08:17  iter: 79  total_loss: 0.709  loss_cls: 0.230  loss_box_reg: 0.392  loss_rpn_cls: 0.019  loss_rpn_loc: 0.058  time: 0.5383  data_time: 0.0084  lr: 0.000400  max_mem: 3094M
[32m[04/20 03:21:58 d2.utils.events]: [0m eta: 0:08:07  iter: 99  total_loss: 0.760  loss_cls: 0.262  loss_box_reg: 0.384  loss_rpn_cls: 0.024  loss_rpn_loc: 0.055  time: 0.5379  data_time: 0.0062  lr: 0.000500  max_mem: 3094M
[32m[04/20 03:22:08 d2.utils.events]: [0m eta: 0:07:58  iter: 119  total_loss: 0.776  loss_cls: 0.257  loss_box_reg: 0.413  loss_rpn_cls: 0.028  loss_rpn_loc: 0.065  time: 0.5372  data_time: 0.0067  lr: 0.000599  max_mem: 3094M
[32m[04/20 03:22:19 d2.utils.events]: [0m eta: 0:07:41  iter: 139  total_loss: 0.606  loss_cls: 0.189  loss_box_reg: 0.289  loss_rpn_cls: 0.027  loss_rpn_loc: 0.060  time: 0.5351  data_time: 0.0085  lr: 0.000699  max_mem: 3094M
[32m[04/20 03:22:30 d2.utils.events]: [0m eta: 0:07:29  iter: 159  total_loss: 0.563  loss_cls: 0.199  loss_box_reg: 0.312  loss_rpn_cls: 0.017  loss_rpn_loc: 0.060  time: 0.5347  data_time: 0.0061  lr: 0.000799  max_mem: 3094M
[32m[04/20 03:22:40 d2.utils.events]: [0m eta: 0:07:17  iter: 179  total_loss: 0.625  loss_cls: 0.210  loss_box_reg: 0.324  loss_rpn_cls: 0.023  loss_rpn_loc: 0.057  time: 0.5331  data_time: 0.0073  lr: 0.000899  max_mem: 3094M
[32m[04/20 03:22:51 d2.utils.events]: [0m eta: 0:07:08  iter: 199  total_loss: 0.658  loss_cls: 0.226  loss_box_reg: 0.357  loss_rpn_cls: 0.017  loss_rpn_loc: 0.056  time: 0.5350  data_time: 0.0065  lr: 0.000999  max_mem: 3094M
[32m[04/20 03:23:02 d2.utils.events]: [0m eta: 0:06:58  iter: 219  total_loss: 0.527  loss_cls: 0.184  loss_box_reg: 0.273  loss_rpn_cls: 0.018  loss_rpn_loc: 0.053  time: 0.5357  data_time: 0.0071  lr: 0.001099  max_mem: 3094M
[32m[04/20 03:23:13 d2.utils.events]: [0m eta: 0:06:48  iter: 239  total_loss: 0.737  loss_cls: 0.225  loss_box_reg: 0.367  loss_rpn_cls: 0.028  loss_rpn_loc: 0.057  time: 0.5375  data_time: 0.0090  lr: 0.001199  max_mem: 3094M
[32m[04/20 03:23:25 d2.utils.events]: [0m eta: 0:06:40  iter: 259  total_loss: 0.749  loss_cls: 0.240  loss_box_reg: 0.402  loss_rpn_cls: 0.023  loss_rpn_loc: 0.059  time: 0.5395  data_time: 0.0075  lr: 0.001299  max_mem: 3094M
[32m[04/20 03:23:35 d2.utils.events]: [0m eta: 0:06:28  iter: 279  total_loss: 0.645  loss_cls: 0.211  loss_box_reg: 0.361  loss_rpn_cls: 0.021  loss_rpn_loc: 0.049  time: 0.5378  data_time: 0.0065  lr: 0.001399  max_mem: 3094M
[32m[04/20 03:23:45 d2.utils.events]: [0m eta: 0:06:16  iter: 299  total_loss: 0.671  loss_cls: 0.219  loss_box_reg: 0.364  loss_rpn_cls: 0.019  loss_rpn_loc: 0.065  time: 0.5356  data_time: 0.0084  lr: 0.001499  max_mem: 3094M
[32m[04/20 03:23:56 d2.utils.events]: [0m eta: 0:06:04  iter: 319  total_loss: 0.642  loss_cls: 0.213  loss_box_reg: 0.354  loss_rpn_cls: 0.015  loss_rpn_loc: 0.064  time: 0.5354  data_time: 0.0090  lr: 0.001598  max_mem: 3094M
[32m[04/20 03:24:07 d2.utils.events]: [0m eta: 0:05:54  iter: 339  total_loss: 0.588  loss_cls: 0.202  loss_box_reg: 0.344  loss_rpn_cls: 0.011  loss_rpn_loc: 0.038  time: 0.5360  data_time: 0.0076  lr: 0.001698  max_mem: 3094M
[32m[04/20 03:24:18 d2.utils.events]: [0m eta: 0:05:43  iter: 359  total_loss: 0.610  loss_cls: 0.218  loss_box_reg: 0.335  loss_rpn_cls: 0.022  loss_rpn_loc: 0.050  time: 0.5360  data_time: 0.0084  lr: 0.001798  max_mem: 3094M
[32m[04/20 03:24:28 d2.utils.events]: [0m eta: 0:05:33  iter: 379  total_loss: 0.569  loss_cls: 0.199  loss_box_reg: 0.331  loss_rpn_cls: 0.017  loss_rpn_loc: 0.037  time: 0.5360  data_time: 0.0065  lr: 0.001898  max_mem: 3094M
[32m[04/20 03:24:39 d2.utils.events]: [0m eta: 0:05:22  iter: 399  total_loss: 0.626  loss_cls: 0.195  loss_box_reg: 0.355  loss_rpn_cls: 0.017  loss_rpn_loc: 0.042  time: 0.5357  data_time: 0.0078  lr: 0.001998  max_mem: 3094M
[32m[04/20 03:24:50 d2.utils.events]: [0m eta: 0:05:11  iter: 419  total_loss: 0.694  loss_cls: 0.222  loss_box_reg: 0.398  loss_rpn_cls: 0.017  loss_rpn_loc: 0.067  time: 0.5350  data_time: 0.0072  lr: 0.002098  max_mem: 3094M
[32m[04/20 03:25:00 d2.utils.events]: [0m eta: 0:05:00  iter: 439  total_loss: 0.685  loss_cls: 0.216  loss_box_reg: 0.383  loss_rpn_cls: 0.020  loss_rpn_loc: 0.044  time: 0.5350  data_time: 0.0081  lr: 0.002198  max_mem: 3094M
[32m[04/20 03:25:11 d2.utils.events]: [0m eta: 0:04:50  iter: 459  total_loss: 0.593  loss_cls: 0.180  loss_box_reg: 0.318  loss_rpn_cls: 0.018  loss_rpn_loc: 0.052  time: 0.5352  data_time: 0.0078  lr: 0.002298  max_mem: 3094M
[32m[04/20 03:25:22 d2.utils.events]: [0m eta: 0:04:39  iter: 479  total_loss: 0.602  loss_cls: 0.200  loss_box_reg: 0.333  loss_rpn_cls: 0.017  loss_rpn_loc: 0.053  time: 0.5354  data_time: 0.0063  lr: 0.002398  max_mem: 3094M
[32m[04/20 03:25:33 d2.utils.events]: [0m eta: 0:04:28  iter: 499  total_loss: 0.743  loss_cls: 0.222  loss_box_reg: 0.428  loss_rpn_cls: 0.018  loss_rpn_loc: 0.073  time: 0.5357  data_time: 0.0070  lr: 0.002498  max_mem: 3094M
[32m[04/20 03:25:44 d2.utils.events]: [0m eta: 0:04:18  iter: 519  total_loss: 0.644  loss_cls: 0.210  loss_box_reg: 0.335  loss_rpn_cls: 0.017  loss_rpn_loc: 0.052  time: 0.5358  data_time: 0.0072  lr: 0.002597  max_mem: 3094M
[32m[04/20 03:25:55 d2.utils.events]: [0m eta: 0:04:07  iter: 539  total_loss: 0.729  loss_cls: 0.224  loss_box_reg: 0.403  loss_rpn_cls: 0.025  loss_rpn_loc: 0.079  time: 0.5357  data_time: 0.0106  lr: 0.002697  max_mem: 3094M
[32m[04/20 03:26:06 d2.utils.events]: [0m eta: 0:03:57  iter: 559  total_loss: 0.766  loss_cls: 0.277  loss_box_reg: 0.405  loss_rpn_cls: 0.027  loss_rpn_loc: 0.057  time: 0.5363  data_time: 0.0080  lr: 0.002797  max_mem: 3094M
[32m[04/20 03:26:16 d2.utils.events]: [0m eta: 0:03:46  iter: 579  total_loss: 0.768  loss_cls: 0.255  loss_box_reg: 0.405  loss_rpn_cls: 0.021  loss_rpn_loc: 0.058  time: 0.5362  data_time: 0.0072  lr: 0.002897  max_mem: 3094M
[32m[04/20 03:26:27 d2.utils.events]: [0m eta: 0:03:35  iter: 599  total_loss: 0.625  loss_cls: 0.192  loss_box_reg: 0.336  loss_rpn_cls: 0.015  loss_rpn_loc: 0.050  time: 0.5366  data_time: 0.0065  lr: 0.002997  max_mem: 3094M
[32m[04/20 03:26:38 d2.utils.events]: [0m eta: 0:03:25  iter: 619  total_loss: 0.685  loss_cls: 0.227  loss_box_reg: 0.354  loss_rpn_cls: 0.024  loss_rpn_loc: 0.060  time: 0.5364  data_time: 0.0065  lr: 0.003097  max_mem: 3094M
[32m[04/20 03:26:49 d2.utils.events]: [0m eta: 0:03:14  iter: 639  total_loss: 0.684  loss_cls: 0.225  loss_box_reg: 0.340  loss_rpn_cls: 0.019  loss_rpn_loc: 0.050  time: 0.5369  data_time: 0.0077  lr: 0.003197  max_mem: 3094M
[32m[04/20 03:27:00 d2.utils.events]: [0m eta: 0:03:03  iter: 659  total_loss: 0.634  loss_cls: 0.205  loss_box_reg: 0.337  loss_rpn_cls: 0.027  loss_rpn_loc: 0.070  time: 0.5365  data_time: 0.0067  lr: 0.003297  max_mem: 3094M
[32m[04/20 03:27:10 d2.utils.events]: [0m eta: 0:02:52  iter: 679  total_loss: 0.655  loss_cls: 0.198  loss_box_reg: 0.331  loss_rpn_cls: 0.028  loss_rpn_loc: 0.067  time: 0.5362  data_time: 0.0084  lr: 0.003397  max_mem: 3094M
[32m[04/20 03:27:21 d2.utils.events]: [0m eta: 0:02:41  iter: 699  total_loss: 0.648  loss_cls: 0.217  loss_box_reg: 0.344  loss_rpn_cls: 0.022  loss_rpn_loc: 0.062  time: 0.5365  data_time: 0.0075  lr: 0.003497  max_mem: 3094M
[32m[04/20 03:27:32 d2.utils.events]: [0m eta: 0:02:31  iter: 719  total_loss: 0.677  loss_cls: 0.212  loss_box_reg: 0.396  loss_rpn_cls: 0.019  loss_rpn_loc: 0.047  time: 0.5364  data_time: 0.0064  lr: 0.003596  max_mem: 3094M
[32m[04/20 03:27:43 d2.utils.events]: [0m eta: 0:02:20  iter: 739  total_loss: 0.677  loss_cls: 0.220  loss_box_reg: 0.371  loss_rpn_cls: 0.021  loss_rpn_loc: 0.060  time: 0.5368  data_time: 0.0078  lr: 0.003696  max_mem: 3094M
[32m[04/20 03:27:54 d2.utils.events]: [0m eta: 0:02:09  iter: 759  total_loss: 0.631  loss_cls: 0.222  loss_box_reg: 0.365  loss_rpn_cls: 0.019  loss_rpn_loc: 0.052  time: 0.5365  data_time: 0.0064  lr: 0.003796  max_mem: 3094M
[32m[04/20 03:28:05 d2.utils.events]: [0m eta: 0:01:58  iter: 779  total_loss: 0.726  loss_cls: 0.229  loss_box_reg: 0.410  loss_rpn_cls: 0.022  loss_rpn_loc: 0.055  time: 0.5371  data_time: 0.0073  lr: 0.003896  max_mem: 3094M
[32m[04/20 03:28:16 d2.utils.events]: [0m eta: 0:01:48  iter: 799  total_loss: 0.648  loss_cls: 0.229  loss_box_reg: 0.308  loss_rpn_cls: 0.029  loss_rpn_loc: 0.066  time: 0.5374  data_time: 0.0069  lr: 0.003996  max_mem: 3094M
[32m[04/20 03:28:27 d2.utils.events]: [0m eta: 0:01:37  iter: 819  total_loss: 0.750  loss_cls: 0.258  loss_box_reg: 0.401  loss_rpn_cls: 0.024  loss_rpn_loc: 0.054  time: 0.5374  data_time: 0.0070  lr: 0.004096  max_mem: 3094M
[32m[04/20 03:28:38 d2.utils.events]: [0m eta: 0:01:26  iter: 839  total_loss: 0.699  loss_cls: 0.211  loss_box_reg: 0.361  loss_rpn_cls: 0.032  loss_rpn_loc: 0.060  time: 0.5374  data_time: 0.0070  lr: 0.004196  max_mem: 3094M
[32m[04/20 03:28:48 d2.utils.events]: [0m eta: 0:01:15  iter: 859  total_loss: 0.729  loss_cls: 0.224  loss_box_reg: 0.385  loss_rpn_cls: 0.028  loss_rpn_loc: 0.072  time: 0.5375  data_time: 0.0088  lr: 0.004296  max_mem: 3094M
[32m[04/20 03:28:59 d2.utils.events]: [0m eta: 0:01:05  iter: 879  total_loss: 0.657  loss_cls: 0.214  loss_box_reg: 0.354  loss_rpn_cls: 0.016  loss_rpn_loc: 0.067  time: 0.5375  data_time: 0.0066  lr: 0.004396  max_mem: 3094M
[32m[04/20 03:29:10 d2.utils.events]: [0m eta: 0:00:54  iter: 899  total_loss: 0.554  loss_cls: 0.184  loss_box_reg: 0.302  loss_rpn_cls: 0.018  loss_rpn_loc: 0.051  time: 0.5377  data_time: 0.0086  lr: 0.004496  max_mem: 3094M
[32m[04/20 03:29:21 d2.utils.events]: [0m eta: 0:00:43  iter: 919  total_loss: 0.829  loss_cls: 0.298  loss_box_reg: 0.409  loss_rpn_cls: 0.026  loss_rpn_loc: 0.069  time: 0.5378  data_time: 0.0078  lr: 0.004595  max_mem: 3094M
[32m[04/20 03:29:32 d2.utils.events]: [0m eta: 0:00:32  iter: 939  total_loss: 0.585  loss_cls: 0.199  loss_box_reg: 0.321  loss_rpn_cls: 0.019  loss_rpn_loc: 0.049  time: 0.5375  data_time: 0.0071  lr: 0.004695  max_mem: 3094M
[32m[04/20 03:29:42 d2.utils.events]: [0m eta: 0:00:22  iter: 959  total_loss: 0.607  loss_cls: 0.186  loss_box_reg: 0.318  loss_rpn_cls: 0.031  loss_rpn_loc: 0.062  time: 0.5371  data_time: 0.0063  lr: 0.004795  max_mem: 3094M
[32m[04/20 03:29:53 d2.utils.events]: [0m eta: 0:00:11  iter: 979  total_loss: 0.522  loss_cls: 0.155  loss_box_reg: 0.276  loss_rpn_cls: 0.018  loss_rpn_loc: 0.047  time: 0.5370  data_time: 0.0080  lr: 0.004895  max_mem: 3094M
[5m[31mWARNING[0m [32m[04/20 03:30:08 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 03:30:08 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[5m[31mWARNING[0m [32m[04/20 03:30:08 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 03:30:08 d2.utils.events]: [0m eta: 0:00:00  iter: 999  total_loss: 0.766  loss_cls: 0.260  loss_box_reg: 0.424  loss_rpn_cls: 0.022  loss_rpn_loc: 0.080  time: 0.5369  data_time: 0.0072  lr: 0.004995  max_mem: 3094M
[32m[04/20 03:30:09 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:08:55 (0.5375 s / it)
[32m[04/20 03:30:09 d2.engine.hooks]: [0mTotal training time: 0:09:04 (0:00:08 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 03:30:15 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 03:30:15 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/20 03:30:15 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 03:30:17 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1233 s / img. ETA=0:17:33
[32m[04/20 03:30:23 d2.evaluation.evaluator]: [0mInference done 51/8355. 0.1233 s / img. ETA=0:17:36
[32m[04/20 03:30:28 d2.evaluation.evaluator]: [0mInference done 92/8355. 0.1218 s / img. ETA=0:17:21
[32m[04/20 03:30:33 d2.evaluation.evaluator]: [0mInference done 131/8355. 0.1222 s / img. ETA=0:17:22
[32m[04/20 03:30:38 d2.evaluation.evaluator]: [0mInference done 171/8355. 0.1221 s / img. ETA=0:17:15
[32m[04/20 03:30:43 d2.evaluation.evaluator]: [0mInference done 212/8355. 0.1218 s / img. ETA=0:17:10
[32m[04/20 03:30:48 d2.evaluation.evaluator]: [0mInference done 252/8355. 0.1219 s / img. ETA=0:17:04
[32m[04/20 03:30:53 d2.evaluation.evaluator]: [0mInference done 292/8355. 0.1220 s / img. ETA=0:17:01
[32m[04/20 03:30:58 d2.evaluation.evaluator]: [0mInference done 333/8355. 0.1218 s / img. ETA=0:16:53
[32m[04/20 03:31:03 d2.evaluation.evaluator]: [0mInference done 374/8355. 0.1215 s / img. ETA=0:16:45
[32m[04/20 03:31:08 d2.evaluation.evaluator]: [0mInference done 414/8355. 0.1215 s / img. ETA=0:16:39
[32m[04/20 03:31:13 d2.evaluation.evaluator]: [0mInference done 455/8355. 0.1214 s / img. ETA=0:16:33
[32m[04/20 03:31:18 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1214 s / img. ETA=0:16:29
[32m[04/20 03:31:23 d2.evaluation.evaluator]: [0mInference done 535/8355. 0.1215 s / img. ETA=0:16:24
[32m[04/20 03:31:29 d2.evaluation.evaluator]: [0mInference done 575/8355. 0.1216 s / img. ETA=0:16:20
[32m[04/20 03:31:34 d2.evaluation.evaluator]: [0mInference done 615/8355. 0.1215 s / img. ETA=0:16:14
[32m[04/20 03:31:39 d2.evaluation.evaluator]: [0mInference done 655/8355. 0.1215 s / img. ETA=0:16:09
[32m[04/20 03:31:44 d2.evaluation.evaluator]: [0mInference done 695/8355. 0.1216 s / img. ETA=0:16:05
[32m[04/20 03:31:49 d2.evaluation.evaluator]: [0mInference done 735/8355. 0.1215 s / img. ETA=0:16:00
[32m[04/20 03:31:54 d2.evaluation.evaluator]: [0mInference done 773/8355. 0.1218 s / img. ETA=0:15:57
[32m[04/20 03:31:59 d2.evaluation.evaluator]: [0mInference done 812/8355. 0.1221 s / img. ETA=0:15:54
[32m[04/20 03:32:04 d2.evaluation.evaluator]: [0mInference done 850/8355. 0.1223 s / img. ETA=0:15:51
[32m[04/20 03:32:09 d2.evaluation.evaluator]: [0mInference done 891/8355. 0.1222 s / img. ETA=0:15:45
[32m[04/20 03:32:14 d2.evaluation.evaluator]: [0mInference done 931/8355. 0.1222 s / img. ETA=0:15:40
[32m[04/20 03:32:19 d2.evaluation.evaluator]: [0mInference done 971/8355. 0.1221 s / img. ETA=0:15:35
[32m[04/20 03:32:24 d2.evaluation.evaluator]: [0mInference done 1011/8355. 0.1221 s / img. ETA=0:15:30
[32m[04/20 03:32:29 d2.evaluation.evaluator]: [0mInference done 1051/8355. 0.1221 s / img. ETA=0:15:25
[32m[04/20 03:32:34 d2.evaluation.evaluator]: [0mInference done 1092/8355. 0.1220 s / img. ETA=0:15:19
[32m[04/20 03:32:39 d2.evaluation.evaluator]: [0mInference done 1132/8355. 0.1220 s / img. ETA=0:15:14
[32m[04/20 03:32:45 d2.evaluation.evaluator]: [0mInference done 1173/8355. 0.1220 s / img. ETA=0:15:08
[32m[04/20 03:32:50 d2.evaluation.evaluator]: [0mInference done 1213/8355. 0.1220 s / img. ETA=0:15:03
[32m[04/20 03:32:55 d2.evaluation.evaluator]: [0mInference done 1253/8355. 0.1220 s / img. ETA=0:14:58
[32m[04/20 03:33:00 d2.evaluation.evaluator]: [0mInference done 1294/8355. 0.1219 s / img. ETA=0:14:52
[32m[04/20 03:33:05 d2.evaluation.evaluator]: [0mInference done 1334/8355. 0.1219 s / img. ETA=0:14:47
[32m[04/20 03:33:10 d2.evaluation.evaluator]: [0mInference done 1375/8355. 0.1218 s / img. ETA=0:14:41
[32m[04/20 03:33:15 d2.evaluation.evaluator]: [0mInference done 1417/8355. 0.1217 s / img. ETA=0:14:35
[32m[04/20 03:33:20 d2.evaluation.evaluator]: [0mInference done 1458/8355. 0.1217 s / img. ETA=0:14:29
[32m[04/20 03:33:25 d2.evaluation.evaluator]: [0mInference done 1498/8355. 0.1217 s / img. ETA=0:14:24
[32m[04/20 03:33:30 d2.evaluation.evaluator]: [0mInference done 1538/8355. 0.1217 s / img. ETA=0:14:19
[32m[04/20 03:33:35 d2.evaluation.evaluator]: [0mInference done 1579/8355. 0.1217 s / img. ETA=0:14:14
[32m[04/20 03:33:40 d2.evaluation.evaluator]: [0mInference done 1619/8355. 0.1217 s / img. ETA=0:14:09
[32m[04/20 03:33:45 d2.evaluation.evaluator]: [0mInference done 1659/8355. 0.1217 s / img. ETA=0:14:04
[32m[04/20 03:33:50 d2.evaluation.evaluator]: [0mInference done 1699/8355. 0.1217 s / img. ETA=0:13:59
[32m[04/20 03:33:55 d2.evaluation.evaluator]: [0mInference done 1739/8355. 0.1217 s / img. ETA=0:13:54
[32m[04/20 03:34:00 d2.evaluation.evaluator]: [0mInference done 1779/8355. 0.1217 s / img. ETA=0:13:49
[32m[04/20 03:34:06 d2.evaluation.evaluator]: [0mInference done 1819/8355. 0.1218 s / img. ETA=0:13:44
[32m[04/20 03:34:11 d2.evaluation.evaluator]: [0mInference done 1859/8355. 0.1218 s / img. ETA=0:13:39
[32m[04/20 03:34:16 d2.evaluation.evaluator]: [0mInference done 1899/8355. 0.1218 s / img. ETA=0:13:34
[32m[04/20 03:34:21 d2.evaluation.evaluator]: [0mInference done 1939/8355. 0.1218 s / img. ETA=0:13:29
[32m[04/20 03:34:26 d2.evaluation.evaluator]: [0mInference done 1980/8355. 0.1218 s / img. ETA=0:13:24
[32m[04/20 03:34:31 d2.evaluation.evaluator]: [0mInference done 2021/8355. 0.1217 s / img. ETA=0:13:18
[32m[04/20 03:34:36 d2.evaluation.evaluator]: [0mInference done 2061/8355. 0.1217 s / img. ETA=0:13:13
[32m[04/20 03:34:41 d2.evaluation.evaluator]: [0mInference done 2101/8355. 0.1217 s / img. ETA=0:13:08
[32m[04/20 03:34:46 d2.evaluation.evaluator]: [0mInference done 2142/8355. 0.1217 s / img. ETA=0:13:03
[32m[04/20 03:34:51 d2.evaluation.evaluator]: [0mInference done 2183/8355. 0.1217 s / img. ETA=0:12:57
[32m[04/20 03:34:56 d2.evaluation.evaluator]: [0mInference done 2223/8355. 0.1216 s / img. ETA=0:12:52
[32m[04/20 03:35:01 d2.evaluation.evaluator]: [0mInference done 2263/8355. 0.1216 s / img. ETA=0:12:47
[32m[04/20 03:35:06 d2.evaluation.evaluator]: [0mInference done 2303/8355. 0.1217 s / img. ETA=0:12:42
[32m[04/20 03:35:11 d2.evaluation.evaluator]: [0mInference done 2343/8355. 0.1217 s / img. ETA=0:12:37
[32m[04/20 03:35:16 d2.evaluation.evaluator]: [0mInference done 2384/8355. 0.1216 s / img. ETA=0:12:32
[32m[04/20 03:35:22 d2.evaluation.evaluator]: [0mInference done 2424/8355. 0.1217 s / img. ETA=0:12:27
[32m[04/20 03:35:27 d2.evaluation.evaluator]: [0mInference done 2464/8355. 0.1217 s / img. ETA=0:12:22
[32m[04/20 03:35:32 d2.evaluation.evaluator]: [0mInference done 2504/8355. 0.1217 s / img. ETA=0:12:17
[32m[04/20 03:35:37 d2.evaluation.evaluator]: [0mInference done 2544/8355. 0.1216 s / img. ETA=0:12:12
[32m[04/20 03:35:42 d2.evaluation.evaluator]: [0mInference done 2584/8355. 0.1216 s / img. ETA=0:12:07
[32m[04/20 03:35:47 d2.evaluation.evaluator]: [0mInference done 2624/8355. 0.1217 s / img. ETA=0:12:02
[32m[04/20 03:35:52 d2.evaluation.evaluator]: [0mInference done 2664/8355. 0.1217 s / img. ETA=0:11:57
[32m[04/20 03:35:57 d2.evaluation.evaluator]: [0mInference done 2704/8355. 0.1217 s / img. ETA=0:11:52
[32m[04/20 03:36:02 d2.evaluation.evaluator]: [0mInference done 2744/8355. 0.1217 s / img. ETA=0:11:47
[32m[04/20 03:36:07 d2.evaluation.evaluator]: [0mInference done 2783/8355. 0.1217 s / img. ETA=0:11:42
[32m[04/20 03:36:12 d2.evaluation.evaluator]: [0mInference done 2823/8355. 0.1217 s / img. ETA=0:11:37
[32m[04/20 03:36:17 d2.evaluation.evaluator]: [0mInference done 2862/8355. 0.1217 s / img. ETA=0:11:33
[32m[04/20 03:36:22 d2.evaluation.evaluator]: [0mInference done 2901/8355. 0.1218 s / img. ETA=0:11:28
[32m[04/20 03:36:27 d2.evaluation.evaluator]: [0mInference done 2941/8355. 0.1218 s / img. ETA=0:11:23
[32m[04/20 03:36:32 d2.evaluation.evaluator]: [0mInference done 2981/8355. 0.1218 s / img. ETA=0:11:18
[32m[04/20 03:36:37 d2.evaluation.evaluator]: [0mInference done 3021/8355. 0.1218 s / img. ETA=0:11:13
[32m[04/20 03:36:42 d2.evaluation.evaluator]: [0mInference done 3061/8355. 0.1218 s / img. ETA=0:11:08
[32m[04/20 03:36:48 d2.evaluation.evaluator]: [0mInference done 3101/8355. 0.1218 s / img. ETA=0:11:03
[32m[04/20 03:36:53 d2.evaluation.evaluator]: [0mInference done 3141/8355. 0.1218 s / img. ETA=0:10:58
[32m[04/20 03:36:58 d2.evaluation.evaluator]: [0mInference done 3182/8355. 0.1218 s / img. ETA=0:10:52
[32m[04/20 03:37:03 d2.evaluation.evaluator]: [0mInference done 3222/8355. 0.1218 s / img. ETA=0:10:47
[32m[04/20 03:37:08 d2.evaluation.evaluator]: [0mInference done 3262/8355. 0.1218 s / img. ETA=0:10:42
[32m[04/20 03:37:13 d2.evaluation.evaluator]: [0mInference done 3302/8355. 0.1218 s / img. ETA=0:10:37
[32m[04/20 03:37:18 d2.evaluation.evaluator]: [0mInference done 3342/8355. 0.1218 s / img. ETA=0:10:32
[32m[04/20 03:37:23 d2.evaluation.evaluator]: [0mInference done 3382/8355. 0.1218 s / img. ETA=0:10:27
[32m[04/20 03:37:28 d2.evaluation.evaluator]: [0mInference done 3422/8355. 0.1218 s / img. ETA=0:10:22
[32m[04/20 03:37:33 d2.evaluation.evaluator]: [0mInference done 3462/8355. 0.1218 s / img. ETA=0:10:17
[32m[04/20 03:37:38 d2.evaluation.evaluator]: [0mInference done 3501/8355. 0.1218 s / img. ETA=0:10:12
[32m[04/20 03:37:43 d2.evaluation.evaluator]: [0mInference done 3541/8355. 0.1218 s / img. ETA=0:10:07
[32m[04/20 03:37:48 d2.evaluation.evaluator]: [0mInference done 3581/8355. 0.1218 s / img. ETA=0:10:02
[32m[04/20 03:37:53 d2.evaluation.evaluator]: [0mInference done 3620/8355. 0.1218 s / img. ETA=0:09:58
[32m[04/20 03:37:58 d2.evaluation.evaluator]: [0mInference done 3660/8355. 0.1219 s / img. ETA=0:09:53
[32m[04/20 03:38:03 d2.evaluation.evaluator]: [0mInference done 3700/8355. 0.1218 s / img. ETA=0:09:47
[32m[04/20 03:38:08 d2.evaluation.evaluator]: [0mInference done 3740/8355. 0.1218 s / img. ETA=0:09:42
[32m[04/20 03:38:14 d2.evaluation.evaluator]: [0mInference done 3781/8355. 0.1218 s / img. ETA=0:09:37
[32m[04/20 03:38:19 d2.evaluation.evaluator]: [0mInference done 3821/8355. 0.1218 s / img. ETA=0:09:32
[32m[04/20 03:38:24 d2.evaluation.evaluator]: [0mInference done 3861/8355. 0.1218 s / img. ETA=0:09:27
[32m[04/20 03:38:29 d2.evaluation.evaluator]: [0mInference done 3901/8355. 0.1218 s / img. ETA=0:09:22
[32m[04/20 03:38:34 d2.evaluation.evaluator]: [0mInference done 3941/8355. 0.1219 s / img. ETA=0:09:17
[32m[04/20 03:38:39 d2.evaluation.evaluator]: [0mInference done 3981/8355. 0.1218 s / img. ETA=0:09:12
[32m[04/20 03:38:44 d2.evaluation.evaluator]: [0mInference done 4021/8355. 0.1218 s / img. ETA=0:09:07
[32m[04/20 03:38:49 d2.evaluation.evaluator]: [0mInference done 4061/8355. 0.1218 s / img. ETA=0:09:02
[32m[04/20 03:38:54 d2.evaluation.evaluator]: [0mInference done 4101/8355. 0.1218 s / img. ETA=0:08:57
[32m[04/20 03:38:59 d2.evaluation.evaluator]: [0mInference done 4142/8355. 0.1218 s / img. ETA=0:08:52
[32m[04/20 03:39:04 d2.evaluation.evaluator]: [0mInference done 4181/8355. 0.1218 s / img. ETA=0:08:47
[32m[04/20 03:39:09 d2.evaluation.evaluator]: [0mInference done 4222/8355. 0.1218 s / img. ETA=0:08:41
[32m[04/20 03:39:14 d2.evaluation.evaluator]: [0mInference done 4262/8355. 0.1218 s / img. ETA=0:08:36
[32m[04/20 03:39:19 d2.evaluation.evaluator]: [0mInference done 4302/8355. 0.1218 s / img. ETA=0:08:31
[32m[04/20 03:39:25 d2.evaluation.evaluator]: [0mInference done 4343/8355. 0.1218 s / img. ETA=0:08:26
[32m[04/20 03:39:30 d2.evaluation.evaluator]: [0mInference done 4384/8355. 0.1218 s / img. ETA=0:08:21
[32m[04/20 03:39:35 d2.evaluation.evaluator]: [0mInference done 4424/8355. 0.1218 s / img. ETA=0:08:16
[32m[04/20 03:39:40 d2.evaluation.evaluator]: [0mInference done 4464/8355. 0.1218 s / img. ETA=0:08:11
[32m[04/20 03:39:45 d2.evaluation.evaluator]: [0mInference done 4504/8355. 0.1218 s / img. ETA=0:08:06
[32m[04/20 03:39:50 d2.evaluation.evaluator]: [0mInference done 4544/8355. 0.1218 s / img. ETA=0:08:01
[32m[04/20 03:39:55 d2.evaluation.evaluator]: [0mInference done 4583/8355. 0.1219 s / img. ETA=0:07:56
[32m[04/20 03:40:00 d2.evaluation.evaluator]: [0mInference done 4623/8355. 0.1219 s / img. ETA=0:07:51
[32m[04/20 03:40:05 d2.evaluation.evaluator]: [0mInference done 4663/8355. 0.1219 s / img. ETA=0:07:46
[32m[04/20 03:40:10 d2.evaluation.evaluator]: [0mInference done 4703/8355. 0.1219 s / img. ETA=0:07:41
[32m[04/20 03:40:15 d2.evaluation.evaluator]: [0mInference done 4743/8355. 0.1219 s / img. ETA=0:07:36
[32m[04/20 03:40:20 d2.evaluation.evaluator]: [0mInference done 4783/8355. 0.1219 s / img. ETA=0:07:31
[32m[04/20 03:40:26 d2.evaluation.evaluator]: [0mInference done 4824/8355. 0.1219 s / img. ETA=0:07:26
[32m[04/20 03:40:31 d2.evaluation.evaluator]: [0mInference done 4864/8355. 0.1219 s / img. ETA=0:07:21
[32m[04/20 03:40:36 d2.evaluation.evaluator]: [0mInference done 4905/8355. 0.1219 s / img. ETA=0:07:15
[32m[04/20 03:40:41 d2.evaluation.evaluator]: [0mInference done 4945/8355. 0.1219 s / img. ETA=0:07:10
[32m[04/20 03:40:46 d2.evaluation.evaluator]: [0mInference done 4985/8355. 0.1219 s / img. ETA=0:07:05
[32m[04/20 03:40:51 d2.evaluation.evaluator]: [0mInference done 5025/8355. 0.1219 s / img. ETA=0:07:00
[32m[04/20 03:40:56 d2.evaluation.evaluator]: [0mInference done 5065/8355. 0.1219 s / img. ETA=0:06:55
[32m[04/20 03:41:01 d2.evaluation.evaluator]: [0mInference done 5106/8355. 0.1219 s / img. ETA=0:06:50
[32m[04/20 03:41:06 d2.evaluation.evaluator]: [0mInference done 5146/8355. 0.1219 s / img. ETA=0:06:45
[32m[04/20 03:41:11 d2.evaluation.evaluator]: [0mInference done 5186/8355. 0.1219 s / img. ETA=0:06:40
[32m[04/20 03:41:16 d2.evaluation.evaluator]: [0mInference done 5226/8355. 0.1219 s / img. ETA=0:06:35
[32m[04/20 03:41:21 d2.evaluation.evaluator]: [0mInference done 5266/8355. 0.1218 s / img. ETA=0:06:30
[32m[04/20 03:41:26 d2.evaluation.evaluator]: [0mInference done 5306/8355. 0.1218 s / img. ETA=0:06:25
[32m[04/20 03:41:31 d2.evaluation.evaluator]: [0mInference done 5346/8355. 0.1218 s / img. ETA=0:06:20
[32m[04/20 03:41:37 d2.evaluation.evaluator]: [0mInference done 5385/8355. 0.1219 s / img. ETA=0:06:15
[32m[04/20 03:41:42 d2.evaluation.evaluator]: [0mInference done 5425/8355. 0.1219 s / img. ETA=0:06:10
[32m[04/20 03:41:47 d2.evaluation.evaluator]: [0mInference done 5465/8355. 0.1219 s / img. ETA=0:06:05
[32m[04/20 03:41:52 d2.evaluation.evaluator]: [0mInference done 5505/8355. 0.1219 s / img. ETA=0:06:00
[32m[04/20 03:41:57 d2.evaluation.evaluator]: [0mInference done 5533/8355. 0.1219 s / img. ETA=0:05:57
[32m[04/20 03:42:02 d2.evaluation.evaluator]: [0mInference done 5574/8355. 0.1219 s / img. ETA=0:05:52
[32m[04/20 03:42:07 d2.evaluation.evaluator]: [0mInference done 5615/8355. 0.1219 s / img. ETA=0:05:46
[32m[04/20 03:42:12 d2.evaluation.evaluator]: [0mInference done 5655/8355. 0.1219 s / img. ETA=0:05:41
[32m[04/20 03:42:17 d2.evaluation.evaluator]: [0mInference done 5695/8355. 0.1219 s / img. ETA=0:05:36
[32m[04/20 03:42:22 d2.evaluation.evaluator]: [0mInference done 5736/8355. 0.1219 s / img. ETA=0:05:31
[32m[04/20 03:42:27 d2.evaluation.evaluator]: [0mInference done 5776/8355. 0.1219 s / img. ETA=0:05:26
[32m[04/20 03:42:32 d2.evaluation.evaluator]: [0mInference done 5816/8355. 0.1219 s / img. ETA=0:05:21
[32m[04/20 03:42:37 d2.evaluation.evaluator]: [0mInference done 5856/8355. 0.1219 s / img. ETA=0:05:16
[32m[04/20 03:42:43 d2.evaluation.evaluator]: [0mInference done 5897/8355. 0.1219 s / img. ETA=0:05:11
[32m[04/20 03:42:48 d2.evaluation.evaluator]: [0mInference done 5937/8355. 0.1219 s / img. ETA=0:05:06
[32m[04/20 03:42:53 d2.evaluation.evaluator]: [0mInference done 5978/8355. 0.1218 s / img. ETA=0:05:00
[32m[04/20 03:42:58 d2.evaluation.evaluator]: [0mInference done 6018/8355. 0.1218 s / img. ETA=0:04:55
[32m[04/20 03:43:03 d2.evaluation.evaluator]: [0mInference done 6059/8355. 0.1218 s / img. ETA=0:04:50
[32m[04/20 03:43:08 d2.evaluation.evaluator]: [0mInference done 6099/8355. 0.1218 s / img. ETA=0:04:45
[32m[04/20 03:43:13 d2.evaluation.evaluator]: [0mInference done 6139/8355. 0.1218 s / img. ETA=0:04:40
[32m[04/20 03:43:18 d2.evaluation.evaluator]: [0mInference done 6179/8355. 0.1218 s / img. ETA=0:04:35
[32m[04/20 03:43:23 d2.evaluation.evaluator]: [0mInference done 6219/8355. 0.1218 s / img. ETA=0:04:30
[32m[04/20 03:43:28 d2.evaluation.evaluator]: [0mInference done 6260/8355. 0.1218 s / img. ETA=0:04:25
[32m[04/20 03:43:33 d2.evaluation.evaluator]: [0mInference done 6301/8355. 0.1218 s / img. ETA=0:04:19
[32m[04/20 03:43:38 d2.evaluation.evaluator]: [0mInference done 6342/8355. 0.1218 s / img. ETA=0:04:14
[32m[04/20 03:43:43 d2.evaluation.evaluator]: [0mInference done 6383/8355. 0.1218 s / img. ETA=0:04:09
[32m[04/20 03:43:48 d2.evaluation.evaluator]: [0mInference done 6423/8355. 0.1218 s / img. ETA=0:04:04
[32m[04/20 03:43:53 d2.evaluation.evaluator]: [0mInference done 6464/8355. 0.1218 s / img. ETA=0:03:59
[32m[04/20 03:43:58 d2.evaluation.evaluator]: [0mInference done 6505/8355. 0.1218 s / img. ETA=0:03:53
[32m[04/20 03:44:04 d2.evaluation.evaluator]: [0mInference done 6546/8355. 0.1218 s / img. ETA=0:03:48
[32m[04/20 03:44:09 d2.evaluation.evaluator]: [0mInference done 6587/8355. 0.1218 s / img. ETA=0:03:43
[32m[04/20 03:44:14 d2.evaluation.evaluator]: [0mInference done 6628/8355. 0.1218 s / img. ETA=0:03:38
[32m[04/20 03:44:19 d2.evaluation.evaluator]: [0mInference done 6669/8355. 0.1218 s / img. ETA=0:03:33
[32m[04/20 03:44:24 d2.evaluation.evaluator]: [0mInference done 6710/8355. 0.1217 s / img. ETA=0:03:27
[32m[04/20 03:44:29 d2.evaluation.evaluator]: [0mInference done 6751/8355. 0.1217 s / img. ETA=0:03:22
[32m[04/20 03:44:34 d2.evaluation.evaluator]: [0mInference done 6792/8355. 0.1217 s / img. ETA=0:03:17
[32m[04/20 03:44:39 d2.evaluation.evaluator]: [0mInference done 6833/8355. 0.1217 s / img. ETA=0:03:12
[32m[04/20 03:44:44 d2.evaluation.evaluator]: [0mInference done 6873/8355. 0.1217 s / img. ETA=0:03:07
[32m[04/20 03:44:49 d2.evaluation.evaluator]: [0mInference done 6914/8355. 0.1217 s / img. ETA=0:03:01
[32m[04/20 03:44:54 d2.evaluation.evaluator]: [0mInference done 6955/8355. 0.1217 s / img. ETA=0:02:56
[32m[04/20 03:44:59 d2.evaluation.evaluator]: [0mInference done 6995/8355. 0.1217 s / img. ETA=0:02:51
[32m[04/20 03:45:05 d2.evaluation.evaluator]: [0mInference done 7035/8355. 0.1217 s / img. ETA=0:02:46
[32m[04/20 03:45:10 d2.evaluation.evaluator]: [0mInference done 7075/8355. 0.1217 s / img. ETA=0:02:41
[32m[04/20 03:45:15 d2.evaluation.evaluator]: [0mInference done 7114/8355. 0.1217 s / img. ETA=0:02:36
[32m[04/20 03:45:20 d2.evaluation.evaluator]: [0mInference done 7154/8355. 0.1217 s / img. ETA=0:02:31
[32m[04/20 03:45:25 d2.evaluation.evaluator]: [0mInference done 7193/8355. 0.1218 s / img. ETA=0:02:26
[32m[04/20 03:45:30 d2.evaluation.evaluator]: [0mInference done 7233/8355. 0.1218 s / img. ETA=0:02:21
[32m[04/20 03:45:35 d2.evaluation.evaluator]: [0mInference done 7274/8355. 0.1218 s / img. ETA=0:02:16
[32m[04/20 03:45:40 d2.evaluation.evaluator]: [0mInference done 7314/8355. 0.1218 s / img. ETA=0:02:11
[32m[04/20 03:45:45 d2.evaluation.evaluator]: [0mInference done 7354/8355. 0.1218 s / img. ETA=0:02:06
[32m[04/20 03:45:50 d2.evaluation.evaluator]: [0mInference done 7393/8355. 0.1218 s / img. ETA=0:02:01
[32m[04/20 03:45:55 d2.evaluation.evaluator]: [0mInference done 7433/8355. 0.1218 s / img. ETA=0:01:56
[32m[04/20 03:46:00 d2.evaluation.evaluator]: [0mInference done 7473/8355. 0.1218 s / img. ETA=0:01:51
[32m[04/20 03:46:05 d2.evaluation.evaluator]: [0mInference done 7514/8355. 0.1218 s / img. ETA=0:01:46
[32m[04/20 03:46:10 d2.evaluation.evaluator]: [0mInference done 7554/8355. 0.1218 s / img. ETA=0:01:41
[32m[04/20 03:46:15 d2.evaluation.evaluator]: [0mInference done 7594/8355. 0.1218 s / img. ETA=0:01:36
[32m[04/20 03:46:20 d2.evaluation.evaluator]: [0mInference done 7634/8355. 0.1218 s / img. ETA=0:01:31
[32m[04/20 03:46:25 d2.evaluation.evaluator]: [0mInference done 7674/8355. 0.1218 s / img. ETA=0:01:26
[32m[04/20 03:46:30 d2.evaluation.evaluator]: [0mInference done 7714/8355. 0.1218 s / img. ETA=0:01:20
[32m[04/20 03:46:35 d2.evaluation.evaluator]: [0mInference done 7754/8355. 0.1218 s / img. ETA=0:01:15
[32m[04/20 03:46:40 d2.evaluation.evaluator]: [0mInference done 7794/8355. 0.1218 s / img. ETA=0:01:10
[32m[04/20 03:46:45 d2.evaluation.evaluator]: [0mInference done 7834/8355. 0.1218 s / img. ETA=0:01:05
[32m[04/20 03:46:50 d2.evaluation.evaluator]: [0mInference done 7874/8355. 0.1218 s / img. ETA=0:01:00
[32m[04/20 03:46:56 d2.evaluation.evaluator]: [0mInference done 7915/8355. 0.1218 s / img. ETA=0:00:55
[32m[04/20 03:47:01 d2.evaluation.evaluator]: [0mInference done 7956/8355. 0.1218 s / img. ETA=0:00:50
[32m[04/20 03:47:06 d2.evaluation.evaluator]: [0mInference done 7996/8355. 0.1218 s / img. ETA=0:00:45
[32m[04/20 03:47:11 d2.evaluation.evaluator]: [0mInference done 8036/8355. 0.1218 s / img. ETA=0:00:40
[32m[04/20 03:47:16 d2.evaluation.evaluator]: [0mInference done 8076/8355. 0.1218 s / img. ETA=0:00:35
[32m[04/20 03:47:21 d2.evaluation.evaluator]: [0mInference done 8116/8355. 0.1218 s / img. ETA=0:00:30
[32m[04/20 03:47:26 d2.evaluation.evaluator]: [0mInference done 8157/8355. 0.1218 s / img. ETA=0:00:24
[32m[04/20 03:47:31 d2.evaluation.evaluator]: [0mInference done 8198/8355. 0.1217 s / img. ETA=0:00:19
[32m[04/20 03:47:36 d2.evaluation.evaluator]: [0mInference done 8239/8355. 0.1217 s / img. ETA=0:00:14
[32m[04/20 03:47:41 d2.evaluation.evaluator]: [0mInference done 8279/8355. 0.1217 s / img. ETA=0:00:09
[32m[04/20 03:47:46 d2.evaluation.evaluator]: [0mInference done 8320/8355. 0.1217 s / img. ETA=0:00:04
[32m[04/20 03:47:51 d2.evaluation.evaluator]: [0mTotal inference time: 0:17:33.989234 (0.126226 s / img per device, on 1 devices)
[32m[04/20 03:47:51 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:56 (0.121724 s / img per device, on 1 devices)
[32m[04/20 03:47:51 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 03:47:51 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 03:47:51 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.59s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=26.89s).
Accumulating evaluation results...
DONE (t=4.04s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.264
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.572
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.205
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.193
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.354
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.551
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.151
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.327
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.266
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.426
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.594
[32m[04/20 03:48:23 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 26.383 | 57.159 | 20.545 | 19.259 | 35.429 | 55.099 |
[32m[04/20 03:48:23 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 31.715 | bicycle       | 16.583 | car            | 38.025 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | 19.211 | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 03:48:25 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 03:48:25 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[32m[04/20 03:48:25 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 03:48:26 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1236 s / img. ETA=0:02:38
[32m[04/20 03:48:31 d2.evaluation.evaluator]: [0mInference done 52/1257. 0.1205 s / img. ETA=0:02:29
[32m[04/20 03:48:37 d2.evaluation.evaluator]: [0mInference done 92/1257. 0.1208 s / img. ETA=0:02:25
[32m[04/20 03:48:42 d2.evaluation.evaluator]: [0mInference done 133/1257. 0.1205 s / img. ETA=0:02:19
[32m[04/20 03:48:47 d2.evaluation.evaluator]: [0mInference done 174/1257. 0.1205 s / img. ETA=0:02:14
[32m[04/20 03:48:52 d2.evaluation.evaluator]: [0mInference done 215/1257. 0.1205 s / img. ETA=0:02:09
[32m[04/20 03:48:57 d2.evaluation.evaluator]: [0mInference done 256/1257. 0.1204 s / img. ETA=0:02:04
[32m[04/20 03:49:02 d2.evaluation.evaluator]: [0mInference done 296/1257. 0.1208 s / img. ETA=0:01:59
[32m[04/20 03:49:07 d2.evaluation.evaluator]: [0mInference done 337/1257. 0.1208 s / img. ETA=0:01:54
[32m[04/20 03:49:12 d2.evaluation.evaluator]: [0mInference done 378/1257. 0.1207 s / img. ETA=0:01:49
[32m[04/20 03:49:17 d2.evaluation.evaluator]: [0mInference done 419/1257. 0.1206 s / img. ETA=0:01:44
[32m[04/20 03:49:22 d2.evaluation.evaluator]: [0mInference done 459/1257. 0.1208 s / img. ETA=0:01:39
[32m[04/20 03:49:27 d2.evaluation.evaluator]: [0mInference done 500/1257. 0.1208 s / img. ETA=0:01:34
[32m[04/20 03:49:32 d2.evaluation.evaluator]: [0mInference done 540/1257. 0.1209 s / img. ETA=0:01:29
[32m[04/20 03:49:37 d2.evaluation.evaluator]: [0mInference done 580/1257. 0.1210 s / img. ETA=0:01:24
[32m[04/20 03:49:43 d2.evaluation.evaluator]: [0mInference done 620/1257. 0.1211 s / img. ETA=0:01:19
[32m[04/20 03:49:48 d2.evaluation.evaluator]: [0mInference done 660/1257. 0.1212 s / img. ETA=0:01:14
[32m[04/20 03:49:53 d2.evaluation.evaluator]: [0mInference done 700/1257. 0.1212 s / img. ETA=0:01:09
[32m[04/20 03:49:58 d2.evaluation.evaluator]: [0mInference done 740/1257. 0.1212 s / img. ETA=0:01:04
[32m[04/20 03:50:03 d2.evaluation.evaluator]: [0mInference done 780/1257. 0.1213 s / img. ETA=0:00:59
[32m[04/20 03:50:08 d2.evaluation.evaluator]: [0mInference done 820/1257. 0.1213 s / img. ETA=0:00:54
[32m[04/20 03:50:13 d2.evaluation.evaluator]: [0mInference done 860/1257. 0.1213 s / img. ETA=0:00:49
[32m[04/20 03:50:18 d2.evaluation.evaluator]: [0mInference done 900/1257. 0.1214 s / img. ETA=0:00:44
[32m[04/20 03:50:23 d2.evaluation.evaluator]: [0mInference done 941/1257. 0.1214 s / img. ETA=0:00:39
[32m[04/20 03:50:28 d2.evaluation.evaluator]: [0mInference done 982/1257. 0.1214 s / img. ETA=0:00:34
[32m[04/20 03:50:33 d2.evaluation.evaluator]: [0mInference done 1023/1257. 0.1214 s / img. ETA=0:00:29
[32m[04/20 03:50:38 d2.evaluation.evaluator]: [0mInference done 1064/1257. 0.1213 s / img. ETA=0:00:24
[32m[04/20 03:50:43 d2.evaluation.evaluator]: [0mInference done 1104/1257. 0.1213 s / img. ETA=0:00:19
[32m[04/20 03:50:48 d2.evaluation.evaluator]: [0mInference done 1145/1257. 0.1213 s / img. ETA=0:00:14
[32m[04/20 03:50:54 d2.evaluation.evaluator]: [0mInference done 1186/1257. 0.1213 s / img. ETA=0:00:08
[32m[04/20 03:50:59 d2.evaluation.evaluator]: [0mInference done 1227/1257. 0.1213 s / img. ETA=0:00:03
[32m[04/20 03:51:03 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:36.940832 (0.125352 s / img per device, on 1 devices)
[32m[04/20 03:51:03 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:31 (0.121348 s / img per device, on 1 devices)
[32m[04/20 03:51:03 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 03:51:03 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 03:51:03 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.37s).
Accumulating evaluation results...
DONE (t=0.46s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.377
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.137
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.104
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.224
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.393
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.099
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.239
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.241
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.161
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.289
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.435
[32m[04/20 03:51:07 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 17.490 | 37.721 | 13.665 | 10.421 | 22.355 | 39.300 |
[32m[04/20 03:51:07 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 25.461 | bicycle       | 5.859 | car            | 38.282 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | 0.356 | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  13  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 03:51:08 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 03:51:08 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 03:51:08 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/20 03:51:09 d2.data.build]: [0mRemoved 889 images with no usable annotations. 7466 images left.
[32m[04/20 03:51:09 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 03:51:09 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 03:51:09 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 03:51:20 d2.utils.events]: [0m eta: 0:08:18  iter: 19  total_loss: 0.767  loss_cls: 0.264  loss_box_reg: 0.408  loss_rpn_cls: 0.023  loss_rpn_loc: 0.090  time: 0.5123  data_time: 0.0277  lr: 0.000100  max_mem: 3094M
[32m[04/20 03:51:30 d2.utils.events]: [0m eta: 0:08:29  iter: 39  total_loss: 0.632  loss_cls: 0.233  loss_box_reg: 0.352  loss_rpn_cls: 0.019  loss_rpn_loc: 0.039  time: 0.5294  data_time: 0.0081  lr: 0.000200  max_mem: 3094M
[32m[04/20 03:51:41 d2.utils.events]: [0m eta: 0:08:23  iter: 59  total_loss: 0.745  loss_cls: 0.249  loss_box_reg: 0.398  loss_rpn_cls: 0.026  loss_rpn_loc: 0.070  time: 0.5314  data_time: 0.0064  lr: 0.000300  max_mem: 3094M
[32m[04/20 03:51:52 d2.utils.events]: [0m eta: 0:08:11  iter: 79  total_loss: 0.591  loss_cls: 0.193  loss_box_reg: 0.326  loss_rpn_cls: 0.028  loss_rpn_loc: 0.051  time: 0.5314  data_time: 0.0093  lr: 0.000400  max_mem: 3094M
[32m[04/20 03:52:03 d2.utils.events]: [0m eta: 0:08:09  iter: 99  total_loss: 0.693  loss_cls: 0.219  loss_box_reg: 0.378  loss_rpn_cls: 0.025  loss_rpn_loc: 0.061  time: 0.5349  data_time: 0.0081  lr: 0.000500  max_mem: 3094M
[32m[04/20 03:52:14 d2.utils.events]: [0m eta: 0:07:56  iter: 119  total_loss: 0.544  loss_cls: 0.184  loss_box_reg: 0.286  loss_rpn_cls: 0.016  loss_rpn_loc: 0.049  time: 0.5353  data_time: 0.0072  lr: 0.000599  max_mem: 3094M
[32m[04/20 03:52:25 d2.utils.events]: [0m eta: 0:07:48  iter: 139  total_loss: 0.649  loss_cls: 0.213  loss_box_reg: 0.335  loss_rpn_cls: 0.018  loss_rpn_loc: 0.054  time: 0.5371  data_time: 0.0074  lr: 0.000699  max_mem: 3094M
[32m[04/20 03:52:36 d2.utils.events]: [0m eta: 0:07:38  iter: 159  total_loss: 0.650  loss_cls: 0.203  loss_box_reg: 0.365  loss_rpn_cls: 0.019  loss_rpn_loc: 0.047  time: 0.5381  data_time: 0.0066  lr: 0.000799  max_mem: 3094M
[32m[04/20 03:52:46 d2.utils.events]: [0m eta: 0:07:21  iter: 179  total_loss: 0.761  loss_cls: 0.242  loss_box_reg: 0.403  loss_rpn_cls: 0.019  loss_rpn_loc: 0.069  time: 0.5364  data_time: 0.0072  lr: 0.000899  max_mem: 3094M
[32m[04/20 03:52:57 d2.utils.events]: [0m eta: 0:07:08  iter: 199  total_loss: 0.505  loss_cls: 0.176  loss_box_reg: 0.268  loss_rpn_cls: 0.021  loss_rpn_loc: 0.044  time: 0.5354  data_time: 0.0064  lr: 0.000999  max_mem: 3094M
[32m[04/20 03:53:07 d2.utils.events]: [0m eta: 0:06:58  iter: 219  total_loss: 0.496  loss_cls: 0.189  loss_box_reg: 0.270  loss_rpn_cls: 0.016  loss_rpn_loc: 0.041  time: 0.5351  data_time: 0.0058  lr: 0.001099  max_mem: 3094M
[32m[04/20 03:53:18 d2.utils.events]: [0m eta: 0:06:46  iter: 239  total_loss: 0.622  loss_cls: 0.211  loss_box_reg: 0.355  loss_rpn_cls: 0.014  loss_rpn_loc: 0.046  time: 0.5344  data_time: 0.0068  lr: 0.001199  max_mem: 3094M
[32m[04/20 03:53:29 d2.utils.events]: [0m eta: 0:06:36  iter: 259  total_loss: 0.688  loss_cls: 0.223  loss_box_reg: 0.372  loss_rpn_cls: 0.024  loss_rpn_loc: 0.073  time: 0.5339  data_time: 0.0071  lr: 0.001299  max_mem: 3094M
[32m[04/20 03:53:40 d2.utils.events]: [0m eta: 0:06:25  iter: 279  total_loss: 0.694  loss_cls: 0.233  loss_box_reg: 0.386  loss_rpn_cls: 0.017  loss_rpn_loc: 0.048  time: 0.5342  data_time: 0.0066  lr: 0.001399  max_mem: 3094M
[32m[04/20 03:53:50 d2.utils.events]: [0m eta: 0:06:14  iter: 299  total_loss: 0.664  loss_cls: 0.228  loss_box_reg: 0.357  loss_rpn_cls: 0.023  loss_rpn_loc: 0.052  time: 0.5343  data_time: 0.0078  lr: 0.001499  max_mem: 3094M
[32m[04/20 03:54:01 d2.utils.events]: [0m eta: 0:06:03  iter: 319  total_loss: 0.526  loss_cls: 0.159  loss_box_reg: 0.303  loss_rpn_cls: 0.022  loss_rpn_loc: 0.039  time: 0.5337  data_time: 0.0077  lr: 0.001598  max_mem: 3094M
[32m[04/20 03:54:12 d2.utils.events]: [0m eta: 0:05:53  iter: 339  total_loss: 0.585  loss_cls: 0.210  loss_box_reg: 0.300  loss_rpn_cls: 0.017  loss_rpn_loc: 0.056  time: 0.5336  data_time: 0.0073  lr: 0.001698  max_mem: 3094M
[32m[04/20 03:54:22 d2.utils.events]: [0m eta: 0:05:42  iter: 359  total_loss: 0.601  loss_cls: 0.193  loss_box_reg: 0.322  loss_rpn_cls: 0.020  loss_rpn_loc: 0.050  time: 0.5340  data_time: 0.0067  lr: 0.001798  max_mem: 3094M
[32m[04/20 03:54:33 d2.utils.events]: [0m eta: 0:05:31  iter: 379  total_loss: 0.591  loss_cls: 0.197  loss_box_reg: 0.320  loss_rpn_cls: 0.017  loss_rpn_loc: 0.052  time: 0.5328  data_time: 0.0074  lr: 0.001898  max_mem: 3094M
[32m[04/20 03:54:44 d2.utils.events]: [0m eta: 0:05:20  iter: 399  total_loss: 0.657  loss_cls: 0.222  loss_box_reg: 0.358  loss_rpn_cls: 0.018  loss_rpn_loc: 0.050  time: 0.5333  data_time: 0.0077  lr: 0.001998  max_mem: 3094M
[32m[04/20 03:54:55 d2.utils.events]: [0m eta: 0:05:10  iter: 419  total_loss: 0.513  loss_cls: 0.187  loss_box_reg: 0.294  loss_rpn_cls: 0.017  loss_rpn_loc: 0.041  time: 0.5342  data_time: 0.0065  lr: 0.002098  max_mem: 3094M
[32m[04/20 03:55:05 d2.utils.events]: [0m eta: 0:04:59  iter: 439  total_loss: 0.680  loss_cls: 0.226  loss_box_reg: 0.369  loss_rpn_cls: 0.018  loss_rpn_loc: 0.056  time: 0.5342  data_time: 0.0072  lr: 0.002198  max_mem: 3094M
[32m[04/20 03:55:16 d2.utils.events]: [0m eta: 0:04:48  iter: 459  total_loss: 0.606  loss_cls: 0.201  loss_box_reg: 0.324  loss_rpn_cls: 0.015  loss_rpn_loc: 0.041  time: 0.5331  data_time: 0.0060  lr: 0.002298  max_mem: 3094M
[32m[04/20 03:55:27 d2.utils.events]: [0m eta: 0:04:37  iter: 479  total_loss: 0.646  loss_cls: 0.218  loss_box_reg: 0.359  loss_rpn_cls: 0.023  loss_rpn_loc: 0.056  time: 0.5338  data_time: 0.0063  lr: 0.002398  max_mem: 3094M
[32m[04/20 03:55:37 d2.utils.events]: [0m eta: 0:04:26  iter: 499  total_loss: 0.578  loss_cls: 0.202  loss_box_reg: 0.313  loss_rpn_cls: 0.016  loss_rpn_loc: 0.043  time: 0.5333  data_time: 0.0065  lr: 0.002498  max_mem: 3094M
[32m[04/20 03:55:48 d2.utils.events]: [0m eta: 0:04:16  iter: 519  total_loss: 0.671  loss_cls: 0.188  loss_box_reg: 0.376  loss_rpn_cls: 0.014  loss_rpn_loc: 0.052  time: 0.5334  data_time: 0.0063  lr: 0.002597  max_mem: 3094M
[32m[04/20 03:55:59 d2.utils.events]: [0m eta: 0:04:05  iter: 539  total_loss: 0.702  loss_cls: 0.238  loss_box_reg: 0.418  loss_rpn_cls: 0.022  loss_rpn_loc: 0.047  time: 0.5340  data_time: 0.0061  lr: 0.002697  max_mem: 3094M
[32m[04/20 03:56:10 d2.utils.events]: [0m eta: 0:03:55  iter: 559  total_loss: 0.662  loss_cls: 0.235  loss_box_reg: 0.345  loss_rpn_cls: 0.019  loss_rpn_loc: 0.059  time: 0.5340  data_time: 0.0067  lr: 0.002797  max_mem: 3094M
[32m[04/20 03:56:20 d2.utils.events]: [0m eta: 0:03:44  iter: 579  total_loss: 0.639  loss_cls: 0.192  loss_box_reg: 0.369  loss_rpn_cls: 0.019  loss_rpn_loc: 0.064  time: 0.5335  data_time: 0.0071  lr: 0.002897  max_mem: 3094M
[32m[04/20 03:56:31 d2.utils.events]: [0m eta: 0:03:33  iter: 599  total_loss: 0.719  loss_cls: 0.207  loss_box_reg: 0.396  loss_rpn_cls: 0.016  loss_rpn_loc: 0.081  time: 0.5336  data_time: 0.0079  lr: 0.002997  max_mem: 3094M
[32m[04/20 03:56:42 d2.utils.events]: [0m eta: 0:03:23  iter: 619  total_loss: 0.776  loss_cls: 0.270  loss_box_reg: 0.387  loss_rpn_cls: 0.021  loss_rpn_loc: 0.057  time: 0.5336  data_time: 0.0065  lr: 0.003097  max_mem: 3094M
[32m[04/20 03:56:53 d2.utils.events]: [0m eta: 0:03:12  iter: 639  total_loss: 0.739  loss_cls: 0.239  loss_box_reg: 0.407  loss_rpn_cls: 0.017  loss_rpn_loc: 0.071  time: 0.5343  data_time: 0.0066  lr: 0.003197  max_mem: 3094M
[32m[04/20 03:57:04 d2.utils.events]: [0m eta: 0:03:01  iter: 659  total_loss: 0.645  loss_cls: 0.205  loss_box_reg: 0.306  loss_rpn_cls: 0.024  loss_rpn_loc: 0.061  time: 0.5343  data_time: 0.0065  lr: 0.003297  max_mem: 3094M
[32m[04/20 03:57:14 d2.utils.events]: [0m eta: 0:02:51  iter: 679  total_loss: 0.636  loss_cls: 0.197  loss_box_reg: 0.365  loss_rpn_cls: 0.019  loss_rpn_loc: 0.057  time: 0.5339  data_time: 0.0073  lr: 0.003397  max_mem: 3094M
[32m[04/20 03:57:25 d2.utils.events]: [0m eta: 0:02:40  iter: 699  total_loss: 0.771  loss_cls: 0.231  loss_box_reg: 0.417  loss_rpn_cls: 0.026  loss_rpn_loc: 0.054  time: 0.5339  data_time: 0.0065  lr: 0.003497  max_mem: 3094M
[32m[04/20 03:57:36 d2.utils.events]: [0m eta: 0:02:29  iter: 719  total_loss: 0.649  loss_cls: 0.229  loss_box_reg: 0.354  loss_rpn_cls: 0.028  loss_rpn_loc: 0.066  time: 0.5339  data_time: 0.0065  lr: 0.003596  max_mem: 3094M
[32m[04/20 03:57:46 d2.utils.events]: [0m eta: 0:02:19  iter: 739  total_loss: 0.739  loss_cls: 0.235  loss_box_reg: 0.368  loss_rpn_cls: 0.025  loss_rpn_loc: 0.050  time: 0.5337  data_time: 0.0067  lr: 0.003696  max_mem: 3094M
[32m[04/20 03:57:57 d2.utils.events]: [0m eta: 0:02:08  iter: 759  total_loss: 0.710  loss_cls: 0.212  loss_box_reg: 0.363  loss_rpn_cls: 0.030  loss_rpn_loc: 0.053  time: 0.5338  data_time: 0.0077  lr: 0.003796  max_mem: 3094M
[32m[04/20 03:58:07 d2.utils.events]: [0m eta: 0:01:57  iter: 779  total_loss: 0.612  loss_cls: 0.212  loss_box_reg: 0.328  loss_rpn_cls: 0.021  loss_rpn_loc: 0.049  time: 0.5334  data_time: 0.0073  lr: 0.003896  max_mem: 3094M
[32m[04/20 03:58:18 d2.utils.events]: [0m eta: 0:01:46  iter: 799  total_loss: 0.762  loss_cls: 0.255  loss_box_reg: 0.418  loss_rpn_cls: 0.020  loss_rpn_loc: 0.067  time: 0.5331  data_time: 0.0075  lr: 0.003996  max_mem: 3094M
[32m[04/20 03:58:29 d2.utils.events]: [0m eta: 0:01:36  iter: 819  total_loss: 0.624  loss_cls: 0.231  loss_box_reg: 0.327  loss_rpn_cls: 0.020  loss_rpn_loc: 0.045  time: 0.5333  data_time: 0.0064  lr: 0.004096  max_mem: 3094M
[32m[04/20 03:58:39 d2.utils.events]: [0m eta: 0:01:25  iter: 839  total_loss: 0.627  loss_cls: 0.212  loss_box_reg: 0.316  loss_rpn_cls: 0.015  loss_rpn_loc: 0.054  time: 0.5331  data_time: 0.0069  lr: 0.004196  max_mem: 3094M
[32m[04/20 03:58:50 d2.utils.events]: [0m eta: 0:01:15  iter: 859  total_loss: 0.701  loss_cls: 0.220  loss_box_reg: 0.368  loss_rpn_cls: 0.023  loss_rpn_loc: 0.063  time: 0.5335  data_time: 0.0071  lr: 0.004296  max_mem: 3094M
[32m[04/20 03:59:02 d2.utils.events]: [0m eta: 0:01:04  iter: 879  total_loss: 0.857  loss_cls: 0.252  loss_box_reg: 0.459  loss_rpn_cls: 0.030  loss_rpn_loc: 0.068  time: 0.5340  data_time: 0.0060  lr: 0.004396  max_mem: 3094M
[32m[04/20 03:59:13 d2.utils.events]: [0m eta: 0:00:53  iter: 899  total_loss: 0.709  loss_cls: 0.230  loss_box_reg: 0.346  loss_rpn_cls: 0.032  loss_rpn_loc: 0.082  time: 0.5342  data_time: 0.0061  lr: 0.004496  max_mem: 3094M
[32m[04/20 03:59:24 d2.utils.events]: [0m eta: 0:00:43  iter: 919  total_loss: 0.751  loss_cls: 0.247  loss_box_reg: 0.370  loss_rpn_cls: 0.027  loss_rpn_loc: 0.064  time: 0.5346  data_time: 0.0080  lr: 0.004595  max_mem: 3094M
[32m[04/20 03:59:34 d2.utils.events]: [0m eta: 0:00:32  iter: 939  total_loss: 0.621  loss_cls: 0.208  loss_box_reg: 0.326  loss_rpn_cls: 0.022  loss_rpn_loc: 0.054  time: 0.5346  data_time: 0.0090  lr: 0.004695  max_mem: 3094M
[32m[04/20 03:59:45 d2.utils.events]: [0m eta: 0:00:21  iter: 959  total_loss: 0.698  loss_cls: 0.231  loss_box_reg: 0.389  loss_rpn_cls: 0.028  loss_rpn_loc: 0.065  time: 0.5345  data_time: 0.0062  lr: 0.004795  max_mem: 3094M
[32m[04/20 03:59:56 d2.utils.events]: [0m eta: 0:00:11  iter: 979  total_loss: 0.695  loss_cls: 0.257  loss_box_reg: 0.341  loss_rpn_cls: 0.023  loss_rpn_loc: 0.049  time: 0.5343  data_time: 0.0073  lr: 0.004895  max_mem: 3094M
[5m[31mWARNING[0m [32m[04/20 04:00:10 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 04:00:10 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel.json
[5m[31mWARNING[0m [32m[04/20 04:00:10 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 04:00:10 d2.utils.events]: [0m eta: 0:00:00  iter: 999  total_loss: 0.690  loss_cls: 0.236  loss_box_reg: 0.343  loss_rpn_cls: 0.033  loss_rpn_loc: 0.057  time: 0.5340  data_time: 0.0062  lr: 0.004995  max_mem: 3094M
[32m[04/20 04:00:11 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:08:52 (0.5345 s / it)
[32m[04/20 04:00:11 d2.engine.hooks]: [0mTotal training time: 0:09:00 (0:00:07 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 04:00:14 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 04:00:14 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel.json
[32m[04/20 04:00:14 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 04:00:16 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1247 s / img. ETA=0:17:45
[32m[04/20 04:00:21 d2.evaluation.evaluator]: [0mInference done 52/8355. 0.1207 s / img. ETA=0:17:10
[32m[04/20 04:00:26 d2.evaluation.evaluator]: [0mInference done 93/8355. 0.1204 s / img. ETA=0:17:05
[32m[04/20 04:00:31 d2.evaluation.evaluator]: [0mInference done 133/8355. 0.1207 s / img. ETA=0:17:03
[32m[04/20 04:00:37 d2.evaluation.evaluator]: [0mInference done 174/8355. 0.1209 s / img. ETA=0:16:59
[32m[04/20 04:00:42 d2.evaluation.evaluator]: [0mInference done 215/8355. 0.1208 s / img. ETA=0:16:53
[32m[04/20 04:00:47 d2.evaluation.evaluator]: [0mInference done 255/8355. 0.1207 s / img. ETA=0:16:52
[32m[04/20 04:00:52 d2.evaluation.evaluator]: [0mInference done 296/8355. 0.1206 s / img. ETA=0:16:45
[32m[04/20 04:00:57 d2.evaluation.evaluator]: [0mInference done 337/8355. 0.1205 s / img. ETA=0:16:38
[32m[04/20 04:01:02 d2.evaluation.evaluator]: [0mInference done 377/8355. 0.1206 s / img. ETA=0:16:34
[32m[04/20 04:01:07 d2.evaluation.evaluator]: [0mInference done 417/8355. 0.1208 s / img. ETA=0:16:31
[32m[04/20 04:01:12 d2.evaluation.evaluator]: [0mInference done 458/8355. 0.1207 s / img. ETA=0:16:25
[32m[04/20 04:01:17 d2.evaluation.evaluator]: [0mInference done 498/8355. 0.1207 s / img. ETA=0:16:20
[32m[04/20 04:01:22 d2.evaluation.evaluator]: [0mInference done 539/8355. 0.1207 s / img. ETA=0:16:14
[32m[04/20 04:01:27 d2.evaluation.evaluator]: [0mInference done 580/8355. 0.1206 s / img. ETA=0:16:09
[32m[04/20 04:01:32 d2.evaluation.evaluator]: [0mInference done 621/8355. 0.1206 s / img. ETA=0:16:04
[32m[04/20 04:01:37 d2.evaluation.evaluator]: [0mInference done 661/8355. 0.1207 s / img. ETA=0:16:00
[32m[04/20 04:01:43 d2.evaluation.evaluator]: [0mInference done 703/8355. 0.1206 s / img. ETA=0:15:53
[32m[04/20 04:01:48 d2.evaluation.evaluator]: [0mInference done 744/8355. 0.1205 s / img. ETA=0:15:48
[32m[04/20 04:01:53 d2.evaluation.evaluator]: [0mInference done 782/8355. 0.1207 s / img. ETA=0:15:46
[32m[04/20 04:01:58 d2.evaluation.evaluator]: [0mInference done 822/8355. 0.1208 s / img. ETA=0:15:42
[32m[04/20 04:02:03 d2.evaluation.evaluator]: [0mInference done 862/8355. 0.1209 s / img. ETA=0:15:38
[32m[04/20 04:02:08 d2.evaluation.evaluator]: [0mInference done 902/8355. 0.1210 s / img. ETA=0:15:33
[32m[04/20 04:02:13 d2.evaluation.evaluator]: [0mInference done 941/8355. 0.1211 s / img. ETA=0:15:30
[32m[04/20 04:02:18 d2.evaluation.evaluator]: [0mInference done 981/8355. 0.1211 s / img. ETA=0:15:25
[32m[04/20 04:02:23 d2.evaluation.evaluator]: [0mInference done 1021/8355. 0.1212 s / img. ETA=0:15:20
[32m[04/20 04:02:28 d2.evaluation.evaluator]: [0mInference done 1062/8355. 0.1211 s / img. ETA=0:15:14
[32m[04/20 04:02:33 d2.evaluation.evaluator]: [0mInference done 1102/8355. 0.1211 s / img. ETA=0:15:09
[32m[04/20 04:02:38 d2.evaluation.evaluator]: [0mInference done 1143/8355. 0.1211 s / img. ETA=0:15:04
[32m[04/20 04:02:43 d2.evaluation.evaluator]: [0mInference done 1183/8355. 0.1212 s / img. ETA=0:14:59
[32m[04/20 04:02:48 d2.evaluation.evaluator]: [0mInference done 1223/8355. 0.1212 s / img. ETA=0:14:55
[32m[04/20 04:02:53 d2.evaluation.evaluator]: [0mInference done 1263/8355. 0.1212 s / img. ETA=0:14:50
[32m[04/20 04:02:58 d2.evaluation.evaluator]: [0mInference done 1303/8355. 0.1212 s / img. ETA=0:14:45
[32m[04/20 04:03:03 d2.evaluation.evaluator]: [0mInference done 1344/8355. 0.1211 s / img. ETA=0:14:39
[32m[04/20 04:03:09 d2.evaluation.evaluator]: [0mInference done 1386/8355. 0.1211 s / img. ETA=0:14:33
[32m[04/20 04:03:14 d2.evaluation.evaluator]: [0mInference done 1428/8355. 0.1210 s / img. ETA=0:14:27
[32m[04/20 04:03:19 d2.evaluation.evaluator]: [0mInference done 1469/8355. 0.1209 s / img. ETA=0:14:21
[32m[04/20 04:03:24 d2.evaluation.evaluator]: [0mInference done 1509/8355. 0.1209 s / img. ETA=0:14:16
[32m[04/20 04:03:29 d2.evaluation.evaluator]: [0mInference done 1549/8355. 0.1210 s / img. ETA=0:14:11
[32m[04/20 04:03:34 d2.evaluation.evaluator]: [0mInference done 1589/8355. 0.1210 s / img. ETA=0:14:07
[32m[04/20 04:03:39 d2.evaluation.evaluator]: [0mInference done 1630/8355. 0.1210 s / img. ETA=0:14:01
[32m[04/20 04:03:44 d2.evaluation.evaluator]: [0mInference done 1670/8355. 0.1210 s / img. ETA=0:13:57
[32m[04/20 04:03:49 d2.evaluation.evaluator]: [0mInference done 1710/8355. 0.1211 s / img. ETA=0:13:52
[32m[04/20 04:03:54 d2.evaluation.evaluator]: [0mInference done 1751/8355. 0.1211 s / img. ETA=0:13:47
[32m[04/20 04:03:59 d2.evaluation.evaluator]: [0mInference done 1790/8355. 0.1212 s / img. ETA=0:13:42
[32m[04/20 04:04:04 d2.evaluation.evaluator]: [0mInference done 1830/8355. 0.1212 s / img. ETA=0:13:37
[32m[04/20 04:04:09 d2.evaluation.evaluator]: [0mInference done 1870/8355. 0.1212 s / img. ETA=0:13:33
[32m[04/20 04:04:14 d2.evaluation.evaluator]: [0mInference done 1910/8355. 0.1212 s / img. ETA=0:13:28
[32m[04/20 04:04:19 d2.evaluation.evaluator]: [0mInference done 1950/8355. 0.1213 s / img. ETA=0:13:23
[32m[04/20 04:04:25 d2.evaluation.evaluator]: [0mInference done 1990/8355. 0.1213 s / img. ETA=0:13:18
[32m[04/20 04:04:30 d2.evaluation.evaluator]: [0mInference done 2030/8355. 0.1213 s / img. ETA=0:13:13
[32m[04/20 04:04:35 d2.evaluation.evaluator]: [0mInference done 2068/8355. 0.1214 s / img. ETA=0:13:09
[32m[04/20 04:04:40 d2.evaluation.evaluator]: [0mInference done 2108/8355. 0.1214 s / img. ETA=0:13:04
[32m[04/20 04:04:45 d2.evaluation.evaluator]: [0mInference done 2147/8355. 0.1215 s / img. ETA=0:13:00
[32m[04/20 04:04:50 d2.evaluation.evaluator]: [0mInference done 2186/8355. 0.1215 s / img. ETA=0:12:55
[32m[04/20 04:04:55 d2.evaluation.evaluator]: [0mInference done 2226/8355. 0.1215 s / img. ETA=0:12:50
[32m[04/20 04:05:00 d2.evaluation.evaluator]: [0mInference done 2265/8355. 0.1215 s / img. ETA=0:12:45
[32m[04/20 04:05:05 d2.evaluation.evaluator]: [0mInference done 2305/8355. 0.1215 s / img. ETA=0:12:41
[32m[04/20 04:05:10 d2.evaluation.evaluator]: [0mInference done 2345/8355. 0.1216 s / img. ETA=0:12:36
[32m[04/20 04:05:15 d2.evaluation.evaluator]: [0mInference done 2385/8355. 0.1216 s / img. ETA=0:12:31
[32m[04/20 04:05:20 d2.evaluation.evaluator]: [0mInference done 2425/8355. 0.1216 s / img. ETA=0:12:26
[32m[04/20 04:05:25 d2.evaluation.evaluator]: [0mInference done 2465/8355. 0.1216 s / img. ETA=0:12:21
[32m[04/20 04:05:30 d2.evaluation.evaluator]: [0mInference done 2505/8355. 0.1216 s / img. ETA=0:12:16
[32m[04/20 04:05:35 d2.evaluation.evaluator]: [0mInference done 2545/8355. 0.1216 s / img. ETA=0:12:11
[32m[04/20 04:05:40 d2.evaluation.evaluator]: [0mInference done 2585/8355. 0.1216 s / img. ETA=0:12:06
[32m[04/20 04:05:45 d2.evaluation.evaluator]: [0mInference done 2626/8355. 0.1216 s / img. ETA=0:12:01
[32m[04/20 04:05:51 d2.evaluation.evaluator]: [0mInference done 2667/8355. 0.1216 s / img. ETA=0:11:55
[32m[04/20 04:05:56 d2.evaluation.evaluator]: [0mInference done 2707/8355. 0.1216 s / img. ETA=0:11:50
[32m[04/20 04:06:01 d2.evaluation.evaluator]: [0mInference done 2746/8355. 0.1216 s / img. ETA=0:11:46
[32m[04/20 04:06:06 d2.evaluation.evaluator]: [0mInference done 2786/8355. 0.1216 s / img. ETA=0:11:41
[32m[04/20 04:06:11 d2.evaluation.evaluator]: [0mInference done 2826/8355. 0.1216 s / img. ETA=0:11:36
[32m[04/20 04:06:16 d2.evaluation.evaluator]: [0mInference done 2865/8355. 0.1217 s / img. ETA=0:11:31
[32m[04/20 04:06:21 d2.evaluation.evaluator]: [0mInference done 2904/8355. 0.1217 s / img. ETA=0:11:26
[32m[04/20 04:06:26 d2.evaluation.evaluator]: [0mInference done 2943/8355. 0.1217 s / img. ETA=0:11:22
[32m[04/20 04:06:31 d2.evaluation.evaluator]: [0mInference done 2983/8355. 0.1218 s / img. ETA=0:11:17
[32m[04/20 04:06:36 d2.evaluation.evaluator]: [0mInference done 3024/8355. 0.1217 s / img. ETA=0:11:12
[32m[04/20 04:06:41 d2.evaluation.evaluator]: [0mInference done 3065/8355. 0.1217 s / img. ETA=0:11:06
[32m[04/20 04:06:46 d2.evaluation.evaluator]: [0mInference done 3105/8355. 0.1217 s / img. ETA=0:11:01
[32m[04/20 04:06:51 d2.evaluation.evaluator]: [0mInference done 3145/8355. 0.1217 s / img. ETA=0:10:56
[32m[04/20 04:06:56 d2.evaluation.evaluator]: [0mInference done 3185/8355. 0.1217 s / img. ETA=0:10:51
[32m[04/20 04:07:01 d2.evaluation.evaluator]: [0mInference done 3226/8355. 0.1217 s / img. ETA=0:10:46
[32m[04/20 04:07:06 d2.evaluation.evaluator]: [0mInference done 3266/8355. 0.1217 s / img. ETA=0:10:41
[32m[04/20 04:07:11 d2.evaluation.evaluator]: [0mInference done 3306/8355. 0.1217 s / img. ETA=0:10:36
[32m[04/20 04:07:17 d2.evaluation.evaluator]: [0mInference done 3347/8355. 0.1217 s / img. ETA=0:10:30
[32m[04/20 04:07:22 d2.evaluation.evaluator]: [0mInference done 3387/8355. 0.1217 s / img. ETA=0:10:25
[32m[04/20 04:07:27 d2.evaluation.evaluator]: [0mInference done 3426/8355. 0.1217 s / img. ETA=0:10:21
[32m[04/20 04:07:32 d2.evaluation.evaluator]: [0mInference done 3466/8355. 0.1217 s / img. ETA=0:10:16
[32m[04/20 04:07:37 d2.evaluation.evaluator]: [0mInference done 3506/8355. 0.1217 s / img. ETA=0:10:11
[32m[04/20 04:07:42 d2.evaluation.evaluator]: [0mInference done 3546/8355. 0.1217 s / img. ETA=0:10:06
[32m[04/20 04:07:47 d2.evaluation.evaluator]: [0mInference done 3586/8355. 0.1217 s / img. ETA=0:10:01
[32m[04/20 04:07:52 d2.evaluation.evaluator]: [0mInference done 3626/8355. 0.1217 s / img. ETA=0:09:56
[32m[04/20 04:07:57 d2.evaluation.evaluator]: [0mInference done 3666/8355. 0.1217 s / img. ETA=0:09:51
[32m[04/20 04:08:02 d2.evaluation.evaluator]: [0mInference done 3706/8355. 0.1217 s / img. ETA=0:09:46
[32m[04/20 04:08:07 d2.evaluation.evaluator]: [0mInference done 3746/8355. 0.1217 s / img. ETA=0:09:41
[32m[04/20 04:08:12 d2.evaluation.evaluator]: [0mInference done 3786/8355. 0.1218 s / img. ETA=0:09:36
[32m[04/20 04:08:18 d2.evaluation.evaluator]: [0mInference done 3826/8355. 0.1218 s / img. ETA=0:09:31
[32m[04/20 04:08:23 d2.evaluation.evaluator]: [0mInference done 3866/8355. 0.1218 s / img. ETA=0:09:26
[32m[04/20 04:08:28 d2.evaluation.evaluator]: [0mInference done 3907/8355. 0.1217 s / img. ETA=0:09:20
[32m[04/20 04:08:33 d2.evaluation.evaluator]: [0mInference done 3948/8355. 0.1217 s / img. ETA=0:09:15
[32m[04/20 04:08:38 d2.evaluation.evaluator]: [0mInference done 3988/8355. 0.1217 s / img. ETA=0:09:10
[32m[04/20 04:08:43 d2.evaluation.evaluator]: [0mInference done 4029/8355. 0.1217 s / img. ETA=0:09:05
[32m[04/20 04:08:48 d2.evaluation.evaluator]: [0mInference done 4069/8355. 0.1217 s / img. ETA=0:09:00
[32m[04/20 04:08:53 d2.evaluation.evaluator]: [0mInference done 4109/8355. 0.1217 s / img. ETA=0:08:55
[32m[04/20 04:08:58 d2.evaluation.evaluator]: [0mInference done 4149/8355. 0.1217 s / img. ETA=0:08:50
[32m[04/20 04:09:03 d2.evaluation.evaluator]: [0mInference done 4189/8355. 0.1217 s / img. ETA=0:08:45
[32m[04/20 04:09:08 d2.evaluation.evaluator]: [0mInference done 4229/8355. 0.1217 s / img. ETA=0:08:40
[32m[04/20 04:09:13 d2.evaluation.evaluator]: [0mInference done 4270/8355. 0.1217 s / img. ETA=0:08:34
[32m[04/20 04:09:18 d2.evaluation.evaluator]: [0mInference done 4310/8355. 0.1217 s / img. ETA=0:08:29
[32m[04/20 04:09:23 d2.evaluation.evaluator]: [0mInference done 4350/8355. 0.1217 s / img. ETA=0:08:24
[32m[04/20 04:09:28 d2.evaluation.evaluator]: [0mInference done 4390/8355. 0.1217 s / img. ETA=0:08:19
