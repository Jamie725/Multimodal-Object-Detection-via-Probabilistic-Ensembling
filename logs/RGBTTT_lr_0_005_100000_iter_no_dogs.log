../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
3 channel input
Require gradient = False for the first several layers of ResNet
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 05:17:24 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 05:17:25 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 05:17:25 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 05:17:25 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 05:17:25 d2.data.build]: [0mDistribution of instances among all 79 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 21744        |    bicycle    | 3806         |      car      | 39372        |
|  motorcycle   | 0            |   airplane    | 0            |      bus      | 0            |
|     train     | 0            |     truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant  | 0            |   stop sign   | 0            |
| parking meter | 0            |     bench     | 0            |     bird      | 0            |
|      cat      | 0            |      dog      | 0            |     horse     | 0            |
|     sheep     | 0            |      cow      | 0            |   elephant    | 0            |
|     bear      | 0            |     zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella    | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase    | 0            |    frisbee    | 0            |
|     skis      | 0            |   snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat  | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |   surfboard   | 0            | tennis racket | 0            |
|    bottle     | 0            |  wine glass   | 0            |      cup      | 0            |
|     fork      | 0            |     knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana     | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange     | 0            |   broccoli    | 0            |
|    carrot     | 0            |    hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake      | 0            |     chair     | 0            |
|     couch     | 0            | potted plant  | 0            |      bed      | 0            |
| dining table  | 0            |    toilet     | 0            |      tv       | 0            |
|    laptop     | 0            |     mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone   | 0            |   microwave   | 0            |
|     oven      | 0            |     bike      | 0            |    hydrant    | 0            |
|     motor     | 0            |     rider     | 0            |     light     | 0            |
|     sign      | 0            | motor vehicle | 0            |  human face   | 0            |
|  hair drier   | 0            |               |              |               |              |
|     total     | 64922        |               |              |               |              |[0m
[32m[04/20 05:17:25 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 05:17:25 d2.data.build]: [0mUsing training sampler TrainingSampler
============== The  0  *  1000  iterations ============
[32m[04/20 05:17:29 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 05:17:52 d2.utils.events]: [0m eta: 0:17:50  iter: 19  total_loss: 1.425  loss_cls: 0.406  loss_box_reg: 0.198  loss_rpn_cls: 0.888  loss_rpn_loc: 0.144  time: 1.0646  data_time: 0.0466  lr: 0.000100  max_mem: 5393M
[32m[04/20 05:18:13 d2.utils.events]: [0m eta: 0:17:09  iter: 39  total_loss: 0.728  loss_cls: 0.246  loss_box_reg: 0.182  loss_rpn_cls: 0.188  loss_rpn_loc: 0.104  time: 1.0504  data_time: 0.0177  lr: 0.000200  max_mem: 5393M
[32m[04/20 05:18:33 d2.utils.events]: [0m eta: 0:16:41  iter: 59  total_loss: 0.790  loss_cls: 0.271  loss_box_reg: 0.243  loss_rpn_cls: 0.150  loss_rpn_loc: 0.108  time: 1.0418  data_time: 0.0150  lr: 0.000300  max_mem: 5393M
[32m[04/20 05:18:54 d2.utils.events]: [0m eta: 0:16:07  iter: 79  total_loss: 0.678  loss_cls: 0.254  loss_box_reg: 0.242  loss_rpn_cls: 0.121  loss_rpn_loc: 0.079  time: 1.0355  data_time: 0.0178  lr: 0.000400  max_mem: 5393M
[32m[04/20 05:19:14 d2.utils.events]: [0m eta: 0:15:37  iter: 99  total_loss: 0.786  loss_cls: 0.277  loss_box_reg: 0.309  loss_rpn_cls: 0.123  loss_rpn_loc: 0.084  time: 1.0322  data_time: 0.0181  lr: 0.000500  max_mem: 5393M
[32m[04/20 05:19:35 d2.utils.events]: [0m eta: 0:15:15  iter: 119  total_loss: 0.783  loss_cls: 0.295  loss_box_reg: 0.314  loss_rpn_cls: 0.099  loss_rpn_loc: 0.086  time: 1.0312  data_time: 0.0194  lr: 0.000599  max_mem: 5393M
[32m[04/20 05:19:55 d2.utils.events]: [0m eta: 0:14:54  iter: 139  total_loss: 0.764  loss_cls: 0.278  loss_box_reg: 0.304  loss_rpn_cls: 0.092  loss_rpn_loc: 0.098  time: 1.0306  data_time: 0.0183  lr: 0.000699  max_mem: 5393M
[32m[04/20 05:20:15 d2.utils.events]: [0m eta: 0:14:22  iter: 159  total_loss: 0.838  loss_cls: 0.300  loss_box_reg: 0.340  loss_rpn_cls: 0.083  loss_rpn_loc: 0.065  time: 1.0259  data_time: 0.0188  lr: 0.000799  max_mem: 5393M
[32m[04/20 05:20:36 d2.utils.events]: [0m eta: 0:14:01  iter: 179  total_loss: 0.803  loss_cls: 0.286  loss_box_reg: 0.328  loss_rpn_cls: 0.077  loss_rpn_loc: 0.075  time: 1.0255  data_time: 0.0181  lr: 0.000899  max_mem: 5393M
[32m[04/20 05:20:56 d2.utils.events]: [0m eta: 0:13:41  iter: 199  total_loss: 0.745  loss_cls: 0.267  loss_box_reg: 0.306  loss_rpn_cls: 0.077  loss_rpn_loc: 0.082  time: 1.0262  data_time: 0.0143  lr: 0.000999  max_mem: 5393M
[32m[04/20 05:21:17 d2.utils.events]: [0m eta: 0:13:20  iter: 219  total_loss: 0.746  loss_cls: 0.270  loss_box_reg: 0.309  loss_rpn_cls: 0.071  loss_rpn_loc: 0.074  time: 1.0259  data_time: 0.0155  lr: 0.001099  max_mem: 5393M
[32m[04/20 05:21:38 d2.utils.events]: [0m eta: 0:13:00  iter: 239  total_loss: 0.778  loss_cls: 0.268  loss_box_reg: 0.348  loss_rpn_cls: 0.069  loss_rpn_loc: 0.089  time: 1.0272  data_time: 0.0195  lr: 0.001199  max_mem: 5393M
[32m[04/20 05:21:58 d2.utils.events]: [0m eta: 0:12:39  iter: 259  total_loss: 0.824  loss_cls: 0.316  loss_box_reg: 0.362  loss_rpn_cls: 0.077  loss_rpn_loc: 0.095  time: 1.0272  data_time: 0.0169  lr: 0.001299  max_mem: 5393M
[32m[04/20 05:22:19 d2.utils.events]: [0m eta: 0:12:19  iter: 279  total_loss: 0.813  loss_cls: 0.305  loss_box_reg: 0.348  loss_rpn_cls: 0.066  loss_rpn_loc: 0.076  time: 1.0275  data_time: 0.0162  lr: 0.001399  max_mem: 5393M
[32m[04/20 05:22:40 d2.utils.events]: [0m eta: 0:11:59  iter: 299  total_loss: 0.786  loss_cls: 0.287  loss_box_reg: 0.340  loss_rpn_cls: 0.058  loss_rpn_loc: 0.070  time: 1.0280  data_time: 0.0191  lr: 0.001499  max_mem: 5393M
[32m[04/20 05:23:00 d2.utils.events]: [0m eta: 0:11:39  iter: 319  total_loss: 0.761  loss_cls: 0.277  loss_box_reg: 0.351  loss_rpn_cls: 0.057  loss_rpn_loc: 0.075  time: 1.0281  data_time: 0.0183  lr: 0.001598  max_mem: 5393M
[32m[04/20 05:23:21 d2.utils.events]: [0m eta: 0:11:18  iter: 339  total_loss: 0.731  loss_cls: 0.285  loss_box_reg: 0.318  loss_rpn_cls: 0.062  loss_rpn_loc: 0.077  time: 1.0270  data_time: 0.0171  lr: 0.001698  max_mem: 5393M
[32m[04/20 05:23:42 d2.utils.events]: [0m eta: 0:10:58  iter: 359  total_loss: 0.712  loss_cls: 0.260  loss_box_reg: 0.270  loss_rpn_cls: 0.058  loss_rpn_loc: 0.067  time: 1.0278  data_time: 0.0179  lr: 0.001798  max_mem: 5393M
[32m[04/20 05:24:02 d2.utils.events]: [0m eta: 0:10:38  iter: 379  total_loss: 0.783  loss_cls: 0.277  loss_box_reg: 0.364  loss_rpn_cls: 0.057  loss_rpn_loc: 0.074  time: 1.0285  data_time: 0.0197  lr: 0.001898  max_mem: 5393M
[32m[04/20 05:24:23 d2.utils.events]: [0m eta: 0:10:18  iter: 399  total_loss: 0.828  loss_cls: 0.284  loss_box_reg: 0.388  loss_rpn_cls: 0.060  loss_rpn_loc: 0.093  time: 1.0285  data_time: 0.0176  lr: 0.001998  max_mem: 5393M
[32m[04/20 05:24:44 d2.utils.events]: [0m eta: 0:09:58  iter: 419  total_loss: 0.829  loss_cls: 0.280  loss_box_reg: 0.376  loss_rpn_cls: 0.046  loss_rpn_loc: 0.083  time: 1.0297  data_time: 0.0175  lr: 0.002098  max_mem: 5393M
[32m[04/20 05:25:05 d2.utils.events]: [0m eta: 0:09:38  iter: 439  total_loss: 0.762  loss_cls: 0.264  loss_box_reg: 0.372  loss_rpn_cls: 0.047  loss_rpn_loc: 0.069  time: 1.0303  data_time: 0.0188  lr: 0.002198  max_mem: 5393M
[32m[04/20 05:25:26 d2.utils.events]: [0m eta: 0:09:18  iter: 459  total_loss: 0.806  loss_cls: 0.265  loss_box_reg: 0.350  loss_rpn_cls: 0.053  loss_rpn_loc: 0.066  time: 1.0303  data_time: 0.0172  lr: 0.002298  max_mem: 5393M
[32m[04/20 05:25:46 d2.utils.events]: [0m eta: 0:08:57  iter: 479  total_loss: 0.824  loss_cls: 0.283  loss_box_reg: 0.431  loss_rpn_cls: 0.057  loss_rpn_loc: 0.089  time: 1.0298  data_time: 0.0162  lr: 0.002398  max_mem: 5393M
[32m[04/20 05:26:06 d2.utils.events]: [0m eta: 0:08:36  iter: 499  total_loss: 0.854  loss_cls: 0.294  loss_box_reg: 0.397  loss_rpn_cls: 0.060  loss_rpn_loc: 0.082  time: 1.0290  data_time: 0.0165  lr: 0.002498  max_mem: 5393M
[32m[04/20 05:26:27 d2.utils.events]: [0m eta: 0:08:15  iter: 519  total_loss: 0.736  loss_cls: 0.250  loss_box_reg: 0.336  loss_rpn_cls: 0.054  loss_rpn_loc: 0.074  time: 1.0288  data_time: 0.0164  lr: 0.002597  max_mem: 5393M
[32m[04/20 05:26:48 d2.utils.events]: [0m eta: 0:07:55  iter: 539  total_loss: 0.693  loss_cls: 0.253  loss_box_reg: 0.318  loss_rpn_cls: 0.043  loss_rpn_loc: 0.066  time: 1.0298  data_time: 0.0169  lr: 0.002697  max_mem: 5393M
[32m[04/20 05:27:08 d2.utils.events]: [0m eta: 0:07:34  iter: 559  total_loss: 0.687  loss_cls: 0.237  loss_box_reg: 0.344  loss_rpn_cls: 0.045  loss_rpn_loc: 0.056  time: 1.0291  data_time: 0.0146  lr: 0.002797  max_mem: 5393M
[32m[04/20 05:27:30 d2.utils.events]: [0m eta: 0:07:14  iter: 579  total_loss: 0.825  loss_cls: 0.276  loss_box_reg: 0.426  loss_rpn_cls: 0.050  loss_rpn_loc: 0.078  time: 1.0299  data_time: 0.0183  lr: 0.002897  max_mem: 5393M
[32m[04/20 05:27:50 d2.utils.events]: [0m eta: 0:06:53  iter: 599  total_loss: 0.767  loss_cls: 0.234  loss_box_reg: 0.355  loss_rpn_cls: 0.058  loss_rpn_loc: 0.078  time: 1.0295  data_time: 0.0155  lr: 0.002997  max_mem: 5393M
[32m[04/20 05:28:11 d2.utils.events]: [0m eta: 0:06:33  iter: 619  total_loss: 0.740  loss_cls: 0.260  loss_box_reg: 0.361  loss_rpn_cls: 0.046  loss_rpn_loc: 0.063  time: 1.0301  data_time: 0.0189  lr: 0.003097  max_mem: 5393M
[32m[04/20 05:28:32 d2.utils.events]: [0m eta: 0:06:13  iter: 639  total_loss: 0.844  loss_cls: 0.292  loss_box_reg: 0.397  loss_rpn_cls: 0.044  loss_rpn_loc: 0.072  time: 1.0303  data_time: 0.0167  lr: 0.003197  max_mem: 5393M
[32m[04/20 05:28:53 d2.utils.events]: [0m eta: 0:05:53  iter: 659  total_loss: 0.817  loss_cls: 0.287  loss_box_reg: 0.385  loss_rpn_cls: 0.053  loss_rpn_loc: 0.096  time: 1.0310  data_time: 0.0165  lr: 0.003297  max_mem: 5393M
[32m[04/20 05:29:13 d2.utils.events]: [0m eta: 0:05:32  iter: 679  total_loss: 0.794  loss_cls: 0.276  loss_box_reg: 0.382  loss_rpn_cls: 0.046  loss_rpn_loc: 0.069  time: 1.0310  data_time: 0.0218  lr: 0.003397  max_mem: 5393M
[32m[04/20 05:29:35 d2.utils.events]: [0m eta: 0:05:12  iter: 699  total_loss: 0.689  loss_cls: 0.255  loss_box_reg: 0.311  loss_rpn_cls: 0.044  loss_rpn_loc: 0.062  time: 1.0315  data_time: 0.0170  lr: 0.003497  max_mem: 5393M
[32m[04/20 05:29:55 d2.utils.events]: [0m eta: 0:04:51  iter: 719  total_loss: 0.661  loss_cls: 0.242  loss_box_reg: 0.337  loss_rpn_cls: 0.047  loss_rpn_loc: 0.057  time: 1.0316  data_time: 0.0158  lr: 0.003596  max_mem: 5393M
[32m[04/20 05:30:16 d2.utils.events]: [0m eta: 0:04:30  iter: 739  total_loss: 0.784  loss_cls: 0.244  loss_box_reg: 0.380  loss_rpn_cls: 0.053  loss_rpn_loc: 0.081  time: 1.0316  data_time: 0.0150  lr: 0.003696  max_mem: 5393M
[32m[04/20 05:30:36 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.774  loss_cls: 0.226  loss_box_reg: 0.414  loss_rpn_cls: 0.043  loss_rpn_loc: 0.082  time: 1.0312  data_time: 0.0157  lr: 0.003796  max_mem: 5393M
[32m[04/20 05:30:57 d2.utils.events]: [0m eta: 0:03:49  iter: 779  total_loss: 0.789  loss_cls: 0.278  loss_box_reg: 0.415  loss_rpn_cls: 0.042  loss_rpn_loc: 0.074  time: 1.0316  data_time: 0.0156  lr: 0.003896  max_mem: 5393M
[32m[04/20 05:31:19 d2.utils.events]: [0m eta: 0:03:28  iter: 799  total_loss: 0.802  loss_cls: 0.278  loss_box_reg: 0.412  loss_rpn_cls: 0.037  loss_rpn_loc: 0.068  time: 1.0323  data_time: 0.0132  lr: 0.003996  max_mem: 5393M
[32m[04/20 05:31:39 d2.utils.events]: [0m eta: 0:03:08  iter: 819  total_loss: 0.734  loss_cls: 0.259  loss_box_reg: 0.355  loss_rpn_cls: 0.039  loss_rpn_loc: 0.075  time: 1.0324  data_time: 0.0192  lr: 0.004096  max_mem: 5393M
[32m[04/20 05:32:00 d2.utils.events]: [0m eta: 0:02:47  iter: 839  total_loss: 0.687  loss_cls: 0.272  loss_box_reg: 0.344  loss_rpn_cls: 0.050  loss_rpn_loc: 0.057  time: 1.0323  data_time: 0.0158  lr: 0.004196  max_mem: 5393M
[32m[04/20 05:32:20 d2.utils.events]: [0m eta: 0:02:26  iter: 859  total_loss: 0.831  loss_cls: 0.282  loss_box_reg: 0.427  loss_rpn_cls: 0.037  loss_rpn_loc: 0.086  time: 1.0321  data_time: 0.0189  lr: 0.004296  max_mem: 5393M
[32m[04/20 05:32:41 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.771  loss_cls: 0.264  loss_box_reg: 0.377  loss_rpn_cls: 0.043  loss_rpn_loc: 0.076  time: 1.0320  data_time: 0.0164  lr: 0.004396  max_mem: 5393M
[32m[04/20 05:33:02 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.813  loss_cls: 0.291  loss_box_reg: 0.380  loss_rpn_cls: 0.035  loss_rpn_loc: 0.074  time: 1.0322  data_time: 0.0183  lr: 0.004496  max_mem: 5393M
[32m[04/20 05:33:23 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.818  loss_cls: 0.273  loss_box_reg: 0.387  loss_rpn_cls: 0.044  loss_rpn_loc: 0.095  time: 1.0323  data_time: 0.0179  lr: 0.004595  max_mem: 5393M
[32m[04/20 05:33:43 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.717  loss_cls: 0.239  loss_box_reg: 0.336  loss_rpn_cls: 0.049  loss_rpn_loc: 0.063  time: 1.0323  data_time: 0.0172  lr: 0.004695  max_mem: 5393M
[32m[04/20 05:34:04 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.727  loss_cls: 0.249  loss_box_reg: 0.363  loss_rpn_cls: 0.038  loss_rpn_loc: 0.076  time: 1.0324  data_time: 0.0201  lr: 0.004795  max_mem: 5393M
[32m[04/20 05:34:25 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.720  loss_cls: 0.247  loss_box_reg: 0.371  loss_rpn_cls: 0.056  loss_rpn_loc: 0.073  time: 1.0320  data_time: 0.0132  lr: 0.004895  max_mem: 5393M
[5m[31mWARNING[0m [32m[04/20 05:34:50 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 05:34:50 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 05:34:50 d2.data.build]: [0mDistribution of instances among all 80 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|    person     | 5406         |    bicycle    | 420          |      car      | 5008         |
|  motorcycle   | 0            |   airplane    | 0            |      bus      | 0            |
|     train     | 0            |     truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant  | 0            |   stop sign   | 0            |
| parking meter | 0            |     bench     | 0            |     bird      | 0            |
|      cat      | 0            |      dog      | 0            |     horse     | 0            |
|     sheep     | 0            |      cow      | 0            |   elephant    | 0            |
|     bear      | 0            |     zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella    | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase    | 0            |    frisbee    | 0            |
|     skis      | 0            |   snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat  | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |   surfboard   | 0            | tennis racket | 0            |
|    bottle     | 0            |  wine glass   | 0            |      cup      | 0            |
|     fork      | 0            |     knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana     | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange     | 0            |   broccoli    | 0            |
|    carrot     | 0            |    hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake      | 0            |     chair     | 0            |
|     couch     | 0            | potted plant  | 0            |      bed      | 0            |
| dining table  | 0            |    toilet     | 0            |      tv       | 0            |
|    laptop     | 0            |     mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone   | 0            |   microwave   | 0            |
|     oven      | 0            |     bike      | 0            |    hydrant    | 0            |
|     motor     | 0            |     rider     | 0            |     light     | 0            |
|     sign      | 0            | motor vehicle | 0            |  human face   | 0            |
|  hair drier   | 0            | license plate | 0            |               |              |
|     total     | 10834        |               |              |               |              |[0m
[5m[31mWARNING[0m [32m[04/20 05:34:50 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 05:34:50 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.786  loss_cls: 0.279  loss_box_reg: 0.418  loss_rpn_cls: 0.044  loss_rpn_loc: 0.072  time: 1.0325  data_time: 0.0138  lr: 0.004995  max_mem: 5393M
[32m[04/20 05:34:51 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:10 (1.0335 s / it)
[32m[04/20 05:34:51 d2.engine.hooks]: [0mTotal training time: 0:17:17 (0:00:07 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 05:34:54 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 05:34:54 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 05:34:55 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 05:34:57 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1198 s / img. ETA=0:16:58
[32m[04/20 05:35:02 d2.evaluation.evaluator]: [0mInference done 52/8355. 0.1204 s / img. ETA=0:17:01
[32m[04/20 05:35:07 d2.evaluation.evaluator]: [0mInference done 93/8355. 0.1206 s / img. ETA=0:16:59
[32m[04/20 05:35:12 d2.evaluation.evaluator]: [0mInference done 134/8355. 0.1202 s / img. ETA=0:16:51
[32m[04/20 05:35:17 d2.evaluation.evaluator]: [0mInference done 176/8355. 0.1199 s / img. ETA=0:16:43
[32m[04/20 05:35:22 d2.evaluation.evaluator]: [0mInference done 217/8355. 0.1201 s / img. ETA=0:16:40
[32m[04/20 05:35:27 d2.evaluation.evaluator]: [0mInference done 258/8355. 0.1200 s / img. ETA=0:16:34
[32m[04/20 05:35:32 d2.evaluation.evaluator]: [0mInference done 299/8355. 0.1200 s / img. ETA=0:16:29
[32m[04/20 05:35:37 d2.evaluation.evaluator]: [0mInference done 340/8355. 0.1201 s / img. ETA=0:16:25
[32m[04/20 05:35:42 d2.evaluation.evaluator]: [0mInference done 381/8355. 0.1201 s / img. ETA=0:16:20
[32m[04/20 05:35:47 d2.evaluation.evaluator]: [0mInference done 422/8355. 0.1201 s / img. ETA=0:16:15
[32m[04/20 05:35:52 d2.evaluation.evaluator]: [0mInference done 463/8355. 0.1202 s / img. ETA=0:16:11
[32m[04/20 05:35:57 d2.evaluation.evaluator]: [0mInference done 504/8355. 0.1202 s / img. ETA=0:16:06
[32m[04/20 05:36:02 d2.evaluation.evaluator]: [0mInference done 545/8355. 0.1202 s / img. ETA=0:16:01
[32m[04/20 05:36:07 d2.evaluation.evaluator]: [0mInference done 586/8355. 0.1202 s / img. ETA=0:15:56
[32m[04/20 05:36:12 d2.evaluation.evaluator]: [0mInference done 627/8355. 0.1202 s / img. ETA=0:15:51
[32m[04/20 05:36:17 d2.evaluation.evaluator]: [0mInference done 668/8355. 0.1202 s / img. ETA=0:15:46
[32m[04/20 05:36:22 d2.evaluation.evaluator]: [0mInference done 709/8355. 0.1202 s / img. ETA=0:15:41
[32m[04/20 05:36:28 d2.evaluation.evaluator]: [0mInference done 750/8355. 0.1202 s / img. ETA=0:15:36
[32m[04/20 05:36:33 d2.evaluation.evaluator]: [0mInference done 791/8355. 0.1202 s / img. ETA=0:15:31
[32m[04/20 05:36:38 d2.evaluation.evaluator]: [0mInference done 832/8355. 0.1203 s / img. ETA=0:15:26
[32m[04/20 05:36:43 d2.evaluation.evaluator]: [0mInference done 873/8355. 0.1203 s / img. ETA=0:15:21
[32m[04/20 05:36:48 d2.evaluation.evaluator]: [0mInference done 914/8355. 0.1203 s / img. ETA=0:15:16
[32m[04/20 05:36:53 d2.evaluation.evaluator]: [0mInference done 955/8355. 0.1203 s / img. ETA=0:15:11
[32m[04/20 05:36:58 d2.evaluation.evaluator]: [0mInference done 996/8355. 0.1203 s / img. ETA=0:15:06
[32m[04/20 05:37:03 d2.evaluation.evaluator]: [0mInference done 1037/8355. 0.1204 s / img. ETA=0:15:02
[32m[04/20 05:37:08 d2.evaluation.evaluator]: [0mInference done 1078/8355. 0.1203 s / img. ETA=0:14:56
[32m[04/20 05:37:13 d2.evaluation.evaluator]: [0mInference done 1120/8355. 0.1203 s / img. ETA=0:14:51
[32m[04/20 05:37:18 d2.evaluation.evaluator]: [0mInference done 1161/8355. 0.1203 s / img. ETA=0:14:46
[32m[04/20 05:37:23 d2.evaluation.evaluator]: [0mInference done 1202/8355. 0.1203 s / img. ETA=0:14:41
[32m[04/20 05:37:28 d2.evaluation.evaluator]: [0mInference done 1243/8355. 0.1203 s / img. ETA=0:14:36
[32m[04/20 05:37:33 d2.evaluation.evaluator]: [0mInference done 1284/8355. 0.1203 s / img. ETA=0:14:31
[32m[04/20 05:37:39 d2.evaluation.evaluator]: [0mInference done 1325/8355. 0.1203 s / img. ETA=0:14:26
[32m[04/20 05:37:44 d2.evaluation.evaluator]: [0mInference done 1366/8355. 0.1204 s / img. ETA=0:14:21
[32m[04/20 05:37:49 d2.evaluation.evaluator]: [0mInference done 1407/8355. 0.1203 s / img. ETA=0:14:16
[32m[04/20 05:37:54 d2.evaluation.evaluator]: [0mInference done 1449/8355. 0.1203 s / img. ETA=0:14:10
[32m[04/20 05:37:59 d2.evaluation.evaluator]: [0mInference done 1490/8355. 0.1203 s / img. ETA=0:14:06
[32m[04/20 05:38:04 d2.evaluation.evaluator]: [0mInference done 1531/8355. 0.1203 s / img. ETA=0:14:01
[32m[04/20 05:38:09 d2.evaluation.evaluator]: [0mInference done 1572/8355. 0.1203 s / img. ETA=0:13:56
[32m[04/20 05:38:14 d2.evaluation.evaluator]: [0mInference done 1613/8355. 0.1203 s / img. ETA=0:13:51
[32m[04/20 05:38:19 d2.evaluation.evaluator]: [0mInference done 1654/8355. 0.1203 s / img. ETA=0:13:46
[32m[04/20 05:38:24 d2.evaluation.evaluator]: [0mInference done 1695/8355. 0.1203 s / img. ETA=0:13:41
[32m[04/20 05:38:29 d2.evaluation.evaluator]: [0mInference done 1736/8355. 0.1203 s / img. ETA=0:13:36
[32m[04/20 05:38:34 d2.evaluation.evaluator]: [0mInference done 1777/8355. 0.1204 s / img. ETA=0:13:31
[32m[04/20 05:38:39 d2.evaluation.evaluator]: [0mInference done 1818/8355. 0.1204 s / img. ETA=0:13:26
[32m[04/20 05:38:44 d2.evaluation.evaluator]: [0mInference done 1859/8355. 0.1204 s / img. ETA=0:13:21
[32m[04/20 05:38:50 d2.evaluation.evaluator]: [0mInference done 1900/8355. 0.1204 s / img. ETA=0:13:16
[32m[04/20 05:38:55 d2.evaluation.evaluator]: [0mInference done 1941/8355. 0.1204 s / img. ETA=0:13:11
[32m[04/20 05:39:00 d2.evaluation.evaluator]: [0mInference done 1982/8355. 0.1204 s / img. ETA=0:13:06
[32m[04/20 05:39:05 d2.evaluation.evaluator]: [0mInference done 2023/8355. 0.1204 s / img. ETA=0:13:01
[32m[04/20 05:39:10 d2.evaluation.evaluator]: [0mInference done 2064/8355. 0.1204 s / img. ETA=0:12:56
[32m[04/20 05:39:15 d2.evaluation.evaluator]: [0mInference done 2105/8355. 0.1204 s / img. ETA=0:12:51
[32m[04/20 05:39:20 d2.evaluation.evaluator]: [0mInference done 2146/8355. 0.1204 s / img. ETA=0:12:46
[32m[04/20 05:39:25 d2.evaluation.evaluator]: [0mInference done 2187/8355. 0.1204 s / img. ETA=0:12:41
[32m[04/20 05:39:30 d2.evaluation.evaluator]: [0mInference done 2228/8355. 0.1204 s / img. ETA=0:12:35
[32m[04/20 05:39:35 d2.evaluation.evaluator]: [0mInference done 2269/8355. 0.1205 s / img. ETA=0:12:31
[32m[04/20 05:39:40 d2.evaluation.evaluator]: [0mInference done 2310/8355. 0.1205 s / img. ETA=0:12:26
[32m[04/20 05:39:45 d2.evaluation.evaluator]: [0mInference done 2351/8355. 0.1205 s / img. ETA=0:12:21
[32m[04/20 05:39:50 d2.evaluation.evaluator]: [0mInference done 2392/8355. 0.1205 s / img. ETA=0:12:15
[32m[04/20 05:39:55 d2.evaluation.evaluator]: [0mInference done 2433/8355. 0.1205 s / img. ETA=0:12:10
[32m[04/20 05:40:01 d2.evaluation.evaluator]: [0mInference done 2474/8355. 0.1205 s / img. ETA=0:12:05
[32m[04/20 05:40:06 d2.evaluation.evaluator]: [0mInference done 2515/8355. 0.1205 s / img. ETA=0:12:00
[32m[04/20 05:40:11 d2.evaluation.evaluator]: [0mInference done 2556/8355. 0.1205 s / img. ETA=0:11:55
[32m[04/20 05:40:16 d2.evaluation.evaluator]: [0mInference done 2597/8355. 0.1205 s / img. ETA=0:11:50
[32m[04/20 05:40:21 d2.evaluation.evaluator]: [0mInference done 2638/8355. 0.1205 s / img. ETA=0:11:45
[32m[04/20 05:40:26 d2.evaluation.evaluator]: [0mInference done 2679/8355. 0.1205 s / img. ETA=0:11:40
[32m[04/20 05:40:31 d2.evaluation.evaluator]: [0mInference done 2720/8355. 0.1204 s / img. ETA=0:11:35
[32m[04/20 05:40:36 d2.evaluation.evaluator]: [0mInference done 2761/8355. 0.1204 s / img. ETA=0:11:30
[32m[04/20 05:40:41 d2.evaluation.evaluator]: [0mInference done 2802/8355. 0.1204 s / img. ETA=0:11:25
[32m[04/20 05:40:46 d2.evaluation.evaluator]: [0mInference done 2843/8355. 0.1204 s / img. ETA=0:11:20
[32m[04/20 05:40:51 d2.evaluation.evaluator]: [0mInference done 2884/8355. 0.1204 s / img. ETA=0:11:15
[32m[04/20 05:40:56 d2.evaluation.evaluator]: [0mInference done 2925/8355. 0.1205 s / img. ETA=0:11:10
[32m[04/20 05:41:01 d2.evaluation.evaluator]: [0mInference done 2966/8355. 0.1204 s / img. ETA=0:11:05
[32m[04/20 05:41:06 d2.evaluation.evaluator]: [0mInference done 3007/8355. 0.1204 s / img. ETA=0:10:59
[32m[04/20 05:41:11 d2.evaluation.evaluator]: [0mInference done 3048/8355. 0.1204 s / img. ETA=0:10:54
[32m[04/20 05:41:16 d2.evaluation.evaluator]: [0mInference done 3089/8355. 0.1205 s / img. ETA=0:10:49
[32m[04/20 05:41:21 d2.evaluation.evaluator]: [0mInference done 3130/8355. 0.1205 s / img. ETA=0:10:44
[32m[04/20 05:41:26 d2.evaluation.evaluator]: [0mInference done 3171/8355. 0.1204 s / img. ETA=0:10:39
[32m[04/20 05:41:31 d2.evaluation.evaluator]: [0mInference done 3212/8355. 0.1204 s / img. ETA=0:10:34
[32m[04/20 05:41:37 d2.evaluation.evaluator]: [0mInference done 3253/8355. 0.1204 s / img. ETA=0:10:29
[32m[04/20 05:41:42 d2.evaluation.evaluator]: [0mInference done 3295/8355. 0.1204 s / img. ETA=0:10:24
[32m[04/20 05:41:47 d2.evaluation.evaluator]: [0mInference done 3337/8355. 0.1204 s / img. ETA=0:10:18
[32m[04/20 05:41:52 d2.evaluation.evaluator]: [0mInference done 3378/8355. 0.1204 s / img. ETA=0:10:13
[32m[04/20 05:41:57 d2.evaluation.evaluator]: [0mInference done 3420/8355. 0.1203 s / img. ETA=0:10:08
[32m[04/20 05:42:02 d2.evaluation.evaluator]: [0mInference done 3461/8355. 0.1203 s / img. ETA=0:10:03
[32m[04/20 05:42:07 d2.evaluation.evaluator]: [0mInference done 3502/8355. 0.1203 s / img. ETA=0:09:58
[32m[04/20 05:42:12 d2.evaluation.evaluator]: [0mInference done 3543/8355. 0.1203 s / img. ETA=0:09:53
[32m[04/20 05:42:17 d2.evaluation.evaluator]: [0mInference done 3584/8355. 0.1203 s / img. ETA=0:09:48
[32m[04/20 05:42:22 d2.evaluation.evaluator]: [0mInference done 3626/8355. 0.1203 s / img. ETA=0:09:42
[32m[04/20 05:42:27 d2.evaluation.evaluator]: [0mInference done 3667/8355. 0.1203 s / img. ETA=0:09:37
[32m[04/20 05:42:32 d2.evaluation.evaluator]: [0mInference done 3708/8355. 0.1203 s / img. ETA=0:09:32
[32m[04/20 05:42:37 d2.evaluation.evaluator]: [0mInference done 3749/8355. 0.1203 s / img. ETA=0:09:27
[32m[04/20 05:42:42 d2.evaluation.evaluator]: [0mInference done 3790/8355. 0.1203 s / img. ETA=0:09:22
[32m[04/20 05:42:47 d2.evaluation.evaluator]: [0mInference done 3831/8355. 0.1203 s / img. ETA=0:09:17
[32m[04/20 05:42:52 d2.evaluation.evaluator]: [0mInference done 3872/8355. 0.1203 s / img. ETA=0:09:12
[32m[04/20 05:42:57 d2.evaluation.evaluator]: [0mInference done 3913/8355. 0.1203 s / img. ETA=0:09:07
[32m[04/20 05:43:03 d2.evaluation.evaluator]: [0mInference done 3954/8355. 0.1203 s / img. ETA=0:09:02
[32m[04/20 05:43:08 d2.evaluation.evaluator]: [0mInference done 3995/8355. 0.1203 s / img. ETA=0:08:57
[32m[04/20 05:43:13 d2.evaluation.evaluator]: [0mInference done 4036/8355. 0.1203 s / img. ETA=0:08:52
[32m[04/20 05:43:18 d2.evaluation.evaluator]: [0mInference done 4077/8355. 0.1203 s / img. ETA=0:08:47
[32m[04/20 05:43:23 d2.evaluation.evaluator]: [0mInference done 4118/8355. 0.1203 s / img. ETA=0:08:42
[32m[04/20 05:43:28 d2.evaluation.evaluator]: [0mInference done 4159/8355. 0.1203 s / img. ETA=0:08:37
[32m[04/20 05:43:33 d2.evaluation.evaluator]: [0mInference done 4200/8355. 0.1203 s / img. ETA=0:08:32
[32m[04/20 05:43:38 d2.evaluation.evaluator]: [0mInference done 4241/8355. 0.1203 s / img. ETA=0:08:27
[32m[04/20 05:43:43 d2.evaluation.evaluator]: [0mInference done 4282/8355. 0.1203 s / img. ETA=0:08:22
[32m[04/20 05:43:48 d2.evaluation.evaluator]: [0mInference done 4323/8355. 0.1203 s / img. ETA=0:08:16
[32m[04/20 05:43:53 d2.evaluation.evaluator]: [0mInference done 4364/8355. 0.1203 s / img. ETA=0:08:11
[32m[04/20 05:43:58 d2.evaluation.evaluator]: [0mInference done 4405/8355. 0.1203 s / img. ETA=0:08:06
[32m[04/20 05:44:03 d2.evaluation.evaluator]: [0mInference done 4446/8355. 0.1203 s / img. ETA=0:08:01
[32m[04/20 05:44:08 d2.evaluation.evaluator]: [0mInference done 4487/8355. 0.1203 s / img. ETA=0:07:56
[32m[04/20 05:44:13 d2.evaluation.evaluator]: [0mInference done 4528/8355. 0.1203 s / img. ETA=0:07:51
[32m[04/20 05:44:18 d2.evaluation.evaluator]: [0mInference done 4569/8355. 0.1203 s / img. ETA=0:07:46
[32m[04/20 05:44:23 d2.evaluation.evaluator]: [0mInference done 4610/8355. 0.1203 s / img. ETA=0:07:41
[32m[04/20 05:44:28 d2.evaluation.evaluator]: [0mInference done 4651/8355. 0.1203 s / img. ETA=0:07:36
[32m[04/20 05:44:34 d2.evaluation.evaluator]: [0mInference done 4692/8355. 0.1203 s / img. ETA=0:07:31
[32m[04/20 05:44:39 d2.evaluation.evaluator]: [0mInference done 4733/8355. 0.1203 s / img. ETA=0:07:26
[32m[04/20 05:44:44 d2.evaluation.evaluator]: [0mInference done 4774/8355. 0.1203 s / img. ETA=0:07:21
[32m[04/20 05:44:49 d2.evaluation.evaluator]: [0mInference done 4815/8355. 0.1203 s / img. ETA=0:07:16
[32m[04/20 05:44:54 d2.evaluation.evaluator]: [0mInference done 4856/8355. 0.1203 s / img. ETA=0:07:11
[32m[04/20 05:44:59 d2.evaluation.evaluator]: [0mInference done 4897/8355. 0.1203 s / img. ETA=0:07:06
[32m[04/20 05:45:04 d2.evaluation.evaluator]: [0mInference done 4938/8355. 0.1203 s / img. ETA=0:07:01
[32m[04/20 05:45:09 d2.evaluation.evaluator]: [0mInference done 4979/8355. 0.1203 s / img. ETA=0:06:56
[32m[04/20 05:45:14 d2.evaluation.evaluator]: [0mInference done 5020/8355. 0.1203 s / img. ETA=0:06:51
[32m[04/20 05:45:19 d2.evaluation.evaluator]: [0mInference done 5061/8355. 0.1203 s / img. ETA=0:06:46
[32m[04/20 05:45:24 d2.evaluation.evaluator]: [0mInference done 5102/8355. 0.1203 s / img. ETA=0:06:41
[32m[04/20 05:45:29 d2.evaluation.evaluator]: [0mInference done 5143/8355. 0.1203 s / img. ETA=0:06:35
[32m[04/20 05:45:34 d2.evaluation.evaluator]: [0mInference done 5184/8355. 0.1203 s / img. ETA=0:06:30
[32m[04/20 05:45:39 d2.evaluation.evaluator]: [0mInference done 5225/8355. 0.1203 s / img. ETA=0:06:25
[32m[04/20 05:45:44 d2.evaluation.evaluator]: [0mInference done 5267/8355. 0.1203 s / img. ETA=0:06:20
[32m[04/20 05:45:49 d2.evaluation.evaluator]: [0mInference done 5308/8355. 0.1203 s / img. ETA=0:06:15
[32m[04/20 05:45:54 d2.evaluation.evaluator]: [0mInference done 5349/8355. 0.1203 s / img. ETA=0:06:10
[32m[04/20 05:45:59 d2.evaluation.evaluator]: [0mInference done 5390/8355. 0.1203 s / img. ETA=0:06:05
[32m[04/20 05:46:05 d2.evaluation.evaluator]: [0mInference done 5432/8355. 0.1203 s / img. ETA=0:06:00
[32m[04/20 05:46:10 d2.evaluation.evaluator]: [0mInference done 5474/8355. 0.1202 s / img. ETA=0:05:54
[32m[04/20 05:46:15 d2.evaluation.evaluator]: [0mInference done 5515/8355. 0.1202 s / img. ETA=0:05:49
[32m[04/20 05:46:20 d2.evaluation.evaluator]: [0mInference done 5557/8355. 0.1202 s / img. ETA=0:05:44
[32m[04/20 05:46:25 d2.evaluation.evaluator]: [0mInference done 5598/8355. 0.1202 s / img. ETA=0:05:39
[32m[04/20 05:46:30 d2.evaluation.evaluator]: [0mInference done 5639/8355. 0.1202 s / img. ETA=0:05:34
[32m[04/20 05:46:35 d2.evaluation.evaluator]: [0mInference done 5680/8355. 0.1202 s / img. ETA=0:05:29
[32m[04/20 05:46:40 d2.evaluation.evaluator]: [0mInference done 5721/8355. 0.1202 s / img. ETA=0:05:24
[32m[04/20 05:46:45 d2.evaluation.evaluator]: [0mInference done 5762/8355. 0.1202 s / img. ETA=0:05:19
[32m[04/20 05:46:50 d2.evaluation.evaluator]: [0mInference done 5804/8355. 0.1202 s / img. ETA=0:05:14
[32m[04/20 05:46:55 d2.evaluation.evaluator]: [0mInference done 5845/8355. 0.1202 s / img. ETA=0:05:09
[32m[04/20 05:47:00 d2.evaluation.evaluator]: [0mInference done 5887/8355. 0.1202 s / img. ETA=0:05:03
[32m[04/20 05:47:05 d2.evaluation.evaluator]: [0mInference done 5928/8355. 0.1202 s / img. ETA=0:04:58
[32m[04/20 05:47:10 d2.evaluation.evaluator]: [0mInference done 5970/8355. 0.1202 s / img. ETA=0:04:53
[32m[04/20 05:47:15 d2.evaluation.evaluator]: [0mInference done 6012/8355. 0.1202 s / img. ETA=0:04:48
[32m[04/20 05:47:20 d2.evaluation.evaluator]: [0mInference done 6053/8355. 0.1202 s / img. ETA=0:04:43
[32m[04/20 05:47:25 d2.evaluation.evaluator]: [0mInference done 6095/8355. 0.1201 s / img. ETA=0:04:38
[32m[04/20 05:47:31 d2.evaluation.evaluator]: [0mInference done 6136/8355. 0.1201 s / img. ETA=0:04:33
[32m[04/20 05:47:36 d2.evaluation.evaluator]: [0mInference done 6177/8355. 0.1201 s / img. ETA=0:04:28
[32m[04/20 05:47:41 d2.evaluation.evaluator]: [0mInference done 6218/8355. 0.1201 s / img. ETA=0:04:23
[32m[04/20 05:47:46 d2.evaluation.evaluator]: [0mInference done 6259/8355. 0.1201 s / img. ETA=0:04:18
[32m[04/20 05:47:51 d2.evaluation.evaluator]: [0mInference done 6301/8355. 0.1201 s / img. ETA=0:04:12
[32m[04/20 05:47:56 d2.evaluation.evaluator]: [0mInference done 6342/8355. 0.1201 s / img. ETA=0:04:07
[32m[04/20 05:48:01 d2.evaluation.evaluator]: [0mInference done 6383/8355. 0.1201 s / img. ETA=0:04:02
[32m[04/20 05:48:06 d2.evaluation.evaluator]: [0mInference done 6424/8355. 0.1201 s / img. ETA=0:03:57
[32m[04/20 05:48:11 d2.evaluation.evaluator]: [0mInference done 6465/8355. 0.1201 s / img. ETA=0:03:52
[32m[04/20 05:48:16 d2.evaluation.evaluator]: [0mInference done 6507/8355. 0.1201 s / img. ETA=0:03:47
[32m[04/20 05:48:21 d2.evaluation.evaluator]: [0mInference done 6548/8355. 0.1201 s / img. ETA=0:03:42
[32m[04/20 05:48:26 d2.evaluation.evaluator]: [0mInference done 6589/8355. 0.1201 s / img. ETA=0:03:37
[32m[04/20 05:48:31 d2.evaluation.evaluator]: [0mInference done 6631/8355. 0.1201 s / img. ETA=0:03:32
[32m[04/20 05:48:36 d2.evaluation.evaluator]: [0mInference done 6673/8355. 0.1201 s / img. ETA=0:03:26
[32m[04/20 05:48:41 d2.evaluation.evaluator]: [0mInference done 6714/8355. 0.1201 s / img. ETA=0:03:21
[32m[04/20 05:48:46 d2.evaluation.evaluator]: [0mInference done 6755/8355. 0.1201 s / img. ETA=0:03:16
[32m[04/20 05:48:51 d2.evaluation.evaluator]: [0mInference done 6797/8355. 0.1201 s / img. ETA=0:03:11
[32m[04/20 05:48:56 d2.evaluation.evaluator]: [0mInference done 6839/8355. 0.1201 s / img. ETA=0:03:06
[32m[04/20 05:49:02 d2.evaluation.evaluator]: [0mInference done 6881/8355. 0.1201 s / img. ETA=0:03:01
[32m[04/20 05:49:07 d2.evaluation.evaluator]: [0mInference done 6922/8355. 0.1201 s / img. ETA=0:02:56
[32m[04/20 05:49:12 d2.evaluation.evaluator]: [0mInference done 6963/8355. 0.1200 s / img. ETA=0:02:51
[32m[04/20 05:49:17 d2.evaluation.evaluator]: [0mInference done 7005/8355. 0.1200 s / img. ETA=0:02:46
[32m[04/20 05:49:22 d2.evaluation.evaluator]: [0mInference done 7046/8355. 0.1200 s / img. ETA=0:02:40
[32m[04/20 05:49:27 d2.evaluation.evaluator]: [0mInference done 7087/8355. 0.1200 s / img. ETA=0:02:35
[32m[04/20 05:49:32 d2.evaluation.evaluator]: [0mInference done 7128/8355. 0.1200 s / img. ETA=0:02:30
[32m[04/20 05:49:37 d2.evaluation.evaluator]: [0mInference done 7169/8355. 0.1200 s / img. ETA=0:02:25
[32m[04/20 05:49:42 d2.evaluation.evaluator]: [0mInference done 7211/8355. 0.1200 s / img. ETA=0:02:20
[32m[04/20 05:49:47 d2.evaluation.evaluator]: [0mInference done 7253/8355. 0.1200 s / img. ETA=0:02:15
[32m[04/20 05:49:52 d2.evaluation.evaluator]: [0mInference done 7295/8355. 0.1200 s / img. ETA=0:02:10
[32m[04/20 05:49:57 d2.evaluation.evaluator]: [0mInference done 7337/8355. 0.1200 s / img. ETA=0:02:05
[32m[04/20 05:50:02 d2.evaluation.evaluator]: [0mInference done 7378/8355. 0.1200 s / img. ETA=0:02:00
[32m[04/20 05:50:07 d2.evaluation.evaluator]: [0mInference done 7419/8355. 0.1200 s / img. ETA=0:01:55
[32m[04/20 05:50:12 d2.evaluation.evaluator]: [0mInference done 7461/8355. 0.1200 s / img. ETA=0:01:49
[32m[04/20 05:50:17 d2.evaluation.evaluator]: [0mInference done 7503/8355. 0.1200 s / img. ETA=0:01:44
[32m[04/20 05:50:22 d2.evaluation.evaluator]: [0mInference done 7544/8355. 0.1200 s / img. ETA=0:01:39
[32m[04/20 05:50:28 d2.evaluation.evaluator]: [0mInference done 7585/8355. 0.1200 s / img. ETA=0:01:34
[32m[04/20 05:50:33 d2.evaluation.evaluator]: [0mInference done 7627/8355. 0.1200 s / img. ETA=0:01:29
[32m[04/20 05:50:38 d2.evaluation.evaluator]: [0mInference done 7669/8355. 0.1200 s / img. ETA=0:01:24
[32m[04/20 05:50:43 d2.evaluation.evaluator]: [0mInference done 7711/8355. 0.1199 s / img. ETA=0:01:19
[32m[04/20 05:50:48 d2.evaluation.evaluator]: [0mInference done 7752/8355. 0.1199 s / img. ETA=0:01:14
[32m[04/20 05:50:53 d2.evaluation.evaluator]: [0mInference done 7794/8355. 0.1199 s / img. ETA=0:01:08
[32m[04/20 05:50:58 d2.evaluation.evaluator]: [0mInference done 7836/8355. 0.1199 s / img. ETA=0:01:03
[32m[04/20 05:51:03 d2.evaluation.evaluator]: [0mInference done 7877/8355. 0.1199 s / img. ETA=0:00:58
[32m[04/20 05:51:08 d2.evaluation.evaluator]: [0mInference done 7919/8355. 0.1199 s / img. ETA=0:00:53
[32m[04/20 05:51:13 d2.evaluation.evaluator]: [0mInference done 7960/8355. 0.1199 s / img. ETA=0:00:48
[32m[04/20 05:51:18 d2.evaluation.evaluator]: [0mInference done 8001/8355. 0.1199 s / img. ETA=0:00:43
[32m[04/20 05:51:23 d2.evaluation.evaluator]: [0mInference done 8042/8355. 0.1199 s / img. ETA=0:00:38
[32m[04/20 05:51:28 d2.evaluation.evaluator]: [0mInference done 8083/8355. 0.1199 s / img. ETA=0:00:33
[32m[04/20 05:51:33 d2.evaluation.evaluator]: [0mInference done 8125/8355. 0.1199 s / img. ETA=0:00:28
[32m[04/20 05:51:38 d2.evaluation.evaluator]: [0mInference done 8166/8355. 0.1199 s / img. ETA=0:00:23
[32m[04/20 05:51:44 d2.evaluation.evaluator]: [0mInference done 8208/8355. 0.1199 s / img. ETA=0:00:18
[32m[04/20 05:51:49 d2.evaluation.evaluator]: [0mInference done 8249/8355. 0.1199 s / img. ETA=0:00:13
[32m[04/20 05:51:54 d2.evaluation.evaluator]: [0mInference done 8290/8355. 0.1199 s / img. ETA=0:00:07
[32m[04/20 05:51:59 d2.evaluation.evaluator]: [0mInference done 8331/8355. 0.1199 s / img. ETA=0:00:02
[32m[04/20 05:52:02 d2.evaluation.evaluator]: [0mTotal inference time: 0:17:06.001366 (0.122874 s / img per device, on 1 devices)
[32m[04/20 05:52:02 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:41 (0.119915 s / img per device, on 1 devices)
[32m[04/20 05:52:02 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 05:52:02 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 05:52:02 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=9.54s).
Accumulating evaluation results...
DONE (t=1.71s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
[32m[04/20 05:52:13 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.110 | 0.165  | 0.165  | 0.000 | 0.000 | 0.231 |
[32m[04/20 05:52:13 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP    | category      | AP    | category       | AP    |
|:--------------|:------|:--------------|:------|:---------------|:------|
| person        | 0.000 | bicycle       | 0.000 | car            | 0.330 |
| motorcycle    | nan   | airplane      | nan   | bus            | nan   |
| train         | nan   | truck         | nan   | boat           | nan   |
| traffic light | nan   | fire hydrant  | nan   | stop sign      | nan   |
| parking meter | nan   | bench         | nan   | bird           | nan   |
| cat           | nan   | dog           | nan   | horse          | nan   |
| sheep         | nan   | cow           | nan   | elephant       | nan   |
| bear          | nan   | zebra         | nan   | giraffe        | nan   |
| backpack      | nan   | umbrella      | nan   | handbag        | nan   |
| tie           | nan   | suitcase      | nan   | frisbee        | nan   |
| skis          | nan   | snowboard     | nan   | sports ball    | nan   |
| kite          | nan   | baseball bat  | nan   | baseball glove | nan   |
| skateboard    | nan   | surfboard     | nan   | tennis racket  | nan   |
| bottle        | nan   | wine glass    | nan   | cup            | nan   |
| fork          | nan   | knife         | nan   | spoon          | nan   |
| bowl          | nan   | banana        | nan   | apple          | nan   |
| sandwich      | nan   | orange        | nan   | broccoli       | nan   |
| carrot        | nan   | hot dog       | nan   | pizza          | nan   |
| donut         | nan   | cake          | nan   | chair          | nan   |
| couch         | nan   | potted plant  | nan   | bed            | nan   |
| dining table  | nan   | toilet        | nan   | tv             | nan   |
| laptop        | nan   | mouse         | nan   | remote         | nan   |
| keyboard      | nan   | cell phone    | nan   | microwave      | nan   |
| oven          | nan   | bike          | nan   | hydrant        | nan   |
| motor         | nan   | rider         | nan   | light          | nan   |
| sign          | nan   | motor vehicle | nan   | human face     | nan   |
| hair drier    | nan   |               |       |                |       |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 05:52:15 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 05:52:15 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 05:52:15 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 05:52:16 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1193 s / img. ETA=0:02:31
[32m[04/20 05:52:21 d2.evaluation.evaluator]: [0mInference done 52/1257. 0.1189 s / img. ETA=0:02:26
[32m[04/20 05:52:26 d2.evaluation.evaluator]: [0mInference done 93/1257. 0.1190 s / img. ETA=0:02:22
[32m[04/20 05:52:32 d2.evaluation.evaluator]: [0mInference done 134/1257. 0.1194 s / img. ETA=0:02:17
[32m[04/20 05:52:37 d2.evaluation.evaluator]: [0mInference done 176/1257. 0.1193 s / img. ETA=0:02:12
[32m[04/20 05:52:42 d2.evaluation.evaluator]: [0mInference done 217/1257. 0.1193 s / img. ETA=0:02:07
[32m[04/20 05:52:47 d2.evaluation.evaluator]: [0mInference done 258/1257. 0.1193 s / img. ETA=0:02:02
[32m[04/20 05:52:52 d2.evaluation.evaluator]: [0mInference done 299/1257. 0.1195 s / img. ETA=0:01:57
[32m[04/20 05:52:57 d2.evaluation.evaluator]: [0mInference done 340/1257. 0.1195 s / img. ETA=0:01:52
[32m[04/20 05:53:02 d2.evaluation.evaluator]: [0mInference done 381/1257. 0.1195 s / img. ETA=0:01:47
[32m[04/20 05:53:07 d2.evaluation.evaluator]: [0mInference done 422/1257. 0.1196 s / img. ETA=0:01:42
[32m[04/20 05:53:12 d2.evaluation.evaluator]: [0mInference done 463/1257. 0.1196 s / img. ETA=0:01:37
[32m[04/20 05:53:17 d2.evaluation.evaluator]: [0mInference done 504/1257. 0.1196 s / img. ETA=0:01:32
[32m[04/20 05:53:22 d2.evaluation.evaluator]: [0mInference done 545/1257. 0.1197 s / img. ETA=0:01:27
[32m[04/20 05:53:27 d2.evaluation.evaluator]: [0mInference done 587/1257. 0.1196 s / img. ETA=0:01:22
[32m[04/20 05:53:32 d2.evaluation.evaluator]: [0mInference done 628/1257. 0.1196 s / img. ETA=0:01:17
[32m[04/20 05:53:37 d2.evaluation.evaluator]: [0mInference done 669/1257. 0.1195 s / img. ETA=0:01:12
[32m[04/20 05:53:42 d2.evaluation.evaluator]: [0mInference done 710/1257. 0.1195 s / img. ETA=0:01:07
[32m[04/20 05:53:47 d2.evaluation.evaluator]: [0mInference done 751/1257. 0.1196 s / img. ETA=0:01:02
[32m[04/20 05:53:52 d2.evaluation.evaluator]: [0mInference done 792/1257. 0.1196 s / img. ETA=0:00:57
[32m[04/20 05:53:57 d2.evaluation.evaluator]: [0mInference done 833/1257. 0.1197 s / img. ETA=0:00:52
[32m[04/20 05:54:02 d2.evaluation.evaluator]: [0mInference done 874/1257. 0.1197 s / img. ETA=0:00:47
[32m[04/20 05:54:08 d2.evaluation.evaluator]: [0mInference done 915/1257. 0.1197 s / img. ETA=0:00:42
[32m[04/20 05:54:13 d2.evaluation.evaluator]: [0mInference done 956/1257. 0.1198 s / img. ETA=0:00:36
[32m[04/20 05:54:18 d2.evaluation.evaluator]: [0mInference done 997/1257. 0.1198 s / img. ETA=0:00:31
[32m[04/20 05:54:23 d2.evaluation.evaluator]: [0mInference done 1038/1257. 0.1198 s / img. ETA=0:00:26
[32m[04/20 05:54:28 d2.evaluation.evaluator]: [0mInference done 1079/1257. 0.1198 s / img. ETA=0:00:21
[32m[04/20 05:54:33 d2.evaluation.evaluator]: [0mInference done 1120/1257. 0.1198 s / img. ETA=0:00:16
[32m[04/20 05:54:38 d2.evaluation.evaluator]: [0mInference done 1161/1257. 0.1199 s / img. ETA=0:00:11
[32m[04/20 05:54:43 d2.evaluation.evaluator]: [0mInference done 1202/1257. 0.1199 s / img. ETA=0:00:06
[32m[04/20 05:54:48 d2.evaluation.evaluator]: [0mInference done 1243/1257. 0.1198 s / img. ETA=0:00:01
[32m[04/20 05:54:50 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:33.959180 (0.122971 s / img per device, on 1 devices)
[32m[04/20 05:54:50 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:30 (0.119846 s / img per device, on 1 devices)
[32m[04/20 05:54:50 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 05:54:50 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 05:54:50 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.37s).
Accumulating evaluation results...
DONE (t=0.27s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.007
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003
[32m[04/20 05:54:51 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.296 | 0.660  | 0.090  | 0.033 | 0.216 | 0.416 |
[32m[04/20 05:54:51 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP    | category      | AP    | category       | AP    |
|:--------------|:------|:--------------|:------|:---------------|:------|
| person        | 0.442 | bicycle       | 0.000 | car            | 0.445 |
| motorcycle    | nan   | airplane      | nan   | bus            | nan   |
| train         | nan   | truck         | nan   | boat           | nan   |
| traffic light | nan   | fire hydrant  | nan   | stop sign      | nan   |
| parking meter | nan   | bench         | nan   | bird           | nan   |
| cat           | nan   | dog           | nan   | horse          | nan   |
| sheep         | nan   | cow           | nan   | elephant       | nan   |
| bear          | nan   | zebra         | nan   | giraffe        | nan   |
| backpack      | nan   | umbrella      | nan   | handbag        | nan   |
| tie           | nan   | suitcase      | nan   | frisbee        | nan   |
| skis          | nan   | snowboard     | nan   | sports ball    | nan   |
| kite          | nan   | baseball bat  | nan   | baseball glove | nan   |
| skateboard    | nan   | surfboard     | nan   | tennis racket  | nan   |
| bottle        | nan   | wine glass    | nan   | cup            | nan   |
| fork          | nan   | knife         | nan   | spoon          | nan   |
| bowl          | nan   | banana        | nan   | apple          | nan   |
| sandwich      | nan   | orange        | nan   | broccoli       | nan   |
| carrot        | nan   | hot dog       | nan   | pizza          | nan   |
| donut         | nan   | cake          | nan   | chair          | nan   |
| couch         | nan   | potted plant  | nan   | bed            | nan   |
| dining table  | nan   | toilet        | nan   | tv             | nan   |
| laptop        | nan   | mouse         | nan   | remote         | nan   |
| keyboard      | nan   | cell phone    | nan   | microwave      | nan   |
| oven          | nan   | bike          | nan   | hydrant        | nan   |
| motor         | nan   | rider         | nan   | light          | nan   |
| sign          | nan   | motor vehicle | nan   | human face     | nan   |
| hair drier    | nan   | license plate | nan   |                |       |
============== The  1  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 05:54:53 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 05:54:53 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 05:54:53 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 05:54:54 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 05:54:54 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 05:54:54 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 05:54:54 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 05:55:15 d2.utils.events]: [0m eta: 0:16:25  iter: 19  total_loss: 0.780  loss_cls: 0.275  loss_box_reg: 0.399  loss_rpn_cls: 0.048  loss_rpn_loc: 0.074  time: 1.0053  data_time: 0.0482  lr: 0.000100  max_mem: 5405M
[32m[04/20 05:55:35 d2.utils.events]: [0m eta: 0:16:07  iter: 39  total_loss: 0.825  loss_cls: 0.285  loss_box_reg: 0.385  loss_rpn_cls: 0.052  loss_rpn_loc: 0.092  time: 1.0079  data_time: 0.0181  lr: 0.000200  max_mem: 5405M
[32m[04/20 05:55:56 d2.utils.events]: [0m eta: 0:16:02  iter: 59  total_loss: 0.697  loss_cls: 0.245  loss_box_reg: 0.332  loss_rpn_cls: 0.035  loss_rpn_loc: 0.072  time: 1.0221  data_time: 0.0180  lr: 0.000300  max_mem: 5405M
[32m[04/20 05:56:17 d2.utils.events]: [0m eta: 0:15:42  iter: 79  total_loss: 0.707  loss_cls: 0.244  loss_box_reg: 0.361  loss_rpn_cls: 0.040  loss_rpn_loc: 0.060  time: 1.0267  data_time: 0.0195  lr: 0.000400  max_mem: 5405M
[32m[04/20 05:56:38 d2.utils.events]: [0m eta: 0:15:28  iter: 99  total_loss: 0.791  loss_cls: 0.272  loss_box_reg: 0.395  loss_rpn_cls: 0.041  loss_rpn_loc: 0.076  time: 1.0306  data_time: 0.0163  lr: 0.000500  max_mem: 5405M
[32m[04/20 05:56:59 d2.utils.events]: [0m eta: 0:15:09  iter: 119  total_loss: 0.765  loss_cls: 0.258  loss_box_reg: 0.361  loss_rpn_cls: 0.046  loss_rpn_loc: 0.069  time: 1.0324  data_time: 0.0158  lr: 0.000599  max_mem: 5405M
[32m[04/20 05:57:19 d2.utils.events]: [0m eta: 0:14:49  iter: 139  total_loss: 0.719  loss_cls: 0.255  loss_box_reg: 0.358  loss_rpn_cls: 0.033  loss_rpn_loc: 0.059  time: 1.0319  data_time: 0.0161  lr: 0.000699  max_mem: 5405M
[32m[04/20 05:57:40 d2.utils.events]: [0m eta: 0:14:30  iter: 159  total_loss: 0.721  loss_cls: 0.240  loss_box_reg: 0.364  loss_rpn_cls: 0.039  loss_rpn_loc: 0.059  time: 1.0327  data_time: 0.0176  lr: 0.000799  max_mem: 5405M
[32m[04/20 05:58:01 d2.utils.events]: [0m eta: 0:14:10  iter: 179  total_loss: 0.720  loss_cls: 0.241  loss_box_reg: 0.339  loss_rpn_cls: 0.033  loss_rpn_loc: 0.064  time: 1.0351  data_time: 0.0177  lr: 0.000899  max_mem: 5405M
[32m[04/20 05:58:22 d2.utils.events]: [0m eta: 0:13:50  iter: 199  total_loss: 0.691  loss_cls: 0.239  loss_box_reg: 0.351  loss_rpn_cls: 0.033  loss_rpn_loc: 0.053  time: 1.0350  data_time: 0.0220  lr: 0.000999  max_mem: 5405M
[32m[04/20 05:58:43 d2.utils.events]: [0m eta: 0:13:29  iter: 219  total_loss: 0.763  loss_cls: 0.247  loss_box_reg: 0.371  loss_rpn_cls: 0.033  loss_rpn_loc: 0.067  time: 1.0365  data_time: 0.0177  lr: 0.001099  max_mem: 5405M
[32m[04/20 05:59:04 d2.utils.events]: [0m eta: 0:13:08  iter: 239  total_loss: 0.675  loss_cls: 0.226  loss_box_reg: 0.364  loss_rpn_cls: 0.032  loss_rpn_loc: 0.062  time: 1.0358  data_time: 0.0201  lr: 0.001199  max_mem: 5405M
[32m[04/20 05:59:24 d2.utils.events]: [0m eta: 0:12:48  iter: 259  total_loss: 0.653  loss_cls: 0.235  loss_box_reg: 0.342  loss_rpn_cls: 0.035  loss_rpn_loc: 0.053  time: 1.0343  data_time: 0.0184  lr: 0.001299  max_mem: 5405M
[32m[04/20 05:59:45 d2.utils.events]: [0m eta: 0:12:28  iter: 279  total_loss: 0.727  loss_cls: 0.252  loss_box_reg: 0.379  loss_rpn_cls: 0.040  loss_rpn_loc: 0.063  time: 1.0359  data_time: 0.0154  lr: 0.001399  max_mem: 5405M
[32m[04/20 06:00:07 d2.utils.events]: [0m eta: 0:12:11  iter: 299  total_loss: 0.722  loss_cls: 0.249  loss_box_reg: 0.379  loss_rpn_cls: 0.030  loss_rpn_loc: 0.076  time: 1.0383  data_time: 0.0174  lr: 0.001499  max_mem: 5405M
[32m[04/20 06:00:28 d2.utils.events]: [0m eta: 0:11:52  iter: 319  total_loss: 0.708  loss_cls: 0.257  loss_box_reg: 0.344  loss_rpn_cls: 0.030  loss_rpn_loc: 0.066  time: 1.0396  data_time: 0.0175  lr: 0.001598  max_mem: 5405M
[32m[04/20 06:00:49 d2.utils.events]: [0m eta: 0:11:34  iter: 339  total_loss: 0.789  loss_cls: 0.257  loss_box_reg: 0.421  loss_rpn_cls: 0.040  loss_rpn_loc: 0.075  time: 1.0401  data_time: 0.0177  lr: 0.001698  max_mem: 5405M
[32m[04/20 06:01:10 d2.utils.events]: [0m eta: 0:11:12  iter: 359  total_loss: 0.717  loss_cls: 0.256  loss_box_reg: 0.356  loss_rpn_cls: 0.042  loss_rpn_loc: 0.069  time: 1.0401  data_time: 0.0185  lr: 0.001798  max_mem: 5405M
[32m[04/20 06:01:30 d2.utils.events]: [0m eta: 0:10:48  iter: 379  total_loss: 0.693  loss_cls: 0.218  loss_box_reg: 0.322  loss_rpn_cls: 0.026  loss_rpn_loc: 0.063  time: 1.0383  data_time: 0.0178  lr: 0.001898  max_mem: 5405M
[32m[04/20 06:01:51 d2.utils.events]: [0m eta: 0:10:25  iter: 399  total_loss: 0.749  loss_cls: 0.253  loss_box_reg: 0.372  loss_rpn_cls: 0.035  loss_rpn_loc: 0.072  time: 1.0375  data_time: 0.0163  lr: 0.001998  max_mem: 5405M
[32m[04/20 06:02:12 d2.utils.events]: [0m eta: 0:10:05  iter: 419  total_loss: 0.685  loss_cls: 0.220  loss_box_reg: 0.362  loss_rpn_cls: 0.025  loss_rpn_loc: 0.085  time: 1.0380  data_time: 0.0156  lr: 0.002098  max_mem: 5405M
[32m[04/20 06:02:32 d2.utils.events]: [0m eta: 0:09:43  iter: 439  total_loss: 0.718  loss_cls: 0.233  loss_box_reg: 0.371  loss_rpn_cls: 0.037  loss_rpn_loc: 0.069  time: 1.0372  data_time: 0.0196  lr: 0.002198  max_mem: 5405M
[32m[04/20 06:02:53 d2.utils.events]: [0m eta: 0:09:23  iter: 459  total_loss: 0.782  loss_cls: 0.276  loss_box_reg: 0.392  loss_rpn_cls: 0.029  loss_rpn_loc: 0.074  time: 1.0382  data_time: 0.0178  lr: 0.002298  max_mem: 5405M
[32m[04/20 06:03:14 d2.utils.events]: [0m eta: 0:09:03  iter: 479  total_loss: 0.643  loss_cls: 0.223  loss_box_reg: 0.326  loss_rpn_cls: 0.039  loss_rpn_loc: 0.061  time: 1.0381  data_time: 0.0179  lr: 0.002398  max_mem: 5405M
[32m[04/20 06:03:35 d2.utils.events]: [0m eta: 0:08:41  iter: 499  total_loss: 0.779  loss_cls: 0.266  loss_box_reg: 0.407  loss_rpn_cls: 0.032  loss_rpn_loc: 0.078  time: 1.0378  data_time: 0.0211  lr: 0.002498  max_mem: 5405M
[32m[04/20 06:03:56 d2.utils.events]: [0m eta: 0:08:21  iter: 519  total_loss: 0.649  loss_cls: 0.219  loss_box_reg: 0.336  loss_rpn_cls: 0.029  loss_rpn_loc: 0.047  time: 1.0383  data_time: 0.0182  lr: 0.002597  max_mem: 5405M
[32m[04/20 06:04:17 d2.utils.events]: [0m eta: 0:08:00  iter: 539  total_loss: 0.696  loss_cls: 0.236  loss_box_reg: 0.376  loss_rpn_cls: 0.034  loss_rpn_loc: 0.066  time: 1.0385  data_time: 0.0186  lr: 0.002697  max_mem: 5405M
[32m[04/20 06:04:37 d2.utils.events]: [0m eta: 0:07:39  iter: 559  total_loss: 0.707  loss_cls: 0.234  loss_box_reg: 0.384  loss_rpn_cls: 0.042  loss_rpn_loc: 0.069  time: 1.0382  data_time: 0.0151  lr: 0.002797  max_mem: 5405M
[32m[04/20 06:04:58 d2.utils.events]: [0m eta: 0:07:18  iter: 579  total_loss: 0.711  loss_cls: 0.233  loss_box_reg: 0.392  loss_rpn_cls: 0.035  loss_rpn_loc: 0.058  time: 1.0381  data_time: 0.0155  lr: 0.002897  max_mem: 5405M
[32m[04/20 06:05:18 d2.utils.events]: [0m eta: 0:06:57  iter: 599  total_loss: 0.787  loss_cls: 0.268  loss_box_reg: 0.411  loss_rpn_cls: 0.032  loss_rpn_loc: 0.068  time: 1.0371  data_time: 0.0156  lr: 0.002997  max_mem: 5405M
[32m[04/20 06:05:40 d2.utils.events]: [0m eta: 0:06:36  iter: 619  total_loss: 0.729  loss_cls: 0.240  loss_box_reg: 0.386  loss_rpn_cls: 0.033  loss_rpn_loc: 0.051  time: 1.0378  data_time: 0.0184  lr: 0.003097  max_mem: 5405M
[32m[04/20 06:06:01 d2.utils.events]: [0m eta: 0:06:15  iter: 639  total_loss: 0.762  loss_cls: 0.259  loss_box_reg: 0.396  loss_rpn_cls: 0.037  loss_rpn_loc: 0.060  time: 1.0383  data_time: 0.0195  lr: 0.003197  max_mem: 5405M
[32m[04/20 06:06:22 d2.utils.events]: [0m eta: 0:05:55  iter: 659  total_loss: 0.770  loss_cls: 0.252  loss_box_reg: 0.398  loss_rpn_cls: 0.035  loss_rpn_loc: 0.068  time: 1.0385  data_time: 0.0166  lr: 0.003297  max_mem: 5405M
[32m[04/20 06:06:43 d2.utils.events]: [0m eta: 0:05:34  iter: 679  total_loss: 0.696  loss_cls: 0.237  loss_box_reg: 0.339  loss_rpn_cls: 0.039  loss_rpn_loc: 0.071  time: 1.0388  data_time: 0.0159  lr: 0.003397  max_mem: 5405M
[32m[04/20 06:07:03 d2.utils.events]: [0m eta: 0:05:13  iter: 699  total_loss: 0.805  loss_cls: 0.273  loss_box_reg: 0.431  loss_rpn_cls: 0.032  loss_rpn_loc: 0.063  time: 1.0383  data_time: 0.0157  lr: 0.003497  max_mem: 5405M
[32m[04/20 06:07:24 d2.utils.events]: [0m eta: 0:04:52  iter: 719  total_loss: 0.735  loss_cls: 0.267  loss_box_reg: 0.376  loss_rpn_cls: 0.044  loss_rpn_loc: 0.073  time: 1.0378  data_time: 0.0190  lr: 0.003596  max_mem: 5405M
[32m[04/20 06:07:44 d2.utils.events]: [0m eta: 0:04:31  iter: 739  total_loss: 0.758  loss_cls: 0.236  loss_box_reg: 0.394  loss_rpn_cls: 0.038  loss_rpn_loc: 0.074  time: 1.0375  data_time: 0.0176  lr: 0.003696  max_mem: 5405M
[32m[04/20 06:08:05 d2.utils.events]: [0m eta: 0:04:10  iter: 759  total_loss: 0.776  loss_cls: 0.273  loss_box_reg: 0.393  loss_rpn_cls: 0.038  loss_rpn_loc: 0.069  time: 1.0373  data_time: 0.0161  lr: 0.003796  max_mem: 5405M
[32m[04/20 06:08:25 d2.utils.events]: [0m eta: 0:03:49  iter: 779  total_loss: 0.763  loss_cls: 0.263  loss_box_reg: 0.414  loss_rpn_cls: 0.031  loss_rpn_loc: 0.068  time: 1.0369  data_time: 0.0183  lr: 0.003896  max_mem: 5405M
[32m[04/20 06:08:47 d2.utils.events]: [0m eta: 0:03:28  iter: 799  total_loss: 0.675  loss_cls: 0.231  loss_box_reg: 0.371  loss_rpn_cls: 0.027  loss_rpn_loc: 0.058  time: 1.0376  data_time: 0.0170  lr: 0.003996  max_mem: 5405M
[32m[04/20 06:09:08 d2.utils.events]: [0m eta: 0:03:08  iter: 819  total_loss: 0.652  loss_cls: 0.222  loss_box_reg: 0.344  loss_rpn_cls: 0.036  loss_rpn_loc: 0.054  time: 1.0379  data_time: 0.0166  lr: 0.004096  max_mem: 5405M
[32m[04/20 06:09:29 d2.utils.events]: [0m eta: 0:02:47  iter: 839  total_loss: 0.736  loss_cls: 0.246  loss_box_reg: 0.385  loss_rpn_cls: 0.034  loss_rpn_loc: 0.079  time: 1.0380  data_time: 0.0186  lr: 0.004196  max_mem: 5405M
[32m[04/20 06:09:50 d2.utils.events]: [0m eta: 0:02:26  iter: 859  total_loss: 0.700  loss_cls: 0.239  loss_box_reg: 0.357  loss_rpn_cls: 0.033  loss_rpn_loc: 0.083  time: 1.0382  data_time: 0.0161  lr: 0.004296  max_mem: 5405M
[32m[04/20 06:10:11 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.657  loss_cls: 0.234  loss_box_reg: 0.354  loss_rpn_cls: 0.032  loss_rpn_loc: 0.060  time: 1.0384  data_time: 0.0189  lr: 0.004396  max_mem: 5405M
[32m[04/20 06:10:31 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.698  loss_cls: 0.243  loss_box_reg: 0.347  loss_rpn_cls: 0.034  loss_rpn_loc: 0.073  time: 1.0375  data_time: 0.0159  lr: 0.004496  max_mem: 5405M
[32m[04/20 06:10:51 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.680  loss_cls: 0.228  loss_box_reg: 0.348  loss_rpn_cls: 0.030  loss_rpn_loc: 0.075  time: 1.0375  data_time: 0.0191  lr: 0.004595  max_mem: 5405M
[32m[04/20 06:11:12 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.712  loss_cls: 0.241  loss_box_reg: 0.349  loss_rpn_cls: 0.034  loss_rpn_loc: 0.059  time: 1.0376  data_time: 0.0168  lr: 0.004695  max_mem: 5405M
[32m[04/20 06:11:33 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.634  loss_cls: 0.223  loss_box_reg: 0.317  loss_rpn_cls: 0.031  loss_rpn_loc: 0.059  time: 1.0377  data_time: 0.0171  lr: 0.004795  max_mem: 5405M
[32m[04/20 06:11:54 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.641  loss_cls: 0.209  loss_box_reg: 0.342  loss_rpn_cls: 0.030  loss_rpn_loc: 0.057  time: 1.0380  data_time: 0.0163  lr: 0.004895  max_mem: 5405M
[5m[31mWARNING[0m [32m[04/20 06:12:18 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 06:12:18 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 06:12:18 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 06:12:18 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.801  loss_cls: 0.262  loss_box_reg: 0.411  loss_rpn_cls: 0.032  loss_rpn_loc: 0.062  time: 1.0374  data_time: 0.0196  lr: 0.004995  max_mem: 5405M
[32m[04/20 06:12:19 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:15 (1.0385 s / it)
[32m[04/20 06:12:19 d2.engine.hooks]: [0mTotal training time: 0:17:22 (0:00:07 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 06:12:23 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 06:12:23 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 06:12:24 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 06:12:25 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1216 s / img. ETA=0:17:14
[32m[04/20 06:12:30 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1187 s / img. ETA=0:16:48
[32m[04/20 06:12:36 d2.evaluation.evaluator]: [0mInference done 95/8355. 0.1184 s / img. ETA=0:16:40
[32m[04/20 06:12:41 d2.evaluation.evaluator]: [0mInference done 137/8355. 0.1183 s / img. ETA=0:16:35
[32m[04/20 06:12:46 d2.evaluation.evaluator]: [0mInference done 179/8355. 0.1182 s / img. ETA=0:16:29
[32m[04/20 06:12:51 d2.evaluation.evaluator]: [0mInference done 220/8355. 0.1184 s / img. ETA=0:16:26
[32m[04/20 06:12:56 d2.evaluation.evaluator]: [0mInference done 262/8355. 0.1183 s / img. ETA=0:16:20
[32m[04/20 06:13:01 d2.evaluation.evaluator]: [0mInference done 304/8355. 0.1182 s / img. ETA=0:16:15
[32m[04/20 06:13:06 d2.evaluation.evaluator]: [0mInference done 346/8355. 0.1182 s / img. ETA=0:16:10
[32m[04/20 06:13:11 d2.evaluation.evaluator]: [0mInference done 388/8355. 0.1183 s / img. ETA=0:16:05
[32m[04/20 06:13:16 d2.evaluation.evaluator]: [0mInference done 429/8355. 0.1185 s / img. ETA=0:16:02
[32m[04/20 06:13:21 d2.evaluation.evaluator]: [0mInference done 471/8355. 0.1185 s / img. ETA=0:15:57
[32m[04/20 06:13:26 d2.evaluation.evaluator]: [0mInference done 513/8355. 0.1184 s / img. ETA=0:15:51
[32m[04/20 06:13:31 d2.evaluation.evaluator]: [0mInference done 555/8355. 0.1184 s / img. ETA=0:15:46
[32m[04/20 06:13:36 d2.evaluation.evaluator]: [0mInference done 597/8355. 0.1184 s / img. ETA=0:15:41
[32m[04/20 06:13:42 d2.evaluation.evaluator]: [0mInference done 639/8355. 0.1184 s / img. ETA=0:15:36
[32m[04/20 06:13:47 d2.evaluation.evaluator]: [0mInference done 681/8355. 0.1183 s / img. ETA=0:15:30
[32m[04/20 06:13:52 d2.evaluation.evaluator]: [0mInference done 722/8355. 0.1184 s / img. ETA=0:15:26
[32m[04/20 06:13:57 d2.evaluation.evaluator]: [0mInference done 764/8355. 0.1184 s / img. ETA=0:15:20
[32m[04/20 06:14:02 d2.evaluation.evaluator]: [0mInference done 805/8355. 0.1184 s / img. ETA=0:15:16
[32m[04/20 06:14:07 d2.evaluation.evaluator]: [0mInference done 847/8355. 0.1184 s / img. ETA=0:15:11
[32m[04/20 06:14:12 d2.evaluation.evaluator]: [0mInference done 888/8355. 0.1184 s / img. ETA=0:15:06
[32m[04/20 06:14:17 d2.evaluation.evaluator]: [0mInference done 930/8355. 0.1185 s / img. ETA=0:15:01
[32m[04/20 06:14:22 d2.evaluation.evaluator]: [0mInference done 972/8355. 0.1185 s / img. ETA=0:14:56
[32m[04/20 06:14:27 d2.evaluation.evaluator]: [0mInference done 1014/8355. 0.1185 s / img. ETA=0:14:51
[32m[04/20 06:14:32 d2.evaluation.evaluator]: [0mInference done 1056/8355. 0.1184 s / img. ETA=0:14:46
[32m[04/20 06:14:37 d2.evaluation.evaluator]: [0mInference done 1098/8355. 0.1184 s / img. ETA=0:14:40
[32m[04/20 06:14:42 d2.evaluation.evaluator]: [0mInference done 1140/8355. 0.1184 s / img. ETA=0:14:35
[32m[04/20 06:14:47 d2.evaluation.evaluator]: [0mInference done 1182/8355. 0.1184 s / img. ETA=0:14:30
[32m[04/20 06:14:53 d2.evaluation.evaluator]: [0mInference done 1224/8355. 0.1184 s / img. ETA=0:14:25
[32m[04/20 06:14:58 d2.evaluation.evaluator]: [0mInference done 1266/8355. 0.1184 s / img. ETA=0:14:20
[32m[04/20 06:15:03 d2.evaluation.evaluator]: [0mInference done 1308/8355. 0.1184 s / img. ETA=0:14:14
[32m[04/20 06:15:08 d2.evaluation.evaluator]: [0mInference done 1350/8355. 0.1183 s / img. ETA=0:14:09
[32m[04/20 06:15:13 d2.evaluation.evaluator]: [0mInference done 1391/8355. 0.1184 s / img. ETA=0:14:04
[32m[04/20 06:15:18 d2.evaluation.evaluator]: [0mInference done 1433/8355. 0.1184 s / img. ETA=0:13:59
[32m[04/20 06:15:23 d2.evaluation.evaluator]: [0mInference done 1475/8355. 0.1184 s / img. ETA=0:13:54
[32m[04/20 06:15:28 d2.evaluation.evaluator]: [0mInference done 1517/8355. 0.1184 s / img. ETA=0:13:49
[32m[04/20 06:15:33 d2.evaluation.evaluator]: [0mInference done 1559/8355. 0.1184 s / img. ETA=0:13:44
[32m[04/20 06:15:38 d2.evaluation.evaluator]: [0mInference done 1601/8355. 0.1184 s / img. ETA=0:13:39
[32m[04/20 06:15:43 d2.evaluation.evaluator]: [0mInference done 1643/8355. 0.1184 s / img. ETA=0:13:34
[32m[04/20 06:15:48 d2.evaluation.evaluator]: [0mInference done 1685/8355. 0.1184 s / img. ETA=0:13:29
[32m[04/20 06:15:54 d2.evaluation.evaluator]: [0mInference done 1727/8355. 0.1184 s / img. ETA=0:13:24
[32m[04/20 06:15:59 d2.evaluation.evaluator]: [0mInference done 1768/8355. 0.1184 s / img. ETA=0:13:19
[32m[04/20 06:16:04 d2.evaluation.evaluator]: [0mInference done 1810/8355. 0.1184 s / img. ETA=0:13:14
[32m[04/20 06:16:09 d2.evaluation.evaluator]: [0mInference done 1852/8355. 0.1184 s / img. ETA=0:13:09
[32m[04/20 06:16:14 d2.evaluation.evaluator]: [0mInference done 1893/8355. 0.1184 s / img. ETA=0:13:04
[32m[04/20 06:16:19 d2.evaluation.evaluator]: [0mInference done 1935/8355. 0.1184 s / img. ETA=0:12:59
[32m[04/20 06:16:24 d2.evaluation.evaluator]: [0mInference done 1977/8355. 0.1184 s / img. ETA=0:12:54
[32m[04/20 06:16:29 d2.evaluation.evaluator]: [0mInference done 2019/8355. 0.1184 s / img. ETA=0:12:49
[32m[04/20 06:16:34 d2.evaluation.evaluator]: [0mInference done 2061/8355. 0.1184 s / img. ETA=0:12:44
[32m[04/20 06:16:39 d2.evaluation.evaluator]: [0mInference done 2102/8355. 0.1184 s / img. ETA=0:12:39
[32m[04/20 06:16:44 d2.evaluation.evaluator]: [0mInference done 2144/8355. 0.1184 s / img. ETA=0:12:34
[32m[04/20 06:16:49 d2.evaluation.evaluator]: [0mInference done 2186/8355. 0.1184 s / img. ETA=0:12:29
[32m[04/20 06:16:55 d2.evaluation.evaluator]: [0mInference done 2228/8355. 0.1185 s / img. ETA=0:12:24
[32m[04/20 06:17:00 d2.evaluation.evaluator]: [0mInference done 2269/8355. 0.1185 s / img. ETA=0:12:19
[32m[04/20 06:17:05 d2.evaluation.evaluator]: [0mInference done 2310/8355. 0.1185 s / img. ETA=0:12:14
[32m[04/20 06:17:10 d2.evaluation.evaluator]: [0mInference done 2352/8355. 0.1185 s / img. ETA=0:12:09
[32m[04/20 06:17:15 d2.evaluation.evaluator]: [0mInference done 2393/8355. 0.1185 s / img. ETA=0:12:04
[32m[04/20 06:17:20 d2.evaluation.evaluator]: [0mInference done 2435/8355. 0.1185 s / img. ETA=0:11:59
[32m[04/20 06:17:25 d2.evaluation.evaluator]: [0mInference done 2476/8355. 0.1185 s / img. ETA=0:11:54
[32m[04/20 06:17:30 d2.evaluation.evaluator]: [0mInference done 2517/8355. 0.1185 s / img. ETA=0:11:49
[32m[04/20 06:17:35 d2.evaluation.evaluator]: [0mInference done 2558/8355. 0.1185 s / img. ETA=0:11:44
[32m[04/20 06:17:40 d2.evaluation.evaluator]: [0mInference done 2600/8355. 0.1185 s / img. ETA=0:11:39
[32m[04/20 06:17:45 d2.evaluation.evaluator]: [0mInference done 2642/8355. 0.1185 s / img. ETA=0:11:34
[32m[04/20 06:17:50 d2.evaluation.evaluator]: [0mInference done 2683/8355. 0.1185 s / img. ETA=0:11:29
[32m[04/20 06:17:55 d2.evaluation.evaluator]: [0mInference done 2725/8355. 0.1185 s / img. ETA=0:11:24
[32m[04/20 06:18:00 d2.evaluation.evaluator]: [0mInference done 2766/8355. 0.1186 s / img. ETA=0:11:19
[32m[04/20 06:18:05 d2.evaluation.evaluator]: [0mInference done 2807/8355. 0.1186 s / img. ETA=0:11:14
[32m[04/20 06:18:10 d2.evaluation.evaluator]: [0mInference done 2848/8355. 0.1186 s / img. ETA=0:11:09
[32m[04/20 06:18:15 d2.evaluation.evaluator]: [0mInference done 2890/8355. 0.1186 s / img. ETA=0:11:04
[32m[04/20 06:18:20 d2.evaluation.evaluator]: [0mInference done 2931/8355. 0.1186 s / img. ETA=0:10:59
[32m[04/20 06:18:25 d2.evaluation.evaluator]: [0mInference done 2972/8355. 0.1186 s / img. ETA=0:10:54
[32m[04/20 06:18:31 d2.evaluation.evaluator]: [0mInference done 3014/8355. 0.1186 s / img. ETA=0:10:49
[32m[04/20 06:18:36 d2.evaluation.evaluator]: [0mInference done 3056/8355. 0.1186 s / img. ETA=0:10:44
[32m[04/20 06:18:41 d2.evaluation.evaluator]: [0mInference done 3098/8355. 0.1186 s / img. ETA=0:10:39
[32m[04/20 06:18:46 d2.evaluation.evaluator]: [0mInference done 3139/8355. 0.1186 s / img. ETA=0:10:34
[32m[04/20 06:18:51 d2.evaluation.evaluator]: [0mInference done 3181/8355. 0.1186 s / img. ETA=0:10:29
[32m[04/20 06:18:56 d2.evaluation.evaluator]: [0mInference done 3223/8355. 0.1186 s / img. ETA=0:10:24
[32m[04/20 06:19:01 d2.evaluation.evaluator]: [0mInference done 3265/8355. 0.1186 s / img. ETA=0:10:18
[32m[04/20 06:19:06 d2.evaluation.evaluator]: [0mInference done 3307/8355. 0.1186 s / img. ETA=0:10:13
[32m[04/20 06:19:11 d2.evaluation.evaluator]: [0mInference done 3348/8355. 0.1186 s / img. ETA=0:10:08
[32m[04/20 06:19:16 d2.evaluation.evaluator]: [0mInference done 3389/8355. 0.1186 s / img. ETA=0:10:03
[32m[04/20 06:19:21 d2.evaluation.evaluator]: [0mInference done 3430/8355. 0.1186 s / img. ETA=0:09:59
[32m[04/20 06:19:26 d2.evaluation.evaluator]: [0mInference done 3471/8355. 0.1186 s / img. ETA=0:09:54
[32m[04/20 06:19:31 d2.evaluation.evaluator]: [0mInference done 3512/8355. 0.1186 s / img. ETA=0:09:49
[32m[04/20 06:19:36 d2.evaluation.evaluator]: [0mInference done 3554/8355. 0.1186 s / img. ETA=0:09:44
[32m[04/20 06:19:41 d2.evaluation.evaluator]: [0mInference done 3595/8355. 0.1186 s / img. ETA=0:09:39
[32m[04/20 06:19:46 d2.evaluation.evaluator]: [0mInference done 3636/8355. 0.1186 s / img. ETA=0:09:34
[32m[04/20 06:19:52 d2.evaluation.evaluator]: [0mInference done 3678/8355. 0.1186 s / img. ETA=0:09:29
[32m[04/20 06:19:57 d2.evaluation.evaluator]: [0mInference done 3720/8355. 0.1186 s / img. ETA=0:09:23
[32m[04/20 06:20:02 d2.evaluation.evaluator]: [0mInference done 3761/8355. 0.1186 s / img. ETA=0:09:18
[32m[04/20 06:20:07 d2.evaluation.evaluator]: [0mInference done 3802/8355. 0.1186 s / img. ETA=0:09:14
[32m[04/20 06:20:12 d2.evaluation.evaluator]: [0mInference done 3843/8355. 0.1187 s / img. ETA=0:09:09
[32m[04/20 06:20:17 d2.evaluation.evaluator]: [0mInference done 3884/8355. 0.1187 s / img. ETA=0:09:04
[32m[04/20 06:20:22 d2.evaluation.evaluator]: [0mInference done 3926/8355. 0.1187 s / img. ETA=0:08:59
[32m[04/20 06:20:27 d2.evaluation.evaluator]: [0mInference done 3968/8355. 0.1187 s / img. ETA=0:08:53
[32m[04/20 06:20:32 d2.evaluation.evaluator]: [0mInference done 4009/8355. 0.1187 s / img. ETA=0:08:48
[32m[04/20 06:20:37 d2.evaluation.evaluator]: [0mInference done 4050/8355. 0.1187 s / img. ETA=0:08:43
[32m[04/20 06:20:42 d2.evaluation.evaluator]: [0mInference done 4092/8355. 0.1187 s / img. ETA=0:08:38
[32m[04/20 06:20:47 d2.evaluation.evaluator]: [0mInference done 4133/8355. 0.1187 s / img. ETA=0:08:33
[32m[04/20 06:20:52 d2.evaluation.evaluator]: [0mInference done 4174/8355. 0.1187 s / img. ETA=0:08:28
[32m[04/20 06:20:57 d2.evaluation.evaluator]: [0mInference done 4215/8355. 0.1187 s / img. ETA=0:08:23
[32m[04/20 06:21:02 d2.evaluation.evaluator]: [0mInference done 4257/8355. 0.1187 s / img. ETA=0:08:18
[32m[04/20 06:21:07 d2.evaluation.evaluator]: [0mInference done 4299/8355. 0.1187 s / img. ETA=0:08:13
[32m[04/20 06:21:12 d2.evaluation.evaluator]: [0mInference done 4341/8355. 0.1187 s / img. ETA=0:08:08
[32m[04/20 06:21:17 d2.evaluation.evaluator]: [0mInference done 4383/8355. 0.1187 s / img. ETA=0:08:03
[32m[04/20 06:21:22 d2.evaluation.evaluator]: [0mInference done 4424/8355. 0.1187 s / img. ETA=0:07:58
[32m[04/20 06:21:28 d2.evaluation.evaluator]: [0mInference done 4466/8355. 0.1187 s / img. ETA=0:07:53
[32m[04/20 06:21:33 d2.evaluation.evaluator]: [0mInference done 4507/8355. 0.1187 s / img. ETA=0:07:48
[32m[04/20 06:21:38 d2.evaluation.evaluator]: [0mInference done 4548/8355. 0.1187 s / img. ETA=0:07:43
[32m[04/20 06:21:43 d2.evaluation.evaluator]: [0mInference done 4589/8355. 0.1187 s / img. ETA=0:07:38
[32m[04/20 06:21:48 d2.evaluation.evaluator]: [0mInference done 4630/8355. 0.1187 s / img. ETA=0:07:33
[32m[04/20 06:21:53 d2.evaluation.evaluator]: [0mInference done 4672/8355. 0.1187 s / img. ETA=0:07:28
[32m[04/20 06:21:58 d2.evaluation.evaluator]: [0mInference done 4713/8355. 0.1187 s / img. ETA=0:07:23
[32m[04/20 06:22:03 d2.evaluation.evaluator]: [0mInference done 4754/8355. 0.1187 s / img. ETA=0:07:18
[32m[04/20 06:22:08 d2.evaluation.evaluator]: [0mInference done 4795/8355. 0.1187 s / img. ETA=0:07:13
[32m[04/20 06:22:13 d2.evaluation.evaluator]: [0mInference done 4837/8355. 0.1187 s / img. ETA=0:07:08
[32m[04/20 06:22:18 d2.evaluation.evaluator]: [0mInference done 4879/8355. 0.1187 s / img. ETA=0:07:03
[32m[04/20 06:22:23 d2.evaluation.evaluator]: [0mInference done 4921/8355. 0.1187 s / img. ETA=0:06:58
[32m[04/20 06:22:28 d2.evaluation.evaluator]: [0mInference done 4963/8355. 0.1187 s / img. ETA=0:06:53
[32m[04/20 06:22:33 d2.evaluation.evaluator]: [0mInference done 5005/8355. 0.1187 s / img. ETA=0:06:47
[32m[04/20 06:22:38 d2.evaluation.evaluator]: [0mInference done 5046/8355. 0.1187 s / img. ETA=0:06:42
[32m[04/20 06:22:44 d2.evaluation.evaluator]: [0mInference done 5087/8355. 0.1187 s / img. ETA=0:06:37
[32m[04/20 06:22:49 d2.evaluation.evaluator]: [0mInference done 5128/8355. 0.1187 s / img. ETA=0:06:33
[32m[04/20 06:22:54 d2.evaluation.evaluator]: [0mInference done 5169/8355. 0.1187 s / img. ETA=0:06:28
[32m[04/20 06:22:59 d2.evaluation.evaluator]: [0mInference done 5210/8355. 0.1187 s / img. ETA=0:06:23
[32m[04/20 06:23:04 d2.evaluation.evaluator]: [0mInference done 5251/8355. 0.1188 s / img. ETA=0:06:18
[32m[04/20 06:23:09 d2.evaluation.evaluator]: [0mInference done 5292/8355. 0.1188 s / img. ETA=0:06:13
[32m[04/20 06:23:14 d2.evaluation.evaluator]: [0mInference done 5333/8355. 0.1188 s / img. ETA=0:06:08
[32m[04/20 06:23:19 d2.evaluation.evaluator]: [0mInference done 5374/8355. 0.1188 s / img. ETA=0:06:03
[32m[04/20 06:23:24 d2.evaluation.evaluator]: [0mInference done 5415/8355. 0.1188 s / img. ETA=0:05:58
[32m[04/20 06:23:29 d2.evaluation.evaluator]: [0mInference done 5456/8355. 0.1188 s / img. ETA=0:05:53
[32m[04/20 06:23:34 d2.evaluation.evaluator]: [0mInference done 5497/8355. 0.1188 s / img. ETA=0:05:48
[32m[04/20 06:23:39 d2.evaluation.evaluator]: [0mInference done 5539/8355. 0.1188 s / img. ETA=0:05:43
[32m[04/20 06:23:44 d2.evaluation.evaluator]: [0mInference done 5580/8355. 0.1188 s / img. ETA=0:05:38
[32m[04/20 06:23:49 d2.evaluation.evaluator]: [0mInference done 5621/8355. 0.1188 s / img. ETA=0:05:33
[32m[04/20 06:23:54 d2.evaluation.evaluator]: [0mInference done 5662/8355. 0.1188 s / img. ETA=0:05:28
[32m[04/20 06:23:59 d2.evaluation.evaluator]: [0mInference done 5703/8355. 0.1188 s / img. ETA=0:05:23
[32m[04/20 06:24:04 d2.evaluation.evaluator]: [0mInference done 5744/8355. 0.1188 s / img. ETA=0:05:18
[32m[04/20 06:24:09 d2.evaluation.evaluator]: [0mInference done 5785/8355. 0.1188 s / img. ETA=0:05:13
[32m[04/20 06:24:14 d2.evaluation.evaluator]: [0mInference done 5827/8355. 0.1188 s / img. ETA=0:05:08
[32m[04/20 06:24:19 d2.evaluation.evaluator]: [0mInference done 5868/8355. 0.1189 s / img. ETA=0:05:03
[32m[04/20 06:24:25 d2.evaluation.evaluator]: [0mInference done 5910/8355. 0.1189 s / img. ETA=0:04:58
[32m[04/20 06:24:30 d2.evaluation.evaluator]: [0mInference done 5952/8355. 0.1189 s / img. ETA=0:04:52
[32m[04/20 06:24:35 d2.evaluation.evaluator]: [0mInference done 5993/8355. 0.1189 s / img. ETA=0:04:47
[32m[04/20 06:24:40 d2.evaluation.evaluator]: [0mInference done 6034/8355. 0.1189 s / img. ETA=0:04:43
[32m[04/20 06:24:45 d2.evaluation.evaluator]: [0mInference done 6076/8355. 0.1189 s / img. ETA=0:04:37
[32m[04/20 06:24:50 d2.evaluation.evaluator]: [0mInference done 6118/8355. 0.1189 s / img. ETA=0:04:32
[32m[04/20 06:24:55 d2.evaluation.evaluator]: [0mInference done 6160/8355. 0.1189 s / img. ETA=0:04:27
[32m[04/20 06:25:00 d2.evaluation.evaluator]: [0mInference done 6202/8355. 0.1189 s / img. ETA=0:04:22
[32m[04/20 06:25:05 d2.evaluation.evaluator]: [0mInference done 6244/8355. 0.1189 s / img. ETA=0:04:17
[32m[04/20 06:25:10 d2.evaluation.evaluator]: [0mInference done 6282/8355. 0.1189 s / img. ETA=0:04:12
[32m[04/20 06:25:15 d2.evaluation.evaluator]: [0mInference done 6324/8355. 0.1189 s / img. ETA=0:04:07
[32m[04/20 06:25:20 d2.evaluation.evaluator]: [0mInference done 6365/8355. 0.1189 s / img. ETA=0:04:02
[32m[04/20 06:25:25 d2.evaluation.evaluator]: [0mInference done 6406/8355. 0.1189 s / img. ETA=0:03:57
[32m[04/20 06:25:31 d2.evaluation.evaluator]: [0mInference done 6448/8355. 0.1189 s / img. ETA=0:03:52
[32m[04/20 06:25:36 d2.evaluation.evaluator]: [0mInference done 6490/8355. 0.1189 s / img. ETA=0:03:47
[32m[04/20 06:25:41 d2.evaluation.evaluator]: [0mInference done 6532/8355. 0.1189 s / img. ETA=0:03:42
[32m[04/20 06:25:46 d2.evaluation.evaluator]: [0mInference done 6574/8355. 0.1189 s / img. ETA=0:03:37
[32m[04/20 06:25:51 d2.evaluation.evaluator]: [0mInference done 6616/8355. 0.1189 s / img. ETA=0:03:32
[32m[04/20 06:25:56 d2.evaluation.evaluator]: [0mInference done 6658/8355. 0.1189 s / img. ETA=0:03:26
[32m[04/20 06:26:01 d2.evaluation.evaluator]: [0mInference done 6700/8355. 0.1189 s / img. ETA=0:03:21
[32m[04/20 06:26:06 d2.evaluation.evaluator]: [0mInference done 6741/8355. 0.1189 s / img. ETA=0:03:16
[32m[04/20 06:26:11 d2.evaluation.evaluator]: [0mInference done 6783/8355. 0.1189 s / img. ETA=0:03:11
[32m[04/20 06:26:16 d2.evaluation.evaluator]: [0mInference done 6825/8355. 0.1189 s / img. ETA=0:03:06
[32m[04/20 06:26:21 d2.evaluation.evaluator]: [0mInference done 6866/8355. 0.1189 s / img. ETA=0:03:01
[32m[04/20 06:26:26 d2.evaluation.evaluator]: [0mInference done 6907/8355. 0.1189 s / img. ETA=0:02:56
[32m[04/20 06:26:31 d2.evaluation.evaluator]: [0mInference done 6949/8355. 0.1189 s / img. ETA=0:02:51
[32m[04/20 06:26:36 d2.evaluation.evaluator]: [0mInference done 6990/8355. 0.1189 s / img. ETA=0:02:46
[32m[04/20 06:26:42 d2.evaluation.evaluator]: [0mInference done 7031/8355. 0.1189 s / img. ETA=0:02:41
[32m[04/20 06:26:47 d2.evaluation.evaluator]: [0mInference done 7072/8355. 0.1189 s / img. ETA=0:02:36
[32m[04/20 06:26:52 d2.evaluation.evaluator]: [0mInference done 7113/8355. 0.1189 s / img. ETA=0:02:31
[32m[04/20 06:26:57 d2.evaluation.evaluator]: [0mInference done 7154/8355. 0.1189 s / img. ETA=0:02:26
[32m[04/20 06:27:02 d2.evaluation.evaluator]: [0mInference done 7195/8355. 0.1189 s / img. ETA=0:02:21
[32m[04/20 06:27:07 d2.evaluation.evaluator]: [0mInference done 7236/8355. 0.1189 s / img. ETA=0:02:16
[32m[04/20 06:27:12 d2.evaluation.evaluator]: [0mInference done 7277/8355. 0.1189 s / img. ETA=0:02:11
[32m[04/20 06:27:17 d2.evaluation.evaluator]: [0mInference done 7318/8355. 0.1189 s / img. ETA=0:02:06
[32m[04/20 06:27:22 d2.evaluation.evaluator]: [0mInference done 7359/8355. 0.1190 s / img. ETA=0:02:01
[32m[04/20 06:27:27 d2.evaluation.evaluator]: [0mInference done 7400/8355. 0.1190 s / img. ETA=0:01:56
[32m[04/20 06:27:32 d2.evaluation.evaluator]: [0mInference done 7441/8355. 0.1190 s / img. ETA=0:01:51
[32m[04/20 06:27:37 d2.evaluation.evaluator]: [0mInference done 7482/8355. 0.1190 s / img. ETA=0:01:46
[32m[04/20 06:27:42 d2.evaluation.evaluator]: [0mInference done 7523/8355. 0.1190 s / img. ETA=0:01:41
[32m[04/20 06:27:47 d2.evaluation.evaluator]: [0mInference done 7564/8355. 0.1190 s / img. ETA=0:01:36
[32m[04/20 06:27:52 d2.evaluation.evaluator]: [0mInference done 7606/8355. 0.1190 s / img. ETA=0:01:31
[32m[04/20 06:27:57 d2.evaluation.evaluator]: [0mInference done 7647/8355. 0.1190 s / img. ETA=0:01:26
[32m[04/20 06:28:02 d2.evaluation.evaluator]: [0mInference done 7688/8355. 0.1190 s / img. ETA=0:01:21
[32m[04/20 06:28:07 d2.evaluation.evaluator]: [0mInference done 7729/8355. 0.1190 s / img. ETA=0:01:16
[32m[04/20 06:28:12 d2.evaluation.evaluator]: [0mInference done 7770/8355. 0.1190 s / img. ETA=0:01:11
[32m[04/20 06:28:17 d2.evaluation.evaluator]: [0mInference done 7811/8355. 0.1190 s / img. ETA=0:01:06
[32m[04/20 06:28:22 d2.evaluation.evaluator]: [0mInference done 7852/8355. 0.1190 s / img. ETA=0:01:01
[32m[04/20 06:28:27 d2.evaluation.evaluator]: [0mInference done 7893/8355. 0.1190 s / img. ETA=0:00:56
[32m[04/20 06:28:32 d2.evaluation.evaluator]: [0mInference done 7934/8355. 0.1190 s / img. ETA=0:00:51
[32m[04/20 06:28:37 d2.evaluation.evaluator]: [0mInference done 7975/8355. 0.1190 s / img. ETA=0:00:46
[32m[04/20 06:28:43 d2.evaluation.evaluator]: [0mInference done 8016/8355. 0.1190 s / img. ETA=0:00:41
[32m[04/20 06:28:48 d2.evaluation.evaluator]: [0mInference done 8057/8355. 0.1190 s / img. ETA=0:00:36
[32m[04/20 06:28:53 d2.evaluation.evaluator]: [0mInference done 8099/8355. 0.1190 s / img. ETA=0:00:31
[32m[04/20 06:28:58 d2.evaluation.evaluator]: [0mInference done 8141/8355. 0.1190 s / img. ETA=0:00:26
[32m[04/20 06:29:03 d2.evaluation.evaluator]: [0mInference done 8183/8355. 0.1190 s / img. ETA=0:00:20
[32m[04/20 06:29:08 d2.evaluation.evaluator]: [0mInference done 8225/8355. 0.1190 s / img. ETA=0:00:15
[32m[04/20 06:29:13 d2.evaluation.evaluator]: [0mInference done 8267/8355. 0.1190 s / img. ETA=0:00:10
[32m[04/20 06:29:18 d2.evaluation.evaluator]: [0mInference done 8308/8355. 0.1190 s / img. ETA=0:00:05
[32m[04/20 06:29:23 d2.evaluation.evaluator]: [0mInference done 8349/8355. 0.1190 s / img. ETA=0:00:00
[32m[04/20 06:29:24 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:59.320224 (0.122074 s / img per device, on 1 devices)
[32m[04/20 06:29:24 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:33 (0.119010 s / img per device, on 1 devices)
[32m[04/20 06:29:24 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 06:29:24 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 06:29:25 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=24.66s).
Accumulating evaluation results...
DONE (t=2.93s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.203
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.411
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.170
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.293
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.410
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.091
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.249
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.352
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.450
[32m[04/20 06:29:52 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 20.251 | 41.138 | 17.000 | 12.659 | 29.310 | 41.012 |
[32m[04/20 06:29:52 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 24.670 | bicycle       | 6.019 | car            | 30.063 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | nan   | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    |               |       |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 06:29:54 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 06:29:54 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 06:29:54 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 06:29:56 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1187 s / img. ETA=0:02:31
[32m[04/20 06:30:01 d2.evaluation.evaluator]: [0mInference done 52/1257. 0.1190 s / img. ETA=0:02:27
[32m[04/20 06:30:06 d2.evaluation.evaluator]: [0mInference done 94/1257. 0.1187 s / img. ETA=0:02:21
[32m[04/20 06:30:11 d2.evaluation.evaluator]: [0mInference done 135/1257. 0.1188 s / img. ETA=0:02:16
[32m[04/20 06:30:16 d2.evaluation.evaluator]: [0mInference done 177/1257. 0.1188 s / img. ETA=0:02:11
[32m[04/20 06:30:21 d2.evaluation.evaluator]: [0mInference done 218/1257. 0.1192 s / img. ETA=0:02:07
[32m[04/20 06:30:26 d2.evaluation.evaluator]: [0mInference done 260/1257. 0.1191 s / img. ETA=0:02:01
[32m[04/20 06:30:31 d2.evaluation.evaluator]: [0mInference done 302/1257. 0.1190 s / img. ETA=0:01:56
[32m[04/20 06:30:36 d2.evaluation.evaluator]: [0mInference done 344/1257. 0.1190 s / img. ETA=0:01:51
[32m[04/20 06:30:42 d2.evaluation.evaluator]: [0mInference done 386/1257. 0.1189 s / img. ETA=0:01:46
[32m[04/20 06:30:47 d2.evaluation.evaluator]: [0mInference done 428/1257. 0.1189 s / img. ETA=0:01:41
[32m[04/20 06:30:52 d2.evaluation.evaluator]: [0mInference done 469/1257. 0.1189 s / img. ETA=0:01:36
[32m[04/20 06:30:57 d2.evaluation.evaluator]: [0mInference done 510/1257. 0.1189 s / img. ETA=0:01:31
[32m[04/20 06:31:02 d2.evaluation.evaluator]: [0mInference done 551/1257. 0.1189 s / img. ETA=0:01:26
[32m[04/20 06:31:07 d2.evaluation.evaluator]: [0mInference done 592/1257. 0.1191 s / img. ETA=0:01:21
[32m[04/20 06:31:12 d2.evaluation.evaluator]: [0mInference done 633/1257. 0.1191 s / img. ETA=0:01:16
[32m[04/20 06:31:17 d2.evaluation.evaluator]: [0mInference done 674/1257. 0.1191 s / img. ETA=0:01:11
[32m[04/20 06:31:22 d2.evaluation.evaluator]: [0mInference done 715/1257. 0.1191 s / img. ETA=0:01:06
[32m[04/20 06:31:27 d2.evaluation.evaluator]: [0mInference done 756/1257. 0.1191 s / img. ETA=0:01:01
[32m[04/20 06:31:32 d2.evaluation.evaluator]: [0mInference done 797/1257. 0.1191 s / img. ETA=0:00:56
[32m[04/20 06:31:37 d2.evaluation.evaluator]: [0mInference done 838/1257. 0.1191 s / img. ETA=0:00:51
[32m[04/20 06:31:42 d2.evaluation.evaluator]: [0mInference done 879/1257. 0.1191 s / img. ETA=0:00:46
[32m[04/20 06:31:47 d2.evaluation.evaluator]: [0mInference done 920/1257. 0.1191 s / img. ETA=0:00:41
[32m[04/20 06:31:52 d2.evaluation.evaluator]: [0mInference done 961/1257. 0.1192 s / img. ETA=0:00:36
[32m[04/20 06:31:57 d2.evaluation.evaluator]: [0mInference done 1002/1257. 0.1192 s / img. ETA=0:00:31
[32m[04/20 06:32:02 d2.evaluation.evaluator]: [0mInference done 1043/1257. 0.1192 s / img. ETA=0:00:26
[32m[04/20 06:32:07 d2.evaluation.evaluator]: [0mInference done 1084/1257. 0.1192 s / img. ETA=0:00:21
[32m[04/20 06:32:12 d2.evaluation.evaluator]: [0mInference done 1125/1257. 0.1192 s / img. ETA=0:00:16
[32m[04/20 06:32:17 d2.evaluation.evaluator]: [0mInference done 1166/1257. 0.1192 s / img. ETA=0:00:11
[32m[04/20 06:32:22 d2.evaluation.evaluator]: [0mInference done 1208/1257. 0.1192 s / img. ETA=0:00:06
[32m[04/20 06:32:27 d2.evaluation.evaluator]: [0mInference done 1249/1257. 0.1192 s / img. ETA=0:00:00
[32m[04/20 06:32:28 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:33.428737 (0.122547 s / img per device, on 1 devices)
[32m[04/20 06:32:28 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:29 (0.119224 s / img per device, on 1 devices)
[32m[04/20 06:32:29 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 06:32:29 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 06:32:29 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.05s).
Accumulating evaluation results...
DONE (t=0.43s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.171
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.337
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.154
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.096
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.209
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.322
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.086
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.208
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.209
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.130
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.254
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.352
[32m[04/20 06:32:32 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 17.138 | 33.668 | 15.351 | 9.639 | 20.851 | 32.222 |
[32m[04/20 06:32:32 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 17.635 | bicycle       | 1.304 | car            | 32.474 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | nan   | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  2  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 06:32:33 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 06:32:34 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 06:32:34 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 06:32:35 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 06:32:35 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 06:32:35 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 06:32:35 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 06:32:57 d2.utils.events]: [0m eta: 0:17:21  iter: 19  total_loss: 0.800  loss_cls: 0.282  loss_box_reg: 0.379  loss_rpn_cls: 0.035  loss_rpn_loc: 0.076  time: 1.0547  data_time: 0.0551  lr: 0.000100  max_mem: 5405M
[32m[04/20 06:33:17 d2.utils.events]: [0m eta: 0:16:38  iter: 39  total_loss: 0.647  loss_cls: 0.222  loss_box_reg: 0.327  loss_rpn_cls: 0.028  loss_rpn_loc: 0.063  time: 1.0326  data_time: 0.0184  lr: 0.000200  max_mem: 5405M
[32m[04/20 06:33:38 d2.utils.events]: [0m eta: 0:16:31  iter: 59  total_loss: 0.774  loss_cls: 0.258  loss_box_reg: 0.384  loss_rpn_cls: 0.036  loss_rpn_loc: 0.067  time: 1.0389  data_time: 0.0143  lr: 0.000300  max_mem: 5405M
[32m[04/20 06:33:59 d2.utils.events]: [0m eta: 0:16:13  iter: 79  total_loss: 0.650  loss_cls: 0.224  loss_box_reg: 0.350  loss_rpn_cls: 0.027  loss_rpn_loc: 0.053  time: 1.0411  data_time: 0.0187  lr: 0.000400  max_mem: 5405M
[32m[04/20 06:34:20 d2.utils.events]: [0m eta: 0:15:53  iter: 99  total_loss: 0.615  loss_cls: 0.207  loss_box_reg: 0.294  loss_rpn_cls: 0.024  loss_rpn_loc: 0.064  time: 1.0445  data_time: 0.0186  lr: 0.000500  max_mem: 5405M
[32m[04/20 06:34:41 d2.utils.events]: [0m eta: 0:15:32  iter: 119  total_loss: 0.720  loss_cls: 0.246  loss_box_reg: 0.391  loss_rpn_cls: 0.028  loss_rpn_loc: 0.063  time: 1.0455  data_time: 0.0161  lr: 0.000599  max_mem: 5405M
[32m[04/20 06:35:02 d2.utils.events]: [0m eta: 0:15:13  iter: 139  total_loss: 0.740  loss_cls: 0.236  loss_box_reg: 0.392  loss_rpn_cls: 0.028  loss_rpn_loc: 0.054  time: 1.0459  data_time: 0.0183  lr: 0.000699  max_mem: 5405M
[32m[04/20 06:35:23 d2.utils.events]: [0m eta: 0:14:50  iter: 159  total_loss: 0.739  loss_cls: 0.251  loss_box_reg: 0.373  loss_rpn_cls: 0.028  loss_rpn_loc: 0.055  time: 1.0435  data_time: 0.0165  lr: 0.000799  max_mem: 5405M
[32m[04/20 06:35:44 d2.utils.events]: [0m eta: 0:14:33  iter: 179  total_loss: 0.749  loss_cls: 0.248  loss_box_reg: 0.372  loss_rpn_cls: 0.031  loss_rpn_loc: 0.070  time: 1.0466  data_time: 0.0186  lr: 0.000899  max_mem: 5405M
[32m[04/20 06:36:05 d2.utils.events]: [0m eta: 0:14:11  iter: 199  total_loss: 0.663  loss_cls: 0.231  loss_box_reg: 0.335  loss_rpn_cls: 0.026  loss_rpn_loc: 0.053  time: 1.0474  data_time: 0.0186  lr: 0.000999  max_mem: 5405M
[32m[04/20 06:36:26 d2.utils.events]: [0m eta: 0:13:49  iter: 219  total_loss: 0.639  loss_cls: 0.224  loss_box_reg: 0.337  loss_rpn_cls: 0.024  loss_rpn_loc: 0.050  time: 1.0461  data_time: 0.0181  lr: 0.001099  max_mem: 5405M
[32m[04/20 06:36:47 d2.utils.events]: [0m eta: 0:13:29  iter: 239  total_loss: 0.716  loss_cls: 0.245  loss_box_reg: 0.382  loss_rpn_cls: 0.025  loss_rpn_loc: 0.067  time: 1.0466  data_time: 0.0157  lr: 0.001199  max_mem: 5405M
[32m[04/20 06:37:08 d2.utils.events]: [0m eta: 0:13:07  iter: 259  total_loss: 0.698  loss_cls: 0.235  loss_box_reg: 0.347  loss_rpn_cls: 0.029  loss_rpn_loc: 0.072  time: 1.0471  data_time: 0.0182  lr: 0.001299  max_mem: 5405M
[32m[04/20 06:37:29 d2.utils.events]: [0m eta: 0:12:46  iter: 279  total_loss: 0.731  loss_cls: 0.253  loss_box_reg: 0.372  loss_rpn_cls: 0.024  loss_rpn_loc: 0.065  time: 1.0467  data_time: 0.0171  lr: 0.001399  max_mem: 5405M
[32m[04/20 06:37:50 d2.utils.events]: [0m eta: 0:12:25  iter: 299  total_loss: 0.647  loss_cls: 0.219  loss_box_reg: 0.316  loss_rpn_cls: 0.029  loss_rpn_loc: 0.063  time: 1.0471  data_time: 0.0151  lr: 0.001499  max_mem: 5405M
[32m[04/20 06:38:11 d2.utils.events]: [0m eta: 0:12:04  iter: 319  total_loss: 0.732  loss_cls: 0.235  loss_box_reg: 0.389  loss_rpn_cls: 0.028  loss_rpn_loc: 0.071  time: 1.0475  data_time: 0.0181  lr: 0.001598  max_mem: 5405M
[32m[04/20 06:38:32 d2.utils.events]: [0m eta: 0:11:41  iter: 339  total_loss: 0.705  loss_cls: 0.234  loss_box_reg: 0.368  loss_rpn_cls: 0.030  loss_rpn_loc: 0.068  time: 1.0462  data_time: 0.0191  lr: 0.001698  max_mem: 5405M
[32m[04/20 06:38:53 d2.utils.events]: [0m eta: 0:11:21  iter: 359  total_loss: 0.751  loss_cls: 0.241  loss_box_reg: 0.373  loss_rpn_cls: 0.030  loss_rpn_loc: 0.063  time: 1.0466  data_time: 0.0177  lr: 0.001798  max_mem: 5405M
[32m[04/20 06:39:14 d2.utils.events]: [0m eta: 0:11:00  iter: 379  total_loss: 0.706  loss_cls: 0.232  loss_box_reg: 0.370  loss_rpn_cls: 0.024  loss_rpn_loc: 0.059  time: 1.0469  data_time: 0.0195  lr: 0.001898  max_mem: 5405M
[32m[04/20 06:39:35 d2.utils.events]: [0m eta: 0:10:39  iter: 399  total_loss: 0.638  loss_cls: 0.224  loss_box_reg: 0.333  loss_rpn_cls: 0.023  loss_rpn_loc: 0.051  time: 1.0471  data_time: 0.0174  lr: 0.001998  max_mem: 5405M
[32m[04/20 06:39:56 d2.utils.events]: [0m eta: 0:10:17  iter: 419  total_loss: 0.753  loss_cls: 0.247  loss_box_reg: 0.384  loss_rpn_cls: 0.028  loss_rpn_loc: 0.073  time: 1.0465  data_time: 0.0163  lr: 0.002098  max_mem: 5405M
[32m[04/20 06:40:17 d2.utils.events]: [0m eta: 0:09:55  iter: 439  total_loss: 0.680  loss_cls: 0.224  loss_box_reg: 0.361  loss_rpn_cls: 0.028  loss_rpn_loc: 0.063  time: 1.0456  data_time: 0.0176  lr: 0.002198  max_mem: 5405M
[32m[04/20 06:40:38 d2.utils.events]: [0m eta: 0:09:34  iter: 459  total_loss: 0.721  loss_cls: 0.254  loss_box_reg: 0.393  loss_rpn_cls: 0.025  loss_rpn_loc: 0.055  time: 1.0455  data_time: 0.0172  lr: 0.002298  max_mem: 5405M
[32m[04/20 06:40:59 d2.utils.events]: [0m eta: 0:09:12  iter: 479  total_loss: 0.666  loss_cls: 0.231  loss_box_reg: 0.353  loss_rpn_cls: 0.027  loss_rpn_loc: 0.053  time: 1.0454  data_time: 0.0156  lr: 0.002398  max_mem: 5405M
[32m[04/20 06:41:20 d2.utils.events]: [0m eta: 0:08:51  iter: 499  total_loss: 0.712  loss_cls: 0.238  loss_box_reg: 0.377  loss_rpn_cls: 0.027  loss_rpn_loc: 0.065  time: 1.0457  data_time: 0.0171  lr: 0.002498  max_mem: 5405M
[32m[04/20 06:41:41 d2.utils.events]: [0m eta: 0:08:30  iter: 519  total_loss: 0.612  loss_cls: 0.207  loss_box_reg: 0.310  loss_rpn_cls: 0.026  loss_rpn_loc: 0.058  time: 1.0459  data_time: 0.0193  lr: 0.002597  max_mem: 5405M
[32m[04/20 06:42:02 d2.utils.events]: [0m eta: 0:08:09  iter: 539  total_loss: 0.670  loss_cls: 0.237  loss_box_reg: 0.351  loss_rpn_cls: 0.026  loss_rpn_loc: 0.056  time: 1.0465  data_time: 0.0163  lr: 0.002697  max_mem: 5405M
[32m[04/20 06:42:23 d2.utils.events]: [0m eta: 0:07:47  iter: 559  total_loss: 0.761  loss_cls: 0.247  loss_box_reg: 0.376  loss_rpn_cls: 0.028  loss_rpn_loc: 0.059  time: 1.0460  data_time: 0.0156  lr: 0.002797  max_mem: 5405M
[32m[04/20 06:42:44 d2.utils.events]: [0m eta: 0:07:26  iter: 579  total_loss: 0.756  loss_cls: 0.266  loss_box_reg: 0.400  loss_rpn_cls: 0.030  loss_rpn_loc: 0.069  time: 1.0465  data_time: 0.0156  lr: 0.002897  max_mem: 5405M
[32m[04/20 06:43:05 d2.utils.events]: [0m eta: 0:07:05  iter: 599  total_loss: 0.683  loss_cls: 0.230  loss_box_reg: 0.344  loss_rpn_cls: 0.026  loss_rpn_loc: 0.053  time: 1.0462  data_time: 0.0177  lr: 0.002997  max_mem: 5405M
[32m[04/20 06:43:25 d2.utils.events]: [0m eta: 0:06:44  iter: 619  total_loss: 0.708  loss_cls: 0.237  loss_box_reg: 0.354  loss_rpn_cls: 0.031  loss_rpn_loc: 0.066  time: 1.0458  data_time: 0.0183  lr: 0.003097  max_mem: 5405M
[32m[04/20 06:43:46 d2.utils.events]: [0m eta: 0:06:23  iter: 639  total_loss: 0.691  loss_cls: 0.237  loss_box_reg: 0.337  loss_rpn_cls: 0.030  loss_rpn_loc: 0.074  time: 1.0458  data_time: 0.0219  lr: 0.003197  max_mem: 5405M
[32m[04/20 06:44:07 d2.utils.events]: [0m eta: 0:06:01  iter: 659  total_loss: 0.749  loss_cls: 0.238  loss_box_reg: 0.338  loss_rpn_cls: 0.032  loss_rpn_loc: 0.053  time: 1.0453  data_time: 0.0211  lr: 0.003297  max_mem: 5405M
[32m[04/20 06:44:28 d2.utils.events]: [0m eta: 0:05:40  iter: 679  total_loss: 0.672  loss_cls: 0.236  loss_box_reg: 0.363  loss_rpn_cls: 0.028  loss_rpn_loc: 0.060  time: 1.0449  data_time: 0.0162  lr: 0.003397  max_mem: 5405M
[32m[04/20 06:44:48 d2.utils.events]: [0m eta: 0:05:18  iter: 699  total_loss: 0.684  loss_cls: 0.239  loss_box_reg: 0.347  loss_rpn_cls: 0.033  loss_rpn_loc: 0.071  time: 1.0443  data_time: 0.0143  lr: 0.003497  max_mem: 5405M
[32m[04/20 06:45:09 d2.utils.events]: [0m eta: 0:04:57  iter: 719  total_loss: 0.740  loss_cls: 0.249  loss_box_reg: 0.382  loss_rpn_cls: 0.035  loss_rpn_loc: 0.067  time: 1.0442  data_time: 0.0188  lr: 0.003596  max_mem: 5405M
[32m[04/20 06:45:30 d2.utils.events]: [0m eta: 0:04:35  iter: 739  total_loss: 0.622  loss_cls: 0.201  loss_box_reg: 0.321  loss_rpn_cls: 0.024  loss_rpn_loc: 0.056  time: 1.0439  data_time: 0.0202  lr: 0.003696  max_mem: 5405M
[32m[04/20 06:45:51 d2.utils.events]: [0m eta: 0:04:14  iter: 759  total_loss: 0.611  loss_cls: 0.198  loss_box_reg: 0.307  loss_rpn_cls: 0.033  loss_rpn_loc: 0.073  time: 1.0437  data_time: 0.0154  lr: 0.003796  max_mem: 5405M
[32m[04/20 06:46:11 d2.utils.events]: [0m eta: 0:03:53  iter: 779  total_loss: 0.694  loss_cls: 0.246  loss_box_reg: 0.340  loss_rpn_cls: 0.038  loss_rpn_loc: 0.060  time: 1.0434  data_time: 0.0160  lr: 0.003896  max_mem: 5405M
[32m[04/20 06:46:32 d2.utils.events]: [0m eta: 0:03:32  iter: 799  total_loss: 0.661  loss_cls: 0.234  loss_box_reg: 0.318  loss_rpn_cls: 0.035  loss_rpn_loc: 0.061  time: 1.0429  data_time: 0.0164  lr: 0.003996  max_mem: 5405M
[32m[04/20 06:46:52 d2.utils.events]: [0m eta: 0:03:10  iter: 819  total_loss: 0.775  loss_cls: 0.255  loss_box_reg: 0.386  loss_rpn_cls: 0.035  loss_rpn_loc: 0.072  time: 1.0424  data_time: 0.0147  lr: 0.004096  max_mem: 5405M
[32m[04/20 06:47:13 d2.utils.events]: [0m eta: 0:02:49  iter: 839  total_loss: 0.701  loss_cls: 0.227  loss_box_reg: 0.357  loss_rpn_cls: 0.029  loss_rpn_loc: 0.057  time: 1.0418  data_time: 0.0146  lr: 0.004196  max_mem: 5405M
[32m[04/20 06:47:33 d2.utils.events]: [0m eta: 0:02:28  iter: 859  total_loss: 0.721  loss_cls: 0.242  loss_box_reg: 0.375  loss_rpn_cls: 0.036  loss_rpn_loc: 0.085  time: 1.0413  data_time: 0.0161  lr: 0.004296  max_mem: 5405M
[32m[04/20 06:47:54 d2.utils.events]: [0m eta: 0:02:07  iter: 879  total_loss: 0.744  loss_cls: 0.238  loss_box_reg: 0.361  loss_rpn_cls: 0.034  loss_rpn_loc: 0.064  time: 1.0410  data_time: 0.0181  lr: 0.004396  max_mem: 5405M
[32m[04/20 06:48:15 d2.utils.events]: [0m eta: 0:01:46  iter: 899  total_loss: 0.630  loss_cls: 0.205  loss_box_reg: 0.327  loss_rpn_cls: 0.027  loss_rpn_loc: 0.059  time: 1.0410  data_time: 0.0165  lr: 0.004496  max_mem: 5405M
[32m[04/20 06:48:36 d2.utils.events]: [0m eta: 0:01:25  iter: 919  total_loss: 0.727  loss_cls: 0.236  loss_box_reg: 0.380  loss_rpn_cls: 0.028  loss_rpn_loc: 0.068  time: 1.0414  data_time: 0.0164  lr: 0.004595  max_mem: 5405M
[32m[04/20 06:48:56 d2.utils.events]: [0m eta: 0:01:04  iter: 939  total_loss: 0.760  loss_cls: 0.248  loss_box_reg: 0.418  loss_rpn_cls: 0.033  loss_rpn_loc: 0.073  time: 1.0408  data_time: 0.0177  lr: 0.004695  max_mem: 5405M
[32m[04/20 06:49:17 d2.utils.events]: [0m eta: 0:00:43  iter: 959  total_loss: 0.654  loss_cls: 0.209  loss_box_reg: 0.318  loss_rpn_cls: 0.032  loss_rpn_loc: 0.060  time: 1.0406  data_time: 0.0132  lr: 0.004795  max_mem: 5405M
[32m[04/20 06:49:38 d2.utils.events]: [0m eta: 0:00:22  iter: 979  total_loss: 0.776  loss_cls: 0.252  loss_box_reg: 0.366  loss_rpn_cls: 0.032  loss_rpn_loc: 0.071  time: 1.0406  data_time: 0.0162  lr: 0.004895  max_mem: 5405M
[5m[31mWARNING[0m [32m[04/20 06:50:02 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 06:50:02 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 06:50:02 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 06:50:02 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.702  loss_cls: 0.236  loss_box_reg: 0.355  loss_rpn_cls: 0.032  loss_rpn_loc: 0.066  time: 1.0407  data_time: 0.0188  lr: 0.004995  max_mem: 5405M
[32m[04/20 06:50:03 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:18 (1.0418 s / it)
[32m[04/20 06:50:03 d2.engine.hooks]: [0mTotal training time: 0:17:25 (0:00:07 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 06:50:07 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 06:50:07 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 06:50:08 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 06:50:09 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1181 s / img. ETA=0:16:43
[32m[04/20 06:50:14 d2.evaluation.evaluator]: [0mInference done 52/8355. 0.1189 s / img. ETA=0:16:51
[32m[04/20 06:50:19 d2.evaluation.evaluator]: [0mInference done 94/8355. 0.1186 s / img. ETA=0:16:43
[32m[04/20 06:50:24 d2.evaluation.evaluator]: [0mInference done 136/8355. 0.1183 s / img. ETA=0:16:35
[32m[04/20 06:50:30 d2.evaluation.evaluator]: [0mInference done 178/8355. 0.1183 s / img. ETA=0:16:29
[32m[04/20 06:50:35 d2.evaluation.evaluator]: [0mInference done 220/8355. 0.1182 s / img. ETA=0:16:24
[32m[04/20 06:50:40 d2.evaluation.evaluator]: [0mInference done 262/8355. 0.1183 s / img. ETA=0:16:20
[32m[04/20 06:50:45 d2.evaluation.evaluator]: [0mInference done 303/8355. 0.1184 s / img. ETA=0:16:16
[32m[04/20 06:50:50 d2.evaluation.evaluator]: [0mInference done 345/8355. 0.1184 s / img. ETA=0:16:11
[32m[04/20 06:50:55 d2.evaluation.evaluator]: [0mInference done 387/8355. 0.1184 s / img. ETA=0:16:06
[32m[04/20 06:51:00 d2.evaluation.evaluator]: [0mInference done 429/8355. 0.1183 s / img. ETA=0:16:00
[32m[04/20 06:51:05 d2.evaluation.evaluator]: [0mInference done 471/8355. 0.1183 s / img. ETA=0:15:54
[32m[04/20 06:51:10 d2.evaluation.evaluator]: [0mInference done 513/8355. 0.1182 s / img. ETA=0:15:49
[32m[04/20 06:51:15 d2.evaluation.evaluator]: [0mInference done 555/8355. 0.1183 s / img. ETA=0:15:44
[32m[04/20 06:51:20 d2.evaluation.evaluator]: [0mInference done 597/8355. 0.1182 s / img. ETA=0:15:39
[32m[04/20 06:51:25 d2.evaluation.evaluator]: [0mInference done 639/8355. 0.1182 s / img. ETA=0:15:34
[32m[04/20 06:51:30 d2.evaluation.evaluator]: [0mInference done 680/8355. 0.1183 s / img. ETA=0:15:30
[32m[04/20 06:51:36 d2.evaluation.evaluator]: [0mInference done 722/8355. 0.1183 s / img. ETA=0:15:25
[32m[04/20 06:51:41 d2.evaluation.evaluator]: [0mInference done 764/8355. 0.1183 s / img. ETA=0:15:20
[32m[04/20 06:51:46 d2.evaluation.evaluator]: [0mInference done 805/8355. 0.1183 s / img. ETA=0:15:15
[32m[04/20 06:51:51 d2.evaluation.evaluator]: [0mInference done 847/8355. 0.1183 s / img. ETA=0:15:10
[32m[04/20 06:51:56 d2.evaluation.evaluator]: [0mInference done 889/8355. 0.1183 s / img. ETA=0:15:05
[32m[04/20 06:52:01 d2.evaluation.evaluator]: [0mInference done 930/8355. 0.1184 s / img. ETA=0:15:00
[32m[04/20 06:52:06 d2.evaluation.evaluator]: [0mInference done 972/8355. 0.1183 s / img. ETA=0:14:55
[32m[04/20 06:52:11 d2.evaluation.evaluator]: [0mInference done 1014/8355. 0.1183 s / img. ETA=0:14:50
[32m[04/20 06:52:16 d2.evaluation.evaluator]: [0mInference done 1056/8355. 0.1183 s / img. ETA=0:14:45
[32m[04/20 06:52:21 d2.evaluation.evaluator]: [0mInference done 1098/8355. 0.1183 s / img. ETA=0:14:39
[32m[04/20 06:52:26 d2.evaluation.evaluator]: [0mInference done 1140/8355. 0.1183 s / img. ETA=0:14:34
[32m[04/20 06:52:31 d2.evaluation.evaluator]: [0mInference done 1182/8355. 0.1183 s / img. ETA=0:14:29
[32m[04/20 06:52:36 d2.evaluation.evaluator]: [0mInference done 1224/8355. 0.1183 s / img. ETA=0:14:24
[32m[04/20 06:52:41 d2.evaluation.evaluator]: [0mInference done 1266/8355. 0.1183 s / img. ETA=0:14:19
[32m[04/20 06:52:47 d2.evaluation.evaluator]: [0mInference done 1308/8355. 0.1182 s / img. ETA=0:14:14
[32m[04/20 06:52:52 d2.evaluation.evaluator]: [0mInference done 1350/8355. 0.1182 s / img. ETA=0:14:08
[32m[04/20 06:52:57 d2.evaluation.evaluator]: [0mInference done 1392/8355. 0.1182 s / img. ETA=0:14:03
[32m[04/20 06:53:02 d2.evaluation.evaluator]: [0mInference done 1433/8355. 0.1182 s / img. ETA=0:13:58
[32m[04/20 06:53:07 d2.evaluation.evaluator]: [0mInference done 1475/8355. 0.1182 s / img. ETA=0:13:53
[32m[04/20 06:53:12 d2.evaluation.evaluator]: [0mInference done 1516/8355. 0.1183 s / img. ETA=0:13:48
[32m[04/20 06:53:17 d2.evaluation.evaluator]: [0mInference done 1557/8355. 0.1183 s / img. ETA=0:13:44
[32m[04/20 06:53:22 d2.evaluation.evaluator]: [0mInference done 1599/8355. 0.1183 s / img. ETA=0:13:39
[32m[04/20 06:53:27 d2.evaluation.evaluator]: [0mInference done 1640/8355. 0.1183 s / img. ETA=0:13:34
[32m[04/20 06:53:32 d2.evaluation.evaluator]: [0mInference done 1682/8355. 0.1183 s / img. ETA=0:13:29
[32m[04/20 06:53:37 d2.evaluation.evaluator]: [0mInference done 1723/8355. 0.1183 s / img. ETA=0:13:24
[32m[04/20 06:53:42 d2.evaluation.evaluator]: [0mInference done 1764/8355. 0.1184 s / img. ETA=0:13:19
[32m[04/20 06:53:47 d2.evaluation.evaluator]: [0mInference done 1805/8355. 0.1184 s / img. ETA=0:13:14
[32m[04/20 06:53:52 d2.evaluation.evaluator]: [0mInference done 1847/8355. 0.1184 s / img. ETA=0:13:09
[32m[04/20 06:53:57 d2.evaluation.evaluator]: [0mInference done 1888/8355. 0.1184 s / img. ETA=0:13:04
[32m[04/20 06:54:02 d2.evaluation.evaluator]: [0mInference done 1930/8355. 0.1184 s / img. ETA=0:12:59
[32m[04/20 06:54:07 d2.evaluation.evaluator]: [0mInference done 1972/8355. 0.1184 s / img. ETA=0:12:54
[32m[04/20 06:54:12 d2.evaluation.evaluator]: [0mInference done 2014/8355. 0.1184 s / img. ETA=0:12:49
[32m[04/20 06:54:18 d2.evaluation.evaluator]: [0mInference done 2056/8355. 0.1184 s / img. ETA=0:12:44
[32m[04/20 06:54:23 d2.evaluation.evaluator]: [0mInference done 2098/8355. 0.1184 s / img. ETA=0:12:39
[32m[04/20 06:54:28 d2.evaluation.evaluator]: [0mInference done 2140/8355. 0.1184 s / img. ETA=0:12:34
[32m[04/20 06:54:33 d2.evaluation.evaluator]: [0mInference done 2181/8355. 0.1184 s / img. ETA=0:12:29
[32m[04/20 06:54:38 d2.evaluation.evaluator]: [0mInference done 2222/8355. 0.1185 s / img. ETA=0:12:24
[32m[04/20 06:54:43 d2.evaluation.evaluator]: [0mInference done 2264/8355. 0.1185 s / img. ETA=0:12:19
[32m[04/20 06:54:48 d2.evaluation.evaluator]: [0mInference done 2305/8355. 0.1185 s / img. ETA=0:12:14
[32m[04/20 06:54:53 d2.evaluation.evaluator]: [0mInference done 2346/8355. 0.1185 s / img. ETA=0:12:09
[32m[04/20 06:54:58 d2.evaluation.evaluator]: [0mInference done 2388/8355. 0.1185 s / img. ETA=0:12:04
[32m[04/20 06:55:03 d2.evaluation.evaluator]: [0mInference done 2429/8355. 0.1185 s / img. ETA=0:11:59
[32m[04/20 06:55:08 d2.evaluation.evaluator]: [0mInference done 2470/8355. 0.1185 s / img. ETA=0:11:55
[32m[04/20 06:55:13 d2.evaluation.evaluator]: [0mInference done 2512/8355. 0.1185 s / img. ETA=0:11:49
[32m[04/20 06:55:18 d2.evaluation.evaluator]: [0mInference done 2553/8355. 0.1185 s / img. ETA=0:11:45
[32m[04/20 06:55:23 d2.evaluation.evaluator]: [0mInference done 2595/8355. 0.1185 s / img. ETA=0:11:39
[32m[04/20 06:55:28 d2.evaluation.evaluator]: [0mInference done 2637/8355. 0.1185 s / img. ETA=0:11:34
[32m[04/20 06:55:33 d2.evaluation.evaluator]: [0mInference done 2678/8355. 0.1185 s / img. ETA=0:11:29
[32m[04/20 06:55:39 d2.evaluation.evaluator]: [0mInference done 2720/8355. 0.1185 s / img. ETA=0:11:24
[32m[04/20 06:55:44 d2.evaluation.evaluator]: [0mInference done 2762/8355. 0.1185 s / img. ETA=0:11:19
[32m[04/20 06:55:49 d2.evaluation.evaluator]: [0mInference done 2803/8355. 0.1185 s / img. ETA=0:11:14
[32m[04/20 06:55:54 d2.evaluation.evaluator]: [0mInference done 2844/8355. 0.1185 s / img. ETA=0:11:09
[32m[04/20 06:55:59 d2.evaluation.evaluator]: [0mInference done 2886/8355. 0.1185 s / img. ETA=0:11:04
[32m[04/20 06:56:04 d2.evaluation.evaluator]: [0mInference done 2928/8355. 0.1185 s / img. ETA=0:10:59
[32m[04/20 06:56:09 d2.evaluation.evaluator]: [0mInference done 2970/8355. 0.1186 s / img. ETA=0:10:54
[32m[04/20 06:56:14 d2.evaluation.evaluator]: [0mInference done 3012/8355. 0.1185 s / img. ETA=0:10:49
[32m[04/20 06:56:19 d2.evaluation.evaluator]: [0mInference done 3053/8355. 0.1186 s / img. ETA=0:10:44
[32m[04/20 06:56:24 d2.evaluation.evaluator]: [0mInference done 3094/8355. 0.1186 s / img. ETA=0:10:39
[32m[04/20 06:56:29 d2.evaluation.evaluator]: [0mInference done 3135/8355. 0.1186 s / img. ETA=0:10:34
[32m[04/20 06:56:34 d2.evaluation.evaluator]: [0mInference done 3177/8355. 0.1186 s / img. ETA=0:10:29
[32m[04/20 06:56:39 d2.evaluation.evaluator]: [0mInference done 3219/8355. 0.1186 s / img. ETA=0:10:24
[32m[04/20 06:56:44 d2.evaluation.evaluator]: [0mInference done 3261/8355. 0.1186 s / img. ETA=0:10:19
[32m[04/20 06:56:49 d2.evaluation.evaluator]: [0mInference done 3302/8355. 0.1186 s / img. ETA=0:10:14
[32m[04/20 06:56:54 d2.evaluation.evaluator]: [0mInference done 3343/8355. 0.1186 s / img. ETA=0:10:09
[32m[04/20 06:57:00 d2.evaluation.evaluator]: [0mInference done 3385/8355. 0.1186 s / img. ETA=0:10:04
[32m[04/20 06:57:05 d2.evaluation.evaluator]: [0mInference done 3426/8355. 0.1186 s / img. ETA=0:09:59
[32m[04/20 06:57:10 d2.evaluation.evaluator]: [0mInference done 3467/8355. 0.1186 s / img. ETA=0:09:54
[32m[04/20 06:57:15 d2.evaluation.evaluator]: [0mInference done 3508/8355. 0.1186 s / img. ETA=0:09:49
[32m[04/20 06:57:20 d2.evaluation.evaluator]: [0mInference done 3549/8355. 0.1186 s / img. ETA=0:09:44
[32m[04/20 06:57:25 d2.evaluation.evaluator]: [0mInference done 3590/8355. 0.1186 s / img. ETA=0:09:39
[32m[04/20 06:57:30 d2.evaluation.evaluator]: [0mInference done 3632/8355. 0.1186 s / img. ETA=0:09:34
[32m[04/20 06:57:35 d2.evaluation.evaluator]: [0mInference done 3674/8355. 0.1186 s / img. ETA=0:09:29
[32m[04/20 06:57:40 d2.evaluation.evaluator]: [0mInference done 3716/8355. 0.1186 s / img. ETA=0:09:24
[32m[04/20 06:57:45 d2.evaluation.evaluator]: [0mInference done 3758/8355. 0.1186 s / img. ETA=0:09:19
[32m[04/20 06:57:50 d2.evaluation.evaluator]: [0mInference done 3800/8355. 0.1186 s / img. ETA=0:09:13
[32m[04/20 06:57:55 d2.evaluation.evaluator]: [0mInference done 3841/8355. 0.1186 s / img. ETA=0:09:09
[32m[04/20 06:58:00 d2.evaluation.evaluator]: [0mInference done 3882/8355. 0.1186 s / img. ETA=0:09:04
[32m[04/20 06:58:05 d2.evaluation.evaluator]: [0mInference done 3924/8355. 0.1186 s / img. ETA=0:08:58
[32m[04/20 06:58:10 d2.evaluation.evaluator]: [0mInference done 3965/8355. 0.1186 s / img. ETA=0:08:54
[32m[04/20 06:58:15 d2.evaluation.evaluator]: [0mInference done 4007/8355. 0.1186 s / img. ETA=0:08:48
[32m[04/20 06:58:20 d2.evaluation.evaluator]: [0mInference done 4048/8355. 0.1186 s / img. ETA=0:08:43
[32m[04/20 06:58:26 d2.evaluation.evaluator]: [0mInference done 4090/8355. 0.1186 s / img. ETA=0:08:38
[32m[04/20 06:58:31 d2.evaluation.evaluator]: [0mInference done 4131/8355. 0.1186 s / img. ETA=0:08:33
[32m[04/20 06:58:36 d2.evaluation.evaluator]: [0mInference done 4173/8355. 0.1186 s / img. ETA=0:08:28
[32m[04/20 06:58:41 d2.evaluation.evaluator]: [0mInference done 4214/8355. 0.1187 s / img. ETA=0:08:23
[32m[04/20 06:58:46 d2.evaluation.evaluator]: [0mInference done 4255/8355. 0.1187 s / img. ETA=0:08:18
[32m[04/20 06:58:51 d2.evaluation.evaluator]: [0mInference done 4297/8355. 0.1187 s / img. ETA=0:08:13
[32m[04/20 06:58:56 d2.evaluation.evaluator]: [0mInference done 4338/8355. 0.1187 s / img. ETA=0:08:08
[32m[04/20 06:59:01 d2.evaluation.evaluator]: [0mInference done 4379/8355. 0.1187 s / img. ETA=0:08:03
[32m[04/20 06:59:06 d2.evaluation.evaluator]: [0mInference done 4420/8355. 0.1187 s / img. ETA=0:07:58
[32m[04/20 06:59:11 d2.evaluation.evaluator]: [0mInference done 4461/8355. 0.1187 s / img. ETA=0:07:54
[32m[04/20 06:59:16 d2.evaluation.evaluator]: [0mInference done 4502/8355. 0.1187 s / img. ETA=0:07:49
[32m[04/20 06:59:21 d2.evaluation.evaluator]: [0mInference done 4543/8355. 0.1187 s / img. ETA=0:07:44
[32m[04/20 06:59:26 d2.evaluation.evaluator]: [0mInference done 4584/8355. 0.1187 s / img. ETA=0:07:39
[32m[04/20 06:59:31 d2.evaluation.evaluator]: [0mInference done 4625/8355. 0.1187 s / img. ETA=0:07:34
[32m[04/20 06:59:36 d2.evaluation.evaluator]: [0mInference done 4667/8355. 0.1187 s / img. ETA=0:07:29
[32m[04/20 06:59:41 d2.evaluation.evaluator]: [0mInference done 4709/8355. 0.1187 s / img. ETA=0:07:23
[32m[04/20 06:59:46 d2.evaluation.evaluator]: [0mInference done 4750/8355. 0.1187 s / img. ETA=0:07:18
[32m[04/20 06:59:52 d2.evaluation.evaluator]: [0mInference done 4792/8355. 0.1187 s / img. ETA=0:07:13
[32m[04/20 06:59:57 d2.evaluation.evaluator]: [0mInference done 4833/8355. 0.1187 s / img. ETA=0:07:08
[32m[04/20 07:00:02 d2.evaluation.evaluator]: [0mInference done 4874/8355. 0.1187 s / img. ETA=0:07:03
[32m[04/20 07:00:07 d2.evaluation.evaluator]: [0mInference done 4916/8355. 0.1187 s / img. ETA=0:06:58
[32m[04/20 07:00:12 d2.evaluation.evaluator]: [0mInference done 4958/8355. 0.1187 s / img. ETA=0:06:53
[32m[04/20 07:00:17 d2.evaluation.evaluator]: [0mInference done 5000/8355. 0.1187 s / img. ETA=0:06:48
[32m[04/20 07:00:22 d2.evaluation.evaluator]: [0mInference done 5041/8355. 0.1187 s / img. ETA=0:06:43
[32m[04/20 07:00:27 d2.evaluation.evaluator]: [0mInference done 5083/8355. 0.1187 s / img. ETA=0:06:38
[32m[04/20 07:00:32 d2.evaluation.evaluator]: [0mInference done 5124/8355. 0.1187 s / img. ETA=0:06:33
[32m[04/20 07:00:37 d2.evaluation.evaluator]: [0mInference done 5165/8355. 0.1187 s / img. ETA=0:06:28
[32m[04/20 07:00:42 d2.evaluation.evaluator]: [0mInference done 5206/8355. 0.1187 s / img. ETA=0:06:23
[32m[04/20 07:00:47 d2.evaluation.evaluator]: [0mInference done 5248/8355. 0.1188 s / img. ETA=0:06:18
[32m[04/20 07:00:52 d2.evaluation.evaluator]: [0mInference done 5289/8355. 0.1188 s / img. ETA=0:06:13
[32m[04/20 07:00:57 d2.evaluation.evaluator]: [0mInference done 5330/8355. 0.1188 s / img. ETA=0:06:08
[32m[04/20 07:01:02 d2.evaluation.evaluator]: [0mInference done 5371/8355. 0.1188 s / img. ETA=0:06:03
[32m[04/20 07:01:07 d2.evaluation.evaluator]: [0mInference done 5412/8355. 0.1188 s / img. ETA=0:05:58
[32m[04/20 07:01:12 d2.evaluation.evaluator]: [0mInference done 5453/8355. 0.1188 s / img. ETA=0:05:53
[32m[04/20 07:01:17 d2.evaluation.evaluator]: [0mInference done 5494/8355. 0.1188 s / img. ETA=0:05:48
[32m[04/20 07:01:22 d2.evaluation.evaluator]: [0mInference done 5535/8355. 0.1188 s / img. ETA=0:05:43
[32m[04/20 07:01:28 d2.evaluation.evaluator]: [0mInference done 5577/8355. 0.1188 s / img. ETA=0:05:38
[32m[04/20 07:01:33 d2.evaluation.evaluator]: [0mInference done 5618/8355. 0.1188 s / img. ETA=0:05:33
[32m[04/20 07:01:38 d2.evaluation.evaluator]: [0mInference done 5659/8355. 0.1188 s / img. ETA=0:05:28
[32m[04/20 07:01:43 d2.evaluation.evaluator]: [0mInference done 5700/8355. 0.1188 s / img. ETA=0:05:23
[32m[04/20 07:01:48 d2.evaluation.evaluator]: [0mInference done 5741/8355. 0.1188 s / img. ETA=0:05:18
[32m[04/20 07:01:53 d2.evaluation.evaluator]: [0mInference done 5782/8355. 0.1188 s / img. ETA=0:05:13
[32m[04/20 07:01:58 d2.evaluation.evaluator]: [0mInference done 5823/8355. 0.1188 s / img. ETA=0:05:08
[32m[04/20 07:02:03 d2.evaluation.evaluator]: [0mInference done 5864/8355. 0.1188 s / img. ETA=0:05:03
[32m[04/20 07:02:08 d2.evaluation.evaluator]: [0mInference done 5905/8355. 0.1188 s / img. ETA=0:04:58
[32m[04/20 07:02:13 d2.evaluation.evaluator]: [0mInference done 5946/8355. 0.1189 s / img. ETA=0:04:53
[32m[04/20 07:02:18 d2.evaluation.evaluator]: [0mInference done 5987/8355. 0.1189 s / img. ETA=0:04:48
[32m[04/20 07:02:23 d2.evaluation.evaluator]: [0mInference done 6029/8355. 0.1189 s / img. ETA=0:04:43
[32m[04/20 07:02:28 d2.evaluation.evaluator]: [0mInference done 6070/8355. 0.1189 s / img. ETA=0:04:38
[32m[04/20 07:02:33 d2.evaluation.evaluator]: [0mInference done 6112/8355. 0.1189 s / img. ETA=0:04:33
[32m[04/20 07:02:38 d2.evaluation.evaluator]: [0mInference done 6154/8355. 0.1189 s / img. ETA=0:04:28
[32m[04/20 07:02:43 d2.evaluation.evaluator]: [0mInference done 6195/8355. 0.1189 s / img. ETA=0:04:23
[32m[04/20 07:02:48 d2.evaluation.evaluator]: [0mInference done 6236/8355. 0.1189 s / img. ETA=0:04:18
[32m[04/20 07:02:53 d2.evaluation.evaluator]: [0mInference done 6277/8355. 0.1189 s / img. ETA=0:04:13
[32m[04/20 07:02:58 d2.evaluation.evaluator]: [0mInference done 6318/8355. 0.1189 s / img. ETA=0:04:08
[32m[04/20 07:03:04 d2.evaluation.evaluator]: [0mInference done 6360/8355. 0.1189 s / img. ETA=0:04:03
[32m[04/20 07:03:09 d2.evaluation.evaluator]: [0mInference done 6402/8355. 0.1189 s / img. ETA=0:03:58
[32m[04/20 07:03:14 d2.evaluation.evaluator]: [0mInference done 6443/8355. 0.1189 s / img. ETA=0:03:53
[32m[04/20 07:03:19 d2.evaluation.evaluator]: [0mInference done 6485/8355. 0.1189 s / img. ETA=0:03:48
[32m[04/20 07:03:24 d2.evaluation.evaluator]: [0mInference done 6526/8355. 0.1189 s / img. ETA=0:03:43
[32m[04/20 07:03:29 d2.evaluation.evaluator]: [0mInference done 6568/8355. 0.1189 s / img. ETA=0:03:37
[32m[04/20 07:03:34 d2.evaluation.evaluator]: [0mInference done 6610/8355. 0.1189 s / img. ETA=0:03:32
[32m[04/20 07:03:39 d2.evaluation.evaluator]: [0mInference done 6651/8355. 0.1189 s / img. ETA=0:03:27
[32m[04/20 07:03:44 d2.evaluation.evaluator]: [0mInference done 6693/8355. 0.1189 s / img. ETA=0:03:22
[32m[04/20 07:03:49 d2.evaluation.evaluator]: [0mInference done 6735/8355. 0.1189 s / img. ETA=0:03:17
[32m[04/20 07:03:54 d2.evaluation.evaluator]: [0mInference done 6777/8355. 0.1189 s / img. ETA=0:03:12
[32m[04/20 07:03:59 d2.evaluation.evaluator]: [0mInference done 6819/8355. 0.1189 s / img. ETA=0:03:07
[32m[04/20 07:04:04 d2.evaluation.evaluator]: [0mInference done 6860/8355. 0.1189 s / img. ETA=0:03:02
[32m[04/20 07:04:09 d2.evaluation.evaluator]: [0mInference done 6901/8355. 0.1189 s / img. ETA=0:02:57
[32m[04/20 07:04:14 d2.evaluation.evaluator]: [0mInference done 6942/8355. 0.1189 s / img. ETA=0:02:52
[32m[04/20 07:04:19 d2.evaluation.evaluator]: [0mInference done 6983/8355. 0.1189 s / img. ETA=0:02:47
[32m[04/20 07:04:25 d2.evaluation.evaluator]: [0mInference done 7024/8355. 0.1189 s / img. ETA=0:02:42
[32m[04/20 07:04:30 d2.evaluation.evaluator]: [0mInference done 7064/8355. 0.1189 s / img. ETA=0:02:37
[32m[04/20 07:04:35 d2.evaluation.evaluator]: [0mInference done 7105/8355. 0.1189 s / img. ETA=0:02:32
[32m[04/20 07:04:40 d2.evaluation.evaluator]: [0mInference done 7146/8355. 0.1189 s / img. ETA=0:02:27
[32m[04/20 07:04:45 d2.evaluation.evaluator]: [0mInference done 7187/8355. 0.1190 s / img. ETA=0:02:22
[32m[04/20 07:04:50 d2.evaluation.evaluator]: [0mInference done 7228/8355. 0.1190 s / img. ETA=0:02:17
[32m[04/20 07:04:55 d2.evaluation.evaluator]: [0mInference done 7269/8355. 0.1190 s / img. ETA=0:02:12
[32m[04/20 07:05:00 d2.evaluation.evaluator]: [0mInference done 7310/8355. 0.1190 s / img. ETA=0:02:07
[32m[04/20 07:05:05 d2.evaluation.evaluator]: [0mInference done 7351/8355. 0.1190 s / img. ETA=0:02:02
[32m[04/20 07:05:10 d2.evaluation.evaluator]: [0mInference done 7392/8355. 0.1190 s / img. ETA=0:01:57
[32m[04/20 07:05:15 d2.evaluation.evaluator]: [0mInference done 7433/8355. 0.1190 s / img. ETA=0:01:52
[32m[04/20 07:05:20 d2.evaluation.evaluator]: [0mInference done 7474/8355. 0.1190 s / img. ETA=0:01:47
[32m[04/20 07:05:25 d2.evaluation.evaluator]: [0mInference done 7515/8355. 0.1190 s / img. ETA=0:01:42
[32m[04/20 07:05:30 d2.evaluation.evaluator]: [0mInference done 7556/8355. 0.1190 s / img. ETA=0:01:37
[32m[04/20 07:05:35 d2.evaluation.evaluator]: [0mInference done 7597/8355. 0.1190 s / img. ETA=0:01:32
[32m[04/20 07:05:40 d2.evaluation.evaluator]: [0mInference done 7638/8355. 0.1190 s / img. ETA=0:01:27
[32m[04/20 07:05:45 d2.evaluation.evaluator]: [0mInference done 7679/8355. 0.1190 s / img. ETA=0:01:22
[32m[04/20 07:05:50 d2.evaluation.evaluator]: [0mInference done 7720/8355. 0.1190 s / img. ETA=0:01:17
[32m[04/20 07:05:55 d2.evaluation.evaluator]: [0mInference done 7761/8355. 0.1190 s / img. ETA=0:01:12
[32m[04/20 07:06:00 d2.evaluation.evaluator]: [0mInference done 7802/8355. 0.1190 s / img. ETA=0:01:07
[32m[04/20 07:06:05 d2.evaluation.evaluator]: [0mInference done 7842/8355. 0.1190 s / img. ETA=0:01:02
[32m[04/20 07:06:10 d2.evaluation.evaluator]: [0mInference done 7882/8355. 0.1191 s / img. ETA=0:00:57
[32m[04/20 07:06:15 d2.evaluation.evaluator]: [0mInference done 7923/8355. 0.1191 s / img. ETA=0:00:52
[32m[04/20 07:06:20 d2.evaluation.evaluator]: [0mInference done 7964/8355. 0.1191 s / img. ETA=0:00:47
[32m[04/20 07:06:26 d2.evaluation.evaluator]: [0mInference done 8005/8355. 0.1191 s / img. ETA=0:00:42
[32m[04/20 07:06:31 d2.evaluation.evaluator]: [0mInference done 8046/8355. 0.1191 s / img. ETA=0:00:37
[32m[04/20 07:06:36 d2.evaluation.evaluator]: [0mInference done 8087/8355. 0.1191 s / img. ETA=0:00:32
[32m[04/20 07:06:41 d2.evaluation.evaluator]: [0mInference done 8129/8355. 0.1191 s / img. ETA=0:00:27
[32m[04/20 07:06:46 d2.evaluation.evaluator]: [0mInference done 8171/8355. 0.1191 s / img. ETA=0:00:22
[32m[04/20 07:06:51 d2.evaluation.evaluator]: [0mInference done 8213/8355. 0.1191 s / img. ETA=0:00:17
[32m[04/20 07:06:56 d2.evaluation.evaluator]: [0mInference done 8255/8355. 0.1191 s / img. ETA=0:00:12
[32m[04/20 07:07:01 d2.evaluation.evaluator]: [0mInference done 8296/8355. 0.1191 s / img. ETA=0:00:07
[32m[04/20 07:07:06 d2.evaluation.evaluator]: [0mInference done 8337/8355. 0.1191 s / img. ETA=0:00:02
[32m[04/20 07:07:08 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:59.606952 (0.122109 s / img per device, on 1 devices)
[32m[04/20 07:07:08 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:34 (0.119056 s / img per device, on 1 devices)
[32m[04/20 07:07:09 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 07:07:09 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 07:07:09 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.51s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=23.44s).
Accumulating evaluation results...
DONE (t=2.85s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.254
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.495
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.230
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.159
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.366
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.517
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.115
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.298
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.421
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.555
[32m[04/20 07:07:36 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 25.380 | 49.463 | 22.971 | 15.948 | 36.590 | 51.743 |
[32m[04/20 07:07:36 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 31.496 | bicycle       | 12.222 | car            | 32.421 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 07:07:37 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 07:07:37 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 07:07:37 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 07:07:39 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1192 s / img. ETA=0:02:31
[32m[04/20 07:07:44 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1187 s / img. ETA=0:02:26
[32m[04/20 07:07:49 d2.evaluation.evaluator]: [0mInference done 94/1257. 0.1189 s / img. ETA=0:02:21
[32m[04/20 07:07:54 d2.evaluation.evaluator]: [0mInference done 135/1257. 0.1190 s / img. ETA=0:02:16
[32m[04/20 07:07:59 d2.evaluation.evaluator]: [0mInference done 176/1257. 0.1190 s / img. ETA=0:02:11
[32m[04/20 07:08:04 d2.evaluation.evaluator]: [0mInference done 217/1257. 0.1190 s / img. ETA=0:02:06
[32m[04/20 07:08:09 d2.evaluation.evaluator]: [0mInference done 259/1257. 0.1190 s / img. ETA=0:02:01
[32m[04/20 07:08:14 d2.evaluation.evaluator]: [0mInference done 300/1257. 0.1190 s / img. ETA=0:01:56
[32m[04/20 07:08:19 d2.evaluation.evaluator]: [0mInference done 342/1257. 0.1189 s / img. ETA=0:01:51
[32m[04/20 07:08:24 d2.evaluation.evaluator]: [0mInference done 383/1257. 0.1190 s / img. ETA=0:01:46
[32m[04/20 07:08:29 d2.evaluation.evaluator]: [0mInference done 425/1257. 0.1189 s / img. ETA=0:01:41
[32m[04/20 07:08:34 d2.evaluation.evaluator]: [0mInference done 466/1257. 0.1189 s / img. ETA=0:01:36
[32m[04/20 07:08:40 d2.evaluation.evaluator]: [0mInference done 507/1257. 0.1190 s / img. ETA=0:01:31
[32m[04/20 07:08:45 d2.evaluation.evaluator]: [0mInference done 548/1257. 0.1190 s / img. ETA=0:01:26
[32m[04/20 07:08:50 d2.evaluation.evaluator]: [0mInference done 589/1257. 0.1190 s / img. ETA=0:01:21
[32m[04/20 07:08:55 d2.evaluation.evaluator]: [0mInference done 630/1257. 0.1190 s / img. ETA=0:01:16
[32m[04/20 07:09:00 d2.evaluation.evaluator]: [0mInference done 671/1257. 0.1190 s / img. ETA=0:01:11
[32m[04/20 07:09:05 d2.evaluation.evaluator]: [0mInference done 712/1257. 0.1191 s / img. ETA=0:01:06
[32m[04/20 07:09:10 d2.evaluation.evaluator]: [0mInference done 753/1257. 0.1191 s / img. ETA=0:01:01
[32m[04/20 07:09:15 d2.evaluation.evaluator]: [0mInference done 794/1257. 0.1191 s / img. ETA=0:00:56
[32m[04/20 07:09:20 d2.evaluation.evaluator]: [0mInference done 835/1257. 0.1191 s / img. ETA=0:00:51
[32m[04/20 07:09:25 d2.evaluation.evaluator]: [0mInference done 876/1257. 0.1191 s / img. ETA=0:00:46
[32m[04/20 07:09:30 d2.evaluation.evaluator]: [0mInference done 917/1257. 0.1191 s / img. ETA=0:00:41
[32m[04/20 07:09:35 d2.evaluation.evaluator]: [0mInference done 959/1257. 0.1191 s / img. ETA=0:00:36
[32m[04/20 07:09:40 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1191 s / img. ETA=0:00:31
[32m[04/20 07:09:45 d2.evaluation.evaluator]: [0mInference done 1041/1257. 0.1191 s / img. ETA=0:00:26
[32m[04/20 07:09:50 d2.evaluation.evaluator]: [0mInference done 1082/1257. 0.1191 s / img. ETA=0:00:21
[32m[04/20 07:09:55 d2.evaluation.evaluator]: [0mInference done 1123/1257. 0.1192 s / img. ETA=0:00:16
[32m[04/20 07:10:00 d2.evaluation.evaluator]: [0mInference done 1164/1257. 0.1192 s / img. ETA=0:00:11
[32m[04/20 07:10:05 d2.evaluation.evaluator]: [0mInference done 1206/1257. 0.1192 s / img. ETA=0:00:06
[32m[04/20 07:10:10 d2.evaluation.evaluator]: [0mInference done 1247/1257. 0.1192 s / img. ETA=0:00:01
[32m[04/20 07:10:11 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:33.250597 (0.122405 s / img per device, on 1 devices)
[32m[04/20 07:10:11 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:29 (0.119188 s / img per device, on 1 devices)
[32m[04/20 07:10:12 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 07:10:12 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 07:10:12 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.14s).
Accumulating evaluation results...
DONE (t=0.53s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.224
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.434
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.206
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.129
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.276
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.398
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.117
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.271
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.272
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.442
[32m[04/20 07:10:15 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 22.390 | 43.409 | 20.560 | 12.851 | 27.596 | 39.810 |
[32m[04/20 07:10:15 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 25.292 | bicycle       | 5.330 | car            | 36.549 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | nan   | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  3  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 07:10:16 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 07:10:17 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 07:10:17 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 07:10:17 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 07:10:18 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 07:10:18 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 07:10:18 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 07:10:39 d2.utils.events]: [0m eta: 0:17:21  iter: 19  total_loss: 0.634  loss_cls: 0.211  loss_box_reg: 0.328  loss_rpn_cls: 0.027  loss_rpn_loc: 0.048  time: 1.0454  data_time: 0.0555  lr: 0.000100  max_mem: 5405M
[32m[04/20 07:11:01 d2.utils.events]: [0m eta: 0:17:03  iter: 39  total_loss: 0.670  loss_cls: 0.233  loss_box_reg: 0.361  loss_rpn_cls: 0.030  loss_rpn_loc: 0.077  time: 1.0568  data_time: 0.0149  lr: 0.000200  max_mem: 5405M
[32m[04/20 07:11:21 d2.utils.events]: [0m eta: 0:16:22  iter: 59  total_loss: 0.691  loss_cls: 0.229  loss_box_reg: 0.348  loss_rpn_cls: 0.026  loss_rpn_loc: 0.063  time: 1.0399  data_time: 0.0159  lr: 0.000300  max_mem: 5405M
[32m[04/20 07:11:42 d2.utils.events]: [0m eta: 0:16:03  iter: 79  total_loss: 0.819  loss_cls: 0.272  loss_box_reg: 0.416  loss_rpn_cls: 0.034  loss_rpn_loc: 0.078  time: 1.0406  data_time: 0.0170  lr: 0.000400  max_mem: 5405M
[32m[04/20 07:12:02 d2.utils.events]: [0m eta: 0:15:37  iter: 99  total_loss: 0.645  loss_cls: 0.224  loss_box_reg: 0.345  loss_rpn_cls: 0.025  loss_rpn_loc: 0.049  time: 1.0385  data_time: 0.0161  lr: 0.000500  max_mem: 5405M
[32m[04/20 07:12:23 d2.utils.events]: [0m eta: 0:15:15  iter: 119  total_loss: 0.779  loss_cls: 0.258  loss_box_reg: 0.396  loss_rpn_cls: 0.033  loss_rpn_loc: 0.074  time: 1.0361  data_time: 0.0162  lr: 0.000599  max_mem: 5405M
[32m[04/20 07:12:43 d2.utils.events]: [0m eta: 0:14:54  iter: 139  total_loss: 0.593  loss_cls: 0.195  loss_box_reg: 0.306  loss_rpn_cls: 0.024  loss_rpn_loc: 0.056  time: 1.0332  data_time: 0.0160  lr: 0.000699  max_mem: 5405M
[32m[04/20 07:13:05 d2.utils.events]: [0m eta: 0:14:37  iter: 159  total_loss: 0.627  loss_cls: 0.217  loss_box_reg: 0.338  loss_rpn_cls: 0.021  loss_rpn_loc: 0.060  time: 1.0364  data_time: 0.0161  lr: 0.000799  max_mem: 5405M
[32m[04/20 07:13:26 d2.utils.events]: [0m eta: 0:14:25  iter: 179  total_loss: 0.672  loss_cls: 0.229  loss_box_reg: 0.358  loss_rpn_cls: 0.025  loss_rpn_loc: 0.058  time: 1.0409  data_time: 0.0158  lr: 0.000899  max_mem: 5405M
[32m[04/20 07:13:48 d2.utils.events]: [0m eta: 0:14:06  iter: 199  total_loss: 0.692  loss_cls: 0.223  loss_box_reg: 0.363  loss_rpn_cls: 0.030  loss_rpn_loc: 0.080  time: 1.0437  data_time: 0.0164  lr: 0.000999  max_mem: 5405M
[32m[04/20 07:14:08 d2.utils.events]: [0m eta: 0:13:43  iter: 219  total_loss: 0.687  loss_cls: 0.230  loss_box_reg: 0.346  loss_rpn_cls: 0.032  loss_rpn_loc: 0.054  time: 1.0409  data_time: 0.0164  lr: 0.001099  max_mem: 5405M
[32m[04/20 07:14:29 d2.utils.events]: [0m eta: 0:13:22  iter: 239  total_loss: 0.660  loss_cls: 0.228  loss_box_reg: 0.348  loss_rpn_cls: 0.023  loss_rpn_loc: 0.058  time: 1.0401  data_time: 0.0199  lr: 0.001199  max_mem: 5405M
[32m[04/20 07:14:50 d2.utils.events]: [0m eta: 0:13:01  iter: 259  total_loss: 0.698  loss_cls: 0.232  loss_box_reg: 0.365  loss_rpn_cls: 0.026  loss_rpn_loc: 0.069  time: 1.0403  data_time: 0.0170  lr: 0.001299  max_mem: 5405M
[32m[04/20 07:15:11 d2.utils.events]: [0m eta: 0:12:40  iter: 279  total_loss: 0.653  loss_cls: 0.211  loss_box_reg: 0.366  loss_rpn_cls: 0.026  loss_rpn_loc: 0.063  time: 1.0413  data_time: 0.0153  lr: 0.001399  max_mem: 5405M
[32m[04/20 07:15:31 d2.utils.events]: [0m eta: 0:12:19  iter: 299  total_loss: 0.765  loss_cls: 0.268  loss_box_reg: 0.397  loss_rpn_cls: 0.031  loss_rpn_loc: 0.060  time: 1.0396  data_time: 0.0161  lr: 0.001499  max_mem: 5405M
[32m[04/20 07:15:51 d2.utils.events]: [0m eta: 0:11:58  iter: 319  total_loss: 0.653  loss_cls: 0.218  loss_box_reg: 0.345  loss_rpn_cls: 0.025  loss_rpn_loc: 0.062  time: 1.0380  data_time: 0.0168  lr: 0.001598  max_mem: 5405M
[32m[04/20 07:16:12 d2.utils.events]: [0m eta: 0:11:36  iter: 339  total_loss: 0.704  loss_cls: 0.228  loss_box_reg: 0.369  loss_rpn_cls: 0.024  loss_rpn_loc: 0.068  time: 1.0377  data_time: 0.0166  lr: 0.001698  max_mem: 5405M
[32m[04/20 07:16:33 d2.utils.events]: [0m eta: 0:11:13  iter: 359  total_loss: 0.769  loss_cls: 0.236  loss_box_reg: 0.377  loss_rpn_cls: 0.033  loss_rpn_loc: 0.057  time: 1.0368  data_time: 0.0313  lr: 0.001798  max_mem: 5405M
[32m[04/20 07:16:53 d2.utils.events]: [0m eta: 0:10:53  iter: 379  total_loss: 0.676  loss_cls: 0.234  loss_box_reg: 0.357  loss_rpn_cls: 0.025  loss_rpn_loc: 0.071  time: 1.0369  data_time: 0.0170  lr: 0.001898  max_mem: 5405M
[32m[04/20 07:17:14 d2.utils.events]: [0m eta: 0:10:31  iter: 399  total_loss: 0.672  loss_cls: 0.223  loss_box_reg: 0.363  loss_rpn_cls: 0.023  loss_rpn_loc: 0.057  time: 1.0366  data_time: 0.0163  lr: 0.001998  max_mem: 5405M
[32m[04/20 07:17:35 d2.utils.events]: [0m eta: 0:10:10  iter: 419  total_loss: 0.686  loss_cls: 0.231  loss_box_reg: 0.372  loss_rpn_cls: 0.019  loss_rpn_loc: 0.063  time: 1.0371  data_time: 0.0184  lr: 0.002098  max_mem: 5405M
[32m[04/20 07:17:56 d2.utils.events]: [0m eta: 0:09:50  iter: 439  total_loss: 0.729  loss_cls: 0.236  loss_box_reg: 0.393  loss_rpn_cls: 0.024  loss_rpn_loc: 0.069  time: 1.0379  data_time: 0.0158  lr: 0.002198  max_mem: 5405M
[32m[04/20 07:18:17 d2.utils.events]: [0m eta: 0:09:28  iter: 459  total_loss: 0.664  loss_cls: 0.224  loss_box_reg: 0.341  loss_rpn_cls: 0.024  loss_rpn_loc: 0.063  time: 1.0377  data_time: 0.0174  lr: 0.002298  max_mem: 5405M
[32m[04/20 07:18:38 d2.utils.events]: [0m eta: 0:09:07  iter: 479  total_loss: 0.670  loss_cls: 0.232  loss_box_reg: 0.353  loss_rpn_cls: 0.028  loss_rpn_loc: 0.052  time: 1.0383  data_time: 0.0181  lr: 0.002398  max_mem: 5405M
[32m[04/20 07:18:59 d2.utils.events]: [0m eta: 0:08:47  iter: 499  total_loss: 0.618  loss_cls: 0.211  loss_box_reg: 0.313  loss_rpn_cls: 0.025  loss_rpn_loc: 0.067  time: 1.0387  data_time: 0.0165  lr: 0.002498  max_mem: 5405M
[32m[04/20 07:19:20 d2.utils.events]: [0m eta: 0:08:24  iter: 519  total_loss: 0.701  loss_cls: 0.228  loss_box_reg: 0.377  loss_rpn_cls: 0.027  loss_rpn_loc: 0.087  time: 1.0379  data_time: 0.0174  lr: 0.002597  max_mem: 5405M
[32m[04/20 07:19:40 d2.utils.events]: [0m eta: 0:08:02  iter: 539  total_loss: 0.667  loss_cls: 0.226  loss_box_reg: 0.367  loss_rpn_cls: 0.023  loss_rpn_loc: 0.052  time: 1.0374  data_time: 0.0178  lr: 0.002697  max_mem: 5405M
[32m[04/20 07:20:01 d2.utils.events]: [0m eta: 0:07:41  iter: 559  total_loss: 0.656  loss_cls: 0.230  loss_box_reg: 0.337  loss_rpn_cls: 0.026  loss_rpn_loc: 0.073  time: 1.0373  data_time: 0.0163  lr: 0.002797  max_mem: 5405M
[32m[04/20 07:20:21 d2.utils.events]: [0m eta: 0:07:20  iter: 579  total_loss: 0.677  loss_cls: 0.225  loss_box_reg: 0.363  loss_rpn_cls: 0.023  loss_rpn_loc: 0.053  time: 1.0370  data_time: 0.0178  lr: 0.002897  max_mem: 5405M
[32m[04/20 07:20:43 d2.utils.events]: [0m eta: 0:07:00  iter: 599  total_loss: 0.662  loss_cls: 0.224  loss_box_reg: 0.351  loss_rpn_cls: 0.021  loss_rpn_loc: 0.053  time: 1.0382  data_time: 0.0203  lr: 0.002997  max_mem: 5405M
[32m[04/20 07:21:04 d2.utils.events]: [0m eta: 0:06:39  iter: 619  total_loss: 0.800  loss_cls: 0.262  loss_box_reg: 0.407  loss_rpn_cls: 0.032  loss_rpn_loc: 0.064  time: 1.0384  data_time: 0.0169  lr: 0.003097  max_mem: 5405M
[32m[04/20 07:21:24 d2.utils.events]: [0m eta: 0:06:18  iter: 639  total_loss: 0.685  loss_cls: 0.239  loss_box_reg: 0.354  loss_rpn_cls: 0.032  loss_rpn_loc: 0.060  time: 1.0379  data_time: 0.0186  lr: 0.003197  max_mem: 5405M
[32m[04/20 07:21:45 d2.utils.events]: [0m eta: 0:05:56  iter: 659  total_loss: 0.750  loss_cls: 0.247  loss_box_reg: 0.403  loss_rpn_cls: 0.022  loss_rpn_loc: 0.066  time: 1.0379  data_time: 0.0143  lr: 0.003297  max_mem: 5405M
[32m[04/20 07:22:06 d2.utils.events]: [0m eta: 0:05:35  iter: 679  total_loss: 0.647  loss_cls: 0.214  loss_box_reg: 0.329  loss_rpn_cls: 0.024  loss_rpn_loc: 0.064  time: 1.0372  data_time: 0.0208  lr: 0.003397  max_mem: 5405M
[32m[04/20 07:22:26 d2.utils.events]: [0m eta: 0:05:14  iter: 699  total_loss: 0.763  loss_cls: 0.256  loss_box_reg: 0.408  loss_rpn_cls: 0.026  loss_rpn_loc: 0.063  time: 1.0373  data_time: 0.0146  lr: 0.003497  max_mem: 5405M
[32m[04/20 07:22:48 d2.utils.events]: [0m eta: 0:04:53  iter: 719  total_loss: 0.795  loss_cls: 0.271  loss_box_reg: 0.411  loss_rpn_cls: 0.031  loss_rpn_loc: 0.075  time: 1.0377  data_time: 0.0160  lr: 0.003596  max_mem: 5405M
[32m[04/20 07:23:08 d2.utils.events]: [0m eta: 0:04:32  iter: 739  total_loss: 0.701  loss_cls: 0.239  loss_box_reg: 0.364  loss_rpn_cls: 0.030  loss_rpn_loc: 0.059  time: 1.0374  data_time: 0.0189  lr: 0.003696  max_mem: 5405M
[32m[04/20 07:23:29 d2.utils.events]: [0m eta: 0:04:11  iter: 759  total_loss: 0.672  loss_cls: 0.252  loss_box_reg: 0.356  loss_rpn_cls: 0.023  loss_rpn_loc: 0.051  time: 1.0379  data_time: 0.0194  lr: 0.003796  max_mem: 5405M
[32m[04/20 07:23:50 d2.utils.events]: [0m eta: 0:03:51  iter: 779  total_loss: 0.726  loss_cls: 0.261  loss_box_reg: 0.388  loss_rpn_cls: 0.022  loss_rpn_loc: 0.064  time: 1.0379  data_time: 0.0173  lr: 0.003896  max_mem: 5405M
[32m[04/20 07:24:11 d2.utils.events]: [0m eta: 0:03:30  iter: 799  total_loss: 0.657  loss_cls: 0.215  loss_box_reg: 0.355  loss_rpn_cls: 0.017  loss_rpn_loc: 0.056  time: 1.0375  data_time: 0.0144  lr: 0.003996  max_mem: 5405M
[32m[04/20 07:24:31 d2.utils.events]: [0m eta: 0:03:09  iter: 819  total_loss: 0.771  loss_cls: 0.248  loss_box_reg: 0.391  loss_rpn_cls: 0.034  loss_rpn_loc: 0.086  time: 1.0374  data_time: 0.0174  lr: 0.004096  max_mem: 5405M
[32m[04/20 07:24:52 d2.utils.events]: [0m eta: 0:02:48  iter: 839  total_loss: 0.750  loss_cls: 0.246  loss_box_reg: 0.398  loss_rpn_cls: 0.035  loss_rpn_loc: 0.059  time: 1.0376  data_time: 0.0174  lr: 0.004196  max_mem: 5405M
[32m[04/20 07:25:13 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.662  loss_cls: 0.215  loss_box_reg: 0.342  loss_rpn_cls: 0.026  loss_rpn_loc: 0.061  time: 1.0377  data_time: 0.0156  lr: 0.004296  max_mem: 5405M
[32m[04/20 07:25:34 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.763  loss_cls: 0.244  loss_box_reg: 0.380  loss_rpn_cls: 0.028  loss_rpn_loc: 0.075  time: 1.0380  data_time: 0.0163  lr: 0.004396  max_mem: 5405M
[32m[04/20 07:25:55 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.634  loss_cls: 0.202  loss_box_reg: 0.328  loss_rpn_cls: 0.025  loss_rpn_loc: 0.071  time: 1.0385  data_time: 0.0154  lr: 0.004496  max_mem: 5405M
[32m[04/20 07:26:16 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.646  loss_cls: 0.203  loss_box_reg: 0.343  loss_rpn_cls: 0.022  loss_rpn_loc: 0.062  time: 1.0386  data_time: 0.0136  lr: 0.004595  max_mem: 5405M
[32m[04/20 07:26:37 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.755  loss_cls: 0.252  loss_box_reg: 0.395  loss_rpn_cls: 0.035  loss_rpn_loc: 0.067  time: 1.0383  data_time: 0.0163  lr: 0.004695  max_mem: 5405M
[32m[04/20 07:26:57 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.620  loss_cls: 0.219  loss_box_reg: 0.341  loss_rpn_cls: 0.025  loss_rpn_loc: 0.052  time: 1.0378  data_time: 0.0174  lr: 0.004795  max_mem: 5405M
[32m[04/20 07:27:18 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.623  loss_cls: 0.220  loss_box_reg: 0.335  loss_rpn_cls: 0.026  loss_rpn_loc: 0.060  time: 1.0379  data_time: 0.0165  lr: 0.004895  max_mem: 5405M
[5m[31mWARNING[0m [32m[04/20 07:27:43 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 07:27:43 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 07:27:44 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 07:27:44 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.641  loss_cls: 0.219  loss_box_reg: 0.324  loss_rpn_cls: 0.029  loss_rpn_loc: 0.066  time: 1.0382  data_time: 0.0159  lr: 0.004995  max_mem: 5405M
[32m[04/20 07:27:45 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:16 (1.0393 s / it)
[32m[04/20 07:27:45 d2.engine.hooks]: [0mTotal training time: 0:17:24 (0:00:08 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 07:27:48 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 07:27:48 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 07:27:49 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 07:27:51 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1184 s / img. ETA=0:16:46
[32m[04/20 07:27:56 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1187 s / img. ETA=0:16:47
[32m[04/20 07:28:01 d2.evaluation.evaluator]: [0mInference done 95/8355. 0.1180 s / img. ETA=0:16:36
[32m[04/20 07:28:06 d2.evaluation.evaluator]: [0mInference done 137/8355. 0.1179 s / img. ETA=0:16:31
[32m[04/20 07:28:11 d2.evaluation.evaluator]: [0mInference done 179/8355. 0.1177 s / img. ETA=0:16:24
[32m[04/20 07:28:16 d2.evaluation.evaluator]: [0mInference done 220/8355. 0.1181 s / img. ETA=0:16:23
[32m[04/20 07:28:21 d2.evaluation.evaluator]: [0mInference done 262/8355. 0.1182 s / img. ETA=0:16:19
[32m[04/20 07:28:26 d2.evaluation.evaluator]: [0mInference done 304/8355. 0.1182 s / img. ETA=0:16:14
[32m[04/20 07:28:31 d2.evaluation.evaluator]: [0mInference done 345/8355. 0.1183 s / img. ETA=0:16:10
[32m[04/20 07:28:36 d2.evaluation.evaluator]: [0mInference done 387/8355. 0.1184 s / img. ETA=0:16:05
[32m[04/20 07:28:41 d2.evaluation.evaluator]: [0mInference done 428/8355. 0.1184 s / img. ETA=0:16:01
[32m[04/20 07:28:46 d2.evaluation.evaluator]: [0mInference done 470/8355. 0.1183 s / img. ETA=0:15:55
[32m[04/20 07:28:52 d2.evaluation.evaluator]: [0mInference done 512/8355. 0.1183 s / img. ETA=0:15:50
[32m[04/20 07:28:57 d2.evaluation.evaluator]: [0mInference done 554/8355. 0.1182 s / img. ETA=0:15:44
[32m[04/20 07:29:02 d2.evaluation.evaluator]: [0mInference done 596/8355. 0.1182 s / img. ETA=0:15:39
[32m[04/20 07:29:07 d2.evaluation.evaluator]: [0mInference done 638/8355. 0.1182 s / img. ETA=0:15:34
[32m[04/20 07:29:12 d2.evaluation.evaluator]: [0mInference done 680/8355. 0.1182 s / img. ETA=0:15:29
[32m[04/20 07:29:17 d2.evaluation.evaluator]: [0mInference done 722/8355. 0.1182 s / img. ETA=0:15:24
[32m[04/20 07:29:22 d2.evaluation.evaluator]: [0mInference done 764/8355. 0.1182 s / img. ETA=0:15:19
[32m[04/20 07:29:27 d2.evaluation.evaluator]: [0mInference done 806/8355. 0.1182 s / img. ETA=0:15:14
[32m[04/20 07:29:32 d2.evaluation.evaluator]: [0mInference done 848/8355. 0.1182 s / img. ETA=0:15:08
[32m[04/20 07:29:37 d2.evaluation.evaluator]: [0mInference done 889/8355. 0.1182 s / img. ETA=0:15:04
[32m[04/20 07:29:42 d2.evaluation.evaluator]: [0mInference done 931/8355. 0.1182 s / img. ETA=0:14:59
[32m[04/20 07:29:47 d2.evaluation.evaluator]: [0mInference done 973/8355. 0.1182 s / img. ETA=0:14:54
[32m[04/20 07:29:52 d2.evaluation.evaluator]: [0mInference done 1015/8355. 0.1182 s / img. ETA=0:14:49
[32m[04/20 07:29:58 d2.evaluation.evaluator]: [0mInference done 1057/8355. 0.1182 s / img. ETA=0:14:43
[32m[04/20 07:30:03 d2.evaluation.evaluator]: [0mInference done 1099/8355. 0.1183 s / img. ETA=0:14:38
[32m[04/20 07:30:08 d2.evaluation.evaluator]: [0mInference done 1141/8355. 0.1183 s / img. ETA=0:14:34
[32m[04/20 07:30:13 d2.evaluation.evaluator]: [0mInference done 1183/8355. 0.1183 s / img. ETA=0:14:28
[32m[04/20 07:30:18 d2.evaluation.evaluator]: [0mInference done 1225/8355. 0.1183 s / img. ETA=0:14:23
[32m[04/20 07:30:23 d2.evaluation.evaluator]: [0mInference done 1267/8355. 0.1183 s / img. ETA=0:14:18
[32m[04/20 07:30:28 d2.evaluation.evaluator]: [0mInference done 1309/8355. 0.1183 s / img. ETA=0:14:13
[32m[04/20 07:30:33 d2.evaluation.evaluator]: [0mInference done 1351/8355. 0.1183 s / img. ETA=0:14:08
[32m[04/20 07:30:38 d2.evaluation.evaluator]: [0mInference done 1393/8355. 0.1182 s / img. ETA=0:14:03
[32m[04/20 07:30:43 d2.evaluation.evaluator]: [0mInference done 1435/8355. 0.1182 s / img. ETA=0:13:57
[32m[04/20 07:30:48 d2.evaluation.evaluator]: [0mInference done 1476/8355. 0.1183 s / img. ETA=0:13:53
[32m[04/20 07:30:53 d2.evaluation.evaluator]: [0mInference done 1517/8355. 0.1183 s / img. ETA=0:13:48
[32m[04/20 07:30:58 d2.evaluation.evaluator]: [0mInference done 1559/8355. 0.1183 s / img. ETA=0:13:43
[32m[04/20 07:31:03 d2.evaluation.evaluator]: [0mInference done 1600/8355. 0.1184 s / img. ETA=0:13:38
[32m[04/20 07:31:09 d2.evaluation.evaluator]: [0mInference done 1641/8355. 0.1184 s / img. ETA=0:13:34
[32m[04/20 07:31:14 d2.evaluation.evaluator]: [0mInference done 1682/8355. 0.1184 s / img. ETA=0:13:29
[32m[04/20 07:31:19 d2.evaluation.evaluator]: [0mInference done 1723/8355. 0.1185 s / img. ETA=0:13:24
[32m[04/20 07:31:24 d2.evaluation.evaluator]: [0mInference done 1764/8355. 0.1185 s / img. ETA=0:13:20
[32m[04/20 07:31:29 d2.evaluation.evaluator]: [0mInference done 1805/8355. 0.1185 s / img. ETA=0:13:15
[32m[04/20 07:31:34 d2.evaluation.evaluator]: [0mInference done 1846/8355. 0.1185 s / img. ETA=0:13:10
[32m[04/20 07:31:39 d2.evaluation.evaluator]: [0mInference done 1887/8355. 0.1186 s / img. ETA=0:13:05
[32m[04/20 07:31:44 d2.evaluation.evaluator]: [0mInference done 1928/8355. 0.1186 s / img. ETA=0:13:00
[32m[04/20 07:31:49 d2.evaluation.evaluator]: [0mInference done 1970/8355. 0.1186 s / img. ETA=0:12:55
[32m[04/20 07:31:54 d2.evaluation.evaluator]: [0mInference done 2011/8355. 0.1186 s / img. ETA=0:12:51
[32m[04/20 07:31:59 d2.evaluation.evaluator]: [0mInference done 2052/8355. 0.1186 s / img. ETA=0:12:46
[32m[04/20 07:32:04 d2.evaluation.evaluator]: [0mInference done 2094/8355. 0.1186 s / img. ETA=0:12:41
[32m[04/20 07:32:09 d2.evaluation.evaluator]: [0mInference done 2135/8355. 0.1186 s / img. ETA=0:12:36
[32m[04/20 07:32:14 d2.evaluation.evaluator]: [0mInference done 2176/8355. 0.1186 s / img. ETA=0:12:31
[32m[04/20 07:32:19 d2.evaluation.evaluator]: [0mInference done 2217/8355. 0.1186 s / img. ETA=0:12:26
[32m[04/20 07:32:24 d2.evaluation.evaluator]: [0mInference done 2258/8355. 0.1187 s / img. ETA=0:12:21
[32m[04/20 07:32:29 d2.evaluation.evaluator]: [0mInference done 2300/8355. 0.1187 s / img. ETA=0:12:16
[32m[04/20 07:32:34 d2.evaluation.evaluator]: [0mInference done 2341/8355. 0.1187 s / img. ETA=0:12:11
[32m[04/20 07:32:39 d2.evaluation.evaluator]: [0mInference done 2382/8355. 0.1187 s / img. ETA=0:12:06
[32m[04/20 07:32:44 d2.evaluation.evaluator]: [0mInference done 2423/8355. 0.1187 s / img. ETA=0:12:01
[32m[04/20 07:32:49 d2.evaluation.evaluator]: [0mInference done 2465/8355. 0.1187 s / img. ETA=0:11:56
[32m[04/20 07:32:54 d2.evaluation.evaluator]: [0mInference done 2507/8355. 0.1187 s / img. ETA=0:11:51
[32m[04/20 07:33:00 d2.evaluation.evaluator]: [0mInference done 2549/8355. 0.1187 s / img. ETA=0:11:46
[32m[04/20 07:33:05 d2.evaluation.evaluator]: [0mInference done 2590/8355. 0.1187 s / img. ETA=0:11:41
[32m[04/20 07:33:10 d2.evaluation.evaluator]: [0mInference done 2632/8355. 0.1187 s / img. ETA=0:11:36
[32m[04/20 07:33:15 d2.evaluation.evaluator]: [0mInference done 2673/8355. 0.1187 s / img. ETA=0:11:31
[32m[04/20 07:33:20 d2.evaluation.evaluator]: [0mInference done 2714/8355. 0.1187 s / img. ETA=0:11:26
[32m[04/20 07:33:25 d2.evaluation.evaluator]: [0mInference done 2756/8355. 0.1187 s / img. ETA=0:11:21
[32m[04/20 07:33:30 d2.evaluation.evaluator]: [0mInference done 2797/8355. 0.1187 s / img. ETA=0:11:16
[32m[04/20 07:33:35 d2.evaluation.evaluator]: [0mInference done 2838/8355. 0.1187 s / img. ETA=0:11:11
[32m[04/20 07:33:40 d2.evaluation.evaluator]: [0mInference done 2879/8355. 0.1187 s / img. ETA=0:11:06
[32m[04/20 07:33:45 d2.evaluation.evaluator]: [0mInference done 2921/8355. 0.1187 s / img. ETA=0:11:01
[32m[04/20 07:33:50 d2.evaluation.evaluator]: [0mInference done 2962/8355. 0.1187 s / img. ETA=0:10:56
[32m[04/20 07:33:55 d2.evaluation.evaluator]: [0mInference done 3004/8355. 0.1187 s / img. ETA=0:10:51
[32m[04/20 07:34:00 d2.evaluation.evaluator]: [0mInference done 3046/8355. 0.1187 s / img. ETA=0:10:46
[32m[04/20 07:34:05 d2.evaluation.evaluator]: [0mInference done 3087/8355. 0.1187 s / img. ETA=0:10:41
[32m[04/20 07:34:10 d2.evaluation.evaluator]: [0mInference done 3128/8355. 0.1187 s / img. ETA=0:10:36
[32m[04/20 07:34:15 d2.evaluation.evaluator]: [0mInference done 3170/8355. 0.1187 s / img. ETA=0:10:31
[32m[04/20 07:34:20 d2.evaluation.evaluator]: [0mInference done 3211/8355. 0.1187 s / img. ETA=0:10:26
[32m[04/20 07:34:25 d2.evaluation.evaluator]: [0mInference done 3252/8355. 0.1188 s / img. ETA=0:10:21
[32m[04/20 07:34:31 d2.evaluation.evaluator]: [0mInference done 3294/8355. 0.1188 s / img. ETA=0:10:16
[32m[04/20 07:34:36 d2.evaluation.evaluator]: [0mInference done 3336/8355. 0.1188 s / img. ETA=0:10:11
[32m[04/20 07:34:41 d2.evaluation.evaluator]: [0mInference done 3377/8355. 0.1188 s / img. ETA=0:10:06
[32m[04/20 07:34:46 d2.evaluation.evaluator]: [0mInference done 3418/8355. 0.1188 s / img. ETA=0:10:01
[32m[04/20 07:34:51 d2.evaluation.evaluator]: [0mInference done 3460/8355. 0.1188 s / img. ETA=0:09:56
[32m[04/20 07:34:56 d2.evaluation.evaluator]: [0mInference done 3501/8355. 0.1188 s / img. ETA=0:09:51
[32m[04/20 07:35:01 d2.evaluation.evaluator]: [0mInference done 3543/8355. 0.1188 s / img. ETA=0:09:46
[32m[04/20 07:35:06 d2.evaluation.evaluator]: [0mInference done 3584/8355. 0.1188 s / img. ETA=0:09:41
[32m[04/20 07:35:11 d2.evaluation.evaluator]: [0mInference done 3625/8355. 0.1188 s / img. ETA=0:09:36
[32m[04/20 07:35:16 d2.evaluation.evaluator]: [0mInference done 3666/8355. 0.1188 s / img. ETA=0:09:31
[32m[04/20 07:35:21 d2.evaluation.evaluator]: [0mInference done 3708/8355. 0.1188 s / img. ETA=0:09:26
[32m[04/20 07:35:26 d2.evaluation.evaluator]: [0mInference done 3750/8355. 0.1188 s / img. ETA=0:09:21
[32m[04/20 07:35:31 d2.evaluation.evaluator]: [0mInference done 3791/8355. 0.1188 s / img. ETA=0:09:16
[32m[04/20 07:35:36 d2.evaluation.evaluator]: [0mInference done 3832/8355. 0.1188 s / img. ETA=0:09:11
[32m[04/20 07:35:41 d2.evaluation.evaluator]: [0mInference done 3873/8355. 0.1188 s / img. ETA=0:09:06
[32m[04/20 07:35:47 d2.evaluation.evaluator]: [0mInference done 3915/8355. 0.1188 s / img. ETA=0:09:01
[32m[04/20 07:35:52 d2.evaluation.evaluator]: [0mInference done 3957/8355. 0.1188 s / img. ETA=0:08:55
[32m[04/20 07:35:57 d2.evaluation.evaluator]: [0mInference done 3999/8355. 0.1188 s / img. ETA=0:08:50
[32m[04/20 07:36:02 d2.evaluation.evaluator]: [0mInference done 4040/8355. 0.1188 s / img. ETA=0:08:45
[32m[04/20 07:36:07 d2.evaluation.evaluator]: [0mInference done 4081/8355. 0.1188 s / img. ETA=0:08:40
[32m[04/20 07:36:12 d2.evaluation.evaluator]: [0mInference done 4122/8355. 0.1188 s / img. ETA=0:08:35
[32m[04/20 07:36:17 d2.evaluation.evaluator]: [0mInference done 4163/8355. 0.1188 s / img. ETA=0:08:30
[32m[04/20 07:36:22 d2.evaluation.evaluator]: [0mInference done 4204/8355. 0.1188 s / img. ETA=0:08:25
[32m[04/20 07:36:27 d2.evaluation.evaluator]: [0mInference done 4246/8355. 0.1188 s / img. ETA=0:08:20
[32m[04/20 07:36:32 d2.evaluation.evaluator]: [0mInference done 4288/8355. 0.1188 s / img. ETA=0:08:15
[32m[04/20 07:36:37 d2.evaluation.evaluator]: [0mInference done 4330/8355. 0.1188 s / img. ETA=0:08:10
[32m[04/20 07:36:42 d2.evaluation.evaluator]: [0mInference done 4372/8355. 0.1188 s / img. ETA=0:08:05
[32m[04/20 07:36:47 d2.evaluation.evaluator]: [0mInference done 4413/8355. 0.1188 s / img. ETA=0:08:00
[32m[04/20 07:36:52 d2.evaluation.evaluator]: [0mInference done 4454/8355. 0.1188 s / img. ETA=0:07:55
[32m[04/20 07:36:57 d2.evaluation.evaluator]: [0mInference done 4496/8355. 0.1188 s / img. ETA=0:07:50
[32m[04/20 07:37:03 d2.evaluation.evaluator]: [0mInference done 4537/8355. 0.1188 s / img. ETA=0:07:45
[32m[04/20 07:37:08 d2.evaluation.evaluator]: [0mInference done 4578/8355. 0.1189 s / img. ETA=0:07:40
[32m[04/20 07:37:13 d2.evaluation.evaluator]: [0mInference done 4619/8355. 0.1189 s / img. ETA=0:07:35
[32m[04/20 07:37:18 d2.evaluation.evaluator]: [0mInference done 4660/8355. 0.1189 s / img. ETA=0:07:30
[32m[04/20 07:37:23 d2.evaluation.evaluator]: [0mInference done 4702/8355. 0.1189 s / img. ETA=0:07:25
[32m[04/20 07:37:28 d2.evaluation.evaluator]: [0mInference done 4744/8355. 0.1189 s / img. ETA=0:07:20
[32m[04/20 07:37:33 d2.evaluation.evaluator]: [0mInference done 4785/8355. 0.1189 s / img. ETA=0:07:15
[32m[04/20 07:37:38 d2.evaluation.evaluator]: [0mInference done 4826/8355. 0.1189 s / img. ETA=0:07:10
[32m[04/20 07:37:43 d2.evaluation.evaluator]: [0mInference done 4867/8355. 0.1189 s / img. ETA=0:07:05
[32m[04/20 07:37:48 d2.evaluation.evaluator]: [0mInference done 4909/8355. 0.1189 s / img. ETA=0:07:00
[32m[04/20 07:37:53 d2.evaluation.evaluator]: [0mInference done 4951/8355. 0.1189 s / img. ETA=0:06:55
[32m[04/20 07:37:58 d2.evaluation.evaluator]: [0mInference done 4992/8355. 0.1189 s / img. ETA=0:06:50
[32m[04/20 07:38:03 d2.evaluation.evaluator]: [0mInference done 5033/8355. 0.1189 s / img. ETA=0:06:45
[32m[04/20 07:38:08 d2.evaluation.evaluator]: [0mInference done 5075/8355. 0.1189 s / img. ETA=0:06:39
[32m[04/20 07:38:13 d2.evaluation.evaluator]: [0mInference done 5116/8355. 0.1189 s / img. ETA=0:06:34
[32m[04/20 07:38:18 d2.evaluation.evaluator]: [0mInference done 5157/8355. 0.1189 s / img. ETA=0:06:30
[32m[04/20 07:38:23 d2.evaluation.evaluator]: [0mInference done 5198/8355. 0.1189 s / img. ETA=0:06:25
[32m[04/20 07:38:28 d2.evaluation.evaluator]: [0mInference done 5239/8355. 0.1189 s / img. ETA=0:06:20
[32m[04/20 07:38:34 d2.evaluation.evaluator]: [0mInference done 5280/8355. 0.1189 s / img. ETA=0:06:15
[32m[04/20 07:38:39 d2.evaluation.evaluator]: [0mInference done 5321/8355. 0.1189 s / img. ETA=0:06:10
[32m[04/20 07:38:44 d2.evaluation.evaluator]: [0mInference done 5362/8355. 0.1189 s / img. ETA=0:06:05
[32m[04/20 07:38:49 d2.evaluation.evaluator]: [0mInference done 5403/8355. 0.1189 s / img. ETA=0:06:00
[32m[04/20 07:38:54 d2.evaluation.evaluator]: [0mInference done 5444/8355. 0.1189 s / img. ETA=0:05:55
[32m[04/20 07:38:59 d2.evaluation.evaluator]: [0mInference done 5485/8355. 0.1189 s / img. ETA=0:05:50
[32m[04/20 07:39:04 d2.evaluation.evaluator]: [0mInference done 5526/8355. 0.1189 s / img. ETA=0:05:45
[32m[04/20 07:39:09 d2.evaluation.evaluator]: [0mInference done 5567/8355. 0.1189 s / img. ETA=0:05:40
[32m[04/20 07:39:14 d2.evaluation.evaluator]: [0mInference done 5608/8355. 0.1190 s / img. ETA=0:05:35
[32m[04/20 07:39:19 d2.evaluation.evaluator]: [0mInference done 5649/8355. 0.1190 s / img. ETA=0:05:30
[32m[04/20 07:39:24 d2.evaluation.evaluator]: [0mInference done 5690/8355. 0.1190 s / img. ETA=0:05:25
[32m[04/20 07:39:29 d2.evaluation.evaluator]: [0mInference done 5731/8355. 0.1190 s / img. ETA=0:05:20
[32m[04/20 07:39:34 d2.evaluation.evaluator]: [0mInference done 5772/8355. 0.1190 s / img. ETA=0:05:15
[32m[04/20 07:39:39 d2.evaluation.evaluator]: [0mInference done 5813/8355. 0.1190 s / img. ETA=0:05:10
[32m[04/20 07:39:44 d2.evaluation.evaluator]: [0mInference done 5854/8355. 0.1190 s / img. ETA=0:05:05
[32m[04/20 07:39:49 d2.evaluation.evaluator]: [0mInference done 5895/8355. 0.1190 s / img. ETA=0:05:00
[32m[04/20 07:39:54 d2.evaluation.evaluator]: [0mInference done 5936/8355. 0.1190 s / img. ETA=0:04:55
[32m[04/20 07:39:59 d2.evaluation.evaluator]: [0mInference done 5977/8355. 0.1190 s / img. ETA=0:04:50
[32m[04/20 07:40:04 d2.evaluation.evaluator]: [0mInference done 6018/8355. 0.1190 s / img. ETA=0:04:45
[32m[04/20 07:40:09 d2.evaluation.evaluator]: [0mInference done 6059/8355. 0.1190 s / img. ETA=0:04:40
[32m[04/20 07:40:14 d2.evaluation.evaluator]: [0mInference done 6100/8355. 0.1190 s / img. ETA=0:04:35
[32m[04/20 07:40:19 d2.evaluation.evaluator]: [0mInference done 6142/8355. 0.1190 s / img. ETA=0:04:30
[32m[04/20 07:40:24 d2.evaluation.evaluator]: [0mInference done 6183/8355. 0.1190 s / img. ETA=0:04:25
[32m[04/20 07:40:29 d2.evaluation.evaluator]: [0mInference done 6224/8355. 0.1190 s / img. ETA=0:04:20
[32m[04/20 07:40:34 d2.evaluation.evaluator]: [0mInference done 6265/8355. 0.1190 s / img. ETA=0:04:15
[32m[04/20 07:40:39 d2.evaluation.evaluator]: [0mInference done 6306/8355. 0.1190 s / img. ETA=0:04:10
[32m[04/20 07:40:44 d2.evaluation.evaluator]: [0mInference done 6347/8355. 0.1190 s / img. ETA=0:04:05
[32m[04/20 07:40:49 d2.evaluation.evaluator]: [0mInference done 6388/8355. 0.1190 s / img. ETA=0:04:00
[32m[04/20 07:40:54 d2.evaluation.evaluator]: [0mInference done 6429/8355. 0.1190 s / img. ETA=0:03:55
[32m[04/20 07:40:59 d2.evaluation.evaluator]: [0mInference done 6470/8355. 0.1190 s / img. ETA=0:03:50
[32m[04/20 07:41:04 d2.evaluation.evaluator]: [0mInference done 6512/8355. 0.1190 s / img. ETA=0:03:44
[32m[04/20 07:41:10 d2.evaluation.evaluator]: [0mInference done 6553/8355. 0.1190 s / img. ETA=0:03:40
[32m[04/20 07:41:15 d2.evaluation.evaluator]: [0mInference done 6595/8355. 0.1190 s / img. ETA=0:03:34
[32m[04/20 07:41:20 d2.evaluation.evaluator]: [0mInference done 6636/8355. 0.1190 s / img. ETA=0:03:29
[32m[04/20 07:41:25 d2.evaluation.evaluator]: [0mInference done 6677/8355. 0.1190 s / img. ETA=0:03:24
[32m[04/20 07:41:30 d2.evaluation.evaluator]: [0mInference done 6719/8355. 0.1190 s / img. ETA=0:03:19
[32m[04/20 07:41:35 d2.evaluation.evaluator]: [0mInference done 6761/8355. 0.1190 s / img. ETA=0:03:14
[32m[04/20 07:41:40 d2.evaluation.evaluator]: [0mInference done 6803/8355. 0.1190 s / img. ETA=0:03:09
[32m[04/20 07:41:45 d2.evaluation.evaluator]: [0mInference done 6844/8355. 0.1190 s / img. ETA=0:03:04
[32m[04/20 07:41:50 d2.evaluation.evaluator]: [0mInference done 6886/8355. 0.1190 s / img. ETA=0:02:59
[32m[04/20 07:41:55 d2.evaluation.evaluator]: [0mInference done 6928/8355. 0.1190 s / img. ETA=0:02:54
[32m[04/20 07:42:00 d2.evaluation.evaluator]: [0mInference done 6969/8355. 0.1190 s / img. ETA=0:02:49
[32m[04/20 07:42:05 d2.evaluation.evaluator]: [0mInference done 7010/8355. 0.1190 s / img. ETA=0:02:44
[32m[04/20 07:42:10 d2.evaluation.evaluator]: [0mInference done 7051/8355. 0.1190 s / img. ETA=0:02:39
[32m[04/20 07:42:15 d2.evaluation.evaluator]: [0mInference done 7092/8355. 0.1190 s / img. ETA=0:02:34
[32m[04/20 07:42:20 d2.evaluation.evaluator]: [0mInference done 7133/8355. 0.1190 s / img. ETA=0:02:29
[32m[04/20 07:42:25 d2.evaluation.evaluator]: [0mInference done 7174/8355. 0.1190 s / img. ETA=0:02:24
[32m[04/20 07:42:31 d2.evaluation.evaluator]: [0mInference done 7215/8355. 0.1190 s / img. ETA=0:02:19
[32m[04/20 07:42:36 d2.evaluation.evaluator]: [0mInference done 7256/8355. 0.1191 s / img. ETA=0:02:14
[32m[04/20 07:42:41 d2.evaluation.evaluator]: [0mInference done 7297/8355. 0.1191 s / img. ETA=0:02:09
[32m[04/20 07:42:46 d2.evaluation.evaluator]: [0mInference done 7338/8355. 0.1191 s / img. ETA=0:02:04
[32m[04/20 07:42:51 d2.evaluation.evaluator]: [0mInference done 7379/8355. 0.1191 s / img. ETA=0:01:59
[32m[04/20 07:42:56 d2.evaluation.evaluator]: [0mInference done 7420/8355. 0.1191 s / img. ETA=0:01:54
[32m[04/20 07:43:01 d2.evaluation.evaluator]: [0mInference done 7461/8355. 0.1191 s / img. ETA=0:01:49
[32m[04/20 07:43:06 d2.evaluation.evaluator]: [0mInference done 7502/8355. 0.1191 s / img. ETA=0:01:44
[32m[04/20 07:43:11 d2.evaluation.evaluator]: [0mInference done 7543/8355. 0.1191 s / img. ETA=0:01:39
[32m[04/20 07:43:16 d2.evaluation.evaluator]: [0mInference done 7584/8355. 0.1191 s / img. ETA=0:01:34
[32m[04/20 07:43:21 d2.evaluation.evaluator]: [0mInference done 7625/8355. 0.1191 s / img. ETA=0:01:29
[32m[04/20 07:43:26 d2.evaluation.evaluator]: [0mInference done 7666/8355. 0.1191 s / img. ETA=0:01:24
[32m[04/20 07:43:31 d2.evaluation.evaluator]: [0mInference done 7707/8355. 0.1191 s / img. ETA=0:01:19
[32m[04/20 07:43:36 d2.evaluation.evaluator]: [0mInference done 7748/8355. 0.1192 s / img. ETA=0:01:14
[32m[04/20 07:43:42 d2.evaluation.evaluator]: [0mInference done 7789/8355. 0.1192 s / img. ETA=0:01:09
[32m[04/20 07:43:47 d2.evaluation.evaluator]: [0mInference done 7830/8355. 0.1192 s / img. ETA=0:01:04
[32m[04/20 07:43:52 d2.evaluation.evaluator]: [0mInference done 7871/8355. 0.1192 s / img. ETA=0:00:59
[32m[04/20 07:43:57 d2.evaluation.evaluator]: [0mInference done 7912/8355. 0.1192 s / img. ETA=0:00:54
[32m[04/20 07:44:02 d2.evaluation.evaluator]: [0mInference done 7953/8355. 0.1192 s / img. ETA=0:00:49
[32m[04/20 07:44:07 d2.evaluation.evaluator]: [0mInference done 7994/8355. 0.1192 s / img. ETA=0:00:44
[32m[04/20 07:44:12 d2.evaluation.evaluator]: [0mInference done 8035/8355. 0.1192 s / img. ETA=0:00:39
[32m[04/20 07:44:17 d2.evaluation.evaluator]: [0mInference done 8077/8355. 0.1192 s / img. ETA=0:00:33
[32m[04/20 07:44:22 d2.evaluation.evaluator]: [0mInference done 8119/8355. 0.1192 s / img. ETA=0:00:28
[32m[04/20 07:44:27 d2.evaluation.evaluator]: [0mInference done 8161/8355. 0.1192 s / img. ETA=0:00:23
[32m[04/20 07:44:32 d2.evaluation.evaluator]: [0mInference done 8203/8355. 0.1192 s / img. ETA=0:00:18
[32m[04/20 07:44:37 d2.evaluation.evaluator]: [0mInference done 8244/8355. 0.1192 s / img. ETA=0:00:13
[32m[04/20 07:44:42 d2.evaluation.evaluator]: [0mInference done 8286/8355. 0.1192 s / img. ETA=0:00:08
[32m[04/20 07:44:48 d2.evaluation.evaluator]: [0mInference done 8328/8355. 0.1192 s / img. ETA=0:00:03
[32m[04/20 07:44:51 d2.evaluation.evaluator]: [0mTotal inference time: 0:17:00.806944 (0.122252 s / img per device, on 1 devices)
[32m[04/20 07:44:51 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:35 (0.119174 s / img per device, on 1 devices)
[32m[04/20 07:44:51 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 07:44:51 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 07:44:52 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.59s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=24.31s).
Accumulating evaluation results...
DONE (t=2.71s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.257
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.505
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.226
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.165
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.529
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.114
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.297
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.428
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.566
[32m[04/20 07:45:19 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 25.702 | 50.494 | 22.631 | 16.523 | 37.039 | 52.865 |
[32m[04/20 07:45:19 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 28.988 | bicycle       | 11.743 | car            | 36.375 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 07:45:21 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 07:45:21 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 07:45:21 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 07:45:23 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1191 s / img. ETA=0:02:31
[32m[04/20 07:45:28 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1189 s / img. ETA=0:02:26
[32m[04/20 07:45:33 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1188 s / img. ETA=0:02:21
[32m[04/20 07:45:38 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1187 s / img. ETA=0:02:16
[32m[04/20 07:45:43 d2.evaluation.evaluator]: [0mInference done 178/1257. 0.1190 s / img. ETA=0:02:11
[32m[04/20 07:45:48 d2.evaluation.evaluator]: [0mInference done 219/1257. 0.1191 s / img. ETA=0:02:06
[32m[04/20 07:45:53 d2.evaluation.evaluator]: [0mInference done 260/1257. 0.1192 s / img. ETA=0:02:01
[32m[04/20 07:45:58 d2.evaluation.evaluator]: [0mInference done 302/1257. 0.1191 s / img. ETA=0:01:56
[32m[04/20 07:46:03 d2.evaluation.evaluator]: [0mInference done 343/1257. 0.1191 s / img. ETA=0:01:51
[32m[04/20 07:46:08 d2.evaluation.evaluator]: [0mInference done 384/1257. 0.1192 s / img. ETA=0:01:46
[32m[04/20 07:46:13 d2.evaluation.evaluator]: [0mInference done 426/1257. 0.1192 s / img. ETA=0:01:41
[32m[04/20 07:46:18 d2.evaluation.evaluator]: [0mInference done 467/1257. 0.1192 s / img. ETA=0:01:36
[32m[04/20 07:46:23 d2.evaluation.evaluator]: [0mInference done 508/1257. 0.1192 s / img. ETA=0:01:31
[32m[04/20 07:46:28 d2.evaluation.evaluator]: [0mInference done 549/1257. 0.1192 s / img. ETA=0:01:26
[32m[04/20 07:46:33 d2.evaluation.evaluator]: [0mInference done 590/1257. 0.1193 s / img. ETA=0:01:21
[32m[04/20 07:46:38 d2.evaluation.evaluator]: [0mInference done 631/1257. 0.1193 s / img. ETA=0:01:16
[32m[04/20 07:46:44 d2.evaluation.evaluator]: [0mInference done 672/1257. 0.1193 s / img. ETA=0:01:11
[32m[04/20 07:46:49 d2.evaluation.evaluator]: [0mInference done 713/1257. 0.1194 s / img. ETA=0:01:06
[32m[04/20 07:46:54 d2.evaluation.evaluator]: [0mInference done 754/1257. 0.1193 s / img. ETA=0:01:01
[32m[04/20 07:46:59 d2.evaluation.evaluator]: [0mInference done 795/1257. 0.1193 s / img. ETA=0:00:56
[32m[04/20 07:47:04 d2.evaluation.evaluator]: [0mInference done 836/1257. 0.1194 s / img. ETA=0:00:51
[32m[04/20 07:47:09 d2.evaluation.evaluator]: [0mInference done 877/1257. 0.1194 s / img. ETA=0:00:46
[32m[04/20 07:47:14 d2.evaluation.evaluator]: [0mInference done 918/1257. 0.1194 s / img. ETA=0:00:41
[32m[04/20 07:47:19 d2.evaluation.evaluator]: [0mInference done 959/1257. 0.1194 s / img. ETA=0:00:36
[32m[04/20 07:47:24 d2.evaluation.evaluator]: [0mInference done 1000/1257. 0.1194 s / img. ETA=0:00:31
[32m[04/20 07:47:29 d2.evaluation.evaluator]: [0mInference done 1041/1257. 0.1194 s / img. ETA=0:00:26
[32m[04/20 07:47:34 d2.evaluation.evaluator]: [0mInference done 1082/1257. 0.1194 s / img. ETA=0:00:21
[32m[04/20 07:47:39 d2.evaluation.evaluator]: [0mInference done 1123/1257. 0.1194 s / img. ETA=0:00:16
[32m[04/20 07:47:44 d2.evaluation.evaluator]: [0mInference done 1164/1257. 0.1194 s / img. ETA=0:00:11
[32m[04/20 07:47:49 d2.evaluation.evaluator]: [0mInference done 1205/1257. 0.1194 s / img. ETA=0:00:06
[32m[04/20 07:47:54 d2.evaluation.evaluator]: [0mInference done 1246/1257. 0.1194 s / img. ETA=0:00:01
[32m[04/20 07:47:55 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:33.511131 (0.122613 s / img per device, on 1 devices)
[32m[04/20 07:47:55 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:29 (0.119416 s / img per device, on 1 devices)
[32m[04/20 07:47:55 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 07:47:55 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 07:47:55 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.19s).
Accumulating evaluation results...
DONE (t=0.44s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.236
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.447
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.218
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.141
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.288
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.414
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.115
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.274
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.181
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.332
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.445
[32m[04/20 07:47:59 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 23.638 | 44.659 | 21.818 | 14.063 | 28.781 | 41.417 |
[32m[04/20 07:47:59 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 25.957 | bicycle       | 5.986 | car            | 38.970 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | nan   | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  4  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 07:48:00 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 07:48:01 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 07:48:01 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 07:48:01 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 07:48:01 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 07:48:01 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 07:48:01 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 07:48:22 d2.utils.events]: [0m eta: 0:16:49  iter: 19  total_loss: 0.685  loss_cls: 0.226  loss_box_reg: 0.375  loss_rpn_cls: 0.023  loss_rpn_loc: 0.060  time: 1.0242  data_time: 0.0447  lr: 0.000100  max_mem: 5405M
[32m[04/20 07:48:43 d2.utils.events]: [0m eta: 0:16:30  iter: 39  total_loss: 0.758  loss_cls: 0.250  loss_box_reg: 0.397  loss_rpn_cls: 0.025  loss_rpn_loc: 0.061  time: 1.0345  data_time: 0.0183  lr: 0.000200  max_mem: 5405M
[32m[04/20 07:49:03 d2.utils.events]: [0m eta: 0:16:09  iter: 59  total_loss: 0.666  loss_cls: 0.222  loss_box_reg: 0.331  loss_rpn_cls: 0.031  loss_rpn_loc: 0.067  time: 1.0272  data_time: 0.0157  lr: 0.000300  max_mem: 5405M
[32m[04/20 07:49:25 d2.utils.events]: [0m eta: 0:15:51  iter: 79  total_loss: 0.664  loss_cls: 0.217  loss_box_reg: 0.363  loss_rpn_cls: 0.022  loss_rpn_loc: 0.051  time: 1.0346  data_time: 0.0157  lr: 0.000400  max_mem: 5405M
[32m[04/20 07:49:45 d2.utils.events]: [0m eta: 0:15:30  iter: 99  total_loss: 0.717  loss_cls: 0.219  loss_box_reg: 0.407  loss_rpn_cls: 0.024  loss_rpn_loc: 0.075  time: 1.0335  data_time: 0.0150  lr: 0.000500  max_mem: 5405M
[32m[04/20 07:50:07 d2.utils.events]: [0m eta: 0:15:20  iter: 119  total_loss: 0.687  loss_cls: 0.231  loss_box_reg: 0.362  loss_rpn_cls: 0.022  loss_rpn_loc: 0.059  time: 1.0381  data_time: 0.0188  lr: 0.000599  max_mem: 5405M
[32m[04/20 07:50:28 d2.utils.events]: [0m eta: 0:15:05  iter: 139  total_loss: 0.644  loss_cls: 0.225  loss_box_reg: 0.328  loss_rpn_cls: 0.026  loss_rpn_loc: 0.055  time: 1.0422  data_time: 0.0160  lr: 0.000699  max_mem: 5405M
[32m[04/20 07:50:49 d2.utils.events]: [0m eta: 0:14:43  iter: 159  total_loss: 0.640  loss_cls: 0.197  loss_box_reg: 0.356  loss_rpn_cls: 0.023  loss_rpn_loc: 0.058  time: 1.0412  data_time: 0.0169  lr: 0.000799  max_mem: 5405M
[32m[04/20 07:51:10 d2.utils.events]: [0m eta: 0:14:24  iter: 179  total_loss: 0.630  loss_cls: 0.196  loss_box_reg: 0.343  loss_rpn_cls: 0.021  loss_rpn_loc: 0.063  time: 1.0428  data_time: 0.0168  lr: 0.000899  max_mem: 5405M
[32m[04/20 07:51:30 d2.utils.events]: [0m eta: 0:13:57  iter: 199  total_loss: 0.702  loss_cls: 0.244  loss_box_reg: 0.346  loss_rpn_cls: 0.026  loss_rpn_loc: 0.075  time: 1.0395  data_time: 0.0145  lr: 0.000999  max_mem: 5405M
[32m[04/20 07:51:50 d2.utils.events]: [0m eta: 0:13:31  iter: 219  total_loss: 0.629  loss_cls: 0.219  loss_box_reg: 0.322  loss_rpn_cls: 0.023  loss_rpn_loc: 0.061  time: 1.0367  data_time: 0.0181  lr: 0.001099  max_mem: 5405M
[32m[04/20 07:52:11 d2.utils.events]: [0m eta: 0:13:13  iter: 239  total_loss: 0.632  loss_cls: 0.208  loss_box_reg: 0.358  loss_rpn_cls: 0.020  loss_rpn_loc: 0.072  time: 1.0375  data_time: 0.0171  lr: 0.001199  max_mem: 5405M
[32m[04/20 07:52:32 d2.utils.events]: [0m eta: 0:12:50  iter: 259  total_loss: 0.692  loss_cls: 0.236  loss_box_reg: 0.358  loss_rpn_cls: 0.023  loss_rpn_loc: 0.058  time: 1.0372  data_time: 0.0178  lr: 0.001299  max_mem: 5405M
[32m[04/20 07:52:53 d2.utils.events]: [0m eta: 0:12:32  iter: 279  total_loss: 0.654  loss_cls: 0.226  loss_box_reg: 0.349  loss_rpn_cls: 0.023  loss_rpn_loc: 0.049  time: 1.0379  data_time: 0.0168  lr: 0.001399  max_mem: 5405M
[32m[04/20 07:53:14 d2.utils.events]: [0m eta: 0:12:13  iter: 299  total_loss: 0.674  loss_cls: 0.221  loss_box_reg: 0.358  loss_rpn_cls: 0.023  loss_rpn_loc: 0.063  time: 1.0397  data_time: 0.0169  lr: 0.001499  max_mem: 5405M
[32m[04/20 07:53:35 d2.utils.events]: [0m eta: 0:11:53  iter: 319  total_loss: 0.646  loss_cls: 0.231  loss_box_reg: 0.346  loss_rpn_cls: 0.025  loss_rpn_loc: 0.045  time: 1.0404  data_time: 0.0191  lr: 0.001598  max_mem: 5405M
[32m[04/20 07:53:56 d2.utils.events]: [0m eta: 0:11:32  iter: 339  total_loss: 0.603  loss_cls: 0.205  loss_box_reg: 0.350  loss_rpn_cls: 0.020  loss_rpn_loc: 0.053  time: 1.0408  data_time: 0.0168  lr: 0.001698  max_mem: 5405M
[32m[04/20 07:54:18 d2.utils.events]: [0m eta: 0:11:12  iter: 359  total_loss: 0.721  loss_cls: 0.229  loss_box_reg: 0.399  loss_rpn_cls: 0.021  loss_rpn_loc: 0.055  time: 1.0421  data_time: 0.0200  lr: 0.001798  max_mem: 5405M
[32m[04/20 07:54:38 d2.utils.events]: [0m eta: 0:10:51  iter: 379  total_loss: 0.613  loss_cls: 0.193  loss_box_reg: 0.319  loss_rpn_cls: 0.020  loss_rpn_loc: 0.053  time: 1.0415  data_time: 0.0164  lr: 0.001898  max_mem: 5405M
[32m[04/20 07:54:59 d2.utils.events]: [0m eta: 0:10:30  iter: 399  total_loss: 0.670  loss_cls: 0.222  loss_box_reg: 0.365  loss_rpn_cls: 0.024  loss_rpn_loc: 0.067  time: 1.0411  data_time: 0.0159  lr: 0.001998  max_mem: 5405M
[32m[04/20 07:55:20 d2.utils.events]: [0m eta: 0:10:10  iter: 419  total_loss: 0.732  loss_cls: 0.236  loss_box_reg: 0.395  loss_rpn_cls: 0.026  loss_rpn_loc: 0.061  time: 1.0421  data_time: 0.0173  lr: 0.002098  max_mem: 5405M
[32m[04/20 07:55:41 d2.utils.events]: [0m eta: 0:09:48  iter: 439  total_loss: 0.620  loss_cls: 0.203  loss_box_reg: 0.339  loss_rpn_cls: 0.020  loss_rpn_loc: 0.054  time: 1.0416  data_time: 0.0156  lr: 0.002198  max_mem: 5405M
[32m[04/20 07:56:02 d2.utils.events]: [0m eta: 0:09:28  iter: 459  total_loss: 0.662  loss_cls: 0.217  loss_box_reg: 0.359  loss_rpn_cls: 0.026  loss_rpn_loc: 0.064  time: 1.0419  data_time: 0.0168  lr: 0.002298  max_mem: 5405M
[32m[04/20 07:56:23 d2.utils.events]: [0m eta: 0:09:07  iter: 479  total_loss: 0.698  loss_cls: 0.230  loss_box_reg: 0.382  loss_rpn_cls: 0.023  loss_rpn_loc: 0.056  time: 1.0417  data_time: 0.0193  lr: 0.002398  max_mem: 5405M
[32m[04/20 07:56:44 d2.utils.events]: [0m eta: 0:08:45  iter: 499  total_loss: 0.628  loss_cls: 0.199  loss_box_reg: 0.333  loss_rpn_cls: 0.022  loss_rpn_loc: 0.047  time: 1.0412  data_time: 0.0187  lr: 0.002498  max_mem: 5405M
[32m[04/20 07:57:04 d2.utils.events]: [0m eta: 0:08:23  iter: 519  total_loss: 0.632  loss_cls: 0.193  loss_box_reg: 0.354  loss_rpn_cls: 0.017  loss_rpn_loc: 0.060  time: 1.0405  data_time: 0.0171  lr: 0.002597  max_mem: 5405M
[32m[04/20 07:57:25 d2.utils.events]: [0m eta: 0:08:02  iter: 539  total_loss: 0.665  loss_cls: 0.223  loss_box_reg: 0.342  loss_rpn_cls: 0.023  loss_rpn_loc: 0.065  time: 1.0408  data_time: 0.0180  lr: 0.002697  max_mem: 5405M
[32m[04/20 07:57:46 d2.utils.events]: [0m eta: 0:07:42  iter: 559  total_loss: 0.614  loss_cls: 0.207  loss_box_reg: 0.342  loss_rpn_cls: 0.021  loss_rpn_loc: 0.052  time: 1.0416  data_time: 0.0175  lr: 0.002797  max_mem: 5405M
[32m[04/20 07:58:07 d2.utils.events]: [0m eta: 0:07:21  iter: 579  total_loss: 0.698  loss_cls: 0.231  loss_box_reg: 0.351  loss_rpn_cls: 0.024  loss_rpn_loc: 0.066  time: 1.0414  data_time: 0.0147  lr: 0.002897  max_mem: 5405M
[32m[04/20 07:58:28 d2.utils.events]: [0m eta: 0:07:01  iter: 599  total_loss: 0.680  loss_cls: 0.231  loss_box_reg: 0.359  loss_rpn_cls: 0.019  loss_rpn_loc: 0.063  time: 1.0412  data_time: 0.0180  lr: 0.002997  max_mem: 5405M
[32m[04/20 07:58:49 d2.utils.events]: [0m eta: 0:06:41  iter: 619  total_loss: 0.711  loss_cls: 0.239  loss_box_reg: 0.380  loss_rpn_cls: 0.023  loss_rpn_loc: 0.053  time: 1.0418  data_time: 0.0177  lr: 0.003097  max_mem: 5405M
[32m[04/20 07:59:10 d2.utils.events]: [0m eta: 0:06:20  iter: 639  total_loss: 0.702  loss_cls: 0.236  loss_box_reg: 0.356  loss_rpn_cls: 0.020  loss_rpn_loc: 0.061  time: 1.0420  data_time: 0.0169  lr: 0.003197  max_mem: 5405M
[32m[04/20 07:59:31 d2.utils.events]: [0m eta: 0:05:58  iter: 659  total_loss: 0.691  loss_cls: 0.222  loss_box_reg: 0.369  loss_rpn_cls: 0.022  loss_rpn_loc: 0.072  time: 1.0419  data_time: 0.0176  lr: 0.003297  max_mem: 5405M
[32m[04/20 07:59:52 d2.utils.events]: [0m eta: 0:05:37  iter: 679  total_loss: 0.663  loss_cls: 0.224  loss_box_reg: 0.367  loss_rpn_cls: 0.024  loss_rpn_loc: 0.062  time: 1.0423  data_time: 0.0147  lr: 0.003397  max_mem: 5405M
[32m[04/20 08:00:13 d2.utils.events]: [0m eta: 0:05:16  iter: 699  total_loss: 0.722  loss_cls: 0.249  loss_box_reg: 0.397  loss_rpn_cls: 0.028  loss_rpn_loc: 0.068  time: 1.0423  data_time: 0.0177  lr: 0.003497  max_mem: 5405M
[32m[04/20 08:00:34 d2.utils.events]: [0m eta: 0:04:55  iter: 719  total_loss: 0.665  loss_cls: 0.223  loss_box_reg: 0.342  loss_rpn_cls: 0.021  loss_rpn_loc: 0.052  time: 1.0425  data_time: 0.0172  lr: 0.003596  max_mem: 5405M
[32m[04/20 08:00:55 d2.utils.events]: [0m eta: 0:04:34  iter: 739  total_loss: 0.749  loss_cls: 0.237  loss_box_reg: 0.393  loss_rpn_cls: 0.026  loss_rpn_loc: 0.069  time: 1.0427  data_time: 0.0165  lr: 0.003696  max_mem: 5405M
[32m[04/20 08:01:16 d2.utils.events]: [0m eta: 0:04:13  iter: 759  total_loss: 0.707  loss_cls: 0.243  loss_box_reg: 0.378  loss_rpn_cls: 0.025  loss_rpn_loc: 0.065  time: 1.0421  data_time: 0.0204  lr: 0.003796  max_mem: 5405M
[32m[04/20 08:01:36 d2.utils.events]: [0m eta: 0:03:52  iter: 779  total_loss: 0.671  loss_cls: 0.214  loss_box_reg: 0.380  loss_rpn_cls: 0.022  loss_rpn_loc: 0.061  time: 1.0419  data_time: 0.0181  lr: 0.003896  max_mem: 5405M
[32m[04/20 08:01:57 d2.utils.events]: [0m eta: 0:03:31  iter: 799  total_loss: 0.549  loss_cls: 0.181  loss_box_reg: 0.306  loss_rpn_cls: 0.015  loss_rpn_loc: 0.042  time: 1.0418  data_time: 0.0149  lr: 0.003996  max_mem: 5405M
[32m[04/20 08:02:18 d2.utils.events]: [0m eta: 0:03:10  iter: 819  total_loss: 0.569  loss_cls: 0.193  loss_box_reg: 0.308  loss_rpn_cls: 0.023  loss_rpn_loc: 0.054  time: 1.0414  data_time: 0.0161  lr: 0.004096  max_mem: 5405M
[32m[04/20 08:02:39 d2.utils.events]: [0m eta: 0:02:49  iter: 839  total_loss: 0.663  loss_cls: 0.219  loss_box_reg: 0.353  loss_rpn_cls: 0.026  loss_rpn_loc: 0.054  time: 1.0417  data_time: 0.0177  lr: 0.004196  max_mem: 5405M
[32m[04/20 08:03:00 d2.utils.events]: [0m eta: 0:02:28  iter: 859  total_loss: 0.602  loss_cls: 0.205  loss_box_reg: 0.291  loss_rpn_cls: 0.026  loss_rpn_loc: 0.063  time: 1.0419  data_time: 0.0176  lr: 0.004296  max_mem: 5405M
[32m[04/20 08:03:20 d2.utils.events]: [0m eta: 0:02:07  iter: 879  total_loss: 0.624  loss_cls: 0.206  loss_box_reg: 0.320  loss_rpn_cls: 0.023  loss_rpn_loc: 0.038  time: 1.0413  data_time: 0.0146  lr: 0.004396  max_mem: 5405M
[32m[04/20 08:03:41 d2.utils.events]: [0m eta: 0:01:46  iter: 899  total_loss: 0.700  loss_cls: 0.241  loss_box_reg: 0.358  loss_rpn_cls: 0.027  loss_rpn_loc: 0.052  time: 1.0413  data_time: 0.0155  lr: 0.004496  max_mem: 5405M
[32m[04/20 08:04:03 d2.utils.events]: [0m eta: 0:01:25  iter: 919  total_loss: 0.751  loss_cls: 0.243  loss_box_reg: 0.383  loss_rpn_cls: 0.026  loss_rpn_loc: 0.076  time: 1.0419  data_time: 0.0167  lr: 0.004595  max_mem: 5405M
[32m[04/20 08:04:24 d2.utils.events]: [0m eta: 0:01:04  iter: 939  total_loss: 0.728  loss_cls: 0.251  loss_box_reg: 0.372  loss_rpn_cls: 0.029  loss_rpn_loc: 0.050  time: 1.0421  data_time: 0.0185  lr: 0.004695  max_mem: 5405M
[32m[04/20 08:04:45 d2.utils.events]: [0m eta: 0:00:43  iter: 959  total_loss: 0.634  loss_cls: 0.203  loss_box_reg: 0.344  loss_rpn_cls: 0.023  loss_rpn_loc: 0.060  time: 1.0420  data_time: 0.0182  lr: 0.004795  max_mem: 5405M
[32m[04/20 08:05:05 d2.utils.events]: [0m eta: 0:00:22  iter: 979  total_loss: 0.703  loss_cls: 0.239  loss_box_reg: 0.380  loss_rpn_cls: 0.027  loss_rpn_loc: 0.070  time: 1.0419  data_time: 0.0200  lr: 0.004895  max_mem: 5405M
[5m[31mWARNING[0m [32m[04/20 08:05:30 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 08:05:30 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 08:05:30 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 08:05:30 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.643  loss_cls: 0.216  loss_box_reg: 0.346  loss_rpn_cls: 0.022  loss_rpn_loc: 0.066  time: 1.0416  data_time: 0.0172  lr: 0.004995  max_mem: 5405M
[32m[04/20 08:05:31 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:19 (1.0427 s / it)
[32m[04/20 08:05:31 d2.engine.hooks]: [0mTotal training time: 0:17:27 (0:00:07 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 08:05:34 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 08:05:34 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 08:05:35 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 08:05:37 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1183 s / img. ETA=0:16:44
[32m[04/20 08:05:42 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1184 s / img. ETA=0:16:45
[32m[04/20 08:05:47 d2.evaluation.evaluator]: [0mInference done 95/8355. 0.1181 s / img. ETA=0:16:37
[32m[04/20 08:05:52 d2.evaluation.evaluator]: [0mInference done 137/8355. 0.1182 s / img. ETA=0:16:33
[32m[04/20 08:05:57 d2.evaluation.evaluator]: [0mInference done 179/8355. 0.1182 s / img. ETA=0:16:28
[32m[04/20 08:06:02 d2.evaluation.evaluator]: [0mInference done 221/8355. 0.1182 s / img. ETA=0:16:23
[32m[04/20 08:06:07 d2.evaluation.evaluator]: [0mInference done 263/8355. 0.1182 s / img. ETA=0:16:18
[32m[04/20 08:06:12 d2.evaluation.evaluator]: [0mInference done 305/8355. 0.1183 s / img. ETA=0:16:14
[32m[04/20 08:06:17 d2.evaluation.evaluator]: [0mInference done 347/8355. 0.1183 s / img. ETA=0:16:09
[32m[04/20 08:06:23 d2.evaluation.evaluator]: [0mInference done 389/8355. 0.1183 s / img. ETA=0:16:04
[32m[04/20 08:06:28 d2.evaluation.evaluator]: [0mInference done 431/8355. 0.1183 s / img. ETA=0:16:00
[32m[04/20 08:06:33 d2.evaluation.evaluator]: [0mInference done 473/8355. 0.1183 s / img. ETA=0:15:54
[32m[04/20 08:06:38 d2.evaluation.evaluator]: [0mInference done 515/8355. 0.1183 s / img. ETA=0:15:49
[32m[04/20 08:06:43 d2.evaluation.evaluator]: [0mInference done 556/8355. 0.1183 s / img. ETA=0:15:44
[32m[04/20 08:06:48 d2.evaluation.evaluator]: [0mInference done 598/8355. 0.1184 s / img. ETA=0:15:39
[32m[04/20 08:06:53 d2.evaluation.evaluator]: [0mInference done 640/8355. 0.1183 s / img. ETA=0:15:34
[32m[04/20 08:06:58 d2.evaluation.evaluator]: [0mInference done 681/8355. 0.1184 s / img. ETA=0:15:30
[32m[04/20 08:07:03 d2.evaluation.evaluator]: [0mInference done 723/8355. 0.1184 s / img. ETA=0:15:25
[32m[04/20 08:07:08 d2.evaluation.evaluator]: [0mInference done 764/8355. 0.1185 s / img. ETA=0:15:21
[32m[04/20 08:07:13 d2.evaluation.evaluator]: [0mInference done 806/8355. 0.1185 s / img. ETA=0:15:16
[32m[04/20 08:07:18 d2.evaluation.evaluator]: [0mInference done 848/8355. 0.1185 s / img. ETA=0:15:10
[32m[04/20 08:07:23 d2.evaluation.evaluator]: [0mInference done 890/8355. 0.1185 s / img. ETA=0:15:05
[32m[04/20 08:07:29 d2.evaluation.evaluator]: [0mInference done 932/8355. 0.1185 s / img. ETA=0:15:00
[32m[04/20 08:07:34 d2.evaluation.evaluator]: [0mInference done 974/8355. 0.1184 s / img. ETA=0:14:55
[32m[04/20 08:07:39 d2.evaluation.evaluator]: [0mInference done 1016/8355. 0.1184 s / img. ETA=0:14:50
[32m[04/20 08:07:44 d2.evaluation.evaluator]: [0mInference done 1058/8355. 0.1184 s / img. ETA=0:14:45
[32m[04/20 08:07:49 d2.evaluation.evaluator]: [0mInference done 1100/8355. 0.1184 s / img. ETA=0:14:39
[32m[04/20 08:07:54 d2.evaluation.evaluator]: [0mInference done 1142/8355. 0.1184 s / img. ETA=0:14:34
[32m[04/20 08:07:59 d2.evaluation.evaluator]: [0mInference done 1184/8355. 0.1183 s / img. ETA=0:14:29
[32m[04/20 08:08:04 d2.evaluation.evaluator]: [0mInference done 1225/8355. 0.1184 s / img. ETA=0:14:24
[32m[04/20 08:08:09 d2.evaluation.evaluator]: [0mInference done 1267/8355. 0.1183 s / img. ETA=0:14:19
[32m[04/20 08:08:14 d2.evaluation.evaluator]: [0mInference done 1309/8355. 0.1183 s / img. ETA=0:14:14
[32m[04/20 08:08:19 d2.evaluation.evaluator]: [0mInference done 1351/8355. 0.1183 s / img. ETA=0:14:08
[32m[04/20 08:08:24 d2.evaluation.evaluator]: [0mInference done 1393/8355. 0.1183 s / img. ETA=0:14:03
[32m[04/20 08:08:29 d2.evaluation.evaluator]: [0mInference done 1435/8355. 0.1182 s / img. ETA=0:13:58
[32m[04/20 08:08:34 d2.evaluation.evaluator]: [0mInference done 1477/8355. 0.1182 s / img. ETA=0:13:53
[32m[04/20 08:08:39 d2.evaluation.evaluator]: [0mInference done 1518/8355. 0.1183 s / img. ETA=0:13:48
[32m[04/20 08:08:44 d2.evaluation.evaluator]: [0mInference done 1559/8355. 0.1183 s / img. ETA=0:13:43
[32m[04/20 08:08:49 d2.evaluation.evaluator]: [0mInference done 1600/8355. 0.1183 s / img. ETA=0:13:38
[32m[04/20 08:08:54 d2.evaluation.evaluator]: [0mInference done 1641/8355. 0.1184 s / img. ETA=0:13:34
[32m[04/20 08:09:00 d2.evaluation.evaluator]: [0mInference done 1682/8355. 0.1184 s / img. ETA=0:13:29
[32m[04/20 08:09:05 d2.evaluation.evaluator]: [0mInference done 1723/8355. 0.1185 s / img. ETA=0:13:24
[32m[04/20 08:09:10 d2.evaluation.evaluator]: [0mInference done 1764/8355. 0.1185 s / img. ETA=0:13:20
[32m[04/20 08:09:15 d2.evaluation.evaluator]: [0mInference done 1805/8355. 0.1185 s / img. ETA=0:13:15
[32m[04/20 08:09:20 d2.evaluation.evaluator]: [0mInference done 1847/8355. 0.1185 s / img. ETA=0:13:10
[32m[04/20 08:09:25 d2.evaluation.evaluator]: [0mInference done 1888/8355. 0.1186 s / img. ETA=0:13:05
[32m[04/20 08:09:30 d2.evaluation.evaluator]: [0mInference done 1930/8355. 0.1186 s / img. ETA=0:13:00
[32m[04/20 08:09:35 d2.evaluation.evaluator]: [0mInference done 1972/8355. 0.1186 s / img. ETA=0:12:55
[32m[04/20 08:09:40 d2.evaluation.evaluator]: [0mInference done 2014/8355. 0.1186 s / img. ETA=0:12:50
[32m[04/20 08:09:45 d2.evaluation.evaluator]: [0mInference done 2056/8355. 0.1186 s / img. ETA=0:12:45
[32m[04/20 08:09:50 d2.evaluation.evaluator]: [0mInference done 2097/8355. 0.1186 s / img. ETA=0:12:40
[32m[04/20 08:09:55 d2.evaluation.evaluator]: [0mInference done 2139/8355. 0.1186 s / img. ETA=0:12:35
[32m[04/20 08:10:00 d2.evaluation.evaluator]: [0mInference done 2181/8355. 0.1186 s / img. ETA=0:12:30
[32m[04/20 08:10:06 d2.evaluation.evaluator]: [0mInference done 2223/8355. 0.1186 s / img. ETA=0:12:24
[32m[04/20 08:10:11 d2.evaluation.evaluator]: [0mInference done 2265/8355. 0.1186 s / img. ETA=0:12:19
[32m[04/20 08:10:16 d2.evaluation.evaluator]: [0mInference done 2306/8355. 0.1186 s / img. ETA=0:12:15
[32m[04/20 08:10:21 d2.evaluation.evaluator]: [0mInference done 2347/8355. 0.1186 s / img. ETA=0:12:10
[32m[04/20 08:10:26 d2.evaluation.evaluator]: [0mInference done 2389/8355. 0.1186 s / img. ETA=0:12:05
[32m[04/20 08:10:31 d2.evaluation.evaluator]: [0mInference done 2431/8355. 0.1186 s / img. ETA=0:12:00
[32m[04/20 08:10:36 d2.evaluation.evaluator]: [0mInference done 2472/8355. 0.1186 s / img. ETA=0:11:55
[32m[04/20 08:10:41 d2.evaluation.evaluator]: [0mInference done 2513/8355. 0.1186 s / img. ETA=0:11:50
[32m[04/20 08:10:46 d2.evaluation.evaluator]: [0mInference done 2554/8355. 0.1186 s / img. ETA=0:11:45
[32m[04/20 08:10:51 d2.evaluation.evaluator]: [0mInference done 2595/8355. 0.1186 s / img. ETA=0:11:40
[32m[04/20 08:10:56 d2.evaluation.evaluator]: [0mInference done 2636/8355. 0.1186 s / img. ETA=0:11:35
[32m[04/20 08:11:01 d2.evaluation.evaluator]: [0mInference done 2677/8355. 0.1186 s / img. ETA=0:11:30
[32m[04/20 08:11:06 d2.evaluation.evaluator]: [0mInference done 2719/8355. 0.1186 s / img. ETA=0:11:25
[32m[04/20 08:11:11 d2.evaluation.evaluator]: [0mInference done 2760/8355. 0.1186 s / img. ETA=0:11:20
[32m[04/20 08:11:16 d2.evaluation.evaluator]: [0mInference done 2802/8355. 0.1186 s / img. ETA=0:11:15
[32m[04/20 08:11:21 d2.evaluation.evaluator]: [0mInference done 2843/8355. 0.1187 s / img. ETA=0:11:10
[32m[04/20 08:11:26 d2.evaluation.evaluator]: [0mInference done 2884/8355. 0.1187 s / img. ETA=0:11:05
[32m[04/20 08:11:31 d2.evaluation.evaluator]: [0mInference done 2925/8355. 0.1187 s / img. ETA=0:11:00
[32m[04/20 08:11:36 d2.evaluation.evaluator]: [0mInference done 2966/8355. 0.1187 s / img. ETA=0:10:55
[32m[04/20 08:11:41 d2.evaluation.evaluator]: [0mInference done 3007/8355. 0.1187 s / img. ETA=0:10:50
[32m[04/20 08:11:46 d2.evaluation.evaluator]: [0mInference done 3048/8355. 0.1187 s / img. ETA=0:10:45
[32m[04/20 08:11:51 d2.evaluation.evaluator]: [0mInference done 3090/8355. 0.1187 s / img. ETA=0:10:40
[32m[04/20 08:11:56 d2.evaluation.evaluator]: [0mInference done 3131/8355. 0.1187 s / img. ETA=0:10:35
[32m[04/20 08:12:02 d2.evaluation.evaluator]: [0mInference done 3173/8355. 0.1187 s / img. ETA=0:10:30
[32m[04/20 08:12:07 d2.evaluation.evaluator]: [0mInference done 3215/8355. 0.1187 s / img. ETA=0:10:25
[32m[04/20 08:12:12 d2.evaluation.evaluator]: [0mInference done 3257/8355. 0.1187 s / img. ETA=0:10:20
[32m[04/20 08:12:17 d2.evaluation.evaluator]: [0mInference done 3298/8355. 0.1187 s / img. ETA=0:10:15
[32m[04/20 08:12:22 d2.evaluation.evaluator]: [0mInference done 3339/8355. 0.1187 s / img. ETA=0:10:10
[32m[04/20 08:12:27 d2.evaluation.evaluator]: [0mInference done 3381/8355. 0.1187 s / img. ETA=0:10:05
[32m[04/20 08:12:32 d2.evaluation.evaluator]: [0mInference done 3422/8355. 0.1187 s / img. ETA=0:10:00
[32m[04/20 08:12:37 d2.evaluation.evaluator]: [0mInference done 3463/8355. 0.1187 s / img. ETA=0:09:55
[32m[04/20 08:12:42 d2.evaluation.evaluator]: [0mInference done 3504/8355. 0.1187 s / img. ETA=0:09:50
[32m[04/20 08:12:47 d2.evaluation.evaluator]: [0mInference done 3546/8355. 0.1187 s / img. ETA=0:09:45
[32m[04/20 08:12:52 d2.evaluation.evaluator]: [0mInference done 3587/8355. 0.1187 s / img. ETA=0:09:40
[32m[04/20 08:12:57 d2.evaluation.evaluator]: [0mInference done 3629/8355. 0.1187 s / img. ETA=0:09:35
[32m[04/20 08:13:02 d2.evaluation.evaluator]: [0mInference done 3670/8355. 0.1188 s / img. ETA=0:09:30
[32m[04/20 08:13:07 d2.evaluation.evaluator]: [0mInference done 3712/8355. 0.1188 s / img. ETA=0:09:25
[32m[04/20 08:13:12 d2.evaluation.evaluator]: [0mInference done 3753/8355. 0.1188 s / img. ETA=0:09:20
[32m[04/20 08:13:17 d2.evaluation.evaluator]: [0mInference done 3794/8355. 0.1188 s / img. ETA=0:09:15
[32m[04/20 08:13:22 d2.evaluation.evaluator]: [0mInference done 3835/8355. 0.1188 s / img. ETA=0:09:10
[32m[04/20 08:13:28 d2.evaluation.evaluator]: [0mInference done 3877/8355. 0.1188 s / img. ETA=0:09:05
[32m[04/20 08:13:33 d2.evaluation.evaluator]: [0mInference done 3919/8355. 0.1188 s / img. ETA=0:09:00
[32m[04/20 08:13:38 d2.evaluation.evaluator]: [0mInference done 3961/8355. 0.1188 s / img. ETA=0:08:55
[32m[04/20 08:13:43 d2.evaluation.evaluator]: [0mInference done 4002/8355. 0.1188 s / img. ETA=0:08:50
[32m[04/20 08:13:48 d2.evaluation.evaluator]: [0mInference done 4043/8355. 0.1188 s / img. ETA=0:08:45
[32m[04/20 08:13:53 d2.evaluation.evaluator]: [0mInference done 4084/8355. 0.1188 s / img. ETA=0:08:40
[32m[04/20 08:13:58 d2.evaluation.evaluator]: [0mInference done 4125/8355. 0.1188 s / img. ETA=0:08:35
[32m[04/20 08:14:03 d2.evaluation.evaluator]: [0mInference done 4166/8355. 0.1188 s / img. ETA=0:08:30
[32m[04/20 08:14:08 d2.evaluation.evaluator]: [0mInference done 4207/8355. 0.1188 s / img. ETA=0:08:25
[32m[04/20 08:14:13 d2.evaluation.evaluator]: [0mInference done 4249/8355. 0.1188 s / img. ETA=0:08:20
[32m[04/20 08:14:18 d2.evaluation.evaluator]: [0mInference done 4291/8355. 0.1188 s / img. ETA=0:08:15
[32m[04/20 08:14:23 d2.evaluation.evaluator]: [0mInference done 4333/8355. 0.1188 s / img. ETA=0:08:09
[32m[04/20 08:14:28 d2.evaluation.evaluator]: [0mInference done 4375/8355. 0.1188 s / img. ETA=0:08:04
[32m[04/20 08:14:33 d2.evaluation.evaluator]: [0mInference done 4416/8355. 0.1188 s / img. ETA=0:07:59
[32m[04/20 08:14:39 d2.evaluation.evaluator]: [0mInference done 4458/8355. 0.1188 s / img. ETA=0:07:54
[32m[04/20 08:14:44 d2.evaluation.evaluator]: [0mInference done 4499/8355. 0.1188 s / img. ETA=0:07:49
[32m[04/20 08:14:49 d2.evaluation.evaluator]: [0mInference done 4540/8355. 0.1188 s / img. ETA=0:07:44
[32m[04/20 08:14:54 d2.evaluation.evaluator]: [0mInference done 4581/8355. 0.1188 s / img. ETA=0:07:39
[32m[04/20 08:14:59 d2.evaluation.evaluator]: [0mInference done 4622/8355. 0.1188 s / img. ETA=0:07:34
[32m[04/20 08:15:04 d2.evaluation.evaluator]: [0mInference done 4664/8355. 0.1188 s / img. ETA=0:07:29
[32m[04/20 08:15:09 d2.evaluation.evaluator]: [0mInference done 4705/8355. 0.1189 s / img. ETA=0:07:24
[32m[04/20 08:15:14 d2.evaluation.evaluator]: [0mInference done 4746/8355. 0.1189 s / img. ETA=0:07:19
[32m[04/20 08:15:19 d2.evaluation.evaluator]: [0mInference done 4787/8355. 0.1189 s / img. ETA=0:07:14
[32m[04/20 08:15:24 d2.evaluation.evaluator]: [0mInference done 4828/8355. 0.1189 s / img. ETA=0:07:09
[32m[04/20 08:15:29 d2.evaluation.evaluator]: [0mInference done 4870/8355. 0.1189 s / img. ETA=0:07:04
[32m[04/20 08:15:34 d2.evaluation.evaluator]: [0mInference done 4911/8355. 0.1189 s / img. ETA=0:06:59
[32m[04/20 08:15:39 d2.evaluation.evaluator]: [0mInference done 4952/8355. 0.1189 s / img. ETA=0:06:54
[32m[04/20 08:15:44 d2.evaluation.evaluator]: [0mInference done 4994/8355. 0.1189 s / img. ETA=0:06:49
[32m[04/20 08:15:49 d2.evaluation.evaluator]: [0mInference done 5035/8355. 0.1189 s / img. ETA=0:06:44
[32m[04/20 08:15:54 d2.evaluation.evaluator]: [0mInference done 5076/8355. 0.1189 s / img. ETA=0:06:39
[32m[04/20 08:15:59 d2.evaluation.evaluator]: [0mInference done 5117/8355. 0.1189 s / img. ETA=0:06:34
[32m[04/20 08:16:04 d2.evaluation.evaluator]: [0mInference done 5158/8355. 0.1189 s / img. ETA=0:06:29
[32m[04/20 08:16:09 d2.evaluation.evaluator]: [0mInference done 5199/8355. 0.1189 s / img. ETA=0:06:24
[32m[04/20 08:16:14 d2.evaluation.evaluator]: [0mInference done 5241/8355. 0.1189 s / img. ETA=0:06:19
[32m[04/20 08:16:19 d2.evaluation.evaluator]: [0mInference done 5282/8355. 0.1189 s / img. ETA=0:06:14
[32m[04/20 08:16:25 d2.evaluation.evaluator]: [0mInference done 5323/8355. 0.1189 s / img. ETA=0:06:09
[32m[04/20 08:16:30 d2.evaluation.evaluator]: [0mInference done 5364/8355. 0.1189 s / img. ETA=0:06:04
[32m[04/20 08:16:35 d2.evaluation.evaluator]: [0mInference done 5405/8355. 0.1189 s / img. ETA=0:05:59
[32m[04/20 08:16:40 d2.evaluation.evaluator]: [0mInference done 5446/8355. 0.1189 s / img. ETA=0:05:54
[32m[04/20 08:16:45 d2.evaluation.evaluator]: [0mInference done 5487/8355. 0.1189 s / img. ETA=0:05:49
[32m[04/20 08:16:50 d2.evaluation.evaluator]: [0mInference done 5528/8355. 0.1190 s / img. ETA=0:05:44
[32m[04/20 08:16:55 d2.evaluation.evaluator]: [0mInference done 5569/8355. 0.1190 s / img. ETA=0:05:39
[32m[04/20 08:17:00 d2.evaluation.evaluator]: [0mInference done 5610/8355. 0.1190 s / img. ETA=0:05:34
[32m[04/20 08:17:05 d2.evaluation.evaluator]: [0mInference done 5651/8355. 0.1190 s / img. ETA=0:05:29
[32m[04/20 08:17:10 d2.evaluation.evaluator]: [0mInference done 5692/8355. 0.1190 s / img. ETA=0:05:24
[32m[04/20 08:17:15 d2.evaluation.evaluator]: [0mInference done 5733/8355. 0.1190 s / img. ETA=0:05:19
[32m[04/20 08:17:20 d2.evaluation.evaluator]: [0mInference done 5774/8355. 0.1190 s / img. ETA=0:05:14
[32m[04/20 08:17:25 d2.evaluation.evaluator]: [0mInference done 5815/8355. 0.1190 s / img. ETA=0:05:10
[32m[04/20 08:17:30 d2.evaluation.evaluator]: [0mInference done 5856/8355. 0.1190 s / img. ETA=0:05:05
[32m[04/20 08:17:35 d2.evaluation.evaluator]: [0mInference done 5897/8355. 0.1190 s / img. ETA=0:05:00
[32m[04/20 08:17:40 d2.evaluation.evaluator]: [0mInference done 5938/8355. 0.1190 s / img. ETA=0:04:55
[32m[04/20 08:17:45 d2.evaluation.evaluator]: [0mInference done 5979/8355. 0.1190 s / img. ETA=0:04:50
[32m[04/20 08:17:50 d2.evaluation.evaluator]: [0mInference done 6020/8355. 0.1190 s / img. ETA=0:04:45
[32m[04/20 08:17:55 d2.evaluation.evaluator]: [0mInference done 6061/8355. 0.1190 s / img. ETA=0:04:40
[32m[04/20 08:18:00 d2.evaluation.evaluator]: [0mInference done 6102/8355. 0.1190 s / img. ETA=0:04:35
[32m[04/20 08:18:05 d2.evaluation.evaluator]: [0mInference done 6143/8355. 0.1190 s / img. ETA=0:04:30
[32m[04/20 08:18:10 d2.evaluation.evaluator]: [0mInference done 6184/8355. 0.1190 s / img. ETA=0:04:25
[32m[04/20 08:18:15 d2.evaluation.evaluator]: [0mInference done 6225/8355. 0.1190 s / img. ETA=0:04:20
[32m[04/20 08:18:21 d2.evaluation.evaluator]: [0mInference done 6266/8355. 0.1191 s / img. ETA=0:04:15
[32m[04/20 08:18:26 d2.evaluation.evaluator]: [0mInference done 6307/8355. 0.1191 s / img. ETA=0:04:10
[32m[04/20 08:18:31 d2.evaluation.evaluator]: [0mInference done 6348/8355. 0.1191 s / img. ETA=0:04:05
[32m[04/20 08:18:36 d2.evaluation.evaluator]: [0mInference done 6390/8355. 0.1191 s / img. ETA=0:03:59
[32m[04/20 08:18:41 d2.evaluation.evaluator]: [0mInference done 6431/8355. 0.1191 s / img. ETA=0:03:54
[32m[04/20 08:18:46 d2.evaluation.evaluator]: [0mInference done 6472/8355. 0.1191 s / img. ETA=0:03:49
[32m[04/20 08:18:51 d2.evaluation.evaluator]: [0mInference done 6514/8355. 0.1191 s / img. ETA=0:03:44
[32m[04/20 08:18:56 d2.evaluation.evaluator]: [0mInference done 6556/8355. 0.1191 s / img. ETA=0:03:39
[32m[04/20 08:19:01 d2.evaluation.evaluator]: [0mInference done 6597/8355. 0.1191 s / img. ETA=0:03:34
[32m[04/20 08:19:06 d2.evaluation.evaluator]: [0mInference done 6639/8355. 0.1191 s / img. ETA=0:03:29
[32m[04/20 08:19:11 d2.evaluation.evaluator]: [0mInference done 6681/8355. 0.1191 s / img. ETA=0:03:24
[32m[04/20 08:19:16 d2.evaluation.evaluator]: [0mInference done 6723/8355. 0.1191 s / img. ETA=0:03:19
[32m[04/20 08:19:21 d2.evaluation.evaluator]: [0mInference done 6765/8355. 0.1191 s / img. ETA=0:03:14
[32m[04/20 08:19:26 d2.evaluation.evaluator]: [0mInference done 6807/8355. 0.1191 s / img. ETA=0:03:08
[32m[04/20 08:19:32 d2.evaluation.evaluator]: [0mInference done 6849/8355. 0.1190 s / img. ETA=0:03:03
[32m[04/20 08:19:37 d2.evaluation.evaluator]: [0mInference done 6891/8355. 0.1190 s / img. ETA=0:02:58
[32m[04/20 08:19:42 d2.evaluation.evaluator]: [0mInference done 6933/8355. 0.1190 s / img. ETA=0:02:53
[32m[04/20 08:19:47 d2.evaluation.evaluator]: [0mInference done 6974/8355. 0.1191 s / img. ETA=0:02:48
[32m[04/20 08:19:52 d2.evaluation.evaluator]: [0mInference done 7015/8355. 0.1191 s / img. ETA=0:02:43
[32m[04/20 08:19:57 d2.evaluation.evaluator]: [0mInference done 7056/8355. 0.1191 s / img. ETA=0:02:38
[32m[04/20 08:20:02 d2.evaluation.evaluator]: [0mInference done 7097/8355. 0.1191 s / img. ETA=0:02:33
[32m[04/20 08:20:07 d2.evaluation.evaluator]: [0mInference done 7138/8355. 0.1191 s / img. ETA=0:02:28
[32m[04/20 08:20:12 d2.evaluation.evaluator]: [0mInference done 7179/8355. 0.1191 s / img. ETA=0:02:23
[32m[04/20 08:20:17 d2.evaluation.evaluator]: [0mInference done 7220/8355. 0.1191 s / img. ETA=0:02:18
[32m[04/20 08:20:22 d2.evaluation.evaluator]: [0mInference done 7261/8355. 0.1191 s / img. ETA=0:02:13
[32m[04/20 08:20:27 d2.evaluation.evaluator]: [0mInference done 7302/8355. 0.1191 s / img. ETA=0:02:08
[32m[04/20 08:20:33 d2.evaluation.evaluator]: [0mInference done 7343/8355. 0.1191 s / img. ETA=0:02:03
[32m[04/20 08:20:38 d2.evaluation.evaluator]: [0mInference done 7383/8355. 0.1192 s / img. ETA=0:01:58
[32m[04/20 08:20:43 d2.evaluation.evaluator]: [0mInference done 7424/8355. 0.1192 s / img. ETA=0:01:53
[32m[04/20 08:20:48 d2.evaluation.evaluator]: [0mInference done 7465/8355. 0.1192 s / img. ETA=0:01:48
[32m[04/20 08:20:53 d2.evaluation.evaluator]: [0mInference done 7506/8355. 0.1192 s / img. ETA=0:01:43
[32m[04/20 08:20:58 d2.evaluation.evaluator]: [0mInference done 7547/8355. 0.1192 s / img. ETA=0:01:38
[32m[04/20 08:21:03 d2.evaluation.evaluator]: [0mInference done 7588/8355. 0.1192 s / img. ETA=0:01:33
[32m[04/20 08:21:08 d2.evaluation.evaluator]: [0mInference done 7629/8355. 0.1192 s / img. ETA=0:01:28
[32m[04/20 08:21:13 d2.evaluation.evaluator]: [0mInference done 7670/8355. 0.1192 s / img. ETA=0:01:23
[32m[04/20 08:21:18 d2.evaluation.evaluator]: [0mInference done 7711/8355. 0.1192 s / img. ETA=0:01:18
[32m[04/20 08:21:23 d2.evaluation.evaluator]: [0mInference done 7752/8355. 0.1192 s / img. ETA=0:01:13
[32m[04/20 08:21:28 d2.evaluation.evaluator]: [0mInference done 7793/8355. 0.1192 s / img. ETA=0:01:08
[32m[04/20 08:21:33 d2.evaluation.evaluator]: [0mInference done 7834/8355. 0.1192 s / img. ETA=0:01:03
[32m[04/20 08:21:38 d2.evaluation.evaluator]: [0mInference done 7875/8355. 0.1192 s / img. ETA=0:00:58
[32m[04/20 08:21:43 d2.evaluation.evaluator]: [0mInference done 7916/8355. 0.1192 s / img. ETA=0:00:53
[32m[04/20 08:21:48 d2.evaluation.evaluator]: [0mInference done 7957/8355. 0.1192 s / img. ETA=0:00:48
[32m[04/20 08:21:54 d2.evaluation.evaluator]: [0mInference done 7998/8355. 0.1193 s / img. ETA=0:00:43
[32m[04/20 08:21:59 d2.evaluation.evaluator]: [0mInference done 8039/8355. 0.1193 s / img. ETA=0:00:38
[32m[04/20 08:22:04 d2.evaluation.evaluator]: [0mInference done 8080/8355. 0.1193 s / img. ETA=0:00:33
[32m[04/20 08:22:09 d2.evaluation.evaluator]: [0mInference done 8122/8355. 0.1192 s / img. ETA=0:00:28
[32m[04/20 08:22:14 d2.evaluation.evaluator]: [0mInference done 8164/8355. 0.1192 s / img. ETA=0:00:23
[32m[04/20 08:22:19 d2.evaluation.evaluator]: [0mInference done 8206/8355. 0.1192 s / img. ETA=0:00:18
[32m[04/20 08:22:24 d2.evaluation.evaluator]: [0mInference done 8247/8355. 0.1192 s / img. ETA=0:00:13
[32m[04/20 08:22:29 d2.evaluation.evaluator]: [0mInference done 8289/8355. 0.1192 s / img. ETA=0:00:08
[32m[04/20 08:22:34 d2.evaluation.evaluator]: [0mInference done 8330/8355. 0.1192 s / img. ETA=0:00:03
[32m[04/20 08:22:37 d2.evaluation.evaluator]: [0mTotal inference time: 0:17:01.073716 (0.122284 s / img per device, on 1 devices)
[32m[04/20 08:22:37 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:35 (0.119238 s / img per device, on 1 devices)
[32m[04/20 08:22:37 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 08:22:38 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 08:22:38 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.52s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=27.32s).
Accumulating evaluation results...
DONE (t=3.23s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.291
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.576
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.254
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.410
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.546
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.124
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.338
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.348
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.251
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.478
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.583
[32m[04/20 08:23:09 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 29.053 | 57.553 | 25.361 | 19.208 | 41.049 | 54.623 |
[32m[04/20 08:23:09 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 31.339 | bicycle       | 16.772 | car            | 39.048 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 08:23:10 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 08:23:10 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 08:23:11 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 08:23:12 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1187 s / img. ETA=0:02:31
[32m[04/20 08:23:17 d2.evaluation.evaluator]: [0mInference done 52/1257. 0.1193 s / img. ETA=0:02:27
[32m[04/20 08:23:22 d2.evaluation.evaluator]: [0mInference done 93/1257. 0.1193 s / img. ETA=0:02:22
[32m[04/20 08:23:27 d2.evaluation.evaluator]: [0mInference done 134/1257. 0.1197 s / img. ETA=0:02:17
[32m[04/20 08:23:32 d2.evaluation.evaluator]: [0mInference done 176/1257. 0.1194 s / img. ETA=0:02:12
[32m[04/20 08:23:37 d2.evaluation.evaluator]: [0mInference done 217/1257. 0.1193 s / img. ETA=0:02:07
[32m[04/20 08:23:42 d2.evaluation.evaluator]: [0mInference done 258/1257. 0.1193 s / img. ETA=0:02:02
[32m[04/20 08:23:47 d2.evaluation.evaluator]: [0mInference done 299/1257. 0.1193 s / img. ETA=0:01:57
[32m[04/20 08:23:53 d2.evaluation.evaluator]: [0mInference done 341/1257. 0.1192 s / img. ETA=0:01:52
[32m[04/20 08:23:58 d2.evaluation.evaluator]: [0mInference done 383/1257. 0.1191 s / img. ETA=0:01:46
[32m[04/20 08:24:03 d2.evaluation.evaluator]: [0mInference done 425/1257. 0.1191 s / img. ETA=0:01:41
[32m[04/20 08:24:08 d2.evaluation.evaluator]: [0mInference done 466/1257. 0.1192 s / img. ETA=0:01:36
[32m[04/20 08:24:13 d2.evaluation.evaluator]: [0mInference done 507/1257. 0.1193 s / img. ETA=0:01:31
[32m[04/20 08:24:18 d2.evaluation.evaluator]: [0mInference done 548/1257. 0.1195 s / img. ETA=0:01:26
[32m[04/20 08:24:23 d2.evaluation.evaluator]: [0mInference done 589/1257. 0.1195 s / img. ETA=0:01:21
[32m[04/20 08:24:28 d2.evaluation.evaluator]: [0mInference done 630/1257. 0.1196 s / img. ETA=0:01:16
[32m[04/20 08:24:33 d2.evaluation.evaluator]: [0mInference done 671/1257. 0.1196 s / img. ETA=0:01:11
[32m[04/20 08:24:38 d2.evaluation.evaluator]: [0mInference done 712/1257. 0.1196 s / img. ETA=0:01:06
[32m[04/20 08:24:43 d2.evaluation.evaluator]: [0mInference done 753/1257. 0.1196 s / img. ETA=0:01:01
[32m[04/20 08:24:48 d2.evaluation.evaluator]: [0mInference done 794/1257. 0.1196 s / img. ETA=0:00:56
[32m[04/20 08:24:53 d2.evaluation.evaluator]: [0mInference done 835/1257. 0.1196 s / img. ETA=0:00:51
[32m[04/20 08:24:58 d2.evaluation.evaluator]: [0mInference done 876/1257. 0.1196 s / img. ETA=0:00:46
[32m[04/20 08:25:03 d2.evaluation.evaluator]: [0mInference done 917/1257. 0.1196 s / img. ETA=0:00:41
[32m[04/20 08:25:08 d2.evaluation.evaluator]: [0mInference done 958/1257. 0.1195 s / img. ETA=0:00:36
[32m[04/20 08:25:13 d2.evaluation.evaluator]: [0mInference done 999/1257. 0.1196 s / img. ETA=0:00:31
[32m[04/20 08:25:18 d2.evaluation.evaluator]: [0mInference done 1040/1257. 0.1196 s / img. ETA=0:00:26
[32m[04/20 08:25:24 d2.evaluation.evaluator]: [0mInference done 1082/1257. 0.1195 s / img. ETA=0:00:21
[32m[04/20 08:25:29 d2.evaluation.evaluator]: [0mInference done 1123/1257. 0.1195 s / img. ETA=0:00:16
[32m[04/20 08:25:34 d2.evaluation.evaluator]: [0mInference done 1164/1257. 0.1195 s / img. ETA=0:00:11
[32m[04/20 08:25:39 d2.evaluation.evaluator]: [0mInference done 1205/1257. 0.1195 s / img. ETA=0:00:06
[32m[04/20 08:25:44 d2.evaluation.evaluator]: [0mInference done 1246/1257. 0.1196 s / img. ETA=0:00:01
[32m[04/20 08:25:45 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:33.709668 (0.122771 s / img per device, on 1 devices)
[32m[04/20 08:25:45 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:29 (0.119582 s / img per device, on 1 devices)
[32m[04/20 08:25:45 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 08:25:45 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 08:25:45 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=4.27s).
Accumulating evaluation results...
DONE (t=0.55s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.243
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.501
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.196
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.303
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.432
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.124
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.303
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.206
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.368
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.479
[32m[04/20 08:25:50 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 24.295 | 50.093 | 19.642 | 13.966 | 30.263 | 43.151 |
[32m[04/20 08:25:50 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 25.709 | bicycle       | 8.405 | car            | 38.772 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | nan   | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  5  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 08:25:51 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 08:25:52 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 08:25:52 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 08:25:52 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 08:25:52 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 08:25:52 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 08:25:53 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 08:26:14 d2.utils.events]: [0m eta: 0:17:43  iter: 19  total_loss: 0.621  loss_cls: 0.211  loss_box_reg: 0.347  loss_rpn_cls: 0.021  loss_rpn_loc: 0.058  time: 1.0622  data_time: 0.0540  lr: 0.000100  max_mem: 5405M
[32m[04/20 08:26:35 d2.utils.events]: [0m eta: 0:16:55  iter: 39  total_loss: 0.547  loss_cls: 0.190  loss_box_reg: 0.293  loss_rpn_cls: 0.027  loss_rpn_loc: 0.056  time: 1.0434  data_time: 0.0162  lr: 0.000200  max_mem: 5405M
[32m[04/20 08:26:56 d2.utils.events]: [0m eta: 0:16:27  iter: 59  total_loss: 0.767  loss_cls: 0.252  loss_box_reg: 0.378  loss_rpn_cls: 0.023  loss_rpn_loc: 0.071  time: 1.0409  data_time: 0.0177  lr: 0.000300  max_mem: 5405M
[32m[04/20 08:27:16 d2.utils.events]: [0m eta: 0:16:04  iter: 79  total_loss: 0.684  loss_cls: 0.217  loss_box_reg: 0.368  loss_rpn_cls: 0.027  loss_rpn_loc: 0.057  time: 1.0383  data_time: 0.0181  lr: 0.000400  max_mem: 5405M
[32m[04/20 08:27:37 d2.utils.events]: [0m eta: 0:15:36  iter: 99  total_loss: 0.674  loss_cls: 0.214  loss_box_reg: 0.370  loss_rpn_cls: 0.025  loss_rpn_loc: 0.062  time: 1.0342  data_time: 0.0151  lr: 0.000500  max_mem: 5405M
[32m[04/20 08:27:58 d2.utils.events]: [0m eta: 0:15:24  iter: 119  total_loss: 0.718  loss_cls: 0.246  loss_box_reg: 0.353  loss_rpn_cls: 0.025  loss_rpn_loc: 0.076  time: 1.0401  data_time: 0.0192  lr: 0.000599  max_mem: 5405M
[32m[04/20 08:28:19 d2.utils.events]: [0m eta: 0:15:05  iter: 139  total_loss: 0.647  loss_cls: 0.216  loss_box_reg: 0.356  loss_rpn_cls: 0.021  loss_rpn_loc: 0.053  time: 1.0398  data_time: 0.0162  lr: 0.000699  max_mem: 5405M
[32m[04/20 08:28:40 d2.utils.events]: [0m eta: 0:14:41  iter: 159  total_loss: 0.586  loss_cls: 0.190  loss_box_reg: 0.328  loss_rpn_cls: 0.021  loss_rpn_loc: 0.063  time: 1.0391  data_time: 0.0198  lr: 0.000799  max_mem: 5405M
[32m[04/20 08:29:01 d2.utils.events]: [0m eta: 0:14:20  iter: 179  total_loss: 0.631  loss_cls: 0.218  loss_box_reg: 0.338  loss_rpn_cls: 0.028  loss_rpn_loc: 0.064  time: 1.0394  data_time: 0.0172  lr: 0.000899  max_mem: 5405M
[32m[04/20 08:29:22 d2.utils.events]: [0m eta: 0:14:00  iter: 199  total_loss: 0.598  loss_cls: 0.192  loss_box_reg: 0.317  loss_rpn_cls: 0.026  loss_rpn_loc: 0.059  time: 1.0407  data_time: 0.0182  lr: 0.000999  max_mem: 5405M
[32m[04/20 08:29:43 d2.utils.events]: [0m eta: 0:13:39  iter: 219  total_loss: 0.652  loss_cls: 0.205  loss_box_reg: 0.330  loss_rpn_cls: 0.023  loss_rpn_loc: 0.059  time: 1.0401  data_time: 0.0164  lr: 0.001099  max_mem: 5405M
[32m[04/20 08:30:03 d2.utils.events]: [0m eta: 0:13:18  iter: 239  total_loss: 0.624  loss_cls: 0.199  loss_box_reg: 0.357  loss_rpn_cls: 0.017  loss_rpn_loc: 0.053  time: 1.0404  data_time: 0.0162  lr: 0.001199  max_mem: 5405M
[32m[04/20 08:30:25 d2.utils.events]: [0m eta: 0:13:00  iter: 259  total_loss: 0.654  loss_cls: 0.213  loss_box_reg: 0.332  loss_rpn_cls: 0.024  loss_rpn_loc: 0.066  time: 1.0413  data_time: 0.0178  lr: 0.001299  max_mem: 5405M
[32m[04/20 08:30:45 d2.utils.events]: [0m eta: 0:12:37  iter: 279  total_loss: 0.639  loss_cls: 0.229  loss_box_reg: 0.360  loss_rpn_cls: 0.020  loss_rpn_loc: 0.049  time: 1.0412  data_time: 0.0172  lr: 0.001399  max_mem: 5405M
[32m[04/20 08:31:06 d2.utils.events]: [0m eta: 0:12:16  iter: 299  total_loss: 0.641  loss_cls: 0.202  loss_box_reg: 0.346  loss_rpn_cls: 0.018  loss_rpn_loc: 0.057  time: 1.0407  data_time: 0.0159  lr: 0.001499  max_mem: 5405M
[32m[04/20 08:31:27 d2.utils.events]: [0m eta: 0:11:57  iter: 319  total_loss: 0.690  loss_cls: 0.220  loss_box_reg: 0.362  loss_rpn_cls: 0.020  loss_rpn_loc: 0.058  time: 1.0417  data_time: 0.0184  lr: 0.001598  max_mem: 5405M
[32m[04/20 08:31:48 d2.utils.events]: [0m eta: 0:11:36  iter: 339  total_loss: 0.595  loss_cls: 0.201  loss_box_reg: 0.338  loss_rpn_cls: 0.018  loss_rpn_loc: 0.050  time: 1.0422  data_time: 0.0203  lr: 0.001698  max_mem: 5405M
[32m[04/20 08:32:09 d2.utils.events]: [0m eta: 0:11:13  iter: 359  total_loss: 0.624  loss_cls: 0.201  loss_box_reg: 0.331  loss_rpn_cls: 0.021  loss_rpn_loc: 0.051  time: 1.0412  data_time: 0.0153  lr: 0.001798  max_mem: 5405M
[32m[04/20 08:32:30 d2.utils.events]: [0m eta: 0:10:53  iter: 379  total_loss: 0.660  loss_cls: 0.208  loss_box_reg: 0.361  loss_rpn_cls: 0.023  loss_rpn_loc: 0.052  time: 1.0416  data_time: 0.0181  lr: 0.001898  max_mem: 5405M
[32m[04/20 08:32:51 d2.utils.events]: [0m eta: 0:10:32  iter: 399  total_loss: 0.633  loss_cls: 0.207  loss_box_reg: 0.353  loss_rpn_cls: 0.025  loss_rpn_loc: 0.044  time: 1.0419  data_time: 0.0184  lr: 0.001998  max_mem: 5405M
[32m[04/20 08:33:11 d2.utils.events]: [0m eta: 0:10:10  iter: 419  total_loss: 0.583  loss_cls: 0.168  loss_box_reg: 0.322  loss_rpn_cls: 0.020  loss_rpn_loc: 0.048  time: 1.0411  data_time: 0.0162  lr: 0.002098  max_mem: 5405M
[32m[04/20 08:33:32 d2.utils.events]: [0m eta: 0:09:48  iter: 439  total_loss: 0.650  loss_cls: 0.220  loss_box_reg: 0.361  loss_rpn_cls: 0.025  loss_rpn_loc: 0.063  time: 1.0410  data_time: 0.0155  lr: 0.002198  max_mem: 5405M
[32m[04/20 08:33:53 d2.utils.events]: [0m eta: 0:09:27  iter: 459  total_loss: 0.656  loss_cls: 0.231  loss_box_reg: 0.363  loss_rpn_cls: 0.022  loss_rpn_loc: 0.060  time: 1.0411  data_time: 0.0160  lr: 0.002298  max_mem: 5405M
[32m[04/20 08:34:14 d2.utils.events]: [0m eta: 0:09:07  iter: 479  total_loss: 0.751  loss_cls: 0.247  loss_box_reg: 0.422  loss_rpn_cls: 0.019  loss_rpn_loc: 0.073  time: 1.0413  data_time: 0.0164  lr: 0.002398  max_mem: 5405M
[32m[04/20 08:34:35 d2.utils.events]: [0m eta: 0:08:47  iter: 499  total_loss: 0.606  loss_cls: 0.212  loss_box_reg: 0.322  loss_rpn_cls: 0.021  loss_rpn_loc: 0.051  time: 1.0419  data_time: 0.0177  lr: 0.002498  max_mem: 5405M
[32m[04/20 08:34:56 d2.utils.events]: [0m eta: 0:08:25  iter: 519  total_loss: 0.664  loss_cls: 0.221  loss_box_reg: 0.385  loss_rpn_cls: 0.022  loss_rpn_loc: 0.056  time: 1.0416  data_time: 0.0191  lr: 0.002597  max_mem: 5405M
[32m[04/20 08:35:17 d2.utils.events]: [0m eta: 0:08:03  iter: 539  total_loss: 0.689  loss_cls: 0.227  loss_box_reg: 0.372  loss_rpn_cls: 0.020  loss_rpn_loc: 0.067  time: 1.0407  data_time: 0.0166  lr: 0.002697  max_mem: 5405M
[32m[04/20 08:35:37 d2.utils.events]: [0m eta: 0:07:42  iter: 559  total_loss: 0.636  loss_cls: 0.226  loss_box_reg: 0.340  loss_rpn_cls: 0.017  loss_rpn_loc: 0.040  time: 1.0408  data_time: 0.0150  lr: 0.002797  max_mem: 5405M
[32m[04/20 08:35:58 d2.utils.events]: [0m eta: 0:07:21  iter: 579  total_loss: 0.647  loss_cls: 0.221  loss_box_reg: 0.363  loss_rpn_cls: 0.024  loss_rpn_loc: 0.060  time: 1.0401  data_time: 0.0168  lr: 0.002897  max_mem: 5405M
[32m[04/20 08:36:19 d2.utils.events]: [0m eta: 0:07:00  iter: 599  total_loss: 0.613  loss_cls: 0.188  loss_box_reg: 0.327  loss_rpn_cls: 0.021  loss_rpn_loc: 0.060  time: 1.0396  data_time: 0.0192  lr: 0.002997  max_mem: 5405M
[32m[04/20 08:36:40 d2.utils.events]: [0m eta: 0:06:39  iter: 619  total_loss: 0.658  loss_cls: 0.218  loss_box_reg: 0.361  loss_rpn_cls: 0.021  loss_rpn_loc: 0.075  time: 1.0396  data_time: 0.0145  lr: 0.003097  max_mem: 5405M
[32m[04/20 08:37:01 d2.utils.events]: [0m eta: 0:06:18  iter: 639  total_loss: 0.721  loss_cls: 0.230  loss_box_reg: 0.383  loss_rpn_cls: 0.023  loss_rpn_loc: 0.073  time: 1.0400  data_time: 0.0196  lr: 0.003197  max_mem: 5405M
[32m[04/20 08:37:21 d2.utils.events]: [0m eta: 0:05:57  iter: 659  total_loss: 0.714  loss_cls: 0.244  loss_box_reg: 0.373  loss_rpn_cls: 0.018  loss_rpn_loc: 0.066  time: 1.0393  data_time: 0.0170  lr: 0.003297  max_mem: 5405M
[32m[04/20 08:37:42 d2.utils.events]: [0m eta: 0:05:36  iter: 679  total_loss: 0.684  loss_cls: 0.230  loss_box_reg: 0.357  loss_rpn_cls: 0.025  loss_rpn_loc: 0.064  time: 1.0388  data_time: 0.0148  lr: 0.003397  max_mem: 5405M
[32m[04/20 08:38:02 d2.utils.events]: [0m eta: 0:05:14  iter: 699  total_loss: 0.667  loss_cls: 0.228  loss_box_reg: 0.353  loss_rpn_cls: 0.020  loss_rpn_loc: 0.061  time: 1.0387  data_time: 0.0189  lr: 0.003497  max_mem: 5405M
[32m[04/20 08:38:23 d2.utils.events]: [0m eta: 0:04:54  iter: 719  total_loss: 0.631  loss_cls: 0.230  loss_box_reg: 0.311  loss_rpn_cls: 0.027  loss_rpn_loc: 0.065  time: 1.0390  data_time: 0.0173  lr: 0.003596  max_mem: 5405M
[32m[04/20 08:38:44 d2.utils.events]: [0m eta: 0:04:33  iter: 739  total_loss: 0.743  loss_cls: 0.247  loss_box_reg: 0.392  loss_rpn_cls: 0.021  loss_rpn_loc: 0.084  time: 1.0390  data_time: 0.0171  lr: 0.003696  max_mem: 5405M
[32m[04/20 08:39:05 d2.utils.events]: [0m eta: 0:04:12  iter: 759  total_loss: 0.660  loss_cls: 0.222  loss_box_reg: 0.360  loss_rpn_cls: 0.026  loss_rpn_loc: 0.052  time: 1.0394  data_time: 0.0171  lr: 0.003796  max_mem: 5405M
[32m[04/20 08:39:26 d2.utils.events]: [0m eta: 0:03:50  iter: 779  total_loss: 0.657  loss_cls: 0.220  loss_box_reg: 0.353  loss_rpn_cls: 0.024  loss_rpn_loc: 0.056  time: 1.0389  data_time: 0.0183  lr: 0.003896  max_mem: 5405M
[32m[04/20 08:39:47 d2.utils.events]: [0m eta: 0:03:30  iter: 799  total_loss: 0.687  loss_cls: 0.251  loss_box_reg: 0.380  loss_rpn_cls: 0.022  loss_rpn_loc: 0.080  time: 1.0391  data_time: 0.0175  lr: 0.003996  max_mem: 5405M
[32m[04/20 08:40:08 d2.utils.events]: [0m eta: 0:03:09  iter: 819  total_loss: 0.719  loss_cls: 0.246  loss_box_reg: 0.380  loss_rpn_cls: 0.030  loss_rpn_loc: 0.066  time: 1.0391  data_time: 0.0170  lr: 0.004096  max_mem: 5405M
[32m[04/20 08:40:28 d2.utils.events]: [0m eta: 0:02:48  iter: 839  total_loss: 0.643  loss_cls: 0.210  loss_box_reg: 0.327  loss_rpn_cls: 0.027  loss_rpn_loc: 0.066  time: 1.0387  data_time: 0.0170  lr: 0.004196  max_mem: 5405M
[32m[04/20 08:40:49 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.644  loss_cls: 0.222  loss_box_reg: 0.335  loss_rpn_cls: 0.020  loss_rpn_loc: 0.054  time: 1.0392  data_time: 0.0174  lr: 0.004296  max_mem: 5405M
[32m[04/20 08:41:11 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.694  loss_cls: 0.239  loss_box_reg: 0.366  loss_rpn_cls: 0.019  loss_rpn_loc: 0.067  time: 1.0397  data_time: 0.0174  lr: 0.004396  max_mem: 5405M
[32m[04/20 08:41:32 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.646  loss_cls: 0.216  loss_box_reg: 0.333  loss_rpn_cls: 0.024  loss_rpn_loc: 0.059  time: 1.0396  data_time: 0.0147  lr: 0.004496  max_mem: 5405M
[32m[04/20 08:41:53 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.673  loss_cls: 0.215  loss_box_reg: 0.361  loss_rpn_cls: 0.025  loss_rpn_loc: 0.053  time: 1.0399  data_time: 0.0191  lr: 0.004595  max_mem: 5405M
[32m[04/20 08:42:13 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.770  loss_cls: 0.250  loss_box_reg: 0.427  loss_rpn_cls: 0.029  loss_rpn_loc: 0.073  time: 1.0398  data_time: 0.0186  lr: 0.004695  max_mem: 5405M
[32m[04/20 08:42:34 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.699  loss_cls: 0.240  loss_box_reg: 0.377  loss_rpn_cls: 0.022  loss_rpn_loc: 0.067  time: 1.0401  data_time: 0.0189  lr: 0.004795  max_mem: 5405M
[32m[04/20 08:42:55 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.659  loss_cls: 0.220  loss_box_reg: 0.357  loss_rpn_cls: 0.022  loss_rpn_loc: 0.051  time: 1.0398  data_time: 0.0159  lr: 0.004895  max_mem: 5405M
[5m[31mWARNING[0m [32m[04/20 08:43:19 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 08:43:19 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 08:43:19 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 08:43:19 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.613  loss_cls: 0.216  loss_box_reg: 0.340  loss_rpn_cls: 0.022  loss_rpn_loc: 0.052  time: 1.0395  data_time: 0.0188  lr: 0.004995  max_mem: 5405M
[32m[04/20 08:43:20 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:17 (1.0405 s / it)
[32m[04/20 08:43:20 d2.engine.hooks]: [0mTotal training time: 0:17:24 (0:00:07 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 08:43:25 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 08:43:25 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 08:43:25 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 08:43:27 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1202 s / img. ETA=0:17:04
[32m[04/20 08:43:32 d2.evaluation.evaluator]: [0mInference done 52/8355. 0.1191 s / img. ETA=0:16:53
[32m[04/20 08:43:37 d2.evaluation.evaluator]: [0mInference done 94/8355. 0.1188 s / img. ETA=0:16:45
[32m[04/20 08:43:42 d2.evaluation.evaluator]: [0mInference done 136/8355. 0.1185 s / img. ETA=0:16:37
[32m[04/20 08:43:47 d2.evaluation.evaluator]: [0mInference done 178/8355. 0.1183 s / img. ETA=0:16:31
[32m[04/20 08:43:52 d2.evaluation.evaluator]: [0mInference done 220/8355. 0.1184 s / img. ETA=0:16:26
[32m[04/20 08:43:57 d2.evaluation.evaluator]: [0mInference done 262/8355. 0.1183 s / img. ETA=0:16:21
[32m[04/20 08:44:02 d2.evaluation.evaluator]: [0mInference done 304/8355. 0.1183 s / img. ETA=0:16:15
[32m[04/20 08:44:07 d2.evaluation.evaluator]: [0mInference done 346/8355. 0.1182 s / img. ETA=0:16:09
[32m[04/20 08:44:12 d2.evaluation.evaluator]: [0mInference done 387/8355. 0.1183 s / img. ETA=0:16:05
[32m[04/20 08:44:17 d2.evaluation.evaluator]: [0mInference done 428/8355. 0.1184 s / img. ETA=0:16:01
[32m[04/20 08:44:22 d2.evaluation.evaluator]: [0mInference done 470/8355. 0.1183 s / img. ETA=0:15:55
[32m[04/20 08:44:28 d2.evaluation.evaluator]: [0mInference done 512/8355. 0.1183 s / img. ETA=0:15:51
[32m[04/20 08:44:33 d2.evaluation.evaluator]: [0mInference done 554/8355. 0.1183 s / img. ETA=0:15:45
[32m[04/20 08:44:38 d2.evaluation.evaluator]: [0mInference done 596/8355. 0.1183 s / img. ETA=0:15:40
[32m[04/20 08:44:43 d2.evaluation.evaluator]: [0mInference done 638/8355. 0.1183 s / img. ETA=0:15:35
[32m[04/20 08:44:48 d2.evaluation.evaluator]: [0mInference done 679/8355. 0.1184 s / img. ETA=0:15:31
[32m[04/20 08:44:53 d2.evaluation.evaluator]: [0mInference done 720/8355. 0.1184 s / img. ETA=0:15:26
[32m[04/20 08:44:58 d2.evaluation.evaluator]: [0mInference done 762/8355. 0.1184 s / img. ETA=0:15:21
[32m[04/20 08:45:03 d2.evaluation.evaluator]: [0mInference done 803/8355. 0.1185 s / img. ETA=0:15:17
[32m[04/20 08:45:08 d2.evaluation.evaluator]: [0mInference done 845/8355. 0.1185 s / img. ETA=0:15:11
[32m[04/20 08:45:13 d2.evaluation.evaluator]: [0mInference done 886/8355. 0.1185 s / img. ETA=0:15:07
[32m[04/20 08:45:18 d2.evaluation.evaluator]: [0mInference done 928/8355. 0.1185 s / img. ETA=0:15:02
[32m[04/20 08:45:23 d2.evaluation.evaluator]: [0mInference done 970/8355. 0.1185 s / img. ETA=0:14:57
[32m[04/20 08:45:28 d2.evaluation.evaluator]: [0mInference done 1011/8355. 0.1185 s / img. ETA=0:14:52
[32m[04/20 08:45:33 d2.evaluation.evaluator]: [0mInference done 1053/8355. 0.1185 s / img. ETA=0:14:46
[32m[04/20 08:45:38 d2.evaluation.evaluator]: [0mInference done 1095/8355. 0.1185 s / img. ETA=0:14:41
[32m[04/20 08:45:44 d2.evaluation.evaluator]: [0mInference done 1137/8355. 0.1185 s / img. ETA=0:14:36
[32m[04/20 08:45:49 d2.evaluation.evaluator]: [0mInference done 1179/8355. 0.1185 s / img. ETA=0:14:31
[32m[04/20 08:45:54 d2.evaluation.evaluator]: [0mInference done 1221/8355. 0.1185 s / img. ETA=0:14:26
[32m[04/20 08:45:59 d2.evaluation.evaluator]: [0mInference done 1263/8355. 0.1185 s / img. ETA=0:14:21
[32m[04/20 08:46:04 d2.evaluation.evaluator]: [0mInference done 1305/8355. 0.1184 s / img. ETA=0:14:15
[32m[04/20 08:46:09 d2.evaluation.evaluator]: [0mInference done 1347/8355. 0.1185 s / img. ETA=0:14:10
[32m[04/20 08:46:14 d2.evaluation.evaluator]: [0mInference done 1389/8355. 0.1184 s / img. ETA=0:14:05
[32m[04/20 08:46:19 d2.evaluation.evaluator]: [0mInference done 1431/8355. 0.1184 s / img. ETA=0:14:00
[32m[04/20 08:46:24 d2.evaluation.evaluator]: [0mInference done 1473/8355. 0.1184 s / img. ETA=0:13:54
[32m[04/20 08:46:29 d2.evaluation.evaluator]: [0mInference done 1514/8355. 0.1184 s / img. ETA=0:13:50
[32m[04/20 08:46:34 d2.evaluation.evaluator]: [0mInference done 1555/8355. 0.1185 s / img. ETA=0:13:45
[32m[04/20 08:46:39 d2.evaluation.evaluator]: [0mInference done 1596/8355. 0.1185 s / img. ETA=0:13:40
[32m[04/20 08:46:44 d2.evaluation.evaluator]: [0mInference done 1637/8355. 0.1185 s / img. ETA=0:13:36
[32m[04/20 08:46:49 d2.evaluation.evaluator]: [0mInference done 1678/8355. 0.1186 s / img. ETA=0:13:31
[32m[04/20 08:46:54 d2.evaluation.evaluator]: [0mInference done 1719/8355. 0.1186 s / img. ETA=0:13:26
[32m[04/20 08:46:59 d2.evaluation.evaluator]: [0mInference done 1760/8355. 0.1186 s / img. ETA=0:13:21
[32m[04/20 08:47:05 d2.evaluation.evaluator]: [0mInference done 1801/8355. 0.1187 s / img. ETA=0:13:17
[32m[04/20 08:47:10 d2.evaluation.evaluator]: [0mInference done 1843/8355. 0.1187 s / img. ETA=0:13:11
[32m[04/20 08:47:15 d2.evaluation.evaluator]: [0mInference done 1884/8355. 0.1187 s / img. ETA=0:13:07
[32m[04/20 08:47:20 d2.evaluation.evaluator]: [0mInference done 1926/8355. 0.1187 s / img. ETA=0:13:02
[32m[04/20 08:47:25 d2.evaluation.evaluator]: [0mInference done 1967/8355. 0.1187 s / img. ETA=0:12:57
[32m[04/20 08:47:30 d2.evaluation.evaluator]: [0mInference done 2009/8355. 0.1187 s / img. ETA=0:12:52
[32m[04/20 08:47:35 d2.evaluation.evaluator]: [0mInference done 2051/8355. 0.1187 s / img. ETA=0:12:47
[32m[04/20 08:47:40 d2.evaluation.evaluator]: [0mInference done 2093/8355. 0.1187 s / img. ETA=0:12:42
[32m[04/20 08:47:45 d2.evaluation.evaluator]: [0mInference done 2135/8355. 0.1187 s / img. ETA=0:12:36
[32m[04/20 08:47:50 d2.evaluation.evaluator]: [0mInference done 2176/8355. 0.1187 s / img. ETA=0:12:31
[32m[04/20 08:47:55 d2.evaluation.evaluator]: [0mInference done 2218/8355. 0.1187 s / img. ETA=0:12:26
[32m[04/20 08:48:00 d2.evaluation.evaluator]: [0mInference done 2260/8355. 0.1187 s / img. ETA=0:12:21
[32m[04/20 08:48:06 d2.evaluation.evaluator]: [0mInference done 2301/8355. 0.1187 s / img. ETA=0:12:16
[32m[04/20 08:48:11 d2.evaluation.evaluator]: [0mInference done 2342/8355. 0.1187 s / img. ETA=0:12:11
[32m[04/20 08:48:16 d2.evaluation.evaluator]: [0mInference done 2384/8355. 0.1187 s / img. ETA=0:12:06
[32m[04/20 08:48:21 d2.evaluation.evaluator]: [0mInference done 2425/8355. 0.1187 s / img. ETA=0:12:01
[32m[04/20 08:48:26 d2.evaluation.evaluator]: [0mInference done 2466/8355. 0.1187 s / img. ETA=0:11:56
[32m[04/20 08:48:31 d2.evaluation.evaluator]: [0mInference done 2508/8355. 0.1187 s / img. ETA=0:11:51
[32m[04/20 08:48:36 d2.evaluation.evaluator]: [0mInference done 2549/8355. 0.1188 s / img. ETA=0:11:46
[32m[04/20 08:48:41 d2.evaluation.evaluator]: [0mInference done 2590/8355. 0.1188 s / img. ETA=0:11:41
[32m[04/20 08:48:46 d2.evaluation.evaluator]: [0mInference done 2631/8355. 0.1188 s / img. ETA=0:11:36
[32m[04/20 08:48:51 d2.evaluation.evaluator]: [0mInference done 2672/8355. 0.1188 s / img. ETA=0:11:31
[32m[04/20 08:48:56 d2.evaluation.evaluator]: [0mInference done 2713/8355. 0.1188 s / img. ETA=0:11:27
[32m[04/20 08:49:01 d2.evaluation.evaluator]: [0mInference done 2755/8355. 0.1188 s / img. ETA=0:11:21
[32m[04/20 08:49:06 d2.evaluation.evaluator]: [0mInference done 2797/8355. 0.1188 s / img. ETA=0:11:16
[32m[04/20 08:49:11 d2.evaluation.evaluator]: [0mInference done 2838/8355. 0.1188 s / img. ETA=0:11:11
[32m[04/20 08:49:16 d2.evaluation.evaluator]: [0mInference done 2879/8355. 0.1188 s / img. ETA=0:11:06
[32m[04/20 08:49:21 d2.evaluation.evaluator]: [0mInference done 2920/8355. 0.1188 s / img. ETA=0:11:01
[32m[04/20 08:49:26 d2.evaluation.evaluator]: [0mInference done 2961/8355. 0.1188 s / img. ETA=0:10:57
[32m[04/20 08:49:31 d2.evaluation.evaluator]: [0mInference done 3002/8355. 0.1189 s / img. ETA=0:10:52
[32m[04/20 08:49:36 d2.evaluation.evaluator]: [0mInference done 3043/8355. 0.1189 s / img. ETA=0:10:47
[32m[04/20 08:49:41 d2.evaluation.evaluator]: [0mInference done 3084/8355. 0.1189 s / img. ETA=0:10:42
[32m[04/20 08:49:46 d2.evaluation.evaluator]: [0mInference done 3125/8355. 0.1189 s / img. ETA=0:10:37
[32m[04/20 08:49:51 d2.evaluation.evaluator]: [0mInference done 3166/8355. 0.1189 s / img. ETA=0:10:32
[32m[04/20 08:49:56 d2.evaluation.evaluator]: [0mInference done 3208/8355. 0.1189 s / img. ETA=0:10:27
[32m[04/20 08:50:02 d2.evaluation.evaluator]: [0mInference done 3250/8355. 0.1189 s / img. ETA=0:10:22
[32m[04/20 08:50:07 d2.evaluation.evaluator]: [0mInference done 3291/8355. 0.1189 s / img. ETA=0:10:17
[32m[04/20 08:50:12 d2.evaluation.evaluator]: [0mInference done 3332/8355. 0.1189 s / img. ETA=0:10:12
[32m[04/20 08:50:17 d2.evaluation.evaluator]: [0mInference done 3373/8355. 0.1189 s / img. ETA=0:10:07
[32m[04/20 08:50:22 d2.evaluation.evaluator]: [0mInference done 3414/8355. 0.1189 s / img. ETA=0:10:02
[32m[04/20 08:50:27 d2.evaluation.evaluator]: [0mInference done 3455/8355. 0.1189 s / img. ETA=0:09:57
[32m[04/20 08:50:32 d2.evaluation.evaluator]: [0mInference done 3496/8355. 0.1189 s / img. ETA=0:09:52
[32m[04/20 08:50:37 d2.evaluation.evaluator]: [0mInference done 3537/8355. 0.1189 s / img. ETA=0:09:47
[32m[04/20 08:50:42 d2.evaluation.evaluator]: [0mInference done 3579/8355. 0.1189 s / img. ETA=0:09:42
[32m[04/20 08:50:47 d2.evaluation.evaluator]: [0mInference done 3620/8355. 0.1189 s / img. ETA=0:09:37
[32m[04/20 08:50:52 d2.evaluation.evaluator]: [0mInference done 3662/8355. 0.1189 s / img. ETA=0:09:32
[32m[04/20 08:50:57 d2.evaluation.evaluator]: [0mInference done 3704/8355. 0.1189 s / img. ETA=0:09:26
[32m[04/20 08:51:02 d2.evaluation.evaluator]: [0mInference done 3746/8355. 0.1189 s / img. ETA=0:09:21
[32m[04/20 08:51:07 d2.evaluation.evaluator]: [0mInference done 3788/8355. 0.1189 s / img. ETA=0:09:16
[32m[04/20 08:51:12 d2.evaluation.evaluator]: [0mInference done 3829/8355. 0.1189 s / img. ETA=0:09:11
[32m[04/20 08:51:17 d2.evaluation.evaluator]: [0mInference done 3870/8355. 0.1189 s / img. ETA=0:09:06
[32m[04/20 08:51:22 d2.evaluation.evaluator]: [0mInference done 3912/8355. 0.1189 s / img. ETA=0:09:01
[32m[04/20 08:51:27 d2.evaluation.evaluator]: [0mInference done 3953/8355. 0.1189 s / img. ETA=0:08:56
[32m[04/20 08:51:32 d2.evaluation.evaluator]: [0mInference done 3994/8355. 0.1189 s / img. ETA=0:08:51
[32m[04/20 08:51:37 d2.evaluation.evaluator]: [0mInference done 4035/8355. 0.1189 s / img. ETA=0:08:46
[32m[04/20 08:51:42 d2.evaluation.evaluator]: [0mInference done 4076/8355. 0.1189 s / img. ETA=0:08:41
[32m[04/20 08:51:48 d2.evaluation.evaluator]: [0mInference done 4117/8355. 0.1189 s / img. ETA=0:08:36
[32m[04/20 08:51:53 d2.evaluation.evaluator]: [0mInference done 4158/8355. 0.1189 s / img. ETA=0:08:31
[32m[04/20 08:51:58 d2.evaluation.evaluator]: [0mInference done 4199/8355. 0.1189 s / img. ETA=0:08:26
[32m[04/20 08:52:03 d2.evaluation.evaluator]: [0mInference done 4240/8355. 0.1189 s / img. ETA=0:08:21
[32m[04/20 08:52:08 d2.evaluation.evaluator]: [0mInference done 4282/8355. 0.1189 s / img. ETA=0:08:16
[32m[04/20 08:52:13 d2.evaluation.evaluator]: [0mInference done 4324/8355. 0.1189 s / img. ETA=0:08:11
[32m[04/20 08:52:18 d2.evaluation.evaluator]: [0mInference done 4365/8355. 0.1189 s / img. ETA=0:08:06
[32m[04/20 08:52:23 d2.evaluation.evaluator]: [0mInference done 4406/8355. 0.1189 s / img. ETA=0:08:01
[32m[04/20 08:52:28 d2.evaluation.evaluator]: [0mInference done 4447/8355. 0.1189 s / img. ETA=0:07:56
[32m[04/20 08:52:33 d2.evaluation.evaluator]: [0mInference done 4488/8355. 0.1190 s / img. ETA=0:07:51
[32m[04/20 08:52:38 d2.evaluation.evaluator]: [0mInference done 4529/8355. 0.1190 s / img. ETA=0:07:46
[32m[04/20 08:52:43 d2.evaluation.evaluator]: [0mInference done 4570/8355. 0.1190 s / img. ETA=0:07:41
[32m[04/20 08:52:48 d2.evaluation.evaluator]: [0mInference done 4611/8355. 0.1190 s / img. ETA=0:07:36
[32m[04/20 08:52:53 d2.evaluation.evaluator]: [0mInference done 4652/8355. 0.1190 s / img. ETA=0:07:31
[32m[04/20 08:52:58 d2.evaluation.evaluator]: [0mInference done 4693/8355. 0.1190 s / img. ETA=0:07:26
[32m[04/20 08:53:03 d2.evaluation.evaluator]: [0mInference done 4734/8355. 0.1190 s / img. ETA=0:07:21
[32m[04/20 08:53:08 d2.evaluation.evaluator]: [0mInference done 4775/8355. 0.1190 s / img. ETA=0:07:16
[32m[04/20 08:53:13 d2.evaluation.evaluator]: [0mInference done 4816/8355. 0.1190 s / img. ETA=0:07:11
[32m[04/20 08:53:18 d2.evaluation.evaluator]: [0mInference done 4857/8355. 0.1190 s / img. ETA=0:07:06
[32m[04/20 08:53:23 d2.evaluation.evaluator]: [0mInference done 4898/8355. 0.1190 s / img. ETA=0:07:01
[32m[04/20 08:53:28 d2.evaluation.evaluator]: [0mInference done 4940/8355. 0.1190 s / img. ETA=0:06:56
[32m[04/20 08:53:33 d2.evaluation.evaluator]: [0mInference done 4982/8355. 0.1190 s / img. ETA=0:06:51
[32m[04/20 08:53:38 d2.evaluation.evaluator]: [0mInference done 5024/8355. 0.1190 s / img. ETA=0:06:46
[32m[04/20 08:53:43 d2.evaluation.evaluator]: [0mInference done 5065/8355. 0.1190 s / img. ETA=0:06:41
[32m[04/20 08:53:49 d2.evaluation.evaluator]: [0mInference done 5106/8355. 0.1190 s / img. ETA=0:06:36
[32m[04/20 08:53:54 d2.evaluation.evaluator]: [0mInference done 5147/8355. 0.1190 s / img. ETA=0:06:31
[32m[04/20 08:53:59 d2.evaluation.evaluator]: [0mInference done 5188/8355. 0.1190 s / img. ETA=0:06:26
[32m[04/20 08:54:04 d2.evaluation.evaluator]: [0mInference done 5229/8355. 0.1190 s / img. ETA=0:06:21
[32m[04/20 08:54:09 d2.evaluation.evaluator]: [0mInference done 5270/8355. 0.1190 s / img. ETA=0:06:16
[32m[04/20 08:54:14 d2.evaluation.evaluator]: [0mInference done 5311/8355. 0.1190 s / img. ETA=0:06:11
[32m[04/20 08:54:19 d2.evaluation.evaluator]: [0mInference done 5352/8355. 0.1190 s / img. ETA=0:06:06
[32m[04/20 08:54:24 d2.evaluation.evaluator]: [0mInference done 5393/8355. 0.1191 s / img. ETA=0:06:01
[32m[04/20 08:54:29 d2.evaluation.evaluator]: [0mInference done 5434/8355. 0.1191 s / img. ETA=0:05:56
[32m[04/20 08:54:34 d2.evaluation.evaluator]: [0mInference done 5475/8355. 0.1191 s / img. ETA=0:05:51
[32m[04/20 08:54:39 d2.evaluation.evaluator]: [0mInference done 5516/8355. 0.1191 s / img. ETA=0:05:46
[32m[04/20 08:54:44 d2.evaluation.evaluator]: [0mInference done 5557/8355. 0.1191 s / img. ETA=0:05:41
[32m[04/20 08:54:49 d2.evaluation.evaluator]: [0mInference done 5598/8355. 0.1191 s / img. ETA=0:05:36
[32m[04/20 08:54:54 d2.evaluation.evaluator]: [0mInference done 5639/8355. 0.1191 s / img. ETA=0:05:31
[32m[04/20 08:54:59 d2.evaluation.evaluator]: [0mInference done 5680/8355. 0.1191 s / img. ETA=0:05:26
[32m[04/20 08:55:04 d2.evaluation.evaluator]: [0mInference done 5722/8355. 0.1191 s / img. ETA=0:05:21
[32m[04/20 08:55:09 d2.evaluation.evaluator]: [0mInference done 5763/8355. 0.1191 s / img. ETA=0:05:16
[32m[04/20 08:55:14 d2.evaluation.evaluator]: [0mInference done 5804/8355. 0.1191 s / img. ETA=0:05:11
[32m[04/20 08:55:20 d2.evaluation.evaluator]: [0mInference done 5845/8355. 0.1191 s / img. ETA=0:05:06
[32m[04/20 08:55:25 d2.evaluation.evaluator]: [0mInference done 5886/8355. 0.1191 s / img. ETA=0:05:01
[32m[04/20 08:55:30 d2.evaluation.evaluator]: [0mInference done 5927/8355. 0.1191 s / img. ETA=0:04:56
[32m[04/20 08:55:35 d2.evaluation.evaluator]: [0mInference done 5968/8355. 0.1191 s / img. ETA=0:04:51
[32m[04/20 08:55:40 d2.evaluation.evaluator]: [0mInference done 6009/8355. 0.1191 s / img. ETA=0:04:46
[32m[04/20 08:55:45 d2.evaluation.evaluator]: [0mInference done 6051/8355. 0.1191 s / img. ETA=0:04:41
[32m[04/20 08:55:50 d2.evaluation.evaluator]: [0mInference done 6092/8355. 0.1191 s / img. ETA=0:04:36
[32m[04/20 08:55:55 d2.evaluation.evaluator]: [0mInference done 6133/8355. 0.1191 s / img. ETA=0:04:31
[32m[04/20 08:56:00 d2.evaluation.evaluator]: [0mInference done 6174/8355. 0.1191 s / img. ETA=0:04:26
[32m[04/20 08:56:05 d2.evaluation.evaluator]: [0mInference done 6215/8355. 0.1191 s / img. ETA=0:04:21
[32m[04/20 08:56:10 d2.evaluation.evaluator]: [0mInference done 6256/8355. 0.1191 s / img. ETA=0:04:16
[32m[04/20 08:56:15 d2.evaluation.evaluator]: [0mInference done 6297/8355. 0.1191 s / img. ETA=0:04:11
[32m[04/20 08:56:20 d2.evaluation.evaluator]: [0mInference done 6338/8355. 0.1192 s / img. ETA=0:04:06
[32m[04/20 08:56:25 d2.evaluation.evaluator]: [0mInference done 6380/8355. 0.1192 s / img. ETA=0:04:01
[32m[04/20 08:56:30 d2.evaluation.evaluator]: [0mInference done 6421/8355. 0.1192 s / img. ETA=0:03:56
[32m[04/20 08:56:35 d2.evaluation.evaluator]: [0mInference done 6462/8355. 0.1192 s / img. ETA=0:03:51
[32m[04/20 08:56:40 d2.evaluation.evaluator]: [0mInference done 6504/8355. 0.1191 s / img. ETA=0:03:46
[32m[04/20 08:56:45 d2.evaluation.evaluator]: [0mInference done 6546/8355. 0.1191 s / img. ETA=0:03:41
[32m[04/20 08:56:50 d2.evaluation.evaluator]: [0mInference done 6587/8355. 0.1191 s / img. ETA=0:03:35
[32m[04/20 08:56:55 d2.evaluation.evaluator]: [0mInference done 6628/8355. 0.1191 s / img. ETA=0:03:30
[32m[04/20 08:57:00 d2.evaluation.evaluator]: [0mInference done 6669/8355. 0.1191 s / img. ETA=0:03:25
[32m[04/20 08:57:05 d2.evaluation.evaluator]: [0mInference done 6711/8355. 0.1191 s / img. ETA=0:03:20
[32m[04/20 08:57:10 d2.evaluation.evaluator]: [0mInference done 6753/8355. 0.1191 s / img. ETA=0:03:15
[32m[04/20 08:57:16 d2.evaluation.evaluator]: [0mInference done 6795/8355. 0.1191 s / img. ETA=0:03:10
[32m[04/20 08:57:21 d2.evaluation.evaluator]: [0mInference done 6837/8355. 0.1191 s / img. ETA=0:03:05
[32m[04/20 08:57:26 d2.evaluation.evaluator]: [0mInference done 6878/8355. 0.1191 s / img. ETA=0:03:00
[32m[04/20 08:57:31 d2.evaluation.evaluator]: [0mInference done 6919/8355. 0.1191 s / img. ETA=0:02:55
[32m[04/20 08:57:36 d2.evaluation.evaluator]: [0mInference done 6960/8355. 0.1191 s / img. ETA=0:02:50
[32m[04/20 08:57:41 d2.evaluation.evaluator]: [0mInference done 7001/8355. 0.1191 s / img. ETA=0:02:45
[32m[04/20 08:57:46 d2.evaluation.evaluator]: [0mInference done 7042/8355. 0.1191 s / img. ETA=0:02:40
[32m[04/20 08:57:51 d2.evaluation.evaluator]: [0mInference done 7083/8355. 0.1191 s / img. ETA=0:02:35
[32m[04/20 08:57:56 d2.evaluation.evaluator]: [0mInference done 7124/8355. 0.1192 s / img. ETA=0:02:30
[32m[04/20 08:58:01 d2.evaluation.evaluator]: [0mInference done 7165/8355. 0.1192 s / img. ETA=0:02:25
[32m[04/20 08:58:06 d2.evaluation.evaluator]: [0mInference done 7206/8355. 0.1192 s / img. ETA=0:02:20
[32m[04/20 08:58:11 d2.evaluation.evaluator]: [0mInference done 7244/8355. 0.1192 s / img. ETA=0:02:15
[32m[04/20 08:58:16 d2.evaluation.evaluator]: [0mInference done 7285/8355. 0.1192 s / img. ETA=0:02:10
[32m[04/20 08:58:21 d2.evaluation.evaluator]: [0mInference done 7326/8355. 0.1192 s / img. ETA=0:02:05
[32m[04/20 08:58:26 d2.evaluation.evaluator]: [0mInference done 7367/8355. 0.1193 s / img. ETA=0:02:00
[32m[04/20 08:58:31 d2.evaluation.evaluator]: [0mInference done 7408/8355. 0.1193 s / img. ETA=0:01:55
[32m[04/20 08:58:37 d2.evaluation.evaluator]: [0mInference done 7449/8355. 0.1193 s / img. ETA=0:01:50
[32m[04/20 08:58:42 d2.evaluation.evaluator]: [0mInference done 7490/8355. 0.1193 s / img. ETA=0:01:45
[32m[04/20 08:58:47 d2.evaluation.evaluator]: [0mInference done 7531/8355. 0.1193 s / img. ETA=0:01:40
[32m[04/20 08:58:52 d2.evaluation.evaluator]: [0mInference done 7572/8355. 0.1193 s / img. ETA=0:01:35
[32m[04/20 08:58:57 d2.evaluation.evaluator]: [0mInference done 7613/8355. 0.1193 s / img. ETA=0:01:30
[32m[04/20 08:59:02 d2.evaluation.evaluator]: [0mInference done 7654/8355. 0.1193 s / img. ETA=0:01:25
[32m[04/20 08:59:07 d2.evaluation.evaluator]: [0mInference done 7695/8355. 0.1193 s / img. ETA=0:01:20
[32m[04/20 08:59:12 d2.evaluation.evaluator]: [0mInference done 7736/8355. 0.1193 s / img. ETA=0:01:15
[32m[04/20 08:59:17 d2.evaluation.evaluator]: [0mInference done 7777/8355. 0.1193 s / img. ETA=0:01:10
[32m[04/20 08:59:22 d2.evaluation.evaluator]: [0mInference done 7818/8355. 0.1193 s / img. ETA=0:01:05
[32m[04/20 08:59:27 d2.evaluation.evaluator]: [0mInference done 7859/8355. 0.1193 s / img. ETA=0:01:00
[32m[04/20 08:59:32 d2.evaluation.evaluator]: [0mInference done 7900/8355. 0.1193 s / img. ETA=0:00:55
[32m[04/20 08:59:37 d2.evaluation.evaluator]: [0mInference done 7941/8355. 0.1193 s / img. ETA=0:00:50
[32m[04/20 08:59:42 d2.evaluation.evaluator]: [0mInference done 7982/8355. 0.1193 s / img. ETA=0:00:45
[32m[04/20 08:59:47 d2.evaluation.evaluator]: [0mInference done 8023/8355. 0.1193 s / img. ETA=0:00:40
[32m[04/20 08:59:52 d2.evaluation.evaluator]: [0mInference done 8065/8355. 0.1193 s / img. ETA=0:00:35
[32m[04/20 08:59:58 d2.evaluation.evaluator]: [0mInference done 8107/8355. 0.1193 s / img. ETA=0:00:30
[32m[04/20 09:00:03 d2.evaluation.evaluator]: [0mInference done 8149/8355. 0.1193 s / img. ETA=0:00:25
[32m[04/20 09:00:08 d2.evaluation.evaluator]: [0mInference done 8191/8355. 0.1193 s / img. ETA=0:00:20
[32m[04/20 09:00:13 d2.evaluation.evaluator]: [0mInference done 8233/8355. 0.1193 s / img. ETA=0:00:14
[32m[04/20 09:00:18 d2.evaluation.evaluator]: [0mInference done 8275/8355. 0.1193 s / img. ETA=0:00:09
[32m[04/20 09:00:23 d2.evaluation.evaluator]: [0mInference done 8316/8355. 0.1193 s / img. ETA=0:00:04
[32m[04/20 09:00:28 d2.evaluation.evaluator]: [0mTotal inference time: 0:17:01.659880 (0.122354 s / img per device, on 1 devices)
[32m[04/20 09:00:28 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:36 (0.119298 s / img per device, on 1 devices)
[32m[04/20 09:00:28 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 09:00:28 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 09:00:29 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.13s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=28.46s).
Accumulating evaluation results...
DONE (t=3.26s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.561
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.258
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.397
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.549
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.114
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.331
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.255
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.454
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.608
[32m[04/20 09:01:01 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 28.693 | 56.120 | 25.826 | 19.456 | 39.688 | 54.880 |
[32m[04/20 09:01:01 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 34.037 | bicycle       | 11.753 | car            | 40.289 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 09:01:02 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 09:01:02 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 09:01:02 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 09:01:04 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1205 s / img. ETA=0:02:33
[32m[04/20 09:01:09 d2.evaluation.evaluator]: [0mInference done 52/1257. 0.1193 s / img. ETA=0:02:27
[32m[04/20 09:01:14 d2.evaluation.evaluator]: [0mInference done 94/1257. 0.1190 s / img. ETA=0:02:22
[32m[04/20 09:01:19 d2.evaluation.evaluator]: [0mInference done 135/1257. 0.1191 s / img. ETA=0:02:17
[32m[04/20 09:01:24 d2.evaluation.evaluator]: [0mInference done 176/1257. 0.1191 s / img. ETA=0:02:12
[32m[04/20 09:01:29 d2.evaluation.evaluator]: [0mInference done 217/1257. 0.1191 s / img. ETA=0:02:07
[32m[04/20 09:01:34 d2.evaluation.evaluator]: [0mInference done 258/1257. 0.1191 s / img. ETA=0:02:02
[32m[04/20 09:01:39 d2.evaluation.evaluator]: [0mInference done 299/1257. 0.1191 s / img. ETA=0:01:57
[32m[04/20 09:01:44 d2.evaluation.evaluator]: [0mInference done 341/1257. 0.1190 s / img. ETA=0:01:52
[32m[04/20 09:01:49 d2.evaluation.evaluator]: [0mInference done 382/1257. 0.1190 s / img. ETA=0:01:47
[32m[04/20 09:01:54 d2.evaluation.evaluator]: [0mInference done 423/1257. 0.1192 s / img. ETA=0:01:42
[32m[04/20 09:01:59 d2.evaluation.evaluator]: [0mInference done 464/1257. 0.1193 s / img. ETA=0:01:37
[32m[04/20 09:02:04 d2.evaluation.evaluator]: [0mInference done 505/1257. 0.1193 s / img. ETA=0:01:32
[32m[04/20 09:02:09 d2.evaluation.evaluator]: [0mInference done 546/1257. 0.1194 s / img. ETA=0:01:27
[32m[04/20 09:02:15 d2.evaluation.evaluator]: [0mInference done 587/1257. 0.1194 s / img. ETA=0:01:22
[32m[04/20 09:02:20 d2.evaluation.evaluator]: [0mInference done 628/1257. 0.1195 s / img. ETA=0:01:17
[32m[04/20 09:02:25 d2.evaluation.evaluator]: [0mInference done 669/1257. 0.1195 s / img. ETA=0:01:12
[32m[04/20 09:02:30 d2.evaluation.evaluator]: [0mInference done 710/1257. 0.1195 s / img. ETA=0:01:07
[32m[04/20 09:02:35 d2.evaluation.evaluator]: [0mInference done 751/1257. 0.1195 s / img. ETA=0:01:02
[32m[04/20 09:02:40 d2.evaluation.evaluator]: [0mInference done 793/1257. 0.1195 s / img. ETA=0:00:57
[32m[04/20 09:02:45 d2.evaluation.evaluator]: [0mInference done 834/1257. 0.1195 s / img. ETA=0:00:51
[32m[04/20 09:02:50 d2.evaluation.evaluator]: [0mInference done 876/1257. 0.1194 s / img. ETA=0:00:46
[32m[04/20 09:02:55 d2.evaluation.evaluator]: [0mInference done 917/1257. 0.1194 s / img. ETA=0:00:41
[32m[04/20 09:03:00 d2.evaluation.evaluator]: [0mInference done 958/1257. 0.1194 s / img. ETA=0:00:36
[32m[04/20 09:03:05 d2.evaluation.evaluator]: [0mInference done 999/1257. 0.1194 s / img. ETA=0:00:31
[32m[04/20 09:03:10 d2.evaluation.evaluator]: [0mInference done 1040/1257. 0.1194 s / img. ETA=0:00:26
[32m[04/20 09:03:15 d2.evaluation.evaluator]: [0mInference done 1081/1257. 0.1194 s / img. ETA=0:00:21
[32m[04/20 09:03:20 d2.evaluation.evaluator]: [0mInference done 1122/1257. 0.1194 s / img. ETA=0:00:16
[32m[04/20 09:03:25 d2.evaluation.evaluator]: [0mInference done 1163/1257. 0.1194 s / img. ETA=0:00:11
[32m[04/20 09:03:30 d2.evaluation.evaluator]: [0mInference done 1204/1257. 0.1193 s / img. ETA=0:00:06
[32m[04/20 09:03:35 d2.evaluation.evaluator]: [0mInference done 1245/1257. 0.1193 s / img. ETA=0:00:01
[32m[04/20 09:03:37 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:33.694731 (0.122759 s / img per device, on 1 devices)
[32m[04/20 09:03:37 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:29 (0.119322 s / img per device, on 1 devices)
[32m[04/20 09:03:37 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 09:03:37 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 09:03:37 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=4.23s).
Accumulating evaluation results...
DONE (t=0.53s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.239
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.468
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.216
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.156
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.285
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.402
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.106
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.291
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.441
[32m[04/20 09:03:42 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 23.942 | 46.822 | 21.618 | 15.581 | 28.500 | 40.184 |
[32m[04/20 09:03:42 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 26.682 | bicycle       | 4.829 | car            | 40.315 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | nan   | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  6  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 09:03:43 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 09:03:43 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 09:03:43 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 09:03:44 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 09:03:44 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 09:03:44 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 09:03:44 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 09:04:05 d2.utils.events]: [0m eta: 0:17:25  iter: 19  total_loss: 0.739  loss_cls: 0.259  loss_box_reg: 0.370  loss_rpn_cls: 0.026  loss_rpn_loc: 0.062  time: 1.0574  data_time: 0.0410  lr: 0.000100  max_mem: 5405M
[32m[04/20 09:04:26 d2.utils.events]: [0m eta: 0:16:59  iter: 39  total_loss: 0.617  loss_cls: 0.232  loss_box_reg: 0.308  loss_rpn_cls: 0.022  loss_rpn_loc: 0.047  time: 1.0404  data_time: 0.0165  lr: 0.000200  max_mem: 5405M
[32m[04/20 09:04:47 d2.utils.events]: [0m eta: 0:16:29  iter: 59  total_loss: 0.739  loss_cls: 0.236  loss_box_reg: 0.397  loss_rpn_cls: 0.017  loss_rpn_loc: 0.073  time: 1.0384  data_time: 0.0187  lr: 0.000300  max_mem: 5405M
[32m[04/20 09:05:08 d2.utils.events]: [0m eta: 0:16:04  iter: 79  total_loss: 0.664  loss_cls: 0.238  loss_box_reg: 0.355  loss_rpn_cls: 0.020  loss_rpn_loc: 0.054  time: 1.0379  data_time: 0.0166  lr: 0.000400  max_mem: 5405M
[32m[04/20 09:05:28 d2.utils.events]: [0m eta: 0:15:40  iter: 99  total_loss: 0.654  loss_cls: 0.212  loss_box_reg: 0.358  loss_rpn_cls: 0.020  loss_rpn_loc: 0.055  time: 1.0379  data_time: 0.0162  lr: 0.000500  max_mem: 5405M
[32m[04/20 09:05:49 d2.utils.events]: [0m eta: 0:15:18  iter: 119  total_loss: 0.700  loss_cls: 0.231  loss_box_reg: 0.388  loss_rpn_cls: 0.025  loss_rpn_loc: 0.076  time: 1.0368  data_time: 0.0153  lr: 0.000599  max_mem: 5405M
[32m[04/20 09:06:10 d2.utils.events]: [0m eta: 0:15:05  iter: 139  total_loss: 0.569  loss_cls: 0.196  loss_box_reg: 0.296  loss_rpn_cls: 0.022  loss_rpn_loc: 0.054  time: 1.0409  data_time: 0.0170  lr: 0.000699  max_mem: 5405M
[32m[04/20 09:06:31 d2.utils.events]: [0m eta: 0:14:42  iter: 159  total_loss: 0.646  loss_cls: 0.198  loss_box_reg: 0.368  loss_rpn_cls: 0.022  loss_rpn_loc: 0.054  time: 1.0406  data_time: 0.0159  lr: 0.000799  max_mem: 5405M
[32m[04/20 09:06:52 d2.utils.events]: [0m eta: 0:14:25  iter: 179  total_loss: 0.673  loss_cls: 0.213  loss_box_reg: 0.377  loss_rpn_cls: 0.020  loss_rpn_loc: 0.063  time: 1.0425  data_time: 0.0186  lr: 0.000899  max_mem: 5405M
[32m[04/20 09:07:13 d2.utils.events]: [0m eta: 0:14:02  iter: 199  total_loss: 0.650  loss_cls: 0.216  loss_box_reg: 0.348  loss_rpn_cls: 0.028  loss_rpn_loc: 0.064  time: 1.0411  data_time: 0.0186  lr: 0.000999  max_mem: 5405M
[32m[04/20 09:07:34 d2.utils.events]: [0m eta: 0:13:46  iter: 219  total_loss: 0.624  loss_cls: 0.213  loss_box_reg: 0.336  loss_rpn_cls: 0.021  loss_rpn_loc: 0.051  time: 1.0420  data_time: 0.0206  lr: 0.001099  max_mem: 5405M
[32m[04/20 09:07:55 d2.utils.events]: [0m eta: 0:13:26  iter: 239  total_loss: 0.625  loss_cls: 0.200  loss_box_reg: 0.358  loss_rpn_cls: 0.015  loss_rpn_loc: 0.052  time: 1.0432  data_time: 0.0158  lr: 0.001199  max_mem: 5405M
[32m[04/20 09:08:16 d2.utils.events]: [0m eta: 0:13:05  iter: 259  total_loss: 0.679  loss_cls: 0.224  loss_box_reg: 0.367  loss_rpn_cls: 0.020  loss_rpn_loc: 0.055  time: 1.0438  data_time: 0.0168  lr: 0.001299  max_mem: 5405M
[32m[04/20 09:08:37 d2.utils.events]: [0m eta: 0:12:41  iter: 279  total_loss: 0.658  loss_cls: 0.215  loss_box_reg: 0.332  loss_rpn_cls: 0.020  loss_rpn_loc: 0.064  time: 1.0413  data_time: 0.0171  lr: 0.001399  max_mem: 5405M
[32m[04/20 09:08:58 d2.utils.events]: [0m eta: 0:12:20  iter: 299  total_loss: 0.682  loss_cls: 0.227  loss_box_reg: 0.364  loss_rpn_cls: 0.022  loss_rpn_loc: 0.059  time: 1.0418  data_time: 0.0173  lr: 0.001499  max_mem: 5405M
[32m[04/20 09:09:18 d2.utils.events]: [0m eta: 0:11:58  iter: 319  total_loss: 0.686  loss_cls: 0.222  loss_box_reg: 0.361  loss_rpn_cls: 0.017  loss_rpn_loc: 0.061  time: 1.0418  data_time: 0.0176  lr: 0.001598  max_mem: 5405M
[32m[04/20 09:09:39 d2.utils.events]: [0m eta: 0:11:34  iter: 339  total_loss: 0.607  loss_cls: 0.203  loss_box_reg: 0.324  loss_rpn_cls: 0.015  loss_rpn_loc: 0.048  time: 1.0402  data_time: 0.0164  lr: 0.001698  max_mem: 5405M
[32m[04/20 09:09:59 d2.utils.events]: [0m eta: 0:11:11  iter: 359  total_loss: 0.624  loss_cls: 0.215  loss_box_reg: 0.353  loss_rpn_cls: 0.014  loss_rpn_loc: 0.062  time: 1.0380  data_time: 0.0169  lr: 0.001798  max_mem: 5405M
[32m[04/20 09:10:19 d2.utils.events]: [0m eta: 0:10:48  iter: 379  total_loss: 0.632  loss_cls: 0.208  loss_box_reg: 0.347  loss_rpn_cls: 0.018  loss_rpn_loc: 0.056  time: 1.0372  data_time: 0.0160  lr: 0.001898  max_mem: 5405M
[32m[04/20 09:10:40 d2.utils.events]: [0m eta: 0:10:27  iter: 399  total_loss: 0.560  loss_cls: 0.190  loss_box_reg: 0.319  loss_rpn_cls: 0.015  loss_rpn_loc: 0.045  time: 1.0372  data_time: 0.0168  lr: 0.001998  max_mem: 5405M
[32m[04/20 09:11:01 d2.utils.events]: [0m eta: 0:10:08  iter: 419  total_loss: 0.690  loss_cls: 0.233  loss_box_reg: 0.387  loss_rpn_cls: 0.024  loss_rpn_loc: 0.064  time: 1.0377  data_time: 0.0113  lr: 0.002098  max_mem: 5405M
[32m[04/20 09:11:22 d2.utils.events]: [0m eta: 0:09:48  iter: 439  total_loss: 0.598  loss_cls: 0.209  loss_box_reg: 0.304  loss_rpn_cls: 0.020  loss_rpn_loc: 0.046  time: 1.0385  data_time: 0.0118  lr: 0.002198  max_mem: 5405M
[32m[04/20 09:11:43 d2.utils.events]: [0m eta: 0:09:28  iter: 459  total_loss: 0.617  loss_cls: 0.209  loss_box_reg: 0.357  loss_rpn_cls: 0.017  loss_rpn_loc: 0.061  time: 1.0391  data_time: 0.0112  lr: 0.002298  max_mem: 5405M
[32m[04/20 09:12:04 d2.utils.events]: [0m eta: 0:09:06  iter: 479  total_loss: 0.643  loss_cls: 0.213  loss_box_reg: 0.349  loss_rpn_cls: 0.021  loss_rpn_loc: 0.058  time: 1.0387  data_time: 0.0118  lr: 0.002398  max_mem: 5405M
[32m[04/20 09:12:25 d2.utils.events]: [0m eta: 0:08:45  iter: 499  total_loss: 0.674  loss_cls: 0.220  loss_box_reg: 0.348  loss_rpn_cls: 0.021  loss_rpn_loc: 0.076  time: 1.0381  data_time: 0.0103  lr: 0.002498  max_mem: 5405M
[32m[04/20 09:12:45 d2.utils.events]: [0m eta: 0:08:24  iter: 519  total_loss: 0.632  loss_cls: 0.211  loss_box_reg: 0.349  loss_rpn_cls: 0.020  loss_rpn_loc: 0.053  time: 1.0380  data_time: 0.0097  lr: 0.002597  max_mem: 5405M
[32m[04/20 09:13:06 d2.utils.events]: [0m eta: 0:08:03  iter: 539  total_loss: 0.669  loss_cls: 0.219  loss_box_reg: 0.369  loss_rpn_cls: 0.014  loss_rpn_loc: 0.054  time: 1.0382  data_time: 0.0098  lr: 0.002697  max_mem: 5405M
[32m[04/20 09:13:27 d2.utils.events]: [0m eta: 0:07:42  iter: 559  total_loss: 0.717  loss_cls: 0.239  loss_box_reg: 0.387  loss_rpn_cls: 0.020  loss_rpn_loc: 0.059  time: 1.0376  data_time: 0.0095  lr: 0.002797  max_mem: 5405M
[32m[04/20 09:13:48 d2.utils.events]: [0m eta: 0:07:21  iter: 579  total_loss: 0.646  loss_cls: 0.217  loss_box_reg: 0.352  loss_rpn_cls: 0.021  loss_rpn_loc: 0.050  time: 1.0375  data_time: 0.0099  lr: 0.002897  max_mem: 5405M
[32m[04/20 09:14:08 d2.utils.events]: [0m eta: 0:07:00  iter: 599  total_loss: 0.539  loss_cls: 0.184  loss_box_reg: 0.318  loss_rpn_cls: 0.019  loss_rpn_loc: 0.041  time: 1.0364  data_time: 0.0100  lr: 0.002997  max_mem: 5405M
[32m[04/20 09:14:28 d2.utils.events]: [0m eta: 0:06:39  iter: 619  total_loss: 0.692  loss_cls: 0.213  loss_box_reg: 0.379  loss_rpn_cls: 0.018  loss_rpn_loc: 0.063  time: 1.0362  data_time: 0.0097  lr: 0.003097  max_mem: 5405M
[32m[04/20 09:14:49 d2.utils.events]: [0m eta: 0:06:17  iter: 639  total_loss: 0.718  loss_cls: 0.225  loss_box_reg: 0.399  loss_rpn_cls: 0.020  loss_rpn_loc: 0.067  time: 1.0359  data_time: 0.0097  lr: 0.003197  max_mem: 5405M
[32m[04/20 09:15:10 d2.utils.events]: [0m eta: 0:05:57  iter: 659  total_loss: 0.689  loss_cls: 0.240  loss_box_reg: 0.361  loss_rpn_cls: 0.023  loss_rpn_loc: 0.070  time: 1.0363  data_time: 0.0101  lr: 0.003297  max_mem: 5405M
[32m[04/20 09:15:31 d2.utils.events]: [0m eta: 0:05:36  iter: 679  total_loss: 0.734  loss_cls: 0.233  loss_box_reg: 0.390  loss_rpn_cls: 0.025  loss_rpn_loc: 0.084  time: 1.0360  data_time: 0.0094  lr: 0.003397  max_mem: 5405M
[32m[04/20 09:15:51 d2.utils.events]: [0m eta: 0:05:15  iter: 699  total_loss: 0.654  loss_cls: 0.218  loss_box_reg: 0.365  loss_rpn_cls: 0.021  loss_rpn_loc: 0.064  time: 1.0358  data_time: 0.0097  lr: 0.003497  max_mem: 5405M
[32m[04/20 09:16:12 d2.utils.events]: [0m eta: 0:04:54  iter: 719  total_loss: 0.704  loss_cls: 0.229  loss_box_reg: 0.383  loss_rpn_cls: 0.022  loss_rpn_loc: 0.060  time: 1.0359  data_time: 0.0096  lr: 0.003596  max_mem: 5405M
[32m[04/20 09:16:32 d2.utils.events]: [0m eta: 0:04:33  iter: 739  total_loss: 0.600  loss_cls: 0.194  loss_box_reg: 0.340  loss_rpn_cls: 0.021  loss_rpn_loc: 0.049  time: 1.0354  data_time: 0.0099  lr: 0.003696  max_mem: 5405M
[32m[04/20 09:16:53 d2.utils.events]: [0m eta: 0:04:12  iter: 759  total_loss: 0.715  loss_cls: 0.246  loss_box_reg: 0.376  loss_rpn_cls: 0.019  loss_rpn_loc: 0.055  time: 1.0352  data_time: 0.0098  lr: 0.003796  max_mem: 5405M
[32m[04/20 09:17:14 d2.utils.events]: [0m eta: 0:03:51  iter: 779  total_loss: 0.697  loss_cls: 0.226  loss_box_reg: 0.371  loss_rpn_cls: 0.021  loss_rpn_loc: 0.059  time: 1.0352  data_time: 0.0098  lr: 0.003896  max_mem: 5405M
[32m[04/20 09:17:34 d2.utils.events]: [0m eta: 0:03:30  iter: 799  total_loss: 0.604  loss_cls: 0.193  loss_box_reg: 0.325  loss_rpn_cls: 0.024  loss_rpn_loc: 0.053  time: 1.0348  data_time: 0.0098  lr: 0.003996  max_mem: 5405M
[32m[04/20 09:17:55 d2.utils.events]: [0m eta: 0:03:09  iter: 819  total_loss: 0.596  loss_cls: 0.206  loss_box_reg: 0.308  loss_rpn_cls: 0.021  loss_rpn_loc: 0.074  time: 1.0346  data_time: 0.0096  lr: 0.004096  max_mem: 5405M
[32m[04/20 09:18:16 d2.utils.events]: [0m eta: 0:02:48  iter: 839  total_loss: 0.715  loss_cls: 0.231  loss_box_reg: 0.377  loss_rpn_cls: 0.023  loss_rpn_loc: 0.066  time: 1.0350  data_time: 0.0098  lr: 0.004196  max_mem: 5405M
[32m[04/20 09:18:37 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.678  loss_cls: 0.225  loss_box_reg: 0.368  loss_rpn_cls: 0.023  loss_rpn_loc: 0.061  time: 1.0349  data_time: 0.0095  lr: 0.004296  max_mem: 5405M
[32m[04/20 09:18:57 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.710  loss_cls: 0.244  loss_box_reg: 0.379  loss_rpn_cls: 0.025  loss_rpn_loc: 0.049  time: 1.0349  data_time: 0.0098  lr: 0.004396  max_mem: 5405M
[32m[04/20 09:19:18 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.588  loss_cls: 0.197  loss_box_reg: 0.297  loss_rpn_cls: 0.023  loss_rpn_loc: 0.051  time: 1.0344  data_time: 0.0094  lr: 0.004496  max_mem: 5405M
[32m[04/20 09:19:38 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.793  loss_cls: 0.253  loss_box_reg: 0.429  loss_rpn_cls: 0.024  loss_rpn_loc: 0.079  time: 1.0344  data_time: 0.0097  lr: 0.004595  max_mem: 5405M
[32m[04/20 09:19:59 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.664  loss_cls: 0.198  loss_box_reg: 0.360  loss_rpn_cls: 0.019  loss_rpn_loc: 0.050  time: 1.0340  data_time: 0.0095  lr: 0.004695  max_mem: 5405M
[32m[04/20 09:20:19 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.677  loss_cls: 0.216  loss_box_reg: 0.357  loss_rpn_cls: 0.022  loss_rpn_loc: 0.052  time: 1.0340  data_time: 0.0097  lr: 0.004795  max_mem: 5405M
[32m[04/20 09:20:40 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.713  loss_cls: 0.240  loss_box_reg: 0.358  loss_rpn_cls: 0.029  loss_rpn_loc: 0.060  time: 1.0334  data_time: 0.0097  lr: 0.004895  max_mem: 5405M
[5m[31mWARNING[0m [32m[04/20 09:21:04 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 09:21:04 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 09:21:04 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 09:21:04 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.630  loss_cls: 0.210  loss_box_reg: 0.335  loss_rpn_cls: 0.028  loss_rpn_loc: 0.054  time: 1.0336  data_time: 0.0097  lr: 0.004995  max_mem: 5405M
[32m[04/20 09:21:05 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:11 (1.0347 s / it)
[32m[04/20 09:21:05 d2.engine.hooks]: [0mTotal training time: 0:17:18 (0:00:06 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 09:21:08 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 09:21:08 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 09:21:08 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 09:21:10 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1166 s / img. ETA=0:16:30
[32m[04/20 09:21:15 d2.evaluation.evaluator]: [0mInference done 54/8355. 0.1164 s / img. ETA=0:16:26
[32m[04/20 09:21:20 d2.evaluation.evaluator]: [0mInference done 97/8355. 0.1162 s / img. ETA=0:16:19
[32m[04/20 09:21:25 d2.evaluation.evaluator]: [0mInference done 140/8355. 0.1160 s / img. ETA=0:16:13
[32m[04/20 09:21:30 d2.evaluation.evaluator]: [0mInference done 183/8355. 0.1159 s / img. ETA=0:16:07
[32m[04/20 09:21:35 d2.evaluation.evaluator]: [0mInference done 226/8355. 0.1160 s / img. ETA=0:16:02
[32m[04/20 09:21:40 d2.evaluation.evaluator]: [0mInference done 269/8355. 0.1160 s / img. ETA=0:15:57
[32m[04/20 09:21:45 d2.evaluation.evaluator]: [0mInference done 312/8355. 0.1161 s / img. ETA=0:15:53
[32m[04/20 09:21:51 d2.evaluation.evaluator]: [0mInference done 355/8355. 0.1161 s / img. ETA=0:15:48
[32m[04/20 09:21:56 d2.evaluation.evaluator]: [0mInference done 398/8355. 0.1161 s / img. ETA=0:15:43
[32m[04/20 09:22:01 d2.evaluation.evaluator]: [0mInference done 440/8355. 0.1162 s / img. ETA=0:15:39
[32m[04/20 09:22:06 d2.evaluation.evaluator]: [0mInference done 483/8355. 0.1161 s / img. ETA=0:15:33
[32m[04/20 09:22:11 d2.evaluation.evaluator]: [0mInference done 526/8355. 0.1161 s / img. ETA=0:15:28
[32m[04/20 09:22:16 d2.evaluation.evaluator]: [0mInference done 569/8355. 0.1161 s / img. ETA=0:15:23
[32m[04/20 09:22:21 d2.evaluation.evaluator]: [0mInference done 612/8355. 0.1161 s / img. ETA=0:15:18
[32m[04/20 09:22:26 d2.evaluation.evaluator]: [0mInference done 655/8355. 0.1161 s / img. ETA=0:15:13
[32m[04/20 09:22:31 d2.evaluation.evaluator]: [0mInference done 697/8355. 0.1162 s / img. ETA=0:15:08
[32m[04/20 09:22:36 d2.evaluation.evaluator]: [0mInference done 740/8355. 0.1162 s / img. ETA=0:15:03
[32m[04/20 09:22:41 d2.evaluation.evaluator]: [0mInference done 783/8355. 0.1162 s / img. ETA=0:14:58
[32m[04/20 09:22:46 d2.evaluation.evaluator]: [0mInference done 826/8355. 0.1162 s / img. ETA=0:14:53
[32m[04/20 09:22:52 d2.evaluation.evaluator]: [0mInference done 869/8355. 0.1162 s / img. ETA=0:14:48
[32m[04/20 09:22:57 d2.evaluation.evaluator]: [0mInference done 911/8355. 0.1162 s / img. ETA=0:14:43
[32m[04/20 09:23:02 d2.evaluation.evaluator]: [0mInference done 954/8355. 0.1162 s / img. ETA=0:14:38
[32m[04/20 09:23:07 d2.evaluation.evaluator]: [0mInference done 997/8355. 0.1162 s / img. ETA=0:14:33
[32m[04/20 09:23:12 d2.evaluation.evaluator]: [0mInference done 1040/8355. 0.1162 s / img. ETA=0:14:27
[32m[04/20 09:23:17 d2.evaluation.evaluator]: [0mInference done 1083/8355. 0.1162 s / img. ETA=0:14:22
[32m[04/20 09:23:22 d2.evaluation.evaluator]: [0mInference done 1126/8355. 0.1162 s / img. ETA=0:14:17
[32m[04/20 09:23:27 d2.evaluation.evaluator]: [0mInference done 1169/8355. 0.1162 s / img. ETA=0:14:12
[32m[04/20 09:23:32 d2.evaluation.evaluator]: [0mInference done 1212/8355. 0.1162 s / img. ETA=0:14:07
[32m[04/20 09:23:37 d2.evaluation.evaluator]: [0mInference done 1255/8355. 0.1161 s / img. ETA=0:14:01
[32m[04/20 09:23:42 d2.evaluation.evaluator]: [0mInference done 1298/8355. 0.1161 s / img. ETA=0:13:56
[32m[04/20 09:23:47 d2.evaluation.evaluator]: [0mInference done 1341/8355. 0.1161 s / img. ETA=0:13:51
[32m[04/20 09:23:53 d2.evaluation.evaluator]: [0mInference done 1384/8355. 0.1161 s / img. ETA=0:13:46
[32m[04/20 09:23:58 d2.evaluation.evaluator]: [0mInference done 1427/8355. 0.1161 s / img. ETA=0:13:41
[32m[04/20 09:24:03 d2.evaluation.evaluator]: [0mInference done 1470/8355. 0.1161 s / img. ETA=0:13:36
[32m[04/20 09:24:08 d2.evaluation.evaluator]: [0mInference done 1512/8355. 0.1162 s / img. ETA=0:13:31
[32m[04/20 09:24:13 d2.evaluation.evaluator]: [0mInference done 1554/8355. 0.1162 s / img. ETA=0:13:27
[32m[04/20 09:24:18 d2.evaluation.evaluator]: [0mInference done 1596/8355. 0.1162 s / img. ETA=0:13:22
[32m[04/20 09:24:23 d2.evaluation.evaluator]: [0mInference done 1638/8355. 0.1163 s / img. ETA=0:13:17
[32m[04/20 09:24:28 d2.evaluation.evaluator]: [0mInference done 1680/8355. 0.1163 s / img. ETA=0:13:12
[32m[04/20 09:24:33 d2.evaluation.evaluator]: [0mInference done 1722/8355. 0.1164 s / img. ETA=0:13:08
[32m[04/20 09:24:38 d2.evaluation.evaluator]: [0mInference done 1764/8355. 0.1164 s / img. ETA=0:13:03
[32m[04/20 09:24:43 d2.evaluation.evaluator]: [0mInference done 1806/8355. 0.1164 s / img. ETA=0:12:58
[32m[04/20 09:24:48 d2.evaluation.evaluator]: [0mInference done 1848/8355. 0.1165 s / img. ETA=0:12:53
[32m[04/20 09:24:53 d2.evaluation.evaluator]: [0mInference done 1890/8355. 0.1165 s / img. ETA=0:12:49
[32m[04/20 09:24:58 d2.evaluation.evaluator]: [0mInference done 1932/8355. 0.1165 s / img. ETA=0:12:44
[32m[04/20 09:25:03 d2.evaluation.evaluator]: [0mInference done 1974/8355. 0.1165 s / img. ETA=0:12:39
[32m[04/20 09:25:08 d2.evaluation.evaluator]: [0mInference done 2016/8355. 0.1166 s / img. ETA=0:12:34
[32m[04/20 09:25:13 d2.evaluation.evaluator]: [0mInference done 2058/8355. 0.1166 s / img. ETA=0:12:29
[32m[04/20 09:25:18 d2.evaluation.evaluator]: [0mInference done 2100/8355. 0.1166 s / img. ETA=0:12:24
[32m[04/20 09:25:24 d2.evaluation.evaluator]: [0mInference done 2143/8355. 0.1166 s / img. ETA=0:12:19
[32m[04/20 09:25:29 d2.evaluation.evaluator]: [0mInference done 2185/8355. 0.1166 s / img. ETA=0:12:14
[32m[04/20 09:25:34 d2.evaluation.evaluator]: [0mInference done 2227/8355. 0.1166 s / img. ETA=0:12:09
[32m[04/20 09:25:39 d2.evaluation.evaluator]: [0mInference done 2269/8355. 0.1166 s / img. ETA=0:12:04
[32m[04/20 09:25:44 d2.evaluation.evaluator]: [0mInference done 2311/8355. 0.1166 s / img. ETA=0:11:59
[32m[04/20 09:25:49 d2.evaluation.evaluator]: [0mInference done 2353/8355. 0.1166 s / img. ETA=0:11:54
[32m[04/20 09:25:54 d2.evaluation.evaluator]: [0mInference done 2395/8355. 0.1166 s / img. ETA=0:11:49
[32m[04/20 09:25:59 d2.evaluation.evaluator]: [0mInference done 2437/8355. 0.1166 s / img. ETA=0:11:44
[32m[04/20 09:26:04 d2.evaluation.evaluator]: [0mInference done 2479/8355. 0.1166 s / img. ETA=0:11:39
[32m[04/20 09:26:09 d2.evaluation.evaluator]: [0mInference done 2521/8355. 0.1166 s / img. ETA=0:11:34
[32m[04/20 09:26:14 d2.evaluation.evaluator]: [0mInference done 2564/8355. 0.1166 s / img. ETA=0:11:29
[32m[04/20 09:26:19 d2.evaluation.evaluator]: [0mInference done 2606/8355. 0.1166 s / img. ETA=0:11:24
[32m[04/20 09:26:24 d2.evaluation.evaluator]: [0mInference done 2648/8355. 0.1166 s / img. ETA=0:11:19
[32m[04/20 09:26:29 d2.evaluation.evaluator]: [0mInference done 2690/8355. 0.1167 s / img. ETA=0:11:14
[32m[04/20 09:26:34 d2.evaluation.evaluator]: [0mInference done 2732/8355. 0.1167 s / img. ETA=0:11:09
[32m[04/20 09:26:39 d2.evaluation.evaluator]: [0mInference done 2774/8355. 0.1167 s / img. ETA=0:11:04
[32m[04/20 09:26:44 d2.evaluation.evaluator]: [0mInference done 2816/8355. 0.1167 s / img. ETA=0:10:59
[32m[04/20 09:26:49 d2.evaluation.evaluator]: [0mInference done 2858/8355. 0.1167 s / img. ETA=0:10:55
[32m[04/20 09:26:54 d2.evaluation.evaluator]: [0mInference done 2900/8355. 0.1167 s / img. ETA=0:10:50
[32m[04/20 09:26:59 d2.evaluation.evaluator]: [0mInference done 2942/8355. 0.1167 s / img. ETA=0:10:45
[32m[04/20 09:27:04 d2.evaluation.evaluator]: [0mInference done 2984/8355. 0.1167 s / img. ETA=0:10:40
[32m[04/20 09:27:09 d2.evaluation.evaluator]: [0mInference done 3026/8355. 0.1167 s / img. ETA=0:10:35
[32m[04/20 09:27:14 d2.evaluation.evaluator]: [0mInference done 3068/8355. 0.1167 s / img. ETA=0:10:30
[32m[04/20 09:27:19 d2.evaluation.evaluator]: [0mInference done 3110/8355. 0.1167 s / img. ETA=0:10:25
[32m[04/20 09:27:24 d2.evaluation.evaluator]: [0mInference done 3152/8355. 0.1167 s / img. ETA=0:10:20
[32m[04/20 09:27:29 d2.evaluation.evaluator]: [0mInference done 3195/8355. 0.1167 s / img. ETA=0:10:14
[32m[04/20 09:27:34 d2.evaluation.evaluator]: [0mInference done 3237/8355. 0.1167 s / img. ETA=0:10:09
[32m[04/20 09:27:39 d2.evaluation.evaluator]: [0mInference done 3279/8355. 0.1167 s / img. ETA=0:10:05
[32m[04/20 09:27:44 d2.evaluation.evaluator]: [0mInference done 3322/8355. 0.1167 s / img. ETA=0:09:59
[32m[04/20 09:27:49 d2.evaluation.evaluator]: [0mInference done 3365/8355. 0.1167 s / img. ETA=0:09:54
[32m[04/20 09:27:55 d2.evaluation.evaluator]: [0mInference done 3408/8355. 0.1167 s / img. ETA=0:09:49
[32m[04/20 09:28:00 d2.evaluation.evaluator]: [0mInference done 3450/8355. 0.1167 s / img. ETA=0:09:44
[32m[04/20 09:28:05 d2.evaluation.evaluator]: [0mInference done 3492/8355. 0.1167 s / img. ETA=0:09:39
[32m[04/20 09:28:10 d2.evaluation.evaluator]: [0mInference done 3534/8355. 0.1167 s / img. ETA=0:09:34
[32m[04/20 09:28:15 d2.evaluation.evaluator]: [0mInference done 3577/8355. 0.1167 s / img. ETA=0:09:29
[32m[04/20 09:28:20 d2.evaluation.evaluator]: [0mInference done 3619/8355. 0.1167 s / img. ETA=0:09:24
[32m[04/20 09:28:25 d2.evaluation.evaluator]: [0mInference done 3661/8355. 0.1167 s / img. ETA=0:09:19
[32m[04/20 09:28:30 d2.evaluation.evaluator]: [0mInference done 3703/8355. 0.1167 s / img. ETA=0:09:14
[32m[04/20 09:28:35 d2.evaluation.evaluator]: [0mInference done 3746/8355. 0.1167 s / img. ETA=0:09:09
[32m[04/20 09:28:40 d2.evaluation.evaluator]: [0mInference done 3788/8355. 0.1167 s / img. ETA=0:09:04
[32m[04/20 09:28:45 d2.evaluation.evaluator]: [0mInference done 3830/8355. 0.1167 s / img. ETA=0:08:59
[32m[04/20 09:28:50 d2.evaluation.evaluator]: [0mInference done 3872/8355. 0.1167 s / img. ETA=0:08:54
[32m[04/20 09:28:55 d2.evaluation.evaluator]: [0mInference done 3915/8355. 0.1167 s / img. ETA=0:08:49
[32m[04/20 09:29:00 d2.evaluation.evaluator]: [0mInference done 3957/8355. 0.1167 s / img. ETA=0:08:44
[32m[04/20 09:29:05 d2.evaluation.evaluator]: [0mInference done 3999/8355. 0.1167 s / img. ETA=0:08:39
[32m[04/20 09:29:10 d2.evaluation.evaluator]: [0mInference done 4041/8355. 0.1167 s / img. ETA=0:08:34
[32m[04/20 09:29:15 d2.evaluation.evaluator]: [0mInference done 4083/8355. 0.1167 s / img. ETA=0:08:29
[32m[04/20 09:29:20 d2.evaluation.evaluator]: [0mInference done 4125/8355. 0.1167 s / img. ETA=0:08:24
[32m[04/20 09:29:25 d2.evaluation.evaluator]: [0mInference done 4167/8355. 0.1167 s / img. ETA=0:08:19
[32m[04/20 09:29:30 d2.evaluation.evaluator]: [0mInference done 4209/8355. 0.1167 s / img. ETA=0:08:14
[32m[04/20 09:29:35 d2.evaluation.evaluator]: [0mInference done 4252/8355. 0.1167 s / img. ETA=0:08:09
[32m[04/20 09:29:40 d2.evaluation.evaluator]: [0mInference done 4294/8355. 0.1167 s / img. ETA=0:08:04
[32m[04/20 09:29:45 d2.evaluation.evaluator]: [0mInference done 4336/8355. 0.1167 s / img. ETA=0:07:59
[32m[04/20 09:29:50 d2.evaluation.evaluator]: [0mInference done 4378/8355. 0.1167 s / img. ETA=0:07:54
[32m[04/20 09:29:55 d2.evaluation.evaluator]: [0mInference done 4420/8355. 0.1167 s / img. ETA=0:07:49
[32m[04/20 09:30:00 d2.evaluation.evaluator]: [0mInference done 4462/8355. 0.1167 s / img. ETA=0:07:44
[32m[04/20 09:30:05 d2.evaluation.evaluator]: [0mInference done 4504/8355. 0.1167 s / img. ETA=0:07:39
[32m[04/20 09:30:11 d2.evaluation.evaluator]: [0mInference done 4546/8355. 0.1168 s / img. ETA=0:07:34
[32m[04/20 09:30:16 d2.evaluation.evaluator]: [0mInference done 4588/8355. 0.1168 s / img. ETA=0:07:29
[32m[04/20 09:30:21 d2.evaluation.evaluator]: [0mInference done 4630/8355. 0.1168 s / img. ETA=0:07:24
[32m[04/20 09:30:26 d2.evaluation.evaluator]: [0mInference done 4672/8355. 0.1168 s / img. ETA=0:07:19
[32m[04/20 09:30:31 d2.evaluation.evaluator]: [0mInference done 4714/8355. 0.1168 s / img. ETA=0:07:14
[32m[04/20 09:30:36 d2.evaluation.evaluator]: [0mInference done 4756/8355. 0.1168 s / img. ETA=0:07:09
[32m[04/20 09:30:41 d2.evaluation.evaluator]: [0mInference done 4798/8355. 0.1168 s / img. ETA=0:07:04
[32m[04/20 09:30:46 d2.evaluation.evaluator]: [0mInference done 4840/8355. 0.1168 s / img. ETA=0:06:59
[32m[04/20 09:30:51 d2.evaluation.evaluator]: [0mInference done 4883/8355. 0.1168 s / img. ETA=0:06:54
[32m[04/20 09:30:56 d2.evaluation.evaluator]: [0mInference done 4925/8355. 0.1168 s / img. ETA=0:06:49
[32m[04/20 09:31:01 d2.evaluation.evaluator]: [0mInference done 4968/8355. 0.1168 s / img. ETA=0:06:43
[32m[04/20 09:31:06 d2.evaluation.evaluator]: [0mInference done 5010/8355. 0.1168 s / img. ETA=0:06:39
[32m[04/20 09:31:11 d2.evaluation.evaluator]: [0mInference done 5052/8355. 0.1168 s / img. ETA=0:06:34
[32m[04/20 09:31:16 d2.evaluation.evaluator]: [0mInference done 5094/8355. 0.1168 s / img. ETA=0:06:29
[32m[04/20 09:31:21 d2.evaluation.evaluator]: [0mInference done 5136/8355. 0.1168 s / img. ETA=0:06:24
[32m[04/20 09:31:26 d2.evaluation.evaluator]: [0mInference done 5178/8355. 0.1168 s / img. ETA=0:06:19
[32m[04/20 09:31:32 d2.evaluation.evaluator]: [0mInference done 5220/8355. 0.1168 s / img. ETA=0:06:14
[32m[04/20 09:31:37 d2.evaluation.evaluator]: [0mInference done 5262/8355. 0.1168 s / img. ETA=0:06:09
[32m[04/20 09:31:42 d2.evaluation.evaluator]: [0mInference done 5304/8355. 0.1168 s / img. ETA=0:06:04
[32m[04/20 09:31:47 d2.evaluation.evaluator]: [0mInference done 5346/8355. 0.1168 s / img. ETA=0:05:59
[32m[04/20 09:31:52 d2.evaluation.evaluator]: [0mInference done 5388/8355. 0.1168 s / img. ETA=0:05:54
[32m[04/20 09:31:57 d2.evaluation.evaluator]: [0mInference done 5430/8355. 0.1168 s / img. ETA=0:05:49
[32m[04/20 09:32:02 d2.evaluation.evaluator]: [0mInference done 5472/8355. 0.1168 s / img. ETA=0:05:44
[32m[04/20 09:32:07 d2.evaluation.evaluator]: [0mInference done 5514/8355. 0.1168 s / img. ETA=0:05:39
[32m[04/20 09:32:12 d2.evaluation.evaluator]: [0mInference done 5557/8355. 0.1168 s / img. ETA=0:05:34
[32m[04/20 09:32:17 d2.evaluation.evaluator]: [0mInference done 5599/8355. 0.1168 s / img. ETA=0:05:29
[32m[04/20 09:32:22 d2.evaluation.evaluator]: [0mInference done 5641/8355. 0.1168 s / img. ETA=0:05:23
[32m[04/20 09:32:27 d2.evaluation.evaluator]: [0mInference done 5683/8355. 0.1168 s / img. ETA=0:05:18
[32m[04/20 09:32:32 d2.evaluation.evaluator]: [0mInference done 5725/8355. 0.1168 s / img. ETA=0:05:13
[32m[04/20 09:32:37 d2.evaluation.evaluator]: [0mInference done 5767/8355. 0.1168 s / img. ETA=0:05:08
[32m[04/20 09:32:42 d2.evaluation.evaluator]: [0mInference done 5809/8355. 0.1168 s / img. ETA=0:05:03
[32m[04/20 09:32:47 d2.evaluation.evaluator]: [0mInference done 5851/8355. 0.1169 s / img. ETA=0:04:58
[32m[04/20 09:32:52 d2.evaluation.evaluator]: [0mInference done 5893/8355. 0.1169 s / img. ETA=0:04:53
[32m[04/20 09:32:57 d2.evaluation.evaluator]: [0mInference done 5935/8355. 0.1169 s / img. ETA=0:04:48
[32m[04/20 09:33:02 d2.evaluation.evaluator]: [0mInference done 5977/8355. 0.1169 s / img. ETA=0:04:43
[32m[04/20 09:33:07 d2.evaluation.evaluator]: [0mInference done 6019/8355. 0.1169 s / img. ETA=0:04:38
[32m[04/20 09:33:12 d2.evaluation.evaluator]: [0mInference done 6061/8355. 0.1169 s / img. ETA=0:04:33
[32m[04/20 09:33:17 d2.evaluation.evaluator]: [0mInference done 6103/8355. 0.1169 s / img. ETA=0:04:28
[32m[04/20 09:33:22 d2.evaluation.evaluator]: [0mInference done 6145/8355. 0.1169 s / img. ETA=0:04:23
[32m[04/20 09:33:28 d2.evaluation.evaluator]: [0mInference done 6187/8355. 0.1169 s / img. ETA=0:04:18
[32m[04/20 09:33:33 d2.evaluation.evaluator]: [0mInference done 6229/8355. 0.1169 s / img. ETA=0:04:13
[32m[04/20 09:33:38 d2.evaluation.evaluator]: [0mInference done 6271/8355. 0.1169 s / img. ETA=0:04:08
[32m[04/20 09:33:43 d2.evaluation.evaluator]: [0mInference done 6313/8355. 0.1169 s / img. ETA=0:04:03
[32m[04/20 09:33:48 d2.evaluation.evaluator]: [0mInference done 6355/8355. 0.1169 s / img. ETA=0:03:58
[32m[04/20 09:33:53 d2.evaluation.evaluator]: [0mInference done 6397/8355. 0.1170 s / img. ETA=0:03:53
[32m[04/20 09:33:58 d2.evaluation.evaluator]: [0mInference done 6439/8355. 0.1170 s / img. ETA=0:03:48
[32m[04/20 09:34:03 d2.evaluation.evaluator]: [0mInference done 6481/8355. 0.1170 s / img. ETA=0:03:43
[32m[04/20 09:34:08 d2.evaluation.evaluator]: [0mInference done 6523/8355. 0.1170 s / img. ETA=0:03:38
[32m[04/20 09:34:13 d2.evaluation.evaluator]: [0mInference done 6565/8355. 0.1170 s / img. ETA=0:03:33
[32m[04/20 09:34:18 d2.evaluation.evaluator]: [0mInference done 6607/8355. 0.1170 s / img. ETA=0:03:28
[32m[04/20 09:34:23 d2.evaluation.evaluator]: [0mInference done 6649/8355. 0.1170 s / img. ETA=0:03:23
[32m[04/20 09:34:28 d2.evaluation.evaluator]: [0mInference done 6692/8355. 0.1170 s / img. ETA=0:03:18
[32m[04/20 09:34:33 d2.evaluation.evaluator]: [0mInference done 6735/8355. 0.1170 s / img. ETA=0:03:13
[32m[04/20 09:34:38 d2.evaluation.evaluator]: [0mInference done 6778/8355. 0.1170 s / img. ETA=0:03:08
[32m[04/20 09:34:43 d2.evaluation.evaluator]: [0mInference done 6820/8355. 0.1170 s / img. ETA=0:03:03
[32m[04/20 09:34:48 d2.evaluation.evaluator]: [0mInference done 6862/8355. 0.1170 s / img. ETA=0:02:58
[32m[04/20 09:34:53 d2.evaluation.evaluator]: [0mInference done 6904/8355. 0.1170 s / img. ETA=0:02:53
[32m[04/20 09:34:58 d2.evaluation.evaluator]: [0mInference done 6946/8355. 0.1170 s / img. ETA=0:02:48
[32m[04/20 09:35:03 d2.evaluation.evaluator]: [0mInference done 6988/8355. 0.1170 s / img. ETA=0:02:43
[32m[04/20 09:35:08 d2.evaluation.evaluator]: [0mInference done 7030/8355. 0.1170 s / img. ETA=0:02:38
[32m[04/20 09:35:13 d2.evaluation.evaluator]: [0mInference done 7072/8355. 0.1170 s / img. ETA=0:02:33
[32m[04/20 09:35:19 d2.evaluation.evaluator]: [0mInference done 7114/8355. 0.1170 s / img. ETA=0:02:28
[32m[04/20 09:35:24 d2.evaluation.evaluator]: [0mInference done 7156/8355. 0.1170 s / img. ETA=0:02:23
[32m[04/20 09:35:29 d2.evaluation.evaluator]: [0mInference done 7198/8355. 0.1170 s / img. ETA=0:02:18
[32m[04/20 09:35:34 d2.evaluation.evaluator]: [0mInference done 7240/8355. 0.1170 s / img. ETA=0:02:13
[32m[04/20 09:35:39 d2.evaluation.evaluator]: [0mInference done 7282/8355. 0.1170 s / img. ETA=0:02:08
[32m[04/20 09:35:44 d2.evaluation.evaluator]: [0mInference done 7324/8355. 0.1170 s / img. ETA=0:02:03
[32m[04/20 09:35:49 d2.evaluation.evaluator]: [0mInference done 7366/8355. 0.1170 s / img. ETA=0:01:58
[32m[04/20 09:35:54 d2.evaluation.evaluator]: [0mInference done 7408/8355. 0.1170 s / img. ETA=0:01:53
[32m[04/20 09:35:59 d2.evaluation.evaluator]: [0mInference done 7450/8355. 0.1170 s / img. ETA=0:01:48
[32m[04/20 09:36:04 d2.evaluation.evaluator]: [0mInference done 7492/8355. 0.1170 s / img. ETA=0:01:43
[32m[04/20 09:36:09 d2.evaluation.evaluator]: [0mInference done 7534/8355. 0.1170 s / img. ETA=0:01:38
[32m[04/20 09:36:14 d2.evaluation.evaluator]: [0mInference done 7574/8355. 0.1171 s / img. ETA=0:01:33
[32m[04/20 09:36:19 d2.evaluation.evaluator]: [0mInference done 7616/8355. 0.1171 s / img. ETA=0:01:28
[32m[04/20 09:36:24 d2.evaluation.evaluator]: [0mInference done 7658/8355. 0.1171 s / img. ETA=0:01:23
[32m[04/20 09:36:29 d2.evaluation.evaluator]: [0mInference done 7700/8355. 0.1171 s / img. ETA=0:01:18
[32m[04/20 09:36:34 d2.evaluation.evaluator]: [0mInference done 7742/8355. 0.1171 s / img. ETA=0:01:13
[32m[04/20 09:36:40 d2.evaluation.evaluator]: [0mInference done 7784/8355. 0.1171 s / img. ETA=0:01:08
[32m[04/20 09:36:45 d2.evaluation.evaluator]: [0mInference done 7826/8355. 0.1171 s / img. ETA=0:01:03
[32m[04/20 09:36:50 d2.evaluation.evaluator]: [0mInference done 7868/8355. 0.1171 s / img. ETA=0:00:58
[32m[04/20 09:36:55 d2.evaluation.evaluator]: [0mInference done 7910/8355. 0.1171 s / img. ETA=0:00:53
[32m[04/20 09:37:00 d2.evaluation.evaluator]: [0mInference done 7952/8355. 0.1171 s / img. ETA=0:00:48
[32m[04/20 09:37:05 d2.evaluation.evaluator]: [0mInference done 7994/8355. 0.1171 s / img. ETA=0:00:43
[32m[04/20 09:37:10 d2.evaluation.evaluator]: [0mInference done 8036/8355. 0.1171 s / img. ETA=0:00:38
[32m[04/20 09:37:15 d2.evaluation.evaluator]: [0mInference done 8078/8355. 0.1171 s / img. ETA=0:00:33
[32m[04/20 09:37:20 d2.evaluation.evaluator]: [0mInference done 8121/8355. 0.1171 s / img. ETA=0:00:27
[32m[04/20 09:37:25 d2.evaluation.evaluator]: [0mInference done 8163/8355. 0.1171 s / img. ETA=0:00:22
[32m[04/20 09:37:30 d2.evaluation.evaluator]: [0mInference done 8205/8355. 0.1171 s / img. ETA=0:00:17
[32m[04/20 09:37:35 d2.evaluation.evaluator]: [0mInference done 8247/8355. 0.1171 s / img. ETA=0:00:12
[32m[04/20 09:37:40 d2.evaluation.evaluator]: [0mInference done 8289/8355. 0.1171 s / img. ETA=0:00:07
[32m[04/20 09:37:45 d2.evaluation.evaluator]: [0mInference done 8331/8355. 0.1171 s / img. ETA=0:00:02
[32m[04/20 09:37:48 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:39.055991 (0.119647 s / img per device, on 1 devices)
[32m[04/20 09:37:48 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:18 (0.117142 s / img per device, on 1 devices)
[32m[04/20 09:37:48 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 09:37:48 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 09:37:49 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=18.50s).
Accumulating evaluation results...
DONE (t=2.05s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.293
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.545
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.277
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.561
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.124
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.332
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.241
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.483
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598
[32m[04/20 09:38:09 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 29.320 | 54.535 | 27.653 | 19.025 | 42.362 | 56.145 |
[32m[04/20 09:38:09 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 31.461 | bicycle       | 13.721 | car            | 42.779 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 09:38:10 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 09:38:10 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 09:38:10 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 09:38:12 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1176 s / img. ETA=0:02:29
[32m[04/20 09:38:17 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1172 s / img. ETA=0:02:24
[32m[04/20 09:38:22 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1172 s / img. ETA=0:02:19
[32m[04/20 09:38:27 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1173 s / img. ETA=0:02:14
[32m[04/20 09:38:32 d2.evaluation.evaluator]: [0mInference done 179/1257. 0.1173 s / img. ETA=0:02:09
[32m[04/20 09:38:37 d2.evaluation.evaluator]: [0mInference done 221/1257. 0.1172 s / img. ETA=0:02:04
[32m[04/20 09:38:42 d2.evaluation.evaluator]: [0mInference done 263/1257. 0.1173 s / img. ETA=0:01:59
[32m[04/20 09:38:47 d2.evaluation.evaluator]: [0mInference done 305/1257. 0.1173 s / img. ETA=0:01:54
[32m[04/20 09:38:52 d2.evaluation.evaluator]: [0mInference done 347/1257. 0.1172 s / img. ETA=0:01:48
[32m[04/20 09:38:57 d2.evaluation.evaluator]: [0mInference done 389/1257. 0.1171 s / img. ETA=0:01:43
[32m[04/20 09:39:02 d2.evaluation.evaluator]: [0mInference done 431/1257. 0.1171 s / img. ETA=0:01:38
[32m[04/20 09:39:07 d2.evaluation.evaluator]: [0mInference done 473/1257. 0.1171 s / img. ETA=0:01:33
[32m[04/20 09:39:12 d2.evaluation.evaluator]: [0mInference done 515/1257. 0.1172 s / img. ETA=0:01:28
[32m[04/20 09:39:17 d2.evaluation.evaluator]: [0mInference done 557/1257. 0.1172 s / img. ETA=0:01:23
[32m[04/20 09:39:22 d2.evaluation.evaluator]: [0mInference done 599/1257. 0.1172 s / img. ETA=0:01:18
[32m[04/20 09:39:27 d2.evaluation.evaluator]: [0mInference done 641/1257. 0.1172 s / img. ETA=0:01:13
[32m[04/20 09:39:32 d2.evaluation.evaluator]: [0mInference done 683/1257. 0.1172 s / img. ETA=0:01:08
[32m[04/20 09:39:37 d2.evaluation.evaluator]: [0mInference done 725/1257. 0.1172 s / img. ETA=0:01:03
[32m[04/20 09:39:42 d2.evaluation.evaluator]: [0mInference done 767/1257. 0.1172 s / img. ETA=0:00:58
[32m[04/20 09:39:48 d2.evaluation.evaluator]: [0mInference done 809/1257. 0.1172 s / img. ETA=0:00:53
[32m[04/20 09:39:53 d2.evaluation.evaluator]: [0mInference done 851/1257. 0.1172 s / img. ETA=0:00:48
[32m[04/20 09:39:58 d2.evaluation.evaluator]: [0mInference done 893/1257. 0.1172 s / img. ETA=0:00:43
[32m[04/20 09:40:03 d2.evaluation.evaluator]: [0mInference done 935/1257. 0.1172 s / img. ETA=0:00:38
[32m[04/20 09:40:08 d2.evaluation.evaluator]: [0mInference done 977/1257. 0.1172 s / img. ETA=0:00:33
[32m[04/20 09:40:13 d2.evaluation.evaluator]: [0mInference done 1019/1257. 0.1172 s / img. ETA=0:00:28
[32m[04/20 09:40:18 d2.evaluation.evaluator]: [0mInference done 1061/1257. 0.1172 s / img. ETA=0:00:23
[32m[04/20 09:40:23 d2.evaluation.evaluator]: [0mInference done 1103/1257. 0.1172 s / img. ETA=0:00:18
[32m[04/20 09:40:28 d2.evaluation.evaluator]: [0mInference done 1145/1257. 0.1172 s / img. ETA=0:00:13
[32m[04/20 09:40:33 d2.evaluation.evaluator]: [0mInference done 1187/1257. 0.1172 s / img. ETA=0:00:08
[32m[04/20 09:40:38 d2.evaluation.evaluator]: [0mInference done 1229/1257. 0.1172 s / img. ETA=0:00:03
[32m[04/20 09:40:41 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:29.973226 (0.119787 s / img per device, on 1 devices)
[32m[04/20 09:40:41 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:26 (0.117237 s / img per device, on 1 devices)
[32m[04/20 09:40:41 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 09:40:41 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 09:40:41 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.56s).
Accumulating evaluation results...
DONE (t=0.33s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.259
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.244
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.151
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.320
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.429
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.113
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.299
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.301
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.371
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.462
[32m[04/20 09:40:44 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 25.888 | 47.963 | 24.420 | 15.145 | 31.990 | 42.887 |
[32m[04/20 09:40:44 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 28.721 | bicycle       | 4.785 | car            | 44.159 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | nan   | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  7  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 09:40:45 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 09:40:45 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 09:40:45 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 09:40:46 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 09:40:46 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 09:40:46 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 09:40:46 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 09:41:07 d2.utils.events]: [0m eta: 0:16:56  iter: 19  total_loss: 0.702  loss_cls: 0.232  loss_box_reg: 0.368  loss_rpn_cls: 0.027  loss_rpn_loc: 0.069  time: 1.0386  data_time: 0.0258  lr: 0.000100  max_mem: 5405M
[32m[04/20 09:41:27 d2.utils.events]: [0m eta: 0:16:20  iter: 39  total_loss: 0.613  loss_cls: 0.205  loss_box_reg: 0.311  loss_rpn_cls: 0.026  loss_rpn_loc: 0.052  time: 1.0296  data_time: 0.0097  lr: 0.000200  max_mem: 5405M
[32m[04/20 09:41:48 d2.utils.events]: [0m eta: 0:16:30  iter: 59  total_loss: 0.580  loss_cls: 0.196  loss_box_reg: 0.301  loss_rpn_cls: 0.021  loss_rpn_loc: 0.052  time: 1.0394  data_time: 0.0097  lr: 0.000300  max_mem: 5405M
[32m[04/20 09:42:09 d2.utils.events]: [0m eta: 0:16:08  iter: 79  total_loss: 0.619  loss_cls: 0.194  loss_box_reg: 0.357  loss_rpn_cls: 0.022  loss_rpn_loc: 0.052  time: 1.0392  data_time: 0.0097  lr: 0.000400  max_mem: 5405M
[32m[04/20 09:42:30 d2.utils.events]: [0m eta: 0:15:45  iter: 99  total_loss: 0.613  loss_cls: 0.191  loss_box_reg: 0.323  loss_rpn_cls: 0.014  loss_rpn_loc: 0.072  time: 1.0360  data_time: 0.0098  lr: 0.000500  max_mem: 5405M
[32m[04/20 09:42:51 d2.utils.events]: [0m eta: 0:15:24  iter: 119  total_loss: 0.675  loss_cls: 0.219  loss_box_reg: 0.357  loss_rpn_cls: 0.021  loss_rpn_loc: 0.053  time: 1.0356  data_time: 0.0097  lr: 0.000599  max_mem: 5405M
[32m[04/20 09:43:12 d2.utils.events]: [0m eta: 0:15:05  iter: 139  total_loss: 0.601  loss_cls: 0.201  loss_box_reg: 0.336  loss_rpn_cls: 0.016  loss_rpn_loc: 0.049  time: 1.0383  data_time: 0.0096  lr: 0.000699  max_mem: 5405M
[32m[04/20 09:43:32 d2.utils.events]: [0m eta: 0:14:41  iter: 159  total_loss: 0.615  loss_cls: 0.194  loss_box_reg: 0.330  loss_rpn_cls: 0.018  loss_rpn_loc: 0.051  time: 1.0348  data_time: 0.0097  lr: 0.000799  max_mem: 5405M
[32m[04/20 09:43:53 d2.utils.events]: [0m eta: 0:14:19  iter: 179  total_loss: 0.616  loss_cls: 0.204  loss_box_reg: 0.321  loss_rpn_cls: 0.024  loss_rpn_loc: 0.055  time: 1.0342  data_time: 0.0098  lr: 0.000899  max_mem: 5405M
[32m[04/20 09:44:13 d2.utils.events]: [0m eta: 0:13:59  iter: 199  total_loss: 0.661  loss_cls: 0.227  loss_box_reg: 0.354  loss_rpn_cls: 0.020  loss_rpn_loc: 0.052  time: 1.0352  data_time: 0.0102  lr: 0.000999  max_mem: 5405M
[32m[04/20 09:44:35 d2.utils.events]: [0m eta: 0:13:40  iter: 219  total_loss: 0.552  loss_cls: 0.188  loss_box_reg: 0.317  loss_rpn_cls: 0.015  loss_rpn_loc: 0.048  time: 1.0366  data_time: 0.0099  lr: 0.001099  max_mem: 5405M
[32m[04/20 09:44:55 d2.utils.events]: [0m eta: 0:13:18  iter: 239  total_loss: 0.575  loss_cls: 0.199  loss_box_reg: 0.322  loss_rpn_cls: 0.019  loss_rpn_loc: 0.054  time: 1.0352  data_time: 0.0097  lr: 0.001199  max_mem: 5405M
[32m[04/20 09:45:16 d2.utils.events]: [0m eta: 0:12:58  iter: 259  total_loss: 0.624  loss_cls: 0.213  loss_box_reg: 0.342  loss_rpn_cls: 0.024  loss_rpn_loc: 0.061  time: 1.0357  data_time: 0.0098  lr: 0.001299  max_mem: 5405M
[32m[04/20 09:45:37 d2.utils.events]: [0m eta: 0:12:37  iter: 279  total_loss: 0.636  loss_cls: 0.208  loss_box_reg: 0.333  loss_rpn_cls: 0.019  loss_rpn_loc: 0.053  time: 1.0359  data_time: 0.0099  lr: 0.001399  max_mem: 5405M
[32m[04/20 09:45:57 d2.utils.events]: [0m eta: 0:12:16  iter: 299  total_loss: 0.680  loss_cls: 0.222  loss_box_reg: 0.363  loss_rpn_cls: 0.017  loss_rpn_loc: 0.067  time: 1.0357  data_time: 0.0097  lr: 0.001499  max_mem: 5405M
[32m[04/20 09:46:18 d2.utils.events]: [0m eta: 0:11:56  iter: 319  total_loss: 0.588  loss_cls: 0.202  loss_box_reg: 0.319  loss_rpn_cls: 0.015  loss_rpn_loc: 0.055  time: 1.0366  data_time: 0.0100  lr: 0.001598  max_mem: 5405M
[32m[04/20 09:46:39 d2.utils.events]: [0m eta: 0:11:33  iter: 339  total_loss: 0.675  loss_cls: 0.230  loss_box_reg: 0.365  loss_rpn_cls: 0.020  loss_rpn_loc: 0.066  time: 1.0352  data_time: 0.0097  lr: 0.001698  max_mem: 5405M
[32m[04/20 09:47:00 d2.utils.events]: [0m eta: 0:11:12  iter: 359  total_loss: 0.665  loss_cls: 0.225  loss_box_reg: 0.340  loss_rpn_cls: 0.017  loss_rpn_loc: 0.048  time: 1.0354  data_time: 0.0097  lr: 0.001798  max_mem: 5405M
[32m[04/20 09:47:20 d2.utils.events]: [0m eta: 0:10:51  iter: 379  total_loss: 0.613  loss_cls: 0.200  loss_box_reg: 0.327  loss_rpn_cls: 0.017  loss_rpn_loc: 0.056  time: 1.0341  data_time: 0.0096  lr: 0.001898  max_mem: 5405M
[32m[04/20 09:47:41 d2.utils.events]: [0m eta: 0:10:30  iter: 399  total_loss: 0.718  loss_cls: 0.239  loss_box_reg: 0.365  loss_rpn_cls: 0.029  loss_rpn_loc: 0.061  time: 1.0347  data_time: 0.0096  lr: 0.001998  max_mem: 5405M
[32m[04/20 09:48:02 d2.utils.events]: [0m eta: 0:10:09  iter: 419  total_loss: 0.772  loss_cls: 0.245  loss_box_reg: 0.408  loss_rpn_cls: 0.022  loss_rpn_loc: 0.075  time: 1.0345  data_time: 0.0097  lr: 0.002098  max_mem: 5405M
[32m[04/20 09:48:22 d2.utils.events]: [0m eta: 0:09:46  iter: 439  total_loss: 0.649  loss_cls: 0.212  loss_box_reg: 0.320  loss_rpn_cls: 0.023  loss_rpn_loc: 0.052  time: 1.0337  data_time: 0.0099  lr: 0.002198  max_mem: 5405M
[32m[04/20 09:48:42 d2.utils.events]: [0m eta: 0:09:24  iter: 459  total_loss: 0.710  loss_cls: 0.244  loss_box_reg: 0.387  loss_rpn_cls: 0.019  loss_rpn_loc: 0.062  time: 1.0331  data_time: 0.0098  lr: 0.002298  max_mem: 5405M
[32m[04/20 09:49:03 d2.utils.events]: [0m eta: 0:09:05  iter: 479  total_loss: 0.634  loss_cls: 0.201  loss_box_reg: 0.336  loss_rpn_cls: 0.017  loss_rpn_loc: 0.057  time: 1.0339  data_time: 0.0100  lr: 0.002398  max_mem: 5405M
[32m[04/20 09:49:24 d2.utils.events]: [0m eta: 0:08:43  iter: 499  total_loss: 0.592  loss_cls: 0.195  loss_box_reg: 0.324  loss_rpn_cls: 0.019  loss_rpn_loc: 0.050  time: 1.0337  data_time: 0.0097  lr: 0.002498  max_mem: 5405M
[32m[04/20 09:49:45 d2.utils.events]: [0m eta: 0:08:24  iter: 519  total_loss: 0.715  loss_cls: 0.231  loss_box_reg: 0.390  loss_rpn_cls: 0.020  loss_rpn_loc: 0.067  time: 1.0347  data_time: 0.0097  lr: 0.002597  max_mem: 5405M
[32m[04/20 09:50:06 d2.utils.events]: [0m eta: 0:08:03  iter: 539  total_loss: 0.623  loss_cls: 0.210  loss_box_reg: 0.348  loss_rpn_cls: 0.017  loss_rpn_loc: 0.050  time: 1.0350  data_time: 0.0099  lr: 0.002697  max_mem: 5405M
[32m[04/20 09:50:27 d2.utils.events]: [0m eta: 0:07:42  iter: 559  total_loss: 0.576  loss_cls: 0.191  loss_box_reg: 0.317  loss_rpn_cls: 0.013  loss_rpn_loc: 0.055  time: 1.0350  data_time: 0.0098  lr: 0.002797  max_mem: 5405M
[32m[04/20 09:50:48 d2.utils.events]: [0m eta: 0:07:21  iter: 579  total_loss: 0.678  loss_cls: 0.215  loss_box_reg: 0.375  loss_rpn_cls: 0.019  loss_rpn_loc: 0.057  time: 1.0348  data_time: 0.0097  lr: 0.002897  max_mem: 5405M
[32m[04/20 09:51:08 d2.utils.events]: [0m eta: 0:06:59  iter: 599  total_loss: 0.713  loss_cls: 0.229  loss_box_reg: 0.384  loss_rpn_cls: 0.021  loss_rpn_loc: 0.072  time: 1.0345  data_time: 0.0098  lr: 0.002997  max_mem: 5405M
[32m[04/20 09:51:29 d2.utils.events]: [0m eta: 0:06:38  iter: 619  total_loss: 0.649  loss_cls: 0.215  loss_box_reg: 0.336  loss_rpn_cls: 0.020  loss_rpn_loc: 0.052  time: 1.0345  data_time: 0.0098  lr: 0.003097  max_mem: 5405M
[32m[04/20 09:51:50 d2.utils.events]: [0m eta: 0:06:17  iter: 639  total_loss: 0.701  loss_cls: 0.229  loss_box_reg: 0.380  loss_rpn_cls: 0.019  loss_rpn_loc: 0.059  time: 1.0342  data_time: 0.0096  lr: 0.003197  max_mem: 5405M
[32m[04/20 09:52:10 d2.utils.events]: [0m eta: 0:05:56  iter: 659  total_loss: 0.639  loss_cls: 0.209  loss_box_reg: 0.335  loss_rpn_cls: 0.017  loss_rpn_loc: 0.055  time: 1.0344  data_time: 0.0097  lr: 0.003297  max_mem: 5405M
[32m[04/20 09:52:31 d2.utils.events]: [0m eta: 0:05:35  iter: 679  total_loss: 0.580  loss_cls: 0.203  loss_box_reg: 0.323  loss_rpn_cls: 0.017  loss_rpn_loc: 0.045  time: 1.0337  data_time: 0.0097  lr: 0.003397  max_mem: 5405M
[32m[04/20 09:52:51 d2.utils.events]: [0m eta: 0:05:14  iter: 699  total_loss: 0.612  loss_cls: 0.213  loss_box_reg: 0.326  loss_rpn_cls: 0.016  loss_rpn_loc: 0.049  time: 1.0332  data_time: 0.0096  lr: 0.003497  max_mem: 5405M
[32m[04/20 09:53:11 d2.utils.events]: [0m eta: 0:04:53  iter: 719  total_loss: 0.682  loss_cls: 0.214  loss_box_reg: 0.356  loss_rpn_cls: 0.025  loss_rpn_loc: 0.058  time: 1.0329  data_time: 0.0094  lr: 0.003596  max_mem: 5405M
[32m[04/20 09:53:32 d2.utils.events]: [0m eta: 0:04:32  iter: 739  total_loss: 0.630  loss_cls: 0.208  loss_box_reg: 0.349  loss_rpn_cls: 0.017  loss_rpn_loc: 0.062  time: 1.0328  data_time: 0.0095  lr: 0.003696  max_mem: 5405M
[32m[04/20 09:53:53 d2.utils.events]: [0m eta: 0:04:11  iter: 759  total_loss: 0.613  loss_cls: 0.209  loss_box_reg: 0.332  loss_rpn_cls: 0.016  loss_rpn_loc: 0.049  time: 1.0329  data_time: 0.0097  lr: 0.003796  max_mem: 5405M
[32m[04/20 09:54:13 d2.utils.events]: [0m eta: 0:03:50  iter: 779  total_loss: 0.671  loss_cls: 0.214  loss_box_reg: 0.376  loss_rpn_cls: 0.020  loss_rpn_loc: 0.057  time: 1.0324  data_time: 0.0096  lr: 0.003896  max_mem: 5405M
[32m[04/20 09:54:34 d2.utils.events]: [0m eta: 0:03:29  iter: 799  total_loss: 0.610  loss_cls: 0.200  loss_box_reg: 0.317  loss_rpn_cls: 0.023  loss_rpn_loc: 0.056  time: 1.0324  data_time: 0.0095  lr: 0.003996  max_mem: 5405M
[32m[04/20 09:54:54 d2.utils.events]: [0m eta: 0:03:08  iter: 819  total_loss: 0.674  loss_cls: 0.207  loss_box_reg: 0.376  loss_rpn_cls: 0.016  loss_rpn_loc: 0.059  time: 1.0322  data_time: 0.0100  lr: 0.004096  max_mem: 5405M
[32m[04/20 09:55:15 d2.utils.events]: [0m eta: 0:02:47  iter: 839  total_loss: 0.582  loss_cls: 0.194  loss_box_reg: 0.328  loss_rpn_cls: 0.017  loss_rpn_loc: 0.057  time: 1.0321  data_time: 0.0095  lr: 0.004196  max_mem: 5405M
[32m[04/20 09:55:36 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.679  loss_cls: 0.233  loss_box_reg: 0.355  loss_rpn_cls: 0.023  loss_rpn_loc: 0.061  time: 1.0323  data_time: 0.0097  lr: 0.004296  max_mem: 5405M
[32m[04/20 09:55:57 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.676  loss_cls: 0.220  loss_box_reg: 0.355  loss_rpn_cls: 0.025  loss_rpn_loc: 0.060  time: 1.0322  data_time: 0.0097  lr: 0.004396  max_mem: 5405M
[32m[04/20 09:56:18 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.636  loss_cls: 0.210  loss_box_reg: 0.335  loss_rpn_cls: 0.022  loss_rpn_loc: 0.052  time: 1.0326  data_time: 0.0100  lr: 0.004496  max_mem: 5405M
[32m[04/20 09:56:38 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.744  loss_cls: 0.247  loss_box_reg: 0.390  loss_rpn_cls: 0.022  loss_rpn_loc: 0.078  time: 1.0327  data_time: 0.0098  lr: 0.004595  max_mem: 5405M
[32m[04/20 09:56:59 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.660  loss_cls: 0.232  loss_box_reg: 0.350  loss_rpn_cls: 0.022  loss_rpn_loc: 0.065  time: 1.0328  data_time: 0.0099  lr: 0.004695  max_mem: 5405M
[32m[04/20 09:57:20 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.651  loss_cls: 0.212  loss_box_reg: 0.328  loss_rpn_cls: 0.024  loss_rpn_loc: 0.060  time: 1.0329  data_time: 0.0098  lr: 0.004795  max_mem: 5405M
[32m[04/20 09:57:40 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.752  loss_cls: 0.254  loss_box_reg: 0.388  loss_rpn_cls: 0.019  loss_rpn_loc: 0.061  time: 1.0326  data_time: 0.0095  lr: 0.004895  max_mem: 5405M
[5m[31mWARNING[0m [32m[04/20 09:58:05 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 09:58:05 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 09:58:05 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 09:58:05 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.682  loss_cls: 0.239  loss_box_reg: 0.354  loss_rpn_cls: 0.021  loss_rpn_loc: 0.060  time: 1.0327  data_time: 0.0098  lr: 0.004995  max_mem: 5405M
[32m[04/20 09:58:05 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:10 (1.0337 s / it)
[32m[04/20 09:58:05 d2.engine.hooks]: [0mTotal training time: 0:17:17 (0:00:06 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 09:58:08 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 09:58:08 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 09:58:09 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 09:58:10 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1163 s / img. ETA=0:16:26
[32m[04/20 09:58:15 d2.evaluation.evaluator]: [0mInference done 54/8355. 0.1162 s / img. ETA=0:16:23
[32m[04/20 09:58:21 d2.evaluation.evaluator]: [0mInference done 97/8355. 0.1160 s / img. ETA=0:16:16
[32m[04/20 09:58:26 d2.evaluation.evaluator]: [0mInference done 140/8355. 0.1160 s / img. ETA=0:16:11
[32m[04/20 09:58:31 d2.evaluation.evaluator]: [0mInference done 183/8355. 0.1159 s / img. ETA=0:16:05
[32m[04/20 09:58:36 d2.evaluation.evaluator]: [0mInference done 226/8355. 0.1160 s / img. ETA=0:16:01
[32m[04/20 09:58:41 d2.evaluation.evaluator]: [0mInference done 269/8355. 0.1160 s / img. ETA=0:15:55
[32m[04/20 09:58:46 d2.evaluation.evaluator]: [0mInference done 312/8355. 0.1160 s / img. ETA=0:15:51
[32m[04/20 09:58:51 d2.evaluation.evaluator]: [0mInference done 355/8355. 0.1160 s / img. ETA=0:15:45
[32m[04/20 09:58:56 d2.evaluation.evaluator]: [0mInference done 398/8355. 0.1160 s / img. ETA=0:15:40
[32m[04/20 09:59:01 d2.evaluation.evaluator]: [0mInference done 441/8355. 0.1160 s / img. ETA=0:15:35
[32m[04/20 09:59:06 d2.evaluation.evaluator]: [0mInference done 484/8355. 0.1160 s / img. ETA=0:15:30
[32m[04/20 09:59:11 d2.evaluation.evaluator]: [0mInference done 527/8355. 0.1159 s / img. ETA=0:15:24
[32m[04/20 09:59:16 d2.evaluation.evaluator]: [0mInference done 570/8355. 0.1159 s / img. ETA=0:15:19
[32m[04/20 09:59:21 d2.evaluation.evaluator]: [0mInference done 613/8355. 0.1159 s / img. ETA=0:15:14
[32m[04/20 09:59:27 d2.evaluation.evaluator]: [0mInference done 656/8355. 0.1159 s / img. ETA=0:15:09
[32m[04/20 09:59:32 d2.evaluation.evaluator]: [0mInference done 699/8355. 0.1160 s / img. ETA=0:15:04
[32m[04/20 09:59:37 d2.evaluation.evaluator]: [0mInference done 742/8355. 0.1160 s / img. ETA=0:14:59
[32m[04/20 09:59:42 d2.evaluation.evaluator]: [0mInference done 785/8355. 0.1160 s / img. ETA=0:14:54
[32m[04/20 09:59:47 d2.evaluation.evaluator]: [0mInference done 828/8355. 0.1160 s / img. ETA=0:14:49
[32m[04/20 09:59:52 d2.evaluation.evaluator]: [0mInference done 871/8355. 0.1159 s / img. ETA=0:14:44
[32m[04/20 09:59:57 d2.evaluation.evaluator]: [0mInference done 914/8355. 0.1160 s / img. ETA=0:14:39
[32m[04/20 10:00:02 d2.evaluation.evaluator]: [0mInference done 957/8355. 0.1160 s / img. ETA=0:14:34
[32m[04/20 10:00:07 d2.evaluation.evaluator]: [0mInference done 1000/8355. 0.1160 s / img. ETA=0:14:29
[32m[04/20 10:00:12 d2.evaluation.evaluator]: [0mInference done 1043/8355. 0.1160 s / img. ETA=0:14:24
[32m[04/20 10:00:17 d2.evaluation.evaluator]: [0mInference done 1086/8355. 0.1159 s / img. ETA=0:14:18
[32m[04/20 10:00:22 d2.evaluation.evaluator]: [0mInference done 1129/8355. 0.1159 s / img. ETA=0:14:13
[32m[04/20 10:00:28 d2.evaluation.evaluator]: [0mInference done 1172/8355. 0.1159 s / img. ETA=0:14:08
[32m[04/20 10:00:33 d2.evaluation.evaluator]: [0mInference done 1215/8355. 0.1159 s / img. ETA=0:14:03
[32m[04/20 10:00:38 d2.evaluation.evaluator]: [0mInference done 1258/8355. 0.1159 s / img. ETA=0:13:58
[32m[04/20 10:00:43 d2.evaluation.evaluator]: [0mInference done 1301/8355. 0.1159 s / img. ETA=0:13:53
[32m[04/20 10:00:48 d2.evaluation.evaluator]: [0mInference done 1344/8355. 0.1159 s / img. ETA=0:13:47
[32m[04/20 10:00:53 d2.evaluation.evaluator]: [0mInference done 1387/8355. 0.1159 s / img. ETA=0:13:42
[32m[04/20 10:00:58 d2.evaluation.evaluator]: [0mInference done 1430/8355. 0.1158 s / img. ETA=0:13:37
[32m[04/20 10:01:03 d2.evaluation.evaluator]: [0mInference done 1473/8355. 0.1158 s / img. ETA=0:13:32
[32m[04/20 10:01:08 d2.evaluation.evaluator]: [0mInference done 1515/8355. 0.1159 s / img. ETA=0:13:27
[32m[04/20 10:01:13 d2.evaluation.evaluator]: [0mInference done 1557/8355. 0.1159 s / img. ETA=0:13:23
[32m[04/20 10:01:18 d2.evaluation.evaluator]: [0mInference done 1599/8355. 0.1159 s / img. ETA=0:13:18
[32m[04/20 10:01:23 d2.evaluation.evaluator]: [0mInference done 1641/8355. 0.1160 s / img. ETA=0:13:13
[32m[04/20 10:01:28 d2.evaluation.evaluator]: [0mInference done 1683/8355. 0.1160 s / img. ETA=0:13:08
[32m[04/20 10:01:33 d2.evaluation.evaluator]: [0mInference done 1725/8355. 0.1160 s / img. ETA=0:13:04
[32m[04/20 10:01:38 d2.evaluation.evaluator]: [0mInference done 1767/8355. 0.1160 s / img. ETA=0:12:59
[32m[04/20 10:01:43 d2.evaluation.evaluator]: [0mInference done 1809/8355. 0.1161 s / img. ETA=0:12:54
[32m[04/20 10:01:48 d2.evaluation.evaluator]: [0mInference done 1851/8355. 0.1161 s / img. ETA=0:12:49
[32m[04/20 10:01:53 d2.evaluation.evaluator]: [0mInference done 1893/8355. 0.1161 s / img. ETA=0:12:44
[32m[04/20 10:01:58 d2.evaluation.evaluator]: [0mInference done 1936/8355. 0.1161 s / img. ETA=0:12:39
[32m[04/20 10:02:03 d2.evaluation.evaluator]: [0mInference done 1979/8355. 0.1161 s / img. ETA=0:12:34
[32m[04/20 10:02:08 d2.evaluation.evaluator]: [0mInference done 2022/8355. 0.1161 s / img. ETA=0:12:29
[32m[04/20 10:02:14 d2.evaluation.evaluator]: [0mInference done 2065/8355. 0.1161 s / img. ETA=0:12:24
[32m[04/20 10:02:19 d2.evaluation.evaluator]: [0mInference done 2108/8355. 0.1161 s / img. ETA=0:12:19
[32m[04/20 10:02:24 d2.evaluation.evaluator]: [0mInference done 2151/8355. 0.1161 s / img. ETA=0:12:14
[32m[04/20 10:02:29 d2.evaluation.evaluator]: [0mInference done 2193/8355. 0.1162 s / img. ETA=0:12:09
[32m[04/20 10:02:34 d2.evaluation.evaluator]: [0mInference done 2236/8355. 0.1162 s / img. ETA=0:12:04
[32m[04/20 10:02:39 d2.evaluation.evaluator]: [0mInference done 2278/8355. 0.1162 s / img. ETA=0:11:59
[32m[04/20 10:02:44 d2.evaluation.evaluator]: [0mInference done 2321/8355. 0.1162 s / img. ETA=0:11:54
[32m[04/20 10:02:49 d2.evaluation.evaluator]: [0mInference done 2364/8355. 0.1162 s / img. ETA=0:11:49
[32m[04/20 10:02:54 d2.evaluation.evaluator]: [0mInference done 2407/8355. 0.1162 s / img. ETA=0:11:44
[32m[04/20 10:02:59 d2.evaluation.evaluator]: [0mInference done 2449/8355. 0.1162 s / img. ETA=0:11:39
[32m[04/20 10:03:04 d2.evaluation.evaluator]: [0mInference done 2492/8355. 0.1162 s / img. ETA=0:11:34
[32m[04/20 10:03:09 d2.evaluation.evaluator]: [0mInference done 2534/8355. 0.1162 s / img. ETA=0:11:29
[32m[04/20 10:03:15 d2.evaluation.evaluator]: [0mInference done 2577/8355. 0.1162 s / img. ETA=0:11:24
[32m[04/20 10:03:20 d2.evaluation.evaluator]: [0mInference done 2619/8355. 0.1162 s / img. ETA=0:11:19
[32m[04/20 10:03:25 d2.evaluation.evaluator]: [0mInference done 2661/8355. 0.1162 s / img. ETA=0:11:14
[32m[04/20 10:03:30 d2.evaluation.evaluator]: [0mInference done 2703/8355. 0.1162 s / img. ETA=0:11:10
[32m[04/20 10:03:35 d2.evaluation.evaluator]: [0mInference done 2746/8355. 0.1163 s / img. ETA=0:11:05
[32m[04/20 10:03:40 d2.evaluation.evaluator]: [0mInference done 2789/8355. 0.1163 s / img. ETA=0:10:59
[32m[04/20 10:03:45 d2.evaluation.evaluator]: [0mInference done 2831/8355. 0.1163 s / img. ETA=0:10:55
[32m[04/20 10:03:50 d2.evaluation.evaluator]: [0mInference done 2874/8355. 0.1163 s / img. ETA=0:10:49
[32m[04/20 10:03:55 d2.evaluation.evaluator]: [0mInference done 2917/8355. 0.1163 s / img. ETA=0:10:44
[32m[04/20 10:04:00 d2.evaluation.evaluator]: [0mInference done 2959/8355. 0.1163 s / img. ETA=0:10:39
[32m[04/20 10:04:05 d2.evaluation.evaluator]: [0mInference done 3002/8355. 0.1163 s / img. ETA=0:10:34
[32m[04/20 10:04:10 d2.evaluation.evaluator]: [0mInference done 3045/8355. 0.1163 s / img. ETA=0:10:29
[32m[04/20 10:04:15 d2.evaluation.evaluator]: [0mInference done 3088/8355. 0.1163 s / img. ETA=0:10:24
[32m[04/20 10:04:20 d2.evaluation.evaluator]: [0mInference done 3131/8355. 0.1163 s / img. ETA=0:10:19
[32m[04/20 10:04:25 d2.evaluation.evaluator]: [0mInference done 3174/8355. 0.1163 s / img. ETA=0:10:14
[32m[04/20 10:04:31 d2.evaluation.evaluator]: [0mInference done 3217/8355. 0.1163 s / img. ETA=0:10:09
[32m[04/20 10:04:36 d2.evaluation.evaluator]: [0mInference done 3260/8355. 0.1163 s / img. ETA=0:10:04
[32m[04/20 10:04:41 d2.evaluation.evaluator]: [0mInference done 3302/8355. 0.1163 s / img. ETA=0:09:59
[32m[04/20 10:04:46 d2.evaluation.evaluator]: [0mInference done 3345/8355. 0.1163 s / img. ETA=0:09:54
[32m[04/20 10:04:51 d2.evaluation.evaluator]: [0mInference done 3388/8355. 0.1163 s / img. ETA=0:09:49
[32m[04/20 10:04:56 d2.evaluation.evaluator]: [0mInference done 3430/8355. 0.1163 s / img. ETA=0:09:44
[32m[04/20 10:05:01 d2.evaluation.evaluator]: [0mInference done 3473/8355. 0.1163 s / img. ETA=0:09:39
[32m[04/20 10:05:06 d2.evaluation.evaluator]: [0mInference done 3515/8355. 0.1163 s / img. ETA=0:09:34
[32m[04/20 10:05:11 d2.evaluation.evaluator]: [0mInference done 3558/8355. 0.1163 s / img. ETA=0:09:28
[32m[04/20 10:05:16 d2.evaluation.evaluator]: [0mInference done 3601/8355. 0.1163 s / img. ETA=0:09:23
[32m[04/20 10:05:21 d2.evaluation.evaluator]: [0mInference done 3644/8355. 0.1163 s / img. ETA=0:09:18
[32m[04/20 10:05:26 d2.evaluation.evaluator]: [0mInference done 3687/8355. 0.1163 s / img. ETA=0:09:13
[32m[04/20 10:05:31 d2.evaluation.evaluator]: [0mInference done 3730/8355. 0.1163 s / img. ETA=0:09:08
[32m[04/20 10:05:37 d2.evaluation.evaluator]: [0mInference done 3773/8355. 0.1163 s / img. ETA=0:09:03
[32m[04/20 10:05:42 d2.evaluation.evaluator]: [0mInference done 3815/8355. 0.1163 s / img. ETA=0:08:58
[32m[04/20 10:05:47 d2.evaluation.evaluator]: [0mInference done 3857/8355. 0.1163 s / img. ETA=0:08:53
[32m[04/20 10:05:52 d2.evaluation.evaluator]: [0mInference done 3900/8355. 0.1163 s / img. ETA=0:08:48
[32m[04/20 10:05:57 d2.evaluation.evaluator]: [0mInference done 3943/8355. 0.1163 s / img. ETA=0:08:43
[32m[04/20 10:06:02 d2.evaluation.evaluator]: [0mInference done 3986/8355. 0.1163 s / img. ETA=0:08:38
[32m[04/20 10:06:07 d2.evaluation.evaluator]: [0mInference done 4028/8355. 0.1163 s / img. ETA=0:08:33
[32m[04/20 10:06:12 d2.evaluation.evaluator]: [0mInference done 4071/8355. 0.1163 s / img. ETA=0:08:28
[32m[04/20 10:06:17 d2.evaluation.evaluator]: [0mInference done 4113/8355. 0.1163 s / img. ETA=0:08:23
[32m[04/20 10:06:22 d2.evaluation.evaluator]: [0mInference done 4155/8355. 0.1163 s / img. ETA=0:08:18
[32m[04/20 10:06:27 d2.evaluation.evaluator]: [0mInference done 4197/8355. 0.1163 s / img. ETA=0:08:13
[32m[04/20 10:06:32 d2.evaluation.evaluator]: [0mInference done 4240/8355. 0.1163 s / img. ETA=0:08:08
[32m[04/20 10:06:37 d2.evaluation.evaluator]: [0mInference done 4283/8355. 0.1163 s / img. ETA=0:08:03
[32m[04/20 10:06:42 d2.evaluation.evaluator]: [0mInference done 4326/8355. 0.1163 s / img. ETA=0:07:58
[32m[04/20 10:06:47 d2.evaluation.evaluator]: [0mInference done 4369/8355. 0.1163 s / img. ETA=0:07:52
[32m[04/20 10:06:52 d2.evaluation.evaluator]: [0mInference done 4411/8355. 0.1163 s / img. ETA=0:07:47
[32m[04/20 10:06:58 d2.evaluation.evaluator]: [0mInference done 4454/8355. 0.1163 s / img. ETA=0:07:42
[32m[04/20 10:07:03 d2.evaluation.evaluator]: [0mInference done 4497/8355. 0.1163 s / img. ETA=0:07:37
[32m[04/20 10:07:08 d2.evaluation.evaluator]: [0mInference done 4539/8355. 0.1163 s / img. ETA=0:07:32
[32m[04/20 10:07:13 d2.evaluation.evaluator]: [0mInference done 4581/8355. 0.1163 s / img. ETA=0:07:27
[32m[04/20 10:07:18 d2.evaluation.evaluator]: [0mInference done 4624/8355. 0.1163 s / img. ETA=0:07:22
[32m[04/20 10:07:23 d2.evaluation.evaluator]: [0mInference done 4667/8355. 0.1163 s / img. ETA=0:07:17
[32m[04/20 10:07:28 d2.evaluation.evaluator]: [0mInference done 4710/8355. 0.1163 s / img. ETA=0:07:12
[32m[04/20 10:07:33 d2.evaluation.evaluator]: [0mInference done 4753/8355. 0.1163 s / img. ETA=0:07:07
[32m[04/20 10:07:38 d2.evaluation.evaluator]: [0mInference done 4795/8355. 0.1163 s / img. ETA=0:07:02
[32m[04/20 10:07:43 d2.evaluation.evaluator]: [0mInference done 4837/8355. 0.1163 s / img. ETA=0:06:57
[32m[04/20 10:07:48 d2.evaluation.evaluator]: [0mInference done 4879/8355. 0.1163 s / img. ETA=0:06:52
[32m[04/20 10:07:53 d2.evaluation.evaluator]: [0mInference done 4921/8355. 0.1163 s / img. ETA=0:06:47
[32m[04/20 10:07:58 d2.evaluation.evaluator]: [0mInference done 4963/8355. 0.1163 s / img. ETA=0:06:42
[32m[04/20 10:08:03 d2.evaluation.evaluator]: [0mInference done 5005/8355. 0.1163 s / img. ETA=0:06:37
[32m[04/20 10:08:08 d2.evaluation.evaluator]: [0mInference done 5047/8355. 0.1163 s / img. ETA=0:06:32
[32m[04/20 10:08:13 d2.evaluation.evaluator]: [0mInference done 5089/8355. 0.1163 s / img. ETA=0:06:27
[32m[04/20 10:08:18 d2.evaluation.evaluator]: [0mInference done 5131/8355. 0.1164 s / img. ETA=0:06:22
[32m[04/20 10:08:23 d2.evaluation.evaluator]: [0mInference done 5173/8355. 0.1164 s / img. ETA=0:06:17
[32m[04/20 10:08:28 d2.evaluation.evaluator]: [0mInference done 5215/8355. 0.1164 s / img. ETA=0:06:12
[32m[04/20 10:08:33 d2.evaluation.evaluator]: [0mInference done 5258/8355. 0.1164 s / img. ETA=0:06:07
[32m[04/20 10:08:38 d2.evaluation.evaluator]: [0mInference done 5300/8355. 0.1164 s / img. ETA=0:06:02
[32m[04/20 10:08:43 d2.evaluation.evaluator]: [0mInference done 5342/8355. 0.1164 s / img. ETA=0:05:57
[32m[04/20 10:08:49 d2.evaluation.evaluator]: [0mInference done 5384/8355. 0.1164 s / img. ETA=0:05:52
[32m[04/20 10:08:54 d2.evaluation.evaluator]: [0mInference done 5427/8355. 0.1164 s / img. ETA=0:05:47
[32m[04/20 10:08:59 d2.evaluation.evaluator]: [0mInference done 5469/8355. 0.1164 s / img. ETA=0:05:42
[32m[04/20 10:09:04 d2.evaluation.evaluator]: [0mInference done 5512/8355. 0.1164 s / img. ETA=0:05:37
[32m[04/20 10:09:09 d2.evaluation.evaluator]: [0mInference done 5555/8355. 0.1164 s / img. ETA=0:05:32
[32m[04/20 10:09:14 d2.evaluation.evaluator]: [0mInference done 5598/8355. 0.1164 s / img. ETA=0:05:27
[32m[04/20 10:09:19 d2.evaluation.evaluator]: [0mInference done 5640/8355. 0.1164 s / img. ETA=0:05:22
[32m[04/20 10:09:24 d2.evaluation.evaluator]: [0mInference done 5682/8355. 0.1164 s / img. ETA=0:05:17
[32m[04/20 10:09:29 d2.evaluation.evaluator]: [0mInference done 5724/8355. 0.1164 s / img. ETA=0:05:12
[32m[04/20 10:09:34 d2.evaluation.evaluator]: [0mInference done 5766/8355. 0.1164 s / img. ETA=0:05:07
[32m[04/20 10:09:39 d2.evaluation.evaluator]: [0mInference done 5808/8355. 0.1164 s / img. ETA=0:05:02
[32m[04/20 10:09:44 d2.evaluation.evaluator]: [0mInference done 5850/8355. 0.1164 s / img. ETA=0:04:57
[32m[04/20 10:09:49 d2.evaluation.evaluator]: [0mInference done 5892/8355. 0.1164 s / img. ETA=0:04:52
[32m[04/20 10:09:54 d2.evaluation.evaluator]: [0mInference done 5934/8355. 0.1164 s / img. ETA=0:04:47
[32m[04/20 10:09:59 d2.evaluation.evaluator]: [0mInference done 5976/8355. 0.1165 s / img. ETA=0:04:42
[32m[04/20 10:10:04 d2.evaluation.evaluator]: [0mInference done 6018/8355. 0.1165 s / img. ETA=0:04:37
[32m[04/20 10:10:09 d2.evaluation.evaluator]: [0mInference done 6060/8355. 0.1165 s / img. ETA=0:04:32
[32m[04/20 10:10:14 d2.evaluation.evaluator]: [0mInference done 6102/8355. 0.1165 s / img. ETA=0:04:27
[32m[04/20 10:10:20 d2.evaluation.evaluator]: [0mInference done 6144/8355. 0.1165 s / img. ETA=0:04:22
[32m[04/20 10:10:25 d2.evaluation.evaluator]: [0mInference done 6186/8355. 0.1165 s / img. ETA=0:04:17
[32m[04/20 10:10:30 d2.evaluation.evaluator]: [0mInference done 6228/8355. 0.1165 s / img. ETA=0:04:12
[32m[04/20 10:10:35 d2.evaluation.evaluator]: [0mInference done 6270/8355. 0.1165 s / img. ETA=0:04:07
[32m[04/20 10:10:40 d2.evaluation.evaluator]: [0mInference done 6312/8355. 0.1165 s / img. ETA=0:04:02
[32m[04/20 10:10:45 d2.evaluation.evaluator]: [0mInference done 6354/8355. 0.1165 s / img. ETA=0:03:58
[32m[04/20 10:10:50 d2.evaluation.evaluator]: [0mInference done 6396/8355. 0.1165 s / img. ETA=0:03:53
[32m[04/20 10:10:55 d2.evaluation.evaluator]: [0mInference done 6438/8355. 0.1165 s / img. ETA=0:03:48
[32m[04/20 10:11:00 d2.evaluation.evaluator]: [0mInference done 6480/8355. 0.1166 s / img. ETA=0:03:43
[32m[04/20 10:11:05 d2.evaluation.evaluator]: [0mInference done 6523/8355. 0.1166 s / img. ETA=0:03:37
[32m[04/20 10:11:10 d2.evaluation.evaluator]: [0mInference done 6566/8355. 0.1165 s / img. ETA=0:03:32
[32m[04/20 10:11:15 d2.evaluation.evaluator]: [0mInference done 6608/8355. 0.1166 s / img. ETA=0:03:27
[32m[04/20 10:11:20 d2.evaluation.evaluator]: [0mInference done 6651/8355. 0.1165 s / img. ETA=0:03:22
[32m[04/20 10:11:25 d2.evaluation.evaluator]: [0mInference done 6694/8355. 0.1165 s / img. ETA=0:03:17
[32m[04/20 10:11:30 d2.evaluation.evaluator]: [0mInference done 6737/8355. 0.1165 s / img. ETA=0:03:12
[32m[04/20 10:11:36 d2.evaluation.evaluator]: [0mInference done 6780/8355. 0.1165 s / img. ETA=0:03:07
[32m[04/20 10:11:41 d2.evaluation.evaluator]: [0mInference done 6822/8355. 0.1165 s / img. ETA=0:03:02
[32m[04/20 10:11:46 d2.evaluation.evaluator]: [0mInference done 6864/8355. 0.1165 s / img. ETA=0:02:57
[32m[04/20 10:11:51 d2.evaluation.evaluator]: [0mInference done 6906/8355. 0.1165 s / img. ETA=0:02:52
[32m[04/20 10:11:56 d2.evaluation.evaluator]: [0mInference done 6948/8355. 0.1165 s / img. ETA=0:02:47
[32m[04/20 10:12:01 d2.evaluation.evaluator]: [0mInference done 6990/8355. 0.1165 s / img. ETA=0:02:42
[32m[04/20 10:12:06 d2.evaluation.evaluator]: [0mInference done 7032/8355. 0.1166 s / img. ETA=0:02:37
[32m[04/20 10:12:11 d2.evaluation.evaluator]: [0mInference done 7074/8355. 0.1166 s / img. ETA=0:02:32
[32m[04/20 10:12:16 d2.evaluation.evaluator]: [0mInference done 7116/8355. 0.1166 s / img. ETA=0:02:27
[32m[04/20 10:12:21 d2.evaluation.evaluator]: [0mInference done 7158/8355. 0.1166 s / img. ETA=0:02:22
[32m[04/20 10:12:26 d2.evaluation.evaluator]: [0mInference done 7200/8355. 0.1166 s / img. ETA=0:02:17
[32m[04/20 10:12:31 d2.evaluation.evaluator]: [0mInference done 7242/8355. 0.1166 s / img. ETA=0:02:12
[32m[04/20 10:12:36 d2.evaluation.evaluator]: [0mInference done 7284/8355. 0.1166 s / img. ETA=0:02:07
[32m[04/20 10:12:41 d2.evaluation.evaluator]: [0mInference done 7326/8355. 0.1166 s / img. ETA=0:02:02
[32m[04/20 10:12:46 d2.evaluation.evaluator]: [0mInference done 7368/8355. 0.1166 s / img. ETA=0:01:57
[32m[04/20 10:12:51 d2.evaluation.evaluator]: [0mInference done 7410/8355. 0.1166 s / img. ETA=0:01:52
[32m[04/20 10:12:56 d2.evaluation.evaluator]: [0mInference done 7452/8355. 0.1166 s / img. ETA=0:01:47
[32m[04/20 10:13:01 d2.evaluation.evaluator]: [0mInference done 7494/8355. 0.1166 s / img. ETA=0:01:42
[32m[04/20 10:13:06 d2.evaluation.evaluator]: [0mInference done 7536/8355. 0.1166 s / img. ETA=0:01:37
[32m[04/20 10:13:11 d2.evaluation.evaluator]: [0mInference done 7578/8355. 0.1166 s / img. ETA=0:01:32
[32m[04/20 10:13:16 d2.evaluation.evaluator]: [0mInference done 7620/8355. 0.1166 s / img. ETA=0:01:27
[32m[04/20 10:13:21 d2.evaluation.evaluator]: [0mInference done 7662/8355. 0.1166 s / img. ETA=0:01:22
[32m[04/20 10:13:26 d2.evaluation.evaluator]: [0mInference done 7704/8355. 0.1167 s / img. ETA=0:01:17
[32m[04/20 10:13:31 d2.evaluation.evaluator]: [0mInference done 7746/8355. 0.1167 s / img. ETA=0:01:12
[32m[04/20 10:13:36 d2.evaluation.evaluator]: [0mInference done 7788/8355. 0.1167 s / img. ETA=0:01:07
[32m[04/20 10:13:41 d2.evaluation.evaluator]: [0mInference done 7830/8355. 0.1167 s / img. ETA=0:01:02
[32m[04/20 10:13:47 d2.evaluation.evaluator]: [0mInference done 7872/8355. 0.1167 s / img. ETA=0:00:57
[32m[04/20 10:13:52 d2.evaluation.evaluator]: [0mInference done 7914/8355. 0.1167 s / img. ETA=0:00:52
[32m[04/20 10:13:57 d2.evaluation.evaluator]: [0mInference done 7956/8355. 0.1167 s / img. ETA=0:00:47
[32m[04/20 10:14:02 d2.evaluation.evaluator]: [0mInference done 7998/8355. 0.1167 s / img. ETA=0:00:42
[32m[04/20 10:14:07 d2.evaluation.evaluator]: [0mInference done 8041/8355. 0.1167 s / img. ETA=0:00:37
[32m[04/20 10:14:12 d2.evaluation.evaluator]: [0mInference done 8084/8355. 0.1167 s / img. ETA=0:00:32
[32m[04/20 10:14:17 d2.evaluation.evaluator]: [0mInference done 8127/8355. 0.1167 s / img. ETA=0:00:27
[32m[04/20 10:14:22 d2.evaluation.evaluator]: [0mInference done 8170/8355. 0.1167 s / img. ETA=0:00:22
[32m[04/20 10:14:27 d2.evaluation.evaluator]: [0mInference done 8212/8355. 0.1167 s / img. ETA=0:00:17
[32m[04/20 10:14:32 d2.evaluation.evaluator]: [0mInference done 8254/8355. 0.1167 s / img. ETA=0:00:12
[32m[04/20 10:14:37 d2.evaluation.evaluator]: [0mInference done 8296/8355. 0.1167 s / img. ETA=0:00:07
[32m[04/20 10:14:42 d2.evaluation.evaluator]: [0mInference done 8338/8355. 0.1167 s / img. ETA=0:00:02
[32m[04/20 10:14:44 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:34.615107 (0.119116 s / img per device, on 1 devices)
[32m[04/20 10:14:44 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:14 (0.116694 s / img per device, on 1 devices)
[32m[04/20 10:14:45 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 10:14:45 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 10:14:45 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.43s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=18.09s).
Accumulating evaluation results...
DONE (t=2.02s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.587
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.284
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.206
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.433
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.603
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.125
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.261
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.487
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.649
[32m[04/20 10:15:05 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 31.141 | 58.689 | 28.382 | 20.591 | 43.337 | 60.302 |
[32m[04/20 10:15:05 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 35.613 | bicycle       | 15.874 | car            | 41.937 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 10:15:06 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 10:15:06 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 10:15:07 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 10:15:08 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1177 s / img. ETA=0:02:29
[32m[04/20 10:15:13 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1167 s / img. ETA=0:02:23
[32m[04/20 10:15:18 d2.evaluation.evaluator]: [0mInference done 97/1257. 0.1166 s / img. ETA=0:02:18
[32m[04/20 10:15:23 d2.evaluation.evaluator]: [0mInference done 139/1257. 0.1166 s / img. ETA=0:02:13
[32m[04/20 10:15:28 d2.evaluation.evaluator]: [0mInference done 182/1257. 0.1166 s / img. ETA=0:02:07
[32m[04/20 10:15:33 d2.evaluation.evaluator]: [0mInference done 225/1257. 0.1166 s / img. ETA=0:02:02
[32m[04/20 10:15:39 d2.evaluation.evaluator]: [0mInference done 267/1257. 0.1166 s / img. ETA=0:01:57
[32m[04/20 10:15:44 d2.evaluation.evaluator]: [0mInference done 310/1257. 0.1166 s / img. ETA=0:01:52
[32m[04/20 10:15:49 d2.evaluation.evaluator]: [0mInference done 353/1257. 0.1165 s / img. ETA=0:01:47
[32m[04/20 10:15:54 d2.evaluation.evaluator]: [0mInference done 396/1257. 0.1165 s / img. ETA=0:01:42
[32m[04/20 10:15:59 d2.evaluation.evaluator]: [0mInference done 438/1257. 0.1165 s / img. ETA=0:01:37
[32m[04/20 10:16:04 d2.evaluation.evaluator]: [0mInference done 480/1257. 0.1166 s / img. ETA=0:01:32
[32m[04/20 10:16:09 d2.evaluation.evaluator]: [0mInference done 522/1257. 0.1167 s / img. ETA=0:01:27
[32m[04/20 10:16:14 d2.evaluation.evaluator]: [0mInference done 564/1257. 0.1167 s / img. ETA=0:01:22
[32m[04/20 10:16:19 d2.evaluation.evaluator]: [0mInference done 606/1257. 0.1167 s / img. ETA=0:01:17
[32m[04/20 10:16:24 d2.evaluation.evaluator]: [0mInference done 648/1257. 0.1168 s / img. ETA=0:01:12
[32m[04/20 10:16:29 d2.evaluation.evaluator]: [0mInference done 690/1257. 0.1168 s / img. ETA=0:01:07
[32m[04/20 10:16:34 d2.evaluation.evaluator]: [0mInference done 732/1257. 0.1169 s / img. ETA=0:01:02
[32m[04/20 10:16:39 d2.evaluation.evaluator]: [0mInference done 775/1257. 0.1169 s / img. ETA=0:00:57
[32m[04/20 10:16:44 d2.evaluation.evaluator]: [0mInference done 817/1257. 0.1168 s / img. ETA=0:00:52
[32m[04/20 10:16:49 d2.evaluation.evaluator]: [0mInference done 859/1257. 0.1169 s / img. ETA=0:00:47
[32m[04/20 10:16:54 d2.evaluation.evaluator]: [0mInference done 901/1257. 0.1169 s / img. ETA=0:00:42
[32m[04/20 10:16:59 d2.evaluation.evaluator]: [0mInference done 943/1257. 0.1169 s / img. ETA=0:00:37
[32m[04/20 10:17:04 d2.evaluation.evaluator]: [0mInference done 985/1257. 0.1169 s / img. ETA=0:00:32
[32m[04/20 10:17:09 d2.evaluation.evaluator]: [0mInference done 1028/1257. 0.1168 s / img. ETA=0:00:27
[32m[04/20 10:17:14 d2.evaluation.evaluator]: [0mInference done 1070/1257. 0.1168 s / img. ETA=0:00:22
[32m[04/20 10:17:19 d2.evaluation.evaluator]: [0mInference done 1112/1257. 0.1168 s / img. ETA=0:00:17
[32m[04/20 10:17:24 d2.evaluation.evaluator]: [0mInference done 1154/1257. 0.1168 s / img. ETA=0:00:12
[32m[04/20 10:17:29 d2.evaluation.evaluator]: [0mInference done 1196/1257. 0.1168 s / img. ETA=0:00:07
[32m[04/20 10:17:34 d2.evaluation.evaluator]: [0mInference done 1238/1257. 0.1168 s / img. ETA=0:00:02
[32m[04/20 10:17:37 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:29.440925 (0.119362 s / img per device, on 1 devices)
[32m[04/20 10:17:37 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:26 (0.116833 s / img per device, on 1 devices)
[32m[04/20 10:17:37 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 10:17:37 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 10:17:37 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.33s).
Accumulating evaluation results...
DONE (t=0.33s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.265
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.506
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.247
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.321
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.467
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.126
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.371
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.514
[32m[04/20 10:17:40 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 26.451 | 50.565 | 24.670 | 16.025 | 32.125 | 46.728 |
[32m[04/20 10:17:40 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 29.211 | bicycle       | 7.816 | car            | 42.325 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | nan   | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  8  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 10:17:40 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 10:17:41 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 10:17:41 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 10:17:41 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 10:17:41 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 10:17:41 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 10:17:41 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 10:18:02 d2.utils.events]: [0m eta: 0:17:20  iter: 19  total_loss: 0.684  loss_cls: 0.227  loss_box_reg: 0.375  loss_rpn_cls: 0.016  loss_rpn_loc: 0.078  time: 1.0471  data_time: 0.0301  lr: 0.000100  max_mem: 5405M
[32m[04/20 10:18:23 d2.utils.events]: [0m eta: 0:16:48  iter: 39  total_loss: 0.730  loss_cls: 0.239  loss_box_reg: 0.383  loss_rpn_cls: 0.017  loss_rpn_loc: 0.056  time: 1.0330  data_time: 0.0097  lr: 0.000200  max_mem: 5405M
[32m[04/20 10:18:43 d2.utils.events]: [0m eta: 0:16:13  iter: 59  total_loss: 0.614  loss_cls: 0.208  loss_box_reg: 0.353  loss_rpn_cls: 0.016  loss_rpn_loc: 0.057  time: 1.0270  data_time: 0.0098  lr: 0.000300  max_mem: 5405M
[32m[04/20 10:19:04 d2.utils.events]: [0m eta: 0:15:44  iter: 79  total_loss: 0.625  loss_cls: 0.200  loss_box_reg: 0.345  loss_rpn_cls: 0.015  loss_rpn_loc: 0.044  time: 1.0279  data_time: 0.0098  lr: 0.000400  max_mem: 5405M
[32m[04/20 10:19:25 d2.utils.events]: [0m eta: 0:15:21  iter: 99  total_loss: 0.574  loss_cls: 0.184  loss_box_reg: 0.298  loss_rpn_cls: 0.015  loss_rpn_loc: 0.047  time: 1.0283  data_time: 0.0098  lr: 0.000500  max_mem: 5405M
[32m[04/20 10:19:45 d2.utils.events]: [0m eta: 0:14:59  iter: 119  total_loss: 0.599  loss_cls: 0.206  loss_box_reg: 0.337  loss_rpn_cls: 0.021  loss_rpn_loc: 0.061  time: 1.0279  data_time: 0.0097  lr: 0.000599  max_mem: 5405M
[32m[04/20 10:20:06 d2.utils.events]: [0m eta: 0:14:42  iter: 139  total_loss: 0.594  loss_cls: 0.195  loss_box_reg: 0.323  loss_rpn_cls: 0.017  loss_rpn_loc: 0.052  time: 1.0293  data_time: 0.0097  lr: 0.000699  max_mem: 5405M
[32m[04/20 10:20:27 d2.utils.events]: [0m eta: 0:14:22  iter: 159  total_loss: 0.634  loss_cls: 0.203  loss_box_reg: 0.362  loss_rpn_cls: 0.023  loss_rpn_loc: 0.049  time: 1.0298  data_time: 0.0096  lr: 0.000799  max_mem: 5405M
[32m[04/20 10:20:48 d2.utils.events]: [0m eta: 0:14:07  iter: 179  total_loss: 0.638  loss_cls: 0.199  loss_box_reg: 0.374  loss_rpn_cls: 0.017  loss_rpn_loc: 0.047  time: 1.0315  data_time: 0.0098  lr: 0.000899  max_mem: 5405M
[32m[04/20 10:21:08 d2.utils.events]: [0m eta: 0:13:51  iter: 199  total_loss: 0.701  loss_cls: 0.229  loss_box_reg: 0.388  loss_rpn_cls: 0.017  loss_rpn_loc: 0.046  time: 1.0320  data_time: 0.0096  lr: 0.000999  max_mem: 5405M
[32m[04/20 10:21:28 d2.utils.events]: [0m eta: 0:13:21  iter: 219  total_loss: 0.640  loss_cls: 0.204  loss_box_reg: 0.356  loss_rpn_cls: 0.019  loss_rpn_loc: 0.062  time: 1.0289  data_time: 0.0095  lr: 0.001099  max_mem: 5405M
[32m[04/20 10:21:49 d2.utils.events]: [0m eta: 0:12:59  iter: 239  total_loss: 0.621  loss_cls: 0.209  loss_box_reg: 0.341  loss_rpn_cls: 0.017  loss_rpn_loc: 0.053  time: 1.0288  data_time: 0.0097  lr: 0.001199  max_mem: 5405M
[32m[04/20 10:22:10 d2.utils.events]: [0m eta: 0:12:40  iter: 259  total_loss: 0.618  loss_cls: 0.202  loss_box_reg: 0.341  loss_rpn_cls: 0.017  loss_rpn_loc: 0.052  time: 1.0296  data_time: 0.0096  lr: 0.001299  max_mem: 5405M
[32m[04/20 10:22:30 d2.utils.events]: [0m eta: 0:12:20  iter: 279  total_loss: 0.663  loss_cls: 0.232  loss_box_reg: 0.352  loss_rpn_cls: 0.022  loss_rpn_loc: 0.056  time: 1.0295  data_time: 0.0097  lr: 0.001399  max_mem: 5405M
[32m[04/20 10:22:51 d2.utils.events]: [0m eta: 0:11:59  iter: 299  total_loss: 0.610  loss_cls: 0.198  loss_box_reg: 0.337  loss_rpn_cls: 0.014  loss_rpn_loc: 0.053  time: 1.0289  data_time: 0.0096  lr: 0.001499  max_mem: 5405M
[32m[04/20 10:23:11 d2.utils.events]: [0m eta: 0:11:39  iter: 319  total_loss: 0.669  loss_cls: 0.218  loss_box_reg: 0.360  loss_rpn_cls: 0.017  loss_rpn_loc: 0.066  time: 1.0279  data_time: 0.0098  lr: 0.001598  max_mem: 5405M
[32m[04/20 10:23:32 d2.utils.events]: [0m eta: 0:11:18  iter: 339  total_loss: 0.566  loss_cls: 0.196  loss_box_reg: 0.308  loss_rpn_cls: 0.013  loss_rpn_loc: 0.049  time: 1.0276  data_time: 0.0094  lr: 0.001698  max_mem: 5405M
[32m[04/20 10:23:53 d2.utils.events]: [0m eta: 0:10:58  iter: 359  total_loss: 0.636  loss_cls: 0.223  loss_box_reg: 0.338  loss_rpn_cls: 0.019  loss_rpn_loc: 0.051  time: 1.0285  data_time: 0.0098  lr: 0.001798  max_mem: 5405M
[32m[04/20 10:24:13 d2.utils.events]: [0m eta: 0:10:38  iter: 379  total_loss: 0.658  loss_cls: 0.223  loss_box_reg: 0.359  loss_rpn_cls: 0.015  loss_rpn_loc: 0.059  time: 1.0287  data_time: 0.0098  lr: 0.001898  max_mem: 5405M
[32m[04/20 10:24:35 d2.utils.events]: [0m eta: 0:10:21  iter: 399  total_loss: 0.533  loss_cls: 0.182  loss_box_reg: 0.293  loss_rpn_cls: 0.017  loss_rpn_loc: 0.043  time: 1.0306  data_time: 0.0098  lr: 0.001998  max_mem: 5405M
[32m[04/20 10:24:55 d2.utils.events]: [0m eta: 0:09:57  iter: 419  total_loss: 0.594  loss_cls: 0.204  loss_box_reg: 0.320  loss_rpn_cls: 0.022  loss_rpn_loc: 0.053  time: 1.0297  data_time: 0.0096  lr: 0.002098  max_mem: 5405M
[32m[04/20 10:25:16 d2.utils.events]: [0m eta: 0:09:39  iter: 439  total_loss: 0.623  loss_cls: 0.204  loss_box_reg: 0.346  loss_rpn_cls: 0.020  loss_rpn_loc: 0.063  time: 1.0300  data_time: 0.0096  lr: 0.002198  max_mem: 5405M
[32m[04/20 10:25:36 d2.utils.events]: [0m eta: 0:09:18  iter: 459  total_loss: 0.571  loss_cls: 0.205  loss_box_reg: 0.308  loss_rpn_cls: 0.017  loss_rpn_loc: 0.049  time: 1.0301  data_time: 0.0098  lr: 0.002298  max_mem: 5405M
[32m[04/20 10:25:57 d2.utils.events]: [0m eta: 0:08:56  iter: 479  total_loss: 0.743  loss_cls: 0.235  loss_box_reg: 0.414  loss_rpn_cls: 0.020  loss_rpn_loc: 0.069  time: 1.0295  data_time: 0.0094  lr: 0.002398  max_mem: 5405M
[32m[04/20 10:26:17 d2.utils.events]: [0m eta: 0:08:36  iter: 499  total_loss: 0.635  loss_cls: 0.210  loss_box_reg: 0.337  loss_rpn_cls: 0.018  loss_rpn_loc: 0.047  time: 1.0290  data_time: 0.0095  lr: 0.002498  max_mem: 5405M
[32m[04/20 10:26:38 d2.utils.events]: [0m eta: 0:08:16  iter: 519  total_loss: 0.655  loss_cls: 0.205  loss_box_reg: 0.339  loss_rpn_cls: 0.016  loss_rpn_loc: 0.057  time: 1.0291  data_time: 0.0099  lr: 0.002597  max_mem: 5405M
[32m[04/20 10:26:58 d2.utils.events]: [0m eta: 0:07:54  iter: 539  total_loss: 0.677  loss_cls: 0.222  loss_box_reg: 0.357  loss_rpn_cls: 0.016  loss_rpn_loc: 0.063  time: 1.0280  data_time: 0.0096  lr: 0.002697  max_mem: 5405M
[32m[04/20 10:27:18 d2.utils.events]: [0m eta: 0:07:33  iter: 559  total_loss: 0.654  loss_cls: 0.227  loss_box_reg: 0.358  loss_rpn_cls: 0.023  loss_rpn_loc: 0.064  time: 1.0273  data_time: 0.0095  lr: 0.002797  max_mem: 5405M
[32m[04/20 10:27:38 d2.utils.events]: [0m eta: 0:07:13  iter: 579  total_loss: 0.605  loss_cls: 0.203  loss_box_reg: 0.323  loss_rpn_cls: 0.025  loss_rpn_loc: 0.065  time: 1.0268  data_time: 0.0096  lr: 0.002897  max_mem: 5405M
[32m[04/20 10:27:59 d2.utils.events]: [0m eta: 0:06:52  iter: 599  total_loss: 0.629  loss_cls: 0.198  loss_box_reg: 0.343  loss_rpn_cls: 0.019  loss_rpn_loc: 0.057  time: 1.0269  data_time: 0.0097  lr: 0.002997  max_mem: 5405M
[32m[04/20 10:28:20 d2.utils.events]: [0m eta: 0:06:31  iter: 619  total_loss: 0.564  loss_cls: 0.195  loss_box_reg: 0.315  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0266  data_time: 0.0095  lr: 0.003097  max_mem: 5405M
[32m[04/20 10:28:40 d2.utils.events]: [0m eta: 0:06:11  iter: 639  total_loss: 0.620  loss_cls: 0.199  loss_box_reg: 0.331  loss_rpn_cls: 0.015  loss_rpn_loc: 0.050  time: 1.0270  data_time: 0.0099  lr: 0.003197  max_mem: 5405M
[32m[04/20 10:29:01 d2.utils.events]: [0m eta: 0:05:51  iter: 659  total_loss: 0.642  loss_cls: 0.231  loss_box_reg: 0.356  loss_rpn_cls: 0.021  loss_rpn_loc: 0.062  time: 1.0271  data_time: 0.0096  lr: 0.003297  max_mem: 5405M
[32m[04/20 10:29:22 d2.utils.events]: [0m eta: 0:05:30  iter: 679  total_loss: 0.643  loss_cls: 0.210  loss_box_reg: 0.353  loss_rpn_cls: 0.017  loss_rpn_loc: 0.051  time: 1.0270  data_time: 0.0100  lr: 0.003397  max_mem: 5405M
[32m[04/20 10:29:42 d2.utils.events]: [0m eta: 0:05:10  iter: 699  total_loss: 0.598  loss_cls: 0.194  loss_box_reg: 0.311  loss_rpn_cls: 0.020  loss_rpn_loc: 0.053  time: 1.0270  data_time: 0.0097  lr: 0.003497  max_mem: 5405M
[32m[04/20 10:30:03 d2.utils.events]: [0m eta: 0:04:49  iter: 719  total_loss: 0.634  loss_cls: 0.204  loss_box_reg: 0.340  loss_rpn_cls: 0.017  loss_rpn_loc: 0.053  time: 1.0269  data_time: 0.0094  lr: 0.003596  max_mem: 5405M
[32m[04/20 10:30:23 d2.utils.events]: [0m eta: 0:04:28  iter: 739  total_loss: 0.635  loss_cls: 0.218  loss_box_reg: 0.332  loss_rpn_cls: 0.019  loss_rpn_loc: 0.045  time: 1.0266  data_time: 0.0097  lr: 0.003696  max_mem: 5405M
[32m[04/20 10:30:44 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.633  loss_cls: 0.211  loss_box_reg: 0.318  loss_rpn_cls: 0.018  loss_rpn_loc: 0.058  time: 1.0277  data_time: 0.0100  lr: 0.003796  max_mem: 5405M
[32m[04/20 10:31:05 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.697  loss_cls: 0.232  loss_box_reg: 0.400  loss_rpn_cls: 0.018  loss_rpn_loc: 0.058  time: 1.0281  data_time: 0.0097  lr: 0.003896  max_mem: 5405M
[32m[04/20 10:31:26 d2.utils.events]: [0m eta: 0:03:27  iter: 799  total_loss: 0.720  loss_cls: 0.226  loss_box_reg: 0.411  loss_rpn_cls: 0.021  loss_rpn_loc: 0.063  time: 1.0280  data_time: 0.0096  lr: 0.003996  max_mem: 5405M
[32m[04/20 10:31:47 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.699  loss_cls: 0.225  loss_box_reg: 0.369  loss_rpn_cls: 0.019  loss_rpn_loc: 0.071  time: 1.0284  data_time: 0.0097  lr: 0.004096  max_mem: 5405M
[32m[04/20 10:32:07 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.727  loss_cls: 0.230  loss_box_reg: 0.390  loss_rpn_cls: 0.021  loss_rpn_loc: 0.071  time: 1.0278  data_time: 0.0096  lr: 0.004196  max_mem: 5405M
[32m[04/20 10:32:27 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.658  loss_cls: 0.216  loss_box_reg: 0.371  loss_rpn_cls: 0.023  loss_rpn_loc: 0.061  time: 1.0277  data_time: 0.0097  lr: 0.004296  max_mem: 5405M
[32m[04/20 10:32:48 d2.utils.events]: [0m eta: 0:02:04  iter: 879  total_loss: 0.723  loss_cls: 0.222  loss_box_reg: 0.384  loss_rpn_cls: 0.023  loss_rpn_loc: 0.059  time: 1.0273  data_time: 0.0096  lr: 0.004396  max_mem: 5405M
[32m[04/20 10:33:08 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.634  loss_cls: 0.218  loss_box_reg: 0.346  loss_rpn_cls: 0.025  loss_rpn_loc: 0.066  time: 1.0271  data_time: 0.0097  lr: 0.004496  max_mem: 5405M
[32m[04/20 10:33:29 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.652  loss_cls: 0.214  loss_box_reg: 0.360  loss_rpn_cls: 0.019  loss_rpn_loc: 0.056  time: 1.0276  data_time: 0.0098  lr: 0.004595  max_mem: 5405M
[32m[04/20 10:33:50 d2.utils.events]: [0m eta: 0:01:02  iter: 939  total_loss: 0.719  loss_cls: 0.248  loss_box_reg: 0.394  loss_rpn_cls: 0.025  loss_rpn_loc: 0.070  time: 1.0276  data_time: 0.0093  lr: 0.004695  max_mem: 5405M
[32m[04/20 10:34:10 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.634  loss_cls: 0.211  loss_box_reg: 0.333  loss_rpn_cls: 0.020  loss_rpn_loc: 0.070  time: 1.0274  data_time: 0.0097  lr: 0.004795  max_mem: 5405M
[32m[04/20 10:34:31 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.702  loss_cls: 0.242  loss_box_reg: 0.361  loss_rpn_cls: 0.020  loss_rpn_loc: 0.061  time: 1.0275  data_time: 0.0097  lr: 0.004895  max_mem: 5405M
[5m[31mWARNING[0m [32m[04/20 10:34:55 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 10:34:55 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 10:34:55 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 10:34:55 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.670  loss_cls: 0.226  loss_box_reg: 0.392  loss_rpn_cls: 0.019  loss_rpn_loc: 0.058  time: 1.0279  data_time: 0.0098  lr: 0.004995  max_mem: 5405M
[32m[04/20 10:34:56 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:05 (1.0289 s / it)
[32m[04/20 10:34:56 d2.engine.hooks]: [0mTotal training time: 0:17:12 (0:00:06 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 10:34:59 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 10:34:59 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 10:34:59 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 10:35:01 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1160 s / img. ETA=0:16:22
[32m[04/20 10:35:06 d2.evaluation.evaluator]: [0mInference done 54/8355. 0.1162 s / img. ETA=0:16:22
[32m[04/20 10:35:11 d2.evaluation.evaluator]: [0mInference done 97/8355. 0.1159 s / img. ETA=0:16:14
[32m[04/20 10:35:16 d2.evaluation.evaluator]: [0mInference done 140/8355. 0.1158 s / img. ETA=0:16:08
[32m[04/20 10:35:21 d2.evaluation.evaluator]: [0mInference done 183/8355. 0.1157 s / img. ETA=0:16:02
[32m[04/20 10:35:26 d2.evaluation.evaluator]: [0mInference done 226/8355. 0.1158 s / img. ETA=0:15:58
[32m[04/20 10:35:31 d2.evaluation.evaluator]: [0mInference done 269/8355. 0.1158 s / img. ETA=0:15:53
[32m[04/20 10:35:36 d2.evaluation.evaluator]: [0mInference done 312/8355. 0.1159 s / img. ETA=0:15:48
[32m[04/20 10:35:42 d2.evaluation.evaluator]: [0mInference done 355/8355. 0.1159 s / img. ETA=0:15:43
[32m[04/20 10:35:47 d2.evaluation.evaluator]: [0mInference done 398/8355. 0.1160 s / img. ETA=0:15:39
[32m[04/20 10:35:52 d2.evaluation.evaluator]: [0mInference done 441/8355. 0.1160 s / img. ETA=0:15:34
[32m[04/20 10:35:57 d2.evaluation.evaluator]: [0mInference done 484/8355. 0.1159 s / img. ETA=0:15:28
[32m[04/20 10:36:02 d2.evaluation.evaluator]: [0mInference done 527/8355. 0.1159 s / img. ETA=0:15:23
[32m[04/20 10:36:07 d2.evaluation.evaluator]: [0mInference done 570/8355. 0.1159 s / img. ETA=0:15:17
[32m[04/20 10:36:12 d2.evaluation.evaluator]: [0mInference done 613/8355. 0.1159 s / img. ETA=0:15:13
[32m[04/20 10:36:17 d2.evaluation.evaluator]: [0mInference done 656/8355. 0.1159 s / img. ETA=0:15:08
[32m[04/20 10:36:22 d2.evaluation.evaluator]: [0mInference done 699/8355. 0.1159 s / img. ETA=0:15:03
[32m[04/20 10:36:27 d2.evaluation.evaluator]: [0mInference done 742/8355. 0.1159 s / img. ETA=0:14:58
[32m[04/20 10:36:32 d2.evaluation.evaluator]: [0mInference done 785/8355. 0.1159 s / img. ETA=0:14:53
[32m[04/20 10:36:37 d2.evaluation.evaluator]: [0mInference done 828/8355. 0.1159 s / img. ETA=0:14:48
[32m[04/20 10:36:42 d2.evaluation.evaluator]: [0mInference done 871/8355. 0.1159 s / img. ETA=0:14:43
[32m[04/20 10:36:48 d2.evaluation.evaluator]: [0mInference done 914/8355. 0.1159 s / img. ETA=0:14:38
[32m[04/20 10:36:53 d2.evaluation.evaluator]: [0mInference done 957/8355. 0.1159 s / img. ETA=0:14:33
[32m[04/20 10:36:58 d2.evaluation.evaluator]: [0mInference done 1000/8355. 0.1159 s / img. ETA=0:14:28
[32m[04/20 10:37:03 d2.evaluation.evaluator]: [0mInference done 1043/8355. 0.1159 s / img. ETA=0:14:23
[32m[04/20 10:37:08 d2.evaluation.evaluator]: [0mInference done 1086/8355. 0.1159 s / img. ETA=0:14:18
[32m[04/20 10:37:13 d2.evaluation.evaluator]: [0mInference done 1129/8355. 0.1159 s / img. ETA=0:14:12
[32m[04/20 10:37:18 d2.evaluation.evaluator]: [0mInference done 1172/8355. 0.1159 s / img. ETA=0:14:07
[32m[04/20 10:37:23 d2.evaluation.evaluator]: [0mInference done 1215/8355. 0.1159 s / img. ETA=0:14:02
[32m[04/20 10:37:28 d2.evaluation.evaluator]: [0mInference done 1258/8355. 0.1159 s / img. ETA=0:13:57
[32m[04/20 10:37:33 d2.evaluation.evaluator]: [0mInference done 1301/8355. 0.1159 s / img. ETA=0:13:52
[32m[04/20 10:37:38 d2.evaluation.evaluator]: [0mInference done 1344/8355. 0.1158 s / img. ETA=0:13:47
[32m[04/20 10:37:43 d2.evaluation.evaluator]: [0mInference done 1387/8355. 0.1158 s / img. ETA=0:13:42
[32m[04/20 10:37:48 d2.evaluation.evaluator]: [0mInference done 1430/8355. 0.1158 s / img. ETA=0:13:37
[32m[04/20 10:37:54 d2.evaluation.evaluator]: [0mInference done 1473/8355. 0.1158 s / img. ETA=0:13:32
[32m[04/20 10:37:59 d2.evaluation.evaluator]: [0mInference done 1515/8355. 0.1159 s / img. ETA=0:13:27
[32m[04/20 10:38:04 d2.evaluation.evaluator]: [0mInference done 1557/8355. 0.1159 s / img. ETA=0:13:22
[32m[04/20 10:38:09 d2.evaluation.evaluator]: [0mInference done 1599/8355. 0.1159 s / img. ETA=0:13:18
[32m[04/20 10:38:14 d2.evaluation.evaluator]: [0mInference done 1641/8355. 0.1160 s / img. ETA=0:13:13
[32m[04/20 10:38:19 d2.evaluation.evaluator]: [0mInference done 1683/8355. 0.1160 s / img. ETA=0:13:08
[32m[04/20 10:38:24 d2.evaluation.evaluator]: [0mInference done 1725/8355. 0.1160 s / img. ETA=0:13:03
[32m[04/20 10:38:29 d2.evaluation.evaluator]: [0mInference done 1767/8355. 0.1161 s / img. ETA=0:12:59
[32m[04/20 10:38:34 d2.evaluation.evaluator]: [0mInference done 1809/8355. 0.1161 s / img. ETA=0:12:54
[32m[04/20 10:38:39 d2.evaluation.evaluator]: [0mInference done 1851/8355. 0.1161 s / img. ETA=0:12:49
[32m[04/20 10:38:44 d2.evaluation.evaluator]: [0mInference done 1893/8355. 0.1162 s / img. ETA=0:12:44
[32m[04/20 10:38:49 d2.evaluation.evaluator]: [0mInference done 1935/8355. 0.1162 s / img. ETA=0:12:40
[32m[04/20 10:38:54 d2.evaluation.evaluator]: [0mInference done 1977/8355. 0.1162 s / img. ETA=0:12:35
[32m[04/20 10:38:59 d2.evaluation.evaluator]: [0mInference done 2019/8355. 0.1162 s / img. ETA=0:12:30
[32m[04/20 10:39:04 d2.evaluation.evaluator]: [0mInference done 2062/8355. 0.1162 s / img. ETA=0:12:25
[32m[04/20 10:39:09 d2.evaluation.evaluator]: [0mInference done 2105/8355. 0.1162 s / img. ETA=0:12:20
[32m[04/20 10:39:14 d2.evaluation.evaluator]: [0mInference done 2148/8355. 0.1162 s / img. ETA=0:12:15
[32m[04/20 10:39:19 d2.evaluation.evaluator]: [0mInference done 2190/8355. 0.1162 s / img. ETA=0:12:10
[32m[04/20 10:39:24 d2.evaluation.evaluator]: [0mInference done 2232/8355. 0.1162 s / img. ETA=0:12:05
[32m[04/20 10:39:29 d2.evaluation.evaluator]: [0mInference done 2274/8355. 0.1163 s / img. ETA=0:12:00
[32m[04/20 10:39:34 d2.evaluation.evaluator]: [0mInference done 2316/8355. 0.1163 s / img. ETA=0:11:55
[32m[04/20 10:39:39 d2.evaluation.evaluator]: [0mInference done 2358/8355. 0.1163 s / img. ETA=0:11:50
[32m[04/20 10:39:44 d2.evaluation.evaluator]: [0mInference done 2400/8355. 0.1163 s / img. ETA=0:11:45
[32m[04/20 10:39:49 d2.evaluation.evaluator]: [0mInference done 2442/8355. 0.1163 s / img. ETA=0:11:40
[32m[04/20 10:39:54 d2.evaluation.evaluator]: [0mInference done 2485/8355. 0.1163 s / img. ETA=0:11:35
[32m[04/20 10:39:59 d2.evaluation.evaluator]: [0mInference done 2528/8355. 0.1163 s / img. ETA=0:11:30
[32m[04/20 10:40:04 d2.evaluation.evaluator]: [0mInference done 2570/8355. 0.1163 s / img. ETA=0:11:25
[32m[04/20 10:40:09 d2.evaluation.evaluator]: [0mInference done 2613/8355. 0.1163 s / img. ETA=0:11:20
[32m[04/20 10:40:14 d2.evaluation.evaluator]: [0mInference done 2655/8355. 0.1163 s / img. ETA=0:11:15
[32m[04/20 10:40:20 d2.evaluation.evaluator]: [0mInference done 2697/8355. 0.1163 s / img. ETA=0:11:11
[32m[04/20 10:40:25 d2.evaluation.evaluator]: [0mInference done 2739/8355. 0.1163 s / img. ETA=0:11:06
[32m[04/20 10:40:30 d2.evaluation.evaluator]: [0mInference done 2781/8355. 0.1163 s / img. ETA=0:11:01
[32m[04/20 10:40:35 d2.evaluation.evaluator]: [0mInference done 2823/8355. 0.1164 s / img. ETA=0:10:56
[32m[04/20 10:40:40 d2.evaluation.evaluator]: [0mInference done 2865/8355. 0.1164 s / img. ETA=0:10:51
[32m[04/20 10:40:45 d2.evaluation.evaluator]: [0mInference done 2907/8355. 0.1164 s / img. ETA=0:10:46
[32m[04/20 10:40:50 d2.evaluation.evaluator]: [0mInference done 2949/8355. 0.1164 s / img. ETA=0:10:41
[32m[04/20 10:40:55 d2.evaluation.evaluator]: [0mInference done 2992/8355. 0.1164 s / img. ETA=0:10:36
[32m[04/20 10:41:00 d2.evaluation.evaluator]: [0mInference done 3035/8355. 0.1164 s / img. ETA=0:10:31
[32m[04/20 10:41:05 d2.evaluation.evaluator]: [0mInference done 3077/8355. 0.1164 s / img. ETA=0:10:26
[32m[04/20 10:41:10 d2.evaluation.evaluator]: [0mInference done 3119/8355. 0.1164 s / img. ETA=0:10:21
[32m[04/20 10:41:15 d2.evaluation.evaluator]: [0mInference done 3162/8355. 0.1164 s / img. ETA=0:10:16
[32m[04/20 10:41:20 d2.evaluation.evaluator]: [0mInference done 3205/8355. 0.1164 s / img. ETA=0:10:11
[32m[04/20 10:41:25 d2.evaluation.evaluator]: [0mInference done 3247/8355. 0.1164 s / img. ETA=0:10:06
[32m[04/20 10:41:30 d2.evaluation.evaluator]: [0mInference done 3290/8355. 0.1164 s / img. ETA=0:10:01
[32m[04/20 10:41:35 d2.evaluation.evaluator]: [0mInference done 3333/8355. 0.1164 s / img. ETA=0:09:56
[32m[04/20 10:41:40 d2.evaluation.evaluator]: [0mInference done 3376/8355. 0.1164 s / img. ETA=0:09:50
[32m[04/20 10:41:45 d2.evaluation.evaluator]: [0mInference done 3419/8355. 0.1164 s / img. ETA=0:09:45
[32m[04/20 10:41:50 d2.evaluation.evaluator]: [0mInference done 3461/8355. 0.1164 s / img. ETA=0:09:40
[32m[04/20 10:41:55 d2.evaluation.evaluator]: [0mInference done 3503/8355. 0.1164 s / img. ETA=0:09:35
[32m[04/20 10:42:01 d2.evaluation.evaluator]: [0mInference done 3546/8355. 0.1164 s / img. ETA=0:09:30
[32m[04/20 10:42:06 d2.evaluation.evaluator]: [0mInference done 3588/8355. 0.1164 s / img. ETA=0:09:25
[32m[04/20 10:42:11 d2.evaluation.evaluator]: [0mInference done 3630/8355. 0.1164 s / img. ETA=0:09:20
[32m[04/20 10:42:16 d2.evaluation.evaluator]: [0mInference done 3673/8355. 0.1164 s / img. ETA=0:09:15
[32m[04/20 10:42:21 d2.evaluation.evaluator]: [0mInference done 3716/8355. 0.1164 s / img. ETA=0:09:10
[32m[04/20 10:42:26 d2.evaluation.evaluator]: [0mInference done 3759/8355. 0.1164 s / img. ETA=0:09:05
[32m[04/20 10:42:31 d2.evaluation.evaluator]: [0mInference done 3801/8355. 0.1164 s / img. ETA=0:09:00
[32m[04/20 10:42:36 d2.evaluation.evaluator]: [0mInference done 3843/8355. 0.1164 s / img. ETA=0:08:55
[32m[04/20 10:42:41 d2.evaluation.evaluator]: [0mInference done 3885/8355. 0.1164 s / img. ETA=0:08:50
[32m[04/20 10:42:46 d2.evaluation.evaluator]: [0mInference done 3928/8355. 0.1164 s / img. ETA=0:08:45
[32m[04/20 10:42:51 d2.evaluation.evaluator]: [0mInference done 3970/8355. 0.1164 s / img. ETA=0:08:40
[32m[04/20 10:42:56 d2.evaluation.evaluator]: [0mInference done 4012/8355. 0.1164 s / img. ETA=0:08:35
[32m[04/20 10:43:01 d2.evaluation.evaluator]: [0mInference done 4054/8355. 0.1164 s / img. ETA=0:08:30
[32m[04/20 10:43:06 d2.evaluation.evaluator]: [0mInference done 4096/8355. 0.1165 s / img. ETA=0:08:25
[32m[04/20 10:43:11 d2.evaluation.evaluator]: [0mInference done 4138/8355. 0.1165 s / img. ETA=0:08:20
[32m[04/20 10:43:16 d2.evaluation.evaluator]: [0mInference done 4180/8355. 0.1165 s / img. ETA=0:08:15
[32m[04/20 10:43:21 d2.evaluation.evaluator]: [0mInference done 4222/8355. 0.1165 s / img. ETA=0:08:10
[32m[04/20 10:43:26 d2.evaluation.evaluator]: [0mInference done 4265/8355. 0.1165 s / img. ETA=0:08:05
[32m[04/20 10:43:31 d2.evaluation.evaluator]: [0mInference done 4307/8355. 0.1165 s / img. ETA=0:08:00
[32m[04/20 10:43:36 d2.evaluation.evaluator]: [0mInference done 4350/8355. 0.1165 s / img. ETA=0:07:55
[32m[04/20 10:43:41 d2.evaluation.evaluator]: [0mInference done 4392/8355. 0.1165 s / img. ETA=0:07:50
[32m[04/20 10:43:47 d2.evaluation.evaluator]: [0mInference done 4434/8355. 0.1165 s / img. ETA=0:07:45
[32m[04/20 10:43:52 d2.evaluation.evaluator]: [0mInference done 4477/8355. 0.1165 s / img. ETA=0:07:40
[32m[04/20 10:43:57 d2.evaluation.evaluator]: [0mInference done 4519/8355. 0.1165 s / img. ETA=0:07:35
[32m[04/20 10:44:02 d2.evaluation.evaluator]: [0mInference done 4561/8355. 0.1165 s / img. ETA=0:07:30
[32m[04/20 10:44:07 d2.evaluation.evaluator]: [0mInference done 4603/8355. 0.1165 s / img. ETA=0:07:25
[32m[04/20 10:44:12 d2.evaluation.evaluator]: [0mInference done 4645/8355. 0.1165 s / img. ETA=0:07:20
[32m[04/20 10:44:17 d2.evaluation.evaluator]: [0mInference done 4688/8355. 0.1165 s / img. ETA=0:07:15
[32m[04/20 10:44:22 d2.evaluation.evaluator]: [0mInference done 4731/8355. 0.1165 s / img. ETA=0:07:10
[32m[04/20 10:44:27 d2.evaluation.evaluator]: [0mInference done 4773/8355. 0.1165 s / img. ETA=0:07:05
[32m[04/20 10:44:32 d2.evaluation.evaluator]: [0mInference done 4815/8355. 0.1165 s / img. ETA=0:07:00
[32m[04/20 10:44:37 d2.evaluation.evaluator]: [0mInference done 4857/8355. 0.1165 s / img. ETA=0:06:55
[32m[04/20 10:44:42 d2.evaluation.evaluator]: [0mInference done 4899/8355. 0.1165 s / img. ETA=0:06:50
[32m[04/20 10:44:47 d2.evaluation.evaluator]: [0mInference done 4942/8355. 0.1165 s / img. ETA=0:06:45
[32m[04/20 10:44:52 d2.evaluation.evaluator]: [0mInference done 4985/8355. 0.1165 s / img. ETA=0:06:40
[32m[04/20 10:44:57 d2.evaluation.evaluator]: [0mInference done 5028/8355. 0.1165 s / img. ETA=0:06:35
[32m[04/20 10:45:02 d2.evaluation.evaluator]: [0mInference done 5070/8355. 0.1165 s / img. ETA=0:06:30
[32m[04/20 10:45:07 d2.evaluation.evaluator]: [0mInference done 5112/8355. 0.1165 s / img. ETA=0:06:25
[32m[04/20 10:45:12 d2.evaluation.evaluator]: [0mInference done 5154/8355. 0.1166 s / img. ETA=0:06:20
[32m[04/20 10:45:18 d2.evaluation.evaluator]: [0mInference done 5196/8355. 0.1166 s / img. ETA=0:06:15
[32m[04/20 10:45:23 d2.evaluation.evaluator]: [0mInference done 5239/8355. 0.1166 s / img. ETA=0:06:10
[32m[04/20 10:45:28 d2.evaluation.evaluator]: [0mInference done 5281/8355. 0.1166 s / img. ETA=0:06:05
[32m[04/20 10:45:33 d2.evaluation.evaluator]: [0mInference done 5323/8355. 0.1166 s / img. ETA=0:06:00
[32m[04/20 10:45:38 d2.evaluation.evaluator]: [0mInference done 5365/8355. 0.1166 s / img. ETA=0:05:55
[32m[04/20 10:45:43 d2.evaluation.evaluator]: [0mInference done 5407/8355. 0.1166 s / img. ETA=0:05:50
[32m[04/20 10:45:48 d2.evaluation.evaluator]: [0mInference done 5449/8355. 0.1166 s / img. ETA=0:05:45
[32m[04/20 10:45:53 d2.evaluation.evaluator]: [0mInference done 5491/8355. 0.1166 s / img. ETA=0:05:40
[32m[04/20 10:45:58 d2.evaluation.evaluator]: [0mInference done 5534/8355. 0.1166 s / img. ETA=0:05:35
[32m[04/20 10:46:03 d2.evaluation.evaluator]: [0mInference done 5577/8355. 0.1166 s / img. ETA=0:05:30
[32m[04/20 10:46:08 d2.evaluation.evaluator]: [0mInference done 5619/8355. 0.1166 s / img. ETA=0:05:25
[32m[04/20 10:46:13 d2.evaluation.evaluator]: [0mInference done 5661/8355. 0.1166 s / img. ETA=0:05:20
[32m[04/20 10:46:18 d2.evaluation.evaluator]: [0mInference done 5703/8355. 0.1166 s / img. ETA=0:05:15
[32m[04/20 10:46:23 d2.evaluation.evaluator]: [0mInference done 5745/8355. 0.1166 s / img. ETA=0:05:10
[32m[04/20 10:46:28 d2.evaluation.evaluator]: [0mInference done 5787/8355. 0.1166 s / img. ETA=0:05:05
[32m[04/20 10:46:33 d2.evaluation.evaluator]: [0mInference done 5829/8355. 0.1166 s / img. ETA=0:05:00
[32m[04/20 10:46:38 d2.evaluation.evaluator]: [0mInference done 5871/8355. 0.1166 s / img. ETA=0:04:55
[32m[04/20 10:46:43 d2.evaluation.evaluator]: [0mInference done 5913/8355. 0.1166 s / img. ETA=0:04:50
[32m[04/20 10:46:48 d2.evaluation.evaluator]: [0mInference done 5955/8355. 0.1166 s / img. ETA=0:04:45
[32m[04/20 10:46:53 d2.evaluation.evaluator]: [0mInference done 5997/8355. 0.1166 s / img. ETA=0:04:40
[32m[04/20 10:46:58 d2.evaluation.evaluator]: [0mInference done 6039/8355. 0.1167 s / img. ETA=0:04:35
[32m[04/20 10:47:04 d2.evaluation.evaluator]: [0mInference done 6081/8355. 0.1167 s / img. ETA=0:04:30
[32m[04/20 10:47:09 d2.evaluation.evaluator]: [0mInference done 6123/8355. 0.1167 s / img. ETA=0:04:25
[32m[04/20 10:47:14 d2.evaluation.evaluator]: [0mInference done 6165/8355. 0.1167 s / img. ETA=0:04:20
[32m[04/20 10:47:19 d2.evaluation.evaluator]: [0mInference done 6207/8355. 0.1167 s / img. ETA=0:04:15
[32m[04/20 10:47:24 d2.evaluation.evaluator]: [0mInference done 6249/8355. 0.1167 s / img. ETA=0:04:10
[32m[04/20 10:47:29 d2.evaluation.evaluator]: [0mInference done 6291/8355. 0.1167 s / img. ETA=0:04:05
[32m[04/20 10:47:34 d2.evaluation.evaluator]: [0mInference done 6333/8355. 0.1167 s / img. ETA=0:04:00
[32m[04/20 10:47:39 d2.evaluation.evaluator]: [0mInference done 6375/8355. 0.1167 s / img. ETA=0:03:55
[32m[04/20 10:47:44 d2.evaluation.evaluator]: [0mInference done 6417/8355. 0.1167 s / img. ETA=0:03:50
[32m[04/20 10:47:49 d2.evaluation.evaluator]: [0mInference done 6459/8355. 0.1167 s / img. ETA=0:03:45
[32m[04/20 10:47:54 d2.evaluation.evaluator]: [0mInference done 6502/8355. 0.1167 s / img. ETA=0:03:40
[32m[04/20 10:47:59 d2.evaluation.evaluator]: [0mInference done 6545/8355. 0.1167 s / img. ETA=0:03:35
[32m[04/20 10:48:04 d2.evaluation.evaluator]: [0mInference done 6587/8355. 0.1167 s / img. ETA=0:03:30
[32m[04/20 10:48:09 d2.evaluation.evaluator]: [0mInference done 6629/8355. 0.1167 s / img. ETA=0:03:25
[32m[04/20 10:48:14 d2.evaluation.evaluator]: [0mInference done 6672/8355. 0.1167 s / img. ETA=0:03:20
[32m[04/20 10:48:19 d2.evaluation.evaluator]: [0mInference done 6715/8355. 0.1167 s / img. ETA=0:03:15
[32m[04/20 10:48:25 d2.evaluation.evaluator]: [0mInference done 6758/8355. 0.1167 s / img. ETA=0:03:10
[32m[04/20 10:48:30 d2.evaluation.evaluator]: [0mInference done 6801/8355. 0.1167 s / img. ETA=0:03:05
[32m[04/20 10:48:35 d2.evaluation.evaluator]: [0mInference done 6843/8355. 0.1167 s / img. ETA=0:03:00
[32m[04/20 10:48:40 d2.evaluation.evaluator]: [0mInference done 6885/8355. 0.1167 s / img. ETA=0:02:55
[32m[04/20 10:48:45 d2.evaluation.evaluator]: [0mInference done 6928/8355. 0.1167 s / img. ETA=0:02:49
[32m[04/20 10:48:50 d2.evaluation.evaluator]: [0mInference done 6970/8355. 0.1167 s / img. ETA=0:02:44
[32m[04/20 10:48:55 d2.evaluation.evaluator]: [0mInference done 7012/8355. 0.1167 s / img. ETA=0:02:39
[32m[04/20 10:49:00 d2.evaluation.evaluator]: [0mInference done 7054/8355. 0.1167 s / img. ETA=0:02:34
[32m[04/20 10:49:05 d2.evaluation.evaluator]: [0mInference done 7096/8355. 0.1167 s / img. ETA=0:02:29
[32m[04/20 10:49:10 d2.evaluation.evaluator]: [0mInference done 7138/8355. 0.1167 s / img. ETA=0:02:24
[32m[04/20 10:49:15 d2.evaluation.evaluator]: [0mInference done 7180/8355. 0.1167 s / img. ETA=0:02:19
[32m[04/20 10:49:20 d2.evaluation.evaluator]: [0mInference done 7222/8355. 0.1168 s / img. ETA=0:02:14
[32m[04/20 10:49:25 d2.evaluation.evaluator]: [0mInference done 7264/8355. 0.1168 s / img. ETA=0:02:09
[32m[04/20 10:49:30 d2.evaluation.evaluator]: [0mInference done 7306/8355. 0.1168 s / img. ETA=0:02:04
[32m[04/20 10:49:35 d2.evaluation.evaluator]: [0mInference done 7348/8355. 0.1168 s / img. ETA=0:01:59
[32m[04/20 10:49:40 d2.evaluation.evaluator]: [0mInference done 7390/8355. 0.1168 s / img. ETA=0:01:55
[32m[04/20 10:49:45 d2.evaluation.evaluator]: [0mInference done 7432/8355. 0.1168 s / img. ETA=0:01:50
[32m[04/20 10:49:50 d2.evaluation.evaluator]: [0mInference done 7474/8355. 0.1168 s / img. ETA=0:01:45
[32m[04/20 10:49:56 d2.evaluation.evaluator]: [0mInference done 7516/8355. 0.1168 s / img. ETA=0:01:40
[32m[04/20 10:50:01 d2.evaluation.evaluator]: [0mInference done 7558/8355. 0.1168 s / img. ETA=0:01:34
[32m[04/20 10:50:06 d2.evaluation.evaluator]: [0mInference done 7600/8355. 0.1168 s / img. ETA=0:01:29
[32m[04/20 10:50:11 d2.evaluation.evaluator]: [0mInference done 7642/8355. 0.1168 s / img. ETA=0:01:24
[32m[04/20 10:50:16 d2.evaluation.evaluator]: [0mInference done 7684/8355. 0.1168 s / img. ETA=0:01:19
[32m[04/20 10:50:21 d2.evaluation.evaluator]: [0mInference done 7726/8355. 0.1168 s / img. ETA=0:01:14
[32m[04/20 10:50:26 d2.evaluation.evaluator]: [0mInference done 7768/8355. 0.1168 s / img. ETA=0:01:09
[32m[04/20 10:50:31 d2.evaluation.evaluator]: [0mInference done 7810/8355. 0.1168 s / img. ETA=0:01:04
[32m[04/20 10:50:36 d2.evaluation.evaluator]: [0mInference done 7852/8355. 0.1168 s / img. ETA=0:00:59
[32m[04/20 10:50:41 d2.evaluation.evaluator]: [0mInference done 7894/8355. 0.1169 s / img. ETA=0:00:54
[32m[04/20 10:50:46 d2.evaluation.evaluator]: [0mInference done 7936/8355. 0.1169 s / img. ETA=0:00:49
[32m[04/20 10:50:51 d2.evaluation.evaluator]: [0mInference done 7978/8355. 0.1169 s / img. ETA=0:00:44
[32m[04/20 10:50:56 d2.evaluation.evaluator]: [0mInference done 8020/8355. 0.1169 s / img. ETA=0:00:39
[32m[04/20 10:51:01 d2.evaluation.evaluator]: [0mInference done 8062/8355. 0.1169 s / img. ETA=0:00:34
[32m[04/20 10:51:06 d2.evaluation.evaluator]: [0mInference done 8105/8355. 0.1169 s / img. ETA=0:00:29
[32m[04/20 10:51:11 d2.evaluation.evaluator]: [0mInference done 8147/8355. 0.1169 s / img. ETA=0:00:24
[32m[04/20 10:51:16 d2.evaluation.evaluator]: [0mInference done 8190/8355. 0.1169 s / img. ETA=0:00:19
[32m[04/20 10:51:21 d2.evaluation.evaluator]: [0mInference done 8232/8355. 0.1169 s / img. ETA=0:00:14
[32m[04/20 10:51:26 d2.evaluation.evaluator]: [0mInference done 8274/8355. 0.1169 s / img. ETA=0:00:09
[32m[04/20 10:51:31 d2.evaluation.evaluator]: [0mInference done 8316/8355. 0.1169 s / img. ETA=0:00:04
[32m[04/20 10:51:36 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:35.905319 (0.119270 s / img per device, on 1 devices)
[32m[04/20 10:51:36 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:15 (0.116864 s / img per device, on 1 devices)
[32m[04/20 10:51:36 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 10:51:36 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 10:51:37 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.43s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=18.17s).
Accumulating evaluation results...
DONE (t=2.02s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.622
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.298
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.227
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.586
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.138
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.377
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.287
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.521
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.638
[32m[04/20 10:51:57 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 32.659 | 62.232 | 29.803 | 22.705 | 45.258 | 58.645 |
[32m[04/20 10:51:57 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 35.405 | bicycle       | 20.523 | car            | 42.050 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 10:51:58 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 10:51:58 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 10:51:58 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 10:52:00 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1177 s / img. ETA=0:02:29
[32m[04/20 10:52:05 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1173 s / img. ETA=0:02:24
[32m[04/20 10:52:10 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1175 s / img. ETA=0:02:19
[32m[04/20 10:52:15 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1173 s / img. ETA=0:02:14
[32m[04/20 10:52:20 d2.evaluation.evaluator]: [0mInference done 180/1257. 0.1171 s / img. ETA=0:02:08
[32m[04/20 10:52:25 d2.evaluation.evaluator]: [0mInference done 223/1257. 0.1170 s / img. ETA=0:02:03
[32m[04/20 10:52:30 d2.evaluation.evaluator]: [0mInference done 265/1257. 0.1170 s / img. ETA=0:01:58
[32m[04/20 10:52:35 d2.evaluation.evaluator]: [0mInference done 308/1257. 0.1170 s / img. ETA=0:01:53
[32m[04/20 10:52:41 d2.evaluation.evaluator]: [0mInference done 351/1257. 0.1169 s / img. ETA=0:01:48
[32m[04/20 10:52:46 d2.evaluation.evaluator]: [0mInference done 394/1257. 0.1168 s / img. ETA=0:01:42
[32m[04/20 10:52:51 d2.evaluation.evaluator]: [0mInference done 437/1257. 0.1168 s / img. ETA=0:01:37
[32m[04/20 10:52:56 d2.evaluation.evaluator]: [0mInference done 479/1257. 0.1168 s / img. ETA=0:01:32
[32m[04/20 10:53:01 d2.evaluation.evaluator]: [0mInference done 521/1257. 0.1168 s / img. ETA=0:01:27
[32m[04/20 10:53:06 d2.evaluation.evaluator]: [0mInference done 563/1257. 0.1169 s / img. ETA=0:01:22
[32m[04/20 10:53:11 d2.evaluation.evaluator]: [0mInference done 605/1257. 0.1169 s / img. ETA=0:01:17
[32m[04/20 10:53:16 d2.evaluation.evaluator]: [0mInference done 647/1257. 0.1169 s / img. ETA=0:01:12
[32m[04/20 10:53:21 d2.evaluation.evaluator]: [0mInference done 689/1257. 0.1170 s / img. ETA=0:01:07
[32m[04/20 10:53:26 d2.evaluation.evaluator]: [0mInference done 731/1257. 0.1170 s / img. ETA=0:01:02
[32m[04/20 10:53:31 d2.evaluation.evaluator]: [0mInference done 773/1257. 0.1170 s / img. ETA=0:00:57
[32m[04/20 10:53:36 d2.evaluation.evaluator]: [0mInference done 815/1257. 0.1170 s / img. ETA=0:00:52
[32m[04/20 10:53:41 d2.evaluation.evaluator]: [0mInference done 857/1257. 0.1170 s / img. ETA=0:00:47
[32m[04/20 10:53:46 d2.evaluation.evaluator]: [0mInference done 899/1257. 0.1170 s / img. ETA=0:00:42
[32m[04/20 10:53:51 d2.evaluation.evaluator]: [0mInference done 941/1257. 0.1170 s / img. ETA=0:00:37
[32m[04/20 10:53:56 d2.evaluation.evaluator]: [0mInference done 983/1257. 0.1170 s / img. ETA=0:00:32
[32m[04/20 10:54:01 d2.evaluation.evaluator]: [0mInference done 1025/1257. 0.1170 s / img. ETA=0:00:27
[32m[04/20 10:54:06 d2.evaluation.evaluator]: [0mInference done 1067/1257. 0.1170 s / img. ETA=0:00:22
[32m[04/20 10:54:11 d2.evaluation.evaluator]: [0mInference done 1109/1257. 0.1170 s / img. ETA=0:00:17
[32m[04/20 10:54:16 d2.evaluation.evaluator]: [0mInference done 1151/1257. 0.1170 s / img. ETA=0:00:12
[32m[04/20 10:54:21 d2.evaluation.evaluator]: [0mInference done 1193/1257. 0.1170 s / img. ETA=0:00:07
[32m[04/20 10:54:26 d2.evaluation.evaluator]: [0mInference done 1235/1257. 0.1170 s / img. ETA=0:00:02
[32m[04/20 10:54:29 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:29.464596 (0.119381 s / img per device, on 1 devices)
[32m[04/20 10:54:29 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:26 (0.116993 s / img per device, on 1 devices)
[32m[04/20 10:54:29 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 10:54:29 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 10:54:29 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.27s).
Accumulating evaluation results...
DONE (t=0.33s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.267
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.516
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.243
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.326
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.470
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.142
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.228
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.387
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.519
[32m[04/20 10:54:32 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 26.693 | 51.582 | 24.331 | 16.721 | 32.579 | 47.005 |
[32m[04/20 10:54:32 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 27.812 | bicycle       | 11.572 | car            | 40.695 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  9  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 10:54:32 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 10:54:33 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 10:54:33 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 10:54:33 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 10:54:33 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 10:54:33 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 10:54:33 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 10:54:54 d2.utils.events]: [0m eta: 0:17:20  iter: 19  total_loss: 0.708  loss_cls: 0.230  loss_box_reg: 0.370  loss_rpn_cls: 0.020  loss_rpn_loc: 0.073  time: 1.0451  data_time: 0.0327  lr: 0.000100  max_mem: 5405M
[32m[04/20 10:55:15 d2.utils.events]: [0m eta: 0:16:57  iter: 39  total_loss: 0.661  loss_cls: 0.215  loss_box_reg: 0.363  loss_rpn_cls: 0.022  loss_rpn_loc: 0.061  time: 1.0391  data_time: 0.0097  lr: 0.000200  max_mem: 5405M
[32m[04/20 10:55:36 d2.utils.events]: [0m eta: 0:16:35  iter: 59  total_loss: 0.636  loss_cls: 0.209  loss_box_reg: 0.347  loss_rpn_cls: 0.021  loss_rpn_loc: 0.046  time: 1.0371  data_time: 0.0098  lr: 0.000300  max_mem: 5405M
[32m[04/20 10:55:56 d2.utils.events]: [0m eta: 0:16:05  iter: 79  total_loss: 0.639  loss_cls: 0.213  loss_box_reg: 0.337  loss_rpn_cls: 0.021  loss_rpn_loc: 0.054  time: 1.0325  data_time: 0.0095  lr: 0.000400  max_mem: 5405M
[32m[04/20 10:56:17 d2.utils.events]: [0m eta: 0:15:50  iter: 99  total_loss: 0.641  loss_cls: 0.212  loss_box_reg: 0.346  loss_rpn_cls: 0.020  loss_rpn_loc: 0.052  time: 1.0335  data_time: 0.0096  lr: 0.000500  max_mem: 5405M
[32m[04/20 10:56:37 d2.utils.events]: [0m eta: 0:15:10  iter: 119  total_loss: 0.669  loss_cls: 0.228  loss_box_reg: 0.382  loss_rpn_cls: 0.015  loss_rpn_loc: 0.054  time: 1.0305  data_time: 0.0094  lr: 0.000599  max_mem: 5405M
[32m[04/20 10:56:58 d2.utils.events]: [0m eta: 0:14:55  iter: 139  total_loss: 0.653  loss_cls: 0.216  loss_box_reg: 0.351  loss_rpn_cls: 0.019  loss_rpn_loc: 0.068  time: 1.0314  data_time: 0.0099  lr: 0.000699  max_mem: 5405M
[32m[04/20 10:57:19 d2.utils.events]: [0m eta: 0:14:39  iter: 159  total_loss: 0.568  loss_cls: 0.200  loss_box_reg: 0.297  loss_rpn_cls: 0.016  loss_rpn_loc: 0.040  time: 1.0335  data_time: 0.0098  lr: 0.000799  max_mem: 5405M
[32m[04/20 10:57:40 d2.utils.events]: [0m eta: 0:14:18  iter: 179  total_loss: 0.629  loss_cls: 0.209  loss_box_reg: 0.351  loss_rpn_cls: 0.013  loss_rpn_loc: 0.049  time: 1.0337  data_time: 0.0097  lr: 0.000899  max_mem: 5405M
[32m[04/20 10:58:00 d2.utils.events]: [0m eta: 0:13:54  iter: 199  total_loss: 0.613  loss_cls: 0.203  loss_box_reg: 0.328  loss_rpn_cls: 0.015  loss_rpn_loc: 0.055  time: 1.0330  data_time: 0.0096  lr: 0.000999  max_mem: 5405M
[32m[04/20 10:58:21 d2.utils.events]: [0m eta: 0:13:36  iter: 219  total_loss: 0.634  loss_cls: 0.209  loss_box_reg: 0.349  loss_rpn_cls: 0.018  loss_rpn_loc: 0.051  time: 1.0338  data_time: 0.0099  lr: 0.001099  max_mem: 5405M
[32m[04/20 10:58:42 d2.utils.events]: [0m eta: 0:13:16  iter: 239  total_loss: 0.663  loss_cls: 0.216  loss_box_reg: 0.375  loss_rpn_cls: 0.017  loss_rpn_loc: 0.060  time: 1.0346  data_time: 0.0099  lr: 0.001199  max_mem: 5405M
[32m[04/20 10:59:03 d2.utils.events]: [0m eta: 0:12:54  iter: 259  total_loss: 0.626  loss_cls: 0.194  loss_box_reg: 0.351  loss_rpn_cls: 0.016  loss_rpn_loc: 0.053  time: 1.0341  data_time: 0.0095  lr: 0.001299  max_mem: 5405M
[32m[04/20 10:59:24 d2.utils.events]: [0m eta: 0:12:34  iter: 279  total_loss: 0.632  loss_cls: 0.211  loss_box_reg: 0.349  loss_rpn_cls: 0.014  loss_rpn_loc: 0.047  time: 1.0346  data_time: 0.0098  lr: 0.001399  max_mem: 5405M
[32m[04/20 10:59:44 d2.utils.events]: [0m eta: 0:12:12  iter: 299  total_loss: 0.537  loss_cls: 0.175  loss_box_reg: 0.299  loss_rpn_cls: 0.014  loss_rpn_loc: 0.046  time: 1.0342  data_time: 0.0097  lr: 0.001499  max_mem: 5405M
[32m[04/20 11:00:05 d2.utils.events]: [0m eta: 0:11:50  iter: 319  total_loss: 0.656  loss_cls: 0.226  loss_box_reg: 0.357  loss_rpn_cls: 0.019  loss_rpn_loc: 0.044  time: 1.0331  data_time: 0.0097  lr: 0.001598  max_mem: 5405M
[32m[04/20 11:00:26 d2.utils.events]: [0m eta: 0:11:30  iter: 339  total_loss: 0.596  loss_cls: 0.199  loss_box_reg: 0.326  loss_rpn_cls: 0.017  loss_rpn_loc: 0.056  time: 1.0336  data_time: 0.0097  lr: 0.001698  max_mem: 5405M
[32m[04/20 11:00:46 d2.utils.events]: [0m eta: 0:11:10  iter: 359  total_loss: 0.615  loss_cls: 0.205  loss_box_reg: 0.341  loss_rpn_cls: 0.021  loss_rpn_loc: 0.062  time: 1.0340  data_time: 0.0098  lr: 0.001798  max_mem: 5405M
[32m[04/20 11:01:07 d2.utils.events]: [0m eta: 0:10:49  iter: 379  total_loss: 0.711  loss_cls: 0.240  loss_box_reg: 0.375  loss_rpn_cls: 0.021  loss_rpn_loc: 0.062  time: 1.0331  data_time: 0.0096  lr: 0.001898  max_mem: 5405M
[32m[04/20 11:01:27 d2.utils.events]: [0m eta: 0:10:27  iter: 399  total_loss: 0.616  loss_cls: 0.202  loss_box_reg: 0.339  loss_rpn_cls: 0.016  loss_rpn_loc: 0.049  time: 1.0324  data_time: 0.0096  lr: 0.001998  max_mem: 5405M
[32m[04/20 11:01:48 d2.utils.events]: [0m eta: 0:10:06  iter: 419  total_loss: 0.679  loss_cls: 0.217  loss_box_reg: 0.351  loss_rpn_cls: 0.015  loss_rpn_loc: 0.059  time: 1.0322  data_time: 0.0096  lr: 0.002098  max_mem: 5405M
[32m[04/20 11:02:09 d2.utils.events]: [0m eta: 0:09:45  iter: 439  total_loss: 0.589  loss_cls: 0.208  loss_box_reg: 0.334  loss_rpn_cls: 0.016  loss_rpn_loc: 0.056  time: 1.0326  data_time: 0.0099  lr: 0.002198  max_mem: 5405M
[32m[04/20 11:02:29 d2.utils.events]: [0m eta: 0:09:25  iter: 459  total_loss: 0.639  loss_cls: 0.198  loss_box_reg: 0.329  loss_rpn_cls: 0.019  loss_rpn_loc: 0.057  time: 1.0322  data_time: 0.0097  lr: 0.002298  max_mem: 5405M
[32m[04/20 11:02:50 d2.utils.events]: [0m eta: 0:09:04  iter: 479  total_loss: 0.666  loss_cls: 0.208  loss_box_reg: 0.381  loss_rpn_cls: 0.018  loss_rpn_loc: 0.061  time: 1.0321  data_time: 0.0098  lr: 0.002398  max_mem: 5405M
[32m[04/20 11:03:11 d2.utils.events]: [0m eta: 0:08:43  iter: 499  total_loss: 0.560  loss_cls: 0.196  loss_box_reg: 0.298  loss_rpn_cls: 0.013  loss_rpn_loc: 0.043  time: 1.0322  data_time: 0.0097  lr: 0.002498  max_mem: 5405M
[32m[04/20 11:03:32 d2.utils.events]: [0m eta: 0:08:22  iter: 519  total_loss: 0.648  loss_cls: 0.210  loss_box_reg: 0.359  loss_rpn_cls: 0.013  loss_rpn_loc: 0.052  time: 1.0327  data_time: 0.0100  lr: 0.002597  max_mem: 5405M
[32m[04/20 11:03:52 d2.utils.events]: [0m eta: 0:08:01  iter: 539  total_loss: 0.572  loss_cls: 0.186  loss_box_reg: 0.320  loss_rpn_cls: 0.014  loss_rpn_loc: 0.046  time: 1.0319  data_time: 0.0095  lr: 0.002697  max_mem: 5405M
[32m[04/20 11:04:13 d2.utils.events]: [0m eta: 0:07:40  iter: 559  total_loss: 0.696  loss_cls: 0.233  loss_box_reg: 0.405  loss_rpn_cls: 0.021  loss_rpn_loc: 0.069  time: 1.0319  data_time: 0.0097  lr: 0.002797  max_mem: 5405M
[32m[04/20 11:04:34 d2.utils.events]: [0m eta: 0:07:20  iter: 579  total_loss: 0.622  loss_cls: 0.217  loss_box_reg: 0.334  loss_rpn_cls: 0.018  loss_rpn_loc: 0.059  time: 1.0332  data_time: 0.0097  lr: 0.002897  max_mem: 5405M
[32m[04/20 11:04:55 d2.utils.events]: [0m eta: 0:07:00  iter: 599  total_loss: 0.629  loss_cls: 0.206  loss_box_reg: 0.349  loss_rpn_cls: 0.017  loss_rpn_loc: 0.052  time: 1.0331  data_time: 0.0096  lr: 0.002997  max_mem: 5405M
[32m[04/20 11:05:15 d2.utils.events]: [0m eta: 0:06:38  iter: 619  total_loss: 0.690  loss_cls: 0.211  loss_box_reg: 0.377  loss_rpn_cls: 0.017  loss_rpn_loc: 0.071  time: 1.0323  data_time: 0.0097  lr: 0.003097  max_mem: 5405M
[32m[04/20 11:05:35 d2.utils.events]: [0m eta: 0:06:16  iter: 639  total_loss: 0.606  loss_cls: 0.202  loss_box_reg: 0.324  loss_rpn_cls: 0.017  loss_rpn_loc: 0.050  time: 1.0313  data_time: 0.0097  lr: 0.003197  max_mem: 5405M
[32m[04/20 11:05:55 d2.utils.events]: [0m eta: 0:05:55  iter: 659  total_loss: 0.600  loss_cls: 0.218  loss_box_reg: 0.328  loss_rpn_cls: 0.015  loss_rpn_loc: 0.061  time: 1.0310  data_time: 0.0096  lr: 0.003297  max_mem: 5405M
[32m[04/20 11:06:15 d2.utils.events]: [0m eta: 0:05:33  iter: 679  total_loss: 0.729  loss_cls: 0.234  loss_box_reg: 0.399  loss_rpn_cls: 0.018  loss_rpn_loc: 0.076  time: 1.0297  data_time: 0.0094  lr: 0.003397  max_mem: 5405M
[32m[04/20 11:06:36 d2.utils.events]: [0m eta: 0:05:12  iter: 699  total_loss: 0.583  loss_cls: 0.174  loss_box_reg: 0.316  loss_rpn_cls: 0.015  loss_rpn_loc: 0.051  time: 1.0293  data_time: 0.0097  lr: 0.003497  max_mem: 5405M
[32m[04/20 11:06:56 d2.utils.events]: [0m eta: 0:04:51  iter: 719  total_loss: 0.595  loss_cls: 0.187  loss_box_reg: 0.341  loss_rpn_cls: 0.018  loss_rpn_loc: 0.048  time: 1.0290  data_time: 0.0096  lr: 0.003596  max_mem: 5405M
[32m[04/20 11:07:17 d2.utils.events]: [0m eta: 0:04:30  iter: 739  total_loss: 0.661  loss_cls: 0.214  loss_box_reg: 0.358  loss_rpn_cls: 0.023  loss_rpn_loc: 0.066  time: 1.0289  data_time: 0.0099  lr: 0.003696  max_mem: 5405M
[32m[04/20 11:07:37 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.701  loss_cls: 0.246  loss_box_reg: 0.383  loss_rpn_cls: 0.020  loss_rpn_loc: 0.050  time: 1.0286  data_time: 0.0096  lr: 0.003796  max_mem: 5405M
[32m[04/20 11:07:57 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.663  loss_cls: 0.232  loss_box_reg: 0.357  loss_rpn_cls: 0.020  loss_rpn_loc: 0.061  time: 1.0284  data_time: 0.0097  lr: 0.003896  max_mem: 5405M
[32m[04/20 11:08:18 d2.utils.events]: [0m eta: 0:03:28  iter: 799  total_loss: 0.623  loss_cls: 0.204  loss_box_reg: 0.339  loss_rpn_cls: 0.018  loss_rpn_loc: 0.060  time: 1.0286  data_time: 0.0096  lr: 0.003996  max_mem: 5405M
[32m[04/20 11:08:39 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.657  loss_cls: 0.214  loss_box_reg: 0.352  loss_rpn_cls: 0.022  loss_rpn_loc: 0.060  time: 1.0288  data_time: 0.0094  lr: 0.004096  max_mem: 5405M
[32m[04/20 11:09:00 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.667  loss_cls: 0.219  loss_box_reg: 0.356  loss_rpn_cls: 0.023  loss_rpn_loc: 0.059  time: 1.0291  data_time: 0.0099  lr: 0.004196  max_mem: 5405M
[32m[04/20 11:09:21 d2.utils.events]: [0m eta: 0:02:26  iter: 859  total_loss: 0.650  loss_cls: 0.204  loss_box_reg: 0.369  loss_rpn_cls: 0.020  loss_rpn_loc: 0.053  time: 1.0294  data_time: 0.0099  lr: 0.004296  max_mem: 5405M
[32m[04/20 11:09:42 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.717  loss_cls: 0.227  loss_box_reg: 0.390  loss_rpn_cls: 0.022  loss_rpn_loc: 0.071  time: 1.0296  data_time: 0.0098  lr: 0.004396  max_mem: 5405M
[32m[04/20 11:10:02 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.596  loss_cls: 0.184  loss_box_reg: 0.323  loss_rpn_cls: 0.018  loss_rpn_loc: 0.050  time: 1.0295  data_time: 0.0097  lr: 0.004496  max_mem: 5405M
[32m[04/20 11:10:23 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.645  loss_cls: 0.199  loss_box_reg: 0.347  loss_rpn_cls: 0.025  loss_rpn_loc: 0.066  time: 1.0296  data_time: 0.0097  lr: 0.004595  max_mem: 5405M
[32m[04/20 11:10:43 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.589  loss_cls: 0.197  loss_box_reg: 0.315  loss_rpn_cls: 0.016  loss_rpn_loc: 0.061  time: 1.0293  data_time: 0.0096  lr: 0.004695  max_mem: 5405M
[32m[04/20 11:11:04 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.731  loss_cls: 0.237  loss_box_reg: 0.397  loss_rpn_cls: 0.022  loss_rpn_loc: 0.073  time: 1.0297  data_time: 0.0094  lr: 0.004795  max_mem: 5405M
[32m[04/20 11:11:25 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.646  loss_cls: 0.213  loss_box_reg: 0.355  loss_rpn_cls: 0.023  loss_rpn_loc: 0.059  time: 1.0297  data_time: 0.0095  lr: 0.004895  max_mem: 5405M
[5m[31mWARNING[0m [32m[04/20 11:11:49 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 11:11:49 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 11:11:49 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 11:11:49 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.610  loss_cls: 0.198  loss_box_reg: 0.334  loss_rpn_cls: 0.017  loss_rpn_loc: 0.039  time: 1.0299  data_time: 0.0099  lr: 0.004995  max_mem: 5405M
[32m[04/20 11:11:50 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:07 (1.0310 s / it)
[32m[04/20 11:11:50 d2.engine.hooks]: [0mTotal training time: 0:17:14 (0:00:06 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 11:11:53 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 11:11:53 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 11:11:53 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 11:11:55 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1161 s / img. ETA=0:16:24
[32m[04/20 11:12:00 d2.evaluation.evaluator]: [0mInference done 54/8355. 0.1163 s / img. ETA=0:16:24
[32m[04/20 11:12:05 d2.evaluation.evaluator]: [0mInference done 97/8355. 0.1161 s / img. ETA=0:16:17
[32m[04/20 11:12:10 d2.evaluation.evaluator]: [0mInference done 140/8355. 0.1160 s / img. ETA=0:16:11
[32m[04/20 11:12:15 d2.evaluation.evaluator]: [0mInference done 183/8355. 0.1158 s / img. ETA=0:16:04
[32m[04/20 11:12:20 d2.evaluation.evaluator]: [0mInference done 226/8355. 0.1158 s / img. ETA=0:15:59
[32m[04/20 11:12:25 d2.evaluation.evaluator]: [0mInference done 269/8355. 0.1159 s / img. ETA=0:15:55
[32m[04/20 11:12:30 d2.evaluation.evaluator]: [0mInference done 312/8355. 0.1160 s / img. ETA=0:15:51
[32m[04/20 11:12:36 d2.evaluation.evaluator]: [0mInference done 355/8355. 0.1160 s / img. ETA=0:15:46
[32m[04/20 11:12:41 d2.evaluation.evaluator]: [0mInference done 398/8355. 0.1161 s / img. ETA=0:15:41
[32m[04/20 11:12:46 d2.evaluation.evaluator]: [0mInference done 441/8355. 0.1161 s / img. ETA=0:15:36
[32m[04/20 11:12:51 d2.evaluation.evaluator]: [0mInference done 484/8355. 0.1161 s / img. ETA=0:15:31
[32m[04/20 11:12:56 d2.evaluation.evaluator]: [0mInference done 527/8355. 0.1160 s / img. ETA=0:15:25
[32m[04/20 11:13:01 d2.evaluation.evaluator]: [0mInference done 570/8355. 0.1160 s / img. ETA=0:15:20
[32m[04/20 11:13:06 d2.evaluation.evaluator]: [0mInference done 613/8355. 0.1160 s / img. ETA=0:15:15
[32m[04/20 11:13:11 d2.evaluation.evaluator]: [0mInference done 656/8355. 0.1160 s / img. ETA=0:15:10
[32m[04/20 11:13:16 d2.evaluation.evaluator]: [0mInference done 698/8355. 0.1161 s / img. ETA=0:15:06
[32m[04/20 11:13:21 d2.evaluation.evaluator]: [0mInference done 741/8355. 0.1161 s / img. ETA=0:15:01
[32m[04/20 11:13:26 d2.evaluation.evaluator]: [0mInference done 784/8355. 0.1161 s / img. ETA=0:14:56
[32m[04/20 11:13:31 d2.evaluation.evaluator]: [0mInference done 827/8355. 0.1161 s / img. ETA=0:14:51
[32m[04/20 11:13:37 d2.evaluation.evaluator]: [0mInference done 870/8355. 0.1161 s / img. ETA=0:14:46
[32m[04/20 11:13:42 d2.evaluation.evaluator]: [0mInference done 912/8355. 0.1161 s / img. ETA=0:14:41
[32m[04/20 11:13:47 d2.evaluation.evaluator]: [0mInference done 955/8355. 0.1161 s / img. ETA=0:14:36
[32m[04/20 11:13:52 d2.evaluation.evaluator]: [0mInference done 998/8355. 0.1161 s / img. ETA=0:14:31
[32m[04/20 11:13:57 d2.evaluation.evaluator]: [0mInference done 1041/8355. 0.1161 s / img. ETA=0:14:26
[32m[04/20 11:14:02 d2.evaluation.evaluator]: [0mInference done 1084/8355. 0.1161 s / img. ETA=0:14:20
[32m[04/20 11:14:07 d2.evaluation.evaluator]: [0mInference done 1127/8355. 0.1161 s / img. ETA=0:14:15
[32m[04/20 11:14:12 d2.evaluation.evaluator]: [0mInference done 1170/8355. 0.1161 s / img. ETA=0:14:10
[32m[04/20 11:14:17 d2.evaluation.evaluator]: [0mInference done 1213/8355. 0.1161 s / img. ETA=0:14:05
[32m[04/20 11:14:22 d2.evaluation.evaluator]: [0mInference done 1256/8355. 0.1161 s / img. ETA=0:14:00
[32m[04/20 11:14:27 d2.evaluation.evaluator]: [0mInference done 1299/8355. 0.1161 s / img. ETA=0:13:55
[32m[04/20 11:14:32 d2.evaluation.evaluator]: [0mInference done 1342/8355. 0.1161 s / img. ETA=0:13:50
[32m[04/20 11:14:38 d2.evaluation.evaluator]: [0mInference done 1385/8355. 0.1161 s / img. ETA=0:13:45
[32m[04/20 11:14:43 d2.evaluation.evaluator]: [0mInference done 1428/8355. 0.1161 s / img. ETA=0:13:39
[32m[04/20 11:14:48 d2.evaluation.evaluator]: [0mInference done 1471/8355. 0.1161 s / img. ETA=0:13:34
[32m[04/20 11:14:53 d2.evaluation.evaluator]: [0mInference done 1513/8355. 0.1161 s / img. ETA=0:13:30
[32m[04/20 11:14:58 d2.evaluation.evaluator]: [0mInference done 1555/8355. 0.1162 s / img. ETA=0:13:25
[32m[04/20 11:15:03 d2.evaluation.evaluator]: [0mInference done 1597/8355. 0.1162 s / img. ETA=0:13:20
[32m[04/20 11:15:08 d2.evaluation.evaluator]: [0mInference done 1639/8355. 0.1162 s / img. ETA=0:13:16
[32m[04/20 11:15:13 d2.evaluation.evaluator]: [0mInference done 1681/8355. 0.1163 s / img. ETA=0:13:11
[32m[04/20 11:15:18 d2.evaluation.evaluator]: [0mInference done 1723/8355. 0.1163 s / img. ETA=0:13:06
[32m[04/20 11:15:23 d2.evaluation.evaluator]: [0mInference done 1765/8355. 0.1163 s / img. ETA=0:13:01
[32m[04/20 11:15:28 d2.evaluation.evaluator]: [0mInference done 1807/8355. 0.1164 s / img. ETA=0:12:57
[32m[04/20 11:15:33 d2.evaluation.evaluator]: [0mInference done 1849/8355. 0.1164 s / img. ETA=0:12:52
[32m[04/20 11:15:38 d2.evaluation.evaluator]: [0mInference done 1891/8355. 0.1164 s / img. ETA=0:12:47
[32m[04/20 11:15:43 d2.evaluation.evaluator]: [0mInference done 1933/8355. 0.1165 s / img. ETA=0:12:42
[32m[04/20 11:15:48 d2.evaluation.evaluator]: [0mInference done 1975/8355. 0.1165 s / img. ETA=0:12:37
[32m[04/20 11:15:53 d2.evaluation.evaluator]: [0mInference done 2015/8355. 0.1166 s / img. ETA=0:12:33
[32m[04/20 11:15:58 d2.evaluation.evaluator]: [0mInference done 2057/8355. 0.1166 s / img. ETA=0:12:29
[32m[04/20 11:16:03 d2.evaluation.evaluator]: [0mInference done 2099/8355. 0.1166 s / img. ETA=0:12:24
[32m[04/20 11:16:08 d2.evaluation.evaluator]: [0mInference done 2142/8355. 0.1166 s / img. ETA=0:12:18
[32m[04/20 11:16:13 d2.evaluation.evaluator]: [0mInference done 2185/8355. 0.1166 s / img. ETA=0:12:13
[32m[04/20 11:16:19 d2.evaluation.evaluator]: [0mInference done 2228/8355. 0.1166 s / img. ETA=0:12:08
[32m[04/20 11:16:24 d2.evaluation.evaluator]: [0mInference done 2270/8355. 0.1166 s / img. ETA=0:12:03
[32m[04/20 11:16:29 d2.evaluation.evaluator]: [0mInference done 2312/8355. 0.1166 s / img. ETA=0:11:58
[32m[04/20 11:16:34 d2.evaluation.evaluator]: [0mInference done 2354/8355. 0.1166 s / img. ETA=0:11:53
[32m[04/20 11:16:39 d2.evaluation.evaluator]: [0mInference done 2397/8355. 0.1166 s / img. ETA=0:11:48
[32m[04/20 11:16:44 d2.evaluation.evaluator]: [0mInference done 2440/8355. 0.1166 s / img. ETA=0:11:43
[32m[04/20 11:16:49 d2.evaluation.evaluator]: [0mInference done 2483/8355. 0.1166 s / img. ETA=0:11:38
[32m[04/20 11:16:54 d2.evaluation.evaluator]: [0mInference done 2526/8355. 0.1166 s / img. ETA=0:11:33
[32m[04/20 11:16:59 d2.evaluation.evaluator]: [0mInference done 2568/8355. 0.1166 s / img. ETA=0:11:28
[32m[04/20 11:17:04 d2.evaluation.evaluator]: [0mInference done 2611/8355. 0.1166 s / img. ETA=0:11:23
[32m[04/20 11:17:09 d2.evaluation.evaluator]: [0mInference done 2653/8355. 0.1166 s / img. ETA=0:11:18
[32m[04/20 11:17:14 d2.evaluation.evaluator]: [0mInference done 2695/8355. 0.1166 s / img. ETA=0:11:13
[32m[04/20 11:17:19 d2.evaluation.evaluator]: [0mInference done 2737/8355. 0.1166 s / img. ETA=0:11:08
[32m[04/20 11:17:24 d2.evaluation.evaluator]: [0mInference done 2780/8355. 0.1166 s / img. ETA=0:11:03
[32m[04/20 11:17:29 d2.evaluation.evaluator]: [0mInference done 2822/8355. 0.1166 s / img. ETA=0:10:58
[32m[04/20 11:17:34 d2.evaluation.evaluator]: [0mInference done 2864/8355. 0.1167 s / img. ETA=0:10:53
[32m[04/20 11:17:39 d2.evaluation.evaluator]: [0mInference done 2907/8355. 0.1167 s / img. ETA=0:10:48
[32m[04/20 11:17:45 d2.evaluation.evaluator]: [0mInference done 2949/8355. 0.1167 s / img. ETA=0:10:43
[32m[04/20 11:17:50 d2.evaluation.evaluator]: [0mInference done 2992/8355. 0.1167 s / img. ETA=0:10:38
[32m[04/20 11:17:55 d2.evaluation.evaluator]: [0mInference done 3035/8355. 0.1167 s / img. ETA=0:10:33
[32m[04/20 11:18:00 d2.evaluation.evaluator]: [0mInference done 3077/8355. 0.1167 s / img. ETA=0:10:28
[32m[04/20 11:18:05 d2.evaluation.evaluator]: [0mInference done 3119/8355. 0.1167 s / img. ETA=0:10:23
[32m[04/20 11:18:10 d2.evaluation.evaluator]: [0mInference done 3162/8355. 0.1167 s / img. ETA=0:10:17
[32m[04/20 11:18:15 d2.evaluation.evaluator]: [0mInference done 3205/8355. 0.1166 s / img. ETA=0:10:12
[32m[04/20 11:18:20 d2.evaluation.evaluator]: [0mInference done 3248/8355. 0.1166 s / img. ETA=0:10:07
[32m[04/20 11:18:25 d2.evaluation.evaluator]: [0mInference done 3291/8355. 0.1166 s / img. ETA=0:10:02
[32m[04/20 11:18:30 d2.evaluation.evaluator]: [0mInference done 3333/8355. 0.1166 s / img. ETA=0:09:57
[32m[04/20 11:18:35 d2.evaluation.evaluator]: [0mInference done 3376/8355. 0.1166 s / img. ETA=0:09:52
[32m[04/20 11:18:40 d2.evaluation.evaluator]: [0mInference done 3419/8355. 0.1166 s / img. ETA=0:09:47
[32m[04/20 11:18:45 d2.evaluation.evaluator]: [0mInference done 3462/8355. 0.1166 s / img. ETA=0:09:42
[32m[04/20 11:18:50 d2.evaluation.evaluator]: [0mInference done 3504/8355. 0.1166 s / img. ETA=0:09:37
[32m[04/20 11:18:55 d2.evaluation.evaluator]: [0mInference done 3546/8355. 0.1166 s / img. ETA=0:09:32
[32m[04/20 11:19:00 d2.evaluation.evaluator]: [0mInference done 3588/8355. 0.1166 s / img. ETA=0:09:27
[32m[04/20 11:19:05 d2.evaluation.evaluator]: [0mInference done 3630/8355. 0.1166 s / img. ETA=0:09:22
[32m[04/20 11:19:11 d2.evaluation.evaluator]: [0mInference done 3672/8355. 0.1166 s / img. ETA=0:09:17
[32m[04/20 11:19:16 d2.evaluation.evaluator]: [0mInference done 3715/8355. 0.1166 s / img. ETA=0:09:12
[32m[04/20 11:19:21 d2.evaluation.evaluator]: [0mInference done 3758/8355. 0.1166 s / img. ETA=0:09:06
[32m[04/20 11:19:26 d2.evaluation.evaluator]: [0mInference done 3800/8355. 0.1166 s / img. ETA=0:09:02
[32m[04/20 11:19:31 d2.evaluation.evaluator]: [0mInference done 3842/8355. 0.1166 s / img. ETA=0:08:57
[32m[04/20 11:19:36 d2.evaluation.evaluator]: [0mInference done 3885/8355. 0.1166 s / img. ETA=0:08:51
[32m[04/20 11:19:41 d2.evaluation.evaluator]: [0mInference done 3928/8355. 0.1166 s / img. ETA=0:08:46
[32m[04/20 11:19:46 d2.evaluation.evaluator]: [0mInference done 3971/8355. 0.1166 s / img. ETA=0:08:41
[32m[04/20 11:19:51 d2.evaluation.evaluator]: [0mInference done 4013/8355. 0.1166 s / img. ETA=0:08:36
[32m[04/20 11:19:56 d2.evaluation.evaluator]: [0mInference done 4055/8355. 0.1166 s / img. ETA=0:08:31
[32m[04/20 11:20:01 d2.evaluation.evaluator]: [0mInference done 4097/8355. 0.1166 s / img. ETA=0:08:26
[32m[04/20 11:20:06 d2.evaluation.evaluator]: [0mInference done 4139/8355. 0.1166 s / img. ETA=0:08:21
[32m[04/20 11:20:11 d2.evaluation.evaluator]: [0mInference done 4181/8355. 0.1166 s / img. ETA=0:08:16
[32m[04/20 11:20:16 d2.evaluation.evaluator]: [0mInference done 4223/8355. 0.1167 s / img. ETA=0:08:11
[32m[04/20 11:20:21 d2.evaluation.evaluator]: [0mInference done 4266/8355. 0.1166 s / img. ETA=0:08:06
[32m[04/20 11:20:26 d2.evaluation.evaluator]: [0mInference done 4308/8355. 0.1167 s / img. ETA=0:08:01
[32m[04/20 11:20:31 d2.evaluation.evaluator]: [0mInference done 4351/8355. 0.1166 s / img. ETA=0:07:56
[32m[04/20 11:20:36 d2.evaluation.evaluator]: [0mInference done 4393/8355. 0.1166 s / img. ETA=0:07:51
[32m[04/20 11:20:41 d2.evaluation.evaluator]: [0mInference done 4435/8355. 0.1167 s / img. ETA=0:07:46
[32m[04/20 11:20:47 d2.evaluation.evaluator]: [0mInference done 4478/8355. 0.1167 s / img. ETA=0:07:41
[32m[04/20 11:20:52 d2.evaluation.evaluator]: [0mInference done 4520/8355. 0.1167 s / img. ETA=0:07:36
[32m[04/20 11:20:57 d2.evaluation.evaluator]: [0mInference done 4562/8355. 0.1167 s / img. ETA=0:07:31
[32m[04/20 11:21:02 d2.evaluation.evaluator]: [0mInference done 4604/8355. 0.1167 s / img. ETA=0:07:26
[32m[04/20 11:21:07 d2.evaluation.evaluator]: [0mInference done 4646/8355. 0.1167 s / img. ETA=0:07:21
[32m[04/20 11:21:12 d2.evaluation.evaluator]: [0mInference done 4689/8355. 0.1167 s / img. ETA=0:07:16
[32m[04/20 11:21:17 d2.evaluation.evaluator]: [0mInference done 4732/8355. 0.1167 s / img. ETA=0:07:11
[32m[04/20 11:21:22 d2.evaluation.evaluator]: [0mInference done 4774/8355. 0.1167 s / img. ETA=0:07:06
[32m[04/20 11:21:27 d2.evaluation.evaluator]: [0mInference done 4816/8355. 0.1167 s / img. ETA=0:07:01
[32m[04/20 11:21:32 d2.evaluation.evaluator]: [0mInference done 4858/8355. 0.1167 s / img. ETA=0:06:56
[32m[04/20 11:21:37 d2.evaluation.evaluator]: [0mInference done 4900/8355. 0.1167 s / img. ETA=0:06:51
[32m[04/20 11:21:42 d2.evaluation.evaluator]: [0mInference done 4942/8355. 0.1167 s / img. ETA=0:06:46
[32m[04/20 11:21:47 d2.evaluation.evaluator]: [0mInference done 4984/8355. 0.1167 s / img. ETA=0:06:41
[32m[04/20 11:21:52 d2.evaluation.evaluator]: [0mInference done 5026/8355. 0.1167 s / img. ETA=0:06:36
[32m[04/20 11:21:57 d2.evaluation.evaluator]: [0mInference done 5068/8355. 0.1167 s / img. ETA=0:06:31
[32m[04/20 11:22:02 d2.evaluation.evaluator]: [0mInference done 5110/8355. 0.1167 s / img. ETA=0:06:26
[32m[04/20 11:22:07 d2.evaluation.evaluator]: [0mInference done 5152/8355. 0.1167 s / img. ETA=0:06:21
[32m[04/20 11:22:12 d2.evaluation.evaluator]: [0mInference done 5194/8355. 0.1167 s / img. ETA=0:06:16
[32m[04/20 11:22:17 d2.evaluation.evaluator]: [0mInference done 5236/8355. 0.1167 s / img. ETA=0:06:11
[32m[04/20 11:22:22 d2.evaluation.evaluator]: [0mInference done 5278/8355. 0.1167 s / img. ETA=0:06:06
[32m[04/20 11:22:27 d2.evaluation.evaluator]: [0mInference done 5320/8355. 0.1167 s / img. ETA=0:06:01
[32m[04/20 11:22:32 d2.evaluation.evaluator]: [0mInference done 5362/8355. 0.1167 s / img. ETA=0:05:56
[32m[04/20 11:22:37 d2.evaluation.evaluator]: [0mInference done 5404/8355. 0.1167 s / img. ETA=0:05:51
[32m[04/20 11:22:42 d2.evaluation.evaluator]: [0mInference done 5446/8355. 0.1167 s / img. ETA=0:05:46
[32m[04/20 11:22:47 d2.evaluation.evaluator]: [0mInference done 5488/8355. 0.1167 s / img. ETA=0:05:41
[32m[04/20 11:22:52 d2.evaluation.evaluator]: [0mInference done 5531/8355. 0.1167 s / img. ETA=0:05:36
[32m[04/20 11:22:58 d2.evaluation.evaluator]: [0mInference done 5574/8355. 0.1167 s / img. ETA=0:05:31
[32m[04/20 11:23:03 d2.evaluation.evaluator]: [0mInference done 5616/8355. 0.1167 s / img. ETA=0:05:26
[32m[04/20 11:23:08 d2.evaluation.evaluator]: [0mInference done 5658/8355. 0.1167 s / img. ETA=0:05:21
[32m[04/20 11:23:13 d2.evaluation.evaluator]: [0mInference done 5700/8355. 0.1167 s / img. ETA=0:05:16
[32m[04/20 11:23:18 d2.evaluation.evaluator]: [0mInference done 5742/8355. 0.1168 s / img. ETA=0:05:11
[32m[04/20 11:23:23 d2.evaluation.evaluator]: [0mInference done 5784/8355. 0.1168 s / img. ETA=0:05:06
[32m[04/20 11:23:28 d2.evaluation.evaluator]: [0mInference done 5826/8355. 0.1168 s / img. ETA=0:05:01
[32m[04/20 11:23:33 d2.evaluation.evaluator]: [0mInference done 5868/8355. 0.1168 s / img. ETA=0:04:56
[32m[04/20 11:23:38 d2.evaluation.evaluator]: [0mInference done 5910/8355. 0.1168 s / img. ETA=0:04:51
[32m[04/20 11:23:43 d2.evaluation.evaluator]: [0mInference done 5952/8355. 0.1168 s / img. ETA=0:04:46
[32m[04/20 11:23:48 d2.evaluation.evaluator]: [0mInference done 5994/8355. 0.1168 s / img. ETA=0:04:41
[32m[04/20 11:23:53 d2.evaluation.evaluator]: [0mInference done 6036/8355. 0.1168 s / img. ETA=0:04:36
[32m[04/20 11:23:58 d2.evaluation.evaluator]: [0mInference done 6078/8355. 0.1168 s / img. ETA=0:04:31
[32m[04/20 11:24:03 d2.evaluation.evaluator]: [0mInference done 6120/8355. 0.1168 s / img. ETA=0:04:26
[32m[04/20 11:24:08 d2.evaluation.evaluator]: [0mInference done 6162/8355. 0.1168 s / img. ETA=0:04:21
[32m[04/20 11:24:13 d2.evaluation.evaluator]: [0mInference done 6204/8355. 0.1168 s / img. ETA=0:04:16
[32m[04/20 11:24:18 d2.evaluation.evaluator]: [0mInference done 6246/8355. 0.1168 s / img. ETA=0:04:11
[32m[04/20 11:24:23 d2.evaluation.evaluator]: [0mInference done 6288/8355. 0.1169 s / img. ETA=0:04:06
[32m[04/20 11:24:29 d2.evaluation.evaluator]: [0mInference done 6330/8355. 0.1169 s / img. ETA=0:04:01
[32m[04/20 11:24:34 d2.evaluation.evaluator]: [0mInference done 6372/8355. 0.1169 s / img. ETA=0:03:56
[32m[04/20 11:24:39 d2.evaluation.evaluator]: [0mInference done 6414/8355. 0.1169 s / img. ETA=0:03:51
[32m[04/20 11:24:44 d2.evaluation.evaluator]: [0mInference done 6456/8355. 0.1169 s / img. ETA=0:03:46
[32m[04/20 11:24:49 d2.evaluation.evaluator]: [0mInference done 6498/8355. 0.1169 s / img. ETA=0:03:41
[32m[04/20 11:24:54 d2.evaluation.evaluator]: [0mInference done 6541/8355. 0.1169 s / img. ETA=0:03:36
[32m[04/20 11:24:59 d2.evaluation.evaluator]: [0mInference done 6584/8355. 0.1169 s / img. ETA=0:03:31
[32m[04/20 11:25:04 d2.evaluation.evaluator]: [0mInference done 6626/8355. 0.1169 s / img. ETA=0:03:26
[32m[04/20 11:25:09 d2.evaluation.evaluator]: [0mInference done 6668/8355. 0.1169 s / img. ETA=0:03:21
[32m[04/20 11:25:14 d2.evaluation.evaluator]: [0mInference done 6711/8355. 0.1169 s / img. ETA=0:03:16
[32m[04/20 11:25:19 d2.evaluation.evaluator]: [0mInference done 6754/8355. 0.1169 s / img. ETA=0:03:10
[32m[04/20 11:25:24 d2.evaluation.evaluator]: [0mInference done 6797/8355. 0.1169 s / img. ETA=0:03:05
[32m[04/20 11:25:29 d2.evaluation.evaluator]: [0mInference done 6839/8355. 0.1169 s / img. ETA=0:03:00
[32m[04/20 11:25:34 d2.evaluation.evaluator]: [0mInference done 6881/8355. 0.1169 s / img. ETA=0:02:55
[32m[04/20 11:25:39 d2.evaluation.evaluator]: [0mInference done 6923/8355. 0.1169 s / img. ETA=0:02:50
[32m[04/20 11:25:44 d2.evaluation.evaluator]: [0mInference done 6965/8355. 0.1169 s / img. ETA=0:02:45
[32m[04/20 11:25:49 d2.evaluation.evaluator]: [0mInference done 7007/8355. 0.1169 s / img. ETA=0:02:40
[32m[04/20 11:25:54 d2.evaluation.evaluator]: [0mInference done 7049/8355. 0.1169 s / img. ETA=0:02:35
[32m[04/20 11:25:59 d2.evaluation.evaluator]: [0mInference done 7091/8355. 0.1169 s / img. ETA=0:02:30
[32m[04/20 11:26:05 d2.evaluation.evaluator]: [0mInference done 7133/8355. 0.1169 s / img. ETA=0:02:25
[32m[04/20 11:26:10 d2.evaluation.evaluator]: [0mInference done 7175/8355. 0.1169 s / img. ETA=0:02:20
[32m[04/20 11:26:15 d2.evaluation.evaluator]: [0mInference done 7217/8355. 0.1169 s / img. ETA=0:02:15
[32m[04/20 11:26:20 d2.evaluation.evaluator]: [0mInference done 7259/8355. 0.1169 s / img. ETA=0:02:10
[32m[04/20 11:26:25 d2.evaluation.evaluator]: [0mInference done 7301/8355. 0.1169 s / img. ETA=0:02:05
[32m[04/20 11:26:30 d2.evaluation.evaluator]: [0mInference done 7343/8355. 0.1169 s / img. ETA=0:02:00
[32m[04/20 11:26:35 d2.evaluation.evaluator]: [0mInference done 7385/8355. 0.1169 s / img. ETA=0:01:55
[32m[04/20 11:26:40 d2.evaluation.evaluator]: [0mInference done 7427/8355. 0.1169 s / img. ETA=0:01:50
[32m[04/20 11:26:45 d2.evaluation.evaluator]: [0mInference done 7469/8355. 0.1169 s / img. ETA=0:01:45
[32m[04/20 11:26:50 d2.evaluation.evaluator]: [0mInference done 7511/8355. 0.1169 s / img. ETA=0:01:40
[32m[04/20 11:26:55 d2.evaluation.evaluator]: [0mInference done 7553/8355. 0.1169 s / img. ETA=0:01:35
[32m[04/20 11:27:00 d2.evaluation.evaluator]: [0mInference done 7595/8355. 0.1169 s / img. ETA=0:01:30
[32m[04/20 11:27:05 d2.evaluation.evaluator]: [0mInference done 7637/8355. 0.1169 s / img. ETA=0:01:25
[32m[04/20 11:27:10 d2.evaluation.evaluator]: [0mInference done 7679/8355. 0.1170 s / img. ETA=0:01:20
[32m[04/20 11:27:15 d2.evaluation.evaluator]: [0mInference done 7721/8355. 0.1170 s / img. ETA=0:01:15
[32m[04/20 11:27:20 d2.evaluation.evaluator]: [0mInference done 7763/8355. 0.1170 s / img. ETA=0:01:10
[32m[04/20 11:27:25 d2.evaluation.evaluator]: [0mInference done 7805/8355. 0.1170 s / img. ETA=0:01:05
[32m[04/20 11:27:30 d2.evaluation.evaluator]: [0mInference done 7847/8355. 0.1170 s / img. ETA=0:01:00
[32m[04/20 11:27:35 d2.evaluation.evaluator]: [0mInference done 7889/8355. 0.1170 s / img. ETA=0:00:55
[32m[04/20 11:27:41 d2.evaluation.evaluator]: [0mInference done 7931/8355. 0.1170 s / img. ETA=0:00:50
[32m[04/20 11:27:46 d2.evaluation.evaluator]: [0mInference done 7973/8355. 0.1170 s / img. ETA=0:00:45
[32m[04/20 11:27:51 d2.evaluation.evaluator]: [0mInference done 8015/8355. 0.1170 s / img. ETA=0:00:40
[32m[04/20 11:27:56 d2.evaluation.evaluator]: [0mInference done 8057/8355. 0.1170 s / img. ETA=0:00:35
[32m[04/20 11:28:01 d2.evaluation.evaluator]: [0mInference done 8099/8355. 0.1170 s / img. ETA=0:00:30
[32m[04/20 11:28:06 d2.evaluation.evaluator]: [0mInference done 8141/8355. 0.1170 s / img. ETA=0:00:25
[32m[04/20 11:28:11 d2.evaluation.evaluator]: [0mInference done 8183/8355. 0.1170 s / img. ETA=0:00:20
[32m[04/20 11:28:16 d2.evaluation.evaluator]: [0mInference done 8225/8355. 0.1170 s / img. ETA=0:00:15
[32m[04/20 11:28:21 d2.evaluation.evaluator]: [0mInference done 8267/8355. 0.1170 s / img. ETA=0:00:10
[32m[04/20 11:28:26 d2.evaluation.evaluator]: [0mInference done 8309/8355. 0.1170 s / img. ETA=0:00:05
[32m[04/20 11:28:31 d2.evaluation.evaluator]: [0mInference done 8351/8355. 0.1170 s / img. ETA=0:00:00
[32m[04/20 11:28:31 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:37.158018 (0.119420 s / img per device, on 1 devices)
[32m[04/20 11:28:31 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:16 (0.116994 s / img per device, on 1 devices)
[32m[04/20 11:28:32 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 11:28:32 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 11:28:32 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=18.64s).
Accumulating evaluation results...
DONE (t=2.14s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.640
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.319
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.466
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.141
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.385
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.395
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.296
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.669
[32m[04/20 11:28:53 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 34.108 | 63.985 | 31.920 | 23.276 | 46.628 | 62.446 |
[32m[04/20 11:28:53 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 36.409 | bicycle       | 22.437 | car            | 43.479 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 11:28:54 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 11:28:54 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 11:28:54 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 11:28:56 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1177 s / img. ETA=0:02:29
[32m[04/20 11:29:01 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1170 s / img. ETA=0:02:23
[32m[04/20 11:29:06 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1170 s / img. ETA=0:02:18
[32m[04/20 11:29:11 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1169 s / img. ETA=0:02:13
[32m[04/20 11:29:16 d2.evaluation.evaluator]: [0mInference done 180/1257. 0.1168 s / img. ETA=0:02:08
[32m[04/20 11:29:21 d2.evaluation.evaluator]: [0mInference done 222/1257. 0.1169 s / img. ETA=0:02:03
[32m[04/20 11:29:26 d2.evaluation.evaluator]: [0mInference done 264/1257. 0.1168 s / img. ETA=0:01:58
[32m[04/20 11:29:31 d2.evaluation.evaluator]: [0mInference done 306/1257. 0.1168 s / img. ETA=0:01:53
[32m[04/20 11:29:36 d2.evaluation.evaluator]: [0mInference done 348/1257. 0.1168 s / img. ETA=0:01:48
[32m[04/20 11:29:41 d2.evaluation.evaluator]: [0mInference done 390/1257. 0.1168 s / img. ETA=0:01:43
[32m[04/20 11:29:46 d2.evaluation.evaluator]: [0mInference done 432/1257. 0.1168 s / img. ETA=0:01:38
[32m[04/20 11:29:51 d2.evaluation.evaluator]: [0mInference done 474/1257. 0.1168 s / img. ETA=0:01:33
[32m[04/20 11:29:56 d2.evaluation.evaluator]: [0mInference done 516/1257. 0.1168 s / img. ETA=0:01:28
[32m[04/20 11:30:01 d2.evaluation.evaluator]: [0mInference done 558/1257. 0.1169 s / img. ETA=0:01:23
[32m[04/20 11:30:06 d2.evaluation.evaluator]: [0mInference done 600/1257. 0.1170 s / img. ETA=0:01:18
[32m[04/20 11:30:11 d2.evaluation.evaluator]: [0mInference done 642/1257. 0.1170 s / img. ETA=0:01:13
[32m[04/20 11:30:16 d2.evaluation.evaluator]: [0mInference done 684/1257. 0.1170 s / img. ETA=0:01:08
[32m[04/20 11:30:21 d2.evaluation.evaluator]: [0mInference done 726/1257. 0.1171 s / img. ETA=0:01:03
[32m[04/20 11:30:26 d2.evaluation.evaluator]: [0mInference done 768/1257. 0.1170 s / img. ETA=0:00:58
[32m[04/20 11:30:31 d2.evaluation.evaluator]: [0mInference done 810/1257. 0.1170 s / img. ETA=0:00:53
[32m[04/20 11:30:36 d2.evaluation.evaluator]: [0mInference done 852/1257. 0.1170 s / img. ETA=0:00:48
[32m[04/20 11:30:41 d2.evaluation.evaluator]: [0mInference done 894/1257. 0.1171 s / img. ETA=0:00:43
[32m[04/20 11:30:46 d2.evaluation.evaluator]: [0mInference done 936/1257. 0.1171 s / img. ETA=0:00:38
[32m[04/20 11:30:51 d2.evaluation.evaluator]: [0mInference done 978/1257. 0.1171 s / img. ETA=0:00:33
[32m[04/20 11:30:56 d2.evaluation.evaluator]: [0mInference done 1020/1257. 0.1171 s / img. ETA=0:00:28
[32m[04/20 11:31:01 d2.evaluation.evaluator]: [0mInference done 1062/1257. 0.1171 s / img. ETA=0:00:23
[32m[04/20 11:31:06 d2.evaluation.evaluator]: [0mInference done 1104/1257. 0.1171 s / img. ETA=0:00:18
[32m[04/20 11:31:11 d2.evaluation.evaluator]: [0mInference done 1146/1257. 0.1171 s / img. ETA=0:00:13
[32m[04/20 11:31:16 d2.evaluation.evaluator]: [0mInference done 1188/1257. 0.1171 s / img. ETA=0:00:08
[32m[04/20 11:31:21 d2.evaluation.evaluator]: [0mInference done 1230/1257. 0.1171 s / img. ETA=0:00:03
[32m[04/20 11:31:25 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:29.748808 (0.119608 s / img per device, on 1 devices)
[32m[04/20 11:31:25 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:26 (0.117070 s / img per device, on 1 devices)
[32m[04/20 11:31:25 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 11:31:25 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 11:31:25 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.63s).
Accumulating evaluation results...
DONE (t=0.34s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.274
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.537
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.247
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.494
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.137
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.326
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.223
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.393
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.549
[32m[04/20 11:31:28 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 27.449 | 53.684 | 24.716 | 16.604 | 33.343 | 49.440 |
[32m[04/20 11:31:28 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 28.525 | bicycle       | 11.044 | car            | 42.778 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  10  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 11:31:29 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 11:31:29 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 11:31:29 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 11:31:29 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 11:31:30 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 11:31:30 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 11:31:30 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 11:31:50 d2.utils.events]: [0m eta: 0:17:14  iter: 19  total_loss: 0.716  loss_cls: 0.230  loss_box_reg: 0.394  loss_rpn_cls: 0.019  loss_rpn_loc: 0.068  time: 1.0381  data_time: 0.0327  lr: 0.000100  max_mem: 5405M
[32m[04/20 11:32:11 d2.utils.events]: [0m eta: 0:16:56  iter: 39  total_loss: 0.643  loss_cls: 0.209  loss_box_reg: 0.353  loss_rpn_cls: 0.017  loss_rpn_loc: 0.054  time: 1.0415  data_time: 0.0097  lr: 0.000200  max_mem: 5405M
[32m[04/20 11:32:31 d2.utils.events]: [0m eta: 0:16:01  iter: 59  total_loss: 0.691  loss_cls: 0.226  loss_box_reg: 0.359  loss_rpn_cls: 0.021  loss_rpn_loc: 0.075  time: 1.0262  data_time: 0.0096  lr: 0.000300  max_mem: 5405M
[32m[04/20 11:32:52 d2.utils.events]: [0m eta: 0:15:45  iter: 79  total_loss: 0.638  loss_cls: 0.210  loss_box_reg: 0.349  loss_rpn_cls: 0.017  loss_rpn_loc: 0.048  time: 1.0259  data_time: 0.0100  lr: 0.000400  max_mem: 5405M
[32m[04/20 11:33:12 d2.utils.events]: [0m eta: 0:15:24  iter: 99  total_loss: 0.618  loss_cls: 0.208  loss_box_reg: 0.326  loss_rpn_cls: 0.021  loss_rpn_loc: 0.063  time: 1.0255  data_time: 0.0097  lr: 0.000500  max_mem: 5405M
[32m[04/20 11:33:33 d2.utils.events]: [0m eta: 0:15:00  iter: 119  total_loss: 0.644  loss_cls: 0.209  loss_box_reg: 0.352  loss_rpn_cls: 0.015  loss_rpn_loc: 0.060  time: 1.0247  data_time: 0.0098  lr: 0.000599  max_mem: 5405M
[32m[04/20 11:33:53 d2.utils.events]: [0m eta: 0:14:39  iter: 139  total_loss: 0.618  loss_cls: 0.202  loss_box_reg: 0.361  loss_rpn_cls: 0.013  loss_rpn_loc: 0.049  time: 1.0240  data_time: 0.0100  lr: 0.000699  max_mem: 5405M
[32m[04/20 11:34:14 d2.utils.events]: [0m eta: 0:14:21  iter: 159  total_loss: 0.534  loss_cls: 0.178  loss_box_reg: 0.288  loss_rpn_cls: 0.015  loss_rpn_loc: 0.048  time: 1.0244  data_time: 0.0094  lr: 0.000799  max_mem: 5405M
[32m[04/20 11:34:35 d2.utils.events]: [0m eta: 0:14:01  iter: 179  total_loss: 0.684  loss_cls: 0.236  loss_box_reg: 0.374  loss_rpn_cls: 0.018  loss_rpn_loc: 0.061  time: 1.0244  data_time: 0.0097  lr: 0.000899  max_mem: 5405M
[32m[04/20 11:34:55 d2.utils.events]: [0m eta: 0:13:41  iter: 199  total_loss: 0.615  loss_cls: 0.207  loss_box_reg: 0.331  loss_rpn_cls: 0.016  loss_rpn_loc: 0.053  time: 1.0248  data_time: 0.0096  lr: 0.000999  max_mem: 5405M
[32m[04/20 11:35:16 d2.utils.events]: [0m eta: 0:13:22  iter: 219  total_loss: 0.624  loss_cls: 0.199  loss_box_reg: 0.347  loss_rpn_cls: 0.014  loss_rpn_loc: 0.057  time: 1.0266  data_time: 0.0099  lr: 0.001099  max_mem: 5405M
[32m[04/20 11:35:37 d2.utils.events]: [0m eta: 0:13:02  iter: 239  total_loss: 0.640  loss_cls: 0.209  loss_box_reg: 0.349  loss_rpn_cls: 0.019  loss_rpn_loc: 0.052  time: 1.0262  data_time: 0.0096  lr: 0.001199  max_mem: 5405M
[32m[04/20 11:35:57 d2.utils.events]: [0m eta: 0:12:41  iter: 259  total_loss: 0.643  loss_cls: 0.209  loss_box_reg: 0.350  loss_rpn_cls: 0.018  loss_rpn_loc: 0.052  time: 1.0272  data_time: 0.0099  lr: 0.001299  max_mem: 5405M
[32m[04/20 11:36:18 d2.utils.events]: [0m eta: 0:12:21  iter: 279  total_loss: 0.638  loss_cls: 0.209  loss_box_reg: 0.340  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0273  data_time: 0.0098  lr: 0.001399  max_mem: 5405M
[32m[04/20 11:36:38 d2.utils.events]: [0m eta: 0:12:01  iter: 299  total_loss: 0.596  loss_cls: 0.183  loss_box_reg: 0.326  loss_rpn_cls: 0.013  loss_rpn_loc: 0.047  time: 1.0267  data_time: 0.0098  lr: 0.001499  max_mem: 5405M
[32m[04/20 11:36:59 d2.utils.events]: [0m eta: 0:11:41  iter: 319  total_loss: 0.632  loss_cls: 0.210  loss_box_reg: 0.328  loss_rpn_cls: 0.021  loss_rpn_loc: 0.054  time: 1.0269  data_time: 0.0097  lr: 0.001598  max_mem: 5405M
[32m[04/20 11:37:20 d2.utils.events]: [0m eta: 0:11:21  iter: 339  total_loss: 0.616  loss_cls: 0.189  loss_box_reg: 0.351  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0277  data_time: 0.0096  lr: 0.001698  max_mem: 5405M
[32m[04/20 11:37:40 d2.utils.events]: [0m eta: 0:10:59  iter: 359  total_loss: 0.600  loss_cls: 0.191  loss_box_reg: 0.337  loss_rpn_cls: 0.015  loss_rpn_loc: 0.064  time: 1.0259  data_time: 0.0097  lr: 0.001798  max_mem: 5405M
[32m[04/20 11:38:01 d2.utils.events]: [0m eta: 0:10:39  iter: 379  total_loss: 0.527  loss_cls: 0.175  loss_box_reg: 0.295  loss_rpn_cls: 0.018  loss_rpn_loc: 0.042  time: 1.0264  data_time: 0.0096  lr: 0.001898  max_mem: 5405M
[32m[04/20 11:38:21 d2.utils.events]: [0m eta: 0:10:17  iter: 399  total_loss: 0.619  loss_cls: 0.193  loss_box_reg: 0.348  loss_rpn_cls: 0.016  loss_rpn_loc: 0.054  time: 1.0255  data_time: 0.0098  lr: 0.001998  max_mem: 5405M
[32m[04/20 11:38:42 d2.utils.events]: [0m eta: 0:09:58  iter: 419  total_loss: 0.681  loss_cls: 0.212  loss_box_reg: 0.373  loss_rpn_cls: 0.022  loss_rpn_loc: 0.062  time: 1.0265  data_time: 0.0096  lr: 0.002098  max_mem: 5405M
[32m[04/20 11:39:02 d2.utils.events]: [0m eta: 0:09:36  iter: 439  total_loss: 0.585  loss_cls: 0.181  loss_box_reg: 0.319  loss_rpn_cls: 0.017  loss_rpn_loc: 0.049  time: 1.0255  data_time: 0.0095  lr: 0.002198  max_mem: 5405M
[32m[04/20 11:39:22 d2.utils.events]: [0m eta: 0:09:15  iter: 459  total_loss: 0.657  loss_cls: 0.209  loss_box_reg: 0.356  loss_rpn_cls: 0.017  loss_rpn_loc: 0.059  time: 1.0249  data_time: 0.0097  lr: 0.002298  max_mem: 5405M
[32m[04/20 11:39:43 d2.utils.events]: [0m eta: 0:08:55  iter: 479  total_loss: 0.585  loss_cls: 0.194  loss_box_reg: 0.323  loss_rpn_cls: 0.012  loss_rpn_loc: 0.058  time: 1.0259  data_time: 0.0096  lr: 0.002398  max_mem: 5405M
[32m[04/20 11:40:04 d2.utils.events]: [0m eta: 0:08:36  iter: 499  total_loss: 0.628  loss_cls: 0.212  loss_box_reg: 0.322  loss_rpn_cls: 0.017  loss_rpn_loc: 0.056  time: 1.0265  data_time: 0.0098  lr: 0.002498  max_mem: 5405M
[32m[04/20 11:40:25 d2.utils.events]: [0m eta: 0:08:15  iter: 519  total_loss: 0.611  loss_cls: 0.202  loss_box_reg: 0.330  loss_rpn_cls: 0.018  loss_rpn_loc: 0.054  time: 1.0263  data_time: 0.0096  lr: 0.002597  max_mem: 5405M
[32m[04/20 11:40:45 d2.utils.events]: [0m eta: 0:07:54  iter: 539  total_loss: 0.705  loss_cls: 0.233  loss_box_reg: 0.359  loss_rpn_cls: 0.027  loss_rpn_loc: 0.076  time: 1.0265  data_time: 0.0096  lr: 0.002697  max_mem: 5405M
[32m[04/20 11:41:07 d2.utils.events]: [0m eta: 0:07:34  iter: 559  total_loss: 0.672  loss_cls: 0.210  loss_box_reg: 0.345  loss_rpn_cls: 0.017  loss_rpn_loc: 0.070  time: 1.0276  data_time: 0.0097  lr: 0.002797  max_mem: 5405M
[32m[04/20 11:41:28 d2.utils.events]: [0m eta: 0:07:15  iter: 579  total_loss: 0.586  loss_cls: 0.191  loss_box_reg: 0.310  loss_rpn_cls: 0.014  loss_rpn_loc: 0.048  time: 1.0285  data_time: 0.0096  lr: 0.002897  max_mem: 5405M
[32m[04/20 11:41:48 d2.utils.events]: [0m eta: 0:06:55  iter: 599  total_loss: 0.633  loss_cls: 0.228  loss_box_reg: 0.360  loss_rpn_cls: 0.017  loss_rpn_loc: 0.054  time: 1.0286  data_time: 0.0097  lr: 0.002997  max_mem: 5405M
[32m[04/20 11:42:09 d2.utils.events]: [0m eta: 0:06:35  iter: 619  total_loss: 0.594  loss_cls: 0.194  loss_box_reg: 0.344  loss_rpn_cls: 0.014  loss_rpn_loc: 0.054  time: 1.0289  data_time: 0.0097  lr: 0.003097  max_mem: 5405M
[32m[04/20 11:42:30 d2.utils.events]: [0m eta: 0:06:15  iter: 639  total_loss: 0.606  loss_cls: 0.209  loss_box_reg: 0.340  loss_rpn_cls: 0.018  loss_rpn_loc: 0.047  time: 1.0288  data_time: 0.0098  lr: 0.003197  max_mem: 5405M
[32m[04/20 11:42:50 d2.utils.events]: [0m eta: 0:05:54  iter: 659  total_loss: 0.621  loss_cls: 0.197  loss_box_reg: 0.351  loss_rpn_cls: 0.015  loss_rpn_loc: 0.050  time: 1.0285  data_time: 0.0096  lr: 0.003297  max_mem: 5405M
[32m[04/20 11:43:11 d2.utils.events]: [0m eta: 0:05:32  iter: 679  total_loss: 0.562  loss_cls: 0.186  loss_box_reg: 0.308  loss_rpn_cls: 0.014  loss_rpn_loc: 0.053  time: 1.0282  data_time: 0.0097  lr: 0.003397  max_mem: 5405M
[32m[04/20 11:43:31 d2.utils.events]: [0m eta: 0:05:11  iter: 699  total_loss: 0.646  loss_cls: 0.209  loss_box_reg: 0.346  loss_rpn_cls: 0.017  loss_rpn_loc: 0.057  time: 1.0275  data_time: 0.0101  lr: 0.003497  max_mem: 5405M
[32m[04/20 11:43:51 d2.utils.events]: [0m eta: 0:04:50  iter: 719  total_loss: 0.617  loss_cls: 0.191  loss_box_reg: 0.345  loss_rpn_cls: 0.016  loss_rpn_loc: 0.061  time: 1.0277  data_time: 0.0096  lr: 0.003596  max_mem: 5405M
[32m[04/20 11:44:12 d2.utils.events]: [0m eta: 0:04:30  iter: 739  total_loss: 0.634  loss_cls: 0.212  loss_box_reg: 0.348  loss_rpn_cls: 0.016  loss_rpn_loc: 0.054  time: 1.0283  data_time: 0.0098  lr: 0.003696  max_mem: 5405M
[32m[04/20 11:44:33 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.647  loss_cls: 0.208  loss_box_reg: 0.358  loss_rpn_cls: 0.018  loss_rpn_loc: 0.059  time: 1.0280  data_time: 0.0098  lr: 0.003796  max_mem: 5405M
[32m[04/20 11:44:53 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.649  loss_cls: 0.198  loss_box_reg: 0.320  loss_rpn_cls: 0.020  loss_rpn_loc: 0.058  time: 1.0277  data_time: 0.0097  lr: 0.003896  max_mem: 5405M
[32m[04/20 11:45:14 d2.utils.events]: [0m eta: 0:03:27  iter: 799  total_loss: 0.629  loss_cls: 0.200  loss_box_reg: 0.342  loss_rpn_cls: 0.016  loss_rpn_loc: 0.056  time: 1.0274  data_time: 0.0096  lr: 0.003996  max_mem: 5405M
[32m[04/20 11:45:35 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.616  loss_cls: 0.210  loss_box_reg: 0.341  loss_rpn_cls: 0.018  loss_rpn_loc: 0.052  time: 1.0282  data_time: 0.0097  lr: 0.004096  max_mem: 5405M
[32m[04/20 11:45:56 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.632  loss_cls: 0.208  loss_box_reg: 0.347  loss_rpn_cls: 0.021  loss_rpn_loc: 0.060  time: 1.0283  data_time: 0.0097  lr: 0.004196  max_mem: 5405M
[32m[04/20 11:46:17 d2.utils.events]: [0m eta: 0:02:26  iter: 859  total_loss: 0.663  loss_cls: 0.224  loss_box_reg: 0.359  loss_rpn_cls: 0.018  loss_rpn_loc: 0.054  time: 1.0287  data_time: 0.0096  lr: 0.004296  max_mem: 5405M
[32m[04/20 11:46:37 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.618  loss_cls: 0.207  loss_box_reg: 0.344  loss_rpn_cls: 0.019  loss_rpn_loc: 0.059  time: 1.0282  data_time: 0.0096  lr: 0.004396  max_mem: 5405M
[32m[04/20 11:46:58 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.702  loss_cls: 0.221  loss_box_reg: 0.390  loss_rpn_cls: 0.023  loss_rpn_loc: 0.059  time: 1.0284  data_time: 0.0096  lr: 0.004496  max_mem: 5405M
[32m[04/20 11:47:18 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.686  loss_cls: 0.230  loss_box_reg: 0.386  loss_rpn_cls: 0.020  loss_rpn_loc: 0.059  time: 1.0283  data_time: 0.0098  lr: 0.004595  max_mem: 5405M
[32m[04/20 11:47:39 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.695  loss_cls: 0.230  loss_box_reg: 0.375  loss_rpn_cls: 0.024  loss_rpn_loc: 0.062  time: 1.0283  data_time: 0.0098  lr: 0.004695  max_mem: 5405M
[32m[04/20 11:47:59 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.677  loss_cls: 0.218  loss_box_reg: 0.380  loss_rpn_cls: 0.019  loss_rpn_loc: 0.062  time: 1.0283  data_time: 0.0099  lr: 0.004795  max_mem: 5405M
[32m[04/20 11:48:20 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.632  loss_cls: 0.216  loss_box_reg: 0.332  loss_rpn_cls: 0.021  loss_rpn_loc: 0.053  time: 1.0282  data_time: 0.0099  lr: 0.004895  max_mem: 5405M
[5m[31mWARNING[0m [32m[04/20 11:48:44 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 11:48:44 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 11:48:44 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 11:48:44 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.621  loss_cls: 0.207  loss_box_reg: 0.334  loss_rpn_cls: 0.021  loss_rpn_loc: 0.052  time: 1.0283  data_time: 0.0100  lr: 0.004995  max_mem: 5405M
[32m[04/20 11:48:45 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:06 (1.0294 s / it)
[32m[04/20 11:48:45 d2.engine.hooks]: [0mTotal training time: 0:17:12 (0:00:06 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 11:48:48 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 11:48:48 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 11:48:48 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 11:48:50 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1166 s / img. ETA=0:16:29
[32m[04/20 11:48:55 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1166 s / img. ETA=0:16:27
[32m[04/20 11:49:00 d2.evaluation.evaluator]: [0mInference done 96/8355. 0.1161 s / img. ETA=0:16:18
[32m[04/20 11:49:05 d2.evaluation.evaluator]: [0mInference done 139/8355. 0.1160 s / img. ETA=0:16:11
[32m[04/20 11:49:10 d2.evaluation.evaluator]: [0mInference done 182/8355. 0.1158 s / img. ETA=0:16:05
[32m[04/20 11:49:15 d2.evaluation.evaluator]: [0mInference done 225/8355. 0.1159 s / img. ETA=0:16:01
[32m[04/20 11:49:20 d2.evaluation.evaluator]: [0mInference done 268/8355. 0.1160 s / img. ETA=0:15:56
[32m[04/20 11:49:25 d2.evaluation.evaluator]: [0mInference done 311/8355. 0.1160 s / img. ETA=0:15:52
[32m[04/20 11:49:30 d2.evaluation.evaluator]: [0mInference done 354/8355. 0.1160 s / img. ETA=0:15:46
[32m[04/20 11:49:35 d2.evaluation.evaluator]: [0mInference done 397/8355. 0.1161 s / img. ETA=0:15:42
[32m[04/20 11:49:41 d2.evaluation.evaluator]: [0mInference done 440/8355. 0.1161 s / img. ETA=0:15:37
[32m[04/20 11:49:46 d2.evaluation.evaluator]: [0mInference done 483/8355. 0.1161 s / img. ETA=0:15:32
[32m[04/20 11:49:51 d2.evaluation.evaluator]: [0mInference done 526/8355. 0.1160 s / img. ETA=0:15:26
[32m[04/20 11:49:56 d2.evaluation.evaluator]: [0mInference done 569/8355. 0.1160 s / img. ETA=0:15:21
[32m[04/20 11:50:01 d2.evaluation.evaluator]: [0mInference done 612/8355. 0.1160 s / img. ETA=0:15:16
[32m[04/20 11:50:06 d2.evaluation.evaluator]: [0mInference done 655/8355. 0.1160 s / img. ETA=0:15:11
[32m[04/20 11:50:11 d2.evaluation.evaluator]: [0mInference done 698/8355. 0.1160 s / img. ETA=0:15:06
[32m[04/20 11:50:16 d2.evaluation.evaluator]: [0mInference done 741/8355. 0.1161 s / img. ETA=0:15:01
[32m[04/20 11:50:21 d2.evaluation.evaluator]: [0mInference done 784/8355. 0.1160 s / img. ETA=0:14:56
[32m[04/20 11:50:26 d2.evaluation.evaluator]: [0mInference done 827/8355. 0.1161 s / img. ETA=0:14:51
[32m[04/20 11:50:31 d2.evaluation.evaluator]: [0mInference done 870/8355. 0.1161 s / img. ETA=0:14:46
[32m[04/20 11:50:36 d2.evaluation.evaluator]: [0mInference done 912/8355. 0.1161 s / img. ETA=0:14:41
[32m[04/20 11:50:42 d2.evaluation.evaluator]: [0mInference done 955/8355. 0.1161 s / img. ETA=0:14:36
[32m[04/20 11:50:47 d2.evaluation.evaluator]: [0mInference done 998/8355. 0.1161 s / img. ETA=0:14:31
[32m[04/20 11:50:52 d2.evaluation.evaluator]: [0mInference done 1041/8355. 0.1161 s / img. ETA=0:14:26
[32m[04/20 11:50:57 d2.evaluation.evaluator]: [0mInference done 1084/8355. 0.1161 s / img. ETA=0:14:20
[32m[04/20 11:51:02 d2.evaluation.evaluator]: [0mInference done 1127/8355. 0.1160 s / img. ETA=0:14:15
[32m[04/20 11:51:07 d2.evaluation.evaluator]: [0mInference done 1170/8355. 0.1160 s / img. ETA=0:14:10
[32m[04/20 11:51:12 d2.evaluation.evaluator]: [0mInference done 1213/8355. 0.1160 s / img. ETA=0:14:05
[32m[04/20 11:51:17 d2.evaluation.evaluator]: [0mInference done 1256/8355. 0.1160 s / img. ETA=0:14:00
[32m[04/20 11:51:22 d2.evaluation.evaluator]: [0mInference done 1299/8355. 0.1160 s / img. ETA=0:13:55
[32m[04/20 11:51:27 d2.evaluation.evaluator]: [0mInference done 1342/8355. 0.1160 s / img. ETA=0:13:50
[32m[04/20 11:51:32 d2.evaluation.evaluator]: [0mInference done 1385/8355. 0.1160 s / img. ETA=0:13:45
[32m[04/20 11:51:38 d2.evaluation.evaluator]: [0mInference done 1428/8355. 0.1160 s / img. ETA=0:13:40
[32m[04/20 11:51:43 d2.evaluation.evaluator]: [0mInference done 1471/8355. 0.1160 s / img. ETA=0:13:35
[32m[04/20 11:51:48 d2.evaluation.evaluator]: [0mInference done 1513/8355. 0.1161 s / img. ETA=0:13:30
[32m[04/20 11:51:53 d2.evaluation.evaluator]: [0mInference done 1555/8355. 0.1161 s / img. ETA=0:13:25
[32m[04/20 11:51:58 d2.evaluation.evaluator]: [0mInference done 1597/8355. 0.1161 s / img. ETA=0:13:20
[32m[04/20 11:52:03 d2.evaluation.evaluator]: [0mInference done 1639/8355. 0.1162 s / img. ETA=0:13:16
[32m[04/20 11:52:08 d2.evaluation.evaluator]: [0mInference done 1681/8355. 0.1162 s / img. ETA=0:13:11
[32m[04/20 11:52:13 d2.evaluation.evaluator]: [0mInference done 1723/8355. 0.1162 s / img. ETA=0:13:06
[32m[04/20 11:52:18 d2.evaluation.evaluator]: [0mInference done 1765/8355. 0.1163 s / img. ETA=0:13:01
[32m[04/20 11:52:23 d2.evaluation.evaluator]: [0mInference done 1807/8355. 0.1163 s / img. ETA=0:12:57
[32m[04/20 11:52:28 d2.evaluation.evaluator]: [0mInference done 1849/8355. 0.1163 s / img. ETA=0:12:52
[32m[04/20 11:52:33 d2.evaluation.evaluator]: [0mInference done 1891/8355. 0.1164 s / img. ETA=0:12:47
[32m[04/20 11:52:38 d2.evaluation.evaluator]: [0mInference done 1933/8355. 0.1164 s / img. ETA=0:12:42
[32m[04/20 11:52:43 d2.evaluation.evaluator]: [0mInference done 1975/8355. 0.1164 s / img. ETA=0:12:37
[32m[04/20 11:52:48 d2.evaluation.evaluator]: [0mInference done 2017/8355. 0.1164 s / img. ETA=0:12:32
[32m[04/20 11:52:53 d2.evaluation.evaluator]: [0mInference done 2059/8355. 0.1164 s / img. ETA=0:12:27
[32m[04/20 11:52:58 d2.evaluation.evaluator]: [0mInference done 2102/8355. 0.1164 s / img. ETA=0:12:22
[32m[04/20 11:53:03 d2.evaluation.evaluator]: [0mInference done 2145/8355. 0.1164 s / img. ETA=0:12:17
[32m[04/20 11:53:08 d2.evaluation.evaluator]: [0mInference done 2187/8355. 0.1164 s / img. ETA=0:12:12
[32m[04/20 11:53:13 d2.evaluation.evaluator]: [0mInference done 2229/8355. 0.1164 s / img. ETA=0:12:07
[32m[04/20 11:53:18 d2.evaluation.evaluator]: [0mInference done 2271/8355. 0.1164 s / img. ETA=0:12:02
[32m[04/20 11:53:23 d2.evaluation.evaluator]: [0mInference done 2313/8355. 0.1165 s / img. ETA=0:11:58
[32m[04/20 11:53:28 d2.evaluation.evaluator]: [0mInference done 2356/8355. 0.1165 s / img. ETA=0:11:52
[32m[04/20 11:53:33 d2.evaluation.evaluator]: [0mInference done 2398/8355. 0.1165 s / img. ETA=0:11:48
[32m[04/20 11:53:38 d2.evaluation.evaluator]: [0mInference done 2440/8355. 0.1165 s / img. ETA=0:11:43
[32m[04/20 11:53:44 d2.evaluation.evaluator]: [0mInference done 2483/8355. 0.1165 s / img. ETA=0:11:38
[32m[04/20 11:53:49 d2.evaluation.evaluator]: [0mInference done 2525/8355. 0.1165 s / img. ETA=0:11:33
[32m[04/20 11:53:54 d2.evaluation.evaluator]: [0mInference done 2567/8355. 0.1165 s / img. ETA=0:11:28
[32m[04/20 11:53:59 d2.evaluation.evaluator]: [0mInference done 2609/8355. 0.1165 s / img. ETA=0:11:23
[32m[04/20 11:54:04 d2.evaluation.evaluator]: [0mInference done 2651/8355. 0.1165 s / img. ETA=0:11:18
[32m[04/20 11:54:09 d2.evaluation.evaluator]: [0mInference done 2693/8355. 0.1165 s / img. ETA=0:11:13
[32m[04/20 11:54:14 d2.evaluation.evaluator]: [0mInference done 2735/8355. 0.1165 s / img. ETA=0:11:08
[32m[04/20 11:54:19 d2.evaluation.evaluator]: [0mInference done 2778/8355. 0.1165 s / img. ETA=0:11:03
[32m[04/20 11:54:24 d2.evaluation.evaluator]: [0mInference done 2820/8355. 0.1165 s / img. ETA=0:10:58
[32m[04/20 11:54:29 d2.evaluation.evaluator]: [0mInference done 2862/8355. 0.1166 s / img. ETA=0:10:53
[32m[04/20 11:54:34 d2.evaluation.evaluator]: [0mInference done 2904/8355. 0.1166 s / img. ETA=0:10:48
[32m[04/20 11:54:39 d2.evaluation.evaluator]: [0mInference done 2946/8355. 0.1166 s / img. ETA=0:10:43
[32m[04/20 11:54:44 d2.evaluation.evaluator]: [0mInference done 2989/8355. 0.1166 s / img. ETA=0:10:38
[32m[04/20 11:54:49 d2.evaluation.evaluator]: [0mInference done 3032/8355. 0.1166 s / img. ETA=0:10:33
[32m[04/20 11:54:54 d2.evaluation.evaluator]: [0mInference done 3074/8355. 0.1166 s / img. ETA=0:10:28
[32m[04/20 11:54:59 d2.evaluation.evaluator]: [0mInference done 3116/8355. 0.1166 s / img. ETA=0:10:23
[32m[04/20 11:55:04 d2.evaluation.evaluator]: [0mInference done 3159/8355. 0.1166 s / img. ETA=0:10:18
[32m[04/20 11:55:09 d2.evaluation.evaluator]: [0mInference done 3202/8355. 0.1166 s / img. ETA=0:10:13
[32m[04/20 11:55:14 d2.evaluation.evaluator]: [0mInference done 3245/8355. 0.1166 s / img. ETA=0:10:07
[32m[04/20 11:55:20 d2.evaluation.evaluator]: [0mInference done 3288/8355. 0.1166 s / img. ETA=0:10:02
[32m[04/20 11:55:25 d2.evaluation.evaluator]: [0mInference done 3331/8355. 0.1165 s / img. ETA=0:09:57
[32m[04/20 11:55:30 d2.evaluation.evaluator]: [0mInference done 3374/8355. 0.1165 s / img. ETA=0:09:52
[32m[04/20 11:55:35 d2.evaluation.evaluator]: [0mInference done 3417/8355. 0.1165 s / img. ETA=0:09:47
[32m[04/20 11:55:40 d2.evaluation.evaluator]: [0mInference done 3460/8355. 0.1165 s / img. ETA=0:09:42
[32m[04/20 11:55:45 d2.evaluation.evaluator]: [0mInference done 3503/8355. 0.1165 s / img. ETA=0:09:37
[32m[04/20 11:55:50 d2.evaluation.evaluator]: [0mInference done 3546/8355. 0.1165 s / img. ETA=0:09:31
[32m[04/20 11:55:55 d2.evaluation.evaluator]: [0mInference done 3589/8355. 0.1165 s / img. ETA=0:09:26
[32m[04/20 11:56:00 d2.evaluation.evaluator]: [0mInference done 3632/8355. 0.1165 s / img. ETA=0:09:21
[32m[04/20 11:56:05 d2.evaluation.evaluator]: [0mInference done 3675/8355. 0.1165 s / img. ETA=0:09:16
[32m[04/20 11:56:11 d2.evaluation.evaluator]: [0mInference done 3718/8355. 0.1165 s / img. ETA=0:09:11
[32m[04/20 11:56:16 d2.evaluation.evaluator]: [0mInference done 3761/8355. 0.1165 s / img. ETA=0:09:06
[32m[04/20 11:56:21 d2.evaluation.evaluator]: [0mInference done 3803/8355. 0.1165 s / img. ETA=0:09:01
[32m[04/20 11:56:26 d2.evaluation.evaluator]: [0mInference done 3845/8355. 0.1165 s / img. ETA=0:08:56
[32m[04/20 11:56:31 d2.evaluation.evaluator]: [0mInference done 3888/8355. 0.1165 s / img. ETA=0:08:51
[32m[04/20 11:56:36 d2.evaluation.evaluator]: [0mInference done 3931/8355. 0.1165 s / img. ETA=0:08:46
[32m[04/20 11:56:41 d2.evaluation.evaluator]: [0mInference done 3973/8355. 0.1165 s / img. ETA=0:08:41
[32m[04/20 11:56:46 d2.evaluation.evaluator]: [0mInference done 4015/8355. 0.1165 s / img. ETA=0:08:36
[32m[04/20 11:56:51 d2.evaluation.evaluator]: [0mInference done 4057/8355. 0.1165 s / img. ETA=0:08:31
[32m[04/20 11:56:56 d2.evaluation.evaluator]: [0mInference done 4099/8355. 0.1166 s / img. ETA=0:08:26
[32m[04/20 11:57:01 d2.evaluation.evaluator]: [0mInference done 4141/8355. 0.1166 s / img. ETA=0:08:21
[32m[04/20 11:57:06 d2.evaluation.evaluator]: [0mInference done 4183/8355. 0.1166 s / img. ETA=0:08:16
[32m[04/20 11:57:11 d2.evaluation.evaluator]: [0mInference done 4225/8355. 0.1166 s / img. ETA=0:08:11
[32m[04/20 11:57:16 d2.evaluation.evaluator]: [0mInference done 4268/8355. 0.1166 s / img. ETA=0:08:06
[32m[04/20 11:57:21 d2.evaluation.evaluator]: [0mInference done 4310/8355. 0.1166 s / img. ETA=0:08:01
[32m[04/20 11:57:26 d2.evaluation.evaluator]: [0mInference done 4353/8355. 0.1166 s / img. ETA=0:07:56
[32m[04/20 11:57:31 d2.evaluation.evaluator]: [0mInference done 4395/8355. 0.1166 s / img. ETA=0:07:51
[32m[04/20 11:57:36 d2.evaluation.evaluator]: [0mInference done 4437/8355. 0.1166 s / img. ETA=0:07:46
[32m[04/20 11:57:41 d2.evaluation.evaluator]: [0mInference done 4480/8355. 0.1166 s / img. ETA=0:07:41
[32m[04/20 11:57:47 d2.evaluation.evaluator]: [0mInference done 4522/8355. 0.1166 s / img. ETA=0:07:36
[32m[04/20 11:57:52 d2.evaluation.evaluator]: [0mInference done 4564/8355. 0.1166 s / img. ETA=0:07:31
[32m[04/20 11:57:57 d2.evaluation.evaluator]: [0mInference done 4606/8355. 0.1166 s / img. ETA=0:07:26
[32m[04/20 11:58:02 d2.evaluation.evaluator]: [0mInference done 4648/8355. 0.1166 s / img. ETA=0:07:21
[32m[04/20 11:58:07 d2.evaluation.evaluator]: [0mInference done 4690/8355. 0.1166 s / img. ETA=0:07:16
[32m[04/20 11:58:12 d2.evaluation.evaluator]: [0mInference done 4733/8355. 0.1166 s / img. ETA=0:07:11
[32m[04/20 11:58:17 d2.evaluation.evaluator]: [0mInference done 4775/8355. 0.1166 s / img. ETA=0:07:06
[32m[04/20 11:58:22 d2.evaluation.evaluator]: [0mInference done 4817/8355. 0.1166 s / img. ETA=0:07:01
[32m[04/20 11:58:27 d2.evaluation.evaluator]: [0mInference done 4859/8355. 0.1166 s / img. ETA=0:06:56
[32m[04/20 11:58:32 d2.evaluation.evaluator]: [0mInference done 4901/8355. 0.1166 s / img. ETA=0:06:51
[32m[04/20 11:58:37 d2.evaluation.evaluator]: [0mInference done 4944/8355. 0.1166 s / img. ETA=0:06:45
[32m[04/20 11:58:42 d2.evaluation.evaluator]: [0mInference done 4987/8355. 0.1166 s / img. ETA=0:06:40
[32m[04/20 11:58:47 d2.evaluation.evaluator]: [0mInference done 5030/8355. 0.1166 s / img. ETA=0:06:35
[32m[04/20 11:58:52 d2.evaluation.evaluator]: [0mInference done 5072/8355. 0.1166 s / img. ETA=0:06:30
[32m[04/20 11:58:57 d2.evaluation.evaluator]: [0mInference done 5114/8355. 0.1166 s / img. ETA=0:06:25
[32m[04/20 11:59:02 d2.evaluation.evaluator]: [0mInference done 5156/8355. 0.1166 s / img. ETA=0:06:20
[32m[04/20 11:59:07 d2.evaluation.evaluator]: [0mInference done 5198/8355. 0.1166 s / img. ETA=0:06:15
[32m[04/20 11:59:12 d2.evaluation.evaluator]: [0mInference done 5240/8355. 0.1166 s / img. ETA=0:06:10
[32m[04/20 11:59:17 d2.evaluation.evaluator]: [0mInference done 5282/8355. 0.1166 s / img. ETA=0:06:05
[32m[04/20 11:59:22 d2.evaluation.evaluator]: [0mInference done 5324/8355. 0.1166 s / img. ETA=0:06:00
[32m[04/20 11:59:27 d2.evaluation.evaluator]: [0mInference done 5366/8355. 0.1166 s / img. ETA=0:05:55
[32m[04/20 11:59:32 d2.evaluation.evaluator]: [0mInference done 5408/8355. 0.1166 s / img. ETA=0:05:50
[32m[04/20 11:59:37 d2.evaluation.evaluator]: [0mInference done 5450/8355. 0.1167 s / img. ETA=0:05:45
[32m[04/20 11:59:42 d2.evaluation.evaluator]: [0mInference done 5492/8355. 0.1167 s / img. ETA=0:05:40
[32m[04/20 11:59:48 d2.evaluation.evaluator]: [0mInference done 5535/8355. 0.1167 s / img. ETA=0:05:35
[32m[04/20 11:59:53 d2.evaluation.evaluator]: [0mInference done 5577/8355. 0.1167 s / img. ETA=0:05:30
[32m[04/20 11:59:58 d2.evaluation.evaluator]: [0mInference done 5619/8355. 0.1167 s / img. ETA=0:05:25
[32m[04/20 12:00:03 d2.evaluation.evaluator]: [0mInference done 5659/8355. 0.1167 s / img. ETA=0:05:21
[32m[04/20 12:00:08 d2.evaluation.evaluator]: [0mInference done 5701/8355. 0.1167 s / img. ETA=0:05:16
[32m[04/20 12:00:13 d2.evaluation.evaluator]: [0mInference done 5743/8355. 0.1167 s / img. ETA=0:05:11
[32m[04/20 12:00:18 d2.evaluation.evaluator]: [0mInference done 5785/8355. 0.1167 s / img. ETA=0:05:06
[32m[04/20 12:00:23 d2.evaluation.evaluator]: [0mInference done 5827/8355. 0.1167 s / img. ETA=0:05:01
[32m[04/20 12:00:28 d2.evaluation.evaluator]: [0mInference done 5869/8355. 0.1168 s / img. ETA=0:04:56
[32m[04/20 12:00:33 d2.evaluation.evaluator]: [0mInference done 5911/8355. 0.1168 s / img. ETA=0:04:51
[32m[04/20 12:00:38 d2.evaluation.evaluator]: [0mInference done 5953/8355. 0.1168 s / img. ETA=0:04:46
[32m[04/20 12:00:43 d2.evaluation.evaluator]: [0mInference done 5995/8355. 0.1168 s / img. ETA=0:04:41
[32m[04/20 12:00:48 d2.evaluation.evaluator]: [0mInference done 6037/8355. 0.1168 s / img. ETA=0:04:36
[32m[04/20 12:00:53 d2.evaluation.evaluator]: [0mInference done 6079/8355. 0.1168 s / img. ETA=0:04:31
[32m[04/20 12:00:58 d2.evaluation.evaluator]: [0mInference done 6121/8355. 0.1168 s / img. ETA=0:04:26
[32m[04/20 12:01:03 d2.evaluation.evaluator]: [0mInference done 6163/8355. 0.1168 s / img. ETA=0:04:21
[32m[04/20 12:01:08 d2.evaluation.evaluator]: [0mInference done 6205/8355. 0.1168 s / img. ETA=0:04:16
[32m[04/20 12:01:14 d2.evaluation.evaluator]: [0mInference done 6247/8355. 0.1168 s / img. ETA=0:04:11
[32m[04/20 12:01:19 d2.evaluation.evaluator]: [0mInference done 6289/8355. 0.1168 s / img. ETA=0:04:06
[32m[04/20 12:01:24 d2.evaluation.evaluator]: [0mInference done 6331/8355. 0.1168 s / img. ETA=0:04:01
[32m[04/20 12:01:29 d2.evaluation.evaluator]: [0mInference done 6373/8355. 0.1169 s / img. ETA=0:03:56
[32m[04/20 12:01:34 d2.evaluation.evaluator]: [0mInference done 6415/8355. 0.1169 s / img. ETA=0:03:51
[32m[04/20 12:01:39 d2.evaluation.evaluator]: [0mInference done 6457/8355. 0.1169 s / img. ETA=0:03:46
[32m[04/20 12:01:44 d2.evaluation.evaluator]: [0mInference done 6499/8355. 0.1169 s / img. ETA=0:03:41
[32m[04/20 12:01:49 d2.evaluation.evaluator]: [0mInference done 6542/8355. 0.1169 s / img. ETA=0:03:36
[32m[04/20 12:01:54 d2.evaluation.evaluator]: [0mInference done 6584/8355. 0.1169 s / img. ETA=0:03:31
[32m[04/20 12:01:59 d2.evaluation.evaluator]: [0mInference done 6626/8355. 0.1169 s / img. ETA=0:03:26
[32m[04/20 12:02:04 d2.evaluation.evaluator]: [0mInference done 6669/8355. 0.1169 s / img. ETA=0:03:21
[32m[04/20 12:02:09 d2.evaluation.evaluator]: [0mInference done 6712/8355. 0.1169 s / img. ETA=0:03:15
[32m[04/20 12:02:14 d2.evaluation.evaluator]: [0mInference done 6755/8355. 0.1169 s / img. ETA=0:03:10
[32m[04/20 12:02:19 d2.evaluation.evaluator]: [0mInference done 6797/8355. 0.1169 s / img. ETA=0:03:05
[32m[04/20 12:02:24 d2.evaluation.evaluator]: [0mInference done 6839/8355. 0.1169 s / img. ETA=0:03:00
[32m[04/20 12:02:29 d2.evaluation.evaluator]: [0mInference done 6881/8355. 0.1169 s / img. ETA=0:02:55
[32m[04/20 12:02:34 d2.evaluation.evaluator]: [0mInference done 6924/8355. 0.1169 s / img. ETA=0:02:50
[32m[04/20 12:02:39 d2.evaluation.evaluator]: [0mInference done 6966/8355. 0.1169 s / img. ETA=0:02:45
[32m[04/20 12:02:44 d2.evaluation.evaluator]: [0mInference done 7008/8355. 0.1169 s / img. ETA=0:02:40
[32m[04/20 12:02:49 d2.evaluation.evaluator]: [0mInference done 7050/8355. 0.1169 s / img. ETA=0:02:35
[32m[04/20 12:02:55 d2.evaluation.evaluator]: [0mInference done 7092/8355. 0.1169 s / img. ETA=0:02:30
[32m[04/20 12:03:00 d2.evaluation.evaluator]: [0mInference done 7134/8355. 0.1169 s / img. ETA=0:02:25
[32m[04/20 12:03:05 d2.evaluation.evaluator]: [0mInference done 7176/8355. 0.1169 s / img. ETA=0:02:20
[32m[04/20 12:03:10 d2.evaluation.evaluator]: [0mInference done 7218/8355. 0.1169 s / img. ETA=0:02:15
[32m[04/20 12:03:15 d2.evaluation.evaluator]: [0mInference done 7260/8355. 0.1169 s / img. ETA=0:02:10
[32m[04/20 12:03:20 d2.evaluation.evaluator]: [0mInference done 7302/8355. 0.1169 s / img. ETA=0:02:05
[32m[04/20 12:03:25 d2.evaluation.evaluator]: [0mInference done 7344/8355. 0.1169 s / img. ETA=0:02:00
[32m[04/20 12:03:30 d2.evaluation.evaluator]: [0mInference done 7386/8355. 0.1169 s / img. ETA=0:01:55
[32m[04/20 12:03:35 d2.evaluation.evaluator]: [0mInference done 7428/8355. 0.1169 s / img. ETA=0:01:50
[32m[04/20 12:03:40 d2.evaluation.evaluator]: [0mInference done 7470/8355. 0.1169 s / img. ETA=0:01:45
[32m[04/20 12:03:45 d2.evaluation.evaluator]: [0mInference done 7512/8355. 0.1169 s / img. ETA=0:01:40
[32m[04/20 12:03:50 d2.evaluation.evaluator]: [0mInference done 7554/8355. 0.1169 s / img. ETA=0:01:35
[32m[04/20 12:03:55 d2.evaluation.evaluator]: [0mInference done 7596/8355. 0.1169 s / img. ETA=0:01:30
[32m[04/20 12:04:00 d2.evaluation.evaluator]: [0mInference done 7638/8355. 0.1169 s / img. ETA=0:01:25
[32m[04/20 12:04:05 d2.evaluation.evaluator]: [0mInference done 7680/8355. 0.1169 s / img. ETA=0:01:20
[32m[04/20 12:04:10 d2.evaluation.evaluator]: [0mInference done 7722/8355. 0.1169 s / img. ETA=0:01:15
[32m[04/20 12:04:15 d2.evaluation.evaluator]: [0mInference done 7764/8355. 0.1169 s / img. ETA=0:01:10
[32m[04/20 12:04:20 d2.evaluation.evaluator]: [0mInference done 7806/8355. 0.1170 s / img. ETA=0:01:05
[32m[04/20 12:04:25 d2.evaluation.evaluator]: [0mInference done 7848/8355. 0.1170 s / img. ETA=0:01:00
[32m[04/20 12:04:31 d2.evaluation.evaluator]: [0mInference done 7890/8355. 0.1170 s / img. ETA=0:00:55
[32m[04/20 12:04:36 d2.evaluation.evaluator]: [0mInference done 7932/8355. 0.1170 s / img. ETA=0:00:50
[32m[04/20 12:04:41 d2.evaluation.evaluator]: [0mInference done 7974/8355. 0.1170 s / img. ETA=0:00:45
[32m[04/20 12:04:46 d2.evaluation.evaluator]: [0mInference done 8016/8355. 0.1170 s / img. ETA=0:00:40
[32m[04/20 12:04:51 d2.evaluation.evaluator]: [0mInference done 8059/8355. 0.1170 s / img. ETA=0:00:35
[32m[04/20 12:04:56 d2.evaluation.evaluator]: [0mInference done 8102/8355. 0.1170 s / img. ETA=0:00:30
[32m[04/20 12:05:01 d2.evaluation.evaluator]: [0mInference done 8144/8355. 0.1170 s / img. ETA=0:00:25
[32m[04/20 12:05:06 d2.evaluation.evaluator]: [0mInference done 8187/8355. 0.1170 s / img. ETA=0:00:20
[32m[04/20 12:05:11 d2.evaluation.evaluator]: [0mInference done 8229/8355. 0.1170 s / img. ETA=0:00:15
[32m[04/20 12:05:16 d2.evaluation.evaluator]: [0mInference done 8271/8355. 0.1170 s / img. ETA=0:00:10
[32m[04/20 12:05:21 d2.evaluation.evaluator]: [0mInference done 8313/8355. 0.1170 s / img. ETA=0:00:05
[32m[04/20 12:05:26 d2.evaluation.evaluator]: [0mInference done 8355/8355. 0.1170 s / img. ETA=0:00:00
[32m[04/20 12:05:26 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:37.143303 (0.119418 s / img per device, on 1 devices)
[32m[04/20 12:05:26 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:16 (0.116972 s / img per device, on 1 devices)
[32m[04/20 12:05:26 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 12:05:26 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 12:05:27 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.30s).
Accumulating evaluation results...
DONE (t=2.17s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.682
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.338
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.255
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.493
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.149
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.416
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.428
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.329
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.561
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.690
[32m[04/20 12:05:48 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 36.200 | 68.211 | 33.818 | 25.492 | 49.258 | 65.106 |
[32m[04/20 12:05:48 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 37.894 | bicycle       | 24.577 | car            | 46.128 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 12:05:49 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 12:05:49 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 12:05:49 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 12:05:51 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1178 s / img. ETA=0:02:29
[32m[04/20 12:05:56 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1174 s / img. ETA=0:02:24
[32m[04/20 12:06:01 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1173 s / img. ETA=0:02:19
[32m[04/20 12:06:06 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1172 s / img. ETA=0:02:14
[32m[04/20 12:06:11 d2.evaluation.evaluator]: [0mInference done 179/1257. 0.1172 s / img. ETA=0:02:09
[32m[04/20 12:06:16 d2.evaluation.evaluator]: [0mInference done 221/1257. 0.1171 s / img. ETA=0:02:03
[32m[04/20 12:06:21 d2.evaluation.evaluator]: [0mInference done 263/1257. 0.1172 s / img. ETA=0:01:58
[32m[04/20 12:06:26 d2.evaluation.evaluator]: [0mInference done 305/1257. 0.1172 s / img. ETA=0:01:53
[32m[04/20 12:06:31 d2.evaluation.evaluator]: [0mInference done 347/1257. 0.1171 s / img. ETA=0:01:48
[32m[04/20 12:06:36 d2.evaluation.evaluator]: [0mInference done 390/1257. 0.1171 s / img. ETA=0:01:43
[32m[04/20 12:06:41 d2.evaluation.evaluator]: [0mInference done 432/1257. 0.1170 s / img. ETA=0:01:38
[32m[04/20 12:06:46 d2.evaluation.evaluator]: [0mInference done 474/1257. 0.1170 s / img. ETA=0:01:33
[32m[04/20 12:06:51 d2.evaluation.evaluator]: [0mInference done 516/1257. 0.1171 s / img. ETA=0:01:28
[32m[04/20 12:06:56 d2.evaluation.evaluator]: [0mInference done 558/1257. 0.1172 s / img. ETA=0:01:23
[32m[04/20 12:07:01 d2.evaluation.evaluator]: [0mInference done 600/1257. 0.1172 s / img. ETA=0:01:18
[32m[04/20 12:07:07 d2.evaluation.evaluator]: [0mInference done 642/1257. 0.1173 s / img. ETA=0:01:13
[32m[04/20 12:07:12 d2.evaluation.evaluator]: [0mInference done 684/1257. 0.1173 s / img. ETA=0:01:08
[32m[04/20 12:07:17 d2.evaluation.evaluator]: [0mInference done 726/1257. 0.1173 s / img. ETA=0:01:03
[32m[04/20 12:07:22 d2.evaluation.evaluator]: [0mInference done 769/1257. 0.1173 s / img. ETA=0:00:58
[32m[04/20 12:07:27 d2.evaluation.evaluator]: [0mInference done 811/1257. 0.1173 s / img. ETA=0:00:53
[32m[04/20 12:07:32 d2.evaluation.evaluator]: [0mInference done 853/1257. 0.1173 s / img. ETA=0:00:48
[32m[04/20 12:07:37 d2.evaluation.evaluator]: [0mInference done 895/1257. 0.1173 s / img. ETA=0:00:43
[32m[04/20 12:07:42 d2.evaluation.evaluator]: [0mInference done 937/1257. 0.1173 s / img. ETA=0:00:38
[32m[04/20 12:07:47 d2.evaluation.evaluator]: [0mInference done 979/1257. 0.1173 s / img. ETA=0:00:33
[32m[04/20 12:07:52 d2.evaluation.evaluator]: [0mInference done 1021/1257. 0.1174 s / img. ETA=0:00:28
[32m[04/20 12:07:57 d2.evaluation.evaluator]: [0mInference done 1063/1257. 0.1173 s / img. ETA=0:00:23
[32m[04/20 12:08:02 d2.evaluation.evaluator]: [0mInference done 1105/1257. 0.1173 s / img. ETA=0:00:18
[32m[04/20 12:08:07 d2.evaluation.evaluator]: [0mInference done 1147/1257. 0.1173 s / img. ETA=0:00:13
[32m[04/20 12:08:12 d2.evaluation.evaluator]: [0mInference done 1189/1257. 0.1173 s / img. ETA=0:00:08
[32m[04/20 12:08:17 d2.evaluation.evaluator]: [0mInference done 1231/1257. 0.1173 s / img. ETA=0:00:03
[32m[04/20 12:08:20 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:29.955224 (0.119773 s / img per device, on 1 devices)
[32m[04/20 12:08:20 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:26 (0.117314 s / img per device, on 1 devices)
[32m[04/20 12:08:20 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 12:08:20 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 12:08:20 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.03s).
Accumulating evaluation results...
DONE (t=0.36s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.557
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.260
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.484
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.144
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.359
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.257
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.431
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.546
[32m[04/20 12:08:24 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 28.828 | 55.707 | 26.021 | 17.171 | 36.373 | 48.418 |
[32m[04/20 12:08:24 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 32.338 | bicycle       | 9.233 | car            | 44.914 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | nan   | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  11  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 12:08:25 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 12:08:25 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 12:08:25 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 12:08:25 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 12:08:25 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 12:08:25 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 12:08:25 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 12:08:46 d2.utils.events]: [0m eta: 0:16:30  iter: 19  total_loss: 0.706  loss_cls: 0.232  loss_box_reg: 0.389  loss_rpn_cls: 0.022  loss_rpn_loc: 0.060  time: 1.0100  data_time: 0.0282  lr: 0.000100  max_mem: 5405M
[32m[04/20 12:09:07 d2.utils.events]: [0m eta: 0:16:31  iter: 39  total_loss: 0.609  loss_cls: 0.198  loss_box_reg: 0.332  loss_rpn_cls: 0.016  loss_rpn_loc: 0.063  time: 1.0251  data_time: 0.0096  lr: 0.000200  max_mem: 5405M
[32m[04/20 12:09:28 d2.utils.events]: [0m eta: 0:16:25  iter: 59  total_loss: 0.630  loss_cls: 0.203  loss_box_reg: 0.332  loss_rpn_cls: 0.017  loss_rpn_loc: 0.051  time: 1.0317  data_time: 0.0098  lr: 0.000300  max_mem: 5405M
[32m[04/20 12:09:49 d2.utils.events]: [0m eta: 0:16:07  iter: 79  total_loss: 0.670  loss_cls: 0.220  loss_box_reg: 0.387  loss_rpn_cls: 0.018  loss_rpn_loc: 0.051  time: 1.0349  data_time: 0.0099  lr: 0.000400  max_mem: 5405M
[32m[04/20 12:10:09 d2.utils.events]: [0m eta: 0:15:44  iter: 99  total_loss: 0.683  loss_cls: 0.208  loss_box_reg: 0.382  loss_rpn_cls: 0.018  loss_rpn_loc: 0.060  time: 1.0332  data_time: 0.0098  lr: 0.000500  max_mem: 5405M
[32m[04/20 12:10:30 d2.utils.events]: [0m eta: 0:15:23  iter: 119  total_loss: 0.630  loss_cls: 0.201  loss_box_reg: 0.353  loss_rpn_cls: 0.015  loss_rpn_loc: 0.059  time: 1.0331  data_time: 0.0099  lr: 0.000599  max_mem: 5405M
[32m[04/20 12:10:50 d2.utils.events]: [0m eta: 0:14:53  iter: 139  total_loss: 0.654  loss_cls: 0.209  loss_box_reg: 0.368  loss_rpn_cls: 0.017  loss_rpn_loc: 0.052  time: 1.0251  data_time: 0.0095  lr: 0.000699  max_mem: 5405M
[32m[04/20 12:11:10 d2.utils.events]: [0m eta: 0:14:28  iter: 159  total_loss: 0.628  loss_cls: 0.189  loss_box_reg: 0.363  loss_rpn_cls: 0.019  loss_rpn_loc: 0.051  time: 1.0240  data_time: 0.0095  lr: 0.000799  max_mem: 5405M
[32m[04/20 12:11:31 d2.utils.events]: [0m eta: 0:14:08  iter: 179  total_loss: 0.658  loss_cls: 0.205  loss_box_reg: 0.371  loss_rpn_cls: 0.016  loss_rpn_loc: 0.057  time: 1.0256  data_time: 0.0097  lr: 0.000899  max_mem: 5405M
[32m[04/20 12:11:52 d2.utils.events]: [0m eta: 0:13:55  iter: 199  total_loss: 0.582  loss_cls: 0.198  loss_box_reg: 0.325  loss_rpn_cls: 0.016  loss_rpn_loc: 0.059  time: 1.0280  data_time: 0.0099  lr: 0.000999  max_mem: 5405M
[32m[04/20 12:12:12 d2.utils.events]: [0m eta: 0:13:30  iter: 219  total_loss: 0.586  loss_cls: 0.181  loss_box_reg: 0.327  loss_rpn_cls: 0.013  loss_rpn_loc: 0.055  time: 1.0271  data_time: 0.0095  lr: 0.001099  max_mem: 5405M
[32m[04/20 12:12:33 d2.utils.events]: [0m eta: 0:13:11  iter: 239  total_loss: 0.637  loss_cls: 0.197  loss_box_reg: 0.344  loss_rpn_cls: 0.015  loss_rpn_loc: 0.056  time: 1.0281  data_time: 0.0098  lr: 0.001199  max_mem: 5405M
[32m[04/20 12:12:54 d2.utils.events]: [0m eta: 0:12:51  iter: 259  total_loss: 0.557  loss_cls: 0.180  loss_box_reg: 0.317  loss_rpn_cls: 0.017  loss_rpn_loc: 0.042  time: 1.0287  data_time: 0.0099  lr: 0.001299  max_mem: 5405M
[32m[04/20 12:13:15 d2.utils.events]: [0m eta: 0:12:33  iter: 279  total_loss: 0.668  loss_cls: 0.227  loss_box_reg: 0.360  loss_rpn_cls: 0.012  loss_rpn_loc: 0.055  time: 1.0302  data_time: 0.0100  lr: 0.001399  max_mem: 5405M
[32m[04/20 12:13:36 d2.utils.events]: [0m eta: 0:12:12  iter: 299  total_loss: 0.574  loss_cls: 0.179  loss_box_reg: 0.313  loss_rpn_cls: 0.016  loss_rpn_loc: 0.046  time: 1.0303  data_time: 0.0098  lr: 0.001499  max_mem: 5405M
[32m[04/20 12:13:57 d2.utils.events]: [0m eta: 0:11:52  iter: 319  total_loss: 0.599  loss_cls: 0.201  loss_box_reg: 0.350  loss_rpn_cls: 0.012  loss_rpn_loc: 0.051  time: 1.0316  data_time: 0.0101  lr: 0.001598  max_mem: 5405M
[32m[04/20 12:14:17 d2.utils.events]: [0m eta: 0:11:31  iter: 339  total_loss: 0.557  loss_cls: 0.190  loss_box_reg: 0.321  loss_rpn_cls: 0.013  loss_rpn_loc: 0.052  time: 1.0314  data_time: 0.0099  lr: 0.001698  max_mem: 5405M
[32m[04/20 12:14:39 d2.utils.events]: [0m eta: 0:11:11  iter: 359  total_loss: 0.607  loss_cls: 0.210  loss_box_reg: 0.330  loss_rpn_cls: 0.014  loss_rpn_loc: 0.045  time: 1.0334  data_time: 0.0100  lr: 0.001798  max_mem: 5405M
[32m[04/20 12:14:59 d2.utils.events]: [0m eta: 0:10:49  iter: 379  total_loss: 0.541  loss_cls: 0.174  loss_box_reg: 0.309  loss_rpn_cls: 0.013  loss_rpn_loc: 0.040  time: 1.0331  data_time: 0.0098  lr: 0.001898  max_mem: 5405M
[32m[04/20 12:15:20 d2.utils.events]: [0m eta: 0:10:28  iter: 399  total_loss: 0.588  loss_cls: 0.176  loss_box_reg: 0.330  loss_rpn_cls: 0.015  loss_rpn_loc: 0.060  time: 1.0335  data_time: 0.0098  lr: 0.001998  max_mem: 5405M
[32m[04/20 12:15:41 d2.utils.events]: [0m eta: 0:10:07  iter: 419  total_loss: 0.618  loss_cls: 0.192  loss_box_reg: 0.361  loss_rpn_cls: 0.013  loss_rpn_loc: 0.051  time: 1.0340  data_time: 0.0099  lr: 0.002098  max_mem: 5405M
[32m[04/20 12:16:01 d2.utils.events]: [0m eta: 0:09:46  iter: 439  total_loss: 0.675  loss_cls: 0.213  loss_box_reg: 0.358  loss_rpn_cls: 0.015  loss_rpn_loc: 0.050  time: 1.0334  data_time: 0.0101  lr: 0.002198  max_mem: 5405M
[32m[04/20 12:16:22 d2.utils.events]: [0m eta: 0:09:25  iter: 459  total_loss: 0.631  loss_cls: 0.201  loss_box_reg: 0.361  loss_rpn_cls: 0.016  loss_rpn_loc: 0.055  time: 1.0329  data_time: 0.0096  lr: 0.002298  max_mem: 5405M
[32m[04/20 12:16:43 d2.utils.events]: [0m eta: 0:09:05  iter: 479  total_loss: 0.666  loss_cls: 0.204  loss_box_reg: 0.355  loss_rpn_cls: 0.019  loss_rpn_loc: 0.046  time: 1.0328  data_time: 0.0099  lr: 0.002398  max_mem: 5405M
[32m[04/20 12:17:03 d2.utils.events]: [0m eta: 0:08:44  iter: 499  total_loss: 0.610  loss_cls: 0.195  loss_box_reg: 0.341  loss_rpn_cls: 0.018  loss_rpn_loc: 0.059  time: 1.0327  data_time: 0.0099  lr: 0.002498  max_mem: 5405M
[32m[04/20 12:17:24 d2.utils.events]: [0m eta: 0:08:23  iter: 519  total_loss: 0.559  loss_cls: 0.184  loss_box_reg: 0.304  loss_rpn_cls: 0.012  loss_rpn_loc: 0.048  time: 1.0327  data_time: 0.0098  lr: 0.002597  max_mem: 5405M
[32m[04/20 12:17:45 d2.utils.events]: [0m eta: 0:08:02  iter: 539  total_loss: 0.589  loss_cls: 0.192  loss_box_reg: 0.313  loss_rpn_cls: 0.014  loss_rpn_loc: 0.057  time: 1.0336  data_time: 0.0098  lr: 0.002697  max_mem: 5405M
[32m[04/20 12:18:06 d2.utils.events]: [0m eta: 0:07:41  iter: 559  total_loss: 0.647  loss_cls: 0.211  loss_box_reg: 0.350  loss_rpn_cls: 0.016  loss_rpn_loc: 0.065  time: 1.0332  data_time: 0.0098  lr: 0.002797  max_mem: 5405M
[32m[04/20 12:18:26 d2.utils.events]: [0m eta: 0:07:20  iter: 579  total_loss: 0.587  loss_cls: 0.206  loss_box_reg: 0.326  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0325  data_time: 0.0095  lr: 0.002897  max_mem: 5405M
[32m[04/20 12:18:46 d2.utils.events]: [0m eta: 0:06:58  iter: 599  total_loss: 0.619  loss_cls: 0.194  loss_box_reg: 0.334  loss_rpn_cls: 0.011  loss_rpn_loc: 0.050  time: 1.0317  data_time: 0.0098  lr: 0.002997  max_mem: 5405M
[32m[04/20 12:19:07 d2.utils.events]: [0m eta: 0:06:37  iter: 619  total_loss: 0.587  loss_cls: 0.188  loss_box_reg: 0.302  loss_rpn_cls: 0.014  loss_rpn_loc: 0.055  time: 1.0319  data_time: 0.0098  lr: 0.003097  max_mem: 5405M
[32m[04/20 12:19:28 d2.utils.events]: [0m eta: 0:06:17  iter: 639  total_loss: 0.574  loss_cls: 0.184  loss_box_reg: 0.317  loss_rpn_cls: 0.014  loss_rpn_loc: 0.046  time: 1.0318  data_time: 0.0095  lr: 0.003197  max_mem: 5405M
[32m[04/20 12:19:49 d2.utils.events]: [0m eta: 0:05:56  iter: 659  total_loss: 0.648  loss_cls: 0.212  loss_box_reg: 0.352  loss_rpn_cls: 0.015  loss_rpn_loc: 0.064  time: 1.0321  data_time: 0.0097  lr: 0.003297  max_mem: 5405M
[32m[04/20 12:20:09 d2.utils.events]: [0m eta: 0:05:35  iter: 679  total_loss: 0.655  loss_cls: 0.221  loss_box_reg: 0.379  loss_rpn_cls: 0.017  loss_rpn_loc: 0.046  time: 1.0317  data_time: 0.0095  lr: 0.003397  max_mem: 5405M
[32m[04/20 12:20:30 d2.utils.events]: [0m eta: 0:05:14  iter: 699  total_loss: 0.578  loss_cls: 0.191  loss_box_reg: 0.323  loss_rpn_cls: 0.016  loss_rpn_loc: 0.058  time: 1.0315  data_time: 0.0096  lr: 0.003497  max_mem: 5405M
[32m[04/20 12:20:51 d2.utils.events]: [0m eta: 0:04:53  iter: 719  total_loss: 0.626  loss_cls: 0.207  loss_box_reg: 0.339  loss_rpn_cls: 0.016  loss_rpn_loc: 0.047  time: 1.0319  data_time: 0.0097  lr: 0.003596  max_mem: 5405M
[32m[04/20 12:21:12 d2.utils.events]: [0m eta: 0:04:32  iter: 739  total_loss: 0.605  loss_cls: 0.198  loss_box_reg: 0.335  loss_rpn_cls: 0.016  loss_rpn_loc: 0.058  time: 1.0323  data_time: 0.0097  lr: 0.003696  max_mem: 5405M
[32m[04/20 12:21:33 d2.utils.events]: [0m eta: 0:04:12  iter: 759  total_loss: 0.596  loss_cls: 0.187  loss_box_reg: 0.338  loss_rpn_cls: 0.014  loss_rpn_loc: 0.048  time: 1.0327  data_time: 0.0097  lr: 0.003796  max_mem: 5405M
[32m[04/20 12:21:53 d2.utils.events]: [0m eta: 0:03:51  iter: 779  total_loss: 0.607  loss_cls: 0.201  loss_box_reg: 0.336  loss_rpn_cls: 0.018  loss_rpn_loc: 0.052  time: 1.0324  data_time: 0.0095  lr: 0.003896  max_mem: 5405M
[32m[04/20 12:22:14 d2.utils.events]: [0m eta: 0:03:30  iter: 799  total_loss: 0.593  loss_cls: 0.189  loss_box_reg: 0.337  loss_rpn_cls: 0.016  loss_rpn_loc: 0.053  time: 1.0326  data_time: 0.0099  lr: 0.003996  max_mem: 5405M
[32m[04/20 12:22:35 d2.utils.events]: [0m eta: 0:03:09  iter: 819  total_loss: 0.589  loss_cls: 0.186  loss_box_reg: 0.333  loss_rpn_cls: 0.018  loss_rpn_loc: 0.052  time: 1.0328  data_time: 0.0099  lr: 0.004096  max_mem: 5405M
[32m[04/20 12:22:56 d2.utils.events]: [0m eta: 0:02:48  iter: 839  total_loss: 0.613  loss_cls: 0.184  loss_box_reg: 0.330  loss_rpn_cls: 0.017  loss_rpn_loc: 0.055  time: 1.0331  data_time: 0.0095  lr: 0.004196  max_mem: 5405M
[32m[04/20 12:23:16 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.626  loss_cls: 0.200  loss_box_reg: 0.351  loss_rpn_cls: 0.021  loss_rpn_loc: 0.052  time: 1.0325  data_time: 0.0095  lr: 0.004296  max_mem: 5405M
[32m[04/20 12:23:36 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.691  loss_cls: 0.223  loss_box_reg: 0.366  loss_rpn_cls: 0.021  loss_rpn_loc: 0.060  time: 1.0320  data_time: 0.0098  lr: 0.004396  max_mem: 5405M
[32m[04/20 12:23:57 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.687  loss_cls: 0.222  loss_box_reg: 0.362  loss_rpn_cls: 0.021  loss_rpn_loc: 0.060  time: 1.0316  data_time: 0.0096  lr: 0.004496  max_mem: 5405M
[32m[04/20 12:24:18 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.660  loss_cls: 0.206  loss_box_reg: 0.356  loss_rpn_cls: 0.018  loss_rpn_loc: 0.063  time: 1.0321  data_time: 0.0095  lr: 0.004595  max_mem: 5405M
[32m[04/20 12:24:38 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.669  loss_cls: 0.236  loss_box_reg: 0.363  loss_rpn_cls: 0.021  loss_rpn_loc: 0.058  time: 1.0318  data_time: 0.0098  lr: 0.004695  max_mem: 5405M
[32m[04/20 12:24:58 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.662  loss_cls: 0.207  loss_box_reg: 0.363  loss_rpn_cls: 0.019  loss_rpn_loc: 0.052  time: 1.0315  data_time: 0.0097  lr: 0.004795  max_mem: 5405M
[32m[04/20 12:25:20 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.629  loss_cls: 0.198  loss_box_reg: 0.343  loss_rpn_cls: 0.019  loss_rpn_loc: 0.059  time: 1.0320  data_time: 0.0097  lr: 0.004895  max_mem: 5405M
[5m[31mWARNING[0m [32m[04/20 12:25:44 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 12:25:44 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 12:25:44 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 12:25:44 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.716  loss_cls: 0.240  loss_box_reg: 0.341  loss_rpn_cls: 0.022  loss_rpn_loc: 0.066  time: 1.0319  data_time: 0.0096  lr: 0.004995  max_mem: 5405M
[32m[04/20 12:25:44 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:09 (1.0330 s / it)
[32m[04/20 12:25:44 d2.engine.hooks]: [0mTotal training time: 0:17:16 (0:00:06 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 12:25:47 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 12:25:47 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 12:25:48 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 12:25:49 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1165 s / img. ETA=0:16:27
[32m[04/20 12:25:54 d2.evaluation.evaluator]: [0mInference done 54/8355. 0.1160 s / img. ETA=0:16:20
[32m[04/20 12:25:59 d2.evaluation.evaluator]: [0mInference done 97/8355. 0.1158 s / img. ETA=0:16:14
[32m[04/20 12:26:04 d2.evaluation.evaluator]: [0mInference done 140/8355. 0.1158 s / img. ETA=0:16:09
[32m[04/20 12:26:09 d2.evaluation.evaluator]: [0mInference done 183/8355. 0.1157 s / img. ETA=0:16:03
[32m[04/20 12:26:14 d2.evaluation.evaluator]: [0mInference done 226/8355. 0.1158 s / img. ETA=0:15:59
[32m[04/20 12:26:20 d2.evaluation.evaluator]: [0mInference done 269/8355. 0.1158 s / img. ETA=0:15:54
[32m[04/20 12:26:25 d2.evaluation.evaluator]: [0mInference done 312/8355. 0.1158 s / img. ETA=0:15:49
[32m[04/20 12:26:30 d2.evaluation.evaluator]: [0mInference done 355/8355. 0.1158 s / img. ETA=0:15:44
[32m[04/20 12:26:35 d2.evaluation.evaluator]: [0mInference done 398/8355. 0.1159 s / img. ETA=0:15:39
[32m[04/20 12:26:40 d2.evaluation.evaluator]: [0mInference done 441/8355. 0.1159 s / img. ETA=0:15:34
[32m[04/20 12:26:45 d2.evaluation.evaluator]: [0mInference done 484/8355. 0.1158 s / img. ETA=0:15:29
[32m[04/20 12:26:50 d2.evaluation.evaluator]: [0mInference done 527/8355. 0.1158 s / img. ETA=0:15:23
[32m[04/20 12:26:55 d2.evaluation.evaluator]: [0mInference done 570/8355. 0.1158 s / img. ETA=0:15:18
[32m[04/20 12:27:00 d2.evaluation.evaluator]: [0mInference done 613/8355. 0.1158 s / img. ETA=0:15:13
[32m[04/20 12:27:05 d2.evaluation.evaluator]: [0mInference done 656/8355. 0.1158 s / img. ETA=0:15:08
[32m[04/20 12:27:10 d2.evaluation.evaluator]: [0mInference done 699/8355. 0.1158 s / img. ETA=0:15:03
[32m[04/20 12:27:15 d2.evaluation.evaluator]: [0mInference done 742/8355. 0.1158 s / img. ETA=0:14:58
[32m[04/20 12:27:20 d2.evaluation.evaluator]: [0mInference done 785/8355. 0.1158 s / img. ETA=0:14:53
[32m[04/20 12:27:26 d2.evaluation.evaluator]: [0mInference done 828/8355. 0.1158 s / img. ETA=0:14:48
[32m[04/20 12:27:31 d2.evaluation.evaluator]: [0mInference done 871/8355. 0.1158 s / img. ETA=0:14:43
[32m[04/20 12:27:36 d2.evaluation.evaluator]: [0mInference done 914/8355. 0.1158 s / img. ETA=0:14:38
[32m[04/20 12:27:41 d2.evaluation.evaluator]: [0mInference done 957/8355. 0.1158 s / img. ETA=0:14:33
[32m[04/20 12:27:46 d2.evaluation.evaluator]: [0mInference done 1000/8355. 0.1158 s / img. ETA=0:14:28
[32m[04/20 12:27:51 d2.evaluation.evaluator]: [0mInference done 1043/8355. 0.1158 s / img. ETA=0:14:23
[32m[04/20 12:27:56 d2.evaluation.evaluator]: [0mInference done 1086/8355. 0.1158 s / img. ETA=0:14:18
[32m[04/20 12:28:01 d2.evaluation.evaluator]: [0mInference done 1129/8355. 0.1158 s / img. ETA=0:14:13
[32m[04/20 12:28:06 d2.evaluation.evaluator]: [0mInference done 1172/8355. 0.1158 s / img. ETA=0:14:08
[32m[04/20 12:28:11 d2.evaluation.evaluator]: [0mInference done 1215/8355. 0.1158 s / img. ETA=0:14:03
[32m[04/20 12:28:16 d2.evaluation.evaluator]: [0mInference done 1258/8355. 0.1158 s / img. ETA=0:13:57
[32m[04/20 12:28:21 d2.evaluation.evaluator]: [0mInference done 1301/8355. 0.1158 s / img. ETA=0:13:52
[32m[04/20 12:28:26 d2.evaluation.evaluator]: [0mInference done 1344/8355. 0.1158 s / img. ETA=0:13:47
[32m[04/20 12:28:32 d2.evaluation.evaluator]: [0mInference done 1387/8355. 0.1158 s / img. ETA=0:13:42
[32m[04/20 12:28:37 d2.evaluation.evaluator]: [0mInference done 1430/8355. 0.1158 s / img. ETA=0:13:37
[32m[04/20 12:28:42 d2.evaluation.evaluator]: [0mInference done 1473/8355. 0.1158 s / img. ETA=0:13:32
[32m[04/20 12:28:47 d2.evaluation.evaluator]: [0mInference done 1515/8355. 0.1159 s / img. ETA=0:13:28
[32m[04/20 12:28:52 d2.evaluation.evaluator]: [0mInference done 1557/8355. 0.1159 s / img. ETA=0:13:23
[32m[04/20 12:28:57 d2.evaluation.evaluator]: [0mInference done 1599/8355. 0.1159 s / img. ETA=0:13:18
[32m[04/20 12:29:02 d2.evaluation.evaluator]: [0mInference done 1641/8355. 0.1160 s / img. ETA=0:13:14
[32m[04/20 12:29:07 d2.evaluation.evaluator]: [0mInference done 1683/8355. 0.1160 s / img. ETA=0:13:09
[32m[04/20 12:29:12 d2.evaluation.evaluator]: [0mInference done 1725/8355. 0.1160 s / img. ETA=0:13:04
[32m[04/20 12:29:17 d2.evaluation.evaluator]: [0mInference done 1767/8355. 0.1161 s / img. ETA=0:12:59
[32m[04/20 12:29:22 d2.evaluation.evaluator]: [0mInference done 1809/8355. 0.1161 s / img. ETA=0:12:55
[32m[04/20 12:29:27 d2.evaluation.evaluator]: [0mInference done 1851/8355. 0.1161 s / img. ETA=0:12:50
[32m[04/20 12:29:32 d2.evaluation.evaluator]: [0mInference done 1893/8355. 0.1162 s / img. ETA=0:12:45
[32m[04/20 12:29:37 d2.evaluation.evaluator]: [0mInference done 1935/8355. 0.1162 s / img. ETA=0:12:40
[32m[04/20 12:29:42 d2.evaluation.evaluator]: [0mInference done 1977/8355. 0.1162 s / img. ETA=0:12:35
[32m[04/20 12:29:47 d2.evaluation.evaluator]: [0mInference done 2020/8355. 0.1162 s / img. ETA=0:12:30
[32m[04/20 12:29:52 d2.evaluation.evaluator]: [0mInference done 2063/8355. 0.1162 s / img. ETA=0:12:25
[32m[04/20 12:29:57 d2.evaluation.evaluator]: [0mInference done 2106/8355. 0.1162 s / img. ETA=0:12:20
[32m[04/20 12:30:02 d2.evaluation.evaluator]: [0mInference done 2149/8355. 0.1162 s / img. ETA=0:12:15
[32m[04/20 12:30:08 d2.evaluation.evaluator]: [0mInference done 2192/8355. 0.1162 s / img. ETA=0:12:10
[32m[04/20 12:30:13 d2.evaluation.evaluator]: [0mInference done 2235/8355. 0.1162 s / img. ETA=0:12:05
[32m[04/20 12:30:18 d2.evaluation.evaluator]: [0mInference done 2277/8355. 0.1163 s / img. ETA=0:12:00
[32m[04/20 12:30:23 d2.evaluation.evaluator]: [0mInference done 2319/8355. 0.1163 s / img. ETA=0:11:55
[32m[04/20 12:30:28 d2.evaluation.evaluator]: [0mInference done 2361/8355. 0.1163 s / img. ETA=0:11:50
[32m[04/20 12:30:33 d2.evaluation.evaluator]: [0mInference done 2404/8355. 0.1163 s / img. ETA=0:11:45
[32m[04/20 12:30:38 d2.evaluation.evaluator]: [0mInference done 2447/8355. 0.1163 s / img. ETA=0:11:40
[32m[04/20 12:30:43 d2.evaluation.evaluator]: [0mInference done 2490/8355. 0.1163 s / img. ETA=0:11:35
[32m[04/20 12:30:48 d2.evaluation.evaluator]: [0mInference done 2533/8355. 0.1163 s / img. ETA=0:11:30
[32m[04/20 12:30:53 d2.evaluation.evaluator]: [0mInference done 2576/8355. 0.1163 s / img. ETA=0:11:25
[32m[04/20 12:30:58 d2.evaluation.evaluator]: [0mInference done 2619/8355. 0.1163 s / img. ETA=0:11:20
[32m[04/20 12:31:04 d2.evaluation.evaluator]: [0mInference done 2662/8355. 0.1163 s / img. ETA=0:11:15
[32m[04/20 12:31:09 d2.evaluation.evaluator]: [0mInference done 2704/8355. 0.1163 s / img. ETA=0:11:10
[32m[04/20 12:31:14 d2.evaluation.evaluator]: [0mInference done 2746/8355. 0.1163 s / img. ETA=0:11:05
[32m[04/20 12:31:19 d2.evaluation.evaluator]: [0mInference done 2789/8355. 0.1163 s / img. ETA=0:11:00
[32m[04/20 12:31:24 d2.evaluation.evaluator]: [0mInference done 2831/8355. 0.1163 s / img. ETA=0:10:55
[32m[04/20 12:31:29 d2.evaluation.evaluator]: [0mInference done 2873/8355. 0.1164 s / img. ETA=0:10:50
[32m[04/20 12:31:34 d2.evaluation.evaluator]: [0mInference done 2916/8355. 0.1164 s / img. ETA=0:10:45
[32m[04/20 12:31:39 d2.evaluation.evaluator]: [0mInference done 2958/8355. 0.1164 s / img. ETA=0:10:40
[32m[04/20 12:31:44 d2.evaluation.evaluator]: [0mInference done 3001/8355. 0.1164 s / img. ETA=0:10:35
[32m[04/20 12:31:49 d2.evaluation.evaluator]: [0mInference done 3044/8355. 0.1164 s / img. ETA=0:10:30
[32m[04/20 12:31:54 d2.evaluation.evaluator]: [0mInference done 3086/8355. 0.1164 s / img. ETA=0:10:25
[32m[04/20 12:31:59 d2.evaluation.evaluator]: [0mInference done 3128/8355. 0.1164 s / img. ETA=0:10:20
[32m[04/20 12:32:04 d2.evaluation.evaluator]: [0mInference done 3171/8355. 0.1164 s / img. ETA=0:10:15
[32m[04/20 12:32:09 d2.evaluation.evaluator]: [0mInference done 3214/8355. 0.1164 s / img. ETA=0:10:10
[32m[04/20 12:32:14 d2.evaluation.evaluator]: [0mInference done 3257/8355. 0.1164 s / img. ETA=0:10:05
[32m[04/20 12:32:20 d2.evaluation.evaluator]: [0mInference done 3300/8355. 0.1164 s / img. ETA=0:10:00
[32m[04/20 12:32:25 d2.evaluation.evaluator]: [0mInference done 3343/8355. 0.1164 s / img. ETA=0:09:54
[32m[04/20 12:32:30 d2.evaluation.evaluator]: [0mInference done 3386/8355. 0.1164 s / img. ETA=0:09:49
[32m[04/20 12:32:35 d2.evaluation.evaluator]: [0mInference done 3429/8355. 0.1164 s / img. ETA=0:09:44
[32m[04/20 12:32:40 d2.evaluation.evaluator]: [0mInference done 3472/8355. 0.1164 s / img. ETA=0:09:39
[32m[04/20 12:32:45 d2.evaluation.evaluator]: [0mInference done 3515/8355. 0.1164 s / img. ETA=0:09:34
[32m[04/20 12:32:50 d2.evaluation.evaluator]: [0mInference done 3558/8355. 0.1164 s / img. ETA=0:09:29
[32m[04/20 12:32:55 d2.evaluation.evaluator]: [0mInference done 3601/8355. 0.1164 s / img. ETA=0:09:24
[32m[04/20 12:33:00 d2.evaluation.evaluator]: [0mInference done 3643/8355. 0.1164 s / img. ETA=0:09:19
[32m[04/20 12:33:05 d2.evaluation.evaluator]: [0mInference done 3686/8355. 0.1164 s / img. ETA=0:09:14
[32m[04/20 12:33:10 d2.evaluation.evaluator]: [0mInference done 3729/8355. 0.1163 s / img. ETA=0:09:09
[32m[04/20 12:33:15 d2.evaluation.evaluator]: [0mInference done 3772/8355. 0.1163 s / img. ETA=0:09:03
[32m[04/20 12:33:20 d2.evaluation.evaluator]: [0mInference done 3814/8355. 0.1164 s / img. ETA=0:08:59
[32m[04/20 12:33:26 d2.evaluation.evaluator]: [0mInference done 3856/8355. 0.1164 s / img. ETA=0:08:54
[32m[04/20 12:33:31 d2.evaluation.evaluator]: [0mInference done 3899/8355. 0.1164 s / img. ETA=0:08:48
[32m[04/20 12:33:36 d2.evaluation.evaluator]: [0mInference done 3942/8355. 0.1164 s / img. ETA=0:08:43
[32m[04/20 12:33:41 d2.evaluation.evaluator]: [0mInference done 3985/8355. 0.1163 s / img. ETA=0:08:38
[32m[04/20 12:33:46 d2.evaluation.evaluator]: [0mInference done 4027/8355. 0.1164 s / img. ETA=0:08:33
[32m[04/20 12:33:51 d2.evaluation.evaluator]: [0mInference done 4069/8355. 0.1164 s / img. ETA=0:08:28
[32m[04/20 12:33:56 d2.evaluation.evaluator]: [0mInference done 4111/8355. 0.1164 s / img. ETA=0:08:23
[32m[04/20 12:34:01 d2.evaluation.evaluator]: [0mInference done 4153/8355. 0.1164 s / img. ETA=0:08:18
[32m[04/20 12:34:06 d2.evaluation.evaluator]: [0mInference done 4196/8355. 0.1164 s / img. ETA=0:08:13
[32m[04/20 12:34:11 d2.evaluation.evaluator]: [0mInference done 4239/8355. 0.1164 s / img. ETA=0:08:08
[32m[04/20 12:34:16 d2.evaluation.evaluator]: [0mInference done 4282/8355. 0.1164 s / img. ETA=0:08:03
[32m[04/20 12:34:21 d2.evaluation.evaluator]: [0mInference done 4325/8355. 0.1164 s / img. ETA=0:07:58
[32m[04/20 12:34:26 d2.evaluation.evaluator]: [0mInference done 4368/8355. 0.1164 s / img. ETA=0:07:53
[32m[04/20 12:34:31 d2.evaluation.evaluator]: [0mInference done 4410/8355. 0.1164 s / img. ETA=0:07:48
[32m[04/20 12:34:36 d2.evaluation.evaluator]: [0mInference done 4453/8355. 0.1164 s / img. ETA=0:07:43
[32m[04/20 12:34:41 d2.evaluation.evaluator]: [0mInference done 4495/8355. 0.1164 s / img. ETA=0:07:38
[32m[04/20 12:34:46 d2.evaluation.evaluator]: [0mInference done 4537/8355. 0.1164 s / img. ETA=0:07:33
[32m[04/20 12:34:52 d2.evaluation.evaluator]: [0mInference done 4579/8355. 0.1164 s / img. ETA=0:07:28
[32m[04/20 12:34:57 d2.evaluation.evaluator]: [0mInference done 4621/8355. 0.1164 s / img. ETA=0:07:23
[32m[04/20 12:35:02 d2.evaluation.evaluator]: [0mInference done 4663/8355. 0.1164 s / img. ETA=0:07:18
[32m[04/20 12:35:07 d2.evaluation.evaluator]: [0mInference done 4706/8355. 0.1164 s / img. ETA=0:07:13
[32m[04/20 12:35:12 d2.evaluation.evaluator]: [0mInference done 4749/8355. 0.1164 s / img. ETA=0:07:08
[32m[04/20 12:35:17 d2.evaluation.evaluator]: [0mInference done 4791/8355. 0.1164 s / img. ETA=0:07:03
[32m[04/20 12:35:22 d2.evaluation.evaluator]: [0mInference done 4833/8355. 0.1164 s / img. ETA=0:06:58
[32m[04/20 12:35:27 d2.evaluation.evaluator]: [0mInference done 4876/8355. 0.1164 s / img. ETA=0:06:53
[32m[04/20 12:35:32 d2.evaluation.evaluator]: [0mInference done 4919/8355. 0.1164 s / img. ETA=0:06:48
[32m[04/20 12:35:37 d2.evaluation.evaluator]: [0mInference done 4962/8355. 0.1164 s / img. ETA=0:06:42
[32m[04/20 12:35:42 d2.evaluation.evaluator]: [0mInference done 5005/8355. 0.1164 s / img. ETA=0:06:37
[32m[04/20 12:35:47 d2.evaluation.evaluator]: [0mInference done 5047/8355. 0.1164 s / img. ETA=0:06:32
[32m[04/20 12:35:52 d2.evaluation.evaluator]: [0mInference done 5089/8355. 0.1164 s / img. ETA=0:06:27
[32m[04/20 12:35:57 d2.evaluation.evaluator]: [0mInference done 5131/8355. 0.1164 s / img. ETA=0:06:22
[32m[04/20 12:36:02 d2.evaluation.evaluator]: [0mInference done 5173/8355. 0.1164 s / img. ETA=0:06:17
[32m[04/20 12:36:07 d2.evaluation.evaluator]: [0mInference done 5215/8355. 0.1164 s / img. ETA=0:06:13
[32m[04/20 12:36:12 d2.evaluation.evaluator]: [0mInference done 5258/8355. 0.1164 s / img. ETA=0:06:07
[32m[04/20 12:36:17 d2.evaluation.evaluator]: [0mInference done 5300/8355. 0.1164 s / img. ETA=0:06:02
[32m[04/20 12:36:22 d2.evaluation.evaluator]: [0mInference done 5342/8355. 0.1164 s / img. ETA=0:05:57
[32m[04/20 12:36:27 d2.evaluation.evaluator]: [0mInference done 5384/8355. 0.1164 s / img. ETA=0:05:52
[32m[04/20 12:36:32 d2.evaluation.evaluator]: [0mInference done 5426/8355. 0.1164 s / img. ETA=0:05:48
[32m[04/20 12:36:38 d2.evaluation.evaluator]: [0mInference done 5468/8355. 0.1164 s / img. ETA=0:05:43
[32m[04/20 12:36:43 d2.evaluation.evaluator]: [0mInference done 5511/8355. 0.1164 s / img. ETA=0:05:37
[32m[04/20 12:36:48 d2.evaluation.evaluator]: [0mInference done 5553/8355. 0.1164 s / img. ETA=0:05:32
[32m[04/20 12:36:53 d2.evaluation.evaluator]: [0mInference done 5596/8355. 0.1164 s / img. ETA=0:05:27
[32m[04/20 12:36:58 d2.evaluation.evaluator]: [0mInference done 5638/8355. 0.1164 s / img. ETA=0:05:22
[32m[04/20 12:37:03 d2.evaluation.evaluator]: [0mInference done 5680/8355. 0.1164 s / img. ETA=0:05:17
[32m[04/20 12:37:08 d2.evaluation.evaluator]: [0mInference done 5722/8355. 0.1164 s / img. ETA=0:05:12
[32m[04/20 12:37:13 d2.evaluation.evaluator]: [0mInference done 5764/8355. 0.1165 s / img. ETA=0:05:07
[32m[04/20 12:37:18 d2.evaluation.evaluator]: [0mInference done 5806/8355. 0.1165 s / img. ETA=0:05:02
[32m[04/20 12:37:23 d2.evaluation.evaluator]: [0mInference done 5848/8355. 0.1165 s / img. ETA=0:04:57
[32m[04/20 12:37:28 d2.evaluation.evaluator]: [0mInference done 5890/8355. 0.1165 s / img. ETA=0:04:53
[32m[04/20 12:37:33 d2.evaluation.evaluator]: [0mInference done 5932/8355. 0.1165 s / img. ETA=0:04:48
[32m[04/20 12:37:38 d2.evaluation.evaluator]: [0mInference done 5974/8355. 0.1165 s / img. ETA=0:04:43
[32m[04/20 12:37:43 d2.evaluation.evaluator]: [0mInference done 6016/8355. 0.1165 s / img. ETA=0:04:38
[32m[04/20 12:37:48 d2.evaluation.evaluator]: [0mInference done 6058/8355. 0.1165 s / img. ETA=0:04:33
[32m[04/20 12:37:53 d2.evaluation.evaluator]: [0mInference done 6100/8355. 0.1165 s / img. ETA=0:04:28
[32m[04/20 12:37:58 d2.evaluation.evaluator]: [0mInference done 6142/8355. 0.1165 s / img. ETA=0:04:23
[32m[04/20 12:38:03 d2.evaluation.evaluator]: [0mInference done 6184/8355. 0.1165 s / img. ETA=0:04:18
[32m[04/20 12:38:08 d2.evaluation.evaluator]: [0mInference done 6226/8355. 0.1166 s / img. ETA=0:04:13
[32m[04/20 12:38:13 d2.evaluation.evaluator]: [0mInference done 6268/8355. 0.1166 s / img. ETA=0:04:08
[32m[04/20 12:38:19 d2.evaluation.evaluator]: [0mInference done 6310/8355. 0.1166 s / img. ETA=0:04:03
[32m[04/20 12:38:24 d2.evaluation.evaluator]: [0mInference done 6352/8355. 0.1166 s / img. ETA=0:03:58
[32m[04/20 12:38:29 d2.evaluation.evaluator]: [0mInference done 6394/8355. 0.1166 s / img. ETA=0:03:53
[32m[04/20 12:38:34 d2.evaluation.evaluator]: [0mInference done 6436/8355. 0.1166 s / img. ETA=0:03:48
[32m[04/20 12:38:39 d2.evaluation.evaluator]: [0mInference done 6478/8355. 0.1166 s / img. ETA=0:03:43
[32m[04/20 12:38:44 d2.evaluation.evaluator]: [0mInference done 6521/8355. 0.1166 s / img. ETA=0:03:38
[32m[04/20 12:38:49 d2.evaluation.evaluator]: [0mInference done 6564/8355. 0.1166 s / img. ETA=0:03:33
[32m[04/20 12:38:54 d2.evaluation.evaluator]: [0mInference done 6606/8355. 0.1166 s / img. ETA=0:03:28
[32m[04/20 12:38:59 d2.evaluation.evaluator]: [0mInference done 6649/8355. 0.1166 s / img. ETA=0:03:23
[32m[04/20 12:39:04 d2.evaluation.evaluator]: [0mInference done 6692/8355. 0.1166 s / img. ETA=0:03:17
[32m[04/20 12:39:09 d2.evaluation.evaluator]: [0mInference done 6735/8355. 0.1166 s / img. ETA=0:03:12
[32m[04/20 12:39:14 d2.evaluation.evaluator]: [0mInference done 6778/8355. 0.1166 s / img. ETA=0:03:07
[32m[04/20 12:39:19 d2.evaluation.evaluator]: [0mInference done 6821/8355. 0.1166 s / img. ETA=0:03:02
[32m[04/20 12:39:24 d2.evaluation.evaluator]: [0mInference done 6863/8355. 0.1166 s / img. ETA=0:02:57
[32m[04/20 12:39:29 d2.evaluation.evaluator]: [0mInference done 6905/8355. 0.1166 s / img. ETA=0:02:52
[32m[04/20 12:39:34 d2.evaluation.evaluator]: [0mInference done 6947/8355. 0.1166 s / img. ETA=0:02:47
[32m[04/20 12:39:39 d2.evaluation.evaluator]: [0mInference done 6989/8355. 0.1166 s / img. ETA=0:02:42
[32m[04/20 12:39:44 d2.evaluation.evaluator]: [0mInference done 7031/8355. 0.1166 s / img. ETA=0:02:37
[32m[04/20 12:39:49 d2.evaluation.evaluator]: [0mInference done 7073/8355. 0.1166 s / img. ETA=0:02:32
[32m[04/20 12:39:55 d2.evaluation.evaluator]: [0mInference done 7115/8355. 0.1166 s / img. ETA=0:02:27
[32m[04/20 12:40:00 d2.evaluation.evaluator]: [0mInference done 7157/8355. 0.1166 s / img. ETA=0:02:22
[32m[04/20 12:40:05 d2.evaluation.evaluator]: [0mInference done 7199/8355. 0.1166 s / img. ETA=0:02:17
[32m[04/20 12:40:10 d2.evaluation.evaluator]: [0mInference done 7241/8355. 0.1166 s / img. ETA=0:02:12
[32m[04/20 12:40:15 d2.evaluation.evaluator]: [0mInference done 7283/8355. 0.1166 s / img. ETA=0:02:07
[32m[04/20 12:40:20 d2.evaluation.evaluator]: [0mInference done 7325/8355. 0.1166 s / img. ETA=0:02:02
[32m[04/20 12:40:25 d2.evaluation.evaluator]: [0mInference done 7367/8355. 0.1167 s / img. ETA=0:01:57
[32m[04/20 12:40:30 d2.evaluation.evaluator]: [0mInference done 7409/8355. 0.1167 s / img. ETA=0:01:52
[32m[04/20 12:40:35 d2.evaluation.evaluator]: [0mInference done 7451/8355. 0.1167 s / img. ETA=0:01:47
[32m[04/20 12:40:40 d2.evaluation.evaluator]: [0mInference done 7493/8355. 0.1167 s / img. ETA=0:01:42
[32m[04/20 12:40:45 d2.evaluation.evaluator]: [0mInference done 7535/8355. 0.1167 s / img. ETA=0:01:37
[32m[04/20 12:40:50 d2.evaluation.evaluator]: [0mInference done 7577/8355. 0.1167 s / img. ETA=0:01:32
[32m[04/20 12:40:55 d2.evaluation.evaluator]: [0mInference done 7619/8355. 0.1167 s / img. ETA=0:01:27
[32m[04/20 12:41:00 d2.evaluation.evaluator]: [0mInference done 7661/8355. 0.1167 s / img. ETA=0:01:22
[32m[04/20 12:41:05 d2.evaluation.evaluator]: [0mInference done 7703/8355. 0.1167 s / img. ETA=0:01:17
[32m[04/20 12:41:10 d2.evaluation.evaluator]: [0mInference done 7745/8355. 0.1167 s / img. ETA=0:01:12
[32m[04/20 12:41:15 d2.evaluation.evaluator]: [0mInference done 7787/8355. 0.1167 s / img. ETA=0:01:07
[32m[04/20 12:41:20 d2.evaluation.evaluator]: [0mInference done 7829/8355. 0.1167 s / img. ETA=0:01:02
[32m[04/20 12:41:25 d2.evaluation.evaluator]: [0mInference done 7871/8355. 0.1167 s / img. ETA=0:00:57
[32m[04/20 12:41:30 d2.evaluation.evaluator]: [0mInference done 7913/8355. 0.1167 s / img. ETA=0:00:52
[32m[04/20 12:41:35 d2.evaluation.evaluator]: [0mInference done 7955/8355. 0.1167 s / img. ETA=0:00:47
[32m[04/20 12:41:40 d2.evaluation.evaluator]: [0mInference done 7997/8355. 0.1167 s / img. ETA=0:00:42
[32m[04/20 12:41:46 d2.evaluation.evaluator]: [0mInference done 8039/8355. 0.1167 s / img. ETA=0:00:37
[32m[04/20 12:41:51 d2.evaluation.evaluator]: [0mInference done 8082/8355. 0.1167 s / img. ETA=0:00:32
[32m[04/20 12:41:56 d2.evaluation.evaluator]: [0mInference done 8125/8355. 0.1167 s / img. ETA=0:00:27
[32m[04/20 12:42:01 d2.evaluation.evaluator]: [0mInference done 8168/8355. 0.1167 s / img. ETA=0:00:22
[32m[04/20 12:42:06 d2.evaluation.evaluator]: [0mInference done 8211/8355. 0.1167 s / img. ETA=0:00:17
[32m[04/20 12:42:11 d2.evaluation.evaluator]: [0mInference done 8253/8355. 0.1167 s / img. ETA=0:00:12
[32m[04/20 12:42:16 d2.evaluation.evaluator]: [0mInference done 8295/8355. 0.1167 s / img. ETA=0:00:07
[32m[04/20 12:42:21 d2.evaluation.evaluator]: [0mInference done 8337/8355. 0.1167 s / img. ETA=0:00:02
[32m[04/20 12:42:23 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:34.916948 (0.119152 s / img per device, on 1 devices)
[32m[04/20 12:42:23 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:14 (0.116730 s / img per device, on 1 devices)
[32m[04/20 12:42:24 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 12:42:24 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 12:42:24 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.90s).
Accumulating evaluation results...
DONE (t=2.18s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.371
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.698
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.342
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.262
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.499
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.668
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.151
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.418
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.432
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.562
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716
[32m[04/20 12:42:46 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 37.087 | 69.788 | 34.179 | 26.240 | 49.926 | 66.796 |
[32m[04/20 12:42:46 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 38.683 | bicycle       | 25.932 | car            | 46.644 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 12:42:47 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 12:42:47 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 12:42:47 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 12:42:49 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1177 s / img. ETA=0:02:29
[32m[04/20 12:42:54 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1169 s / img. ETA=0:02:23
[32m[04/20 12:42:59 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1169 s / img. ETA=0:02:18
[32m[04/20 12:43:04 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1169 s / img. ETA=0:02:13
[32m[04/20 12:43:09 d2.evaluation.evaluator]: [0mInference done 179/1257. 0.1169 s / img. ETA=0:02:08
[32m[04/20 12:43:14 d2.evaluation.evaluator]: [0mInference done 221/1257. 0.1169 s / img. ETA=0:02:03
[32m[04/20 12:43:19 d2.evaluation.evaluator]: [0mInference done 263/1257. 0.1169 s / img. ETA=0:01:58
[32m[04/20 12:43:24 d2.evaluation.evaluator]: [0mInference done 305/1257. 0.1169 s / img. ETA=0:01:53
[32m[04/20 12:43:29 d2.evaluation.evaluator]: [0mInference done 347/1257. 0.1169 s / img. ETA=0:01:48
[32m[04/20 12:43:34 d2.evaluation.evaluator]: [0mInference done 389/1257. 0.1169 s / img. ETA=0:01:43
[32m[04/20 12:43:39 d2.evaluation.evaluator]: [0mInference done 432/1257. 0.1168 s / img. ETA=0:01:38
[32m[04/20 12:43:44 d2.evaluation.evaluator]: [0mInference done 474/1257. 0.1168 s / img. ETA=0:01:33
[32m[04/20 12:43:49 d2.evaluation.evaluator]: [0mInference done 516/1257. 0.1169 s / img. ETA=0:01:28
[32m[04/20 12:43:54 d2.evaluation.evaluator]: [0mInference done 558/1257. 0.1169 s / img. ETA=0:01:23
[32m[04/20 12:43:59 d2.evaluation.evaluator]: [0mInference done 600/1257. 0.1169 s / img. ETA=0:01:18
[32m[04/20 12:44:04 d2.evaluation.evaluator]: [0mInference done 642/1257. 0.1169 s / img. ETA=0:01:13
[32m[04/20 12:44:09 d2.evaluation.evaluator]: [0mInference done 684/1257. 0.1170 s / img. ETA=0:01:08
[32m[04/20 12:44:14 d2.evaluation.evaluator]: [0mInference done 726/1257. 0.1170 s / img. ETA=0:01:03
[32m[04/20 12:44:19 d2.evaluation.evaluator]: [0mInference done 768/1257. 0.1170 s / img. ETA=0:00:58
[32m[04/20 12:44:24 d2.evaluation.evaluator]: [0mInference done 810/1257. 0.1170 s / img. ETA=0:00:53
[32m[04/20 12:44:30 d2.evaluation.evaluator]: [0mInference done 852/1257. 0.1170 s / img. ETA=0:00:48
[32m[04/20 12:44:35 d2.evaluation.evaluator]: [0mInference done 894/1257. 0.1170 s / img. ETA=0:00:43
[32m[04/20 12:44:40 d2.evaluation.evaluator]: [0mInference done 936/1257. 0.1170 s / img. ETA=0:00:38
[32m[04/20 12:44:45 d2.evaluation.evaluator]: [0mInference done 978/1257. 0.1170 s / img. ETA=0:00:33
[32m[04/20 12:44:50 d2.evaluation.evaluator]: [0mInference done 1020/1257. 0.1170 s / img. ETA=0:00:28
[32m[04/20 12:44:55 d2.evaluation.evaluator]: [0mInference done 1062/1257. 0.1170 s / img. ETA=0:00:23
[32m[04/20 12:45:00 d2.evaluation.evaluator]: [0mInference done 1104/1257. 0.1170 s / img. ETA=0:00:18
[32m[04/20 12:45:05 d2.evaluation.evaluator]: [0mInference done 1146/1257. 0.1170 s / img. ETA=0:00:13
[32m[04/20 12:45:10 d2.evaluation.evaluator]: [0mInference done 1188/1257. 0.1170 s / img. ETA=0:00:08
[32m[04/20 12:45:15 d2.evaluation.evaluator]: [0mInference done 1230/1257. 0.1170 s / img. ETA=0:00:03
[32m[04/20 12:45:18 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:29.727155 (0.119590 s / img per device, on 1 devices)
[32m[04/20 12:45:18 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:26 (0.117032 s / img per device, on 1 devices)
[32m[04/20 12:45:18 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 12:45:18 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 12:45:18 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.03s).
Accumulating evaluation results...
DONE (t=0.35s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.561
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.261
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.353
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.491
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.143
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.354
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.245
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.567
[32m[04/20 12:45:22 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 28.815 | 56.056 | 26.112 | 17.528 | 35.320 | 49.137 |
[32m[04/20 12:45:22 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 32.355 | bicycle       | 10.272 | car            | 43.817 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  12  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 12:45:22 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 12:45:23 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 12:45:23 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 12:45:23 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 12:45:23 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 12:45:23 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 12:45:23 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 12:45:44 d2.utils.events]: [0m eta: 0:16:48  iter: 19  total_loss: 0.600  loss_cls: 0.208  loss_box_reg: 0.332  loss_rpn_cls: 0.018  loss_rpn_loc: 0.052  time: 1.0231  data_time: 0.0259  lr: 0.000100  max_mem: 5405M
[32m[04/20 12:46:05 d2.utils.events]: [0m eta: 0:16:58  iter: 39  total_loss: 0.619  loss_cls: 0.197  loss_box_reg: 0.354  loss_rpn_cls: 0.016  loss_rpn_loc: 0.048  time: 1.0381  data_time: 0.0097  lr: 0.000200  max_mem: 5405M
[32m[04/20 12:46:26 d2.utils.events]: [0m eta: 0:16:41  iter: 59  total_loss: 0.619  loss_cls: 0.213  loss_box_reg: 0.352  loss_rpn_cls: 0.017  loss_rpn_loc: 0.046  time: 1.0399  data_time: 0.0097  lr: 0.000300  max_mem: 5405M
[32m[04/20 12:46:46 d2.utils.events]: [0m eta: 0:16:16  iter: 79  total_loss: 0.648  loss_cls: 0.212  loss_box_reg: 0.347  loss_rpn_cls: 0.018  loss_rpn_loc: 0.056  time: 1.0387  data_time: 0.0097  lr: 0.000400  max_mem: 5405M
[32m[04/20 12:47:07 d2.utils.events]: [0m eta: 0:15:46  iter: 99  total_loss: 0.555  loss_cls: 0.169  loss_box_reg: 0.313  loss_rpn_cls: 0.014  loss_rpn_loc: 0.053  time: 1.0319  data_time: 0.0094  lr: 0.000500  max_mem: 5405M
[32m[04/20 12:47:27 d2.utils.events]: [0m eta: 0:15:23  iter: 119  total_loss: 0.652  loss_cls: 0.200  loss_box_reg: 0.353  loss_rpn_cls: 0.014  loss_rpn_loc: 0.063  time: 1.0331  data_time: 0.0096  lr: 0.000599  max_mem: 5405M
[32m[04/20 12:47:48 d2.utils.events]: [0m eta: 0:14:54  iter: 139  total_loss: 0.588  loss_cls: 0.196  loss_box_reg: 0.315  loss_rpn_cls: 0.016  loss_rpn_loc: 0.050  time: 1.0312  data_time: 0.0094  lr: 0.000699  max_mem: 5405M
[32m[04/20 12:48:09 d2.utils.events]: [0m eta: 0:14:35  iter: 159  total_loss: 0.609  loss_cls: 0.197  loss_box_reg: 0.341  loss_rpn_cls: 0.017  loss_rpn_loc: 0.048  time: 1.0318  data_time: 0.0098  lr: 0.000799  max_mem: 5405M
[32m[04/20 12:48:29 d2.utils.events]: [0m eta: 0:14:15  iter: 179  total_loss: 0.615  loss_cls: 0.205  loss_box_reg: 0.330  loss_rpn_cls: 0.015  loss_rpn_loc: 0.047  time: 1.0318  data_time: 0.0096  lr: 0.000899  max_mem: 5405M
[32m[04/20 12:48:50 d2.utils.events]: [0m eta: 0:13:56  iter: 199  total_loss: 0.585  loss_cls: 0.179  loss_box_reg: 0.334  loss_rpn_cls: 0.013  loss_rpn_loc: 0.060  time: 1.0339  data_time: 0.0098  lr: 0.000999  max_mem: 5405M
[32m[04/20 12:49:11 d2.utils.events]: [0m eta: 0:13:38  iter: 219  total_loss: 0.572  loss_cls: 0.193  loss_box_reg: 0.302  loss_rpn_cls: 0.015  loss_rpn_loc: 0.054  time: 1.0347  data_time: 0.0096  lr: 0.001099  max_mem: 5405M
[32m[04/20 12:49:32 d2.utils.events]: [0m eta: 0:13:19  iter: 239  total_loss: 0.608  loss_cls: 0.203  loss_box_reg: 0.327  loss_rpn_cls: 0.017  loss_rpn_loc: 0.047  time: 1.0351  data_time: 0.0096  lr: 0.001199  max_mem: 5405M
[32m[04/20 12:49:53 d2.utils.events]: [0m eta: 0:12:57  iter: 259  total_loss: 0.710  loss_cls: 0.219  loss_box_reg: 0.359  loss_rpn_cls: 0.022  loss_rpn_loc: 0.068  time: 1.0338  data_time: 0.0096  lr: 0.001299  max_mem: 5405M
[32m[04/20 12:50:13 d2.utils.events]: [0m eta: 0:12:31  iter: 279  total_loss: 0.572  loss_cls: 0.192  loss_box_reg: 0.320  loss_rpn_cls: 0.017  loss_rpn_loc: 0.053  time: 1.0320  data_time: 0.0096  lr: 0.001399  max_mem: 5405M
[32m[04/20 12:50:33 d2.utils.events]: [0m eta: 0:12:02  iter: 299  total_loss: 0.595  loss_cls: 0.187  loss_box_reg: 0.345  loss_rpn_cls: 0.016  loss_rpn_loc: 0.045  time: 1.0295  data_time: 0.0096  lr: 0.001499  max_mem: 5405M
[32m[04/20 12:50:53 d2.utils.events]: [0m eta: 0:11:41  iter: 319  total_loss: 0.663  loss_cls: 0.207  loss_box_reg: 0.337  loss_rpn_cls: 0.017  loss_rpn_loc: 0.060  time: 1.0290  data_time: 0.0098  lr: 0.001598  max_mem: 5405M
[32m[04/20 12:51:14 d2.utils.events]: [0m eta: 0:11:21  iter: 339  total_loss: 0.562  loss_cls: 0.194  loss_box_reg: 0.311  loss_rpn_cls: 0.016  loss_rpn_loc: 0.043  time: 1.0297  data_time: 0.0099  lr: 0.001698  max_mem: 5405M
[32m[04/20 12:51:34 d2.utils.events]: [0m eta: 0:11:00  iter: 359  total_loss: 0.652  loss_cls: 0.190  loss_box_reg: 0.371  loss_rpn_cls: 0.016  loss_rpn_loc: 0.048  time: 1.0289  data_time: 0.0100  lr: 0.001798  max_mem: 5405M
[32m[04/20 12:51:55 d2.utils.events]: [0m eta: 0:10:39  iter: 379  total_loss: 0.576  loss_cls: 0.196  loss_box_reg: 0.318  loss_rpn_cls: 0.017  loss_rpn_loc: 0.043  time: 1.0286  data_time: 0.0098  lr: 0.001898  max_mem: 5405M
[32m[04/20 12:52:16 d2.utils.events]: [0m eta: 0:10:19  iter: 399  total_loss: 0.646  loss_cls: 0.206  loss_box_reg: 0.351  loss_rpn_cls: 0.016  loss_rpn_loc: 0.055  time: 1.0293  data_time: 0.0097  lr: 0.001998  max_mem: 5405M
[32m[04/20 12:52:37 d2.utils.events]: [0m eta: 0:09:59  iter: 419  total_loss: 0.650  loss_cls: 0.207  loss_box_reg: 0.363  loss_rpn_cls: 0.014  loss_rpn_loc: 0.056  time: 1.0298  data_time: 0.0099  lr: 0.002098  max_mem: 5405M
[32m[04/20 12:52:57 d2.utils.events]: [0m eta: 0:09:38  iter: 439  total_loss: 0.576  loss_cls: 0.190  loss_box_reg: 0.328  loss_rpn_cls: 0.014  loss_rpn_loc: 0.050  time: 1.0284  data_time: 0.0096  lr: 0.002198  max_mem: 5405M
[32m[04/20 12:53:17 d2.utils.events]: [0m eta: 0:09:17  iter: 459  total_loss: 0.637  loss_cls: 0.204  loss_box_reg: 0.352  loss_rpn_cls: 0.018  loss_rpn_loc: 0.063  time: 1.0281  data_time: 0.0096  lr: 0.002298  max_mem: 5405M
[32m[04/20 12:53:37 d2.utils.events]: [0m eta: 0:08:56  iter: 479  total_loss: 0.558  loss_cls: 0.177  loss_box_reg: 0.307  loss_rpn_cls: 0.012  loss_rpn_loc: 0.049  time: 1.0270  data_time: 0.0094  lr: 0.002398  max_mem: 5405M
[32m[04/20 12:53:58 d2.utils.events]: [0m eta: 0:08:35  iter: 499  total_loss: 0.615  loss_cls: 0.201  loss_box_reg: 0.334  loss_rpn_cls: 0.014  loss_rpn_loc: 0.063  time: 1.0271  data_time: 0.0097  lr: 0.002498  max_mem: 5405M
[32m[04/20 12:54:19 d2.utils.events]: [0m eta: 0:08:15  iter: 519  total_loss: 0.610  loss_cls: 0.195  loss_box_reg: 0.346  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0278  data_time: 0.0094  lr: 0.002597  max_mem: 5405M
[32m[04/20 12:54:40 d2.utils.events]: [0m eta: 0:07:56  iter: 539  total_loss: 0.662  loss_cls: 0.223  loss_box_reg: 0.352  loss_rpn_cls: 0.018  loss_rpn_loc: 0.048  time: 1.0291  data_time: 0.0099  lr: 0.002697  max_mem: 5405M
[32m[04/20 12:55:00 d2.utils.events]: [0m eta: 0:07:34  iter: 559  total_loss: 0.620  loss_cls: 0.205  loss_box_reg: 0.338  loss_rpn_cls: 0.014  loss_rpn_loc: 0.054  time: 1.0285  data_time: 0.0095  lr: 0.002797  max_mem: 5405M
[32m[04/20 12:55:21 d2.utils.events]: [0m eta: 0:07:16  iter: 579  total_loss: 0.574  loss_cls: 0.196  loss_box_reg: 0.318  loss_rpn_cls: 0.012  loss_rpn_loc: 0.045  time: 1.0292  data_time: 0.0097  lr: 0.002897  max_mem: 5405M
[32m[04/20 12:55:42 d2.utils.events]: [0m eta: 0:06:54  iter: 599  total_loss: 0.593  loss_cls: 0.196  loss_box_reg: 0.318  loss_rpn_cls: 0.020  loss_rpn_loc: 0.051  time: 1.0289  data_time: 0.0097  lr: 0.002997  max_mem: 5405M
[32m[04/20 12:56:02 d2.utils.events]: [0m eta: 0:06:32  iter: 619  total_loss: 0.663  loss_cls: 0.213  loss_box_reg: 0.355  loss_rpn_cls: 0.019  loss_rpn_loc: 0.050  time: 1.0286  data_time: 0.0097  lr: 0.003097  max_mem: 5405M
[32m[04/20 12:56:23 d2.utils.events]: [0m eta: 0:06:12  iter: 639  total_loss: 0.578  loss_cls: 0.188  loss_box_reg: 0.331  loss_rpn_cls: 0.018  loss_rpn_loc: 0.052  time: 1.0286  data_time: 0.0097  lr: 0.003197  max_mem: 5405M
[32m[04/20 12:56:44 d2.utils.events]: [0m eta: 0:05:52  iter: 659  total_loss: 0.708  loss_cls: 0.227  loss_box_reg: 0.395  loss_rpn_cls: 0.016  loss_rpn_loc: 0.070  time: 1.0291  data_time: 0.0099  lr: 0.003297  max_mem: 5405M
[32m[04/20 12:57:04 d2.utils.events]: [0m eta: 0:05:31  iter: 679  total_loss: 0.667  loss_cls: 0.196  loss_box_reg: 0.391  loss_rpn_cls: 0.016  loss_rpn_loc: 0.060  time: 1.0287  data_time: 0.0096  lr: 0.003397  max_mem: 5405M
[32m[04/20 12:57:25 d2.utils.events]: [0m eta: 0:05:10  iter: 699  total_loss: 0.637  loss_cls: 0.196  loss_box_reg: 0.350  loss_rpn_cls: 0.020  loss_rpn_loc: 0.052  time: 1.0289  data_time: 0.0097  lr: 0.003497  max_mem: 5405M
[32m[04/20 12:57:46 d2.utils.events]: [0m eta: 0:04:50  iter: 719  total_loss: 0.603  loss_cls: 0.201  loss_box_reg: 0.326  loss_rpn_cls: 0.017  loss_rpn_loc: 0.054  time: 1.0296  data_time: 0.0098  lr: 0.003596  max_mem: 5405M
[32m[04/20 12:58:07 d2.utils.events]: [0m eta: 0:04:29  iter: 739  total_loss: 0.558  loss_cls: 0.181  loss_box_reg: 0.313  loss_rpn_cls: 0.018  loss_rpn_loc: 0.051  time: 1.0293  data_time: 0.0098  lr: 0.003696  max_mem: 5405M
[32m[04/20 12:58:28 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.619  loss_cls: 0.202  loss_box_reg: 0.345  loss_rpn_cls: 0.017  loss_rpn_loc: 0.057  time: 1.0298  data_time: 0.0098  lr: 0.003796  max_mem: 5405M
[32m[04/20 12:58:48 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.656  loss_cls: 0.202  loss_box_reg: 0.360  loss_rpn_cls: 0.017  loss_rpn_loc: 0.063  time: 1.0299  data_time: 0.0097  lr: 0.003896  max_mem: 5405M
[32m[04/20 12:59:09 d2.utils.events]: [0m eta: 0:03:27  iter: 799  total_loss: 0.591  loss_cls: 0.196  loss_box_reg: 0.341  loss_rpn_cls: 0.017  loss_rpn_loc: 0.056  time: 1.0298  data_time: 0.0097  lr: 0.003996  max_mem: 5405M
[32m[04/20 12:59:30 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.582  loss_cls: 0.155  loss_box_reg: 0.337  loss_rpn_cls: 0.014  loss_rpn_loc: 0.049  time: 1.0303  data_time: 0.0098  lr: 0.004096  max_mem: 5405M
[32m[04/20 12:59:50 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.599  loss_cls: 0.202  loss_box_reg: 0.356  loss_rpn_cls: 0.020  loss_rpn_loc: 0.060  time: 1.0298  data_time: 0.0104  lr: 0.004196  max_mem: 5405M
[32m[04/20 13:00:11 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.576  loss_cls: 0.203  loss_box_reg: 0.310  loss_rpn_cls: 0.020  loss_rpn_loc: 0.051  time: 1.0298  data_time: 0.0099  lr: 0.004296  max_mem: 5405M
[32m[04/20 13:00:31 d2.utils.events]: [0m eta: 0:02:04  iter: 879  total_loss: 0.628  loss_cls: 0.192  loss_box_reg: 0.351  loss_rpn_cls: 0.019  loss_rpn_loc: 0.053  time: 1.0295  data_time: 0.0103  lr: 0.004396  max_mem: 5405M
[32m[04/20 13:00:52 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.709  loss_cls: 0.225  loss_box_reg: 0.367  loss_rpn_cls: 0.017  loss_rpn_loc: 0.056  time: 1.0293  data_time: 0.0105  lr: 0.004496  max_mem: 5405M
[32m[04/20 13:01:12 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.685  loss_cls: 0.232  loss_box_reg: 0.380  loss_rpn_cls: 0.018  loss_rpn_loc: 0.052  time: 1.0291  data_time: 0.0112  lr: 0.004595  max_mem: 5405M
[32m[04/20 13:01:33 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.678  loss_cls: 0.230  loss_box_reg: 0.367  loss_rpn_cls: 0.018  loss_rpn_loc: 0.070  time: 1.0297  data_time: 0.0100  lr: 0.004695  max_mem: 5405M
[32m[04/20 13:01:54 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.586  loss_cls: 0.182  loss_box_reg: 0.332  loss_rpn_cls: 0.017  loss_rpn_loc: 0.056  time: 1.0301  data_time: 0.0106  lr: 0.004795  max_mem: 5405M
[32m[04/20 13:02:15 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.689  loss_cls: 0.231  loss_box_reg: 0.376  loss_rpn_cls: 0.021  loss_rpn_loc: 0.063  time: 1.0301  data_time: 0.0102  lr: 0.004895  max_mem: 5405M
[5m[31mWARNING[0m [32m[04/20 13:02:40 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 13:02:40 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 13:02:40 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 13:02:40 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.670  loss_cls: 0.224  loss_box_reg: 0.337  loss_rpn_cls: 0.016  loss_rpn_loc: 0.063  time: 1.0305  data_time: 0.0124  lr: 0.004995  max_mem: 5405M
[32m[04/20 13:02:40 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:08 (1.0315 s / it)
[32m[04/20 13:02:40 d2.engine.hooks]: [0mTotal training time: 0:17:14 (0:00:06 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 13:02:43 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 13:02:43 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 13:02:44 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 13:02:45 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1179 s / img. ETA=0:16:39
[32m[04/20 13:02:50 d2.evaluation.evaluator]: [0mInference done 54/8355. 0.1169 s / img. ETA=0:16:27
[32m[04/20 13:02:55 d2.evaluation.evaluator]: [0mInference done 97/8355. 0.1164 s / img. ETA=0:16:18
[32m[04/20 13:03:00 d2.evaluation.evaluator]: [0mInference done 140/8355. 0.1164 s / img. ETA=0:16:13
[32m[04/20 13:03:06 d2.evaluation.evaluator]: [0mInference done 183/8355. 0.1164 s / img. ETA=0:16:08
[32m[04/20 13:03:11 d2.evaluation.evaluator]: [0mInference done 225/8355. 0.1166 s / img. ETA=0:16:05
[32m[04/20 13:03:16 d2.evaluation.evaluator]: [0mInference done 268/8355. 0.1166 s / img. ETA=0:16:00
[32m[04/20 13:03:21 d2.evaluation.evaluator]: [0mInference done 310/8355. 0.1167 s / img. ETA=0:15:56
[32m[04/20 13:03:26 d2.evaluation.evaluator]: [0mInference done 353/8355. 0.1167 s / img. ETA=0:15:51
[32m[04/20 13:03:31 d2.evaluation.evaluator]: [0mInference done 395/8355. 0.1168 s / img. ETA=0:15:47
[32m[04/20 13:03:36 d2.evaluation.evaluator]: [0mInference done 438/8355. 0.1168 s / img. ETA=0:15:41
[32m[04/20 13:03:41 d2.evaluation.evaluator]: [0mInference done 481/8355. 0.1168 s / img. ETA=0:15:36
[32m[04/20 13:03:46 d2.evaluation.evaluator]: [0mInference done 524/8355. 0.1168 s / img. ETA=0:15:31
[32m[04/20 13:03:51 d2.evaluation.evaluator]: [0mInference done 567/8355. 0.1168 s / img. ETA=0:15:26
[32m[04/20 13:03:56 d2.evaluation.evaluator]: [0mInference done 609/8355. 0.1168 s / img. ETA=0:15:21
[32m[04/20 13:04:01 d2.evaluation.evaluator]: [0mInference done 651/8355. 0.1168 s / img. ETA=0:15:16
[32m[04/20 13:04:06 d2.evaluation.evaluator]: [0mInference done 693/8355. 0.1168 s / img. ETA=0:15:11
[32m[04/20 13:04:11 d2.evaluation.evaluator]: [0mInference done 736/8355. 0.1168 s / img. ETA=0:15:06
[32m[04/20 13:04:17 d2.evaluation.evaluator]: [0mInference done 779/8355. 0.1167 s / img. ETA=0:15:00
[32m[04/20 13:04:22 d2.evaluation.evaluator]: [0mInference done 821/8355. 0.1168 s / img. ETA=0:14:56
[32m[04/20 13:04:27 d2.evaluation.evaluator]: [0mInference done 864/8355. 0.1168 s / img. ETA=0:14:50
[32m[04/20 13:04:32 d2.evaluation.evaluator]: [0mInference done 906/8355. 0.1168 s / img. ETA=0:14:46
[32m[04/20 13:04:37 d2.evaluation.evaluator]: [0mInference done 949/8355. 0.1168 s / img. ETA=0:14:41
[32m[04/20 13:04:42 d2.evaluation.evaluator]: [0mInference done 991/8355. 0.1168 s / img. ETA=0:14:36
[32m[04/20 13:04:47 d2.evaluation.evaluator]: [0mInference done 1034/8355. 0.1168 s / img. ETA=0:14:30
[32m[04/20 13:04:52 d2.evaluation.evaluator]: [0mInference done 1077/8355. 0.1168 s / img. ETA=0:14:25
[32m[04/20 13:04:57 d2.evaluation.evaluator]: [0mInference done 1120/8355. 0.1167 s / img. ETA=0:14:20
[32m[04/20 13:05:02 d2.evaluation.evaluator]: [0mInference done 1162/8355. 0.1168 s / img. ETA=0:14:15
[32m[04/20 13:05:07 d2.evaluation.evaluator]: [0mInference done 1204/8355. 0.1168 s / img. ETA=0:14:10
[32m[04/20 13:05:12 d2.evaluation.evaluator]: [0mInference done 1247/8355. 0.1168 s / img. ETA=0:14:05
[32m[04/20 13:05:17 d2.evaluation.evaluator]: [0mInference done 1289/8355. 0.1168 s / img. ETA=0:14:00
[32m[04/20 13:05:22 d2.evaluation.evaluator]: [0mInference done 1331/8355. 0.1168 s / img. ETA=0:13:56
[32m[04/20 13:05:27 d2.evaluation.evaluator]: [0mInference done 1374/8355. 0.1168 s / img. ETA=0:13:50
[32m[04/20 13:05:32 d2.evaluation.evaluator]: [0mInference done 1417/8355. 0.1168 s / img. ETA=0:13:45
[32m[04/20 13:05:38 d2.evaluation.evaluator]: [0mInference done 1460/8355. 0.1167 s / img. ETA=0:13:40
[32m[04/20 13:05:43 d2.evaluation.evaluator]: [0mInference done 1502/8355. 0.1168 s / img. ETA=0:13:35
[32m[04/20 13:05:48 d2.evaluation.evaluator]: [0mInference done 1544/8355. 0.1168 s / img. ETA=0:13:30
[32m[04/20 13:05:53 d2.evaluation.evaluator]: [0mInference done 1586/8355. 0.1169 s / img. ETA=0:13:26
[32m[04/20 13:05:58 d2.evaluation.evaluator]: [0mInference done 1628/8355. 0.1169 s / img. ETA=0:13:21
[32m[04/20 13:06:03 d2.evaluation.evaluator]: [0mInference done 1670/8355. 0.1169 s / img. ETA=0:13:16
[32m[04/20 13:06:08 d2.evaluation.evaluator]: [0mInference done 1712/8355. 0.1169 s / img. ETA=0:13:12
[32m[04/20 13:06:13 d2.evaluation.evaluator]: [0mInference done 1754/8355. 0.1170 s / img. ETA=0:13:07
[32m[04/20 13:06:18 d2.evaluation.evaluator]: [0mInference done 1796/8355. 0.1170 s / img. ETA=0:13:02
[32m[04/20 13:06:23 d2.evaluation.evaluator]: [0mInference done 1838/8355. 0.1170 s / img. ETA=0:12:57
[32m[04/20 13:06:28 d2.evaluation.evaluator]: [0mInference done 1880/8355. 0.1170 s / img. ETA=0:12:52
[32m[04/20 13:06:33 d2.evaluation.evaluator]: [0mInference done 1922/8355. 0.1171 s / img. ETA=0:12:47
[32m[04/20 13:06:38 d2.evaluation.evaluator]: [0mInference done 1964/8355. 0.1171 s / img. ETA=0:12:42
[32m[04/20 13:06:43 d2.evaluation.evaluator]: [0mInference done 2006/8355. 0.1171 s / img. ETA=0:12:38
[32m[04/20 13:06:48 d2.evaluation.evaluator]: [0mInference done 2048/8355. 0.1171 s / img. ETA=0:12:33
[32m[04/20 13:06:53 d2.evaluation.evaluator]: [0mInference done 2090/8355. 0.1171 s / img. ETA=0:12:28
[32m[04/20 13:06:59 d2.evaluation.evaluator]: [0mInference done 2132/8355. 0.1171 s / img. ETA=0:12:23
[32m[04/20 13:07:04 d2.evaluation.evaluator]: [0mInference done 2174/8355. 0.1171 s / img. ETA=0:12:18
[32m[04/20 13:07:09 d2.evaluation.evaluator]: [0mInference done 2216/8355. 0.1171 s / img. ETA=0:12:13
[32m[04/20 13:07:14 d2.evaluation.evaluator]: [0mInference done 2258/8355. 0.1172 s / img. ETA=0:12:08
[32m[04/20 13:07:19 d2.evaluation.evaluator]: [0mInference done 2300/8355. 0.1172 s / img. ETA=0:12:03
[32m[04/20 13:07:24 d2.evaluation.evaluator]: [0mInference done 2342/8355. 0.1172 s / img. ETA=0:11:58
[32m[04/20 13:07:29 d2.evaluation.evaluator]: [0mInference done 2384/8355. 0.1172 s / img. ETA=0:11:53
[32m[04/20 13:07:34 d2.evaluation.evaluator]: [0mInference done 2426/8355. 0.1172 s / img. ETA=0:11:49
[32m[04/20 13:07:39 d2.evaluation.evaluator]: [0mInference done 2468/8355. 0.1173 s / img. ETA=0:11:44
[32m[04/20 13:07:44 d2.evaluation.evaluator]: [0mInference done 2510/8355. 0.1173 s / img. ETA=0:11:39
[32m[04/20 13:07:49 d2.evaluation.evaluator]: [0mInference done 2552/8355. 0.1173 s / img. ETA=0:11:34
[32m[04/20 13:07:54 d2.evaluation.evaluator]: [0mInference done 2594/8355. 0.1173 s / img. ETA=0:11:29
[32m[04/20 13:07:59 d2.evaluation.evaluator]: [0mInference done 2636/8355. 0.1173 s / img. ETA=0:11:24
[32m[04/20 13:08:04 d2.evaluation.evaluator]: [0mInference done 2678/8355. 0.1173 s / img. ETA=0:11:19
[32m[04/20 13:08:09 d2.evaluation.evaluator]: [0mInference done 2720/8355. 0.1173 s / img. ETA=0:11:14
[32m[04/20 13:08:14 d2.evaluation.evaluator]: [0mInference done 2762/8355. 0.1173 s / img. ETA=0:11:09
[32m[04/20 13:08:20 d2.evaluation.evaluator]: [0mInference done 2804/8355. 0.1173 s / img. ETA=0:11:04
[32m[04/20 13:08:25 d2.evaluation.evaluator]: [0mInference done 2846/8355. 0.1173 s / img. ETA=0:10:59
[32m[04/20 13:08:30 d2.evaluation.evaluator]: [0mInference done 2888/8355. 0.1173 s / img. ETA=0:10:54
[32m[04/20 13:08:35 d2.evaluation.evaluator]: [0mInference done 2930/8355. 0.1173 s / img. ETA=0:10:49
[32m[04/20 13:08:40 d2.evaluation.evaluator]: [0mInference done 2972/8355. 0.1174 s / img. ETA=0:10:44
[32m[04/20 13:08:45 d2.evaluation.evaluator]: [0mInference done 3014/8355. 0.1174 s / img. ETA=0:10:39
[32m[04/20 13:08:50 d2.evaluation.evaluator]: [0mInference done 3056/8355. 0.1174 s / img. ETA=0:10:34
[32m[04/20 13:08:55 d2.evaluation.evaluator]: [0mInference done 3098/8355. 0.1174 s / img. ETA=0:10:29
[32m[04/20 13:09:00 d2.evaluation.evaluator]: [0mInference done 3140/8355. 0.1174 s / img. ETA=0:10:24
[32m[04/20 13:09:05 d2.evaluation.evaluator]: [0mInference done 3182/8355. 0.1173 s / img. ETA=0:10:19
[32m[04/20 13:09:10 d2.evaluation.evaluator]: [0mInference done 3224/8355. 0.1173 s / img. ETA=0:10:14
[32m[04/20 13:09:15 d2.evaluation.evaluator]: [0mInference done 3266/8355. 0.1173 s / img. ETA=0:10:09
[32m[04/20 13:09:20 d2.evaluation.evaluator]: [0mInference done 3308/8355. 0.1173 s / img. ETA=0:10:04
[32m[04/20 13:09:25 d2.evaluation.evaluator]: [0mInference done 3350/8355. 0.1173 s / img. ETA=0:09:59
[32m[04/20 13:09:30 d2.evaluation.evaluator]: [0mInference done 3392/8355. 0.1173 s / img. ETA=0:09:54
[32m[04/20 13:09:35 d2.evaluation.evaluator]: [0mInference done 3434/8355. 0.1173 s / img. ETA=0:09:49
[32m[04/20 13:09:40 d2.evaluation.evaluator]: [0mInference done 3476/8355. 0.1173 s / img. ETA=0:09:44
[32m[04/20 13:09:45 d2.evaluation.evaluator]: [0mInference done 3518/8355. 0.1173 s / img. ETA=0:09:39
[32m[04/20 13:09:50 d2.evaluation.evaluator]: [0mInference done 3560/8355. 0.1173 s / img. ETA=0:09:34
[32m[04/20 13:09:55 d2.evaluation.evaluator]: [0mInference done 3602/8355. 0.1173 s / img. ETA=0:09:29
[32m[04/20 13:10:00 d2.evaluation.evaluator]: [0mInference done 3644/8355. 0.1174 s / img. ETA=0:09:24
[32m[04/20 13:10:05 d2.evaluation.evaluator]: [0mInference done 3686/8355. 0.1174 s / img. ETA=0:09:19
[32m[04/20 13:10:10 d2.evaluation.evaluator]: [0mInference done 3728/8355. 0.1174 s / img. ETA=0:09:14
[32m[04/20 13:10:15 d2.evaluation.evaluator]: [0mInference done 3770/8355. 0.1174 s / img. ETA=0:09:09
[32m[04/20 13:10:20 d2.evaluation.evaluator]: [0mInference done 3812/8355. 0.1174 s / img. ETA=0:09:04
[32m[04/20 13:10:26 d2.evaluation.evaluator]: [0mInference done 3854/8355. 0.1174 s / img. ETA=0:08:59
[32m[04/20 13:10:31 d2.evaluation.evaluator]: [0mInference done 3896/8355. 0.1174 s / img. ETA=0:08:54
[32m[04/20 13:10:36 d2.evaluation.evaluator]: [0mInference done 3938/8355. 0.1174 s / img. ETA=0:08:49
[32m[04/20 13:10:41 d2.evaluation.evaluator]: [0mInference done 3980/8355. 0.1174 s / img. ETA=0:08:44
[32m[04/20 13:10:46 d2.evaluation.evaluator]: [0mInference done 4022/8355. 0.1174 s / img. ETA=0:08:39
[32m[04/20 13:10:51 d2.evaluation.evaluator]: [0mInference done 4064/8355. 0.1174 s / img. ETA=0:08:34
[32m[04/20 13:10:56 d2.evaluation.evaluator]: [0mInference done 4106/8355. 0.1174 s / img. ETA=0:08:29
[32m[04/20 13:11:01 d2.evaluation.evaluator]: [0mInference done 4148/8355. 0.1174 s / img. ETA=0:08:24
[32m[04/20 13:11:06 d2.evaluation.evaluator]: [0mInference done 4190/8355. 0.1174 s / img. ETA=0:08:19
[32m[04/20 13:11:11 d2.evaluation.evaluator]: [0mInference done 4232/8355. 0.1174 s / img. ETA=0:08:13
[32m[04/20 13:11:16 d2.evaluation.evaluator]: [0mInference done 4274/8355. 0.1174 s / img. ETA=0:08:08
[32m[04/20 13:11:21 d2.evaluation.evaluator]: [0mInference done 4316/8355. 0.1174 s / img. ETA=0:08:03
[32m[04/20 13:11:26 d2.evaluation.evaluator]: [0mInference done 4358/8355. 0.1174 s / img. ETA=0:07:58
[32m[04/20 13:11:31 d2.evaluation.evaluator]: [0mInference done 4400/8355. 0.1174 s / img. ETA=0:07:53
[32m[04/20 13:11:36 d2.evaluation.evaluator]: [0mInference done 4442/8355. 0.1174 s / img. ETA=0:07:48
[32m[04/20 13:11:41 d2.evaluation.evaluator]: [0mInference done 4484/8355. 0.1174 s / img. ETA=0:07:43
[32m[04/20 13:11:46 d2.evaluation.evaluator]: [0mInference done 4526/8355. 0.1174 s / img. ETA=0:07:38
[32m[04/20 13:11:51 d2.evaluation.evaluator]: [0mInference done 4568/8355. 0.1174 s / img. ETA=0:07:33
[32m[04/20 13:11:56 d2.evaluation.evaluator]: [0mInference done 4610/8355. 0.1174 s / img. ETA=0:07:28
[32m[04/20 13:12:01 d2.evaluation.evaluator]: [0mInference done 4652/8355. 0.1174 s / img. ETA=0:07:23
[32m[04/20 13:12:06 d2.evaluation.evaluator]: [0mInference done 4694/8355. 0.1174 s / img. ETA=0:07:18
[32m[04/20 13:12:12 d2.evaluation.evaluator]: [0mInference done 4736/8355. 0.1174 s / img. ETA=0:07:13
[32m[04/20 13:12:17 d2.evaluation.evaluator]: [0mInference done 4778/8355. 0.1174 s / img. ETA=0:07:08
[32m[04/20 13:12:22 d2.evaluation.evaluator]: [0mInference done 4820/8355. 0.1174 s / img. ETA=0:07:03
[32m[04/20 13:12:27 d2.evaluation.evaluator]: [0mInference done 4862/8355. 0.1174 s / img. ETA=0:06:58
[32m[04/20 13:12:32 d2.evaluation.evaluator]: [0mInference done 4904/8355. 0.1174 s / img. ETA=0:06:53
[32m[04/20 13:12:37 d2.evaluation.evaluator]: [0mInference done 4946/8355. 0.1174 s / img. ETA=0:06:48
[32m[04/20 13:12:42 d2.evaluation.evaluator]: [0mInference done 4988/8355. 0.1174 s / img. ETA=0:06:43
[32m[04/20 13:12:47 d2.evaluation.evaluator]: [0mInference done 5030/8355. 0.1174 s / img. ETA=0:06:38
[32m[04/20 13:12:52 d2.evaluation.evaluator]: [0mInference done 5072/8355. 0.1174 s / img. ETA=0:06:33
[32m[04/20 13:12:57 d2.evaluation.evaluator]: [0mInference done 5114/8355. 0.1174 s / img. ETA=0:06:28
[32m[04/20 13:13:02 d2.evaluation.evaluator]: [0mInference done 5156/8355. 0.1174 s / img. ETA=0:06:23
[32m[04/20 13:13:07 d2.evaluation.evaluator]: [0mInference done 5198/8355. 0.1175 s / img. ETA=0:06:18
[32m[04/20 13:13:12 d2.evaluation.evaluator]: [0mInference done 5240/8355. 0.1175 s / img. ETA=0:06:13
[32m[04/20 13:13:17 d2.evaluation.evaluator]: [0mInference done 5282/8355. 0.1175 s / img. ETA=0:06:08
[32m[04/20 13:13:22 d2.evaluation.evaluator]: [0mInference done 5324/8355. 0.1175 s / img. ETA=0:06:03
[32m[04/20 13:13:27 d2.evaluation.evaluator]: [0mInference done 5366/8355. 0.1175 s / img. ETA=0:05:58
[32m[04/20 13:13:33 d2.evaluation.evaluator]: [0mInference done 5408/8355. 0.1175 s / img. ETA=0:05:53
[32m[04/20 13:13:38 d2.evaluation.evaluator]: [0mInference done 5450/8355. 0.1175 s / img. ETA=0:05:48
[32m[04/20 13:13:43 d2.evaluation.evaluator]: [0mInference done 5492/8355. 0.1175 s / img. ETA=0:05:43
[32m[04/20 13:13:48 d2.evaluation.evaluator]: [0mInference done 5534/8355. 0.1175 s / img. ETA=0:05:38
[32m[04/20 13:13:53 d2.evaluation.evaluator]: [0mInference done 5576/8355. 0.1175 s / img. ETA=0:05:33
[32m[04/20 13:13:58 d2.evaluation.evaluator]: [0mInference done 5618/8355. 0.1175 s / img. ETA=0:05:28
[32m[04/20 13:14:03 d2.evaluation.evaluator]: [0mInference done 5660/8355. 0.1175 s / img. ETA=0:05:23
[32m[04/20 13:14:08 d2.evaluation.evaluator]: [0mInference done 5702/8355. 0.1175 s / img. ETA=0:05:18
[32m[04/20 13:14:13 d2.evaluation.evaluator]: [0mInference done 5744/8355. 0.1175 s / img. ETA=0:05:13
[32m[04/20 13:14:18 d2.evaluation.evaluator]: [0mInference done 5786/8355. 0.1175 s / img. ETA=0:05:08
[32m[04/20 13:14:23 d2.evaluation.evaluator]: [0mInference done 5828/8355. 0.1175 s / img. ETA=0:05:03
[32m[04/20 13:14:28 d2.evaluation.evaluator]: [0mInference done 5870/8355. 0.1175 s / img. ETA=0:04:58
[32m[04/20 13:14:33 d2.evaluation.evaluator]: [0mInference done 5912/8355. 0.1175 s / img. ETA=0:04:53
[32m[04/20 13:14:38 d2.evaluation.evaluator]: [0mInference done 5954/8355. 0.1175 s / img. ETA=0:04:48
[32m[04/20 13:14:43 d2.evaluation.evaluator]: [0mInference done 5996/8355. 0.1175 s / img. ETA=0:04:43
[32m[04/20 13:14:48 d2.evaluation.evaluator]: [0mInference done 6038/8355. 0.1175 s / img. ETA=0:04:38
[32m[04/20 13:14:53 d2.evaluation.evaluator]: [0mInference done 6080/8355. 0.1175 s / img. ETA=0:04:32
[32m[04/20 13:14:59 d2.evaluation.evaluator]: [0mInference done 6122/8355. 0.1175 s / img. ETA=0:04:27
[32m[04/20 13:15:04 d2.evaluation.evaluator]: [0mInference done 6164/8355. 0.1175 s / img. ETA=0:04:22
[32m[04/20 13:15:09 d2.evaluation.evaluator]: [0mInference done 6206/8355. 0.1175 s / img. ETA=0:04:17
[32m[04/20 13:15:14 d2.evaluation.evaluator]: [0mInference done 6248/8355. 0.1175 s / img. ETA=0:04:12
[32m[04/20 13:15:19 d2.evaluation.evaluator]: [0mInference done 6290/8355. 0.1175 s / img. ETA=0:04:07
[32m[04/20 13:15:24 d2.evaluation.evaluator]: [0mInference done 6332/8355. 0.1175 s / img. ETA=0:04:02
[32m[04/20 13:15:29 d2.evaluation.evaluator]: [0mInference done 6374/8355. 0.1175 s / img. ETA=0:03:57
[32m[04/20 13:15:34 d2.evaluation.evaluator]: [0mInference done 6416/8355. 0.1175 s / img. ETA=0:03:52
[32m[04/20 13:15:39 d2.evaluation.evaluator]: [0mInference done 6458/8355. 0.1175 s / img. ETA=0:03:47
[32m[04/20 13:15:44 d2.evaluation.evaluator]: [0mInference done 6500/8355. 0.1175 s / img. ETA=0:03:42
[32m[04/20 13:15:49 d2.evaluation.evaluator]: [0mInference done 6542/8355. 0.1175 s / img. ETA=0:03:37
[32m[04/20 13:15:54 d2.evaluation.evaluator]: [0mInference done 6584/8355. 0.1175 s / img. ETA=0:03:32
[32m[04/20 13:15:59 d2.evaluation.evaluator]: [0mInference done 6626/8355. 0.1175 s / img. ETA=0:03:27
[32m[04/20 13:16:04 d2.evaluation.evaluator]: [0mInference done 6668/8355. 0.1175 s / img. ETA=0:03:22
[32m[04/20 13:16:09 d2.evaluation.evaluator]: [0mInference done 6710/8355. 0.1175 s / img. ETA=0:03:17
[32m[04/20 13:16:14 d2.evaluation.evaluator]: [0mInference done 6752/8355. 0.1175 s / img. ETA=0:03:12
[32m[04/20 13:16:19 d2.evaluation.evaluator]: [0mInference done 6794/8355. 0.1175 s / img. ETA=0:03:07
[32m[04/20 13:16:24 d2.evaluation.evaluator]: [0mInference done 6836/8355. 0.1175 s / img. ETA=0:03:02
[32m[04/20 13:16:29 d2.evaluation.evaluator]: [0mInference done 6878/8355. 0.1175 s / img. ETA=0:02:57
[32m[04/20 13:16:34 d2.evaluation.evaluator]: [0mInference done 6921/8355. 0.1175 s / img. ETA=0:02:52
[32m[04/20 13:16:39 d2.evaluation.evaluator]: [0mInference done 6963/8355. 0.1175 s / img. ETA=0:02:47
[32m[04/20 13:16:44 d2.evaluation.evaluator]: [0mInference done 7005/8355. 0.1175 s / img. ETA=0:02:41
[32m[04/20 13:16:49 d2.evaluation.evaluator]: [0mInference done 7046/8355. 0.1175 s / img. ETA=0:02:37
[32m[04/20 13:16:55 d2.evaluation.evaluator]: [0mInference done 7088/8355. 0.1175 s / img. ETA=0:02:32
[32m[04/20 13:17:00 d2.evaluation.evaluator]: [0mInference done 7130/8355. 0.1175 s / img. ETA=0:02:27
[32m[04/20 13:17:05 d2.evaluation.evaluator]: [0mInference done 7172/8355. 0.1175 s / img. ETA=0:02:21
[32m[04/20 13:17:10 d2.evaluation.evaluator]: [0mInference done 7214/8355. 0.1175 s / img. ETA=0:02:16
[32m[04/20 13:17:15 d2.evaluation.evaluator]: [0mInference done 7255/8355. 0.1176 s / img. ETA=0:02:12
[32m[04/20 13:17:20 d2.evaluation.evaluator]: [0mInference done 7297/8355. 0.1176 s / img. ETA=0:02:07
[32m[04/20 13:17:25 d2.evaluation.evaluator]: [0mInference done 7339/8355. 0.1176 s / img. ETA=0:02:01
[32m[04/20 13:17:30 d2.evaluation.evaluator]: [0mInference done 7380/8355. 0.1176 s / img. ETA=0:01:57
[32m[04/20 13:17:35 d2.evaluation.evaluator]: [0mInference done 7421/8355. 0.1176 s / img. ETA=0:01:52
[32m[04/20 13:17:40 d2.evaluation.evaluator]: [0mInference done 7463/8355. 0.1176 s / img. ETA=0:01:47
[32m[04/20 13:17:45 d2.evaluation.evaluator]: [0mInference done 7505/8355. 0.1176 s / img. ETA=0:01:42
[32m[04/20 13:17:50 d2.evaluation.evaluator]: [0mInference done 7547/8355. 0.1176 s / img. ETA=0:01:37
[32m[04/20 13:17:55 d2.evaluation.evaluator]: [0mInference done 7589/8355. 0.1176 s / img. ETA=0:01:32
[32m[04/20 13:18:00 d2.evaluation.evaluator]: [0mInference done 7631/8355. 0.1176 s / img. ETA=0:01:26
[32m[04/20 13:18:05 d2.evaluation.evaluator]: [0mInference done 7673/8355. 0.1176 s / img. ETA=0:01:21
[32m[04/20 13:18:11 d2.evaluation.evaluator]: [0mInference done 7715/8355. 0.1176 s / img. ETA=0:01:16
[32m[04/20 13:18:16 d2.evaluation.evaluator]: [0mInference done 7757/8355. 0.1176 s / img. ETA=0:01:11
[32m[04/20 13:18:21 d2.evaluation.evaluator]: [0mInference done 7798/8355. 0.1176 s / img. ETA=0:01:06
[32m[04/20 13:18:26 d2.evaluation.evaluator]: [0mInference done 7840/8355. 0.1176 s / img. ETA=0:01:01
[32m[04/20 13:18:31 d2.evaluation.evaluator]: [0mInference done 7882/8355. 0.1176 s / img. ETA=0:00:56
[32m[04/20 13:18:36 d2.evaluation.evaluator]: [0mInference done 7924/8355. 0.1176 s / img. ETA=0:00:51
[32m[04/20 13:18:41 d2.evaluation.evaluator]: [0mInference done 7966/8355. 0.1176 s / img. ETA=0:00:46
[32m[04/20 13:18:46 d2.evaluation.evaluator]: [0mInference done 8008/8355. 0.1176 s / img. ETA=0:00:41
[32m[04/20 13:18:51 d2.evaluation.evaluator]: [0mInference done 8050/8355. 0.1176 s / img. ETA=0:00:36
[32m[04/20 13:18:56 d2.evaluation.evaluator]: [0mInference done 8092/8355. 0.1176 s / img. ETA=0:00:31
[32m[04/20 13:19:01 d2.evaluation.evaluator]: [0mInference done 8134/8355. 0.1176 s / img. ETA=0:00:26
[32m[04/20 13:19:06 d2.evaluation.evaluator]: [0mInference done 8176/8355. 0.1176 s / img. ETA=0:00:21
[32m[04/20 13:19:11 d2.evaluation.evaluator]: [0mInference done 8218/8355. 0.1176 s / img. ETA=0:00:16
[32m[04/20 13:19:16 d2.evaluation.evaluator]: [0mInference done 8260/8355. 0.1176 s / img. ETA=0:00:11
[32m[04/20 13:19:21 d2.evaluation.evaluator]: [0mInference done 8302/8355. 0.1176 s / img. ETA=0:00:06
[32m[04/20 13:19:26 d2.evaluation.evaluator]: [0mInference done 8344/8355. 0.1176 s / img. ETA=0:00:01
[32m[04/20 13:19:28 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:43.188365 (0.120142 s / img per device, on 1 devices)
[32m[04/20 13:19:28 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:22 (0.117629 s / img per device, on 1 devices)
[32m[04/20 13:19:28 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 13:19:28 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 13:19:28 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.18s).
Accumulating evaluation results...
DONE (t=2.98s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.694
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.333
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.259
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.490
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.148
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.417
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.339
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.548
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.713
[32m[04/20 13:19:52 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 36.527 | 69.444 | 33.319 | 25.918 | 48.965 | 65.154 |
[32m[04/20 13:19:52 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 39.154 | bicycle       | 24.209 | car            | 46.217 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 13:19:53 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 13:19:53 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 13:19:53 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 13:19:55 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1181 s / img. ETA=0:02:30
[32m[04/20 13:20:00 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1187 s / img. ETA=0:02:26
[32m[04/20 13:20:05 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1184 s / img. ETA=0:02:20
[32m[04/20 13:20:10 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1184 s / img. ETA=0:02:15
[32m[04/20 13:20:15 d2.evaluation.evaluator]: [0mInference done 179/1257. 0.1183 s / img. ETA=0:02:10
[32m[04/20 13:20:20 d2.evaluation.evaluator]: [0mInference done 221/1257. 0.1181 s / img. ETA=0:02:05
[32m[04/20 13:20:25 d2.evaluation.evaluator]: [0mInference done 263/1257. 0.1180 s / img. ETA=0:02:00
[32m[04/20 13:20:30 d2.evaluation.evaluator]: [0mInference done 305/1257. 0.1180 s / img. ETA=0:01:54
[32m[04/20 13:20:35 d2.evaluation.evaluator]: [0mInference done 347/1257. 0.1179 s / img. ETA=0:01:49
[32m[04/20 13:20:40 d2.evaluation.evaluator]: [0mInference done 389/1257. 0.1180 s / img. ETA=0:01:44
[32m[04/20 13:20:45 d2.evaluation.evaluator]: [0mInference done 431/1257. 0.1181 s / img. ETA=0:01:39
[32m[04/20 13:20:51 d2.evaluation.evaluator]: [0mInference done 473/1257. 0.1181 s / img. ETA=0:01:34
[32m[04/20 13:20:56 d2.evaluation.evaluator]: [0mInference done 514/1257. 0.1181 s / img. ETA=0:01:29
[32m[04/20 13:21:01 d2.evaluation.evaluator]: [0mInference done 555/1257. 0.1182 s / img. ETA=0:01:24
[32m[04/20 13:21:06 d2.evaluation.evaluator]: [0mInference done 597/1257. 0.1183 s / img. ETA=0:01:19
[32m[04/20 13:21:11 d2.evaluation.evaluator]: [0mInference done 638/1257. 0.1183 s / img. ETA=0:01:14
[32m[04/20 13:21:16 d2.evaluation.evaluator]: [0mInference done 679/1257. 0.1184 s / img. ETA=0:01:10
[32m[04/20 13:21:21 d2.evaluation.evaluator]: [0mInference done 721/1257. 0.1184 s / img. ETA=0:01:04
[32m[04/20 13:21:26 d2.evaluation.evaluator]: [0mInference done 763/1257. 0.1184 s / img. ETA=0:00:59
[32m[04/20 13:21:31 d2.evaluation.evaluator]: [0mInference done 805/1257. 0.1184 s / img. ETA=0:00:54
[32m[04/20 13:21:36 d2.evaluation.evaluator]: [0mInference done 847/1257. 0.1184 s / img. ETA=0:00:49
[32m[04/20 13:21:41 d2.evaluation.evaluator]: [0mInference done 889/1257. 0.1184 s / img. ETA=0:00:44
[32m[04/20 13:21:46 d2.evaluation.evaluator]: [0mInference done 931/1257. 0.1184 s / img. ETA=0:00:39
[32m[04/20 13:21:51 d2.evaluation.evaluator]: [0mInference done 973/1257. 0.1184 s / img. ETA=0:00:34
[32m[04/20 13:21:56 d2.evaluation.evaluator]: [0mInference done 1015/1257. 0.1184 s / img. ETA=0:00:29
[32m[04/20 13:22:01 d2.evaluation.evaluator]: [0mInference done 1057/1257. 0.1184 s / img. ETA=0:00:24
[32m[04/20 13:22:07 d2.evaluation.evaluator]: [0mInference done 1099/1257. 0.1184 s / img. ETA=0:00:19
[32m[04/20 13:22:12 d2.evaluation.evaluator]: [0mInference done 1141/1257. 0.1184 s / img. ETA=0:00:14
[32m[04/20 13:22:17 d2.evaluation.evaluator]: [0mInference done 1183/1257. 0.1184 s / img. ETA=0:00:08
[32m[04/20 13:22:22 d2.evaluation.evaluator]: [0mInference done 1225/1257. 0.1184 s / img. ETA=0:00:03
[32m[04/20 13:22:26 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:31.730820 (0.121191 s / img per device, on 1 devices)
[32m[04/20 13:22:26 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:28 (0.118354 s / img per device, on 1 devices)
[32m[04/20 13:22:26 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 13:22:26 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 13:22:26 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.63s).
Accumulating evaluation results...
DONE (t=0.37s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.277
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.540
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.250
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.340
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.453
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.140
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.335
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.339
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.246
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.394
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.514
[32m[04/20 13:22:29 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 27.703 | 54.033 | 25.044 | 17.319 | 34.010 | 45.297 |
[32m[04/20 13:22:29 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 29.465 | bicycle       | 9.728 | car            | 43.916 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | nan   | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  13  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 13:22:30 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 13:22:30 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 13:22:30 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 13:22:30 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 13:22:31 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 13:22:31 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 13:22:31 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 13:22:52 d2.utils.events]: [0m eta: 0:17:10  iter: 19  total_loss: 0.703  loss_cls: 0.244  loss_box_reg: 0.375  loss_rpn_cls: 0.020  loss_rpn_loc: 0.064  time: 1.0348  data_time: 0.0392  lr: 0.000100  max_mem: 5405M
[32m[04/20 13:23:12 d2.utils.events]: [0m eta: 0:16:25  iter: 39  total_loss: 0.571  loss_cls: 0.191  loss_box_reg: 0.318  loss_rpn_cls: 0.017  loss_rpn_loc: 0.058  time: 1.0227  data_time: 0.0109  lr: 0.000200  max_mem: 5405M
[32m[04/20 13:23:32 d2.utils.events]: [0m eta: 0:16:02  iter: 59  total_loss: 0.638  loss_cls: 0.212  loss_box_reg: 0.348  loss_rpn_cls: 0.018  loss_rpn_loc: 0.061  time: 1.0192  data_time: 0.0117  lr: 0.000300  max_mem: 5405M
[32m[04/20 13:23:53 d2.utils.events]: [0m eta: 0:15:43  iter: 79  total_loss: 0.581  loss_cls: 0.169  loss_box_reg: 0.316  loss_rpn_cls: 0.016  loss_rpn_loc: 0.048  time: 1.0221  data_time: 0.0110  lr: 0.000400  max_mem: 5405M
[32m[04/20 13:24:13 d2.utils.events]: [0m eta: 0:15:20  iter: 99  total_loss: 0.509  loss_cls: 0.168  loss_box_reg: 0.284  loss_rpn_cls: 0.012  loss_rpn_loc: 0.053  time: 1.0172  data_time: 0.0110  lr: 0.000500  max_mem: 5405M
[32m[04/20 13:24:34 d2.utils.events]: [0m eta: 0:15:02  iter: 119  total_loss: 0.623  loss_cls: 0.195  loss_box_reg: 0.338  loss_rpn_cls: 0.014  loss_rpn_loc: 0.053  time: 1.0215  data_time: 0.0127  lr: 0.000599  max_mem: 5405M
[32m[04/20 13:24:55 d2.utils.events]: [0m eta: 0:14:43  iter: 139  total_loss: 0.707  loss_cls: 0.241  loss_box_reg: 0.384  loss_rpn_cls: 0.017  loss_rpn_loc: 0.058  time: 1.0229  data_time: 0.0113  lr: 0.000699  max_mem: 5405M
[32m[04/20 13:25:15 d2.utils.events]: [0m eta: 0:14:28  iter: 159  total_loss: 0.632  loss_cls: 0.207  loss_box_reg: 0.340  loss_rpn_cls: 0.016  loss_rpn_loc: 0.055  time: 1.0234  data_time: 0.0112  lr: 0.000799  max_mem: 5405M
[32m[04/20 13:25:36 d2.utils.events]: [0m eta: 0:14:04  iter: 179  total_loss: 0.591  loss_cls: 0.187  loss_box_reg: 0.321  loss_rpn_cls: 0.015  loss_rpn_loc: 0.047  time: 1.0236  data_time: 0.0106  lr: 0.000899  max_mem: 5405M
[32m[04/20 13:25:56 d2.utils.events]: [0m eta: 0:13:42  iter: 199  total_loss: 0.642  loss_cls: 0.199  loss_box_reg: 0.342  loss_rpn_cls: 0.014  loss_rpn_loc: 0.066  time: 1.0216  data_time: 0.0114  lr: 0.000999  max_mem: 5405M
[32m[04/20 13:26:16 d2.utils.events]: [0m eta: 0:13:20  iter: 219  total_loss: 0.555  loss_cls: 0.183  loss_box_reg: 0.295  loss_rpn_cls: 0.017  loss_rpn_loc: 0.042  time: 1.0202  data_time: 0.0108  lr: 0.001099  max_mem: 5405M
[32m[04/20 13:26:36 d2.utils.events]: [0m eta: 0:12:58  iter: 239  total_loss: 0.654  loss_cls: 0.228  loss_box_reg: 0.357  loss_rpn_cls: 0.016  loss_rpn_loc: 0.063  time: 1.0192  data_time: 0.0113  lr: 0.001199  max_mem: 5405M
[32m[04/20 13:26:57 d2.utils.events]: [0m eta: 0:12:37  iter: 259  total_loss: 0.624  loss_cls: 0.199  loss_box_reg: 0.355  loss_rpn_cls: 0.018  loss_rpn_loc: 0.059  time: 1.0189  data_time: 0.0109  lr: 0.001299  max_mem: 5405M
[32m[04/20 13:27:18 d2.utils.events]: [0m eta: 0:12:17  iter: 279  total_loss: 0.598  loss_cls: 0.210  loss_box_reg: 0.336  loss_rpn_cls: 0.015  loss_rpn_loc: 0.055  time: 1.0202  data_time: 0.0110  lr: 0.001399  max_mem: 5405M
[32m[04/20 13:27:38 d2.utils.events]: [0m eta: 0:11:58  iter: 299  total_loss: 0.567  loss_cls: 0.187  loss_box_reg: 0.303  loss_rpn_cls: 0.016  loss_rpn_loc: 0.053  time: 1.0216  data_time: 0.0122  lr: 0.001499  max_mem: 5405M
[32m[04/20 13:27:59 d2.utils.events]: [0m eta: 0:11:39  iter: 319  total_loss: 0.605  loss_cls: 0.202  loss_box_reg: 0.335  loss_rpn_cls: 0.014  loss_rpn_loc: 0.049  time: 1.0230  data_time: 0.0114  lr: 0.001598  max_mem: 5405M
[32m[04/20 13:28:20 d2.utils.events]: [0m eta: 0:11:19  iter: 339  total_loss: 0.597  loss_cls: 0.198  loss_box_reg: 0.339  loss_rpn_cls: 0.017  loss_rpn_loc: 0.044  time: 1.0242  data_time: 0.0114  lr: 0.001698  max_mem: 5405M
[32m[04/20 13:28:41 d2.utils.events]: [0m eta: 0:10:59  iter: 359  total_loss: 0.627  loss_cls: 0.183  loss_box_reg: 0.336  loss_rpn_cls: 0.014  loss_rpn_loc: 0.057  time: 1.0257  data_time: 0.0123  lr: 0.001798  max_mem: 5405M
[32m[04/20 13:29:02 d2.utils.events]: [0m eta: 0:10:37  iter: 379  total_loss: 0.614  loss_cls: 0.211  loss_box_reg: 0.351  loss_rpn_cls: 0.015  loss_rpn_loc: 0.054  time: 1.0251  data_time: 0.0126  lr: 0.001898  max_mem: 5405M
[32m[04/20 13:29:22 d2.utils.events]: [0m eta: 0:10:17  iter: 399  total_loss: 0.582  loss_cls: 0.186  loss_box_reg: 0.337  loss_rpn_cls: 0.013  loss_rpn_loc: 0.043  time: 1.0249  data_time: 0.0108  lr: 0.001998  max_mem: 5405M
[32m[04/20 13:29:43 d2.utils.events]: [0m eta: 0:09:57  iter: 419  total_loss: 0.621  loss_cls: 0.212  loss_box_reg: 0.334  loss_rpn_cls: 0.014  loss_rpn_loc: 0.048  time: 1.0259  data_time: 0.0110  lr: 0.002098  max_mem: 5405M
[32m[04/20 13:30:04 d2.utils.events]: [0m eta: 0:09:38  iter: 439  total_loss: 0.623  loss_cls: 0.196  loss_box_reg: 0.347  loss_rpn_cls: 0.016  loss_rpn_loc: 0.057  time: 1.0265  data_time: 0.0110  lr: 0.002198  max_mem: 5405M
[32m[04/20 13:30:25 d2.utils.events]: [0m eta: 0:09:20  iter: 459  total_loss: 0.585  loss_cls: 0.198  loss_box_reg: 0.314  loss_rpn_cls: 0.017  loss_rpn_loc: 0.059  time: 1.0280  data_time: 0.0118  lr: 0.002298  max_mem: 5405M
[32m[04/20 13:30:46 d2.utils.events]: [0m eta: 0:08:58  iter: 479  total_loss: 0.658  loss_cls: 0.214  loss_box_reg: 0.365  loss_rpn_cls: 0.016  loss_rpn_loc: 0.056  time: 1.0274  data_time: 0.0113  lr: 0.002398  max_mem: 5405M
[32m[04/20 13:31:06 d2.utils.events]: [0m eta: 0:08:38  iter: 499  total_loss: 0.615  loss_cls: 0.186  loss_box_reg: 0.344  loss_rpn_cls: 0.013  loss_rpn_loc: 0.045  time: 1.0272  data_time: 0.0111  lr: 0.002498  max_mem: 5405M
[32m[04/20 13:31:27 d2.utils.events]: [0m eta: 0:08:17  iter: 519  total_loss: 0.529  loss_cls: 0.169  loss_box_reg: 0.310  loss_rpn_cls: 0.013  loss_rpn_loc: 0.042  time: 1.0277  data_time: 0.0111  lr: 0.002597  max_mem: 5405M
[32m[04/20 13:31:47 d2.utils.events]: [0m eta: 0:07:55  iter: 539  total_loss: 0.579  loss_cls: 0.185  loss_box_reg: 0.316  loss_rpn_cls: 0.015  loss_rpn_loc: 0.048  time: 1.0265  data_time: 0.0108  lr: 0.002697  max_mem: 5405M
[32m[04/20 13:32:08 d2.utils.events]: [0m eta: 0:07:35  iter: 559  total_loss: 0.595  loss_cls: 0.182  loss_box_reg: 0.332  loss_rpn_cls: 0.015  loss_rpn_loc: 0.053  time: 1.0268  data_time: 0.0106  lr: 0.002797  max_mem: 5405M
[32m[04/20 13:32:28 d2.utils.events]: [0m eta: 0:07:15  iter: 579  total_loss: 0.517  loss_cls: 0.179  loss_box_reg: 0.279  loss_rpn_cls: 0.013  loss_rpn_loc: 0.047  time: 1.0272  data_time: 0.0111  lr: 0.002897  max_mem: 5405M
[32m[04/20 13:32:50 d2.utils.events]: [0m eta: 0:06:55  iter: 599  total_loss: 0.622  loss_cls: 0.197  loss_box_reg: 0.347  loss_rpn_cls: 0.011  loss_rpn_loc: 0.060  time: 1.0282  data_time: 0.0115  lr: 0.002997  max_mem: 5405M
[32m[04/20 13:33:10 d2.utils.events]: [0m eta: 0:06:34  iter: 619  total_loss: 0.568  loss_cls: 0.194  loss_box_reg: 0.315  loss_rpn_cls: 0.014  loss_rpn_loc: 0.053  time: 1.0284  data_time: 0.0124  lr: 0.003097  max_mem: 5405M
[32m[04/20 13:33:31 d2.utils.events]: [0m eta: 0:06:13  iter: 639  total_loss: 0.516  loss_cls: 0.161  loss_box_reg: 0.270  loss_rpn_cls: 0.012  loss_rpn_loc: 0.045  time: 1.0282  data_time: 0.0110  lr: 0.003197  max_mem: 5405M
[32m[04/20 13:33:51 d2.utils.events]: [0m eta: 0:05:52  iter: 659  total_loss: 0.576  loss_cls: 0.180  loss_box_reg: 0.336  loss_rpn_cls: 0.017  loss_rpn_loc: 0.056  time: 1.0282  data_time: 0.0113  lr: 0.003297  max_mem: 5405M
[32m[04/20 13:34:12 d2.utils.events]: [0m eta: 0:05:32  iter: 679  total_loss: 0.498  loss_cls: 0.163  loss_box_reg: 0.277  loss_rpn_cls: 0.015  loss_rpn_loc: 0.043  time: 1.0285  data_time: 0.0118  lr: 0.003397  max_mem: 5405M
[32m[04/20 13:34:33 d2.utils.events]: [0m eta: 0:05:11  iter: 699  total_loss: 0.666  loss_cls: 0.224  loss_box_reg: 0.365  loss_rpn_cls: 0.018  loss_rpn_loc: 0.056  time: 1.0285  data_time: 0.0109  lr: 0.003497  max_mem: 5405M
[32m[04/20 13:34:54 d2.utils.events]: [0m eta: 0:04:50  iter: 719  total_loss: 0.545  loss_cls: 0.186  loss_box_reg: 0.303  loss_rpn_cls: 0.016  loss_rpn_loc: 0.047  time: 1.0290  data_time: 0.0111  lr: 0.003596  max_mem: 5405M
[32m[04/20 13:35:14 d2.utils.events]: [0m eta: 0:04:30  iter: 739  total_loss: 0.624  loss_cls: 0.205  loss_box_reg: 0.346  loss_rpn_cls: 0.016  loss_rpn_loc: 0.050  time: 1.0284  data_time: 0.0106  lr: 0.003696  max_mem: 5405M
[32m[04/20 13:35:35 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.660  loss_cls: 0.214  loss_box_reg: 0.362  loss_rpn_cls: 0.016  loss_rpn_loc: 0.063  time: 1.0283  data_time: 0.0113  lr: 0.003796  max_mem: 5405M
[32m[04/20 13:35:55 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.646  loss_cls: 0.208  loss_box_reg: 0.331  loss_rpn_cls: 0.016  loss_rpn_loc: 0.066  time: 1.0285  data_time: 0.0125  lr: 0.003896  max_mem: 5405M
[32m[04/20 13:36:16 d2.utils.events]: [0m eta: 0:03:27  iter: 799  total_loss: 0.682  loss_cls: 0.208  loss_box_reg: 0.354  loss_rpn_cls: 0.018  loss_rpn_loc: 0.045  time: 1.0285  data_time: 0.0110  lr: 0.003996  max_mem: 5405M
[32m[04/20 13:36:37 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.550  loss_cls: 0.185  loss_box_reg: 0.304  loss_rpn_cls: 0.014  loss_rpn_loc: 0.036  time: 1.0284  data_time: 0.0121  lr: 0.004096  max_mem: 5405M
[32m[04/20 13:36:57 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.621  loss_cls: 0.205  loss_box_reg: 0.340  loss_rpn_cls: 0.015  loss_rpn_loc: 0.054  time: 1.0284  data_time: 0.0107  lr: 0.004196  max_mem: 5405M
[32m[04/20 13:37:18 d2.utils.events]: [0m eta: 0:02:26  iter: 859  total_loss: 0.643  loss_cls: 0.209  loss_box_reg: 0.356  loss_rpn_cls: 0.021  loss_rpn_loc: 0.051  time: 1.0285  data_time: 0.0104  lr: 0.004296  max_mem: 5405M
[32m[04/20 13:37:38 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.588  loss_cls: 0.192  loss_box_reg: 0.320  loss_rpn_cls: 0.013  loss_rpn_loc: 0.042  time: 1.0284  data_time: 0.0121  lr: 0.004396  max_mem: 5405M
[32m[04/20 13:37:58 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.691  loss_cls: 0.227  loss_box_reg: 0.402  loss_rpn_cls: 0.018  loss_rpn_loc: 0.055  time: 1.0274  data_time: 0.0113  lr: 0.004496  max_mem: 5405M
[32m[04/20 13:38:19 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.584  loss_cls: 0.193  loss_box_reg: 0.325  loss_rpn_cls: 0.011  loss_rpn_loc: 0.049  time: 1.0275  data_time: 0.0115  lr: 0.004595  max_mem: 5405M
[32m[04/20 13:38:39 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.634  loss_cls: 0.204  loss_box_reg: 0.343  loss_rpn_cls: 0.021  loss_rpn_loc: 0.060  time: 1.0274  data_time: 0.0109  lr: 0.004695  max_mem: 5405M
[32m[04/20 13:39:00 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.699  loss_cls: 0.233  loss_box_reg: 0.370  loss_rpn_cls: 0.020  loss_rpn_loc: 0.049  time: 1.0278  data_time: 0.0110  lr: 0.004795  max_mem: 5405M
[32m[04/20 13:39:21 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.630  loss_cls: 0.208  loss_box_reg: 0.348  loss_rpn_cls: 0.016  loss_rpn_loc: 0.053  time: 1.0282  data_time: 0.0129  lr: 0.004895  max_mem: 5405M
[5m[31mWARNING[0m [32m[04/20 13:39:46 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 13:39:46 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 13:39:46 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 13:39:46 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.605  loss_cls: 0.190  loss_box_reg: 0.333  loss_rpn_cls: 0.020  loss_rpn_loc: 0.049  time: 1.0289  data_time: 0.0118  lr: 0.004995  max_mem: 5405M
[32m[04/20 13:39:47 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:06 (1.0300 s / it)
[32m[04/20 13:39:47 d2.engine.hooks]: [0mTotal training time: 0:17:13 (0:00:06 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 13:39:50 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 13:39:50 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 13:39:50 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 13:39:52 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1183 s / img. ETA=0:16:44
[32m[04/20 13:39:57 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1180 s / img. ETA=0:16:38
[32m[04/20 13:40:02 d2.evaluation.evaluator]: [0mInference done 95/8355. 0.1176 s / img. ETA=0:16:29
[32m[04/20 13:40:07 d2.evaluation.evaluator]: [0mInference done 137/8355. 0.1176 s / img. ETA=0:16:26
[32m[04/20 13:40:12 d2.evaluation.evaluator]: [0mInference done 179/8355. 0.1174 s / img. ETA=0:16:20
[32m[04/20 13:40:17 d2.evaluation.evaluator]: [0mInference done 221/8355. 0.1175 s / img. ETA=0:16:16
[32m[04/20 13:40:22 d2.evaluation.evaluator]: [0mInference done 263/8355. 0.1175 s / img. ETA=0:16:11
[32m[04/20 13:40:27 d2.evaluation.evaluator]: [0mInference done 305/8355. 0.1175 s / img. ETA=0:16:05
[32m[04/20 13:40:32 d2.evaluation.evaluator]: [0mInference done 347/8355. 0.1175 s / img. ETA=0:16:01
[32m[04/20 13:40:37 d2.evaluation.evaluator]: [0mInference done 389/8355. 0.1176 s / img. ETA=0:15:56
[32m[04/20 13:40:42 d2.evaluation.evaluator]: [0mInference done 431/8355. 0.1175 s / img. ETA=0:15:51
[32m[04/20 13:40:47 d2.evaluation.evaluator]: [0mInference done 473/8355. 0.1175 s / img. ETA=0:15:46
[32m[04/20 13:40:52 d2.evaluation.evaluator]: [0mInference done 515/8355. 0.1176 s / img. ETA=0:15:41
[32m[04/20 13:40:57 d2.evaluation.evaluator]: [0mInference done 557/8355. 0.1175 s / img. ETA=0:15:36
[32m[04/20 13:41:02 d2.evaluation.evaluator]: [0mInference done 599/8355. 0.1175 s / img. ETA=0:15:31
[32m[04/20 13:41:08 d2.evaluation.evaluator]: [0mInference done 642/8355. 0.1175 s / img. ETA=0:15:25
[32m[04/20 13:41:13 d2.evaluation.evaluator]: [0mInference done 684/8355. 0.1175 s / img. ETA=0:15:21
[32m[04/20 13:41:18 d2.evaluation.evaluator]: [0mInference done 726/8355. 0.1175 s / img. ETA=0:15:16
[32m[04/20 13:41:23 d2.evaluation.evaluator]: [0mInference done 768/8355. 0.1175 s / img. ETA=0:15:11
[32m[04/20 13:41:28 d2.evaluation.evaluator]: [0mInference done 810/8355. 0.1175 s / img. ETA=0:15:06
[32m[04/20 13:41:33 d2.evaluation.evaluator]: [0mInference done 852/8355. 0.1175 s / img. ETA=0:15:01
[32m[04/20 13:41:38 d2.evaluation.evaluator]: [0mInference done 894/8355. 0.1175 s / img. ETA=0:14:56
[32m[04/20 13:41:43 d2.evaluation.evaluator]: [0mInference done 936/8355. 0.1176 s / img. ETA=0:14:51
[32m[04/20 13:41:48 d2.evaluation.evaluator]: [0mInference done 978/8355. 0.1176 s / img. ETA=0:14:46
[32m[04/20 13:41:53 d2.evaluation.evaluator]: [0mInference done 1020/8355. 0.1175 s / img. ETA=0:14:41
[32m[04/20 13:41:58 d2.evaluation.evaluator]: [0mInference done 1062/8355. 0.1176 s / img. ETA=0:14:36
[32m[04/20 13:42:03 d2.evaluation.evaluator]: [0mInference done 1104/8355. 0.1176 s / img. ETA=0:14:31
[32m[04/20 13:42:08 d2.evaluation.evaluator]: [0mInference done 1146/8355. 0.1176 s / img. ETA=0:14:26
[32m[04/20 13:42:13 d2.evaluation.evaluator]: [0mInference done 1188/8355. 0.1175 s / img. ETA=0:14:21
[32m[04/20 13:42:18 d2.evaluation.evaluator]: [0mInference done 1230/8355. 0.1175 s / img. ETA=0:14:15
[32m[04/20 13:42:23 d2.evaluation.evaluator]: [0mInference done 1272/8355. 0.1175 s / img. ETA=0:14:10
[32m[04/20 13:42:28 d2.evaluation.evaluator]: [0mInference done 1314/8355. 0.1175 s / img. ETA=0:14:05
[32m[04/20 13:42:33 d2.evaluation.evaluator]: [0mInference done 1356/8355. 0.1175 s / img. ETA=0:14:00
[32m[04/20 13:42:38 d2.evaluation.evaluator]: [0mInference done 1399/8355. 0.1175 s / img. ETA=0:13:55
[32m[04/20 13:42:44 d2.evaluation.evaluator]: [0mInference done 1442/8355. 0.1174 s / img. ETA=0:13:49
[32m[04/20 13:42:49 d2.evaluation.evaluator]: [0mInference done 1484/8355. 0.1175 s / img. ETA=0:13:44
[32m[04/20 13:42:54 d2.evaluation.evaluator]: [0mInference done 1526/8355. 0.1175 s / img. ETA=0:13:40
[32m[04/20 13:42:59 d2.evaluation.evaluator]: [0mInference done 1568/8355. 0.1175 s / img. ETA=0:13:35
[32m[04/20 13:43:04 d2.evaluation.evaluator]: [0mInference done 1610/8355. 0.1176 s / img. ETA=0:13:30
[32m[04/20 13:43:09 d2.evaluation.evaluator]: [0mInference done 1651/8355. 0.1176 s / img. ETA=0:13:25
[32m[04/20 13:43:14 d2.evaluation.evaluator]: [0mInference done 1693/8355. 0.1176 s / img. ETA=0:13:20
[32m[04/20 13:43:19 d2.evaluation.evaluator]: [0mInference done 1735/8355. 0.1176 s / img. ETA=0:13:16
[32m[04/20 13:43:24 d2.evaluation.evaluator]: [0mInference done 1777/8355. 0.1177 s / img. ETA=0:13:11
[32m[04/20 13:43:29 d2.evaluation.evaluator]: [0mInference done 1819/8355. 0.1177 s / img. ETA=0:13:06
[32m[04/20 13:43:34 d2.evaluation.evaluator]: [0mInference done 1860/8355. 0.1177 s / img. ETA=0:13:01
[32m[04/20 13:43:39 d2.evaluation.evaluator]: [0mInference done 1902/8355. 0.1177 s / img. ETA=0:12:56
[32m[04/20 13:43:44 d2.evaluation.evaluator]: [0mInference done 1944/8355. 0.1177 s / img. ETA=0:12:51
[32m[04/20 13:43:50 d2.evaluation.evaluator]: [0mInference done 1986/8355. 0.1178 s / img. ETA=0:12:46
[32m[04/20 13:43:55 d2.evaluation.evaluator]: [0mInference done 2028/8355. 0.1178 s / img. ETA=0:12:41
[32m[04/20 13:44:00 d2.evaluation.evaluator]: [0mInference done 2070/8355. 0.1178 s / img. ETA=0:12:36
[32m[04/20 13:44:05 d2.evaluation.evaluator]: [0mInference done 2112/8355. 0.1178 s / img. ETA=0:12:31
[32m[04/20 13:44:10 d2.evaluation.evaluator]: [0mInference done 2154/8355. 0.1178 s / img. ETA=0:12:26
[32m[04/20 13:44:15 d2.evaluation.evaluator]: [0mInference done 2196/8355. 0.1178 s / img. ETA=0:12:21
[32m[04/20 13:44:20 d2.evaluation.evaluator]: [0mInference done 2238/8355. 0.1178 s / img. ETA=0:12:16
[32m[04/20 13:44:25 d2.evaluation.evaluator]: [0mInference done 2280/8355. 0.1178 s / img. ETA=0:12:11
[32m[04/20 13:44:30 d2.evaluation.evaluator]: [0mInference done 2322/8355. 0.1178 s / img. ETA=0:12:06
[32m[04/20 13:44:35 d2.evaluation.evaluator]: [0mInference done 2364/8355. 0.1178 s / img. ETA=0:12:01
[32m[04/20 13:44:40 d2.evaluation.evaluator]: [0mInference done 2406/8355. 0.1178 s / img. ETA=0:11:56
[32m[04/20 13:44:45 d2.evaluation.evaluator]: [0mInference done 2448/8355. 0.1178 s / img. ETA=0:11:51
[32m[04/20 13:44:50 d2.evaluation.evaluator]: [0mInference done 2490/8355. 0.1178 s / img. ETA=0:11:46
[32m[04/20 13:44:55 d2.evaluation.evaluator]: [0mInference done 2532/8355. 0.1178 s / img. ETA=0:11:41
[32m[04/20 13:45:00 d2.evaluation.evaluator]: [0mInference done 2574/8355. 0.1178 s / img. ETA=0:11:36
[32m[04/20 13:45:06 d2.evaluation.evaluator]: [0mInference done 2616/8355. 0.1178 s / img. ETA=0:11:31
[32m[04/20 13:45:11 d2.evaluation.evaluator]: [0mInference done 2658/8355. 0.1178 s / img. ETA=0:11:26
[32m[04/20 13:45:16 d2.evaluation.evaluator]: [0mInference done 2700/8355. 0.1178 s / img. ETA=0:11:21
[32m[04/20 13:45:21 d2.evaluation.evaluator]: [0mInference done 2742/8355. 0.1178 s / img. ETA=0:11:16
[32m[04/20 13:45:26 d2.evaluation.evaluator]: [0mInference done 2784/8355. 0.1178 s / img. ETA=0:11:11
[32m[04/20 13:45:31 d2.evaluation.evaluator]: [0mInference done 2826/8355. 0.1178 s / img. ETA=0:11:06
[32m[04/20 13:45:36 d2.evaluation.evaluator]: [0mInference done 2868/8355. 0.1178 s / img. ETA=0:11:01
[32m[04/20 13:45:41 d2.evaluation.evaluator]: [0mInference done 2910/8355. 0.1179 s / img. ETA=0:10:56
[32m[04/20 13:45:46 d2.evaluation.evaluator]: [0mInference done 2952/8355. 0.1179 s / img. ETA=0:10:51
[32m[04/20 13:45:51 d2.evaluation.evaluator]: [0mInference done 2994/8355. 0.1179 s / img. ETA=0:10:46
[32m[04/20 13:45:56 d2.evaluation.evaluator]: [0mInference done 3036/8355. 0.1179 s / img. ETA=0:10:40
[32m[04/20 13:46:01 d2.evaluation.evaluator]: [0mInference done 3078/8355. 0.1179 s / img. ETA=0:10:35
[32m[04/20 13:46:06 d2.evaluation.evaluator]: [0mInference done 3120/8355. 0.1179 s / img. ETA=0:10:30
[32m[04/20 13:46:12 d2.evaluation.evaluator]: [0mInference done 3162/8355. 0.1179 s / img. ETA=0:10:25
[32m[04/20 13:46:17 d2.evaluation.evaluator]: [0mInference done 3204/8355. 0.1179 s / img. ETA=0:10:20
[32m[04/20 13:46:22 d2.evaluation.evaluator]: [0mInference done 3246/8355. 0.1179 s / img. ETA=0:10:15
[32m[04/20 13:46:27 d2.evaluation.evaluator]: [0mInference done 3288/8355. 0.1179 s / img. ETA=0:10:10
[32m[04/20 13:46:32 d2.evaluation.evaluator]: [0mInference done 3330/8355. 0.1179 s / img. ETA=0:10:05
[32m[04/20 13:46:37 d2.evaluation.evaluator]: [0mInference done 3372/8355. 0.1179 s / img. ETA=0:10:00
[32m[04/20 13:46:42 d2.evaluation.evaluator]: [0mInference done 3414/8355. 0.1179 s / img. ETA=0:09:55
[32m[04/20 13:46:47 d2.evaluation.evaluator]: [0mInference done 3456/8355. 0.1179 s / img. ETA=0:09:50
[32m[04/20 13:46:52 d2.evaluation.evaluator]: [0mInference done 3498/8355. 0.1179 s / img. ETA=0:09:45
[32m[04/20 13:46:57 d2.evaluation.evaluator]: [0mInference done 3540/8355. 0.1179 s / img. ETA=0:09:40
[32m[04/20 13:47:02 d2.evaluation.evaluator]: [0mInference done 3582/8355. 0.1179 s / img. ETA=0:09:35
[32m[04/20 13:47:07 d2.evaluation.evaluator]: [0mInference done 3624/8355. 0.1179 s / img. ETA=0:09:30
[32m[04/20 13:47:12 d2.evaluation.evaluator]: [0mInference done 3666/8355. 0.1179 s / img. ETA=0:09:25
[32m[04/20 13:47:17 d2.evaluation.evaluator]: [0mInference done 3708/8355. 0.1179 s / img. ETA=0:09:20
[32m[04/20 13:47:22 d2.evaluation.evaluator]: [0mInference done 3750/8355. 0.1179 s / img. ETA=0:09:14
[32m[04/20 13:47:27 d2.evaluation.evaluator]: [0mInference done 3792/8355. 0.1178 s / img. ETA=0:09:09
[32m[04/20 13:47:33 d2.evaluation.evaluator]: [0mInference done 3834/8355. 0.1179 s / img. ETA=0:09:04
[32m[04/20 13:47:38 d2.evaluation.evaluator]: [0mInference done 3876/8355. 0.1179 s / img. ETA=0:08:59
[32m[04/20 13:47:43 d2.evaluation.evaluator]: [0mInference done 3918/8355. 0.1179 s / img. ETA=0:08:54
[32m[04/20 13:47:48 d2.evaluation.evaluator]: [0mInference done 3960/8355. 0.1179 s / img. ETA=0:08:49
[32m[04/20 13:47:53 d2.evaluation.evaluator]: [0mInference done 4002/8355. 0.1179 s / img. ETA=0:08:44
[32m[04/20 13:47:58 d2.evaluation.evaluator]: [0mInference done 4044/8355. 0.1179 s / img. ETA=0:08:39
[32m[04/20 13:48:03 d2.evaluation.evaluator]: [0mInference done 4086/8355. 0.1179 s / img. ETA=0:08:34
[32m[04/20 13:48:08 d2.evaluation.evaluator]: [0mInference done 4128/8355. 0.1179 s / img. ETA=0:08:29
[32m[04/20 13:48:13 d2.evaluation.evaluator]: [0mInference done 4170/8355. 0.1179 s / img. ETA=0:08:24
[32m[04/20 13:48:18 d2.evaluation.evaluator]: [0mInference done 4212/8355. 0.1179 s / img. ETA=0:08:19
[32m[04/20 13:48:23 d2.evaluation.evaluator]: [0mInference done 4254/8355. 0.1179 s / img. ETA=0:08:14
[32m[04/20 13:48:28 d2.evaluation.evaluator]: [0mInference done 4296/8355. 0.1179 s / img. ETA=0:08:09
[32m[04/20 13:48:34 d2.evaluation.evaluator]: [0mInference done 4338/8355. 0.1179 s / img. ETA=0:08:04
[32m[04/20 13:48:39 d2.evaluation.evaluator]: [0mInference done 4380/8355. 0.1179 s / img. ETA=0:07:59
[32m[04/20 13:48:44 d2.evaluation.evaluator]: [0mInference done 4422/8355. 0.1179 s / img. ETA=0:07:54
[32m[04/20 13:48:49 d2.evaluation.evaluator]: [0mInference done 4464/8355. 0.1179 s / img. ETA=0:07:49
[32m[04/20 13:48:54 d2.evaluation.evaluator]: [0mInference done 4506/8355. 0.1179 s / img. ETA=0:07:44
[32m[04/20 13:48:59 d2.evaluation.evaluator]: [0mInference done 4548/8355. 0.1179 s / img. ETA=0:07:39
[32m[04/20 13:49:04 d2.evaluation.evaluator]: [0mInference done 4590/8355. 0.1179 s / img. ETA=0:07:33
[32m[04/20 13:49:09 d2.evaluation.evaluator]: [0mInference done 4632/8355. 0.1179 s / img. ETA=0:07:28
[32m[04/20 13:49:14 d2.evaluation.evaluator]: [0mInference done 4674/8355. 0.1179 s / img. ETA=0:07:23
[32m[04/20 13:49:19 d2.evaluation.evaluator]: [0mInference done 4716/8355. 0.1179 s / img. ETA=0:07:18
[32m[04/20 13:49:24 d2.evaluation.evaluator]: [0mInference done 4758/8355. 0.1179 s / img. ETA=0:07:13
[32m[04/20 13:49:29 d2.evaluation.evaluator]: [0mInference done 4800/8355. 0.1179 s / img. ETA=0:07:08
[32m[04/20 13:49:34 d2.evaluation.evaluator]: [0mInference done 4842/8355. 0.1179 s / img. ETA=0:07:03
[32m[04/20 13:49:39 d2.evaluation.evaluator]: [0mInference done 4884/8355. 0.1179 s / img. ETA=0:06:58
[32m[04/20 13:49:45 d2.evaluation.evaluator]: [0mInference done 4926/8355. 0.1179 s / img. ETA=0:06:53
[32m[04/20 13:49:50 d2.evaluation.evaluator]: [0mInference done 4968/8355. 0.1179 s / img. ETA=0:06:48
[32m[04/20 13:49:55 d2.evaluation.evaluator]: [0mInference done 5010/8355. 0.1179 s / img. ETA=0:06:43
[32m[04/20 13:50:00 d2.evaluation.evaluator]: [0mInference done 5052/8355. 0.1179 s / img. ETA=0:06:38
[32m[04/20 13:50:05 d2.evaluation.evaluator]: [0mInference done 5093/8355. 0.1180 s / img. ETA=0:06:33
[32m[04/20 13:50:10 d2.evaluation.evaluator]: [0mInference done 5134/8355. 0.1180 s / img. ETA=0:06:28
[32m[04/20 13:50:15 d2.evaluation.evaluator]: [0mInference done 5176/8355. 0.1180 s / img. ETA=0:06:23
[32m[04/20 13:50:20 d2.evaluation.evaluator]: [0mInference done 5218/8355. 0.1180 s / img. ETA=0:06:18
[32m[04/20 13:50:25 d2.evaluation.evaluator]: [0mInference done 5260/8355. 0.1180 s / img. ETA=0:06:13
[32m[04/20 13:50:30 d2.evaluation.evaluator]: [0mInference done 5302/8355. 0.1180 s / img. ETA=0:06:08
[32m[04/20 13:50:35 d2.evaluation.evaluator]: [0mInference done 5344/8355. 0.1180 s / img. ETA=0:06:03
[32m[04/20 13:50:40 d2.evaluation.evaluator]: [0mInference done 5386/8355. 0.1180 s / img. ETA=0:05:58
[32m[04/20 13:50:45 d2.evaluation.evaluator]: [0mInference done 5427/8355. 0.1180 s / img. ETA=0:05:53
[32m[04/20 13:50:50 d2.evaluation.evaluator]: [0mInference done 5469/8355. 0.1180 s / img. ETA=0:05:48
[32m[04/20 13:50:55 d2.evaluation.evaluator]: [0mInference done 5511/8355. 0.1180 s / img. ETA=0:05:43
[32m[04/20 13:51:01 d2.evaluation.evaluator]: [0mInference done 5553/8355. 0.1180 s / img. ETA=0:05:38
[32m[04/20 13:51:06 d2.evaluation.evaluator]: [0mInference done 5595/8355. 0.1180 s / img. ETA=0:05:33
[32m[04/20 13:51:11 d2.evaluation.evaluator]: [0mInference done 5637/8355. 0.1180 s / img. ETA=0:05:27
[32m[04/20 13:51:16 d2.evaluation.evaluator]: [0mInference done 5679/8355. 0.1180 s / img. ETA=0:05:22
[32m[04/20 13:51:21 d2.evaluation.evaluator]: [0mInference done 5721/8355. 0.1180 s / img. ETA=0:05:17
[32m[04/20 13:51:26 d2.evaluation.evaluator]: [0mInference done 5763/8355. 0.1180 s / img. ETA=0:05:12
[32m[04/20 13:51:31 d2.evaluation.evaluator]: [0mInference done 5805/8355. 0.1180 s / img. ETA=0:05:07
[32m[04/20 13:51:36 d2.evaluation.evaluator]: [0mInference done 5847/8355. 0.1180 s / img. ETA=0:05:02
[32m[04/20 13:51:41 d2.evaluation.evaluator]: [0mInference done 5889/8355. 0.1180 s / img. ETA=0:04:57
[32m[04/20 13:51:46 d2.evaluation.evaluator]: [0mInference done 5931/8355. 0.1180 s / img. ETA=0:04:52
[32m[04/20 13:51:51 d2.evaluation.evaluator]: [0mInference done 5973/8355. 0.1180 s / img. ETA=0:04:47
[32m[04/20 13:51:56 d2.evaluation.evaluator]: [0mInference done 6015/8355. 0.1180 s / img. ETA=0:04:42
[32m[04/20 13:52:01 d2.evaluation.evaluator]: [0mInference done 6057/8355. 0.1180 s / img. ETA=0:04:37
[32m[04/20 13:52:06 d2.evaluation.evaluator]: [0mInference done 6099/8355. 0.1180 s / img. ETA=0:04:32
[32m[04/20 13:52:11 d2.evaluation.evaluator]: [0mInference done 6141/8355. 0.1180 s / img. ETA=0:04:27
[32m[04/20 13:52:17 d2.evaluation.evaluator]: [0mInference done 6183/8355. 0.1180 s / img. ETA=0:04:22
[32m[04/20 13:52:22 d2.evaluation.evaluator]: [0mInference done 6225/8355. 0.1180 s / img. ETA=0:04:16
[32m[04/20 13:52:27 d2.evaluation.evaluator]: [0mInference done 6267/8355. 0.1180 s / img. ETA=0:04:11
[32m[04/20 13:52:32 d2.evaluation.evaluator]: [0mInference done 6309/8355. 0.1180 s / img. ETA=0:04:06
[32m[04/20 13:52:37 d2.evaluation.evaluator]: [0mInference done 6351/8355. 0.1180 s / img. ETA=0:04:01
[32m[04/20 13:52:42 d2.evaluation.evaluator]: [0mInference done 6393/8355. 0.1180 s / img. ETA=0:03:56
[32m[04/20 13:52:47 d2.evaluation.evaluator]: [0mInference done 6435/8355. 0.1180 s / img. ETA=0:03:51
[32m[04/20 13:52:52 d2.evaluation.evaluator]: [0mInference done 6477/8355. 0.1180 s / img. ETA=0:03:46
[32m[04/20 13:52:57 d2.evaluation.evaluator]: [0mInference done 6519/8355. 0.1180 s / img. ETA=0:03:41
[32m[04/20 13:53:02 d2.evaluation.evaluator]: [0mInference done 6561/8355. 0.1180 s / img. ETA=0:03:36
[32m[04/20 13:53:07 d2.evaluation.evaluator]: [0mInference done 6603/8355. 0.1180 s / img. ETA=0:03:31
[32m[04/20 13:53:12 d2.evaluation.evaluator]: [0mInference done 6645/8355. 0.1180 s / img. ETA=0:03:26
[32m[04/20 13:53:17 d2.evaluation.evaluator]: [0mInference done 6687/8355. 0.1180 s / img. ETA=0:03:21
[32m[04/20 13:53:22 d2.evaluation.evaluator]: [0mInference done 6729/8355. 0.1180 s / img. ETA=0:03:16
[32m[04/20 13:53:27 d2.evaluation.evaluator]: [0mInference done 6772/8355. 0.1179 s / img. ETA=0:03:10
[32m[04/20 13:53:32 d2.evaluation.evaluator]: [0mInference done 6814/8355. 0.1179 s / img. ETA=0:03:05
[32m[04/20 13:53:37 d2.evaluation.evaluator]: [0mInference done 6856/8355. 0.1179 s / img. ETA=0:03:00
[32m[04/20 13:53:42 d2.evaluation.evaluator]: [0mInference done 6898/8355. 0.1179 s / img. ETA=0:02:55
[32m[04/20 13:53:47 d2.evaluation.evaluator]: [0mInference done 6940/8355. 0.1179 s / img. ETA=0:02:50
[32m[04/20 13:53:52 d2.evaluation.evaluator]: [0mInference done 6982/8355. 0.1179 s / img. ETA=0:02:45
[32m[04/20 13:53:58 d2.evaluation.evaluator]: [0mInference done 7024/8355. 0.1179 s / img. ETA=0:02:40
[32m[04/20 13:54:03 d2.evaluation.evaluator]: [0mInference done 7066/8355. 0.1179 s / img. ETA=0:02:35
[32m[04/20 13:54:08 d2.evaluation.evaluator]: [0mInference done 7108/8355. 0.1180 s / img. ETA=0:02:30
[32m[04/20 13:54:13 d2.evaluation.evaluator]: [0mInference done 7149/8355. 0.1180 s / img. ETA=0:02:25
[32m[04/20 13:54:18 d2.evaluation.evaluator]: [0mInference done 7191/8355. 0.1180 s / img. ETA=0:02:20
[32m[04/20 13:54:23 d2.evaluation.evaluator]: [0mInference done 7233/8355. 0.1180 s / img. ETA=0:02:15
[32m[04/20 13:54:28 d2.evaluation.evaluator]: [0mInference done 7275/8355. 0.1180 s / img. ETA=0:02:10
[32m[04/20 13:54:33 d2.evaluation.evaluator]: [0mInference done 7316/8355. 0.1180 s / img. ETA=0:02:05
[32m[04/20 13:54:38 d2.evaluation.evaluator]: [0mInference done 7358/8355. 0.1180 s / img. ETA=0:02:00
[32m[04/20 13:54:43 d2.evaluation.evaluator]: [0mInference done 7400/8355. 0.1180 s / img. ETA=0:01:55
[32m[04/20 13:54:48 d2.evaluation.evaluator]: [0mInference done 7442/8355. 0.1180 s / img. ETA=0:01:50
[32m[04/20 13:54:53 d2.evaluation.evaluator]: [0mInference done 7484/8355. 0.1180 s / img. ETA=0:01:45
[32m[04/20 13:54:59 d2.evaluation.evaluator]: [0mInference done 7526/8355. 0.1180 s / img. ETA=0:01:40
[32m[04/20 13:55:04 d2.evaluation.evaluator]: [0mInference done 7567/8355. 0.1180 s / img. ETA=0:01:35
[32m[04/20 13:55:09 d2.evaluation.evaluator]: [0mInference done 7609/8355. 0.1180 s / img. ETA=0:01:30
[32m[04/20 13:55:14 d2.evaluation.evaluator]: [0mInference done 7650/8355. 0.1180 s / img. ETA=0:01:25
[32m[04/20 13:55:19 d2.evaluation.evaluator]: [0mInference done 7691/8355. 0.1180 s / img. ETA=0:01:20
[32m[04/20 13:55:24 d2.evaluation.evaluator]: [0mInference done 7733/8355. 0.1180 s / img. ETA=0:01:15
[32m[04/20 13:55:29 d2.evaluation.evaluator]: [0mInference done 7774/8355. 0.1180 s / img. ETA=0:01:10
[32m[04/20 13:55:34 d2.evaluation.evaluator]: [0mInference done 7815/8355. 0.1180 s / img. ETA=0:01:05
[32m[04/20 13:55:39 d2.evaluation.evaluator]: [0mInference done 7856/8355. 0.1181 s / img. ETA=0:01:00
[32m[04/20 13:55:44 d2.evaluation.evaluator]: [0mInference done 7897/8355. 0.1181 s / img. ETA=0:00:55
[32m[04/20 13:55:49 d2.evaluation.evaluator]: [0mInference done 7939/8355. 0.1181 s / img. ETA=0:00:50
[32m[04/20 13:55:54 d2.evaluation.evaluator]: [0mInference done 7981/8355. 0.1181 s / img. ETA=0:00:45
[32m[04/20 13:55:59 d2.evaluation.evaluator]: [0mInference done 8023/8355. 0.1181 s / img. ETA=0:00:40
[32m[04/20 13:56:04 d2.evaluation.evaluator]: [0mInference done 8065/8355. 0.1181 s / img. ETA=0:00:35
[32m[04/20 13:56:09 d2.evaluation.evaluator]: [0mInference done 8107/8355. 0.1181 s / img. ETA=0:00:29
[32m[04/20 13:56:14 d2.evaluation.evaluator]: [0mInference done 8149/8355. 0.1181 s / img. ETA=0:00:24
[32m[04/20 13:56:19 d2.evaluation.evaluator]: [0mInference done 8191/8355. 0.1181 s / img. ETA=0:00:19
[32m[04/20 13:56:24 d2.evaluation.evaluator]: [0mInference done 8233/8355. 0.1181 s / img. ETA=0:00:14
[32m[04/20 13:56:29 d2.evaluation.evaluator]: [0mInference done 8275/8355. 0.1181 s / img. ETA=0:00:09
[32m[04/20 13:56:34 d2.evaluation.evaluator]: [0mInference done 8317/8355. 0.1181 s / img. ETA=0:00:04
[32m[04/20 13:56:39 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:48.043278 (0.120724 s / img per device, on 1 devices)
[32m[04/20 13:56:39 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:25 (0.118054 s / img per device, on 1 devices)
[32m[04/20 13:56:39 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 13:56:39 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 13:56:40 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.47s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=21.73s).
Accumulating evaluation results...
DONE (t=2.42s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.379
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.711
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.353
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.272
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.505
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.653
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.154
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.432
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.355
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.569
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.694
[32m[04/20 13:57:04 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 37.946 | 71.069 | 35.344 | 27.187 | 50.486 | 65.259 |
[32m[04/20 13:57:04 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 39.059 | bicycle       | 27.851 | car            | 46.927 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 13:57:06 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 13:57:06 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 13:57:06 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 13:57:07 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1194 s / img. ETA=0:02:31
[32m[04/20 13:57:12 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1183 s / img. ETA=0:02:25
[32m[04/20 13:57:17 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1183 s / img. ETA=0:02:20
[32m[04/20 13:57:22 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1180 s / img. ETA=0:02:15
[32m[04/20 13:57:27 d2.evaluation.evaluator]: [0mInference done 179/1257. 0.1179 s / img. ETA=0:02:10
[32m[04/20 13:57:33 d2.evaluation.evaluator]: [0mInference done 221/1257. 0.1179 s / img. ETA=0:02:05
[32m[04/20 13:57:38 d2.evaluation.evaluator]: [0mInference done 263/1257. 0.1179 s / img. ETA=0:01:59
[32m[04/20 13:57:43 d2.evaluation.evaluator]: [0mInference done 305/1257. 0.1178 s / img. ETA=0:01:54
[32m[04/20 13:57:48 d2.evaluation.evaluator]: [0mInference done 347/1257. 0.1179 s / img. ETA=0:01:49
[32m[04/20 13:57:53 d2.evaluation.evaluator]: [0mInference done 389/1257. 0.1179 s / img. ETA=0:01:44
[32m[04/20 13:57:58 d2.evaluation.evaluator]: [0mInference done 431/1257. 0.1179 s / img. ETA=0:01:39
[32m[04/20 13:58:03 d2.evaluation.evaluator]: [0mInference done 473/1257. 0.1179 s / img. ETA=0:01:34
[32m[04/20 13:58:08 d2.evaluation.evaluator]: [0mInference done 515/1257. 0.1179 s / img. ETA=0:01:29
[32m[04/20 13:58:13 d2.evaluation.evaluator]: [0mInference done 556/1257. 0.1180 s / img. ETA=0:01:24
[32m[04/20 13:58:18 d2.evaluation.evaluator]: [0mInference done 598/1257. 0.1181 s / img. ETA=0:01:19
[32m[04/20 13:58:23 d2.evaluation.evaluator]: [0mInference done 639/1257. 0.1182 s / img. ETA=0:01:14
[32m[04/20 13:58:28 d2.evaluation.evaluator]: [0mInference done 680/1257. 0.1182 s / img. ETA=0:01:09
[32m[04/20 13:58:33 d2.evaluation.evaluator]: [0mInference done 722/1257. 0.1182 s / img. ETA=0:01:04
[32m[04/20 13:58:38 d2.evaluation.evaluator]: [0mInference done 764/1257. 0.1182 s / img. ETA=0:00:59
[32m[04/20 13:58:43 d2.evaluation.evaluator]: [0mInference done 806/1257. 0.1182 s / img. ETA=0:00:54
[32m[04/20 13:58:48 d2.evaluation.evaluator]: [0mInference done 848/1257. 0.1183 s / img. ETA=0:00:49
[32m[04/20 13:58:54 d2.evaluation.evaluator]: [0mInference done 890/1257. 0.1183 s / img. ETA=0:00:44
[32m[04/20 13:58:59 d2.evaluation.evaluator]: [0mInference done 932/1257. 0.1183 s / img. ETA=0:00:39
[32m[04/20 13:59:04 d2.evaluation.evaluator]: [0mInference done 974/1257. 0.1183 s / img. ETA=0:00:34
[32m[04/20 13:59:09 d2.evaluation.evaluator]: [0mInference done 1016/1257. 0.1183 s / img. ETA=0:00:29
[32m[04/20 13:59:14 d2.evaluation.evaluator]: [0mInference done 1058/1257. 0.1183 s / img. ETA=0:00:24
[32m[04/20 13:59:19 d2.evaluation.evaluator]: [0mInference done 1100/1257. 0.1183 s / img. ETA=0:00:18
[32m[04/20 13:59:24 d2.evaluation.evaluator]: [0mInference done 1142/1257. 0.1183 s / img. ETA=0:00:13
[32m[04/20 13:59:29 d2.evaluation.evaluator]: [0mInference done 1184/1257. 0.1183 s / img. ETA=0:00:08
[32m[04/20 13:59:34 d2.evaluation.evaluator]: [0mInference done 1226/1257. 0.1183 s / img. ETA=0:00:03
[32m[04/20 13:59:38 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:31.489438 (0.120998 s / img per device, on 1 devices)
[32m[04/20 13:59:38 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:28 (0.118285 s / img per device, on 1 devices)
[32m[04/20 13:59:38 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 13:59:38 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 13:59:38 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.94s).
Accumulating evaluation results...
DONE (t=0.42s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.574
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.248
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.346
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.496
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.148
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.360
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.273
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.553
[32m[04/20 13:59:42 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 28.780 | 57.425 | 24.783 | 18.004 | 34.575 | 49.605 |
[32m[04/20 13:59:42 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 30.039 | bicycle       | 12.583 | car            | 43.718 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  14  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 13:59:42 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 13:59:43 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 13:59:43 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 13:59:43 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 13:59:43 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 13:59:43 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 13:59:43 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 14:00:04 d2.utils.events]: [0m eta: 0:17:03  iter: 19  total_loss: 0.645  loss_cls: 0.211  loss_box_reg: 0.357  loss_rpn_cls: 0.019  loss_rpn_loc: 0.054  time: 1.0364  data_time: 0.0302  lr: 0.000100  max_mem: 5405M
[32m[04/20 14:00:24 d2.utils.events]: [0m eta: 0:16:18  iter: 39  total_loss: 0.555  loss_cls: 0.180  loss_box_reg: 0.297  loss_rpn_cls: 0.014  loss_rpn_loc: 0.048  time: 1.0207  data_time: 0.0105  lr: 0.000200  max_mem: 5405M
[32m[04/20 14:00:45 d2.utils.events]: [0m eta: 0:15:56  iter: 59  total_loss: 0.620  loss_cls: 0.190  loss_box_reg: 0.349  loss_rpn_cls: 0.013  loss_rpn_loc: 0.053  time: 1.0221  data_time: 0.0112  lr: 0.000300  max_mem: 5405M
[32m[04/20 14:01:06 d2.utils.events]: [0m eta: 0:15:54  iter: 79  total_loss: 0.601  loss_cls: 0.195  loss_box_reg: 0.310  loss_rpn_cls: 0.012  loss_rpn_loc: 0.059  time: 1.0255  data_time: 0.0123  lr: 0.000400  max_mem: 5405M
[32m[04/20 14:01:26 d2.utils.events]: [0m eta: 0:15:39  iter: 99  total_loss: 0.602  loss_cls: 0.195  loss_box_reg: 0.345  loss_rpn_cls: 0.015  loss_rpn_loc: 0.051  time: 1.0288  data_time: 0.0109  lr: 0.000500  max_mem: 5405M
[32m[04/20 14:01:47 d2.utils.events]: [0m eta: 0:15:22  iter: 119  total_loss: 0.633  loss_cls: 0.202  loss_box_reg: 0.336  loss_rpn_cls: 0.017  loss_rpn_loc: 0.061  time: 1.0293  data_time: 0.0107  lr: 0.000599  max_mem: 5405M
[32m[04/20 14:02:08 d2.utils.events]: [0m eta: 0:14:57  iter: 139  total_loss: 0.539  loss_cls: 0.179  loss_box_reg: 0.299  loss_rpn_cls: 0.016  loss_rpn_loc: 0.044  time: 1.0289  data_time: 0.0118  lr: 0.000699  max_mem: 5405M
[32m[04/20 14:02:29 d2.utils.events]: [0m eta: 0:14:42  iter: 159  total_loss: 0.686  loss_cls: 0.205  loss_box_reg: 0.375  loss_rpn_cls: 0.013  loss_rpn_loc: 0.054  time: 1.0317  data_time: 0.0116  lr: 0.000799  max_mem: 5405M
[32m[04/20 14:02:50 d2.utils.events]: [0m eta: 0:14:21  iter: 179  total_loss: 0.537  loss_cls: 0.173  loss_box_reg: 0.306  loss_rpn_cls: 0.009  loss_rpn_loc: 0.054  time: 1.0324  data_time: 0.0125  lr: 0.000899  max_mem: 5405M
[32m[04/20 14:03:10 d2.utils.events]: [0m eta: 0:14:00  iter: 199  total_loss: 0.581  loss_cls: 0.172  loss_box_reg: 0.337  loss_rpn_cls: 0.015  loss_rpn_loc: 0.055  time: 1.0310  data_time: 0.0112  lr: 0.000999  max_mem: 5405M
[32m[04/20 14:03:31 d2.utils.events]: [0m eta: 0:13:38  iter: 219  total_loss: 0.662  loss_cls: 0.213  loss_box_reg: 0.345  loss_rpn_cls: 0.018  loss_rpn_loc: 0.064  time: 1.0303  data_time: 0.0121  lr: 0.001099  max_mem: 5405M
[32m[04/20 14:03:51 d2.utils.events]: [0m eta: 0:13:18  iter: 239  total_loss: 0.549  loss_cls: 0.175  loss_box_reg: 0.307  loss_rpn_cls: 0.014  loss_rpn_loc: 0.057  time: 1.0313  data_time: 0.0116  lr: 0.001199  max_mem: 5405M
[32m[04/20 14:04:12 d2.utils.events]: [0m eta: 0:12:56  iter: 259  total_loss: 0.649  loss_cls: 0.200  loss_box_reg: 0.363  loss_rpn_cls: 0.015  loss_rpn_loc: 0.050  time: 1.0305  data_time: 0.0117  lr: 0.001299  max_mem: 5405M
[32m[04/20 14:04:32 d2.utils.events]: [0m eta: 0:12:34  iter: 279  total_loss: 0.533  loss_cls: 0.173  loss_box_reg: 0.298  loss_rpn_cls: 0.016  loss_rpn_loc: 0.043  time: 1.0298  data_time: 0.0123  lr: 0.001399  max_mem: 5405M
[32m[04/20 14:04:53 d2.utils.events]: [0m eta: 0:12:13  iter: 299  total_loss: 0.600  loss_cls: 0.188  loss_box_reg: 0.330  loss_rpn_cls: 0.013  loss_rpn_loc: 0.056  time: 1.0303  data_time: 0.0111  lr: 0.001499  max_mem: 5405M
[32m[04/20 14:05:14 d2.utils.events]: [0m eta: 0:11:53  iter: 319  total_loss: 0.585  loss_cls: 0.190  loss_box_reg: 0.334  loss_rpn_cls: 0.011  loss_rpn_loc: 0.045  time: 1.0316  data_time: 0.0114  lr: 0.001598  max_mem: 5405M
[32m[04/20 14:05:35 d2.utils.events]: [0m eta: 0:11:32  iter: 339  total_loss: 0.644  loss_cls: 0.207  loss_box_reg: 0.347  loss_rpn_cls: 0.016  loss_rpn_loc: 0.046  time: 1.0312  data_time: 0.0107  lr: 0.001698  max_mem: 5405M
[32m[04/20 14:05:55 d2.utils.events]: [0m eta: 0:11:10  iter: 359  total_loss: 0.552  loss_cls: 0.187  loss_box_reg: 0.315  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0307  data_time: 0.0118  lr: 0.001798  max_mem: 5405M
[32m[04/20 14:06:16 d2.utils.events]: [0m eta: 0:10:47  iter: 379  total_loss: 0.551  loss_cls: 0.184  loss_box_reg: 0.330  loss_rpn_cls: 0.014  loss_rpn_loc: 0.040  time: 1.0303  data_time: 0.0106  lr: 0.001898  max_mem: 5405M
[32m[04/20 14:06:37 d2.utils.events]: [0m eta: 0:10:28  iter: 399  total_loss: 0.576  loss_cls: 0.190  loss_box_reg: 0.324  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 1.0307  data_time: 0.0130  lr: 0.001998  max_mem: 5405M
[32m[04/20 14:06:57 d2.utils.events]: [0m eta: 0:10:05  iter: 419  total_loss: 0.657  loss_cls: 0.215  loss_box_reg: 0.349  loss_rpn_cls: 0.015  loss_rpn_loc: 0.049  time: 1.0297  data_time: 0.0124  lr: 0.002098  max_mem: 5405M
[32m[04/20 14:07:18 d2.utils.events]: [0m eta: 0:09:45  iter: 439  total_loss: 0.587  loss_cls: 0.200  loss_box_reg: 0.326  loss_rpn_cls: 0.015  loss_rpn_loc: 0.045  time: 1.0300  data_time: 0.0111  lr: 0.002198  max_mem: 5405M
[32m[04/20 14:07:38 d2.utils.events]: [0m eta: 0:09:24  iter: 459  total_loss: 0.576  loss_cls: 0.175  loss_box_reg: 0.329  loss_rpn_cls: 0.012  loss_rpn_loc: 0.052  time: 1.0300  data_time: 0.0110  lr: 0.002298  max_mem: 5405M
[32m[04/20 14:07:59 d2.utils.events]: [0m eta: 0:09:04  iter: 479  total_loss: 0.597  loss_cls: 0.190  loss_box_reg: 0.346  loss_rpn_cls: 0.013  loss_rpn_loc: 0.050  time: 1.0308  data_time: 0.0119  lr: 0.002398  max_mem: 5405M
[32m[04/20 14:08:21 d2.utils.events]: [0m eta: 0:08:45  iter: 499  total_loss: 0.622  loss_cls: 0.205  loss_box_reg: 0.332  loss_rpn_cls: 0.013  loss_rpn_loc: 0.051  time: 1.0321  data_time: 0.0115  lr: 0.002498  max_mem: 5405M
[32m[04/20 14:08:41 d2.utils.events]: [0m eta: 0:08:23  iter: 519  total_loss: 0.637  loss_cls: 0.203  loss_box_reg: 0.358  loss_rpn_cls: 0.014  loss_rpn_loc: 0.058  time: 1.0319  data_time: 0.0108  lr: 0.002597  max_mem: 5405M
[32m[04/20 14:09:02 d2.utils.events]: [0m eta: 0:08:03  iter: 539  total_loss: 0.647  loss_cls: 0.208  loss_box_reg: 0.345  loss_rpn_cls: 0.016  loss_rpn_loc: 0.056  time: 1.0326  data_time: 0.0107  lr: 0.002697  max_mem: 5405M
[32m[04/20 14:09:23 d2.utils.events]: [0m eta: 0:07:41  iter: 559  total_loss: 0.561  loss_cls: 0.179  loss_box_reg: 0.324  loss_rpn_cls: 0.013  loss_rpn_loc: 0.045  time: 1.0322  data_time: 0.0114  lr: 0.002797  max_mem: 5405M
[32m[04/20 14:09:43 d2.utils.events]: [0m eta: 0:07:20  iter: 579  total_loss: 0.622  loss_cls: 0.210  loss_box_reg: 0.343  loss_rpn_cls: 0.018  loss_rpn_loc: 0.050  time: 1.0317  data_time: 0.0114  lr: 0.002897  max_mem: 5405M
[32m[04/20 14:10:04 d2.utils.events]: [0m eta: 0:06:59  iter: 599  total_loss: 0.647  loss_cls: 0.195  loss_box_reg: 0.357  loss_rpn_cls: 0.012  loss_rpn_loc: 0.064  time: 1.0316  data_time: 0.0113  lr: 0.002997  max_mem: 5405M
[32m[04/20 14:10:24 d2.utils.events]: [0m eta: 0:06:37  iter: 619  total_loss: 0.559  loss_cls: 0.192  loss_box_reg: 0.310  loss_rpn_cls: 0.011  loss_rpn_loc: 0.046  time: 1.0312  data_time: 0.0103  lr: 0.003097  max_mem: 5405M
[32m[04/20 14:10:45 d2.utils.events]: [0m eta: 0:06:17  iter: 639  total_loss: 0.647  loss_cls: 0.208  loss_box_reg: 0.376  loss_rpn_cls: 0.015  loss_rpn_loc: 0.053  time: 1.0317  data_time: 0.0111  lr: 0.003197  max_mem: 5405M
[32m[04/20 14:11:06 d2.utils.events]: [0m eta: 0:05:56  iter: 659  total_loss: 0.662  loss_cls: 0.212  loss_box_reg: 0.368  loss_rpn_cls: 0.014  loss_rpn_loc: 0.055  time: 1.0322  data_time: 0.0113  lr: 0.003297  max_mem: 5405M
[32m[04/20 14:11:27 d2.utils.events]: [0m eta: 0:05:36  iter: 679  total_loss: 0.608  loss_cls: 0.198  loss_box_reg: 0.330  loss_rpn_cls: 0.016  loss_rpn_loc: 0.056  time: 1.0325  data_time: 0.0109  lr: 0.003397  max_mem: 5405M
[32m[04/20 14:11:48 d2.utils.events]: [0m eta: 0:05:15  iter: 699  total_loss: 0.564  loss_cls: 0.177  loss_box_reg: 0.332  loss_rpn_cls: 0.011  loss_rpn_loc: 0.043  time: 1.0326  data_time: 0.0122  lr: 0.003497  max_mem: 5405M
[32m[04/20 14:12:09 d2.utils.events]: [0m eta: 0:04:54  iter: 719  total_loss: 0.592  loss_cls: 0.190  loss_box_reg: 0.319  loss_rpn_cls: 0.015  loss_rpn_loc: 0.055  time: 1.0330  data_time: 0.0109  lr: 0.003596  max_mem: 5405M
[32m[04/20 14:12:30 d2.utils.events]: [0m eta: 0:04:33  iter: 739  total_loss: 0.624  loss_cls: 0.205  loss_box_reg: 0.353  loss_rpn_cls: 0.014  loss_rpn_loc: 0.049  time: 1.0333  data_time: 0.0111  lr: 0.003696  max_mem: 5405M
[32m[04/20 14:12:51 d2.utils.events]: [0m eta: 0:04:12  iter: 759  total_loss: 0.572  loss_cls: 0.184  loss_box_reg: 0.344  loss_rpn_cls: 0.011  loss_rpn_loc: 0.049  time: 1.0336  data_time: 0.0117  lr: 0.003796  max_mem: 5405M
[32m[04/20 14:13:11 d2.utils.events]: [0m eta: 0:03:51  iter: 779  total_loss: 0.675  loss_cls: 0.197  loss_box_reg: 0.352  loss_rpn_cls: 0.016  loss_rpn_loc: 0.070  time: 1.0334  data_time: 0.0110  lr: 0.003896  max_mem: 5405M
[32m[04/20 14:13:32 d2.utils.events]: [0m eta: 0:03:30  iter: 799  total_loss: 0.552  loss_cls: 0.185  loss_box_reg: 0.321  loss_rpn_cls: 0.018  loss_rpn_loc: 0.046  time: 1.0338  data_time: 0.0115  lr: 0.003996  max_mem: 5405M
[32m[04/20 14:13:53 d2.utils.events]: [0m eta: 0:03:09  iter: 819  total_loss: 0.581  loss_cls: 0.194  loss_box_reg: 0.301  loss_rpn_cls: 0.019  loss_rpn_loc: 0.059  time: 1.0337  data_time: 0.0109  lr: 0.004096  max_mem: 5405M
[32m[04/20 14:14:14 d2.utils.events]: [0m eta: 0:02:48  iter: 839  total_loss: 0.692  loss_cls: 0.223  loss_box_reg: 0.377  loss_rpn_cls: 0.020  loss_rpn_loc: 0.055  time: 1.0339  data_time: 0.0121  lr: 0.004196  max_mem: 5405M
[32m[04/20 14:14:35 d2.utils.events]: [0m eta: 0:02:28  iter: 859  total_loss: 0.689  loss_cls: 0.218  loss_box_reg: 0.377  loss_rpn_cls: 0.017  loss_rpn_loc: 0.061  time: 1.0343  data_time: 0.0116  lr: 0.004296  max_mem: 5405M
[32m[04/20 14:14:56 d2.utils.events]: [0m eta: 0:02:07  iter: 879  total_loss: 0.580  loss_cls: 0.195  loss_box_reg: 0.319  loss_rpn_cls: 0.018  loss_rpn_loc: 0.043  time: 1.0343  data_time: 0.0113  lr: 0.004396  max_mem: 5405M
[32m[04/20 14:15:16 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.640  loss_cls: 0.196  loss_box_reg: 0.332  loss_rpn_cls: 0.019  loss_rpn_loc: 0.053  time: 1.0338  data_time: 0.0110  lr: 0.004496  max_mem: 5405M
[32m[04/20 14:15:36 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.603  loss_cls: 0.187  loss_box_reg: 0.338  loss_rpn_cls: 0.014  loss_rpn_loc: 0.056  time: 1.0335  data_time: 0.0109  lr: 0.004595  max_mem: 5405M
[32m[04/20 14:15:57 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.638  loss_cls: 0.194  loss_box_reg: 0.353  loss_rpn_cls: 0.015  loss_rpn_loc: 0.057  time: 1.0332  data_time: 0.0122  lr: 0.004695  max_mem: 5405M
[32m[04/20 14:16:17 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.738  loss_cls: 0.236  loss_box_reg: 0.405  loss_rpn_cls: 0.020  loss_rpn_loc: 0.069  time: 1.0329  data_time: 0.0111  lr: 0.004795  max_mem: 5405M
[32m[04/20 14:16:38 d2.utils.events]: [0m eta: 0:00:22  iter: 979  total_loss: 0.530  loss_cls: 0.175  loss_box_reg: 0.303  loss_rpn_cls: 0.014  loss_rpn_loc: 0.050  time: 1.0331  data_time: 0.0112  lr: 0.004895  max_mem: 5405M
[5m[31mWARNING[0m [32m[04/20 14:17:03 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 14:17:03 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 14:17:03 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 14:17:03 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.685  loss_cls: 0.204  loss_box_reg: 0.396  loss_rpn_cls: 0.016  loss_rpn_loc: 0.059  time: 1.0332  data_time: 0.0111  lr: 0.004995  max_mem: 5405M
[32m[04/20 14:17:03 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:11 (1.0343 s / it)
[32m[04/20 14:17:03 d2.engine.hooks]: [0mTotal training time: 0:17:17 (0:00:06 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 14:17:05 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 14:17:05 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 14:17:06 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 14:17:07 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1168 s / img. ETA=0:16:29
[32m[04/20 14:17:12 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1168 s / img. ETA=0:16:27
[32m[04/20 14:17:18 d2.evaluation.evaluator]: [0mInference done 96/8355. 0.1168 s / img. ETA=0:16:22
[32m[04/20 14:17:23 d2.evaluation.evaluator]: [0mInference done 138/8355. 0.1172 s / img. ETA=0:16:21
[32m[04/20 14:17:28 d2.evaluation.evaluator]: [0mInference done 181/8355. 0.1171 s / img. ETA=0:16:15
[32m[04/20 14:17:33 d2.evaluation.evaluator]: [0mInference done 223/8355. 0.1171 s / img. ETA=0:16:10
[32m[04/20 14:17:38 d2.evaluation.evaluator]: [0mInference done 265/8355. 0.1171 s / img. ETA=0:16:05
[32m[04/20 14:17:43 d2.evaluation.evaluator]: [0mInference done 307/8355. 0.1171 s / img. ETA=0:16:00
[32m[04/20 14:17:48 d2.evaluation.evaluator]: [0mInference done 350/8355. 0.1171 s / img. ETA=0:15:55
[32m[04/20 14:17:53 d2.evaluation.evaluator]: [0mInference done 392/8355. 0.1172 s / img. ETA=0:15:51
[32m[04/20 14:17:58 d2.evaluation.evaluator]: [0mInference done 434/8355. 0.1173 s / img. ETA=0:15:46
[32m[04/20 14:18:03 d2.evaluation.evaluator]: [0mInference done 477/8355. 0.1172 s / img. ETA=0:15:40
[32m[04/20 14:18:08 d2.evaluation.evaluator]: [0mInference done 520/8355. 0.1170 s / img. ETA=0:15:34
[32m[04/20 14:18:13 d2.evaluation.evaluator]: [0mInference done 563/8355. 0.1170 s / img. ETA=0:15:29
[32m[04/20 14:18:18 d2.evaluation.evaluator]: [0mInference done 605/8355. 0.1170 s / img. ETA=0:15:24
[32m[04/20 14:18:23 d2.evaluation.evaluator]: [0mInference done 648/8355. 0.1169 s / img. ETA=0:15:18
[32m[04/20 14:18:28 d2.evaluation.evaluator]: [0mInference done 690/8355. 0.1169 s / img. ETA=0:15:13
[32m[04/20 14:18:33 d2.evaluation.evaluator]: [0mInference done 733/8355. 0.1169 s / img. ETA=0:15:08
[32m[04/20 14:18:39 d2.evaluation.evaluator]: [0mInference done 776/8355. 0.1169 s / img. ETA=0:15:02
[32m[04/20 14:18:44 d2.evaluation.evaluator]: [0mInference done 818/8355. 0.1169 s / img. ETA=0:14:57
[32m[04/20 14:18:49 d2.evaluation.evaluator]: [0mInference done 861/8355. 0.1169 s / img. ETA=0:14:52
[32m[04/20 14:18:54 d2.evaluation.evaluator]: [0mInference done 903/8355. 0.1169 s / img. ETA=0:14:47
[32m[04/20 14:18:59 d2.evaluation.evaluator]: [0mInference done 946/8355. 0.1168 s / img. ETA=0:14:42
[32m[04/20 14:19:04 d2.evaluation.evaluator]: [0mInference done 989/8355. 0.1168 s / img. ETA=0:14:37
[32m[04/20 14:19:09 d2.evaluation.evaluator]: [0mInference done 1032/8355. 0.1168 s / img. ETA=0:14:31
[32m[04/20 14:19:14 d2.evaluation.evaluator]: [0mInference done 1075/8355. 0.1168 s / img. ETA=0:14:26
[32m[04/20 14:19:19 d2.evaluation.evaluator]: [0mInference done 1118/8355. 0.1167 s / img. ETA=0:14:21
[32m[04/20 14:19:24 d2.evaluation.evaluator]: [0mInference done 1161/8355. 0.1167 s / img. ETA=0:14:15
[32m[04/20 14:19:29 d2.evaluation.evaluator]: [0mInference done 1204/8355. 0.1167 s / img. ETA=0:14:10
[32m[04/20 14:19:34 d2.evaluation.evaluator]: [0mInference done 1247/8355. 0.1167 s / img. ETA=0:14:05
[32m[04/20 14:19:39 d2.evaluation.evaluator]: [0mInference done 1290/8355. 0.1166 s / img. ETA=0:14:00
[32m[04/20 14:19:45 d2.evaluation.evaluator]: [0mInference done 1333/8355. 0.1166 s / img. ETA=0:13:54
[32m[04/20 14:19:50 d2.evaluation.evaluator]: [0mInference done 1376/8355. 0.1166 s / img. ETA=0:13:49
[32m[04/20 14:19:55 d2.evaluation.evaluator]: [0mInference done 1419/8355. 0.1166 s / img. ETA=0:13:44
[32m[04/20 14:20:00 d2.evaluation.evaluator]: [0mInference done 1462/8355. 0.1166 s / img. ETA=0:13:38
[32m[04/20 14:20:05 d2.evaluation.evaluator]: [0mInference done 1504/8355. 0.1166 s / img. ETA=0:13:34
[32m[04/20 14:20:10 d2.evaluation.evaluator]: [0mInference done 1546/8355. 0.1166 s / img. ETA=0:13:29
[32m[04/20 14:20:15 d2.evaluation.evaluator]: [0mInference done 1588/8355. 0.1167 s / img. ETA=0:13:24
[32m[04/20 14:20:20 d2.evaluation.evaluator]: [0mInference done 1630/8355. 0.1167 s / img. ETA=0:13:20
[32m[04/20 14:20:25 d2.evaluation.evaluator]: [0mInference done 1672/8355. 0.1168 s / img. ETA=0:13:15
[32m[04/20 14:20:30 d2.evaluation.evaluator]: [0mInference done 1714/8355. 0.1168 s / img. ETA=0:13:10
[32m[04/20 14:20:35 d2.evaluation.evaluator]: [0mInference done 1756/8355. 0.1168 s / img. ETA=0:13:05
[32m[04/20 14:20:40 d2.evaluation.evaluator]: [0mInference done 1798/8355. 0.1169 s / img. ETA=0:13:01
[32m[04/20 14:20:45 d2.evaluation.evaluator]: [0mInference done 1840/8355. 0.1169 s / img. ETA=0:12:56
[32m[04/20 14:20:50 d2.evaluation.evaluator]: [0mInference done 1882/8355. 0.1169 s / img. ETA=0:12:51
[32m[04/20 14:20:55 d2.evaluation.evaluator]: [0mInference done 1924/8355. 0.1169 s / img. ETA=0:12:46
[32m[04/20 14:21:01 d2.evaluation.evaluator]: [0mInference done 1966/8355. 0.1170 s / img. ETA=0:12:41
[32m[04/20 14:21:06 d2.evaluation.evaluator]: [0mInference done 2008/8355. 0.1170 s / img. ETA=0:12:36
[32m[04/20 14:21:11 d2.evaluation.evaluator]: [0mInference done 2050/8355. 0.1170 s / img. ETA=0:12:32
[32m[04/20 14:21:16 d2.evaluation.evaluator]: [0mInference done 2092/8355. 0.1170 s / img. ETA=0:12:27
[32m[04/20 14:21:21 d2.evaluation.evaluator]: [0mInference done 2135/8355. 0.1170 s / img. ETA=0:12:21
[32m[04/20 14:21:26 d2.evaluation.evaluator]: [0mInference done 2177/8355. 0.1170 s / img. ETA=0:12:16
[32m[04/20 14:21:31 d2.evaluation.evaluator]: [0mInference done 2219/8355. 0.1170 s / img. ETA=0:12:11
[32m[04/20 14:21:36 d2.evaluation.evaluator]: [0mInference done 2261/8355. 0.1170 s / img. ETA=0:12:06
[32m[04/20 14:21:41 d2.evaluation.evaluator]: [0mInference done 2303/8355. 0.1170 s / img. ETA=0:12:02
[32m[04/20 14:21:46 d2.evaluation.evaluator]: [0mInference done 2345/8355. 0.1170 s / img. ETA=0:11:57
[32m[04/20 14:21:51 d2.evaluation.evaluator]: [0mInference done 2387/8355. 0.1170 s / img. ETA=0:11:52
[32m[04/20 14:21:56 d2.evaluation.evaluator]: [0mInference done 2429/8355. 0.1170 s / img. ETA=0:11:47
[32m[04/20 14:22:01 d2.evaluation.evaluator]: [0mInference done 2471/8355. 0.1170 s / img. ETA=0:11:42
[32m[04/20 14:22:06 d2.evaluation.evaluator]: [0mInference done 2513/8355. 0.1170 s / img. ETA=0:11:37
[32m[04/20 14:22:11 d2.evaluation.evaluator]: [0mInference done 2555/8355. 0.1171 s / img. ETA=0:11:32
[32m[04/20 14:22:16 d2.evaluation.evaluator]: [0mInference done 2597/8355. 0.1171 s / img. ETA=0:11:27
[32m[04/20 14:22:21 d2.evaluation.evaluator]: [0mInference done 2639/8355. 0.1171 s / img. ETA=0:11:22
[32m[04/20 14:22:26 d2.evaluation.evaluator]: [0mInference done 2681/8355. 0.1171 s / img. ETA=0:11:17
[32m[04/20 14:22:31 d2.evaluation.evaluator]: [0mInference done 2723/8355. 0.1171 s / img. ETA=0:11:12
[32m[04/20 14:22:36 d2.evaluation.evaluator]: [0mInference done 2765/8355. 0.1171 s / img. ETA=0:11:07
[32m[04/20 14:22:41 d2.evaluation.evaluator]: [0mInference done 2807/8355. 0.1171 s / img. ETA=0:11:02
[32m[04/20 14:22:46 d2.evaluation.evaluator]: [0mInference done 2849/8355. 0.1171 s / img. ETA=0:10:57
[32m[04/20 14:22:51 d2.evaluation.evaluator]: [0mInference done 2891/8355. 0.1171 s / img. ETA=0:10:52
[32m[04/20 14:22:56 d2.evaluation.evaluator]: [0mInference done 2933/8355. 0.1171 s / img. ETA=0:10:47
[32m[04/20 14:23:02 d2.evaluation.evaluator]: [0mInference done 2975/8355. 0.1171 s / img. ETA=0:10:42
[32m[04/20 14:23:07 d2.evaluation.evaluator]: [0mInference done 3017/8355. 0.1171 s / img. ETA=0:10:37
[32m[04/20 14:23:12 d2.evaluation.evaluator]: [0mInference done 3059/8355. 0.1171 s / img. ETA=0:10:32
[32m[04/20 14:23:17 d2.evaluation.evaluator]: [0mInference done 3101/8355. 0.1171 s / img. ETA=0:10:27
[32m[04/20 14:23:22 d2.evaluation.evaluator]: [0mInference done 3143/8355. 0.1171 s / img. ETA=0:10:22
[32m[04/20 14:23:27 d2.evaluation.evaluator]: [0mInference done 3186/8355. 0.1171 s / img. ETA=0:10:17
[32m[04/20 14:23:32 d2.evaluation.evaluator]: [0mInference done 3228/8355. 0.1171 s / img. ETA=0:10:12
[32m[04/20 14:23:37 d2.evaluation.evaluator]: [0mInference done 3270/8355. 0.1171 s / img. ETA=0:10:07
[32m[04/20 14:23:42 d2.evaluation.evaluator]: [0mInference done 3312/8355. 0.1171 s / img. ETA=0:10:02
[32m[04/20 14:23:47 d2.evaluation.evaluator]: [0mInference done 3354/8355. 0.1171 s / img. ETA=0:09:57
[32m[04/20 14:23:52 d2.evaluation.evaluator]: [0mInference done 3396/8355. 0.1171 s / img. ETA=0:09:52
[32m[04/20 14:23:57 d2.evaluation.evaluator]: [0mInference done 3438/8355. 0.1171 s / img. ETA=0:09:47
[32m[04/20 14:24:02 d2.evaluation.evaluator]: [0mInference done 3480/8355. 0.1172 s / img. ETA=0:09:42
[32m[04/20 14:24:07 d2.evaluation.evaluator]: [0mInference done 3522/8355. 0.1172 s / img. ETA=0:09:37
[32m[04/20 14:24:12 d2.evaluation.evaluator]: [0mInference done 3564/8355. 0.1172 s / img. ETA=0:09:32
[32m[04/20 14:24:17 d2.evaluation.evaluator]: [0mInference done 3606/8355. 0.1172 s / img. ETA=0:09:27
[32m[04/20 14:24:22 d2.evaluation.evaluator]: [0mInference done 3648/8355. 0.1172 s / img. ETA=0:09:22
[32m[04/20 14:24:27 d2.evaluation.evaluator]: [0mInference done 3690/8355. 0.1172 s / img. ETA=0:09:17
[32m[04/20 14:24:32 d2.evaluation.evaluator]: [0mInference done 3732/8355. 0.1172 s / img. ETA=0:09:12
[32m[04/20 14:24:37 d2.evaluation.evaluator]: [0mInference done 3774/8355. 0.1172 s / img. ETA=0:09:07
[32m[04/20 14:24:42 d2.evaluation.evaluator]: [0mInference done 3816/8355. 0.1172 s / img. ETA=0:09:02
[32m[04/20 14:24:47 d2.evaluation.evaluator]: [0mInference done 3858/8355. 0.1172 s / img. ETA=0:08:57
[32m[04/20 14:24:52 d2.evaluation.evaluator]: [0mInference done 3900/8355. 0.1172 s / img. ETA=0:08:52
[32m[04/20 14:24:57 d2.evaluation.evaluator]: [0mInference done 3942/8355. 0.1172 s / img. ETA=0:08:47
[32m[04/20 14:25:02 d2.evaluation.evaluator]: [0mInference done 3984/8355. 0.1172 s / img. ETA=0:08:42
[32m[04/20 14:25:07 d2.evaluation.evaluator]: [0mInference done 4026/8355. 0.1172 s / img. ETA=0:08:37
[32m[04/20 14:25:13 d2.evaluation.evaluator]: [0mInference done 4068/8355. 0.1172 s / img. ETA=0:08:32
[32m[04/20 14:25:18 d2.evaluation.evaluator]: [0mInference done 4110/8355. 0.1172 s / img. ETA=0:08:27
[32m[04/20 14:25:23 d2.evaluation.evaluator]: [0mInference done 4152/8355. 0.1172 s / img. ETA=0:08:22
[32m[04/20 14:25:28 d2.evaluation.evaluator]: [0mInference done 4194/8355. 0.1172 s / img. ETA=0:08:17
[32m[04/20 14:25:33 d2.evaluation.evaluator]: [0mInference done 4236/8355. 0.1172 s / img. ETA=0:08:12
[32m[04/20 14:25:38 d2.evaluation.evaluator]: [0mInference done 4278/8355. 0.1172 s / img. ETA=0:08:07
[32m[04/20 14:25:43 d2.evaluation.evaluator]: [0mInference done 4320/8355. 0.1172 s / img. ETA=0:08:02
[32m[04/20 14:25:48 d2.evaluation.evaluator]: [0mInference done 4362/8355. 0.1172 s / img. ETA=0:07:57
[32m[04/20 14:25:53 d2.evaluation.evaluator]: [0mInference done 4404/8355. 0.1172 s / img. ETA=0:07:52
[32m[04/20 14:25:58 d2.evaluation.evaluator]: [0mInference done 4446/8355. 0.1172 s / img. ETA=0:07:47
[32m[04/20 14:26:03 d2.evaluation.evaluator]: [0mInference done 4488/8355. 0.1172 s / img. ETA=0:07:42
[32m[04/20 14:26:08 d2.evaluation.evaluator]: [0mInference done 4530/8355. 0.1172 s / img. ETA=0:07:37
[32m[04/20 14:26:13 d2.evaluation.evaluator]: [0mInference done 4572/8355. 0.1172 s / img. ETA=0:07:32
[32m[04/20 14:26:18 d2.evaluation.evaluator]: [0mInference done 4614/8355. 0.1172 s / img. ETA=0:07:27
[32m[04/20 14:26:23 d2.evaluation.evaluator]: [0mInference done 4656/8355. 0.1173 s / img. ETA=0:07:22
[32m[04/20 14:26:28 d2.evaluation.evaluator]: [0mInference done 4698/8355. 0.1173 s / img. ETA=0:07:17
[32m[04/20 14:26:33 d2.evaluation.evaluator]: [0mInference done 4740/8355. 0.1173 s / img. ETA=0:07:12
[32m[04/20 14:26:38 d2.evaluation.evaluator]: [0mInference done 4782/8355. 0.1173 s / img. ETA=0:07:07
[32m[04/20 14:26:43 d2.evaluation.evaluator]: [0mInference done 4824/8355. 0.1173 s / img. ETA=0:07:02
[32m[04/20 14:26:48 d2.evaluation.evaluator]: [0mInference done 4866/8355. 0.1173 s / img. ETA=0:06:57
[32m[04/20 14:26:53 d2.evaluation.evaluator]: [0mInference done 4908/8355. 0.1173 s / img. ETA=0:06:52
[32m[04/20 14:26:58 d2.evaluation.evaluator]: [0mInference done 4950/8355. 0.1173 s / img. ETA=0:06:47
[32m[04/20 14:27:03 d2.evaluation.evaluator]: [0mInference done 4992/8355. 0.1173 s / img. ETA=0:06:42
[32m[04/20 14:27:08 d2.evaluation.evaluator]: [0mInference done 5034/8355. 0.1173 s / img. ETA=0:06:37
[32m[04/20 14:27:14 d2.evaluation.evaluator]: [0mInference done 5076/8355. 0.1173 s / img. ETA=0:06:32
[32m[04/20 14:27:19 d2.evaluation.evaluator]: [0mInference done 5118/8355. 0.1173 s / img. ETA=0:06:27
[32m[04/20 14:27:24 d2.evaluation.evaluator]: [0mInference done 5160/8355. 0.1173 s / img. ETA=0:06:22
[32m[04/20 14:27:29 d2.evaluation.evaluator]: [0mInference done 5202/8355. 0.1173 s / img. ETA=0:06:17
[32m[04/20 14:27:34 d2.evaluation.evaluator]: [0mInference done 5244/8355. 0.1173 s / img. ETA=0:06:12
[32m[04/20 14:27:39 d2.evaluation.evaluator]: [0mInference done 5286/8355. 0.1173 s / img. ETA=0:06:07
[32m[04/20 14:27:44 d2.evaluation.evaluator]: [0mInference done 5328/8355. 0.1173 s / img. ETA=0:06:02
[32m[04/20 14:27:49 d2.evaluation.evaluator]: [0mInference done 5370/8355. 0.1173 s / img. ETA=0:05:57
[32m[04/20 14:27:54 d2.evaluation.evaluator]: [0mInference done 5412/8355. 0.1173 s / img. ETA=0:05:52
[32m[04/20 14:27:59 d2.evaluation.evaluator]: [0mInference done 5454/8355. 0.1173 s / img. ETA=0:05:47
[32m[04/20 14:28:04 d2.evaluation.evaluator]: [0mInference done 5496/8355. 0.1173 s / img. ETA=0:05:42
[32m[04/20 14:28:09 d2.evaluation.evaluator]: [0mInference done 5538/8355. 0.1173 s / img. ETA=0:05:37
[32m[04/20 14:28:14 d2.evaluation.evaluator]: [0mInference done 5580/8355. 0.1173 s / img. ETA=0:05:32
[32m[04/20 14:28:19 d2.evaluation.evaluator]: [0mInference done 5622/8355. 0.1173 s / img. ETA=0:05:27
[32m[04/20 14:28:24 d2.evaluation.evaluator]: [0mInference done 5664/8355. 0.1173 s / img. ETA=0:05:22
[32m[04/20 14:28:29 d2.evaluation.evaluator]: [0mInference done 5706/8355. 0.1173 s / img. ETA=0:05:17
[32m[04/20 14:28:34 d2.evaluation.evaluator]: [0mInference done 5748/8355. 0.1173 s / img. ETA=0:05:12
[32m[04/20 14:28:39 d2.evaluation.evaluator]: [0mInference done 5790/8355. 0.1174 s / img. ETA=0:05:07
[32m[04/20 14:28:45 d2.evaluation.evaluator]: [0mInference done 5832/8355. 0.1174 s / img. ETA=0:05:02
[32m[04/20 14:28:50 d2.evaluation.evaluator]: [0mInference done 5874/8355. 0.1174 s / img. ETA=0:04:57
[32m[04/20 14:28:55 d2.evaluation.evaluator]: [0mInference done 5916/8355. 0.1174 s / img. ETA=0:04:52
[32m[04/20 14:29:00 d2.evaluation.evaluator]: [0mInference done 5958/8355. 0.1174 s / img. ETA=0:04:47
[32m[04/20 14:29:05 d2.evaluation.evaluator]: [0mInference done 6000/8355. 0.1174 s / img. ETA=0:04:42
[32m[04/20 14:29:10 d2.evaluation.evaluator]: [0mInference done 6042/8355. 0.1174 s / img. ETA=0:04:37
[32m[04/20 14:29:15 d2.evaluation.evaluator]: [0mInference done 6083/8355. 0.1174 s / img. ETA=0:04:32
[32m[04/20 14:29:20 d2.evaluation.evaluator]: [0mInference done 6125/8355. 0.1174 s / img. ETA=0:04:27
[32m[04/20 14:29:25 d2.evaluation.evaluator]: [0mInference done 6167/8355. 0.1174 s / img. ETA=0:04:22
[32m[04/20 14:29:30 d2.evaluation.evaluator]: [0mInference done 6209/8355. 0.1174 s / img. ETA=0:04:17
[32m[04/20 14:29:35 d2.evaluation.evaluator]: [0mInference done 6250/8355. 0.1174 s / img. ETA=0:04:12
[32m[04/20 14:29:40 d2.evaluation.evaluator]: [0mInference done 6292/8355. 0.1174 s / img. ETA=0:04:07
[32m[04/20 14:29:45 d2.evaluation.evaluator]: [0mInference done 6334/8355. 0.1174 s / img. ETA=0:04:02
[32m[04/20 14:29:50 d2.evaluation.evaluator]: [0mInference done 6376/8355. 0.1174 s / img. ETA=0:03:57
[32m[04/20 14:29:55 d2.evaluation.evaluator]: [0mInference done 6418/8355. 0.1175 s / img. ETA=0:03:52
[32m[04/20 14:30:00 d2.evaluation.evaluator]: [0mInference done 6460/8355. 0.1175 s / img. ETA=0:03:47
[32m[04/20 14:30:05 d2.evaluation.evaluator]: [0mInference done 6502/8355. 0.1175 s / img. ETA=0:03:42
[32m[04/20 14:30:10 d2.evaluation.evaluator]: [0mInference done 6544/8355. 0.1175 s / img. ETA=0:03:37
[32m[04/20 14:30:16 d2.evaluation.evaluator]: [0mInference done 6586/8355. 0.1175 s / img. ETA=0:03:32
[32m[04/20 14:30:21 d2.evaluation.evaluator]: [0mInference done 6628/8355. 0.1175 s / img. ETA=0:03:27
[32m[04/20 14:30:26 d2.evaluation.evaluator]: [0mInference done 6670/8355. 0.1175 s / img. ETA=0:03:21
[32m[04/20 14:30:31 d2.evaluation.evaluator]: [0mInference done 6712/8355. 0.1175 s / img. ETA=0:03:16
[32m[04/20 14:30:36 d2.evaluation.evaluator]: [0mInference done 6754/8355. 0.1175 s / img. ETA=0:03:11
[32m[04/20 14:30:41 d2.evaluation.evaluator]: [0mInference done 6796/8355. 0.1175 s / img. ETA=0:03:06
[32m[04/20 14:30:46 d2.evaluation.evaluator]: [0mInference done 6838/8355. 0.1174 s / img. ETA=0:03:01
[32m[04/20 14:30:51 d2.evaluation.evaluator]: [0mInference done 6880/8355. 0.1175 s / img. ETA=0:02:56
[32m[04/20 14:30:56 d2.evaluation.evaluator]: [0mInference done 6922/8355. 0.1174 s / img. ETA=0:02:51
[32m[04/20 14:31:01 d2.evaluation.evaluator]: [0mInference done 6964/8355. 0.1175 s / img. ETA=0:02:46
[32m[04/20 14:31:06 d2.evaluation.evaluator]: [0mInference done 7006/8355. 0.1175 s / img. ETA=0:02:41
[32m[04/20 14:31:11 d2.evaluation.evaluator]: [0mInference done 7048/8355. 0.1175 s / img. ETA=0:02:36
[32m[04/20 14:31:16 d2.evaluation.evaluator]: [0mInference done 7090/8355. 0.1175 s / img. ETA=0:02:31
[32m[04/20 14:31:21 d2.evaluation.evaluator]: [0mInference done 7132/8355. 0.1175 s / img. ETA=0:02:26
[32m[04/20 14:31:26 d2.evaluation.evaluator]: [0mInference done 7174/8355. 0.1175 s / img. ETA=0:02:21
[32m[04/20 14:31:31 d2.evaluation.evaluator]: [0mInference done 7216/8355. 0.1175 s / img. ETA=0:02:16
[32m[04/20 14:31:36 d2.evaluation.evaluator]: [0mInference done 7258/8355. 0.1175 s / img. ETA=0:02:11
[32m[04/20 14:31:41 d2.evaluation.evaluator]: [0mInference done 7300/8355. 0.1175 s / img. ETA=0:02:06
[32m[04/20 14:31:47 d2.evaluation.evaluator]: [0mInference done 7341/8355. 0.1175 s / img. ETA=0:02:01
[32m[04/20 14:31:52 d2.evaluation.evaluator]: [0mInference done 7382/8355. 0.1175 s / img. ETA=0:01:56
[32m[04/20 14:31:57 d2.evaluation.evaluator]: [0mInference done 7424/8355. 0.1175 s / img. ETA=0:01:51
[32m[04/20 14:32:02 d2.evaluation.evaluator]: [0mInference done 7466/8355. 0.1176 s / img. ETA=0:01:46
[32m[04/20 14:32:07 d2.evaluation.evaluator]: [0mInference done 7508/8355. 0.1176 s / img. ETA=0:01:41
[32m[04/20 14:32:12 d2.evaluation.evaluator]: [0mInference done 7550/8355. 0.1176 s / img. ETA=0:01:36
[32m[04/20 14:32:17 d2.evaluation.evaluator]: [0mInference done 7592/8355. 0.1176 s / img. ETA=0:01:31
[32m[04/20 14:32:22 d2.evaluation.evaluator]: [0mInference done 7634/8355. 0.1176 s / img. ETA=0:01:26
[32m[04/20 14:32:27 d2.evaluation.evaluator]: [0mInference done 7676/8355. 0.1176 s / img. ETA=0:01:21
[32m[04/20 14:32:32 d2.evaluation.evaluator]: [0mInference done 7718/8355. 0.1176 s / img. ETA=0:01:16
[32m[04/20 14:32:37 d2.evaluation.evaluator]: [0mInference done 7760/8355. 0.1176 s / img. ETA=0:01:11
[32m[04/20 14:32:42 d2.evaluation.evaluator]: [0mInference done 7802/8355. 0.1176 s / img. ETA=0:01:06
[32m[04/20 14:32:47 d2.evaluation.evaluator]: [0mInference done 7844/8355. 0.1176 s / img. ETA=0:01:01
[32m[04/20 14:32:52 d2.evaluation.evaluator]: [0mInference done 7886/8355. 0.1176 s / img. ETA=0:00:56
[32m[04/20 14:32:57 d2.evaluation.evaluator]: [0mInference done 7928/8355. 0.1176 s / img. ETA=0:00:51
[32m[04/20 14:33:02 d2.evaluation.evaluator]: [0mInference done 7970/8355. 0.1176 s / img. ETA=0:00:46
[32m[04/20 14:33:07 d2.evaluation.evaluator]: [0mInference done 8012/8355. 0.1176 s / img. ETA=0:00:41
[32m[04/20 14:33:13 d2.evaluation.evaluator]: [0mInference done 8055/8355. 0.1176 s / img. ETA=0:00:35
[32m[04/20 14:33:18 d2.evaluation.evaluator]: [0mInference done 8097/8355. 0.1176 s / img. ETA=0:00:30
[32m[04/20 14:33:23 d2.evaluation.evaluator]: [0mInference done 8140/8355. 0.1176 s / img. ETA=0:00:25
[32m[04/20 14:33:28 d2.evaluation.evaluator]: [0mInference done 8182/8355. 0.1176 s / img. ETA=0:00:20
[32m[04/20 14:33:33 d2.evaluation.evaluator]: [0mInference done 8224/8355. 0.1175 s / img. ETA=0:00:15
[32m[04/20 14:33:38 d2.evaluation.evaluator]: [0mInference done 8266/8355. 0.1175 s / img. ETA=0:00:10
[32m[04/20 14:33:43 d2.evaluation.evaluator]: [0mInference done 8308/8355. 0.1176 s / img. ETA=0:00:05
[32m[04/20 14:33:48 d2.evaluation.evaluator]: [0mInference done 8350/8355. 0.1176 s / img. ETA=0:00:00
[32m[04/20 14:33:49 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:41.814311 (0.119978 s / img per device, on 1 devices)
[32m[04/20 14:33:49 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:21 (0.117551 s / img per device, on 1 devices)
[32m[04/20 14:33:49 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 14:33:49 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 14:33:49 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.43s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.06s).
Accumulating evaluation results...
DONE (t=2.11s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.360
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.694
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.325
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.253
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.490
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.646
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.144
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.409
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.421
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.324
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.548
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.682
[32m[04/20 14:34:11 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 36.024 | 69.392 | 32.482 | 25.259 | 49.013 | 64.616 |
[32m[04/20 14:34:11 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 38.320 | bicycle       | 23.161 | car            | 46.590 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 14:34:12 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 14:34:12 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 14:34:12 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 14:34:13 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1179 s / img. ETA=0:02:29
[32m[04/20 14:34:18 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1171 s / img. ETA=0:02:23
[32m[04/20 14:34:23 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1171 s / img. ETA=0:02:18
[32m[04/20 14:34:28 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1171 s / img. ETA=0:02:14
[32m[04/20 14:34:33 d2.evaluation.evaluator]: [0mInference done 179/1257. 0.1170 s / img. ETA=0:02:08
[32m[04/20 14:34:38 d2.evaluation.evaluator]: [0mInference done 221/1257. 0.1170 s / img. ETA=0:02:03
[32m[04/20 14:34:43 d2.evaluation.evaluator]: [0mInference done 263/1257. 0.1170 s / img. ETA=0:01:58
[32m[04/20 14:34:48 d2.evaluation.evaluator]: [0mInference done 305/1257. 0.1170 s / img. ETA=0:01:53
[32m[04/20 14:34:54 d2.evaluation.evaluator]: [0mInference done 348/1257. 0.1168 s / img. ETA=0:01:48
[32m[04/20 14:34:59 d2.evaluation.evaluator]: [0mInference done 391/1257. 0.1168 s / img. ETA=0:01:43
[32m[04/20 14:35:04 d2.evaluation.evaluator]: [0mInference done 433/1257. 0.1168 s / img. ETA=0:01:38
[32m[04/20 14:35:09 d2.evaluation.evaluator]: [0mInference done 475/1257. 0.1168 s / img. ETA=0:01:33
[32m[04/20 14:35:14 d2.evaluation.evaluator]: [0mInference done 517/1257. 0.1169 s / img. ETA=0:01:28
[32m[04/20 14:35:19 d2.evaluation.evaluator]: [0mInference done 559/1257. 0.1170 s / img. ETA=0:01:23
[32m[04/20 14:35:24 d2.evaluation.evaluator]: [0mInference done 601/1257. 0.1170 s / img. ETA=0:01:18
[32m[04/20 14:35:29 d2.evaluation.evaluator]: [0mInference done 643/1257. 0.1170 s / img. ETA=0:01:13
[32m[04/20 14:35:34 d2.evaluation.evaluator]: [0mInference done 685/1257. 0.1170 s / img. ETA=0:01:08
[32m[04/20 14:35:39 d2.evaluation.evaluator]: [0mInference done 727/1257. 0.1170 s / img. ETA=0:01:03
[32m[04/20 14:35:44 d2.evaluation.evaluator]: [0mInference done 769/1257. 0.1170 s / img. ETA=0:00:58
[32m[04/20 14:35:49 d2.evaluation.evaluator]: [0mInference done 811/1257. 0.1170 s / img. ETA=0:00:53
[32m[04/20 14:35:54 d2.evaluation.evaluator]: [0mInference done 853/1257. 0.1171 s / img. ETA=0:00:48
[32m[04/20 14:35:59 d2.evaluation.evaluator]: [0mInference done 895/1257. 0.1171 s / img. ETA=0:00:43
[32m[04/20 14:36:04 d2.evaluation.evaluator]: [0mInference done 937/1257. 0.1171 s / img. ETA=0:00:38
[32m[04/20 14:36:09 d2.evaluation.evaluator]: [0mInference done 979/1257. 0.1170 s / img. ETA=0:00:33
[32m[04/20 14:36:14 d2.evaluation.evaluator]: [0mInference done 1021/1257. 0.1171 s / img. ETA=0:00:28
[32m[04/20 14:36:19 d2.evaluation.evaluator]: [0mInference done 1063/1257. 0.1171 s / img. ETA=0:00:23
[32m[04/20 14:36:24 d2.evaluation.evaluator]: [0mInference done 1105/1257. 0.1171 s / img. ETA=0:00:18
[32m[04/20 14:36:29 d2.evaluation.evaluator]: [0mInference done 1147/1257. 0.1171 s / img. ETA=0:00:13
[32m[04/20 14:36:34 d2.evaluation.evaluator]: [0mInference done 1189/1257. 0.1171 s / img. ETA=0:00:08
[32m[04/20 14:36:39 d2.evaluation.evaluator]: [0mInference done 1231/1257. 0.1171 s / img. ETA=0:00:03
[32m[04/20 14:36:42 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:29.784280 (0.119636 s / img per device, on 1 devices)
[32m[04/20 14:36:42 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:26 (0.117082 s / img per device, on 1 devices)
[32m[04/20 14:36:42 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 14:36:42 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 14:36:43 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.39s).
Accumulating evaluation results...
DONE (t=0.33s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.267
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.532
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.230
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.169
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.322
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.489
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.134
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.324
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.239
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.374
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.521
[32m[04/20 14:36:45 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 26.741 | 53.193 | 22.987 | 16.931 | 32.242 | 48.888 |
[32m[04/20 14:36:45 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 27.257 | bicycle       | 9.130 | car            | 43.837 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | nan   | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  15  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 14:36:46 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 14:36:46 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 14:36:46 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 14:36:47 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 14:36:47 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 14:36:47 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 14:36:47 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 14:37:08 d2.utils.events]: [0m eta: 0:17:18  iter: 19  total_loss: 0.612  loss_cls: 0.219  loss_box_reg: 0.339  loss_rpn_cls: 0.013  loss_rpn_loc: 0.048  time: 1.0327  data_time: 0.0331  lr: 0.000100  max_mem: 5405M
[32m[04/20 14:37:28 d2.utils.events]: [0m eta: 0:16:32  iter: 39  total_loss: 0.589  loss_cls: 0.189  loss_box_reg: 0.322  loss_rpn_cls: 0.014  loss_rpn_loc: 0.046  time: 1.0208  data_time: 0.0097  lr: 0.000200  max_mem: 5405M
[32m[04/20 14:37:49 d2.utils.events]: [0m eta: 0:16:11  iter: 59  total_loss: 0.545  loss_cls: 0.172  loss_box_reg: 0.302  loss_rpn_cls: 0.012  loss_rpn_loc: 0.052  time: 1.0239  data_time: 0.0096  lr: 0.000300  max_mem: 5405M
[32m[04/20 14:38:09 d2.utils.events]: [0m eta: 0:15:57  iter: 79  total_loss: 0.548  loss_cls: 0.186  loss_box_reg: 0.299  loss_rpn_cls: 0.015  loss_rpn_loc: 0.048  time: 1.0249  data_time: 0.0096  lr: 0.000400  max_mem: 5405M
[32m[04/20 14:38:30 d2.utils.events]: [0m eta: 0:15:30  iter: 99  total_loss: 0.631  loss_cls: 0.209  loss_box_reg: 0.329  loss_rpn_cls: 0.017  loss_rpn_loc: 0.051  time: 1.0214  data_time: 0.0097  lr: 0.000500  max_mem: 5405M
[32m[04/20 14:38:50 d2.utils.events]: [0m eta: 0:15:07  iter: 119  total_loss: 0.561  loss_cls: 0.175  loss_box_reg: 0.312  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 1.0222  data_time: 0.0096  lr: 0.000599  max_mem: 5405M
[32m[04/20 14:39:11 d2.utils.events]: [0m eta: 0:14:46  iter: 139  total_loss: 0.602  loss_cls: 0.195  loss_box_reg: 0.338  loss_rpn_cls: 0.017  loss_rpn_loc: 0.055  time: 1.0228  data_time: 0.0095  lr: 0.000699  max_mem: 5405M
[32m[04/20 14:39:31 d2.utils.events]: [0m eta: 0:14:21  iter: 159  total_loss: 0.634  loss_cls: 0.205  loss_box_reg: 0.350  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0212  data_time: 0.0102  lr: 0.000799  max_mem: 5405M
[32m[04/20 14:39:51 d2.utils.events]: [0m eta: 0:13:59  iter: 179  total_loss: 0.592  loss_cls: 0.190  loss_box_reg: 0.336  loss_rpn_cls: 0.014  loss_rpn_loc: 0.044  time: 1.0209  data_time: 0.0099  lr: 0.000899  max_mem: 5405M
[32m[04/20 14:40:11 d2.utils.events]: [0m eta: 0:13:37  iter: 199  total_loss: 0.562  loss_cls: 0.176  loss_box_reg: 0.278  loss_rpn_cls: 0.018  loss_rpn_loc: 0.049  time: 1.0191  data_time: 0.0097  lr: 0.000999  max_mem: 5405M
[32m[04/20 14:40:32 d2.utils.events]: [0m eta: 0:13:17  iter: 219  total_loss: 0.554  loss_cls: 0.180  loss_box_reg: 0.319  loss_rpn_cls: 0.011  loss_rpn_loc: 0.046  time: 1.0199  data_time: 0.0097  lr: 0.001099  max_mem: 5405M
[32m[04/20 14:40:53 d2.utils.events]: [0m eta: 0:13:01  iter: 239  total_loss: 0.645  loss_cls: 0.211  loss_box_reg: 0.357  loss_rpn_cls: 0.014  loss_rpn_loc: 0.061  time: 1.0222  data_time: 0.0100  lr: 0.001199  max_mem: 5405M
[32m[04/20 14:41:14 d2.utils.events]: [0m eta: 0:12:41  iter: 259  total_loss: 0.510  loss_cls: 0.178  loss_box_reg: 0.284  loss_rpn_cls: 0.011  loss_rpn_loc: 0.052  time: 1.0241  data_time: 0.0114  lr: 0.001299  max_mem: 5405M
[32m[04/20 14:41:35 d2.utils.events]: [0m eta: 0:12:21  iter: 279  total_loss: 0.610  loss_cls: 0.198  loss_box_reg: 0.357  loss_rpn_cls: 0.016  loss_rpn_loc: 0.043  time: 1.0255  data_time: 0.0106  lr: 0.001399  max_mem: 5405M
[32m[04/20 14:41:55 d2.utils.events]: [0m eta: 0:12:01  iter: 299  total_loss: 0.654  loss_cls: 0.195  loss_box_reg: 0.368  loss_rpn_cls: 0.012  loss_rpn_loc: 0.058  time: 1.0250  data_time: 0.0096  lr: 0.001499  max_mem: 5405M
[32m[04/20 14:42:16 d2.utils.events]: [0m eta: 0:11:40  iter: 319  total_loss: 0.587  loss_cls: 0.194  loss_box_reg: 0.341  loss_rpn_cls: 0.011  loss_rpn_loc: 0.045  time: 1.0249  data_time: 0.0111  lr: 0.001598  max_mem: 5405M
[32m[04/20 14:42:37 d2.utils.events]: [0m eta: 0:11:20  iter: 339  total_loss: 0.611  loss_cls: 0.193  loss_box_reg: 0.343  loss_rpn_cls: 0.012  loss_rpn_loc: 0.044  time: 1.0257  data_time: 0.0109  lr: 0.001698  max_mem: 5405M
[32m[04/20 14:42:57 d2.utils.events]: [0m eta: 0:10:59  iter: 359  total_loss: 0.509  loss_cls: 0.162  loss_box_reg: 0.286  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0261  data_time: 0.0108  lr: 0.001798  max_mem: 5405M
[32m[04/20 14:43:18 d2.utils.events]: [0m eta: 0:10:39  iter: 379  total_loss: 0.572  loss_cls: 0.177  loss_box_reg: 0.337  loss_rpn_cls: 0.014  loss_rpn_loc: 0.048  time: 1.0265  data_time: 0.0106  lr: 0.001898  max_mem: 5405M
[32m[04/20 14:43:39 d2.utils.events]: [0m eta: 0:10:18  iter: 399  total_loss: 0.555  loss_cls: 0.178  loss_box_reg: 0.320  loss_rpn_cls: 0.012  loss_rpn_loc: 0.048  time: 1.0267  data_time: 0.0118  lr: 0.001998  max_mem: 5405M
[32m[04/20 14:43:59 d2.utils.events]: [0m eta: 0:09:57  iter: 419  total_loss: 0.551  loss_cls: 0.171  loss_box_reg: 0.327  loss_rpn_cls: 0.012  loss_rpn_loc: 0.046  time: 1.0262  data_time: 0.0115  lr: 0.002098  max_mem: 5405M
[32m[04/20 14:44:20 d2.utils.events]: [0m eta: 0:09:37  iter: 439  total_loss: 0.615  loss_cls: 0.191  loss_box_reg: 0.337  loss_rpn_cls: 0.012  loss_rpn_loc: 0.045  time: 1.0273  data_time: 0.0118  lr: 0.002198  max_mem: 5405M
[32m[04/20 14:44:41 d2.utils.events]: [0m eta: 0:09:16  iter: 459  total_loss: 0.596  loss_cls: 0.182  loss_box_reg: 0.334  loss_rpn_cls: 0.015  loss_rpn_loc: 0.061  time: 1.0267  data_time: 0.0108  lr: 0.002298  max_mem: 5405M
[32m[04/20 14:45:02 d2.utils.events]: [0m eta: 0:08:58  iter: 479  total_loss: 0.632  loss_cls: 0.183  loss_box_reg: 0.353  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0283  data_time: 0.0110  lr: 0.002398  max_mem: 5405M
[32m[04/20 14:45:23 d2.utils.events]: [0m eta: 0:08:38  iter: 499  total_loss: 0.570  loss_cls: 0.176  loss_box_reg: 0.329  loss_rpn_cls: 0.012  loss_rpn_loc: 0.057  time: 1.0288  data_time: 0.0122  lr: 0.002498  max_mem: 5405M
[32m[04/20 14:45:44 d2.utils.events]: [0m eta: 0:08:19  iter: 519  total_loss: 0.596  loss_cls: 0.191  loss_box_reg: 0.345  loss_rpn_cls: 0.014  loss_rpn_loc: 0.051  time: 1.0295  data_time: 0.0107  lr: 0.002597  max_mem: 5405M
[32m[04/20 14:46:05 d2.utils.events]: [0m eta: 0:07:58  iter: 539  total_loss: 0.571  loss_cls: 0.182  loss_box_reg: 0.316  loss_rpn_cls: 0.016  loss_rpn_loc: 0.052  time: 1.0297  data_time: 0.0102  lr: 0.002697  max_mem: 5405M
[32m[04/20 14:46:26 d2.utils.events]: [0m eta: 0:07:38  iter: 559  total_loss: 0.689  loss_cls: 0.216  loss_box_reg: 0.382  loss_rpn_cls: 0.012  loss_rpn_loc: 0.065  time: 1.0306  data_time: 0.0115  lr: 0.002797  max_mem: 5405M
[32m[04/20 14:46:46 d2.utils.events]: [0m eta: 0:07:17  iter: 579  total_loss: 0.650  loss_cls: 0.198  loss_box_reg: 0.348  loss_rpn_cls: 0.015  loss_rpn_loc: 0.061  time: 1.0302  data_time: 0.0104  lr: 0.002897  max_mem: 5405M
[32m[04/20 14:47:06 d2.utils.events]: [0m eta: 0:06:56  iter: 599  total_loss: 0.567  loss_cls: 0.179  loss_box_reg: 0.317  loss_rpn_cls: 0.016  loss_rpn_loc: 0.052  time: 1.0295  data_time: 0.0104  lr: 0.002997  max_mem: 5405M
[32m[04/20 14:47:26 d2.utils.events]: [0m eta: 0:06:35  iter: 619  total_loss: 0.598  loss_cls: 0.187  loss_box_reg: 0.331  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0285  data_time: 0.0117  lr: 0.003097  max_mem: 5405M
[32m[04/20 14:47:47 d2.utils.events]: [0m eta: 0:06:14  iter: 639  total_loss: 0.600  loss_cls: 0.193  loss_box_reg: 0.339  loss_rpn_cls: 0.015  loss_rpn_loc: 0.050  time: 1.0284  data_time: 0.0123  lr: 0.003197  max_mem: 5405M
[32m[04/20 14:48:07 d2.utils.events]: [0m eta: 0:05:52  iter: 659  total_loss: 0.614  loss_cls: 0.191  loss_box_reg: 0.336  loss_rpn_cls: 0.014  loss_rpn_loc: 0.066  time: 1.0275  data_time: 0.0111  lr: 0.003297  max_mem: 5405M
[32m[04/20 14:48:28 d2.utils.events]: [0m eta: 0:05:32  iter: 679  total_loss: 0.574  loss_cls: 0.190  loss_box_reg: 0.331  loss_rpn_cls: 0.010  loss_rpn_loc: 0.051  time: 1.0275  data_time: 0.0118  lr: 0.003397  max_mem: 5405M
[32m[04/20 14:48:49 d2.utils.events]: [0m eta: 0:05:12  iter: 699  total_loss: 0.598  loss_cls: 0.185  loss_box_reg: 0.324  loss_rpn_cls: 0.013  loss_rpn_loc: 0.057  time: 1.0283  data_time: 0.0103  lr: 0.003497  max_mem: 5405M
[32m[04/20 14:49:09 d2.utils.events]: [0m eta: 0:04:50  iter: 719  total_loss: 0.623  loss_cls: 0.203  loss_box_reg: 0.355  loss_rpn_cls: 0.016  loss_rpn_loc: 0.055  time: 1.0282  data_time: 0.0107  lr: 0.003596  max_mem: 5405M
[32m[04/20 14:49:30 d2.utils.events]: [0m eta: 0:04:29  iter: 739  total_loss: 0.676  loss_cls: 0.223  loss_box_reg: 0.368  loss_rpn_cls: 0.018  loss_rpn_loc: 0.053  time: 1.0283  data_time: 0.0105  lr: 0.003696  max_mem: 5405M
[32m[04/20 14:49:51 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.620  loss_cls: 0.208  loss_box_reg: 0.339  loss_rpn_cls: 0.016  loss_rpn_loc: 0.057  time: 1.0284  data_time: 0.0104  lr: 0.003796  max_mem: 5405M
[32m[04/20 14:50:11 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.654  loss_cls: 0.219  loss_box_reg: 0.368  loss_rpn_cls: 0.013  loss_rpn_loc: 0.053  time: 1.0282  data_time: 0.0119  lr: 0.003896  max_mem: 5405M
[32m[04/20 14:50:32 d2.utils.events]: [0m eta: 0:03:28  iter: 799  total_loss: 0.620  loss_cls: 0.203  loss_box_reg: 0.344  loss_rpn_cls: 0.013  loss_rpn_loc: 0.062  time: 1.0288  data_time: 0.0129  lr: 0.003996  max_mem: 5405M
[32m[04/20 14:50:53 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.613  loss_cls: 0.198  loss_box_reg: 0.347  loss_rpn_cls: 0.018  loss_rpn_loc: 0.055  time: 1.0284  data_time: 0.0110  lr: 0.004096  max_mem: 5405M
[32m[04/20 14:51:13 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.691  loss_cls: 0.214  loss_box_reg: 0.375  loss_rpn_cls: 0.020  loss_rpn_loc: 0.061  time: 1.0287  data_time: 0.0114  lr: 0.004196  max_mem: 5405M
[32m[04/20 14:51:34 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.580  loss_cls: 0.194  loss_box_reg: 0.339  loss_rpn_cls: 0.017  loss_rpn_loc: 0.045  time: 1.0284  data_time: 0.0104  lr: 0.004296  max_mem: 5405M
[32m[04/20 14:51:54 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.642  loss_cls: 0.210  loss_box_reg: 0.348  loss_rpn_cls: 0.019  loss_rpn_loc: 0.068  time: 1.0280  data_time: 0.0110  lr: 0.004396  max_mem: 5405M
[32m[04/20 14:52:15 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.571  loss_cls: 0.179  loss_box_reg: 0.310  loss_rpn_cls: 0.014  loss_rpn_loc: 0.046  time: 1.0282  data_time: 0.0109  lr: 0.004496  max_mem: 5405M
[32m[04/20 14:52:36 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.556  loss_cls: 0.182  loss_box_reg: 0.320  loss_rpn_cls: 0.012  loss_rpn_loc: 0.045  time: 1.0283  data_time: 0.0106  lr: 0.004595  max_mem: 5405M
[32m[04/20 14:52:56 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.598  loss_cls: 0.193  loss_box_reg: 0.317  loss_rpn_cls: 0.016  loss_rpn_loc: 0.060  time: 1.0285  data_time: 0.0101  lr: 0.004695  max_mem: 5405M
[32m[04/20 14:53:18 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.564  loss_cls: 0.188  loss_box_reg: 0.328  loss_rpn_cls: 0.012  loss_rpn_loc: 0.054  time: 1.0292  data_time: 0.0127  lr: 0.004795  max_mem: 5405M
[32m[04/20 14:53:38 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.629  loss_cls: 0.210  loss_box_reg: 0.346  loss_rpn_cls: 0.017  loss_rpn_loc: 0.062  time: 1.0289  data_time: 0.0112  lr: 0.004895  max_mem: 5405M
[5m[31mWARNING[0m [32m[04/20 14:54:02 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 14:54:02 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 14:54:02 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 14:54:02 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.582  loss_cls: 0.190  loss_box_reg: 0.335  loss_rpn_cls: 0.014  loss_rpn_loc: 0.059  time: 1.0289  data_time: 0.0108  lr: 0.004995  max_mem: 5405M
[32m[04/20 14:54:03 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:06 (1.0300 s / it)
[32m[04/20 14:54:03 d2.engine.hooks]: [0mTotal training time: 0:17:13 (0:00:06 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 14:54:05 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 14:54:05 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 14:54:05 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 14:54:07 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1181 s / img. ETA=0:16:39
[32m[04/20 14:54:12 d2.evaluation.evaluator]: [0mInference done 54/8355. 0.1169 s / img. ETA=0:16:27
[32m[04/20 14:54:17 d2.evaluation.evaluator]: [0mInference done 97/8355. 0.1166 s / img. ETA=0:16:20
[32m[04/20 14:54:22 d2.evaluation.evaluator]: [0mInference done 140/8355. 0.1165 s / img. ETA=0:16:14
[32m[04/20 14:54:27 d2.evaluation.evaluator]: [0mInference done 183/8355. 0.1165 s / img. ETA=0:16:09
[32m[04/20 14:54:32 d2.evaluation.evaluator]: [0mInference done 226/8355. 0.1165 s / img. ETA=0:16:04
[32m[04/20 14:54:38 d2.evaluation.evaluator]: [0mInference done 268/8355. 0.1166 s / img. ETA=0:16:01
[32m[04/20 14:54:43 d2.evaluation.evaluator]: [0mInference done 310/8355. 0.1167 s / img. ETA=0:15:57
[32m[04/20 14:54:48 d2.evaluation.evaluator]: [0mInference done 353/8355. 0.1166 s / img. ETA=0:15:51
[32m[04/20 14:54:53 d2.evaluation.evaluator]: [0mInference done 395/8355. 0.1167 s / img. ETA=0:15:47
[32m[04/20 14:54:58 d2.evaluation.evaluator]: [0mInference done 437/8355. 0.1168 s / img. ETA=0:15:42
[32m[04/20 14:55:03 d2.evaluation.evaluator]: [0mInference done 480/8355. 0.1168 s / img. ETA=0:15:37
[32m[04/20 14:55:08 d2.evaluation.evaluator]: [0mInference done 523/8355. 0.1168 s / img. ETA=0:15:32
[32m[04/20 14:55:13 d2.evaluation.evaluator]: [0mInference done 566/8355. 0.1168 s / img. ETA=0:15:27
[32m[04/20 14:55:18 d2.evaluation.evaluator]: [0mInference done 609/8355. 0.1167 s / img. ETA=0:15:21
[32m[04/20 14:55:23 d2.evaluation.evaluator]: [0mInference done 652/8355. 0.1167 s / img. ETA=0:15:16
[32m[04/20 14:55:28 d2.evaluation.evaluator]: [0mInference done 694/8355. 0.1167 s / img. ETA=0:15:11
[32m[04/20 14:55:33 d2.evaluation.evaluator]: [0mInference done 736/8355. 0.1168 s / img. ETA=0:15:07
[32m[04/20 14:55:38 d2.evaluation.evaluator]: [0mInference done 779/8355. 0.1168 s / img. ETA=0:15:01
[32m[04/20 14:55:43 d2.evaluation.evaluator]: [0mInference done 821/8355. 0.1168 s / img. ETA=0:14:56
[32m[04/20 14:55:49 d2.evaluation.evaluator]: [0mInference done 864/8355. 0.1168 s / img. ETA=0:14:51
[32m[04/20 14:55:54 d2.evaluation.evaluator]: [0mInference done 906/8355. 0.1168 s / img. ETA=0:14:47
[32m[04/20 14:55:59 d2.evaluation.evaluator]: [0mInference done 948/8355. 0.1168 s / img. ETA=0:14:42
[32m[04/20 14:56:04 d2.evaluation.evaluator]: [0mInference done 991/8355. 0.1168 s / img. ETA=0:14:36
[32m[04/20 14:56:09 d2.evaluation.evaluator]: [0mInference done 1034/8355. 0.1168 s / img. ETA=0:14:31
[32m[04/20 14:56:14 d2.evaluation.evaluator]: [0mInference done 1077/8355. 0.1168 s / img. ETA=0:14:26
[32m[04/20 14:56:19 d2.evaluation.evaluator]: [0mInference done 1120/8355. 0.1167 s / img. ETA=0:14:21
[32m[04/20 14:56:24 d2.evaluation.evaluator]: [0mInference done 1163/8355. 0.1167 s / img. ETA=0:14:15
[32m[04/20 14:56:29 d2.evaluation.evaluator]: [0mInference done 1205/8355. 0.1167 s / img. ETA=0:14:11
[32m[04/20 14:56:34 d2.evaluation.evaluator]: [0mInference done 1248/8355. 0.1167 s / img. ETA=0:14:05
[32m[04/20 14:56:39 d2.evaluation.evaluator]: [0mInference done 1290/8355. 0.1167 s / img. ETA=0:14:00
[32m[04/20 14:56:44 d2.evaluation.evaluator]: [0mInference done 1333/8355. 0.1167 s / img. ETA=0:13:55
[32m[04/20 14:56:49 d2.evaluation.evaluator]: [0mInference done 1376/8355. 0.1167 s / img. ETA=0:13:50
[32m[04/20 14:56:54 d2.evaluation.evaluator]: [0mInference done 1419/8355. 0.1167 s / img. ETA=0:13:45
[32m[04/20 14:57:00 d2.evaluation.evaluator]: [0mInference done 1462/8355. 0.1167 s / img. ETA=0:13:39
[32m[04/20 14:57:05 d2.evaluation.evaluator]: [0mInference done 1504/8355. 0.1167 s / img. ETA=0:13:35
[32m[04/20 14:57:10 d2.evaluation.evaluator]: [0mInference done 1546/8355. 0.1168 s / img. ETA=0:13:30
[32m[04/20 14:57:15 d2.evaluation.evaluator]: [0mInference done 1588/8355. 0.1168 s / img. ETA=0:13:25
[32m[04/20 14:57:20 d2.evaluation.evaluator]: [0mInference done 1630/8355. 0.1168 s / img. ETA=0:13:21
[32m[04/20 14:57:25 d2.evaluation.evaluator]: [0mInference done 1672/8355. 0.1169 s / img. ETA=0:13:16
[32m[04/20 14:57:30 d2.evaluation.evaluator]: [0mInference done 1714/8355. 0.1169 s / img. ETA=0:13:11
[32m[04/20 14:57:35 d2.evaluation.evaluator]: [0mInference done 1756/8355. 0.1169 s / img. ETA=0:13:06
[32m[04/20 14:57:40 d2.evaluation.evaluator]: [0mInference done 1798/8355. 0.1169 s / img. ETA=0:13:01
[32m[04/20 14:57:45 d2.evaluation.evaluator]: [0mInference done 1840/8355. 0.1169 s / img. ETA=0:12:56
[32m[04/20 14:57:50 d2.evaluation.evaluator]: [0mInference done 1882/8355. 0.1170 s / img. ETA=0:12:52
[32m[04/20 14:57:55 d2.evaluation.evaluator]: [0mInference done 1924/8355. 0.1170 s / img. ETA=0:12:47
[32m[04/20 14:58:00 d2.evaluation.evaluator]: [0mInference done 1966/8355. 0.1170 s / img. ETA=0:12:42
[32m[04/20 14:58:05 d2.evaluation.evaluator]: [0mInference done 2008/8355. 0.1170 s / img. ETA=0:12:37
[32m[04/20 14:58:10 d2.evaluation.evaluator]: [0mInference done 2047/8355. 0.1172 s / img. ETA=0:12:33
[32m[04/20 14:58:15 d2.evaluation.evaluator]: [0mInference done 2089/8355. 0.1172 s / img. ETA=0:12:28
[32m[04/20 14:58:20 d2.evaluation.evaluator]: [0mInference done 2131/8355. 0.1172 s / img. ETA=0:12:23
[32m[04/20 14:58:25 d2.evaluation.evaluator]: [0mInference done 2173/8355. 0.1172 s / img. ETA=0:12:18
[32m[04/20 14:58:30 d2.evaluation.evaluator]: [0mInference done 2215/8355. 0.1172 s / img. ETA=0:12:13
[32m[04/20 14:58:36 d2.evaluation.evaluator]: [0mInference done 2257/8355. 0.1172 s / img. ETA=0:12:09
[32m[04/20 14:58:41 d2.evaluation.evaluator]: [0mInference done 2299/8355. 0.1172 s / img. ETA=0:12:04
[32m[04/20 14:58:46 d2.evaluation.evaluator]: [0mInference done 2341/8355. 0.1173 s / img. ETA=0:11:59
[32m[04/20 14:58:51 d2.evaluation.evaluator]: [0mInference done 2383/8355. 0.1173 s / img. ETA=0:11:54
[32m[04/20 14:58:56 d2.evaluation.evaluator]: [0mInference done 2425/8355. 0.1173 s / img. ETA=0:11:49
[32m[04/20 14:59:01 d2.evaluation.evaluator]: [0mInference done 2467/8355. 0.1173 s / img. ETA=0:11:44
[32m[04/20 14:59:06 d2.evaluation.evaluator]: [0mInference done 2509/8355. 0.1173 s / img. ETA=0:11:39
[32m[04/20 14:59:11 d2.evaluation.evaluator]: [0mInference done 2551/8355. 0.1173 s / img. ETA=0:11:34
[32m[04/20 14:59:16 d2.evaluation.evaluator]: [0mInference done 2593/8355. 0.1173 s / img. ETA=0:11:29
[32m[04/20 14:59:21 d2.evaluation.evaluator]: [0mInference done 2635/8355. 0.1173 s / img. ETA=0:11:24
[32m[04/20 14:59:26 d2.evaluation.evaluator]: [0mInference done 2677/8355. 0.1173 s / img. ETA=0:11:19
[32m[04/20 14:59:31 d2.evaluation.evaluator]: [0mInference done 2719/8355. 0.1173 s / img. ETA=0:11:14
[32m[04/20 14:59:36 d2.evaluation.evaluator]: [0mInference done 2761/8355. 0.1173 s / img. ETA=0:11:09
[32m[04/20 14:59:41 d2.evaluation.evaluator]: [0mInference done 2803/8355. 0.1174 s / img. ETA=0:11:04
[32m[04/20 14:59:46 d2.evaluation.evaluator]: [0mInference done 2845/8355. 0.1174 s / img. ETA=0:10:59
[32m[04/20 14:59:51 d2.evaluation.evaluator]: [0mInference done 2887/8355. 0.1174 s / img. ETA=0:10:54
[32m[04/20 14:59:56 d2.evaluation.evaluator]: [0mInference done 2929/8355. 0.1174 s / img. ETA=0:10:49
[32m[04/20 15:00:01 d2.evaluation.evaluator]: [0mInference done 2971/8355. 0.1174 s / img. ETA=0:10:44
[32m[04/20 15:00:06 d2.evaluation.evaluator]: [0mInference done 3013/8355. 0.1174 s / img. ETA=0:10:39
[32m[04/20 15:00:12 d2.evaluation.evaluator]: [0mInference done 3055/8355. 0.1174 s / img. ETA=0:10:34
[32m[04/20 15:00:17 d2.evaluation.evaluator]: [0mInference done 3097/8355. 0.1174 s / img. ETA=0:10:29
[32m[04/20 15:00:22 d2.evaluation.evaluator]: [0mInference done 3139/8355. 0.1174 s / img. ETA=0:10:24
[32m[04/20 15:00:27 d2.evaluation.evaluator]: [0mInference done 3181/8355. 0.1174 s / img. ETA=0:10:19
[32m[04/20 15:00:32 d2.evaluation.evaluator]: [0mInference done 3223/8355. 0.1174 s / img. ETA=0:10:14
[32m[04/20 15:00:37 d2.evaluation.evaluator]: [0mInference done 3265/8355. 0.1174 s / img. ETA=0:10:09
[32m[04/20 15:00:42 d2.evaluation.evaluator]: [0mInference done 3307/8355. 0.1174 s / img. ETA=0:10:04
[32m[04/20 15:00:47 d2.evaluation.evaluator]: [0mInference done 3349/8355. 0.1174 s / img. ETA=0:09:59
[32m[04/20 15:00:52 d2.evaluation.evaluator]: [0mInference done 3391/8355. 0.1174 s / img. ETA=0:09:54
[32m[04/20 15:00:57 d2.evaluation.evaluator]: [0mInference done 3433/8355. 0.1174 s / img. ETA=0:09:49
[32m[04/20 15:01:02 d2.evaluation.evaluator]: [0mInference done 3475/8355. 0.1174 s / img. ETA=0:09:44
[32m[04/20 15:01:07 d2.evaluation.evaluator]: [0mInference done 3517/8355. 0.1174 s / img. ETA=0:09:39
[32m[04/20 15:01:12 d2.evaluation.evaluator]: [0mInference done 3559/8355. 0.1174 s / img. ETA=0:09:34
[32m[04/20 15:01:17 d2.evaluation.evaluator]: [0mInference done 3601/8355. 0.1174 s / img. ETA=0:09:29
[32m[04/20 15:01:22 d2.evaluation.evaluator]: [0mInference done 3643/8355. 0.1174 s / img. ETA=0:09:24
[32m[04/20 15:01:27 d2.evaluation.evaluator]: [0mInference done 3685/8355. 0.1174 s / img. ETA=0:09:19
[32m[04/20 15:01:32 d2.evaluation.evaluator]: [0mInference done 3727/8355. 0.1174 s / img. ETA=0:09:14
[32m[04/20 15:01:37 d2.evaluation.evaluator]: [0mInference done 3769/8355. 0.1174 s / img. ETA=0:09:09
[32m[04/20 15:01:42 d2.evaluation.evaluator]: [0mInference done 3811/8355. 0.1175 s / img. ETA=0:09:04
[32m[04/20 15:01:47 d2.evaluation.evaluator]: [0mInference done 3853/8355. 0.1175 s / img. ETA=0:08:59
[32m[04/20 15:01:52 d2.evaluation.evaluator]: [0mInference done 3895/8355. 0.1175 s / img. ETA=0:08:54
[32m[04/20 15:01:57 d2.evaluation.evaluator]: [0mInference done 3937/8355. 0.1175 s / img. ETA=0:08:49
[32m[04/20 15:02:03 d2.evaluation.evaluator]: [0mInference done 3979/8355. 0.1175 s / img. ETA=0:08:44
[32m[04/20 15:02:08 d2.evaluation.evaluator]: [0mInference done 4021/8355. 0.1175 s / img. ETA=0:08:39
[32m[04/20 15:02:13 d2.evaluation.evaluator]: [0mInference done 4063/8355. 0.1175 s / img. ETA=0:08:34
[32m[04/20 15:02:18 d2.evaluation.evaluator]: [0mInference done 4105/8355. 0.1175 s / img. ETA=0:08:29
[32m[04/20 15:02:23 d2.evaluation.evaluator]: [0mInference done 4147/8355. 0.1175 s / img. ETA=0:08:24
[32m[04/20 15:02:28 d2.evaluation.evaluator]: [0mInference done 4189/8355. 0.1175 s / img. ETA=0:08:19
[32m[04/20 15:02:33 d2.evaluation.evaluator]: [0mInference done 4231/8355. 0.1175 s / img. ETA=0:08:14
[32m[04/20 15:02:38 d2.evaluation.evaluator]: [0mInference done 4273/8355. 0.1175 s / img. ETA=0:08:09
[32m[04/20 15:02:43 d2.evaluation.evaluator]: [0mInference done 4315/8355. 0.1175 s / img. ETA=0:08:04
[32m[04/20 15:02:48 d2.evaluation.evaluator]: [0mInference done 4357/8355. 0.1175 s / img. ETA=0:07:59
[32m[04/20 15:02:53 d2.evaluation.evaluator]: [0mInference done 4399/8355. 0.1175 s / img. ETA=0:07:54
[32m[04/20 15:02:58 d2.evaluation.evaluator]: [0mInference done 4441/8355. 0.1175 s / img. ETA=0:07:49
[32m[04/20 15:03:03 d2.evaluation.evaluator]: [0mInference done 4483/8355. 0.1175 s / img. ETA=0:07:44
[32m[04/20 15:03:08 d2.evaluation.evaluator]: [0mInference done 4525/8355. 0.1175 s / img. ETA=0:07:39
[32m[04/20 15:03:13 d2.evaluation.evaluator]: [0mInference done 4567/8355. 0.1175 s / img. ETA=0:07:34
[32m[04/20 15:03:18 d2.evaluation.evaluator]: [0mInference done 4609/8355. 0.1175 s / img. ETA=0:07:29
[32m[04/20 15:03:24 d2.evaluation.evaluator]: [0mInference done 4651/8355. 0.1175 s / img. ETA=0:07:24
[32m[04/20 15:03:29 d2.evaluation.evaluator]: [0mInference done 4693/8355. 0.1175 s / img. ETA=0:07:19
[32m[04/20 15:03:34 d2.evaluation.evaluator]: [0mInference done 4735/8355. 0.1175 s / img. ETA=0:07:14
[32m[04/20 15:03:39 d2.evaluation.evaluator]: [0mInference done 4777/8355. 0.1175 s / img. ETA=0:07:09
[32m[04/20 15:03:44 d2.evaluation.evaluator]: [0mInference done 4819/8355. 0.1175 s / img. ETA=0:07:04
[32m[04/20 15:03:49 d2.evaluation.evaluator]: [0mInference done 4861/8355. 0.1175 s / img. ETA=0:06:59
[32m[04/20 15:03:54 d2.evaluation.evaluator]: [0mInference done 4903/8355. 0.1175 s / img. ETA=0:06:54
[32m[04/20 15:03:59 d2.evaluation.evaluator]: [0mInference done 4945/8355. 0.1175 s / img. ETA=0:06:49
[32m[04/20 15:04:04 d2.evaluation.evaluator]: [0mInference done 4987/8355. 0.1176 s / img. ETA=0:06:44
[32m[04/20 15:04:09 d2.evaluation.evaluator]: [0mInference done 5029/8355. 0.1176 s / img. ETA=0:06:39
[32m[04/20 15:04:14 d2.evaluation.evaluator]: [0mInference done 5071/8355. 0.1176 s / img. ETA=0:06:34
[32m[04/20 15:04:19 d2.evaluation.evaluator]: [0mInference done 5113/8355. 0.1176 s / img. ETA=0:06:28
[32m[04/20 15:04:24 d2.evaluation.evaluator]: [0mInference done 5155/8355. 0.1176 s / img. ETA=0:06:23
[32m[04/20 15:04:29 d2.evaluation.evaluator]: [0mInference done 5197/8355. 0.1176 s / img. ETA=0:06:18
[32m[04/20 15:04:34 d2.evaluation.evaluator]: [0mInference done 5239/8355. 0.1176 s / img. ETA=0:06:13
[32m[04/20 15:04:39 d2.evaluation.evaluator]: [0mInference done 5281/8355. 0.1176 s / img. ETA=0:06:08
[32m[04/20 15:04:44 d2.evaluation.evaluator]: [0mInference done 5323/8355. 0.1176 s / img. ETA=0:06:03
[32m[04/20 15:04:50 d2.evaluation.evaluator]: [0mInference done 5365/8355. 0.1176 s / img. ETA=0:05:58
[32m[04/20 15:04:55 d2.evaluation.evaluator]: [0mInference done 5407/8355. 0.1176 s / img. ETA=0:05:53
[32m[04/20 15:05:00 d2.evaluation.evaluator]: [0mInference done 5449/8355. 0.1176 s / img. ETA=0:05:48
[32m[04/20 15:05:05 d2.evaluation.evaluator]: [0mInference done 5491/8355. 0.1176 s / img. ETA=0:05:43
[32m[04/20 15:05:10 d2.evaluation.evaluator]: [0mInference done 5533/8355. 0.1176 s / img. ETA=0:05:38
[32m[04/20 15:05:15 d2.evaluation.evaluator]: [0mInference done 5575/8355. 0.1176 s / img. ETA=0:05:33
[32m[04/20 15:05:20 d2.evaluation.evaluator]: [0mInference done 5617/8355. 0.1176 s / img. ETA=0:05:28
[32m[04/20 15:05:25 d2.evaluation.evaluator]: [0mInference done 5659/8355. 0.1176 s / img. ETA=0:05:23
[32m[04/20 15:05:30 d2.evaluation.evaluator]: [0mInference done 5701/8355. 0.1176 s / img. ETA=0:05:18
[32m[04/20 15:05:35 d2.evaluation.evaluator]: [0mInference done 5743/8355. 0.1176 s / img. ETA=0:05:13
[32m[04/20 15:05:40 d2.evaluation.evaluator]: [0mInference done 5785/8355. 0.1176 s / img. ETA=0:05:08
[32m[04/20 15:05:45 d2.evaluation.evaluator]: [0mInference done 5827/8355. 0.1176 s / img. ETA=0:05:03
[32m[04/20 15:05:50 d2.evaluation.evaluator]: [0mInference done 5869/8355. 0.1176 s / img. ETA=0:04:58
[32m[04/20 15:05:55 d2.evaluation.evaluator]: [0mInference done 5911/8355. 0.1176 s / img. ETA=0:04:53
[32m[04/20 15:06:00 d2.evaluation.evaluator]: [0mInference done 5953/8355. 0.1176 s / img. ETA=0:04:48
[32m[04/20 15:06:06 d2.evaluation.evaluator]: [0mInference done 5995/8355. 0.1176 s / img. ETA=0:04:43
[32m[04/20 15:06:11 d2.evaluation.evaluator]: [0mInference done 6037/8355. 0.1176 s / img. ETA=0:04:38
[32m[04/20 15:06:16 d2.evaluation.evaluator]: [0mInference done 6079/8355. 0.1177 s / img. ETA=0:04:33
[32m[04/20 15:06:21 d2.evaluation.evaluator]: [0mInference done 6121/8355. 0.1177 s / img. ETA=0:04:28
[32m[04/20 15:06:26 d2.evaluation.evaluator]: [0mInference done 6163/8355. 0.1177 s / img. ETA=0:04:23
[32m[04/20 15:06:31 d2.evaluation.evaluator]: [0mInference done 6204/8355. 0.1177 s / img. ETA=0:04:18
[32m[04/20 15:06:36 d2.evaluation.evaluator]: [0mInference done 6246/8355. 0.1177 s / img. ETA=0:04:13
[32m[04/20 15:06:41 d2.evaluation.evaluator]: [0mInference done 6288/8355. 0.1177 s / img. ETA=0:04:08
[32m[04/20 15:06:46 d2.evaluation.evaluator]: [0mInference done 6330/8355. 0.1177 s / img. ETA=0:04:03
[32m[04/20 15:06:51 d2.evaluation.evaluator]: [0mInference done 6372/8355. 0.1177 s / img. ETA=0:03:58
[32m[04/20 15:06:56 d2.evaluation.evaluator]: [0mInference done 6414/8355. 0.1177 s / img. ETA=0:03:53
[32m[04/20 15:07:01 d2.evaluation.evaluator]: [0mInference done 6456/8355. 0.1177 s / img. ETA=0:03:48
[32m[04/20 15:07:06 d2.evaluation.evaluator]: [0mInference done 6498/8355. 0.1177 s / img. ETA=0:03:43
[32m[04/20 15:07:11 d2.evaluation.evaluator]: [0mInference done 6540/8355. 0.1177 s / img. ETA=0:03:38
[32m[04/20 15:07:16 d2.evaluation.evaluator]: [0mInference done 6582/8355. 0.1177 s / img. ETA=0:03:32
[32m[04/20 15:07:21 d2.evaluation.evaluator]: [0mInference done 6624/8355. 0.1177 s / img. ETA=0:03:27
[32m[04/20 15:07:26 d2.evaluation.evaluator]: [0mInference done 6666/8355. 0.1177 s / img. ETA=0:03:22
[32m[04/20 15:07:31 d2.evaluation.evaluator]: [0mInference done 6708/8355. 0.1177 s / img. ETA=0:03:17
[32m[04/20 15:07:36 d2.evaluation.evaluator]: [0mInference done 6750/8355. 0.1177 s / img. ETA=0:03:12
[32m[04/20 15:07:41 d2.evaluation.evaluator]: [0mInference done 6792/8355. 0.1177 s / img. ETA=0:03:07
[32m[04/20 15:07:47 d2.evaluation.evaluator]: [0mInference done 6834/8355. 0.1177 s / img. ETA=0:03:02
[32m[04/20 15:07:52 d2.evaluation.evaluator]: [0mInference done 6876/8355. 0.1177 s / img. ETA=0:02:57
[32m[04/20 15:07:57 d2.evaluation.evaluator]: [0mInference done 6918/8355. 0.1177 s / img. ETA=0:02:52
[32m[04/20 15:08:02 d2.evaluation.evaluator]: [0mInference done 6960/8355. 0.1177 s / img. ETA=0:02:47
[32m[04/20 15:08:07 d2.evaluation.evaluator]: [0mInference done 7002/8355. 0.1177 s / img. ETA=0:02:42
[32m[04/20 15:08:12 d2.evaluation.evaluator]: [0mInference done 7044/8355. 0.1177 s / img. ETA=0:02:37
[32m[04/20 15:08:17 d2.evaluation.evaluator]: [0mInference done 7086/8355. 0.1177 s / img. ETA=0:02:32
[32m[04/20 15:08:22 d2.evaluation.evaluator]: [0mInference done 7128/8355. 0.1177 s / img. ETA=0:02:27
[32m[04/20 15:08:27 d2.evaluation.evaluator]: [0mInference done 7169/8355. 0.1177 s / img. ETA=0:02:22
[32m[04/20 15:08:32 d2.evaluation.evaluator]: [0mInference done 7210/8355. 0.1177 s / img. ETA=0:02:17
[32m[04/20 15:08:37 d2.evaluation.evaluator]: [0mInference done 7252/8355. 0.1177 s / img. ETA=0:02:12
[32m[04/20 15:08:42 d2.evaluation.evaluator]: [0mInference done 7293/8355. 0.1177 s / img. ETA=0:02:07
[32m[04/20 15:08:47 d2.evaluation.evaluator]: [0mInference done 7334/8355. 0.1177 s / img. ETA=0:02:02
[32m[04/20 15:08:52 d2.evaluation.evaluator]: [0mInference done 7376/8355. 0.1178 s / img. ETA=0:01:57
[32m[04/20 15:08:57 d2.evaluation.evaluator]: [0mInference done 7418/8355. 0.1178 s / img. ETA=0:01:52
[32m[04/20 15:09:03 d2.evaluation.evaluator]: [0mInference done 7460/8355. 0.1178 s / img. ETA=0:01:47
[32m[04/20 15:09:08 d2.evaluation.evaluator]: [0mInference done 7502/8355. 0.1178 s / img. ETA=0:01:42
[32m[04/20 15:09:13 d2.evaluation.evaluator]: [0mInference done 7544/8355. 0.1178 s / img. ETA=0:01:37
[32m[04/20 15:09:18 d2.evaluation.evaluator]: [0mInference done 7586/8355. 0.1178 s / img. ETA=0:01:32
[32m[04/20 15:09:23 d2.evaluation.evaluator]: [0mInference done 7628/8355. 0.1178 s / img. ETA=0:01:27
[32m[04/20 15:09:28 d2.evaluation.evaluator]: [0mInference done 7670/8355. 0.1178 s / img. ETA=0:01:22
[32m[04/20 15:09:33 d2.evaluation.evaluator]: [0mInference done 7712/8355. 0.1178 s / img. ETA=0:01:17
[32m[04/20 15:09:38 d2.evaluation.evaluator]: [0mInference done 7754/8355. 0.1178 s / img. ETA=0:01:12
[32m[04/20 15:09:43 d2.evaluation.evaluator]: [0mInference done 7796/8355. 0.1178 s / img. ETA=0:01:07
[32m[04/20 15:09:48 d2.evaluation.evaluator]: [0mInference done 7838/8355. 0.1178 s / img. ETA=0:01:02
[32m[04/20 15:09:53 d2.evaluation.evaluator]: [0mInference done 7880/8355. 0.1178 s / img. ETA=0:00:57
[32m[04/20 15:09:58 d2.evaluation.evaluator]: [0mInference done 7922/8355. 0.1178 s / img. ETA=0:00:52
[32m[04/20 15:10:03 d2.evaluation.evaluator]: [0mInference done 7964/8355. 0.1178 s / img. ETA=0:00:47
[32m[04/20 15:10:09 d2.evaluation.evaluator]: [0mInference done 8006/8355. 0.1178 s / img. ETA=0:00:41
[32m[04/20 15:10:14 d2.evaluation.evaluator]: [0mInference done 8048/8355. 0.1178 s / img. ETA=0:00:36
[32m[04/20 15:10:19 d2.evaluation.evaluator]: [0mInference done 8090/8355. 0.1178 s / img. ETA=0:00:31
[32m[04/20 15:10:24 d2.evaluation.evaluator]: [0mInference done 8132/8355. 0.1178 s / img. ETA=0:00:26
[32m[04/20 15:10:29 d2.evaluation.evaluator]: [0mInference done 8174/8355. 0.1178 s / img. ETA=0:00:21
[32m[04/20 15:10:34 d2.evaluation.evaluator]: [0mInference done 8216/8355. 0.1178 s / img. ETA=0:00:16
[32m[04/20 15:10:39 d2.evaluation.evaluator]: [0mInference done 8258/8355. 0.1178 s / img. ETA=0:00:11
[32m[04/20 15:10:44 d2.evaluation.evaluator]: [0mInference done 8300/8355. 0.1178 s / img. ETA=0:00:06
[32m[04/20 15:10:49 d2.evaluation.evaluator]: [0mInference done 8342/8355. 0.1178 s / img. ETA=0:00:01
[32m[04/20 15:10:50 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:44.210114 (0.120265 s / img per device, on 1 devices)
[32m[04/20 15:10:50 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:23 (0.117795 s / img per device, on 1 devices)
[32m[04/20 15:10:51 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 15:10:51 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 15:10:51 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.59s).
Accumulating evaluation results...
DONE (t=2.20s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.379
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.696
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.362
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.268
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.518
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.156
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.428
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.440
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.334
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.584
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.717
[32m[04/20 15:11:13 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 37.888 | 69.632 | 36.222 | 26.791 | 51.802 | 67.491 |
[32m[04/20 15:11:13 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 38.299 | bicycle       | 28.512 | car            | 46.853 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 15:11:14 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 15:11:14 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 15:11:14 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 15:11:16 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1199 s / img. ETA=0:02:32
[32m[04/20 15:11:21 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1190 s / img. ETA=0:02:26
[32m[04/20 15:11:26 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1190 s / img. ETA=0:02:21
[32m[04/20 15:11:31 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1187 s / img. ETA=0:02:15
[32m[04/20 15:11:36 d2.evaluation.evaluator]: [0mInference done 179/1257. 0.1187 s / img. ETA=0:02:10
[32m[04/20 15:11:41 d2.evaluation.evaluator]: [0mInference done 221/1257. 0.1186 s / img. ETA=0:02:05
[32m[04/20 15:11:46 d2.evaluation.evaluator]: [0mInference done 263/1257. 0.1186 s / img. ETA=0:02:00
[32m[04/20 15:11:51 d2.evaluation.evaluator]: [0mInference done 305/1257. 0.1186 s / img. ETA=0:01:55
[32m[04/20 15:11:56 d2.evaluation.evaluator]: [0mInference done 347/1257. 0.1185 s / img. ETA=0:01:50
[32m[04/20 15:12:02 d2.evaluation.evaluator]: [0mInference done 389/1257. 0.1185 s / img. ETA=0:01:45
[32m[04/20 15:12:07 d2.evaluation.evaluator]: [0mInference done 431/1257. 0.1185 s / img. ETA=0:01:39
[32m[04/20 15:12:12 d2.evaluation.evaluator]: [0mInference done 473/1257. 0.1185 s / img. ETA=0:01:34
[32m[04/20 15:12:17 d2.evaluation.evaluator]: [0mInference done 515/1257. 0.1185 s / img. ETA=0:01:29
[32m[04/20 15:12:22 d2.evaluation.evaluator]: [0mInference done 557/1257. 0.1185 s / img. ETA=0:01:24
[32m[04/20 15:12:27 d2.evaluation.evaluator]: [0mInference done 599/1257. 0.1185 s / img. ETA=0:01:19
[32m[04/20 15:12:32 d2.evaluation.evaluator]: [0mInference done 641/1257. 0.1185 s / img. ETA=0:01:14
[32m[04/20 15:12:37 d2.evaluation.evaluator]: [0mInference done 683/1257. 0.1185 s / img. ETA=0:01:09
[32m[04/20 15:12:42 d2.evaluation.evaluator]: [0mInference done 725/1257. 0.1185 s / img. ETA=0:01:04
[32m[04/20 15:12:47 d2.evaluation.evaluator]: [0mInference done 767/1257. 0.1185 s / img. ETA=0:00:59
[32m[04/20 15:12:52 d2.evaluation.evaluator]: [0mInference done 809/1257. 0.1185 s / img. ETA=0:00:54
[32m[04/20 15:12:57 d2.evaluation.evaluator]: [0mInference done 850/1257. 0.1185 s / img. ETA=0:00:49
[32m[04/20 15:13:02 d2.evaluation.evaluator]: [0mInference done 892/1257. 0.1185 s / img. ETA=0:00:44
[32m[04/20 15:13:08 d2.evaluation.evaluator]: [0mInference done 934/1257. 0.1185 s / img. ETA=0:00:39
[32m[04/20 15:13:13 d2.evaluation.evaluator]: [0mInference done 976/1257. 0.1185 s / img. ETA=0:00:34
[32m[04/20 15:13:18 d2.evaluation.evaluator]: [0mInference done 1018/1257. 0.1185 s / img. ETA=0:00:28
[32m[04/20 15:13:23 d2.evaluation.evaluator]: [0mInference done 1060/1257. 0.1185 s / img. ETA=0:00:23
[32m[04/20 15:13:28 d2.evaluation.evaluator]: [0mInference done 1102/1257. 0.1185 s / img. ETA=0:00:18
[32m[04/20 15:13:33 d2.evaluation.evaluator]: [0mInference done 1144/1257. 0.1185 s / img. ETA=0:00:13
[32m[04/20 15:13:38 d2.evaluation.evaluator]: [0mInference done 1186/1257. 0.1185 s / img. ETA=0:00:08
[32m[04/20 15:13:43 d2.evaluation.evaluator]: [0mInference done 1228/1257. 0.1185 s / img. ETA=0:00:03
[32m[04/20 15:13:47 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:31.542958 (0.121041 s / img per device, on 1 devices)
[32m[04/20 15:13:47 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:28 (0.118463 s / img per device, on 1 devices)
[32m[04/20 15:13:47 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 15:13:47 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 15:13:47 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.26s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.94s).
Accumulating evaluation results...
DONE (t=0.38s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.565
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.255
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.353
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.470
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.143
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.349
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.351
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.248
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.506
[32m[04/20 15:13:50 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 28.845 | 56.477 | 25.539 | 18.269 | 35.342 | 47.025 |
[32m[04/20 15:13:50 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 30.141 | bicycle       | 10.912 | car            | 45.482 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  16  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 15:13:51 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 15:13:52 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 15:13:52 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 15:13:52 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 15:13:52 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 15:13:52 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 15:13:52 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 15:14:13 d2.utils.events]: [0m eta: 0:17:04  iter: 19  total_loss: 0.647  loss_cls: 0.215  loss_box_reg: 0.325  loss_rpn_cls: 0.018  loss_rpn_loc: 0.063  time: 1.0372  data_time: 0.0343  lr: 0.000100  max_mem: 5405M
[32m[04/20 15:14:34 d2.utils.events]: [0m eta: 0:16:32  iter: 39  total_loss: 0.625  loss_cls: 0.196  loss_box_reg: 0.343  loss_rpn_cls: 0.015  loss_rpn_loc: 0.051  time: 1.0272  data_time: 0.0116  lr: 0.000200  max_mem: 5405M
[32m[04/20 15:14:54 d2.utils.events]: [0m eta: 0:16:12  iter: 59  total_loss: 0.603  loss_cls: 0.187  loss_box_reg: 0.338  loss_rpn_cls: 0.018  loss_rpn_loc: 0.052  time: 1.0217  data_time: 0.0114  lr: 0.000300  max_mem: 5405M
[32m[04/20 15:15:14 d2.utils.events]: [0m eta: 0:15:43  iter: 79  total_loss: 0.608  loss_cls: 0.192  loss_box_reg: 0.339  loss_rpn_cls: 0.016  loss_rpn_loc: 0.053  time: 1.0199  data_time: 0.0112  lr: 0.000400  max_mem: 5405M
[32m[04/20 15:15:35 d2.utils.events]: [0m eta: 0:15:26  iter: 99  total_loss: 0.609  loss_cls: 0.185  loss_box_reg: 0.344  loss_rpn_cls: 0.011  loss_rpn_loc: 0.054  time: 1.0221  data_time: 0.0118  lr: 0.000500  max_mem: 5405M
[32m[04/20 15:15:56 d2.utils.events]: [0m eta: 0:15:26  iter: 119  total_loss: 0.577  loss_cls: 0.187  loss_box_reg: 0.326  loss_rpn_cls: 0.013  loss_rpn_loc: 0.055  time: 1.0297  data_time: 0.0117  lr: 0.000599  max_mem: 5405M
[32m[04/20 15:16:17 d2.utils.events]: [0m eta: 0:15:03  iter: 139  total_loss: 0.684  loss_cls: 0.227  loss_box_reg: 0.351  loss_rpn_cls: 0.013  loss_rpn_loc: 0.057  time: 1.0312  data_time: 0.0110  lr: 0.000699  max_mem: 5405M
[32m[04/20 15:16:38 d2.utils.events]: [0m eta: 0:14:45  iter: 159  total_loss: 0.643  loss_cls: 0.213  loss_box_reg: 0.354  loss_rpn_cls: 0.013  loss_rpn_loc: 0.048  time: 1.0332  data_time: 0.0113  lr: 0.000799  max_mem: 5405M
[32m[04/20 15:16:59 d2.utils.events]: [0m eta: 0:14:24  iter: 179  total_loss: 0.626  loss_cls: 0.199  loss_box_reg: 0.354  loss_rpn_cls: 0.017  loss_rpn_loc: 0.053  time: 1.0326  data_time: 0.0121  lr: 0.000899  max_mem: 5405M
[32m[04/20 15:17:20 d2.utils.events]: [0m eta: 0:14:03  iter: 199  total_loss: 0.561  loss_cls: 0.168  loss_box_reg: 0.313  loss_rpn_cls: 0.013  loss_rpn_loc: 0.044  time: 1.0332  data_time: 0.0118  lr: 0.000999  max_mem: 5405M
[32m[04/20 15:17:40 d2.utils.events]: [0m eta: 0:13:41  iter: 219  total_loss: 0.551  loss_cls: 0.173  loss_box_reg: 0.299  loss_rpn_cls: 0.010  loss_rpn_loc: 0.044  time: 1.0332  data_time: 0.0113  lr: 0.001099  max_mem: 5405M
[32m[04/20 15:18:01 d2.utils.events]: [0m eta: 0:13:19  iter: 239  total_loss: 0.654  loss_cls: 0.202  loss_box_reg: 0.377  loss_rpn_cls: 0.015  loss_rpn_loc: 0.058  time: 1.0320  data_time: 0.0110  lr: 0.001199  max_mem: 5405M
[32m[04/20 15:18:22 d2.utils.events]: [0m eta: 0:12:58  iter: 259  total_loss: 0.538  loss_cls: 0.169  loss_box_reg: 0.305  loss_rpn_cls: 0.012  loss_rpn_loc: 0.042  time: 1.0324  data_time: 0.0110  lr: 0.001299  max_mem: 5405M
[32m[04/20 15:18:42 d2.utils.events]: [0m eta: 0:12:36  iter: 279  total_loss: 0.541  loss_cls: 0.174  loss_box_reg: 0.313  loss_rpn_cls: 0.011  loss_rpn_loc: 0.054  time: 1.0310  data_time: 0.0110  lr: 0.001399  max_mem: 5405M
[32m[04/20 15:19:03 d2.utils.events]: [0m eta: 0:12:16  iter: 299  total_loss: 0.562  loss_cls: 0.183  loss_box_reg: 0.319  loss_rpn_cls: 0.013  loss_rpn_loc: 0.054  time: 1.0326  data_time: 0.0120  lr: 0.001499  max_mem: 5405M
[32m[04/20 15:19:24 d2.utils.events]: [0m eta: 0:11:54  iter: 319  total_loss: 0.644  loss_cls: 0.201  loss_box_reg: 0.354  loss_rpn_cls: 0.013  loss_rpn_loc: 0.064  time: 1.0323  data_time: 0.0122  lr: 0.001598  max_mem: 5405M
[32m[04/20 15:19:44 d2.utils.events]: [0m eta: 0:11:33  iter: 339  total_loss: 0.588  loss_cls: 0.181  loss_box_reg: 0.335  loss_rpn_cls: 0.010  loss_rpn_loc: 0.053  time: 1.0316  data_time: 0.0120  lr: 0.001698  max_mem: 5405M
[32m[04/20 15:20:05 d2.utils.events]: [0m eta: 0:11:12  iter: 359  total_loss: 0.569  loss_cls: 0.185  loss_box_reg: 0.309  loss_rpn_cls: 0.012  loss_rpn_loc: 0.047  time: 1.0325  data_time: 0.0112  lr: 0.001798  max_mem: 5405M
[32m[04/20 15:20:26 d2.utils.events]: [0m eta: 0:10:50  iter: 379  total_loss: 0.556  loss_cls: 0.190  loss_box_reg: 0.297  loss_rpn_cls: 0.009  loss_rpn_loc: 0.041  time: 1.0323  data_time: 0.0127  lr: 0.001898  max_mem: 5405M
[32m[04/20 15:20:47 d2.utils.events]: [0m eta: 0:10:30  iter: 399  total_loss: 0.637  loss_cls: 0.193  loss_box_reg: 0.358  loss_rpn_cls: 0.014  loss_rpn_loc: 0.046  time: 1.0327  data_time: 0.0108  lr: 0.001998  max_mem: 5405M
[32m[04/20 15:21:08 d2.utils.events]: [0m eta: 0:10:10  iter: 419  total_loss: 0.581  loss_cls: 0.185  loss_box_reg: 0.343  loss_rpn_cls: 0.010  loss_rpn_loc: 0.044  time: 1.0333  data_time: 0.0111  lr: 0.002098  max_mem: 5405M
[32m[04/20 15:21:28 d2.utils.events]: [0m eta: 0:09:48  iter: 439  total_loss: 0.552  loss_cls: 0.177  loss_box_reg: 0.308  loss_rpn_cls: 0.009  loss_rpn_loc: 0.054  time: 1.0331  data_time: 0.0121  lr: 0.002198  max_mem: 5405M
[32m[04/20 15:21:48 d2.utils.events]: [0m eta: 0:09:25  iter: 459  total_loss: 0.557  loss_cls: 0.169  loss_box_reg: 0.300  loss_rpn_cls: 0.014  loss_rpn_loc: 0.059  time: 1.0320  data_time: 0.0109  lr: 0.002298  max_mem: 5405M
[32m[04/20 15:22:09 d2.utils.events]: [0m eta: 0:09:05  iter: 479  total_loss: 0.571  loss_cls: 0.171  loss_box_reg: 0.303  loss_rpn_cls: 0.015  loss_rpn_loc: 0.055  time: 1.0323  data_time: 0.0120  lr: 0.002398  max_mem: 5405M
[32m[04/20 15:22:30 d2.utils.events]: [0m eta: 0:08:43  iter: 499  total_loss: 0.637  loss_cls: 0.199  loss_box_reg: 0.364  loss_rpn_cls: 0.013  loss_rpn_loc: 0.060  time: 1.0320  data_time: 0.0117  lr: 0.002498  max_mem: 5405M
[32m[04/20 15:22:51 d2.utils.events]: [0m eta: 0:08:24  iter: 519  total_loss: 0.582  loss_cls: 0.184  loss_box_reg: 0.328  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0329  data_time: 0.0115  lr: 0.002597  max_mem: 5405M
[32m[04/20 15:23:12 d2.utils.events]: [0m eta: 0:08:03  iter: 539  total_loss: 0.586  loss_cls: 0.172  loss_box_reg: 0.331  loss_rpn_cls: 0.012  loss_rpn_loc: 0.058  time: 1.0325  data_time: 0.0103  lr: 0.002697  max_mem: 5405M
[32m[04/20 15:23:32 d2.utils.events]: [0m eta: 0:07:42  iter: 559  total_loss: 0.674  loss_cls: 0.208  loss_box_reg: 0.381  loss_rpn_cls: 0.018  loss_rpn_loc: 0.066  time: 1.0329  data_time: 0.0105  lr: 0.002797  max_mem: 5405M
[32m[04/20 15:23:53 d2.utils.events]: [0m eta: 0:07:21  iter: 579  total_loss: 0.634  loss_cls: 0.200  loss_box_reg: 0.363  loss_rpn_cls: 0.015  loss_rpn_loc: 0.046  time: 1.0332  data_time: 0.0120  lr: 0.002897  max_mem: 5405M
[32m[04/20 15:24:15 d2.utils.events]: [0m eta: 0:07:00  iter: 599  total_loss: 0.603  loss_cls: 0.201  loss_box_reg: 0.343  loss_rpn_cls: 0.019  loss_rpn_loc: 0.047  time: 1.0340  data_time: 0.0125  lr: 0.002997  max_mem: 5405M
[32m[04/20 15:24:35 d2.utils.events]: [0m eta: 0:06:39  iter: 619  total_loss: 0.522  loss_cls: 0.163  loss_box_reg: 0.294  loss_rpn_cls: 0.013  loss_rpn_loc: 0.049  time: 1.0339  data_time: 0.0108  lr: 0.003097  max_mem: 5405M
[32m[04/20 15:24:56 d2.utils.events]: [0m eta: 0:06:19  iter: 639  total_loss: 0.585  loss_cls: 0.178  loss_box_reg: 0.318  loss_rpn_cls: 0.015  loss_rpn_loc: 0.060  time: 1.0346  data_time: 0.0116  lr: 0.003197  max_mem: 5405M
[32m[04/20 15:25:17 d2.utils.events]: [0m eta: 0:05:58  iter: 659  total_loss: 0.616  loss_cls: 0.193  loss_box_reg: 0.352  loss_rpn_cls: 0.013  loss_rpn_loc: 0.052  time: 1.0350  data_time: 0.0113  lr: 0.003297  max_mem: 5405M
[32m[04/20 15:25:39 d2.utils.events]: [0m eta: 0:05:37  iter: 679  total_loss: 0.672  loss_cls: 0.206  loss_box_reg: 0.373  loss_rpn_cls: 0.012  loss_rpn_loc: 0.055  time: 1.0356  data_time: 0.0107  lr: 0.003397  max_mem: 5405M
[32m[04/20 15:25:59 d2.utils.events]: [0m eta: 0:05:16  iter: 699  total_loss: 0.571  loss_cls: 0.183  loss_box_reg: 0.306  loss_rpn_cls: 0.017  loss_rpn_loc: 0.055  time: 1.0351  data_time: 0.0109  lr: 0.003497  max_mem: 5405M
[32m[04/20 15:26:19 d2.utils.events]: [0m eta: 0:04:55  iter: 719  total_loss: 0.573  loss_cls: 0.189  loss_box_reg: 0.328  loss_rpn_cls: 0.014  loss_rpn_loc: 0.050  time: 1.0346  data_time: 0.0117  lr: 0.003596  max_mem: 5405M
[32m[04/20 15:26:40 d2.utils.events]: [0m eta: 0:04:34  iter: 739  total_loss: 0.612  loss_cls: 0.193  loss_box_reg: 0.329  loss_rpn_cls: 0.014  loss_rpn_loc: 0.051  time: 1.0349  data_time: 0.0117  lr: 0.003696  max_mem: 5405M
[32m[04/20 15:27:01 d2.utils.events]: [0m eta: 0:04:13  iter: 759  total_loss: 0.587  loss_cls: 0.189  loss_box_reg: 0.337  loss_rpn_cls: 0.018  loss_rpn_loc: 0.052  time: 1.0343  data_time: 0.0107  lr: 0.003796  max_mem: 5405M
[32m[04/20 15:27:21 d2.utils.events]: [0m eta: 0:03:52  iter: 779  total_loss: 0.590  loss_cls: 0.205  loss_box_reg: 0.321  loss_rpn_cls: 0.015  loss_rpn_loc: 0.052  time: 1.0342  data_time: 0.0115  lr: 0.003896  max_mem: 5405M
[32m[04/20 15:27:42 d2.utils.events]: [0m eta: 0:03:30  iter: 799  total_loss: 0.667  loss_cls: 0.203  loss_box_reg: 0.378  loss_rpn_cls: 0.016  loss_rpn_loc: 0.064  time: 1.0341  data_time: 0.0113  lr: 0.003996  max_mem: 5405M
[32m[04/20 15:28:03 d2.utils.events]: [0m eta: 0:03:09  iter: 819  total_loss: 0.607  loss_cls: 0.203  loss_box_reg: 0.334  loss_rpn_cls: 0.013  loss_rpn_loc: 0.048  time: 1.0339  data_time: 0.0115  lr: 0.004096  max_mem: 5405M
[32m[04/20 15:28:23 d2.utils.events]: [0m eta: 0:02:48  iter: 839  total_loss: 0.658  loss_cls: 0.206  loss_box_reg: 0.371  loss_rpn_cls: 0.019  loss_rpn_loc: 0.058  time: 1.0341  data_time: 0.0113  lr: 0.004196  max_mem: 5405M
[32m[04/20 15:28:44 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.564  loss_cls: 0.190  loss_box_reg: 0.334  loss_rpn_cls: 0.015  loss_rpn_loc: 0.046  time: 1.0340  data_time: 0.0108  lr: 0.004296  max_mem: 5405M
[32m[04/20 15:29:05 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.599  loss_cls: 0.191  loss_box_reg: 0.335  loss_rpn_cls: 0.012  loss_rpn_loc: 0.045  time: 1.0343  data_time: 0.0112  lr: 0.004396  max_mem: 5405M
[32m[04/20 15:29:26 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.718  loss_cls: 0.233  loss_box_reg: 0.413  loss_rpn_cls: 0.012  loss_rpn_loc: 0.051  time: 1.0341  data_time: 0.0123  lr: 0.004496  max_mem: 5405M
[32m[04/20 15:29:46 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.628  loss_cls: 0.211  loss_box_reg: 0.350  loss_rpn_cls: 0.019  loss_rpn_loc: 0.054  time: 1.0341  data_time: 0.0105  lr: 0.004595  max_mem: 5405M
[32m[04/20 15:30:07 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.556  loss_cls: 0.194  loss_box_reg: 0.299  loss_rpn_cls: 0.016  loss_rpn_loc: 0.049  time: 1.0342  data_time: 0.0116  lr: 0.004695  max_mem: 5405M
[32m[04/20 15:30:28 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.577  loss_cls: 0.192  loss_box_reg: 0.336  loss_rpn_cls: 0.017  loss_rpn_loc: 0.048  time: 1.0345  data_time: 0.0114  lr: 0.004795  max_mem: 5405M
[32m[04/20 15:30:49 d2.utils.events]: [0m eta: 0:00:22  iter: 979  total_loss: 0.605  loss_cls: 0.197  loss_box_reg: 0.355  loss_rpn_cls: 0.015  loss_rpn_loc: 0.060  time: 1.0346  data_time: 0.0115  lr: 0.004895  max_mem: 5405M
[5m[31mWARNING[0m [32m[04/20 15:31:13 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 15:31:13 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 15:31:13 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 15:31:13 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.574  loss_cls: 0.186  loss_box_reg: 0.315  loss_rpn_cls: 0.012  loss_rpn_loc: 0.044  time: 1.0348  data_time: 0.0116  lr: 0.004995  max_mem: 5405M
[32m[04/20 15:31:14 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:12 (1.0358 s / it)
[32m[04/20 15:31:14 d2.engine.hooks]: [0mTotal training time: 0:17:19 (0:00:06 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 15:31:16 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 15:31:16 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 15:31:17 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 15:31:18 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1182 s / img. ETA=0:16:41
[32m[04/20 15:31:23 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1176 s / img. ETA=0:16:35
[32m[04/20 15:31:28 d2.evaluation.evaluator]: [0mInference done 95/8355. 0.1172 s / img. ETA=0:16:27
[32m[04/20 15:31:33 d2.evaluation.evaluator]: [0mInference done 137/8355. 0.1172 s / img. ETA=0:16:21
[32m[04/20 15:31:38 d2.evaluation.evaluator]: [0mInference done 179/8355. 0.1171 s / img. ETA=0:16:16
[32m[04/20 15:31:43 d2.evaluation.evaluator]: [0mInference done 222/8355. 0.1171 s / img. ETA=0:16:10
[32m[04/20 15:31:49 d2.evaluation.evaluator]: [0mInference done 265/8355. 0.1170 s / img. ETA=0:16:04
[32m[04/20 15:31:54 d2.evaluation.evaluator]: [0mInference done 307/8355. 0.1170 s / img. ETA=0:15:59
[32m[04/20 15:31:59 d2.evaluation.evaluator]: [0mInference done 349/8355. 0.1170 s / img. ETA=0:15:54
[32m[04/20 15:32:04 d2.evaluation.evaluator]: [0mInference done 391/8355. 0.1171 s / img. ETA=0:15:50
[32m[04/20 15:32:09 d2.evaluation.evaluator]: [0mInference done 433/8355. 0.1171 s / img. ETA=0:15:45
[32m[04/20 15:32:14 d2.evaluation.evaluator]: [0mInference done 475/8355. 0.1171 s / img. ETA=0:15:40
[32m[04/20 15:32:19 d2.evaluation.evaluator]: [0mInference done 518/8355. 0.1170 s / img. ETA=0:15:34
[32m[04/20 15:32:24 d2.evaluation.evaluator]: [0mInference done 561/8355. 0.1170 s / img. ETA=0:15:28
[32m[04/20 15:32:29 d2.evaluation.evaluator]: [0mInference done 603/8355. 0.1170 s / img. ETA=0:15:24
[32m[04/20 15:32:34 d2.evaluation.evaluator]: [0mInference done 646/8355. 0.1169 s / img. ETA=0:15:18
[32m[04/20 15:32:39 d2.evaluation.evaluator]: [0mInference done 688/8355. 0.1169 s / img. ETA=0:15:13
[32m[04/20 15:32:44 d2.evaluation.evaluator]: [0mInference done 731/8355. 0.1169 s / img. ETA=0:15:08
[32m[04/20 15:32:49 d2.evaluation.evaluator]: [0mInference done 774/8355. 0.1169 s / img. ETA=0:15:03
[32m[04/20 15:32:54 d2.evaluation.evaluator]: [0mInference done 816/8355. 0.1169 s / img. ETA=0:14:58
[32m[04/20 15:32:59 d2.evaluation.evaluator]: [0mInference done 859/8355. 0.1169 s / img. ETA=0:14:53
[32m[04/20 15:33:04 d2.evaluation.evaluator]: [0mInference done 901/8355. 0.1169 s / img. ETA=0:14:48
[32m[04/20 15:33:09 d2.evaluation.evaluator]: [0mInference done 943/8355. 0.1169 s / img. ETA=0:14:43
[32m[04/20 15:33:14 d2.evaluation.evaluator]: [0mInference done 986/8355. 0.1169 s / img. ETA=0:14:38
[32m[04/20 15:33:20 d2.evaluation.evaluator]: [0mInference done 1029/8355. 0.1169 s / img. ETA=0:14:32
[32m[04/20 15:33:25 d2.evaluation.evaluator]: [0mInference done 1072/8355. 0.1169 s / img. ETA=0:14:27
[32m[04/20 15:33:30 d2.evaluation.evaluator]: [0mInference done 1115/8355. 0.1168 s / img. ETA=0:14:22
[32m[04/20 15:33:35 d2.evaluation.evaluator]: [0mInference done 1158/8355. 0.1168 s / img. ETA=0:14:17
[32m[04/20 15:33:40 d2.evaluation.evaluator]: [0mInference done 1201/8355. 0.1168 s / img. ETA=0:14:11
[32m[04/20 15:33:45 d2.evaluation.evaluator]: [0mInference done 1244/8355. 0.1168 s / img. ETA=0:14:06
[32m[04/20 15:33:50 d2.evaluation.evaluator]: [0mInference done 1287/8355. 0.1168 s / img. ETA=0:14:01
[32m[04/20 15:33:55 d2.evaluation.evaluator]: [0mInference done 1330/8355. 0.1168 s / img. ETA=0:13:56
[32m[04/20 15:34:00 d2.evaluation.evaluator]: [0mInference done 1373/8355. 0.1168 s / img. ETA=0:13:51
[32m[04/20 15:34:05 d2.evaluation.evaluator]: [0mInference done 1416/8355. 0.1167 s / img. ETA=0:13:45
[32m[04/20 15:34:11 d2.evaluation.evaluator]: [0mInference done 1459/8355. 0.1167 s / img. ETA=0:13:40
[32m[04/20 15:34:16 d2.evaluation.evaluator]: [0mInference done 1501/8355. 0.1167 s / img. ETA=0:13:35
[32m[04/20 15:34:21 d2.evaluation.evaluator]: [0mInference done 1543/8355. 0.1168 s / img. ETA=0:13:31
[32m[04/20 15:34:26 d2.evaluation.evaluator]: [0mInference done 1585/8355. 0.1168 s / img. ETA=0:13:26
[32m[04/20 15:34:31 d2.evaluation.evaluator]: [0mInference done 1627/8355. 0.1169 s / img. ETA=0:13:21
[32m[04/20 15:34:36 d2.evaluation.evaluator]: [0mInference done 1669/8355. 0.1169 s / img. ETA=0:13:16
[32m[04/20 15:34:41 d2.evaluation.evaluator]: [0mInference done 1711/8355. 0.1169 s / img. ETA=0:13:12
[32m[04/20 15:34:46 d2.evaluation.evaluator]: [0mInference done 1753/8355. 0.1170 s / img. ETA=0:13:07
[32m[04/20 15:34:51 d2.evaluation.evaluator]: [0mInference done 1795/8355. 0.1170 s / img. ETA=0:13:02
[32m[04/20 15:34:56 d2.evaluation.evaluator]: [0mInference done 1837/8355. 0.1170 s / img. ETA=0:12:57
[32m[04/20 15:35:01 d2.evaluation.evaluator]: [0mInference done 1879/8355. 0.1170 s / img. ETA=0:12:52
[32m[04/20 15:35:06 d2.evaluation.evaluator]: [0mInference done 1921/8355. 0.1170 s / img. ETA=0:12:47
[32m[04/20 15:35:11 d2.evaluation.evaluator]: [0mInference done 1963/8355. 0.1170 s / img. ETA=0:12:42
[32m[04/20 15:35:16 d2.evaluation.evaluator]: [0mInference done 2005/8355. 0.1170 s / img. ETA=0:12:37
[32m[04/20 15:35:21 d2.evaluation.evaluator]: [0mInference done 2047/8355. 0.1171 s / img. ETA=0:12:32
[32m[04/20 15:35:26 d2.evaluation.evaluator]: [0mInference done 2089/8355. 0.1171 s / img. ETA=0:12:27
[32m[04/20 15:35:31 d2.evaluation.evaluator]: [0mInference done 2131/8355. 0.1171 s / img. ETA=0:12:22
[32m[04/20 15:35:36 d2.evaluation.evaluator]: [0mInference done 2173/8355. 0.1171 s / img. ETA=0:12:17
[32m[04/20 15:35:41 d2.evaluation.evaluator]: [0mInference done 2215/8355. 0.1171 s / img. ETA=0:12:13
[32m[04/20 15:35:46 d2.evaluation.evaluator]: [0mInference done 2257/8355. 0.1171 s / img. ETA=0:12:08
[32m[04/20 15:35:52 d2.evaluation.evaluator]: [0mInference done 2299/8355. 0.1171 s / img. ETA=0:12:03
[32m[04/20 15:35:57 d2.evaluation.evaluator]: [0mInference done 2341/8355. 0.1171 s / img. ETA=0:11:58
[32m[04/20 15:36:02 d2.evaluation.evaluator]: [0mInference done 2383/8355. 0.1171 s / img. ETA=0:11:53
[32m[04/20 15:36:07 d2.evaluation.evaluator]: [0mInference done 2425/8355. 0.1171 s / img. ETA=0:11:48
[32m[04/20 15:36:12 d2.evaluation.evaluator]: [0mInference done 2467/8355. 0.1171 s / img. ETA=0:11:43
[32m[04/20 15:36:17 d2.evaluation.evaluator]: [0mInference done 2509/8355. 0.1172 s / img. ETA=0:11:38
[32m[04/20 15:36:22 d2.evaluation.evaluator]: [0mInference done 2551/8355. 0.1172 s / img. ETA=0:11:33
[32m[04/20 15:36:27 d2.evaluation.evaluator]: [0mInference done 2593/8355. 0.1172 s / img. ETA=0:11:28
[32m[04/20 15:36:32 d2.evaluation.evaluator]: [0mInference done 2635/8355. 0.1172 s / img. ETA=0:11:23
[32m[04/20 15:36:37 d2.evaluation.evaluator]: [0mInference done 2677/8355. 0.1172 s / img. ETA=0:11:18
[32m[04/20 15:36:42 d2.evaluation.evaluator]: [0mInference done 2719/8355. 0.1172 s / img. ETA=0:11:13
[32m[04/20 15:36:47 d2.evaluation.evaluator]: [0mInference done 2761/8355. 0.1172 s / img. ETA=0:11:08
[32m[04/20 15:36:52 d2.evaluation.evaluator]: [0mInference done 2803/8355. 0.1172 s / img. ETA=0:11:03
[32m[04/20 15:36:57 d2.evaluation.evaluator]: [0mInference done 2845/8355. 0.1173 s / img. ETA=0:10:59
[32m[04/20 15:37:02 d2.evaluation.evaluator]: [0mInference done 2887/8355. 0.1173 s / img. ETA=0:10:54
[32m[04/20 15:37:07 d2.evaluation.evaluator]: [0mInference done 2929/8355. 0.1173 s / img. ETA=0:10:49
[32m[04/20 15:37:12 d2.evaluation.evaluator]: [0mInference done 2971/8355. 0.1173 s / img. ETA=0:10:44
[32m[04/20 15:37:17 d2.evaluation.evaluator]: [0mInference done 3013/8355. 0.1173 s / img. ETA=0:10:39
[32m[04/20 15:37:23 d2.evaluation.evaluator]: [0mInference done 3055/8355. 0.1173 s / img. ETA=0:10:34
[32m[04/20 15:37:28 d2.evaluation.evaluator]: [0mInference done 3097/8355. 0.1173 s / img. ETA=0:10:29
[32m[04/20 15:37:33 d2.evaluation.evaluator]: [0mInference done 3139/8355. 0.1173 s / img. ETA=0:10:24
[32m[04/20 15:37:38 d2.evaluation.evaluator]: [0mInference done 3181/8355. 0.1173 s / img. ETA=0:10:19
[32m[04/20 15:37:43 d2.evaluation.evaluator]: [0mInference done 3223/8355. 0.1173 s / img. ETA=0:10:14
[32m[04/20 15:37:48 d2.evaluation.evaluator]: [0mInference done 3265/8355. 0.1173 s / img. ETA=0:10:09
[32m[04/20 15:37:53 d2.evaluation.evaluator]: [0mInference done 3307/8355. 0.1173 s / img. ETA=0:10:04
[32m[04/20 15:37:58 d2.evaluation.evaluator]: [0mInference done 3349/8355. 0.1173 s / img. ETA=0:09:59
[32m[04/20 15:38:03 d2.evaluation.evaluator]: [0mInference done 3391/8355. 0.1173 s / img. ETA=0:09:54
[32m[04/20 15:38:08 d2.evaluation.evaluator]: [0mInference done 3433/8355. 0.1173 s / img. ETA=0:09:49
[32m[04/20 15:38:13 d2.evaluation.evaluator]: [0mInference done 3475/8355. 0.1173 s / img. ETA=0:09:44
[32m[04/20 15:38:18 d2.evaluation.evaluator]: [0mInference done 3517/8355. 0.1173 s / img. ETA=0:09:39
[32m[04/20 15:38:23 d2.evaluation.evaluator]: [0mInference done 3559/8355. 0.1173 s / img. ETA=0:09:34
[32m[04/20 15:38:28 d2.evaluation.evaluator]: [0mInference done 3601/8355. 0.1173 s / img. ETA=0:09:29
[32m[04/20 15:38:33 d2.evaluation.evaluator]: [0mInference done 3643/8355. 0.1173 s / img. ETA=0:09:24
[32m[04/20 15:38:38 d2.evaluation.evaluator]: [0mInference done 3685/8355. 0.1173 s / img. ETA=0:09:19
[32m[04/20 15:38:43 d2.evaluation.evaluator]: [0mInference done 3728/8355. 0.1173 s / img. ETA=0:09:13
[32m[04/20 15:38:48 d2.evaluation.evaluator]: [0mInference done 3770/8355. 0.1173 s / img. ETA=0:09:08
[32m[04/20 15:38:53 d2.evaluation.evaluator]: [0mInference done 3812/8355. 0.1173 s / img. ETA=0:09:03
[32m[04/20 15:38:58 d2.evaluation.evaluator]: [0mInference done 3854/8355. 0.1173 s / img. ETA=0:08:58
[32m[04/20 15:39:03 d2.evaluation.evaluator]: [0mInference done 3896/8355. 0.1173 s / img. ETA=0:08:53
[32m[04/20 15:39:08 d2.evaluation.evaluator]: [0mInference done 3938/8355. 0.1173 s / img. ETA=0:08:48
[32m[04/20 15:39:13 d2.evaluation.evaluator]: [0mInference done 3980/8355. 0.1173 s / img. ETA=0:08:43
[32m[04/20 15:39:19 d2.evaluation.evaluator]: [0mInference done 4022/8355. 0.1173 s / img. ETA=0:08:38
[32m[04/20 15:39:24 d2.evaluation.evaluator]: [0mInference done 4064/8355. 0.1173 s / img. ETA=0:08:33
[32m[04/20 15:39:29 d2.evaluation.evaluator]: [0mInference done 4106/8355. 0.1174 s / img. ETA=0:08:28
[32m[04/20 15:39:34 d2.evaluation.evaluator]: [0mInference done 4148/8355. 0.1174 s / img. ETA=0:08:23
[32m[04/20 15:39:39 d2.evaluation.evaluator]: [0mInference done 4190/8355. 0.1174 s / img. ETA=0:08:18
[32m[04/20 15:39:44 d2.evaluation.evaluator]: [0mInference done 4232/8355. 0.1174 s / img. ETA=0:08:13
[32m[04/20 15:39:49 d2.evaluation.evaluator]: [0mInference done 4274/8355. 0.1174 s / img. ETA=0:08:08
[32m[04/20 15:39:54 d2.evaluation.evaluator]: [0mInference done 4316/8355. 0.1173 s / img. ETA=0:08:03
[32m[04/20 15:39:59 d2.evaluation.evaluator]: [0mInference done 4358/8355. 0.1173 s / img. ETA=0:07:58
[32m[04/20 15:40:04 d2.evaluation.evaluator]: [0mInference done 4400/8355. 0.1173 s / img. ETA=0:07:53
[32m[04/20 15:40:09 d2.evaluation.evaluator]: [0mInference done 4442/8355. 0.1174 s / img. ETA=0:07:48
[32m[04/20 15:40:14 d2.evaluation.evaluator]: [0mInference done 4484/8355. 0.1174 s / img. ETA=0:07:43
[32m[04/20 15:40:19 d2.evaluation.evaluator]: [0mInference done 4526/8355. 0.1174 s / img. ETA=0:07:38
[32m[04/20 15:40:24 d2.evaluation.evaluator]: [0mInference done 4568/8355. 0.1174 s / img. ETA=0:07:33
[32m[04/20 15:40:29 d2.evaluation.evaluator]: [0mInference done 4610/8355. 0.1174 s / img. ETA=0:07:28
[32m[04/20 15:40:34 d2.evaluation.evaluator]: [0mInference done 4652/8355. 0.1174 s / img. ETA=0:07:23
[32m[04/20 15:40:39 d2.evaluation.evaluator]: [0mInference done 4694/8355. 0.1174 s / img. ETA=0:07:18
[32m[04/20 15:40:44 d2.evaluation.evaluator]: [0mInference done 4736/8355. 0.1174 s / img. ETA=0:07:13
[32m[04/20 15:40:49 d2.evaluation.evaluator]: [0mInference done 4778/8355. 0.1174 s / img. ETA=0:07:08
[32m[04/20 15:40:54 d2.evaluation.evaluator]: [0mInference done 4820/8355. 0.1174 s / img. ETA=0:07:03
[32m[04/20 15:40:59 d2.evaluation.evaluator]: [0mInference done 4862/8355. 0.1174 s / img. ETA=0:06:58
[32m[04/20 15:41:04 d2.evaluation.evaluator]: [0mInference done 4904/8355. 0.1174 s / img. ETA=0:06:53
[32m[04/20 15:41:10 d2.evaluation.evaluator]: [0mInference done 4946/8355. 0.1174 s / img. ETA=0:06:48
[32m[04/20 15:41:15 d2.evaluation.evaluator]: [0mInference done 4988/8355. 0.1174 s / img. ETA=0:06:43
[32m[04/20 15:41:20 d2.evaluation.evaluator]: [0mInference done 5030/8355. 0.1174 s / img. ETA=0:06:38
[32m[04/20 15:41:25 d2.evaluation.evaluator]: [0mInference done 5072/8355. 0.1174 s / img. ETA=0:06:33
[32m[04/20 15:41:30 d2.evaluation.evaluator]: [0mInference done 5114/8355. 0.1174 s / img. ETA=0:06:28
[32m[04/20 15:41:35 d2.evaluation.evaluator]: [0mInference done 5156/8355. 0.1174 s / img. ETA=0:06:23
[32m[04/20 15:41:40 d2.evaluation.evaluator]: [0mInference done 5198/8355. 0.1174 s / img. ETA=0:06:18
[32m[04/20 15:41:45 d2.evaluation.evaluator]: [0mInference done 5240/8355. 0.1174 s / img. ETA=0:06:13
[32m[04/20 15:41:50 d2.evaluation.evaluator]: [0mInference done 5282/8355. 0.1174 s / img. ETA=0:06:08
[32m[04/20 15:41:55 d2.evaluation.evaluator]: [0mInference done 5324/8355. 0.1174 s / img. ETA=0:06:03
[32m[04/20 15:42:00 d2.evaluation.evaluator]: [0mInference done 5366/8355. 0.1174 s / img. ETA=0:05:58
[32m[04/20 15:42:05 d2.evaluation.evaluator]: [0mInference done 5408/8355. 0.1174 s / img. ETA=0:05:53
[32m[04/20 15:42:10 d2.evaluation.evaluator]: [0mInference done 5450/8355. 0.1174 s / img. ETA=0:05:48
[32m[04/20 15:42:15 d2.evaluation.evaluator]: [0mInference done 5492/8355. 0.1174 s / img. ETA=0:05:43
[32m[04/20 15:42:20 d2.evaluation.evaluator]: [0mInference done 5534/8355. 0.1174 s / img. ETA=0:05:38
[32m[04/20 15:42:25 d2.evaluation.evaluator]: [0mInference done 5576/8355. 0.1174 s / img. ETA=0:05:33
[32m[04/20 15:42:30 d2.evaluation.evaluator]: [0mInference done 5618/8355. 0.1174 s / img. ETA=0:05:28
[32m[04/20 15:42:35 d2.evaluation.evaluator]: [0mInference done 5660/8355. 0.1174 s / img. ETA=0:05:23
[32m[04/20 15:42:40 d2.evaluation.evaluator]: [0mInference done 5702/8355. 0.1174 s / img. ETA=0:05:18
[32m[04/20 15:42:46 d2.evaluation.evaluator]: [0mInference done 5744/8355. 0.1174 s / img. ETA=0:05:13
[32m[04/20 15:42:51 d2.evaluation.evaluator]: [0mInference done 5786/8355. 0.1175 s / img. ETA=0:05:07
[32m[04/20 15:42:56 d2.evaluation.evaluator]: [0mInference done 5828/8355. 0.1175 s / img. ETA=0:05:02
[32m[04/20 15:43:01 d2.evaluation.evaluator]: [0mInference done 5870/8355. 0.1175 s / img. ETA=0:04:57
[32m[04/20 15:43:06 d2.evaluation.evaluator]: [0mInference done 5912/8355. 0.1175 s / img. ETA=0:04:52
[32m[04/20 15:43:11 d2.evaluation.evaluator]: [0mInference done 5954/8355. 0.1175 s / img. ETA=0:04:47
[32m[04/20 15:43:16 d2.evaluation.evaluator]: [0mInference done 5996/8355. 0.1175 s / img. ETA=0:04:42
[32m[04/20 15:43:21 d2.evaluation.evaluator]: [0mInference done 6038/8355. 0.1175 s / img. ETA=0:04:37
[32m[04/20 15:43:26 d2.evaluation.evaluator]: [0mInference done 6080/8355. 0.1175 s / img. ETA=0:04:32
[32m[04/20 15:43:31 d2.evaluation.evaluator]: [0mInference done 6122/8355. 0.1175 s / img. ETA=0:04:27
[32m[04/20 15:43:36 d2.evaluation.evaluator]: [0mInference done 6164/8355. 0.1175 s / img. ETA=0:04:22
[32m[04/20 15:43:41 d2.evaluation.evaluator]: [0mInference done 6206/8355. 0.1175 s / img. ETA=0:04:17
[32m[04/20 15:43:46 d2.evaluation.evaluator]: [0mInference done 6248/8355. 0.1175 s / img. ETA=0:04:12
[32m[04/20 15:43:52 d2.evaluation.evaluator]: [0mInference done 6290/8355. 0.1175 s / img. ETA=0:04:07
[32m[04/20 15:43:57 d2.evaluation.evaluator]: [0mInference done 6332/8355. 0.1175 s / img. ETA=0:04:02
[32m[04/20 15:44:02 d2.evaluation.evaluator]: [0mInference done 6374/8355. 0.1175 s / img. ETA=0:03:57
[32m[04/20 15:44:07 d2.evaluation.evaluator]: [0mInference done 6416/8355. 0.1175 s / img. ETA=0:03:52
[32m[04/20 15:44:12 d2.evaluation.evaluator]: [0mInference done 6458/8355. 0.1175 s / img. ETA=0:03:47
[32m[04/20 15:44:17 d2.evaluation.evaluator]: [0mInference done 6500/8355. 0.1175 s / img. ETA=0:03:42
[32m[04/20 15:44:22 d2.evaluation.evaluator]: [0mInference done 6542/8355. 0.1175 s / img. ETA=0:03:37
[32m[04/20 15:44:27 d2.evaluation.evaluator]: [0mInference done 6584/8355. 0.1175 s / img. ETA=0:03:32
[32m[04/20 15:44:32 d2.evaluation.evaluator]: [0mInference done 6626/8355. 0.1175 s / img. ETA=0:03:27
[32m[04/20 15:44:37 d2.evaluation.evaluator]: [0mInference done 6669/8355. 0.1175 s / img. ETA=0:03:22
[32m[04/20 15:44:42 d2.evaluation.evaluator]: [0mInference done 6712/8355. 0.1175 s / img. ETA=0:03:17
[32m[04/20 15:44:47 d2.evaluation.evaluator]: [0mInference done 6755/8355. 0.1175 s / img. ETA=0:03:11
[32m[04/20 15:44:52 d2.evaluation.evaluator]: [0mInference done 6797/8355. 0.1175 s / img. ETA=0:03:06
[32m[04/20 15:44:57 d2.evaluation.evaluator]: [0mInference done 6839/8355. 0.1175 s / img. ETA=0:03:01
[32m[04/20 15:45:02 d2.evaluation.evaluator]: [0mInference done 6881/8355. 0.1175 s / img. ETA=0:02:56
[32m[04/20 15:45:07 d2.evaluation.evaluator]: [0mInference done 6924/8355. 0.1175 s / img. ETA=0:02:51
[32m[04/20 15:45:12 d2.evaluation.evaluator]: [0mInference done 6966/8355. 0.1175 s / img. ETA=0:02:46
[32m[04/20 15:45:17 d2.evaluation.evaluator]: [0mInference done 7008/8355. 0.1175 s / img. ETA=0:02:41
[32m[04/20 15:45:23 d2.evaluation.evaluator]: [0mInference done 7050/8355. 0.1175 s / img. ETA=0:02:36
[32m[04/20 15:45:28 d2.evaluation.evaluator]: [0mInference done 7092/8355. 0.1175 s / img. ETA=0:02:31
[32m[04/20 15:45:33 d2.evaluation.evaluator]: [0mInference done 7134/8355. 0.1175 s / img. ETA=0:02:26
[32m[04/20 15:45:38 d2.evaluation.evaluator]: [0mInference done 7176/8355. 0.1175 s / img. ETA=0:02:21
[32m[04/20 15:45:43 d2.evaluation.evaluator]: [0mInference done 7218/8355. 0.1175 s / img. ETA=0:02:16
[32m[04/20 15:45:48 d2.evaluation.evaluator]: [0mInference done 7260/8355. 0.1175 s / img. ETA=0:02:11
[32m[04/20 15:45:53 d2.evaluation.evaluator]: [0mInference done 7302/8355. 0.1175 s / img. ETA=0:02:06
[32m[04/20 15:45:58 d2.evaluation.evaluator]: [0mInference done 7344/8355. 0.1175 s / img. ETA=0:02:01
[32m[04/20 15:46:03 d2.evaluation.evaluator]: [0mInference done 7386/8355. 0.1175 s / img. ETA=0:01:56
[32m[04/20 15:46:08 d2.evaluation.evaluator]: [0mInference done 7428/8355. 0.1175 s / img. ETA=0:01:51
[32m[04/20 15:46:13 d2.evaluation.evaluator]: [0mInference done 7470/8355. 0.1176 s / img. ETA=0:01:46
[32m[04/20 15:46:19 d2.evaluation.evaluator]: [0mInference done 7512/8355. 0.1176 s / img. ETA=0:01:41
[32m[04/20 15:46:24 d2.evaluation.evaluator]: [0mInference done 7554/8355. 0.1176 s / img. ETA=0:01:36
[32m[04/20 15:46:29 d2.evaluation.evaluator]: [0mInference done 7596/8355. 0.1176 s / img. ETA=0:01:31
[32m[04/20 15:46:34 d2.evaluation.evaluator]: [0mInference done 7638/8355. 0.1176 s / img. ETA=0:01:26
[32m[04/20 15:46:39 d2.evaluation.evaluator]: [0mInference done 7680/8355. 0.1176 s / img. ETA=0:01:21
[32m[04/20 15:46:44 d2.evaluation.evaluator]: [0mInference done 7722/8355. 0.1176 s / img. ETA=0:01:15
[32m[04/20 15:46:49 d2.evaluation.evaluator]: [0mInference done 7764/8355. 0.1176 s / img. ETA=0:01:10
[32m[04/20 15:46:54 d2.evaluation.evaluator]: [0mInference done 7806/8355. 0.1176 s / img. ETA=0:01:05
[32m[04/20 15:46:59 d2.evaluation.evaluator]: [0mInference done 7848/8355. 0.1176 s / img. ETA=0:01:00
[32m[04/20 15:47:04 d2.evaluation.evaluator]: [0mInference done 7889/8355. 0.1176 s / img. ETA=0:00:55
[32m[04/20 15:47:09 d2.evaluation.evaluator]: [0mInference done 7931/8355. 0.1176 s / img. ETA=0:00:50
[32m[04/20 15:47:14 d2.evaluation.evaluator]: [0mInference done 7973/8355. 0.1176 s / img. ETA=0:00:45
[32m[04/20 15:47:19 d2.evaluation.evaluator]: [0mInference done 8015/8355. 0.1176 s / img. ETA=0:00:40
[32m[04/20 15:47:24 d2.evaluation.evaluator]: [0mInference done 8057/8355. 0.1176 s / img. ETA=0:00:35
[32m[04/20 15:47:29 d2.evaluation.evaluator]: [0mInference done 8099/8355. 0.1176 s / img. ETA=0:00:30
[32m[04/20 15:47:35 d2.evaluation.evaluator]: [0mInference done 8141/8355. 0.1176 s / img. ETA=0:00:25
[32m[04/20 15:47:40 d2.evaluation.evaluator]: [0mInference done 8183/8355. 0.1176 s / img. ETA=0:00:20
[32m[04/20 15:47:45 d2.evaluation.evaluator]: [0mInference done 8225/8355. 0.1176 s / img. ETA=0:00:15
[32m[04/20 15:47:50 d2.evaluation.evaluator]: [0mInference done 8267/8355. 0.1176 s / img. ETA=0:00:10
[32m[04/20 15:47:55 d2.evaluation.evaluator]: [0mInference done 8309/8355. 0.1176 s / img. ETA=0:00:05
[32m[04/20 15:48:00 d2.evaluation.evaluator]: [0mInference done 8351/8355. 0.1176 s / img. ETA=0:00:00
[32m[04/20 15:48:00 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:42.663962 (0.120080 s / img per device, on 1 devices)
[32m[04/20 15:48:00 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:22 (0.117608 s / img per device, on 1 devices)
[32m[04/20 15:48:01 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 15:48:01 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 15:48:01 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=20.53s).
Accumulating evaluation results...
DONE (t=2.99s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.386
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.703
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.375
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.278
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.515
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.679
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.155
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.430
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.345
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.574
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.721
[32m[04/20 15:48:24 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 38.648 | 70.284 | 37.458 | 27.819 | 51.503 | 67.883 |
[32m[04/20 15:48:24 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 41.076 | bicycle       | 26.719 | car            | 48.149 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 15:48:26 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 15:48:26 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 15:48:26 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 15:48:27 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1176 s / img. ETA=0:02:28
[32m[04/20 15:48:32 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1177 s / img. ETA=0:02:24
[32m[04/20 15:48:38 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1180 s / img. ETA=0:02:19
[32m[04/20 15:48:43 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1182 s / img. ETA=0:02:15
[32m[04/20 15:48:48 d2.evaluation.evaluator]: [0mInference done 179/1257. 0.1181 s / img. ETA=0:02:09
[32m[04/20 15:48:53 d2.evaluation.evaluator]: [0mInference done 221/1257. 0.1181 s / img. ETA=0:02:04
[32m[04/20 15:48:58 d2.evaluation.evaluator]: [0mInference done 263/1257. 0.1180 s / img. ETA=0:01:59
[32m[04/20 15:49:03 d2.evaluation.evaluator]: [0mInference done 305/1257. 0.1182 s / img. ETA=0:01:54
[32m[04/20 15:49:08 d2.evaluation.evaluator]: [0mInference done 347/1257. 0.1182 s / img. ETA=0:01:49
[32m[04/20 15:49:13 d2.evaluation.evaluator]: [0mInference done 389/1257. 0.1182 s / img. ETA=0:01:44
[32m[04/20 15:49:18 d2.evaluation.evaluator]: [0mInference done 431/1257. 0.1182 s / img. ETA=0:01:39
[32m[04/20 15:49:23 d2.evaluation.evaluator]: [0mInference done 473/1257. 0.1182 s / img. ETA=0:01:34
[32m[04/20 15:49:28 d2.evaluation.evaluator]: [0mInference done 515/1257. 0.1182 s / img. ETA=0:01:29
[32m[04/20 15:49:33 d2.evaluation.evaluator]: [0mInference done 557/1257. 0.1182 s / img. ETA=0:01:24
[32m[04/20 15:49:38 d2.evaluation.evaluator]: [0mInference done 599/1257. 0.1183 s / img. ETA=0:01:19
[32m[04/20 15:49:44 d2.evaluation.evaluator]: [0mInference done 641/1257. 0.1183 s / img. ETA=0:01:14
[32m[04/20 15:49:49 d2.evaluation.evaluator]: [0mInference done 683/1257. 0.1183 s / img. ETA=0:01:09
[32m[04/20 15:49:54 d2.evaluation.evaluator]: [0mInference done 725/1257. 0.1183 s / img. ETA=0:01:04
[32m[04/20 15:49:59 d2.evaluation.evaluator]: [0mInference done 767/1257. 0.1183 s / img. ETA=0:00:59
[32m[04/20 15:50:04 d2.evaluation.evaluator]: [0mInference done 809/1257. 0.1184 s / img. ETA=0:00:54
[32m[04/20 15:50:09 d2.evaluation.evaluator]: [0mInference done 851/1257. 0.1184 s / img. ETA=0:00:49
[32m[04/20 15:50:14 d2.evaluation.evaluator]: [0mInference done 893/1257. 0.1184 s / img. ETA=0:00:44
[32m[04/20 15:50:19 d2.evaluation.evaluator]: [0mInference done 935/1257. 0.1184 s / img. ETA=0:00:38
[32m[04/20 15:50:24 d2.evaluation.evaluator]: [0mInference done 977/1257. 0.1184 s / img. ETA=0:00:33
[32m[04/20 15:50:29 d2.evaluation.evaluator]: [0mInference done 1019/1257. 0.1184 s / img. ETA=0:00:28
[32m[04/20 15:50:34 d2.evaluation.evaluator]: [0mInference done 1061/1257. 0.1184 s / img. ETA=0:00:23
[32m[04/20 15:50:39 d2.evaluation.evaluator]: [0mInference done 1103/1257. 0.1184 s / img. ETA=0:00:18
[32m[04/20 15:50:45 d2.evaluation.evaluator]: [0mInference done 1145/1257. 0.1184 s / img. ETA=0:00:13
[32m[04/20 15:50:50 d2.evaluation.evaluator]: [0mInference done 1187/1257. 0.1184 s / img. ETA=0:00:08
[32m[04/20 15:50:55 d2.evaluation.evaluator]: [0mInference done 1229/1257. 0.1184 s / img. ETA=0:00:03
[32m[04/20 15:50:58 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:31.440808 (0.120959 s / img per device, on 1 devices)
[32m[04/20 15:50:58 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:28 (0.118432 s / img per device, on 1 devices)
[32m[04/20 15:50:58 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 15:50:58 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 15:50:58 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.78s).
Accumulating evaluation results...
DONE (t=0.39s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.560
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.275
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.361
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.463
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.138
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.347
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.245
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.496
[32m[04/20 15:51:02 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 29.598 | 55.965 | 27.462 | 18.646 | 36.068 | 46.328 |
[32m[04/20 15:51:02 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 32.705 | bicycle       | 10.626 | car            | 45.463 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  17  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 15:51:02 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 15:51:03 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 15:51:03 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 15:51:03 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 15:51:03 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 15:51:03 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 15:51:03 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 15:51:24 d2.utils.events]: [0m eta: 0:16:34  iter: 19  total_loss: 0.611  loss_cls: 0.198  loss_box_reg: 0.336  loss_rpn_cls: 0.015  loss_rpn_loc: 0.054  time: 1.0188  data_time: 0.0399  lr: 0.000100  max_mem: 5405M
[32m[04/20 15:51:45 d2.utils.events]: [0m eta: 0:16:18  iter: 39  total_loss: 0.538  loss_cls: 0.174  loss_box_reg: 0.302  loss_rpn_cls: 0.016  loss_rpn_loc: 0.041  time: 1.0245  data_time: 0.0113  lr: 0.000200  max_mem: 5405M
[32m[04/20 15:52:05 d2.utils.events]: [0m eta: 0:16:01  iter: 59  total_loss: 0.557  loss_cls: 0.186  loss_box_reg: 0.308  loss_rpn_cls: 0.014  loss_rpn_loc: 0.058  time: 1.0269  data_time: 0.0108  lr: 0.000300  max_mem: 5405M
[32m[04/20 15:52:26 d2.utils.events]: [0m eta: 0:15:40  iter: 79  total_loss: 0.603  loss_cls: 0.193  loss_box_reg: 0.326  loss_rpn_cls: 0.011  loss_rpn_loc: 0.053  time: 1.0246  data_time: 0.0111  lr: 0.000400  max_mem: 5405M
[32m[04/20 15:52:47 d2.utils.events]: [0m eta: 0:15:26  iter: 99  total_loss: 0.612  loss_cls: 0.205  loss_box_reg: 0.364  loss_rpn_cls: 0.016  loss_rpn_loc: 0.054  time: 1.0289  data_time: 0.0110  lr: 0.000500  max_mem: 5405M
[32m[04/20 15:53:07 d2.utils.events]: [0m eta: 0:15:05  iter: 119  total_loss: 0.588  loss_cls: 0.183  loss_box_reg: 0.331  loss_rpn_cls: 0.012  loss_rpn_loc: 0.057  time: 1.0292  data_time: 0.0112  lr: 0.000599  max_mem: 5405M
[32m[04/20 15:53:28 d2.utils.events]: [0m eta: 0:14:44  iter: 139  total_loss: 0.585  loss_cls: 0.189  loss_box_reg: 0.343  loss_rpn_cls: 0.015  loss_rpn_loc: 0.047  time: 1.0279  data_time: 0.0106  lr: 0.000699  max_mem: 5405M
[32m[04/20 15:53:48 d2.utils.events]: [0m eta: 0:14:25  iter: 159  total_loss: 0.506  loss_cls: 0.163  loss_box_reg: 0.291  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0266  data_time: 0.0106  lr: 0.000799  max_mem: 5405M
[32m[04/20 15:54:09 d2.utils.events]: [0m eta: 0:14:03  iter: 179  total_loss: 0.626  loss_cls: 0.202  loss_box_reg: 0.355  loss_rpn_cls: 0.015  loss_rpn_loc: 0.060  time: 1.0255  data_time: 0.0114  lr: 0.000899  max_mem: 5405M
[32m[04/20 15:54:30 d2.utils.events]: [0m eta: 0:13:43  iter: 199  total_loss: 0.629  loss_cls: 0.202  loss_box_reg: 0.363  loss_rpn_cls: 0.015  loss_rpn_loc: 0.052  time: 1.0273  data_time: 0.0110  lr: 0.000999  max_mem: 5405M
[32m[04/20 15:54:50 d2.utils.events]: [0m eta: 0:13:21  iter: 219  total_loss: 0.555  loss_cls: 0.182  loss_box_reg: 0.322  loss_rpn_cls: 0.011  loss_rpn_loc: 0.043  time: 1.0261  data_time: 0.0119  lr: 0.001099  max_mem: 5405M
[32m[04/20 15:55:11 d2.utils.events]: [0m eta: 0:13:00  iter: 239  total_loss: 0.618  loss_cls: 0.192  loss_box_reg: 0.350  loss_rpn_cls: 0.016  loss_rpn_loc: 0.055  time: 1.0261  data_time: 0.0105  lr: 0.001199  max_mem: 5405M
[32m[04/20 15:55:32 d2.utils.events]: [0m eta: 0:12:41  iter: 259  total_loss: 0.613  loss_cls: 0.188  loss_box_reg: 0.323  loss_rpn_cls: 0.020  loss_rpn_loc: 0.055  time: 1.0278  data_time: 0.0115  lr: 0.001299  max_mem: 5405M
[32m[04/20 15:55:53 d2.utils.events]: [0m eta: 0:12:25  iter: 279  total_loss: 0.622  loss_cls: 0.192  loss_box_reg: 0.345  loss_rpn_cls: 0.012  loss_rpn_loc: 0.056  time: 1.0312  data_time: 0.0109  lr: 0.001399  max_mem: 5405M
[32m[04/20 15:56:14 d2.utils.events]: [0m eta: 0:12:09  iter: 299  total_loss: 0.589  loss_cls: 0.189  loss_box_reg: 0.323  loss_rpn_cls: 0.015  loss_rpn_loc: 0.047  time: 1.0326  data_time: 0.0120  lr: 0.001499  max_mem: 5405M
[32m[04/20 15:56:35 d2.utils.events]: [0m eta: 0:11:47  iter: 319  total_loss: 0.583  loss_cls: 0.193  loss_box_reg: 0.333  loss_rpn_cls: 0.012  loss_rpn_loc: 0.057  time: 1.0325  data_time: 0.0115  lr: 0.001598  max_mem: 5405M
[32m[04/20 15:56:56 d2.utils.events]: [0m eta: 0:11:27  iter: 339  total_loss: 0.518  loss_cls: 0.166  loss_box_reg: 0.291  loss_rpn_cls: 0.013  loss_rpn_loc: 0.054  time: 1.0330  data_time: 0.0112  lr: 0.001698  max_mem: 5405M
[32m[04/20 15:57:16 d2.utils.events]: [0m eta: 0:11:03  iter: 359  total_loss: 0.637  loss_cls: 0.202  loss_box_reg: 0.368  loss_rpn_cls: 0.013  loss_rpn_loc: 0.047  time: 1.0330  data_time: 0.0109  lr: 0.001798  max_mem: 5405M
[32m[04/20 15:57:37 d2.utils.events]: [0m eta: 0:10:43  iter: 379  total_loss: 0.574  loss_cls: 0.184  loss_box_reg: 0.317  loss_rpn_cls: 0.014  loss_rpn_loc: 0.050  time: 1.0328  data_time: 0.0105  lr: 0.001898  max_mem: 5405M
[32m[04/20 15:57:58 d2.utils.events]: [0m eta: 0:10:24  iter: 399  total_loss: 0.580  loss_cls: 0.184  loss_box_reg: 0.326  loss_rpn_cls: 0.013  loss_rpn_loc: 0.042  time: 1.0328  data_time: 0.0128  lr: 0.001998  max_mem: 5405M
[32m[04/20 15:58:18 d2.utils.events]: [0m eta: 0:10:03  iter: 419  total_loss: 0.592  loss_cls: 0.188  loss_box_reg: 0.311  loss_rpn_cls: 0.012  loss_rpn_loc: 0.047  time: 1.0324  data_time: 0.0120  lr: 0.002098  max_mem: 5405M
[32m[04/20 15:58:38 d2.utils.events]: [0m eta: 0:09:40  iter: 439  total_loss: 0.565  loss_cls: 0.180  loss_box_reg: 0.330  loss_rpn_cls: 0.013  loss_rpn_loc: 0.046  time: 1.0310  data_time: 0.0122  lr: 0.002198  max_mem: 5405M
[32m[04/20 15:58:59 d2.utils.events]: [0m eta: 0:09:20  iter: 459  total_loss: 0.563  loss_cls: 0.162  loss_box_reg: 0.301  loss_rpn_cls: 0.013  loss_rpn_loc: 0.045  time: 1.0311  data_time: 0.0113  lr: 0.002298  max_mem: 5405M
[32m[04/20 15:59:19 d2.utils.events]: [0m eta: 0:08:58  iter: 479  total_loss: 0.608  loss_cls: 0.195  loss_box_reg: 0.344  loss_rpn_cls: 0.014  loss_rpn_loc: 0.064  time: 1.0299  data_time: 0.0108  lr: 0.002398  max_mem: 5405M
[32m[04/20 15:59:39 d2.utils.events]: [0m eta: 0:08:36  iter: 499  total_loss: 0.589  loss_cls: 0.198  loss_box_reg: 0.329  loss_rpn_cls: 0.016  loss_rpn_loc: 0.057  time: 1.0286  data_time: 0.0108  lr: 0.002498  max_mem: 5405M
[32m[04/20 16:00:00 d2.utils.events]: [0m eta: 0:08:15  iter: 519  total_loss: 0.549  loss_cls: 0.178  loss_box_reg: 0.316  loss_rpn_cls: 0.012  loss_rpn_loc: 0.042  time: 1.0291  data_time: 0.0105  lr: 0.002597  max_mem: 5405M
[32m[04/20 16:00:20 d2.utils.events]: [0m eta: 0:07:54  iter: 539  total_loss: 0.533  loss_cls: 0.161  loss_box_reg: 0.296  loss_rpn_cls: 0.009  loss_rpn_loc: 0.042  time: 1.0284  data_time: 0.0107  lr: 0.002697  max_mem: 5405M
[32m[04/20 16:00:40 d2.utils.events]: [0m eta: 0:07:33  iter: 559  total_loss: 0.588  loss_cls: 0.196  loss_box_reg: 0.330  loss_rpn_cls: 0.017  loss_rpn_loc: 0.054  time: 1.0269  data_time: 0.0109  lr: 0.002797  max_mem: 5405M
[32m[04/20 16:01:01 d2.utils.events]: [0m eta: 0:07:13  iter: 579  total_loss: 0.568  loss_cls: 0.182  loss_box_reg: 0.335  loss_rpn_cls: 0.014  loss_rpn_loc: 0.063  time: 1.0271  data_time: 0.0109  lr: 0.002897  max_mem: 5405M
[32m[04/20 16:01:22 d2.utils.events]: [0m eta: 0:06:52  iter: 599  total_loss: 0.580  loss_cls: 0.176  loss_box_reg: 0.335  loss_rpn_cls: 0.014  loss_rpn_loc: 0.053  time: 1.0279  data_time: 0.0114  lr: 0.002997  max_mem: 5405M
[32m[04/20 16:01:43 d2.utils.events]: [0m eta: 0:06:32  iter: 619  total_loss: 0.586  loss_cls: 0.191  loss_box_reg: 0.345  loss_rpn_cls: 0.013  loss_rpn_loc: 0.063  time: 1.0285  data_time: 0.0118  lr: 0.003097  max_mem: 5405M
[32m[04/20 16:02:04 d2.utils.events]: [0m eta: 0:06:12  iter: 639  total_loss: 0.602  loss_cls: 0.188  loss_box_reg: 0.356  loss_rpn_cls: 0.013  loss_rpn_loc: 0.047  time: 1.0289  data_time: 0.0110  lr: 0.003197  max_mem: 5405M
[32m[04/20 16:02:24 d2.utils.events]: [0m eta: 0:05:51  iter: 659  total_loss: 0.619  loss_cls: 0.186  loss_box_reg: 0.317  loss_rpn_cls: 0.013  loss_rpn_loc: 0.054  time: 1.0287  data_time: 0.0105  lr: 0.003297  max_mem: 5405M
[32m[04/20 16:02:45 d2.utils.events]: [0m eta: 0:05:31  iter: 679  total_loss: 0.580  loss_cls: 0.193  loss_box_reg: 0.330  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0295  data_time: 0.0108  lr: 0.003397  max_mem: 5405M
[32m[04/20 16:03:06 d2.utils.events]: [0m eta: 0:05:10  iter: 699  total_loss: 0.615  loss_cls: 0.187  loss_box_reg: 0.339  loss_rpn_cls: 0.011  loss_rpn_loc: 0.057  time: 1.0293  data_time: 0.0132  lr: 0.003497  max_mem: 5405M
[32m[04/20 16:03:27 d2.utils.events]: [0m eta: 0:04:49  iter: 719  total_loss: 0.527  loss_cls: 0.171  loss_box_reg: 0.315  loss_rpn_cls: 0.012  loss_rpn_loc: 0.047  time: 1.0296  data_time: 0.0109  lr: 0.003596  max_mem: 5405M
[32m[04/20 16:03:47 d2.utils.events]: [0m eta: 0:04:29  iter: 739  total_loss: 0.604  loss_cls: 0.191  loss_box_reg: 0.347  loss_rpn_cls: 0.014  loss_rpn_loc: 0.050  time: 1.0293  data_time: 0.0113  lr: 0.003696  max_mem: 5405M
[32m[04/20 16:04:08 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.598  loss_cls: 0.201  loss_box_reg: 0.327  loss_rpn_cls: 0.014  loss_rpn_loc: 0.056  time: 1.0295  data_time: 0.0108  lr: 0.003796  max_mem: 5405M
[32m[04/20 16:04:29 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.592  loss_cls: 0.189  loss_box_reg: 0.347  loss_rpn_cls: 0.016  loss_rpn_loc: 0.056  time: 1.0299  data_time: 0.0115  lr: 0.003896  max_mem: 5405M
[32m[04/20 16:04:50 d2.utils.events]: [0m eta: 0:03:27  iter: 799  total_loss: 0.532  loss_cls: 0.164  loss_box_reg: 0.325  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 1.0302  data_time: 0.0109  lr: 0.003996  max_mem: 5405M
[32m[04/20 16:05:10 d2.utils.events]: [0m eta: 0:03:06  iter: 819  total_loss: 0.541  loss_cls: 0.173  loss_box_reg: 0.301  loss_rpn_cls: 0.010  loss_rpn_loc: 0.041  time: 1.0298  data_time: 0.0110  lr: 0.004096  max_mem: 5405M
[32m[04/20 16:05:31 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.582  loss_cls: 0.189  loss_box_reg: 0.336  loss_rpn_cls: 0.012  loss_rpn_loc: 0.047  time: 1.0300  data_time: 0.0111  lr: 0.004196  max_mem: 5405M
[32m[04/20 16:05:52 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.625  loss_cls: 0.198  loss_box_reg: 0.363  loss_rpn_cls: 0.011  loss_rpn_loc: 0.052  time: 1.0302  data_time: 0.0109  lr: 0.004296  max_mem: 5405M
[32m[04/20 16:06:13 d2.utils.events]: [0m eta: 0:02:04  iter: 879  total_loss: 0.589  loss_cls: 0.210  loss_box_reg: 0.335  loss_rpn_cls: 0.014  loss_rpn_loc: 0.039  time: 1.0303  data_time: 0.0110  lr: 0.004396  max_mem: 5405M
[32m[04/20 16:06:34 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.618  loss_cls: 0.194  loss_box_reg: 0.350  loss_rpn_cls: 0.014  loss_rpn_loc: 0.057  time: 1.0307  data_time: 0.0115  lr: 0.004496  max_mem: 5405M
[32m[04/20 16:06:54 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.695  loss_cls: 0.227  loss_box_reg: 0.353  loss_rpn_cls: 0.014  loss_rpn_loc: 0.068  time: 1.0308  data_time: 0.0107  lr: 0.004595  max_mem: 5405M
[32m[04/20 16:07:15 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.614  loss_cls: 0.179  loss_box_reg: 0.346  loss_rpn_cls: 0.021  loss_rpn_loc: 0.056  time: 1.0310  data_time: 0.0113  lr: 0.004695  max_mem: 5405M
[32m[04/20 16:07:36 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.661  loss_cls: 0.205  loss_box_reg: 0.367  loss_rpn_cls: 0.017  loss_rpn_loc: 0.055  time: 1.0311  data_time: 0.0130  lr: 0.004795  max_mem: 5405M
[32m[04/20 16:07:57 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.657  loss_cls: 0.206  loss_box_reg: 0.383  loss_rpn_cls: 0.017  loss_rpn_loc: 0.063  time: 1.0313  data_time: 0.0105  lr: 0.004895  max_mem: 5405M
[5m[31mWARNING[0m [32m[04/20 16:08:22 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 16:08:22 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 16:08:22 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 16:08:22 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.615  loss_cls: 0.208  loss_box_reg: 0.343  loss_rpn_cls: 0.013  loss_rpn_loc: 0.049  time: 1.0317  data_time: 0.0126  lr: 0.004995  max_mem: 5405M
[32m[04/20 16:08:22 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:09 (1.0328 s / it)
[32m[04/20 16:08:22 d2.engine.hooks]: [0mTotal training time: 0:17:16 (0:00:06 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 16:08:24 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 16:08:24 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 16:08:25 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 16:08:26 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1175 s / img. ETA=0:16:36
[32m[04/20 16:08:31 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1171 s / img. ETA=0:16:29
[32m[04/20 16:08:36 d2.evaluation.evaluator]: [0mInference done 96/8355. 0.1169 s / img. ETA=0:16:22
[32m[04/20 16:08:42 d2.evaluation.evaluator]: [0mInference done 139/8355. 0.1169 s / img. ETA=0:16:17
[32m[04/20 16:08:47 d2.evaluation.evaluator]: [0mInference done 182/8355. 0.1169 s / img. ETA=0:16:12
[32m[04/20 16:08:52 d2.evaluation.evaluator]: [0mInference done 225/8355. 0.1169 s / img. ETA=0:16:07
[32m[04/20 16:08:57 d2.evaluation.evaluator]: [0mInference done 268/8355. 0.1168 s / img. ETA=0:16:02
[32m[04/20 16:09:02 d2.evaluation.evaluator]: [0mInference done 310/8355. 0.1169 s / img. ETA=0:15:57
[32m[04/20 16:09:07 d2.evaluation.evaluator]: [0mInference done 353/8355. 0.1169 s / img. ETA=0:15:52
[32m[04/20 16:09:12 d2.evaluation.evaluator]: [0mInference done 395/8355. 0.1170 s / img. ETA=0:15:48
[32m[04/20 16:09:17 d2.evaluation.evaluator]: [0mInference done 437/8355. 0.1170 s / img. ETA=0:15:43
[32m[04/20 16:09:22 d2.evaluation.evaluator]: [0mInference done 480/8355. 0.1170 s / img. ETA=0:15:38
[32m[04/20 16:09:27 d2.evaluation.evaluator]: [0mInference done 523/8355. 0.1170 s / img. ETA=0:15:33
[32m[04/20 16:09:32 d2.evaluation.evaluator]: [0mInference done 566/8355. 0.1170 s / img. ETA=0:15:28
[32m[04/20 16:09:38 d2.evaluation.evaluator]: [0mInference done 609/8355. 0.1170 s / img. ETA=0:15:22
[32m[04/20 16:09:43 d2.evaluation.evaluator]: [0mInference done 651/8355. 0.1170 s / img. ETA=0:15:17
[32m[04/20 16:09:48 d2.evaluation.evaluator]: [0mInference done 693/8355. 0.1170 s / img. ETA=0:15:12
[32m[04/20 16:09:53 d2.evaluation.evaluator]: [0mInference done 735/8355. 0.1170 s / img. ETA=0:15:07
[32m[04/20 16:09:58 d2.evaluation.evaluator]: [0mInference done 778/8355. 0.1170 s / img. ETA=0:15:02
[32m[04/20 16:10:03 d2.evaluation.evaluator]: [0mInference done 820/8355. 0.1170 s / img. ETA=0:14:57
[32m[04/20 16:10:08 d2.evaluation.evaluator]: [0mInference done 862/8355. 0.1170 s / img. ETA=0:14:52
[32m[04/20 16:10:13 d2.evaluation.evaluator]: [0mInference done 904/8355. 0.1170 s / img. ETA=0:14:48
[32m[04/20 16:10:18 d2.evaluation.evaluator]: [0mInference done 946/8355. 0.1170 s / img. ETA=0:14:43
[32m[04/20 16:10:23 d2.evaluation.evaluator]: [0mInference done 989/8355. 0.1170 s / img. ETA=0:14:37
[32m[04/20 16:10:28 d2.evaluation.evaluator]: [0mInference done 1032/8355. 0.1170 s / img. ETA=0:14:32
[32m[04/20 16:10:33 d2.evaluation.evaluator]: [0mInference done 1074/8355. 0.1170 s / img. ETA=0:14:27
[32m[04/20 16:10:38 d2.evaluation.evaluator]: [0mInference done 1117/8355. 0.1170 s / img. ETA=0:14:22
[32m[04/20 16:10:43 d2.evaluation.evaluator]: [0mInference done 1160/8355. 0.1169 s / img. ETA=0:14:17
[32m[04/20 16:10:48 d2.evaluation.evaluator]: [0mInference done 1203/8355. 0.1169 s / img. ETA=0:14:11
[32m[04/20 16:10:53 d2.evaluation.evaluator]: [0mInference done 1245/8355. 0.1169 s / img. ETA=0:14:07
[32m[04/20 16:10:58 d2.evaluation.evaluator]: [0mInference done 1287/8355. 0.1169 s / img. ETA=0:14:02
[32m[04/20 16:11:03 d2.evaluation.evaluator]: [0mInference done 1330/8355. 0.1169 s / img. ETA=0:13:56
[32m[04/20 16:11:09 d2.evaluation.evaluator]: [0mInference done 1373/8355. 0.1169 s / img. ETA=0:13:51
[32m[04/20 16:11:14 d2.evaluation.evaluator]: [0mInference done 1416/8355. 0.1169 s / img. ETA=0:13:46
[32m[04/20 16:11:19 d2.evaluation.evaluator]: [0mInference done 1459/8355. 0.1169 s / img. ETA=0:13:41
[32m[04/20 16:11:24 d2.evaluation.evaluator]: [0mInference done 1501/8355. 0.1169 s / img. ETA=0:13:36
[32m[04/20 16:11:29 d2.evaluation.evaluator]: [0mInference done 1543/8355. 0.1169 s / img. ETA=0:13:31
[32m[04/20 16:11:34 d2.evaluation.evaluator]: [0mInference done 1585/8355. 0.1170 s / img. ETA=0:13:26
[32m[04/20 16:11:39 d2.evaluation.evaluator]: [0mInference done 1627/8355. 0.1170 s / img. ETA=0:13:22
[32m[04/20 16:11:44 d2.evaluation.evaluator]: [0mInference done 1669/8355. 0.1171 s / img. ETA=0:13:17
[32m[04/20 16:11:49 d2.evaluation.evaluator]: [0mInference done 1711/8355. 0.1171 s / img. ETA=0:13:12
[32m[04/20 16:11:54 d2.evaluation.evaluator]: [0mInference done 1753/8355. 0.1171 s / img. ETA=0:13:08
[32m[04/20 16:11:59 d2.evaluation.evaluator]: [0mInference done 1795/8355. 0.1172 s / img. ETA=0:13:03
[32m[04/20 16:12:04 d2.evaluation.evaluator]: [0mInference done 1837/8355. 0.1172 s / img. ETA=0:12:58
[32m[04/20 16:12:10 d2.evaluation.evaluator]: [0mInference done 1879/8355. 0.1173 s / img. ETA=0:12:53
[32m[04/20 16:12:15 d2.evaluation.evaluator]: [0mInference done 1921/8355. 0.1173 s / img. ETA=0:12:48
[32m[04/20 16:12:20 d2.evaluation.evaluator]: [0mInference done 1963/8355. 0.1173 s / img. ETA=0:12:44
[32m[04/20 16:12:25 d2.evaluation.evaluator]: [0mInference done 2005/8355. 0.1173 s / img. ETA=0:12:39
[32m[04/20 16:12:30 d2.evaluation.evaluator]: [0mInference done 2047/8355. 0.1173 s / img. ETA=0:12:34
[32m[04/20 16:12:35 d2.evaluation.evaluator]: [0mInference done 2089/8355. 0.1173 s / img. ETA=0:12:29
[32m[04/20 16:12:40 d2.evaluation.evaluator]: [0mInference done 2131/8355. 0.1173 s / img. ETA=0:12:24
[32m[04/20 16:12:45 d2.evaluation.evaluator]: [0mInference done 2173/8355. 0.1173 s / img. ETA=0:12:19
[32m[04/20 16:12:50 d2.evaluation.evaluator]: [0mInference done 2215/8355. 0.1174 s / img. ETA=0:12:14
[32m[04/20 16:12:55 d2.evaluation.evaluator]: [0mInference done 2257/8355. 0.1174 s / img. ETA=0:12:09
[32m[04/20 16:13:00 d2.evaluation.evaluator]: [0mInference done 2299/8355. 0.1174 s / img. ETA=0:12:04
[32m[04/20 16:13:05 d2.evaluation.evaluator]: [0mInference done 2341/8355. 0.1174 s / img. ETA=0:11:59
[32m[04/20 16:13:10 d2.evaluation.evaluator]: [0mInference done 2383/8355. 0.1174 s / img. ETA=0:11:54
[32m[04/20 16:13:15 d2.evaluation.evaluator]: [0mInference done 2425/8355. 0.1175 s / img. ETA=0:11:50
[32m[04/20 16:13:20 d2.evaluation.evaluator]: [0mInference done 2467/8355. 0.1175 s / img. ETA=0:11:45
[32m[04/20 16:13:25 d2.evaluation.evaluator]: [0mInference done 2509/8355. 0.1175 s / img. ETA=0:11:40
[32m[04/20 16:13:31 d2.evaluation.evaluator]: [0mInference done 2551/8355. 0.1175 s / img. ETA=0:11:35
[32m[04/20 16:13:36 d2.evaluation.evaluator]: [0mInference done 2593/8355. 0.1175 s / img. ETA=0:11:30
[32m[04/20 16:13:41 d2.evaluation.evaluator]: [0mInference done 2635/8355. 0.1175 s / img. ETA=0:11:25
[32m[04/20 16:13:46 d2.evaluation.evaluator]: [0mInference done 2677/8355. 0.1175 s / img. ETA=0:11:19
[32m[04/20 16:13:51 d2.evaluation.evaluator]: [0mInference done 2719/8355. 0.1175 s / img. ETA=0:11:14
[32m[04/20 16:13:56 d2.evaluation.evaluator]: [0mInference done 2761/8355. 0.1175 s / img. ETA=0:11:09
[32m[04/20 16:14:01 d2.evaluation.evaluator]: [0mInference done 2803/8355. 0.1174 s / img. ETA=0:11:04
[32m[04/20 16:14:06 d2.evaluation.evaluator]: [0mInference done 2845/8355. 0.1175 s / img. ETA=0:10:59
[32m[04/20 16:14:11 d2.evaluation.evaluator]: [0mInference done 2887/8355. 0.1174 s / img. ETA=0:10:54
[32m[04/20 16:14:16 d2.evaluation.evaluator]: [0mInference done 2929/8355. 0.1174 s / img. ETA=0:10:49
[32m[04/20 16:14:21 d2.evaluation.evaluator]: [0mInference done 2971/8355. 0.1174 s / img. ETA=0:10:44
[32m[04/20 16:14:26 d2.evaluation.evaluator]: [0mInference done 3013/8355. 0.1174 s / img. ETA=0:10:39
[32m[04/20 16:14:31 d2.evaluation.evaluator]: [0mInference done 3055/8355. 0.1174 s / img. ETA=0:10:34
[32m[04/20 16:14:36 d2.evaluation.evaluator]: [0mInference done 3097/8355. 0.1174 s / img. ETA=0:10:29
[32m[04/20 16:14:41 d2.evaluation.evaluator]: [0mInference done 3139/8355. 0.1174 s / img. ETA=0:10:24
[32m[04/20 16:14:46 d2.evaluation.evaluator]: [0mInference done 3182/8355. 0.1174 s / img. ETA=0:10:19
[32m[04/20 16:14:51 d2.evaluation.evaluator]: [0mInference done 3225/8355. 0.1174 s / img. ETA=0:10:14
[32m[04/20 16:14:56 d2.evaluation.evaluator]: [0mInference done 3267/8355. 0.1174 s / img. ETA=0:10:09
[32m[04/20 16:15:01 d2.evaluation.evaluator]: [0mInference done 3310/8355. 0.1174 s / img. ETA=0:10:03
[32m[04/20 16:15:06 d2.evaluation.evaluator]: [0mInference done 3353/8355. 0.1173 s / img. ETA=0:09:58
[32m[04/20 16:15:11 d2.evaluation.evaluator]: [0mInference done 3396/8355. 0.1173 s / img. ETA=0:09:53
[32m[04/20 16:15:16 d2.evaluation.evaluator]: [0mInference done 3439/8355. 0.1173 s / img. ETA=0:09:48
[32m[04/20 16:15:21 d2.evaluation.evaluator]: [0mInference done 3481/8355. 0.1173 s / img. ETA=0:09:43
[32m[04/20 16:15:27 d2.evaluation.evaluator]: [0mInference done 3523/8355. 0.1173 s / img. ETA=0:09:38
[32m[04/20 16:15:32 d2.evaluation.evaluator]: [0mInference done 3566/8355. 0.1173 s / img. ETA=0:09:32
[32m[04/20 16:15:37 d2.evaluation.evaluator]: [0mInference done 3609/8355. 0.1173 s / img. ETA=0:09:27
[32m[04/20 16:15:42 d2.evaluation.evaluator]: [0mInference done 3651/8355. 0.1173 s / img. ETA=0:09:22
[32m[04/20 16:15:47 d2.evaluation.evaluator]: [0mInference done 3693/8355. 0.1173 s / img. ETA=0:09:17
[32m[04/20 16:15:52 d2.evaluation.evaluator]: [0mInference done 3735/8355. 0.1173 s / img. ETA=0:09:12
[32m[04/20 16:15:57 d2.evaluation.evaluator]: [0mInference done 3778/8355. 0.1172 s / img. ETA=0:09:07
[32m[04/20 16:16:02 d2.evaluation.evaluator]: [0mInference done 3820/8355. 0.1173 s / img. ETA=0:09:02
[32m[04/20 16:16:07 d2.evaluation.evaluator]: [0mInference done 3862/8355. 0.1173 s / img. ETA=0:08:57
[32m[04/20 16:16:12 d2.evaluation.evaluator]: [0mInference done 3905/8355. 0.1172 s / img. ETA=0:08:52
[32m[04/20 16:16:17 d2.evaluation.evaluator]: [0mInference done 3947/8355. 0.1172 s / img. ETA=0:08:47
[32m[04/20 16:16:22 d2.evaluation.evaluator]: [0mInference done 3989/8355. 0.1172 s / img. ETA=0:08:42
[32m[04/20 16:16:27 d2.evaluation.evaluator]: [0mInference done 4031/8355. 0.1172 s / img. ETA=0:08:37
[32m[04/20 16:16:32 d2.evaluation.evaluator]: [0mInference done 4073/8355. 0.1172 s / img. ETA=0:08:32
[32m[04/20 16:16:37 d2.evaluation.evaluator]: [0mInference done 4115/8355. 0.1172 s / img. ETA=0:08:27
[32m[04/20 16:16:42 d2.evaluation.evaluator]: [0mInference done 4157/8355. 0.1172 s / img. ETA=0:08:22
[32m[04/20 16:16:47 d2.evaluation.evaluator]: [0mInference done 4199/8355. 0.1172 s / img. ETA=0:08:17
[32m[04/20 16:16:52 d2.evaluation.evaluator]: [0mInference done 4241/8355. 0.1172 s / img. ETA=0:08:12
[32m[04/20 16:16:57 d2.evaluation.evaluator]: [0mInference done 4284/8355. 0.1172 s / img. ETA=0:08:06
[32m[04/20 16:17:02 d2.evaluation.evaluator]: [0mInference done 4326/8355. 0.1172 s / img. ETA=0:08:01
[32m[04/20 16:17:07 d2.evaluation.evaluator]: [0mInference done 4369/8355. 0.1172 s / img. ETA=0:07:56
[32m[04/20 16:17:13 d2.evaluation.evaluator]: [0mInference done 4411/8355. 0.1172 s / img. ETA=0:07:51
[32m[04/20 16:17:18 d2.evaluation.evaluator]: [0mInference done 4453/8355. 0.1172 s / img. ETA=0:07:46
[32m[04/20 16:17:23 d2.evaluation.evaluator]: [0mInference done 4495/8355. 0.1172 s / img. ETA=0:07:41
[32m[04/20 16:17:28 d2.evaluation.evaluator]: [0mInference done 4537/8355. 0.1172 s / img. ETA=0:07:36
[32m[04/20 16:17:33 d2.evaluation.evaluator]: [0mInference done 4579/8355. 0.1172 s / img. ETA=0:07:31
[32m[04/20 16:17:38 d2.evaluation.evaluator]: [0mInference done 4621/8355. 0.1172 s / img. ETA=0:07:26
[32m[04/20 16:17:43 d2.evaluation.evaluator]: [0mInference done 4663/8355. 0.1172 s / img. ETA=0:07:21
[32m[04/20 16:17:48 d2.evaluation.evaluator]: [0mInference done 4705/8355. 0.1172 s / img. ETA=0:07:16
[32m[04/20 16:17:53 d2.evaluation.evaluator]: [0mInference done 4747/8355. 0.1172 s / img. ETA=0:07:11
[32m[04/20 16:17:58 d2.evaluation.evaluator]: [0mInference done 4789/8355. 0.1172 s / img. ETA=0:07:06
[32m[04/20 16:18:03 d2.evaluation.evaluator]: [0mInference done 4831/8355. 0.1172 s / img. ETA=0:07:01
[32m[04/20 16:18:08 d2.evaluation.evaluator]: [0mInference done 4873/8355. 0.1172 s / img. ETA=0:06:56
[32m[04/20 16:18:13 d2.evaluation.evaluator]: [0mInference done 4915/8355. 0.1172 s / img. ETA=0:06:51
[32m[04/20 16:18:18 d2.evaluation.evaluator]: [0mInference done 4957/8355. 0.1172 s / img. ETA=0:06:46
[32m[04/20 16:18:23 d2.evaluation.evaluator]: [0mInference done 5000/8355. 0.1172 s / img. ETA=0:06:41
[32m[04/20 16:18:28 d2.evaluation.evaluator]: [0mInference done 5042/8355. 0.1172 s / img. ETA=0:06:36
[32m[04/20 16:18:33 d2.evaluation.evaluator]: [0mInference done 5084/8355. 0.1172 s / img. ETA=0:06:31
[32m[04/20 16:18:38 d2.evaluation.evaluator]: [0mInference done 5126/8355. 0.1172 s / img. ETA=0:06:26
[32m[04/20 16:18:43 d2.evaluation.evaluator]: [0mInference done 5168/8355. 0.1172 s / img. ETA=0:06:21
[32m[04/20 16:18:48 d2.evaluation.evaluator]: [0mInference done 5210/8355. 0.1172 s / img. ETA=0:06:16
[32m[04/20 16:18:53 d2.evaluation.evaluator]: [0mInference done 5253/8355. 0.1172 s / img. ETA=0:06:10
[32m[04/20 16:18:58 d2.evaluation.evaluator]: [0mInference done 5295/8355. 0.1172 s / img. ETA=0:06:05
[32m[04/20 16:19:03 d2.evaluation.evaluator]: [0mInference done 5337/8355. 0.1172 s / img. ETA=0:06:00
[32m[04/20 16:19:08 d2.evaluation.evaluator]: [0mInference done 5379/8355. 0.1172 s / img. ETA=0:05:55
[32m[04/20 16:19:13 d2.evaluation.evaluator]: [0mInference done 5421/8355. 0.1172 s / img. ETA=0:05:50
[32m[04/20 16:19:18 d2.evaluation.evaluator]: [0mInference done 5463/8355. 0.1172 s / img. ETA=0:05:45
[32m[04/20 16:19:23 d2.evaluation.evaluator]: [0mInference done 5505/8355. 0.1172 s / img. ETA=0:05:40
[32m[04/20 16:19:28 d2.evaluation.evaluator]: [0mInference done 5548/8355. 0.1172 s / img. ETA=0:05:35
[32m[04/20 16:19:33 d2.evaluation.evaluator]: [0mInference done 5591/8355. 0.1172 s / img. ETA=0:05:30
[32m[04/20 16:19:38 d2.evaluation.evaluator]: [0mInference done 5633/8355. 0.1172 s / img. ETA=0:05:25
[32m[04/20 16:19:43 d2.evaluation.evaluator]: [0mInference done 5675/8355. 0.1172 s / img. ETA=0:05:20
[32m[04/20 16:19:49 d2.evaluation.evaluator]: [0mInference done 5718/8355. 0.1171 s / img. ETA=0:05:15
[32m[04/20 16:19:54 d2.evaluation.evaluator]: [0mInference done 5760/8355. 0.1171 s / img. ETA=0:05:10
[32m[04/20 16:19:59 d2.evaluation.evaluator]: [0mInference done 5802/8355. 0.1171 s / img. ETA=0:05:05
[32m[04/20 16:20:04 d2.evaluation.evaluator]: [0mInference done 5844/8355. 0.1172 s / img. ETA=0:05:00
[32m[04/20 16:20:09 d2.evaluation.evaluator]: [0mInference done 5886/8355. 0.1172 s / img. ETA=0:04:55
[32m[04/20 16:20:14 d2.evaluation.evaluator]: [0mInference done 5928/8355. 0.1172 s / img. ETA=0:04:50
[32m[04/20 16:20:19 d2.evaluation.evaluator]: [0mInference done 5970/8355. 0.1172 s / img. ETA=0:04:45
[32m[04/20 16:20:24 d2.evaluation.evaluator]: [0mInference done 6012/8355. 0.1172 s / img. ETA=0:04:40
[32m[04/20 16:20:29 d2.evaluation.evaluator]: [0mInference done 6054/8355. 0.1172 s / img. ETA=0:04:35
[32m[04/20 16:20:34 d2.evaluation.evaluator]: [0mInference done 6096/8355. 0.1172 s / img. ETA=0:04:30
[32m[04/20 16:20:39 d2.evaluation.evaluator]: [0mInference done 6138/8355. 0.1172 s / img. ETA=0:04:25
[32m[04/20 16:20:44 d2.evaluation.evaluator]: [0mInference done 6180/8355. 0.1172 s / img. ETA=0:04:20
[32m[04/20 16:20:49 d2.evaluation.evaluator]: [0mInference done 6222/8355. 0.1172 s / img. ETA=0:04:15
[32m[04/20 16:20:54 d2.evaluation.evaluator]: [0mInference done 6264/8355. 0.1172 s / img. ETA=0:04:10
[32m[04/20 16:20:59 d2.evaluation.evaluator]: [0mInference done 6306/8355. 0.1172 s / img. ETA=0:04:05
[32m[04/20 16:21:04 d2.evaluation.evaluator]: [0mInference done 6348/8355. 0.1172 s / img. ETA=0:04:00
[32m[04/20 16:21:09 d2.evaluation.evaluator]: [0mInference done 6390/8355. 0.1172 s / img. ETA=0:03:55
[32m[04/20 16:21:14 d2.evaluation.evaluator]: [0mInference done 6432/8355. 0.1172 s / img. ETA=0:03:50
[32m[04/20 16:21:19 d2.evaluation.evaluator]: [0mInference done 6474/8355. 0.1172 s / img. ETA=0:03:44
[32m[04/20 16:21:25 d2.evaluation.evaluator]: [0mInference done 6517/8355. 0.1172 s / img. ETA=0:03:39
[32m[04/20 16:21:30 d2.evaluation.evaluator]: [0mInference done 6560/8355. 0.1172 s / img. ETA=0:03:34
[32m[04/20 16:21:35 d2.evaluation.evaluator]: [0mInference done 6602/8355. 0.1172 s / img. ETA=0:03:29
[32m[04/20 16:21:40 d2.evaluation.evaluator]: [0mInference done 6644/8355. 0.1172 s / img. ETA=0:03:24
[32m[04/20 16:21:45 d2.evaluation.evaluator]: [0mInference done 6687/8355. 0.1172 s / img. ETA=0:03:19
[32m[04/20 16:21:50 d2.evaluation.evaluator]: [0mInference done 6730/8355. 0.1172 s / img. ETA=0:03:14
[32m[04/20 16:21:55 d2.evaluation.evaluator]: [0mInference done 6773/8355. 0.1172 s / img. ETA=0:03:09
[32m[04/20 16:22:00 d2.evaluation.evaluator]: [0mInference done 6816/8355. 0.1172 s / img. ETA=0:03:04
[32m[04/20 16:22:05 d2.evaluation.evaluator]: [0mInference done 6858/8355. 0.1172 s / img. ETA=0:02:59
[32m[04/20 16:22:10 d2.evaluation.evaluator]: [0mInference done 6901/8355. 0.1172 s / img. ETA=0:02:53
[32m[04/20 16:22:15 d2.evaluation.evaluator]: [0mInference done 6943/8355. 0.1171 s / img. ETA=0:02:48
[32m[04/20 16:22:20 d2.evaluation.evaluator]: [0mInference done 6985/8355. 0.1171 s / img. ETA=0:02:43
[32m[04/20 16:22:25 d2.evaluation.evaluator]: [0mInference done 7027/8355. 0.1171 s / img. ETA=0:02:38
[32m[04/20 16:22:30 d2.evaluation.evaluator]: [0mInference done 7069/8355. 0.1172 s / img. ETA=0:02:33
[32m[04/20 16:22:35 d2.evaluation.evaluator]: [0mInference done 7111/8355. 0.1172 s / img. ETA=0:02:28
[32m[04/20 16:22:40 d2.evaluation.evaluator]: [0mInference done 7153/8355. 0.1172 s / img. ETA=0:02:23
[32m[04/20 16:22:45 d2.evaluation.evaluator]: [0mInference done 7195/8355. 0.1172 s / img. ETA=0:02:18
[32m[04/20 16:22:51 d2.evaluation.evaluator]: [0mInference done 7237/8355. 0.1172 s / img. ETA=0:02:13
[32m[04/20 16:22:56 d2.evaluation.evaluator]: [0mInference done 7279/8355. 0.1172 s / img. ETA=0:02:08
[32m[04/20 16:23:01 d2.evaluation.evaluator]: [0mInference done 7321/8355. 0.1172 s / img. ETA=0:02:03
[32m[04/20 16:23:06 d2.evaluation.evaluator]: [0mInference done 7363/8355. 0.1172 s / img. ETA=0:01:58
[32m[04/20 16:23:11 d2.evaluation.evaluator]: [0mInference done 7405/8355. 0.1172 s / img. ETA=0:01:53
[32m[04/20 16:23:16 d2.evaluation.evaluator]: [0mInference done 7447/8355. 0.1172 s / img. ETA=0:01:48
[32m[04/20 16:23:21 d2.evaluation.evaluator]: [0mInference done 7489/8355. 0.1172 s / img. ETA=0:01:43
[32m[04/20 16:23:26 d2.evaluation.evaluator]: [0mInference done 7531/8355. 0.1172 s / img. ETA=0:01:38
[32m[04/20 16:23:31 d2.evaluation.evaluator]: [0mInference done 7573/8355. 0.1172 s / img. ETA=0:01:33
[32m[04/20 16:23:36 d2.evaluation.evaluator]: [0mInference done 7615/8355. 0.1172 s / img. ETA=0:01:28
[32m[04/20 16:23:41 d2.evaluation.evaluator]: [0mInference done 7657/8355. 0.1172 s / img. ETA=0:01:23
[32m[04/20 16:23:46 d2.evaluation.evaluator]: [0mInference done 7699/8355. 0.1172 s / img. ETA=0:01:18
[32m[04/20 16:23:51 d2.evaluation.evaluator]: [0mInference done 7741/8355. 0.1172 s / img. ETA=0:01:13
[32m[04/20 16:23:56 d2.evaluation.evaluator]: [0mInference done 7783/8355. 0.1172 s / img. ETA=0:01:08
[32m[04/20 16:24:01 d2.evaluation.evaluator]: [0mInference done 7825/8355. 0.1172 s / img. ETA=0:01:03
[32m[04/20 16:24:06 d2.evaluation.evaluator]: [0mInference done 7867/8355. 0.1172 s / img. ETA=0:00:58
[32m[04/20 16:24:11 d2.evaluation.evaluator]: [0mInference done 7909/8355. 0.1172 s / img. ETA=0:00:53
[32m[04/20 16:24:16 d2.evaluation.evaluator]: [0mInference done 7951/8355. 0.1172 s / img. ETA=0:00:48
[32m[04/20 16:24:21 d2.evaluation.evaluator]: [0mInference done 7993/8355. 0.1172 s / img. ETA=0:00:43
[32m[04/20 16:24:26 d2.evaluation.evaluator]: [0mInference done 8036/8355. 0.1172 s / img. ETA=0:00:38
[32m[04/20 16:24:32 d2.evaluation.evaluator]: [0mInference done 8079/8355. 0.1172 s / img. ETA=0:00:33
[32m[04/20 16:24:37 d2.evaluation.evaluator]: [0mInference done 8122/8355. 0.1172 s / img. ETA=0:00:27
[32m[04/20 16:24:42 d2.evaluation.evaluator]: [0mInference done 8165/8355. 0.1172 s / img. ETA=0:00:22
[32m[04/20 16:24:47 d2.evaluation.evaluator]: [0mInference done 8208/8355. 0.1172 s / img. ETA=0:00:17
[32m[04/20 16:24:52 d2.evaluation.evaluator]: [0mInference done 8250/8355. 0.1172 s / img. ETA=0:00:12
[32m[04/20 16:24:57 d2.evaluation.evaluator]: [0mInference done 8292/8355. 0.1172 s / img. ETA=0:00:07
[32m[04/20 16:25:02 d2.evaluation.evaluator]: [0mInference done 8334/8355. 0.1172 s / img. ETA=0:00:02
[32m[04/20 16:25:05 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:38.943154 (0.119634 s / img per device, on 1 devices)
[32m[04/20 16:25:05 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:18 (0.117196 s / img per device, on 1 devices)
[32m[04/20 16:25:05 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 16:25:05 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 16:25:05 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.45s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.66s).
Accumulating evaluation results...
DONE (t=2.19s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.392
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.736
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.364
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.290
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.517
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.447
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.368
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.668
[32m[04/20 16:25:27 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.237 | 73.639 | 36.385 | 29.021 | 51.688 | 63.035 |
[32m[04/20 16:25:27 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 39.900 | bicycle       | 29.823 | car            | 47.989 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 16:25:29 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 16:25:29 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 16:25:29 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 16:25:30 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1169 s / img. ETA=0:02:28
[32m[04/20 16:25:35 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1168 s / img. ETA=0:02:23
[32m[04/20 16:25:40 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1169 s / img. ETA=0:02:18
[32m[04/20 16:25:45 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1169 s / img. ETA=0:02:13
[32m[04/20 16:25:50 d2.evaluation.evaluator]: [0mInference done 179/1257. 0.1169 s / img. ETA=0:02:08
[32m[04/20 16:25:55 d2.evaluation.evaluator]: [0mInference done 221/1257. 0.1169 s / img. ETA=0:02:03
[32m[04/20 16:26:00 d2.evaluation.evaluator]: [0mInference done 263/1257. 0.1169 s / img. ETA=0:01:58
[32m[04/20 16:26:05 d2.evaluation.evaluator]: [0mInference done 305/1257. 0.1169 s / img. ETA=0:01:53
[32m[04/20 16:26:10 d2.evaluation.evaluator]: [0mInference done 347/1257. 0.1169 s / img. ETA=0:01:48
[32m[04/20 16:26:15 d2.evaluation.evaluator]: [0mInference done 389/1257. 0.1169 s / img. ETA=0:01:43
[32m[04/20 16:26:20 d2.evaluation.evaluator]: [0mInference done 431/1257. 0.1169 s / img. ETA=0:01:38
[32m[04/20 16:26:25 d2.evaluation.evaluator]: [0mInference done 473/1257. 0.1168 s / img. ETA=0:01:33
[32m[04/20 16:26:30 d2.evaluation.evaluator]: [0mInference done 515/1257. 0.1168 s / img. ETA=0:01:28
[32m[04/20 16:26:35 d2.evaluation.evaluator]: [0mInference done 557/1257. 0.1169 s / img. ETA=0:01:23
[32m[04/20 16:26:40 d2.evaluation.evaluator]: [0mInference done 599/1257. 0.1169 s / img. ETA=0:01:18
[32m[04/20 16:26:45 d2.evaluation.evaluator]: [0mInference done 641/1257. 0.1169 s / img. ETA=0:01:13
[32m[04/20 16:26:50 d2.evaluation.evaluator]: [0mInference done 683/1257. 0.1169 s / img. ETA=0:01:08
[32m[04/20 16:26:55 d2.evaluation.evaluator]: [0mInference done 725/1257. 0.1169 s / img. ETA=0:01:03
[32m[04/20 16:27:00 d2.evaluation.evaluator]: [0mInference done 767/1257. 0.1169 s / img. ETA=0:00:58
[32m[04/20 16:27:05 d2.evaluation.evaluator]: [0mInference done 809/1257. 0.1169 s / img. ETA=0:00:53
[32m[04/20 16:27:11 d2.evaluation.evaluator]: [0mInference done 851/1257. 0.1170 s / img. ETA=0:00:48
[32m[04/20 16:27:16 d2.evaluation.evaluator]: [0mInference done 893/1257. 0.1170 s / img. ETA=0:00:43
[32m[04/20 16:27:21 d2.evaluation.evaluator]: [0mInference done 935/1257. 0.1170 s / img. ETA=0:00:38
[32m[04/20 16:27:26 d2.evaluation.evaluator]: [0mInference done 977/1257. 0.1170 s / img. ETA=0:00:33
[32m[04/20 16:27:31 d2.evaluation.evaluator]: [0mInference done 1019/1257. 0.1171 s / img. ETA=0:00:28
[32m[04/20 16:27:36 d2.evaluation.evaluator]: [0mInference done 1061/1257. 0.1171 s / img. ETA=0:00:23
[32m[04/20 16:27:41 d2.evaluation.evaluator]: [0mInference done 1103/1257. 0.1171 s / img. ETA=0:00:18
[32m[04/20 16:27:46 d2.evaluation.evaluator]: [0mInference done 1145/1257. 0.1171 s / img. ETA=0:00:13
[32m[04/20 16:27:51 d2.evaluation.evaluator]: [0mInference done 1187/1257. 0.1171 s / img. ETA=0:00:08
[32m[04/20 16:27:56 d2.evaluation.evaluator]: [0mInference done 1229/1257. 0.1171 s / img. ETA=0:00:03
[32m[04/20 16:27:59 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:29.743157 (0.119603 s / img per device, on 1 devices)
[32m[04/20 16:27:59 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:26 (0.117064 s / img per device, on 1 devices)
[32m[04/20 16:27:59 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 16:27:59 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 16:27:59 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.53s).
Accumulating evaluation results...
DONE (t=0.36s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.297
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.580
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.269
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.188
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.365
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.455
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.155
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.368
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.371
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.271
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.438
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.484
[32m[04/20 16:28:02 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 29.700 | 57.981 | 26.915 | 18.758 | 36.521 | 45.452 |
[32m[04/20 16:28:02 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 32.170 | bicycle       | 13.208 | car            | 43.721 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  18  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 16:28:03 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 16:28:03 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 16:28:03 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 16:28:04 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 16:28:04 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 16:28:04 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 16:28:04 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 16:28:24 d2.utils.events]: [0m eta: 0:16:41  iter: 19  total_loss: 0.589  loss_cls: 0.190  loss_box_reg: 0.345  loss_rpn_cls: 0.014  loss_rpn_loc: 0.053  time: 1.0103  data_time: 0.0291  lr: 0.000100  max_mem: 5406M
[32m[04/20 16:28:45 d2.utils.events]: [0m eta: 0:16:22  iter: 39  total_loss: 0.646  loss_cls: 0.204  loss_box_reg: 0.345  loss_rpn_cls: 0.013  loss_rpn_loc: 0.071  time: 1.0173  data_time: 0.0095  lr: 0.000200  max_mem: 5406M
[32m[04/20 16:29:06 d2.utils.events]: [0m eta: 0:16:19  iter: 59  total_loss: 0.530  loss_cls: 0.188  loss_box_reg: 0.289  loss_rpn_cls: 0.013  loss_rpn_loc: 0.046  time: 1.0273  data_time: 0.0097  lr: 0.000300  max_mem: 5406M
[32m[04/20 16:29:27 d2.utils.events]: [0m eta: 0:16:05  iter: 79  total_loss: 0.606  loss_cls: 0.186  loss_box_reg: 0.330  loss_rpn_cls: 0.013  loss_rpn_loc: 0.049  time: 1.0329  data_time: 0.0096  lr: 0.000400  max_mem: 5406M
[32m[04/20 16:29:47 d2.utils.events]: [0m eta: 0:15:48  iter: 99  total_loss: 0.537  loss_cls: 0.176  loss_box_reg: 0.313  loss_rpn_cls: 0.008  loss_rpn_loc: 0.045  time: 1.0348  data_time: 0.0099  lr: 0.000500  max_mem: 5406M
[32m[04/20 16:30:08 d2.utils.events]: [0m eta: 0:15:28  iter: 119  total_loss: 0.577  loss_cls: 0.200  loss_box_reg: 0.325  loss_rpn_cls: 0.013  loss_rpn_loc: 0.048  time: 1.0360  data_time: 0.0098  lr: 0.000599  max_mem: 5406M
[32m[04/20 16:30:29 d2.utils.events]: [0m eta: 0:15:04  iter: 139  total_loss: 0.594  loss_cls: 0.182  loss_box_reg: 0.328  loss_rpn_cls: 0.017  loss_rpn_loc: 0.054  time: 1.0343  data_time: 0.0097  lr: 0.000699  max_mem: 5406M
[32m[04/20 16:30:49 d2.utils.events]: [0m eta: 0:14:38  iter: 159  total_loss: 0.588  loss_cls: 0.182  loss_box_reg: 0.317  loss_rpn_cls: 0.014  loss_rpn_loc: 0.050  time: 1.0328  data_time: 0.0097  lr: 0.000799  max_mem: 5406M
[32m[04/20 16:31:10 d2.utils.events]: [0m eta: 0:14:17  iter: 179  total_loss: 0.537  loss_cls: 0.164  loss_box_reg: 0.286  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 1.0338  data_time: 0.0096  lr: 0.000899  max_mem: 5406M
[32m[04/20 16:31:31 d2.utils.events]: [0m eta: 0:14:01  iter: 199  total_loss: 0.596  loss_cls: 0.188  loss_box_reg: 0.351  loss_rpn_cls: 0.011  loss_rpn_loc: 0.056  time: 1.0354  data_time: 0.0103  lr: 0.000999  max_mem: 5406M
[32m[04/20 16:31:52 d2.utils.events]: [0m eta: 0:13:40  iter: 219  total_loss: 0.565  loss_cls: 0.177  loss_box_reg: 0.336  loss_rpn_cls: 0.012  loss_rpn_loc: 0.054  time: 1.0344  data_time: 0.0096  lr: 0.001099  max_mem: 5406M
[32m[04/20 16:32:12 d2.utils.events]: [0m eta: 0:13:13  iter: 239  total_loss: 0.544  loss_cls: 0.175  loss_box_reg: 0.307  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 1.0315  data_time: 0.0094  lr: 0.001199  max_mem: 5406M
[32m[04/20 16:32:32 d2.utils.events]: [0m eta: 0:12:46  iter: 259  total_loss: 0.592  loss_cls: 0.179  loss_box_reg: 0.321  loss_rpn_cls: 0.015  loss_rpn_loc: 0.056  time: 1.0292  data_time: 0.0094  lr: 0.001299  max_mem: 5406M
[32m[04/20 16:32:53 d2.utils.events]: [0m eta: 0:12:28  iter: 279  total_loss: 0.561  loss_cls: 0.178  loss_box_reg: 0.302  loss_rpn_cls: 0.012  loss_rpn_loc: 0.044  time: 1.0304  data_time: 0.0095  lr: 0.001399  max_mem: 5406M
[32m[04/20 16:33:14 d2.utils.events]: [0m eta: 0:12:07  iter: 299  total_loss: 0.559  loss_cls: 0.173  loss_box_reg: 0.315  loss_rpn_cls: 0.011  loss_rpn_loc: 0.053  time: 1.0302  data_time: 0.0096  lr: 0.001499  max_mem: 5406M
[32m[04/20 16:33:34 d2.utils.events]: [0m eta: 0:11:47  iter: 319  total_loss: 0.524  loss_cls: 0.168  loss_box_reg: 0.299  loss_rpn_cls: 0.013  loss_rpn_loc: 0.039  time: 1.0298  data_time: 0.0099  lr: 0.001598  max_mem: 5406M
[32m[04/20 16:33:55 d2.utils.events]: [0m eta: 0:11:26  iter: 339  total_loss: 0.564  loss_cls: 0.192  loss_box_reg: 0.306  loss_rpn_cls: 0.012  loss_rpn_loc: 0.048  time: 1.0298  data_time: 0.0094  lr: 0.001698  max_mem: 5406M
[32m[04/20 16:34:15 d2.utils.events]: [0m eta: 0:11:05  iter: 359  total_loss: 0.630  loss_cls: 0.191  loss_box_reg: 0.344  loss_rpn_cls: 0.014  loss_rpn_loc: 0.059  time: 1.0297  data_time: 0.0096  lr: 0.001798  max_mem: 5406M
[32m[04/20 16:34:36 d2.utils.events]: [0m eta: 0:10:45  iter: 379  total_loss: 0.537  loss_cls: 0.176  loss_box_reg: 0.311  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 1.0301  data_time: 0.0097  lr: 0.001898  max_mem: 5406M
[32m[04/20 16:34:56 d2.utils.events]: [0m eta: 0:10:23  iter: 399  total_loss: 0.538  loss_cls: 0.172  loss_box_reg: 0.323  loss_rpn_cls: 0.015  loss_rpn_loc: 0.058  time: 1.0292  data_time: 0.0097  lr: 0.001998  max_mem: 5406M
[32m[04/20 16:35:17 d2.utils.events]: [0m eta: 0:10:01  iter: 419  total_loss: 0.587  loss_cls: 0.195  loss_box_reg: 0.327  loss_rpn_cls: 0.011  loss_rpn_loc: 0.057  time: 1.0288  data_time: 0.0093  lr: 0.002098  max_mem: 5406M
[32m[04/20 16:35:37 d2.utils.events]: [0m eta: 0:09:40  iter: 439  total_loss: 0.580  loss_cls: 0.176  loss_box_reg: 0.351  loss_rpn_cls: 0.010  loss_rpn_loc: 0.056  time: 1.0283  data_time: 0.0097  lr: 0.002198  max_mem: 5406M
[32m[04/20 16:35:58 d2.utils.events]: [0m eta: 0:09:21  iter: 459  total_loss: 0.611  loss_cls: 0.194  loss_box_reg: 0.337  loss_rpn_cls: 0.013  loss_rpn_loc: 0.058  time: 1.0295  data_time: 0.0099  lr: 0.002298  max_mem: 5406M
[32m[04/20 16:36:19 d2.utils.events]: [0m eta: 0:09:00  iter: 479  total_loss: 0.524  loss_cls: 0.158  loss_box_reg: 0.320  loss_rpn_cls: 0.008  loss_rpn_loc: 0.031  time: 1.0300  data_time: 0.0100  lr: 0.002398  max_mem: 5406M
[32m[04/20 16:36:41 d2.utils.events]: [0m eta: 0:08:40  iter: 499  total_loss: 0.587  loss_cls: 0.180  loss_box_reg: 0.341  loss_rpn_cls: 0.013  loss_rpn_loc: 0.048  time: 1.0312  data_time: 0.0099  lr: 0.002498  max_mem: 5406M
[32m[04/20 16:37:01 d2.utils.events]: [0m eta: 0:08:19  iter: 519  total_loss: 0.592  loss_cls: 0.192  loss_box_reg: 0.335  loss_rpn_cls: 0.011  loss_rpn_loc: 0.055  time: 1.0313  data_time: 0.0099  lr: 0.002597  max_mem: 5406M
[32m[04/20 16:37:22 d2.utils.events]: [0m eta: 0:07:58  iter: 539  total_loss: 0.627  loss_cls: 0.200  loss_box_reg: 0.342  loss_rpn_cls: 0.011  loss_rpn_loc: 0.055  time: 1.0309  data_time: 0.0096  lr: 0.002697  max_mem: 5406M
[32m[04/20 16:37:42 d2.utils.events]: [0m eta: 0:07:38  iter: 559  total_loss: 0.524  loss_cls: 0.156  loss_box_reg: 0.307  loss_rpn_cls: 0.011  loss_rpn_loc: 0.044  time: 1.0307  data_time: 0.0095  lr: 0.002797  max_mem: 5406M
[32m[04/20 16:38:03 d2.utils.events]: [0m eta: 0:07:17  iter: 579  total_loss: 0.553  loss_cls: 0.179  loss_box_reg: 0.320  loss_rpn_cls: 0.013  loss_rpn_loc: 0.045  time: 1.0308  data_time: 0.0098  lr: 0.002897  max_mem: 5406M
[32m[04/20 16:38:24 d2.utils.events]: [0m eta: 0:06:56  iter: 599  total_loss: 0.487  loss_cls: 0.153  loss_box_reg: 0.276  loss_rpn_cls: 0.009  loss_rpn_loc: 0.038  time: 1.0305  data_time: 0.0098  lr: 0.002997  max_mem: 5406M
[32m[04/20 16:38:45 d2.utils.events]: [0m eta: 0:06:35  iter: 619  total_loss: 0.620  loss_cls: 0.201  loss_box_reg: 0.342  loss_rpn_cls: 0.011  loss_rpn_loc: 0.050  time: 1.0312  data_time: 0.0097  lr: 0.003097  max_mem: 5406M
[32m[04/20 16:39:05 d2.utils.events]: [0m eta: 0:06:15  iter: 639  total_loss: 0.630  loss_cls: 0.201  loss_box_reg: 0.361  loss_rpn_cls: 0.012  loss_rpn_loc: 0.052  time: 1.0311  data_time: 0.0095  lr: 0.003197  max_mem: 5406M
[32m[04/20 16:39:26 d2.utils.events]: [0m eta: 0:05:54  iter: 659  total_loss: 0.675  loss_cls: 0.225  loss_box_reg: 0.375  loss_rpn_cls: 0.015  loss_rpn_loc: 0.071  time: 1.0311  data_time: 0.0098  lr: 0.003297  max_mem: 5406M
[32m[04/20 16:39:46 d2.utils.events]: [0m eta: 0:05:32  iter: 679  total_loss: 0.610  loss_cls: 0.199  loss_box_reg: 0.326  loss_rpn_cls: 0.015  loss_rpn_loc: 0.073  time: 1.0302  data_time: 0.0095  lr: 0.003397  max_mem: 5406M
[32m[04/20 16:40:07 d2.utils.events]: [0m eta: 0:05:11  iter: 699  total_loss: 0.566  loss_cls: 0.191  loss_box_reg: 0.338  loss_rpn_cls: 0.014  loss_rpn_loc: 0.051  time: 1.0301  data_time: 0.0096  lr: 0.003497  max_mem: 5406M
[32m[04/20 16:40:27 d2.utils.events]: [0m eta: 0:04:51  iter: 719  total_loss: 0.595  loss_cls: 0.191  loss_box_reg: 0.339  loss_rpn_cls: 0.015  loss_rpn_loc: 0.068  time: 1.0298  data_time: 0.0097  lr: 0.003596  max_mem: 5406M
[32m[04/20 16:40:47 d2.utils.events]: [0m eta: 0:04:30  iter: 739  total_loss: 0.642  loss_cls: 0.195  loss_box_reg: 0.352  loss_rpn_cls: 0.016  loss_rpn_loc: 0.086  time: 1.0289  data_time: 0.0096  lr: 0.003696  max_mem: 5406M
[32m[04/20 16:41:08 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.553  loss_cls: 0.169  loss_box_reg: 0.316  loss_rpn_cls: 0.012  loss_rpn_loc: 0.047  time: 1.0289  data_time: 0.0098  lr: 0.003796  max_mem: 5406M
[32m[04/20 16:41:28 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.657  loss_cls: 0.197  loss_box_reg: 0.337  loss_rpn_cls: 0.015  loss_rpn_loc: 0.063  time: 1.0281  data_time: 0.0095  lr: 0.003896  max_mem: 5406M
[32m[04/20 16:41:48 d2.utils.events]: [0m eta: 0:03:27  iter: 799  total_loss: 0.550  loss_cls: 0.187  loss_box_reg: 0.304  loss_rpn_cls: 0.009  loss_rpn_loc: 0.051  time: 1.0281  data_time: 0.0097  lr: 0.003996  max_mem: 5406M
[32m[04/20 16:42:09 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.597  loss_cls: 0.196  loss_box_reg: 0.341  loss_rpn_cls: 0.014  loss_rpn_loc: 0.047  time: 1.0279  data_time: 0.0101  lr: 0.004096  max_mem: 5406M
[32m[04/20 16:42:29 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.558  loss_cls: 0.191  loss_box_reg: 0.306  loss_rpn_cls: 0.014  loss_rpn_loc: 0.047  time: 1.0280  data_time: 0.0098  lr: 0.004196  max_mem: 5406M
[32m[04/20 16:42:50 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.554  loss_cls: 0.175  loss_box_reg: 0.318  loss_rpn_cls: 0.011  loss_rpn_loc: 0.041  time: 1.0283  data_time: 0.0097  lr: 0.004296  max_mem: 5406M
[32m[04/20 16:43:11 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.622  loss_cls: 0.201  loss_box_reg: 0.349  loss_rpn_cls: 0.015  loss_rpn_loc: 0.048  time: 1.0289  data_time: 0.0099  lr: 0.004396  max_mem: 5406M
[32m[04/20 16:43:32 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.547  loss_cls: 0.175  loss_box_reg: 0.311  loss_rpn_cls: 0.014  loss_rpn_loc: 0.051  time: 1.0286  data_time: 0.0099  lr: 0.004496  max_mem: 5406M
[32m[04/20 16:43:52 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.615  loss_cls: 0.213  loss_box_reg: 0.334  loss_rpn_cls: 0.012  loss_rpn_loc: 0.051  time: 1.0284  data_time: 0.0097  lr: 0.004595  max_mem: 5406M
[32m[04/20 16:44:13 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.633  loss_cls: 0.212  loss_box_reg: 0.351  loss_rpn_cls: 0.016  loss_rpn_loc: 0.060  time: 1.0287  data_time: 0.0096  lr: 0.004695  max_mem: 5406M
[32m[04/20 16:44:34 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.601  loss_cls: 0.198  loss_box_reg: 0.329  loss_rpn_cls: 0.016  loss_rpn_loc: 0.055  time: 1.0291  data_time: 0.0095  lr: 0.004795  max_mem: 5406M
[32m[04/20 16:44:54 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.572  loss_cls: 0.193  loss_box_reg: 0.307  loss_rpn_cls: 0.015  loss_rpn_loc: 0.048  time: 1.0285  data_time: 0.0087  lr: 0.004895  max_mem: 5406M
[5m[31mWARNING[0m [32m[04/20 16:45:21 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 16:45:21 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 16:45:21 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 16:45:21 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.584  loss_cls: 0.196  loss_box_reg: 0.338  loss_rpn_cls: 0.019  loss_rpn_loc: 0.051  time: 1.0288  data_time: 0.0092  lr: 0.004995  max_mem: 5406M
[32m[04/20 16:45:22 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:06 (1.0298 s / it)
[32m[04/20 16:45:22 d2.engine.hooks]: [0mTotal training time: 0:17:15 (0:00:09 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 16:45:24 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 16:45:24 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 16:45:24 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 16:45:26 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1161 s / img. ETA=0:16:23
[32m[04/20 16:45:31 d2.evaluation.evaluator]: [0mInference done 54/8355. 0.1161 s / img. ETA=0:16:21
[32m[04/20 16:45:36 d2.evaluation.evaluator]: [0mInference done 97/8355. 0.1159 s / img. ETA=0:16:14
[32m[04/20 16:45:41 d2.evaluation.evaluator]: [0mInference done 140/8355. 0.1157 s / img. ETA=0:16:08
[32m[04/20 16:45:46 d2.evaluation.evaluator]: [0mInference done 183/8355. 0.1156 s / img. ETA=0:16:02
[32m[04/20 16:45:51 d2.evaluation.evaluator]: [0mInference done 226/8355. 0.1157 s / img. ETA=0:15:57
[32m[04/20 16:45:56 d2.evaluation.evaluator]: [0mInference done 269/8355. 0.1158 s / img. ETA=0:15:53
[32m[04/20 16:46:01 d2.evaluation.evaluator]: [0mInference done 312/8355. 0.1158 s / img. ETA=0:15:48
[32m[04/20 16:46:06 d2.evaluation.evaluator]: [0mInference done 355/8355. 0.1158 s / img. ETA=0:15:43
[32m[04/20 16:46:11 d2.evaluation.evaluator]: [0mInference done 398/8355. 0.1159 s / img. ETA=0:15:38
[32m[04/20 16:46:16 d2.evaluation.evaluator]: [0mInference done 441/8355. 0.1159 s / img. ETA=0:15:34
[32m[04/20 16:46:22 d2.evaluation.evaluator]: [0mInference done 484/8355. 0.1158 s / img. ETA=0:15:28
[32m[04/20 16:46:27 d2.evaluation.evaluator]: [0mInference done 527/8355. 0.1158 s / img. ETA=0:15:23
[32m[04/20 16:46:32 d2.evaluation.evaluator]: [0mInference done 570/8355. 0.1158 s / img. ETA=0:15:18
[32m[04/20 16:46:37 d2.evaluation.evaluator]: [0mInference done 613/8355. 0.1158 s / img. ETA=0:15:13
[32m[04/20 16:46:42 d2.evaluation.evaluator]: [0mInference done 656/8355. 0.1159 s / img. ETA=0:15:08
[32m[04/20 16:46:47 d2.evaluation.evaluator]: [0mInference done 698/8355. 0.1159 s / img. ETA=0:15:04
[32m[04/20 16:46:52 d2.evaluation.evaluator]: [0mInference done 741/8355. 0.1159 s / img. ETA=0:14:59
[32m[04/20 16:46:57 d2.evaluation.evaluator]: [0mInference done 784/8355. 0.1159 s / img. ETA=0:14:54
[32m[04/20 16:47:02 d2.evaluation.evaluator]: [0mInference done 827/8355. 0.1160 s / img. ETA=0:14:49
[32m[04/20 16:47:07 d2.evaluation.evaluator]: [0mInference done 870/8355. 0.1160 s / img. ETA=0:14:44
[32m[04/20 16:47:12 d2.evaluation.evaluator]: [0mInference done 913/8355. 0.1160 s / img. ETA=0:14:39
[32m[04/20 16:47:17 d2.evaluation.evaluator]: [0mInference done 956/8355. 0.1160 s / img. ETA=0:14:34
[32m[04/20 16:47:23 d2.evaluation.evaluator]: [0mInference done 999/8355. 0.1160 s / img. ETA=0:14:29
[32m[04/20 16:47:28 d2.evaluation.evaluator]: [0mInference done 1042/8355. 0.1160 s / img. ETA=0:14:24
[32m[04/20 16:47:33 d2.evaluation.evaluator]: [0mInference done 1085/8355. 0.1160 s / img. ETA=0:14:19
[32m[04/20 16:47:38 d2.evaluation.evaluator]: [0mInference done 1128/8355. 0.1160 s / img. ETA=0:14:13
[32m[04/20 16:47:43 d2.evaluation.evaluator]: [0mInference done 1171/8355. 0.1159 s / img. ETA=0:14:08
[32m[04/20 16:47:48 d2.evaluation.evaluator]: [0mInference done 1214/8355. 0.1159 s / img. ETA=0:14:03
[32m[04/20 16:47:53 d2.evaluation.evaluator]: [0mInference done 1257/8355. 0.1159 s / img. ETA=0:13:58
[32m[04/20 16:47:58 d2.evaluation.evaluator]: [0mInference done 1300/8355. 0.1159 s / img. ETA=0:13:53
[32m[04/20 16:48:03 d2.evaluation.evaluator]: [0mInference done 1343/8355. 0.1159 s / img. ETA=0:13:48
[32m[04/20 16:48:08 d2.evaluation.evaluator]: [0mInference done 1386/8355. 0.1159 s / img. ETA=0:13:43
[32m[04/20 16:48:13 d2.evaluation.evaluator]: [0mInference done 1429/8355. 0.1159 s / img. ETA=0:13:37
[32m[04/20 16:48:18 d2.evaluation.evaluator]: [0mInference done 1472/8355. 0.1159 s / img. ETA=0:13:32
[32m[04/20 16:48:23 d2.evaluation.evaluator]: [0mInference done 1514/8355. 0.1159 s / img. ETA=0:13:28
[32m[04/20 16:48:28 d2.evaluation.evaluator]: [0mInference done 1556/8355. 0.1160 s / img. ETA=0:13:23
[32m[04/20 16:48:33 d2.evaluation.evaluator]: [0mInference done 1598/8355. 0.1160 s / img. ETA=0:13:18
[32m[04/20 16:48:38 d2.evaluation.evaluator]: [0mInference done 1640/8355. 0.1161 s / img. ETA=0:13:14
[32m[04/20 16:48:43 d2.evaluation.evaluator]: [0mInference done 1682/8355. 0.1161 s / img. ETA=0:13:09
[32m[04/20 16:48:48 d2.evaluation.evaluator]: [0mInference done 1724/8355. 0.1161 s / img. ETA=0:13:04
[32m[04/20 16:48:53 d2.evaluation.evaluator]: [0mInference done 1766/8355. 0.1162 s / img. ETA=0:12:59
[32m[04/20 16:48:58 d2.evaluation.evaluator]: [0mInference done 1808/8355. 0.1162 s / img. ETA=0:12:55
[32m[04/20 16:49:04 d2.evaluation.evaluator]: [0mInference done 1850/8355. 0.1162 s / img. ETA=0:12:50
[32m[04/20 16:49:09 d2.evaluation.evaluator]: [0mInference done 1892/8355. 0.1162 s / img. ETA=0:12:45
[32m[04/20 16:49:14 d2.evaluation.evaluator]: [0mInference done 1934/8355. 0.1163 s / img. ETA=0:12:40
[32m[04/20 16:49:19 d2.evaluation.evaluator]: [0mInference done 1976/8355. 0.1163 s / img. ETA=0:12:35
[32m[04/20 16:49:24 d2.evaluation.evaluator]: [0mInference done 2019/8355. 0.1163 s / img. ETA=0:12:30
[32m[04/20 16:49:29 d2.evaluation.evaluator]: [0mInference done 2061/8355. 0.1163 s / img. ETA=0:12:25
[32m[04/20 16:49:34 d2.evaluation.evaluator]: [0mInference done 2104/8355. 0.1163 s / img. ETA=0:12:20
[32m[04/20 16:49:39 d2.evaluation.evaluator]: [0mInference done 2147/8355. 0.1163 s / img. ETA=0:12:15
[32m[04/20 16:49:44 d2.evaluation.evaluator]: [0mInference done 2190/8355. 0.1163 s / img. ETA=0:12:10
[32m[04/20 16:49:49 d2.evaluation.evaluator]: [0mInference done 2233/8355. 0.1163 s / img. ETA=0:12:05
[32m[04/20 16:49:54 d2.evaluation.evaluator]: [0mInference done 2275/8355. 0.1163 s / img. ETA=0:12:00
[32m[04/20 16:49:59 d2.evaluation.evaluator]: [0mInference done 2317/8355. 0.1163 s / img. ETA=0:11:55
[32m[04/20 16:50:04 d2.evaluation.evaluator]: [0mInference done 2359/8355. 0.1163 s / img. ETA=0:11:50
[32m[04/20 16:50:09 d2.evaluation.evaluator]: [0mInference done 2402/8355. 0.1163 s / img. ETA=0:11:45
[32m[04/20 16:50:14 d2.evaluation.evaluator]: [0mInference done 2445/8355. 0.1164 s / img. ETA=0:11:40
[32m[04/20 16:50:19 d2.evaluation.evaluator]: [0mInference done 2488/8355. 0.1163 s / img. ETA=0:11:35
[32m[04/20 16:50:25 d2.evaluation.evaluator]: [0mInference done 2531/8355. 0.1164 s / img. ETA=0:11:30
[32m[04/20 16:50:30 d2.evaluation.evaluator]: [0mInference done 2573/8355. 0.1164 s / img. ETA=0:11:25
[32m[04/20 16:50:35 d2.evaluation.evaluator]: [0mInference done 2615/8355. 0.1164 s / img. ETA=0:11:20
[32m[04/20 16:50:40 d2.evaluation.evaluator]: [0mInference done 2657/8355. 0.1164 s / img. ETA=0:11:15
[32m[04/20 16:50:45 d2.evaluation.evaluator]: [0mInference done 2699/8355. 0.1164 s / img. ETA=0:11:10
[32m[04/20 16:50:50 d2.evaluation.evaluator]: [0mInference done 2741/8355. 0.1164 s / img. ETA=0:11:06
[32m[04/20 16:50:55 d2.evaluation.evaluator]: [0mInference done 2783/8355. 0.1164 s / img. ETA=0:11:01
[32m[04/20 16:51:00 d2.evaluation.evaluator]: [0mInference done 2825/8355. 0.1164 s / img. ETA=0:10:56
[32m[04/20 16:51:05 d2.evaluation.evaluator]: [0mInference done 2867/8355. 0.1164 s / img. ETA=0:10:51
[32m[04/20 16:51:10 d2.evaluation.evaluator]: [0mInference done 2910/8355. 0.1164 s / img. ETA=0:10:46
[32m[04/20 16:51:15 d2.evaluation.evaluator]: [0mInference done 2952/8355. 0.1165 s / img. ETA=0:10:41
[32m[04/20 16:51:20 d2.evaluation.evaluator]: [0mInference done 2995/8355. 0.1165 s / img. ETA=0:10:36
[32m[04/20 16:51:25 d2.evaluation.evaluator]: [0mInference done 3038/8355. 0.1165 s / img. ETA=0:10:31
[32m[04/20 16:51:30 d2.evaluation.evaluator]: [0mInference done 3080/8355. 0.1165 s / img. ETA=0:10:26
[32m[04/20 16:51:35 d2.evaluation.evaluator]: [0mInference done 3122/8355. 0.1165 s / img. ETA=0:10:21
[32m[04/20 16:51:40 d2.evaluation.evaluator]: [0mInference done 3165/8355. 0.1165 s / img. ETA=0:10:16
[32m[04/20 16:51:45 d2.evaluation.evaluator]: [0mInference done 3208/8355. 0.1165 s / img. ETA=0:10:10
[32m[04/20 16:51:50 d2.evaluation.evaluator]: [0mInference done 3251/8355. 0.1165 s / img. ETA=0:10:05
[32m[04/20 16:51:55 d2.evaluation.evaluator]: [0mInference done 3294/8355. 0.1165 s / img. ETA=0:10:00
[32m[04/20 16:52:00 d2.evaluation.evaluator]: [0mInference done 3337/8355. 0.1165 s / img. ETA=0:09:55
[32m[04/20 16:52:06 d2.evaluation.evaluator]: [0mInference done 3380/8355. 0.1165 s / img. ETA=0:09:50
[32m[04/20 16:52:11 d2.evaluation.evaluator]: [0mInference done 3423/8355. 0.1165 s / img. ETA=0:09:45
[32m[04/20 16:52:16 d2.evaluation.evaluator]: [0mInference done 3466/8355. 0.1164 s / img. ETA=0:09:40
[32m[04/20 16:52:21 d2.evaluation.evaluator]: [0mInference done 3509/8355. 0.1165 s / img. ETA=0:09:35
[32m[04/20 16:52:26 d2.evaluation.evaluator]: [0mInference done 3552/8355. 0.1164 s / img. ETA=0:09:30
[32m[04/20 16:52:31 d2.evaluation.evaluator]: [0mInference done 3595/8355. 0.1164 s / img. ETA=0:09:24
[32m[04/20 16:52:36 d2.evaluation.evaluator]: [0mInference done 3638/8355. 0.1165 s / img. ETA=0:09:19
[32m[04/20 16:52:41 d2.evaluation.evaluator]: [0mInference done 3681/8355. 0.1164 s / img. ETA=0:09:14
[32m[04/20 16:52:46 d2.evaluation.evaluator]: [0mInference done 3724/8355. 0.1165 s / img. ETA=0:09:09
[32m[04/20 16:52:52 d2.evaluation.evaluator]: [0mInference done 3767/8355. 0.1165 s / img. ETA=0:09:04
[32m[04/20 16:52:57 d2.evaluation.evaluator]: [0mInference done 3809/8355. 0.1165 s / img. ETA=0:08:59
[32m[04/20 16:53:02 d2.evaluation.evaluator]: [0mInference done 3851/8355. 0.1165 s / img. ETA=0:08:54
[32m[04/20 16:53:07 d2.evaluation.evaluator]: [0mInference done 3894/8355. 0.1165 s / img. ETA=0:08:49
[32m[04/20 16:53:12 d2.evaluation.evaluator]: [0mInference done 3937/8355. 0.1165 s / img. ETA=0:08:44
[32m[04/20 16:53:17 d2.evaluation.evaluator]: [0mInference done 3979/8355. 0.1165 s / img. ETA=0:08:39
[32m[04/20 16:53:22 d2.evaluation.evaluator]: [0mInference done 4021/8355. 0.1165 s / img. ETA=0:08:34
[32m[04/20 16:53:27 d2.evaluation.evaluator]: [0mInference done 4063/8355. 0.1165 s / img. ETA=0:08:29
[32m[04/20 16:53:32 d2.evaluation.evaluator]: [0mInference done 4105/8355. 0.1165 s / img. ETA=0:08:24
[32m[04/20 16:53:37 d2.evaluation.evaluator]: [0mInference done 4147/8355. 0.1165 s / img. ETA=0:08:19
[32m[04/20 16:53:42 d2.evaluation.evaluator]: [0mInference done 4189/8355. 0.1165 s / img. ETA=0:08:14
[32m[04/20 16:53:47 d2.evaluation.evaluator]: [0mInference done 4232/8355. 0.1165 s / img. ETA=0:08:09
[32m[04/20 16:53:52 d2.evaluation.evaluator]: [0mInference done 4275/8355. 0.1165 s / img. ETA=0:08:04
[32m[04/20 16:53:57 d2.evaluation.evaluator]: [0mInference done 4318/8355. 0.1165 s / img. ETA=0:07:59
[32m[04/20 16:54:02 d2.evaluation.evaluator]: [0mInference done 4361/8355. 0.1165 s / img. ETA=0:07:54
[32m[04/20 16:54:07 d2.evaluation.evaluator]: [0mInference done 4404/8355. 0.1165 s / img. ETA=0:07:49
[32m[04/20 16:54:12 d2.evaluation.evaluator]: [0mInference done 4446/8355. 0.1165 s / img. ETA=0:07:44
[32m[04/20 16:54:17 d2.evaluation.evaluator]: [0mInference done 4489/8355. 0.1165 s / img. ETA=0:07:39
[32m[04/20 16:54:23 d2.evaluation.evaluator]: [0mInference done 4531/8355. 0.1165 s / img. ETA=0:07:34
[32m[04/20 16:54:28 d2.evaluation.evaluator]: [0mInference done 4573/8355. 0.1165 s / img. ETA=0:07:29
[32m[04/20 16:54:33 d2.evaluation.evaluator]: [0mInference done 4615/8355. 0.1165 s / img. ETA=0:07:24
[32m[04/20 16:54:38 d2.evaluation.evaluator]: [0mInference done 4658/8355. 0.1165 s / img. ETA=0:07:19
[32m[04/20 16:54:43 d2.evaluation.evaluator]: [0mInference done 4701/8355. 0.1165 s / img. ETA=0:07:13
[32m[04/20 16:54:48 d2.evaluation.evaluator]: [0mInference done 4744/8355. 0.1165 s / img. ETA=0:07:08
[32m[04/20 16:54:53 d2.evaluation.evaluator]: [0mInference done 4786/8355. 0.1165 s / img. ETA=0:07:03
[32m[04/20 16:54:58 d2.evaluation.evaluator]: [0mInference done 4828/8355. 0.1165 s / img. ETA=0:06:58
[32m[04/20 16:55:03 d2.evaluation.evaluator]: [0mInference done 4870/8355. 0.1165 s / img. ETA=0:06:53
[32m[04/20 16:55:08 d2.evaluation.evaluator]: [0mInference done 4912/8355. 0.1166 s / img. ETA=0:06:49
[32m[04/20 16:55:13 d2.evaluation.evaluator]: [0mInference done 4954/8355. 0.1166 s / img. ETA=0:06:44
[32m[04/20 16:55:18 d2.evaluation.evaluator]: [0mInference done 4996/8355. 0.1166 s / img. ETA=0:06:39
[32m[04/20 16:55:23 d2.evaluation.evaluator]: [0mInference done 5038/8355. 0.1166 s / img. ETA=0:06:34
[32m[04/20 16:55:28 d2.evaluation.evaluator]: [0mInference done 5080/8355. 0.1166 s / img. ETA=0:06:29
[32m[04/20 16:55:33 d2.evaluation.evaluator]: [0mInference done 5122/8355. 0.1166 s / img. ETA=0:06:24
[32m[04/20 16:55:38 d2.evaluation.evaluator]: [0mInference done 5164/8355. 0.1166 s / img. ETA=0:06:19
[32m[04/20 16:55:43 d2.evaluation.evaluator]: [0mInference done 5206/8355. 0.1166 s / img. ETA=0:06:14
[32m[04/20 16:55:48 d2.evaluation.evaluator]: [0mInference done 5248/8355. 0.1166 s / img. ETA=0:06:09
[32m[04/20 16:55:54 d2.evaluation.evaluator]: [0mInference done 5290/8355. 0.1166 s / img. ETA=0:06:04
[32m[04/20 16:55:59 d2.evaluation.evaluator]: [0mInference done 5332/8355. 0.1167 s / img. ETA=0:05:59
[32m[04/20 16:56:04 d2.evaluation.evaluator]: [0mInference done 5374/8355. 0.1167 s / img. ETA=0:05:54
[32m[04/20 16:56:09 d2.evaluation.evaluator]: [0mInference done 5416/8355. 0.1167 s / img. ETA=0:05:49
[32m[04/20 16:56:14 d2.evaluation.evaluator]: [0mInference done 5458/8355. 0.1167 s / img. ETA=0:05:44
[32m[04/20 16:56:19 d2.evaluation.evaluator]: [0mInference done 5500/8355. 0.1167 s / img. ETA=0:05:39
[32m[04/20 16:56:24 d2.evaluation.evaluator]: [0mInference done 5542/8355. 0.1167 s / img. ETA=0:05:34
[32m[04/20 16:56:29 d2.evaluation.evaluator]: [0mInference done 5584/8355. 0.1167 s / img. ETA=0:05:29
[32m[04/20 16:56:34 d2.evaluation.evaluator]: [0mInference done 5626/8355. 0.1167 s / img. ETA=0:05:24
[32m[04/20 16:56:39 d2.evaluation.evaluator]: [0mInference done 5668/8355. 0.1167 s / img. ETA=0:05:19
[32m[04/20 16:56:44 d2.evaluation.evaluator]: [0mInference done 5710/8355. 0.1167 s / img. ETA=0:05:14
[32m[04/20 16:56:49 d2.evaluation.evaluator]: [0mInference done 5752/8355. 0.1168 s / img. ETA=0:05:09
[32m[04/20 16:56:54 d2.evaluation.evaluator]: [0mInference done 5794/8355. 0.1168 s / img. ETA=0:05:04
[32m[04/20 16:56:59 d2.evaluation.evaluator]: [0mInference done 5836/8355. 0.1168 s / img. ETA=0:04:59
[32m[04/20 16:57:04 d2.evaluation.evaluator]: [0mInference done 5878/8355. 0.1168 s / img. ETA=0:04:54
[32m[04/20 16:57:10 d2.evaluation.evaluator]: [0mInference done 5920/8355. 0.1168 s / img. ETA=0:04:50
[32m[04/20 16:57:15 d2.evaluation.evaluator]: [0mInference done 5962/8355. 0.1168 s / img. ETA=0:04:45
[32m[04/20 16:57:20 d2.evaluation.evaluator]: [0mInference done 6004/8355. 0.1168 s / img. ETA=0:04:40
[32m[04/20 16:57:25 d2.evaluation.evaluator]: [0mInference done 6046/8355. 0.1168 s / img. ETA=0:04:35
[32m[04/20 16:57:30 d2.evaluation.evaluator]: [0mInference done 6088/8355. 0.1168 s / img. ETA=0:04:30
[32m[04/20 16:57:35 d2.evaluation.evaluator]: [0mInference done 6130/8355. 0.1168 s / img. ETA=0:04:25
[32m[04/20 16:57:40 d2.evaluation.evaluator]: [0mInference done 6172/8355. 0.1169 s / img. ETA=0:04:20
[32m[04/20 16:57:45 d2.evaluation.evaluator]: [0mInference done 6214/8355. 0.1169 s / img. ETA=0:04:15
[32m[04/20 16:57:50 d2.evaluation.evaluator]: [0mInference done 6256/8355. 0.1169 s / img. ETA=0:04:10
[32m[04/20 16:57:55 d2.evaluation.evaluator]: [0mInference done 6298/8355. 0.1169 s / img. ETA=0:04:05
[32m[04/20 16:58:00 d2.evaluation.evaluator]: [0mInference done 6340/8355. 0.1169 s / img. ETA=0:04:00
[32m[04/20 16:58:05 d2.evaluation.evaluator]: [0mInference done 6382/8355. 0.1169 s / img. ETA=0:03:55
[32m[04/20 16:58:10 d2.evaluation.evaluator]: [0mInference done 6424/8355. 0.1169 s / img. ETA=0:03:50
[32m[04/20 16:58:15 d2.evaluation.evaluator]: [0mInference done 6466/8355. 0.1169 s / img. ETA=0:03:45
[32m[04/20 16:58:20 d2.evaluation.evaluator]: [0mInference done 6508/8355. 0.1169 s / img. ETA=0:03:40
[32m[04/20 16:58:25 d2.evaluation.evaluator]: [0mInference done 6550/8355. 0.1169 s / img. ETA=0:03:35
[32m[04/20 16:58:31 d2.evaluation.evaluator]: [0mInference done 6592/8355. 0.1169 s / img. ETA=0:03:30
[32m[04/20 16:58:36 d2.evaluation.evaluator]: [0mInference done 6634/8355. 0.1169 s / img. ETA=0:03:25
[32m[04/20 16:58:41 d2.evaluation.evaluator]: [0mInference done 6676/8355. 0.1169 s / img. ETA=0:03:20
[32m[04/20 16:58:46 d2.evaluation.evaluator]: [0mInference done 6718/8355. 0.1169 s / img. ETA=0:03:15
[32m[04/20 16:58:51 d2.evaluation.evaluator]: [0mInference done 6760/8355. 0.1169 s / img. ETA=0:03:10
[32m[04/20 16:58:56 d2.evaluation.evaluator]: [0mInference done 6802/8355. 0.1169 s / img. ETA=0:03:05
[32m[04/20 16:59:01 d2.evaluation.evaluator]: [0mInference done 6844/8355. 0.1169 s / img. ETA=0:03:00
[32m[04/20 16:59:06 d2.evaluation.evaluator]: [0mInference done 6886/8355. 0.1169 s / img. ETA=0:02:55
[32m[04/20 16:59:11 d2.evaluation.evaluator]: [0mInference done 6928/8355. 0.1169 s / img. ETA=0:02:50
[32m[04/20 16:59:16 d2.evaluation.evaluator]: [0mInference done 6970/8355. 0.1169 s / img. ETA=0:02:45
[32m[04/20 16:59:21 d2.evaluation.evaluator]: [0mInference done 7012/8355. 0.1170 s / img. ETA=0:02:40
[32m[04/20 16:59:26 d2.evaluation.evaluator]: [0mInference done 7054/8355. 0.1170 s / img. ETA=0:02:35
[32m[04/20 16:59:31 d2.evaluation.evaluator]: [0mInference done 7096/8355. 0.1170 s / img. ETA=0:02:30
[32m[04/20 16:59:36 d2.evaluation.evaluator]: [0mInference done 7138/8355. 0.1170 s / img. ETA=0:02:25
[32m[04/20 16:59:41 d2.evaluation.evaluator]: [0mInference done 7180/8355. 0.1170 s / img. ETA=0:02:20
[32m[04/20 16:59:46 d2.evaluation.evaluator]: [0mInference done 7222/8355. 0.1170 s / img. ETA=0:02:15
[32m[04/20 16:59:52 d2.evaluation.evaluator]: [0mInference done 7264/8355. 0.1170 s / img. ETA=0:02:10
[32m[04/20 16:59:57 d2.evaluation.evaluator]: [0mInference done 7306/8355. 0.1170 s / img. ETA=0:02:05
[32m[04/20 17:00:02 d2.evaluation.evaluator]: [0mInference done 7348/8355. 0.1170 s / img. ETA=0:02:00
[32m[04/20 17:00:07 d2.evaluation.evaluator]: [0mInference done 7390/8355. 0.1170 s / img. ETA=0:01:55
[32m[04/20 17:00:12 d2.evaluation.evaluator]: [0mInference done 7432/8355. 0.1171 s / img. ETA=0:01:50
[32m[04/20 17:00:17 d2.evaluation.evaluator]: [0mInference done 7474/8355. 0.1171 s / img. ETA=0:01:45
[32m[04/20 17:00:22 d2.evaluation.evaluator]: [0mInference done 7516/8355. 0.1171 s / img. ETA=0:01:40
[32m[04/20 17:00:27 d2.evaluation.evaluator]: [0mInference done 7558/8355. 0.1171 s / img. ETA=0:01:35
[32m[04/20 17:00:32 d2.evaluation.evaluator]: [0mInference done 7600/8355. 0.1171 s / img. ETA=0:01:30
[32m[04/20 17:00:37 d2.evaluation.evaluator]: [0mInference done 7642/8355. 0.1171 s / img. ETA=0:01:25
[32m[04/20 17:00:42 d2.evaluation.evaluator]: [0mInference done 7684/8355. 0.1171 s / img. ETA=0:01:20
[32m[04/20 17:00:47 d2.evaluation.evaluator]: [0mInference done 7726/8355. 0.1171 s / img. ETA=0:01:15
[32m[04/20 17:00:53 d2.evaluation.evaluator]: [0mInference done 7768/8355. 0.1171 s / img. ETA=0:01:10
[32m[04/20 17:00:58 d2.evaluation.evaluator]: [0mInference done 7810/8355. 0.1171 s / img. ETA=0:01:05
[32m[04/20 17:01:03 d2.evaluation.evaluator]: [0mInference done 7852/8355. 0.1171 s / img. ETA=0:01:00
[32m[04/20 17:01:08 d2.evaluation.evaluator]: [0mInference done 7894/8355. 0.1171 s / img. ETA=0:00:55
[32m[04/20 17:01:13 d2.evaluation.evaluator]: [0mInference done 7936/8355. 0.1171 s / img. ETA=0:00:50
[32m[04/20 17:01:18 d2.evaluation.evaluator]: [0mInference done 7978/8355. 0.1171 s / img. ETA=0:00:45
[32m[04/20 17:01:23 d2.evaluation.evaluator]: [0mInference done 8020/8355. 0.1172 s / img. ETA=0:00:40
[32m[04/20 17:01:28 d2.evaluation.evaluator]: [0mInference done 8062/8355. 0.1172 s / img. ETA=0:00:35
[32m[04/20 17:01:33 d2.evaluation.evaluator]: [0mInference done 8104/8355. 0.1172 s / img. ETA=0:00:30
[32m[04/20 17:01:38 d2.evaluation.evaluator]: [0mInference done 8146/8355. 0.1172 s / img. ETA=0:00:24
[32m[04/20 17:01:43 d2.evaluation.evaluator]: [0mInference done 8188/8355. 0.1172 s / img. ETA=0:00:19
[32m[04/20 17:01:48 d2.evaluation.evaluator]: [0mInference done 8230/8355. 0.1172 s / img. ETA=0:00:14
[32m[04/20 17:01:53 d2.evaluation.evaluator]: [0mInference done 8272/8355. 0.1172 s / img. ETA=0:00:09
[32m[04/20 17:01:58 d2.evaluation.evaluator]: [0mInference done 8314/8355. 0.1172 s / img. ETA=0:00:04
[32m[04/20 17:02:03 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:38.387028 (0.119567 s / img per device, on 1 devices)
[32m[04/20 17:02:03 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:18 (0.117177 s / img per device, on 1 devices)
[32m[04/20 17:02:04 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 17:02:04 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 17:02:04 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.47s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=24.51s).
Accumulating evaluation results...
DONE (t=3.68s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.397
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.738
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.380
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.289
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.528
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.693
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.159
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.447
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.365
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733
[32m[04/20 17:02:33 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.704 | 73.777 | 37.964 | 28.936 | 52.768 | 69.266 |
[32m[04/20 17:02:33 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 41.409 | bicycle       | 28.852 | car            | 48.853 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 17:02:34 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 17:02:34 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 17:02:34 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 17:02:36 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1190 s / img. ETA=0:02:31
[32m[04/20 17:02:41 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1179 s / img. ETA=0:02:25
[32m[04/20 17:02:46 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1178 s / img. ETA=0:02:20
[32m[04/20 17:02:51 d2.evaluation.evaluator]: [0mInference done 136/1257. 0.1181 s / img. ETA=0:02:15
[32m[04/20 17:02:56 d2.evaluation.evaluator]: [0mInference done 178/1257. 0.1182 s / img. ETA=0:02:10
[32m[04/20 17:03:01 d2.evaluation.evaluator]: [0mInference done 220/1257. 0.1182 s / img. ETA=0:02:05
[32m[04/20 17:03:06 d2.evaluation.evaluator]: [0mInference done 262/1257. 0.1182 s / img. ETA=0:02:00
[32m[04/20 17:03:11 d2.evaluation.evaluator]: [0mInference done 304/1257. 0.1182 s / img. ETA=0:01:55
[32m[04/20 17:03:16 d2.evaluation.evaluator]: [0mInference done 346/1257. 0.1181 s / img. ETA=0:01:50
[32m[04/20 17:03:21 d2.evaluation.evaluator]: [0mInference done 388/1257. 0.1181 s / img. ETA=0:01:45
[32m[04/20 17:03:26 d2.evaluation.evaluator]: [0mInference done 430/1257. 0.1181 s / img. ETA=0:01:40
[32m[04/20 17:03:31 d2.evaluation.evaluator]: [0mInference done 472/1257. 0.1181 s / img. ETA=0:01:34
[32m[04/20 17:03:36 d2.evaluation.evaluator]: [0mInference done 513/1257. 0.1182 s / img. ETA=0:01:30
[32m[04/20 17:03:41 d2.evaluation.evaluator]: [0mInference done 555/1257. 0.1182 s / img. ETA=0:01:25
[32m[04/20 17:03:47 d2.evaluation.evaluator]: [0mInference done 597/1257. 0.1183 s / img. ETA=0:01:19
[32m[04/20 17:03:52 d2.evaluation.evaluator]: [0mInference done 639/1257. 0.1183 s / img. ETA=0:01:14
[32m[04/20 17:03:57 d2.evaluation.evaluator]: [0mInference done 681/1257. 0.1183 s / img. ETA=0:01:09
[32m[04/20 17:04:02 d2.evaluation.evaluator]: [0mInference done 723/1257. 0.1183 s / img. ETA=0:01:04
[32m[04/20 17:04:07 d2.evaluation.evaluator]: [0mInference done 765/1257. 0.1183 s / img. ETA=0:00:59
[32m[04/20 17:04:12 d2.evaluation.evaluator]: [0mInference done 807/1257. 0.1183 s / img. ETA=0:00:54
[32m[04/20 17:04:17 d2.evaluation.evaluator]: [0mInference done 849/1257. 0.1183 s / img. ETA=0:00:49
[32m[04/20 17:04:22 d2.evaluation.evaluator]: [0mInference done 891/1257. 0.1183 s / img. ETA=0:00:44
[32m[04/20 17:04:27 d2.evaluation.evaluator]: [0mInference done 933/1257. 0.1183 s / img. ETA=0:00:39
[32m[04/20 17:04:32 d2.evaluation.evaluator]: [0mInference done 975/1257. 0.1183 s / img. ETA=0:00:34
[32m[04/20 17:04:37 d2.evaluation.evaluator]: [0mInference done 1017/1257. 0.1183 s / img. ETA=0:00:29
[32m[04/20 17:04:43 d2.evaluation.evaluator]: [0mInference done 1059/1257. 0.1183 s / img. ETA=0:00:23
[32m[04/20 17:04:48 d2.evaluation.evaluator]: [0mInference done 1101/1257. 0.1183 s / img. ETA=0:00:18
[32m[04/20 17:04:53 d2.evaluation.evaluator]: [0mInference done 1143/1257. 0.1183 s / img. ETA=0:00:13
[32m[04/20 17:04:58 d2.evaluation.evaluator]: [0mInference done 1185/1257. 0.1183 s / img. ETA=0:00:08
[32m[04/20 17:05:03 d2.evaluation.evaluator]: [0mInference done 1227/1257. 0.1183 s / img. ETA=0:00:03
[32m[04/20 17:05:06 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:31.646990 (0.121124 s / img per device, on 1 devices)
[32m[04/20 17:05:06 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:28 (0.118281 s / img per device, on 1 devices)
[32m[04/20 17:05:07 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 17:05:07 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 17:05:07 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.20s).
Accumulating evaluation results...
DONE (t=0.42s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.594
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.269
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.372
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.479
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.147
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.370
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.376
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.278
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.439
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.516
[32m[04/20 17:05:10 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 30.470 | 59.356 | 26.941 | 19.091 | 37.178 | 47.911 |
[32m[04/20 17:05:10 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 35.952 | bicycle       | 10.843 | car            | 44.614 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  19  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 17:05:11 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 17:05:12 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 17:05:12 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 17:05:12 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 17:05:12 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 17:05:12 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 17:05:12 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 17:05:34 d2.utils.events]: [0m eta: 0:17:05  iter: 19  total_loss: 0.648  loss_cls: 0.211  loss_box_reg: 0.371  loss_rpn_cls: 0.017  loss_rpn_loc: 0.067  time: 1.0463  data_time: 0.0365  lr: 0.000100  max_mem: 5406M
[32m[04/20 17:05:54 d2.utils.events]: [0m eta: 0:16:51  iter: 39  total_loss: 0.593  loss_cls: 0.202  loss_box_reg: 0.331  loss_rpn_cls: 0.014  loss_rpn_loc: 0.052  time: 1.0415  data_time: 0.0119  lr: 0.000200  max_mem: 5406M
[32m[04/20 17:06:15 d2.utils.events]: [0m eta: 0:16:00  iter: 59  total_loss: 0.569  loss_cls: 0.176  loss_box_reg: 0.330  loss_rpn_cls: 0.012  loss_rpn_loc: 0.044  time: 1.0293  data_time: 0.0120  lr: 0.000300  max_mem: 5406M
[32m[04/20 17:06:35 d2.utils.events]: [0m eta: 0:15:41  iter: 79  total_loss: 0.608  loss_cls: 0.194  loss_box_reg: 0.335  loss_rpn_cls: 0.013  loss_rpn_loc: 0.058  time: 1.0285  data_time: 0.0120  lr: 0.000400  max_mem: 5406M
[32m[04/20 17:06:55 d2.utils.events]: [0m eta: 0:15:19  iter: 99  total_loss: 0.610  loss_cls: 0.190  loss_box_reg: 0.325  loss_rpn_cls: 0.013  loss_rpn_loc: 0.062  time: 1.0189  data_time: 0.0122  lr: 0.000500  max_mem: 5406M
[32m[04/20 17:07:15 d2.utils.events]: [0m eta: 0:14:59  iter: 119  total_loss: 0.578  loss_cls: 0.190  loss_box_reg: 0.308  loss_rpn_cls: 0.013  loss_rpn_loc: 0.049  time: 1.0206  data_time: 0.0110  lr: 0.000599  max_mem: 5406M
[32m[04/20 17:07:36 d2.utils.events]: [0m eta: 0:14:41  iter: 139  total_loss: 0.606  loss_cls: 0.192  loss_box_reg: 0.342  loss_rpn_cls: 0.013  loss_rpn_loc: 0.049  time: 1.0200  data_time: 0.0116  lr: 0.000699  max_mem: 5406M
[32m[04/20 17:07:57 d2.utils.events]: [0m eta: 0:14:25  iter: 159  total_loss: 0.545  loss_cls: 0.171  loss_box_reg: 0.310  loss_rpn_cls: 0.010  loss_rpn_loc: 0.044  time: 1.0229  data_time: 0.0116  lr: 0.000799  max_mem: 5406M
[32m[04/20 17:08:18 d2.utils.events]: [0m eta: 0:14:10  iter: 179  total_loss: 0.519  loss_cls: 0.164  loss_box_reg: 0.300  loss_rpn_cls: 0.011  loss_rpn_loc: 0.053  time: 1.0271  data_time: 0.0117  lr: 0.000899  max_mem: 5406M
[32m[04/20 17:08:39 d2.utils.events]: [0m eta: 0:13:51  iter: 199  total_loss: 0.650  loss_cls: 0.199  loss_box_reg: 0.346  loss_rpn_cls: 0.012  loss_rpn_loc: 0.067  time: 1.0284  data_time: 0.0119  lr: 0.000999  max_mem: 5406M
[32m[04/20 17:09:00 d2.utils.events]: [0m eta: 0:13:30  iter: 219  total_loss: 0.589  loss_cls: 0.182  loss_box_reg: 0.360  loss_rpn_cls: 0.011  loss_rpn_loc: 0.045  time: 1.0299  data_time: 0.0134  lr: 0.001099  max_mem: 5406M
[32m[04/20 17:09:20 d2.utils.events]: [0m eta: 0:13:07  iter: 239  total_loss: 0.622  loss_cls: 0.202  loss_box_reg: 0.331  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0286  data_time: 0.0120  lr: 0.001199  max_mem: 5406M
[32m[04/20 17:09:41 d2.utils.events]: [0m eta: 0:12:48  iter: 259  total_loss: 0.514  loss_cls: 0.153  loss_box_reg: 0.304  loss_rpn_cls: 0.011  loss_rpn_loc: 0.054  time: 1.0295  data_time: 0.0122  lr: 0.001299  max_mem: 5406M
[32m[04/20 17:10:02 d2.utils.events]: [0m eta: 0:12:26  iter: 279  total_loss: 0.584  loss_cls: 0.197  loss_box_reg: 0.338  loss_rpn_cls: 0.012  loss_rpn_loc: 0.057  time: 1.0295  data_time: 0.0119  lr: 0.001399  max_mem: 5406M
[32m[04/20 17:10:22 d2.utils.events]: [0m eta: 0:12:06  iter: 299  total_loss: 0.603  loss_cls: 0.190  loss_box_reg: 0.328  loss_rpn_cls: 0.013  loss_rpn_loc: 0.064  time: 1.0297  data_time: 0.0119  lr: 0.001499  max_mem: 5406M
[32m[04/20 17:10:43 d2.utils.events]: [0m eta: 0:11:46  iter: 319  total_loss: 0.564  loss_cls: 0.168  loss_box_reg: 0.318  loss_rpn_cls: 0.009  loss_rpn_loc: 0.060  time: 1.0311  data_time: 0.0130  lr: 0.001598  max_mem: 5406M
[32m[04/20 17:11:04 d2.utils.events]: [0m eta: 0:11:26  iter: 339  total_loss: 0.549  loss_cls: 0.189  loss_box_reg: 0.317  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 1.0318  data_time: 0.0114  lr: 0.001698  max_mem: 5406M
[32m[04/20 17:11:25 d2.utils.events]: [0m eta: 0:11:05  iter: 359  total_loss: 0.542  loss_cls: 0.172  loss_box_reg: 0.312  loss_rpn_cls: 0.012  loss_rpn_loc: 0.047  time: 1.0315  data_time: 0.0117  lr: 0.001798  max_mem: 5406M
[32m[04/20 17:11:45 d2.utils.events]: [0m eta: 0:10:44  iter: 379  total_loss: 0.667  loss_cls: 0.204  loss_box_reg: 0.394  loss_rpn_cls: 0.013  loss_rpn_loc: 0.064  time: 1.0304  data_time: 0.0116  lr: 0.001898  max_mem: 5406M
[32m[04/20 17:12:06 d2.utils.events]: [0m eta: 0:10:22  iter: 399  total_loss: 0.528  loss_cls: 0.169  loss_box_reg: 0.284  loss_rpn_cls: 0.012  loss_rpn_loc: 0.036  time: 1.0299  data_time: 0.0125  lr: 0.001998  max_mem: 5406M
[32m[04/20 17:12:26 d2.utils.events]: [0m eta: 0:10:02  iter: 419  total_loss: 0.598  loss_cls: 0.182  loss_box_reg: 0.340  loss_rpn_cls: 0.013  loss_rpn_loc: 0.051  time: 1.0302  data_time: 0.0122  lr: 0.002098  max_mem: 5406M
[32m[04/20 17:12:47 d2.utils.events]: [0m eta: 0:09:42  iter: 439  total_loss: 0.570  loss_cls: 0.198  loss_box_reg: 0.328  loss_rpn_cls: 0.017  loss_rpn_loc: 0.045  time: 1.0312  data_time: 0.0122  lr: 0.002198  max_mem: 5406M
[32m[04/20 17:13:08 d2.utils.events]: [0m eta: 0:09:21  iter: 459  total_loss: 0.586  loss_cls: 0.195  loss_box_reg: 0.333  loss_rpn_cls: 0.013  loss_rpn_loc: 0.052  time: 1.0309  data_time: 0.0122  lr: 0.002298  max_mem: 5406M
[32m[04/20 17:13:29 d2.utils.events]: [0m eta: 0:09:01  iter: 479  total_loss: 0.455  loss_cls: 0.138  loss_box_reg: 0.276  loss_rpn_cls: 0.010  loss_rpn_loc: 0.041  time: 1.0308  data_time: 0.0114  lr: 0.002398  max_mem: 5406M
[32m[04/20 17:13:50 d2.utils.events]: [0m eta: 0:08:40  iter: 499  total_loss: 0.591  loss_cls: 0.195  loss_box_reg: 0.328  loss_rpn_cls: 0.010  loss_rpn_loc: 0.057  time: 1.0302  data_time: 0.0113  lr: 0.002498  max_mem: 5406M
[32m[04/20 17:14:10 d2.utils.events]: [0m eta: 0:08:19  iter: 519  total_loss: 0.587  loss_cls: 0.183  loss_box_reg: 0.325  loss_rpn_cls: 0.011  loss_rpn_loc: 0.066  time: 1.0301  data_time: 0.0109  lr: 0.002597  max_mem: 5406M
[32m[04/20 17:14:32 d2.utils.events]: [0m eta: 0:07:59  iter: 539  total_loss: 0.582  loss_cls: 0.195  loss_box_reg: 0.319  loss_rpn_cls: 0.014  loss_rpn_loc: 0.060  time: 1.0312  data_time: 0.0104  lr: 0.002697  max_mem: 5406M
[32m[04/20 17:14:52 d2.utils.events]: [0m eta: 0:07:38  iter: 559  total_loss: 0.566  loss_cls: 0.177  loss_box_reg: 0.333  loss_rpn_cls: 0.011  loss_rpn_loc: 0.053  time: 1.0300  data_time: 0.0107  lr: 0.002797  max_mem: 5406M
[32m[04/20 17:15:12 d2.utils.events]: [0m eta: 0:07:17  iter: 579  total_loss: 0.583  loss_cls: 0.189  loss_box_reg: 0.336  loss_rpn_cls: 0.010  loss_rpn_loc: 0.059  time: 1.0303  data_time: 0.0109  lr: 0.002897  max_mem: 5406M
[32m[04/20 17:15:33 d2.utils.events]: [0m eta: 0:06:57  iter: 599  total_loss: 0.557  loss_cls: 0.178  loss_box_reg: 0.326  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 1.0307  data_time: 0.0103  lr: 0.002997  max_mem: 5406M
[32m[04/20 17:15:54 d2.utils.events]: [0m eta: 0:06:36  iter: 619  total_loss: 0.617  loss_cls: 0.195  loss_box_reg: 0.343  loss_rpn_cls: 0.010  loss_rpn_loc: 0.055  time: 1.0304  data_time: 0.0118  lr: 0.003097  max_mem: 5406M
[32m[04/20 17:16:15 d2.utils.events]: [0m eta: 0:06:15  iter: 639  total_loss: 0.592  loss_cls: 0.188  loss_box_reg: 0.349  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 1.0306  data_time: 0.0108  lr: 0.003197  max_mem: 5406M
[32m[04/20 17:16:35 d2.utils.events]: [0m eta: 0:05:54  iter: 659  total_loss: 0.600  loss_cls: 0.187  loss_box_reg: 0.347  loss_rpn_cls: 0.010  loss_rpn_loc: 0.055  time: 1.0308  data_time: 0.0118  lr: 0.003297  max_mem: 5406M
[32m[04/20 17:16:56 d2.utils.events]: [0m eta: 0:05:33  iter: 679  total_loss: 0.663  loss_cls: 0.217  loss_box_reg: 0.386  loss_rpn_cls: 0.017  loss_rpn_loc: 0.049  time: 1.0305  data_time: 0.0102  lr: 0.003397  max_mem: 5406M
[32m[04/20 17:17:17 d2.utils.events]: [0m eta: 0:05:12  iter: 699  total_loss: 0.644  loss_cls: 0.207  loss_box_reg: 0.342  loss_rpn_cls: 0.012  loss_rpn_loc: 0.061  time: 1.0308  data_time: 0.0109  lr: 0.003497  max_mem: 5406M
[32m[04/20 17:17:38 d2.utils.events]: [0m eta: 0:04:52  iter: 719  total_loss: 0.626  loss_cls: 0.202  loss_box_reg: 0.343  loss_rpn_cls: 0.016  loss_rpn_loc: 0.052  time: 1.0316  data_time: 0.0117  lr: 0.003596  max_mem: 5406M
[32m[04/20 17:17:58 d2.utils.events]: [0m eta: 0:04:31  iter: 739  total_loss: 0.601  loss_cls: 0.183  loss_box_reg: 0.334  loss_rpn_cls: 0.011  loss_rpn_loc: 0.049  time: 1.0313  data_time: 0.0102  lr: 0.003696  max_mem: 5406M
[32m[04/20 17:18:19 d2.utils.events]: [0m eta: 0:04:11  iter: 759  total_loss: 0.596  loss_cls: 0.189  loss_box_reg: 0.310  loss_rpn_cls: 0.016  loss_rpn_loc: 0.054  time: 1.0318  data_time: 0.0115  lr: 0.003796  max_mem: 5406M
[32m[04/20 17:18:40 d2.utils.events]: [0m eta: 0:03:50  iter: 779  total_loss: 0.635  loss_cls: 0.197  loss_box_reg: 0.355  loss_rpn_cls: 0.013  loss_rpn_loc: 0.066  time: 1.0320  data_time: 0.0108  lr: 0.003896  max_mem: 5406M
[32m[04/20 17:19:00 d2.utils.events]: [0m eta: 0:03:29  iter: 799  total_loss: 0.573  loss_cls: 0.184  loss_box_reg: 0.325  loss_rpn_cls: 0.011  loss_rpn_loc: 0.050  time: 1.0315  data_time: 0.0109  lr: 0.003996  max_mem: 5406M
[32m[04/20 17:19:22 d2.utils.events]: [0m eta: 0:03:08  iter: 819  total_loss: 0.541  loss_cls: 0.168  loss_box_reg: 0.323  loss_rpn_cls: 0.010  loss_rpn_loc: 0.040  time: 1.0321  data_time: 0.0116  lr: 0.004096  max_mem: 5406M
[32m[04/20 17:19:43 d2.utils.events]: [0m eta: 0:02:47  iter: 839  total_loss: 0.610  loss_cls: 0.202  loss_box_reg: 0.326  loss_rpn_cls: 0.015  loss_rpn_loc: 0.053  time: 1.0323  data_time: 0.0107  lr: 0.004196  max_mem: 5406M
[32m[04/20 17:20:03 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.552  loss_cls: 0.189  loss_box_reg: 0.311  loss_rpn_cls: 0.012  loss_rpn_loc: 0.045  time: 1.0325  data_time: 0.0107  lr: 0.004296  max_mem: 5406M
[32m[04/20 17:20:24 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.588  loss_cls: 0.194  loss_box_reg: 0.344  loss_rpn_cls: 0.014  loss_rpn_loc: 0.045  time: 1.0319  data_time: 0.0105  lr: 0.004396  max_mem: 5406M
[32m[04/20 17:20:44 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.671  loss_cls: 0.220  loss_box_reg: 0.372  loss_rpn_cls: 0.015  loss_rpn_loc: 0.061  time: 1.0321  data_time: 0.0121  lr: 0.004496  max_mem: 5406M
[32m[04/20 17:21:05 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.636  loss_cls: 0.187  loss_box_reg: 0.342  loss_rpn_cls: 0.018  loss_rpn_loc: 0.051  time: 1.0317  data_time: 0.0104  lr: 0.004595  max_mem: 5406M
[32m[04/20 17:21:26 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.597  loss_cls: 0.211  loss_box_reg: 0.326  loss_rpn_cls: 0.016  loss_rpn_loc: 0.051  time: 1.0319  data_time: 0.0104  lr: 0.004695  max_mem: 5406M
[32m[04/20 17:21:46 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.650  loss_cls: 0.212  loss_box_reg: 0.356  loss_rpn_cls: 0.016  loss_rpn_loc: 0.070  time: 1.0317  data_time: 0.0105  lr: 0.004795  max_mem: 5406M
[32m[04/20 17:22:07 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.703  loss_cls: 0.216  loss_box_reg: 0.392  loss_rpn_cls: 0.017  loss_rpn_loc: 0.063  time: 1.0319  data_time: 0.0123  lr: 0.004895  max_mem: 5406M
[5m[31mWARNING[0m [32m[04/20 17:22:31 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 17:22:31 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 17:22:31 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 17:22:31 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.661  loss_cls: 0.209  loss_box_reg: 0.376  loss_rpn_cls: 0.017  loss_rpn_loc: 0.052  time: 1.0319  data_time: 0.0107  lr: 0.004995  max_mem: 5406M
[32m[04/20 17:22:32 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:09 (1.0329 s / it)
[32m[04/20 17:22:32 d2.engine.hooks]: [0mTotal training time: 0:17:17 (0:00:07 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 17:22:36 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 17:22:36 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 17:22:37 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 17:22:38 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1172 s / img. ETA=0:16:36
[32m[04/20 17:22:43 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1169 s / img. ETA=0:16:30
[32m[04/20 17:22:48 d2.evaluation.evaluator]: [0mInference done 96/8355. 0.1165 s / img. ETA=0:16:22
[32m[04/20 17:22:53 d2.evaluation.evaluator]: [0mInference done 139/8355. 0.1164 s / img. ETA=0:16:17
[32m[04/20 17:22:58 d2.evaluation.evaluator]: [0mInference done 182/8355. 0.1164 s / img. ETA=0:16:11
[32m[04/20 17:23:03 d2.evaluation.evaluator]: [0mInference done 224/8355. 0.1165 s / img. ETA=0:16:07
[32m[04/20 17:23:09 d2.evaluation.evaluator]: [0mInference done 267/8355. 0.1165 s / img. ETA=0:16:02
[32m[04/20 17:23:14 d2.evaluation.evaluator]: [0mInference done 309/8355. 0.1165 s / img. ETA=0:15:57
[32m[04/20 17:23:19 d2.evaluation.evaluator]: [0mInference done 352/8355. 0.1165 s / img. ETA=0:15:52
[32m[04/20 17:23:24 d2.evaluation.evaluator]: [0mInference done 394/8355. 0.1165 s / img. ETA=0:15:47
[32m[04/20 17:23:29 d2.evaluation.evaluator]: [0mInference done 436/8355. 0.1166 s / img. ETA=0:15:43
[32m[04/20 17:23:34 d2.evaluation.evaluator]: [0mInference done 478/8355. 0.1166 s / img. ETA=0:15:38
[32m[04/20 17:23:39 d2.evaluation.evaluator]: [0mInference done 521/8355. 0.1166 s / img. ETA=0:15:33
[32m[04/20 17:23:44 d2.evaluation.evaluator]: [0mInference done 563/8355. 0.1166 s / img. ETA=0:15:28
[32m[04/20 17:23:49 d2.evaluation.evaluator]: [0mInference done 605/8355. 0.1166 s / img. ETA=0:15:23
[32m[04/20 17:23:54 d2.evaluation.evaluator]: [0mInference done 648/8355. 0.1166 s / img. ETA=0:15:18
[32m[04/20 17:23:59 d2.evaluation.evaluator]: [0mInference done 690/8355. 0.1167 s / img. ETA=0:15:13
[32m[04/20 17:24:04 d2.evaluation.evaluator]: [0mInference done 732/8355. 0.1167 s / img. ETA=0:15:08
[32m[04/20 17:24:09 d2.evaluation.evaluator]: [0mInference done 775/8355. 0.1166 s / img. ETA=0:15:03
[32m[04/20 17:24:14 d2.evaluation.evaluator]: [0mInference done 817/8355. 0.1167 s / img. ETA=0:14:58
[32m[04/20 17:24:19 d2.evaluation.evaluator]: [0mInference done 859/8355. 0.1167 s / img. ETA=0:14:53
[32m[04/20 17:24:24 d2.evaluation.evaluator]: [0mInference done 901/8355. 0.1167 s / img. ETA=0:14:49
[32m[04/20 17:24:29 d2.evaluation.evaluator]: [0mInference done 943/8355. 0.1167 s / img. ETA=0:14:43
[32m[04/20 17:24:34 d2.evaluation.evaluator]: [0mInference done 986/8355. 0.1167 s / img. ETA=0:14:38
[32m[04/20 17:24:39 d2.evaluation.evaluator]: [0mInference done 1028/8355. 0.1167 s / img. ETA=0:14:33
[32m[04/20 17:24:44 d2.evaluation.evaluator]: [0mInference done 1070/8355. 0.1167 s / img. ETA=0:14:28
[32m[04/20 17:24:49 d2.evaluation.evaluator]: [0mInference done 1112/8355. 0.1167 s / img. ETA=0:14:23
[32m[04/20 17:24:55 d2.evaluation.evaluator]: [0mInference done 1155/8355. 0.1167 s / img. ETA=0:14:18
[32m[04/20 17:25:00 d2.evaluation.evaluator]: [0mInference done 1197/8355. 0.1167 s / img. ETA=0:14:13
[32m[04/20 17:25:05 d2.evaluation.evaluator]: [0mInference done 1239/8355. 0.1167 s / img. ETA=0:14:08
[32m[04/20 17:25:10 d2.evaluation.evaluator]: [0mInference done 1282/8355. 0.1167 s / img. ETA=0:14:03
[32m[04/20 17:25:15 d2.evaluation.evaluator]: [0mInference done 1325/8355. 0.1167 s / img. ETA=0:13:58
[32m[04/20 17:25:20 d2.evaluation.evaluator]: [0mInference done 1367/8355. 0.1167 s / img. ETA=0:13:53
[32m[04/20 17:25:25 d2.evaluation.evaluator]: [0mInference done 1410/8355. 0.1167 s / img. ETA=0:13:48
[32m[04/20 17:25:30 d2.evaluation.evaluator]: [0mInference done 1452/8355. 0.1167 s / img. ETA=0:13:43
[32m[04/20 17:25:35 d2.evaluation.evaluator]: [0mInference done 1494/8355. 0.1167 s / img. ETA=0:13:38
[32m[04/20 17:25:40 d2.evaluation.evaluator]: [0mInference done 1536/8355. 0.1168 s / img. ETA=0:13:33
[32m[04/20 17:25:45 d2.evaluation.evaluator]: [0mInference done 1578/8355. 0.1168 s / img. ETA=0:13:28
[32m[04/20 17:25:50 d2.evaluation.evaluator]: [0mInference done 1620/8355. 0.1168 s / img. ETA=0:13:24
[32m[04/20 17:25:55 d2.evaluation.evaluator]: [0mInference done 1662/8355. 0.1169 s / img. ETA=0:13:19
[32m[04/20 17:26:00 d2.evaluation.evaluator]: [0mInference done 1704/8355. 0.1169 s / img. ETA=0:13:14
[32m[04/20 17:26:05 d2.evaluation.evaluator]: [0mInference done 1746/8355. 0.1169 s / img. ETA=0:13:09
[32m[04/20 17:26:10 d2.evaluation.evaluator]: [0mInference done 1788/8355. 0.1169 s / img. ETA=0:13:04
[32m[04/20 17:26:15 d2.evaluation.evaluator]: [0mInference done 1830/8355. 0.1169 s / img. ETA=0:12:59
[32m[04/20 17:26:21 d2.evaluation.evaluator]: [0mInference done 1872/8355. 0.1170 s / img. ETA=0:12:54
[32m[04/20 17:26:26 d2.evaluation.evaluator]: [0mInference done 1914/8355. 0.1170 s / img. ETA=0:12:49
[32m[04/20 17:26:31 d2.evaluation.evaluator]: [0mInference done 1956/8355. 0.1170 s / img. ETA=0:12:44
[32m[04/20 17:26:36 d2.evaluation.evaluator]: [0mInference done 1998/8355. 0.1170 s / img. ETA=0:12:40
[32m[04/20 17:26:41 d2.evaluation.evaluator]: [0mInference done 2040/8355. 0.1170 s / img. ETA=0:12:35
[32m[04/20 17:26:46 d2.evaluation.evaluator]: [0mInference done 2082/8355. 0.1170 s / img. ETA=0:12:30
[32m[04/20 17:26:51 d2.evaluation.evaluator]: [0mInference done 2124/8355. 0.1170 s / img. ETA=0:12:25
[32m[04/20 17:26:56 d2.evaluation.evaluator]: [0mInference done 2166/8355. 0.1170 s / img. ETA=0:12:20
[32m[04/20 17:27:01 d2.evaluation.evaluator]: [0mInference done 2208/8355. 0.1171 s / img. ETA=0:12:15
[32m[04/20 17:27:06 d2.evaluation.evaluator]: [0mInference done 2250/8355. 0.1171 s / img. ETA=0:12:10
[32m[04/20 17:27:11 d2.evaluation.evaluator]: [0mInference done 2292/8355. 0.1171 s / img. ETA=0:12:05
[32m[04/20 17:27:16 d2.evaluation.evaluator]: [0mInference done 2334/8355. 0.1171 s / img. ETA=0:12:00
[32m[04/20 17:27:21 d2.evaluation.evaluator]: [0mInference done 2376/8355. 0.1171 s / img. ETA=0:11:55
[32m[04/20 17:27:26 d2.evaluation.evaluator]: [0mInference done 2418/8355. 0.1171 s / img. ETA=0:11:50
[32m[04/20 17:27:31 d2.evaluation.evaluator]: [0mInference done 2460/8355. 0.1171 s / img. ETA=0:11:45
[32m[04/20 17:27:36 d2.evaluation.evaluator]: [0mInference done 2502/8355. 0.1171 s / img. ETA=0:11:40
[32m[04/20 17:27:41 d2.evaluation.evaluator]: [0mInference done 2544/8355. 0.1171 s / img. ETA=0:11:35
[32m[04/20 17:27:46 d2.evaluation.evaluator]: [0mInference done 2586/8355. 0.1171 s / img. ETA=0:11:30
[32m[04/20 17:27:51 d2.evaluation.evaluator]: [0mInference done 2628/8355. 0.1171 s / img. ETA=0:11:25
[32m[04/20 17:27:56 d2.evaluation.evaluator]: [0mInference done 2670/8355. 0.1171 s / img. ETA=0:11:20
[32m[04/20 17:28:01 d2.evaluation.evaluator]: [0mInference done 2712/8355. 0.1171 s / img. ETA=0:11:15
[32m[04/20 17:28:06 d2.evaluation.evaluator]: [0mInference done 2754/8355. 0.1171 s / img. ETA=0:11:10
[32m[04/20 17:28:11 d2.evaluation.evaluator]: [0mInference done 2796/8355. 0.1171 s / img. ETA=0:11:05
[32m[04/20 17:28:17 d2.evaluation.evaluator]: [0mInference done 2838/8355. 0.1172 s / img. ETA=0:11:00
[32m[04/20 17:28:22 d2.evaluation.evaluator]: [0mInference done 2880/8355. 0.1172 s / img. ETA=0:10:55
[32m[04/20 17:28:27 d2.evaluation.evaluator]: [0mInference done 2922/8355. 0.1172 s / img. ETA=0:10:50
[32m[04/20 17:28:32 d2.evaluation.evaluator]: [0mInference done 2964/8355. 0.1172 s / img. ETA=0:10:45
[32m[04/20 17:28:37 d2.evaluation.evaluator]: [0mInference done 3006/8355. 0.1172 s / img. ETA=0:10:40
[32m[04/20 17:28:42 d2.evaluation.evaluator]: [0mInference done 3049/8355. 0.1172 s / img. ETA=0:10:35
[32m[04/20 17:28:47 d2.evaluation.evaluator]: [0mInference done 3091/8355. 0.1172 s / img. ETA=0:10:30
[32m[04/20 17:28:52 d2.evaluation.evaluator]: [0mInference done 3133/8355. 0.1172 s / img. ETA=0:10:25
[32m[04/20 17:28:57 d2.evaluation.evaluator]: [0mInference done 3175/8355. 0.1172 s / img. ETA=0:10:20
[32m[04/20 17:29:02 d2.evaluation.evaluator]: [0mInference done 3217/8355. 0.1172 s / img. ETA=0:10:15
[32m[04/20 17:29:07 d2.evaluation.evaluator]: [0mInference done 3259/8355. 0.1172 s / img. ETA=0:10:10
[32m[04/20 17:29:12 d2.evaluation.evaluator]: [0mInference done 3301/8355. 0.1172 s / img. ETA=0:10:04
[32m[04/20 17:29:17 d2.evaluation.evaluator]: [0mInference done 3343/8355. 0.1172 s / img. ETA=0:09:59
[32m[04/20 17:29:22 d2.evaluation.evaluator]: [0mInference done 3385/8355. 0.1172 s / img. ETA=0:09:54
[32m[04/20 17:29:27 d2.evaluation.evaluator]: [0mInference done 3427/8355. 0.1172 s / img. ETA=0:09:49
[32m[04/20 17:29:32 d2.evaluation.evaluator]: [0mInference done 3469/8355. 0.1172 s / img. ETA=0:09:44
[32m[04/20 17:29:37 d2.evaluation.evaluator]: [0mInference done 3511/8355. 0.1172 s / img. ETA=0:09:39
[32m[04/20 17:29:42 d2.evaluation.evaluator]: [0mInference done 3553/8355. 0.1172 s / img. ETA=0:09:34
[32m[04/20 17:29:47 d2.evaluation.evaluator]: [0mInference done 3595/8355. 0.1172 s / img. ETA=0:09:29
[32m[04/20 17:29:52 d2.evaluation.evaluator]: [0mInference done 3637/8355. 0.1172 s / img. ETA=0:09:24
[32m[04/20 17:29:57 d2.evaluation.evaluator]: [0mInference done 3679/8355. 0.1172 s / img. ETA=0:09:19
[32m[04/20 17:30:02 d2.evaluation.evaluator]: [0mInference done 3721/8355. 0.1172 s / img. ETA=0:09:14
[32m[04/20 17:30:07 d2.evaluation.evaluator]: [0mInference done 3763/8355. 0.1172 s / img. ETA=0:09:09
[32m[04/20 17:30:12 d2.evaluation.evaluator]: [0mInference done 3805/8355. 0.1172 s / img. ETA=0:09:04
[32m[04/20 17:30:17 d2.evaluation.evaluator]: [0mInference done 3847/8355. 0.1172 s / img. ETA=0:08:59
[32m[04/20 17:30:22 d2.evaluation.evaluator]: [0mInference done 3889/8355. 0.1172 s / img. ETA=0:08:54
[32m[04/20 17:30:27 d2.evaluation.evaluator]: [0mInference done 3931/8355. 0.1172 s / img. ETA=0:08:49
[32m[04/20 17:30:32 d2.evaluation.evaluator]: [0mInference done 3973/8355. 0.1172 s / img. ETA=0:08:44
[32m[04/20 17:30:37 d2.evaluation.evaluator]: [0mInference done 4015/8355. 0.1172 s / img. ETA=0:08:39
[32m[04/20 17:30:42 d2.evaluation.evaluator]: [0mInference done 4057/8355. 0.1172 s / img. ETA=0:08:34
[32m[04/20 17:30:48 d2.evaluation.evaluator]: [0mInference done 4099/8355. 0.1172 s / img. ETA=0:08:29
[32m[04/20 17:30:53 d2.evaluation.evaluator]: [0mInference done 4141/8355. 0.1172 s / img. ETA=0:08:24
[32m[04/20 17:30:58 d2.evaluation.evaluator]: [0mInference done 4183/8355. 0.1172 s / img. ETA=0:08:19
[32m[04/20 17:31:03 d2.evaluation.evaluator]: [0mInference done 4225/8355. 0.1172 s / img. ETA=0:08:14
[32m[04/20 17:31:08 d2.evaluation.evaluator]: [0mInference done 4267/8355. 0.1172 s / img. ETA=0:08:09
[32m[04/20 17:31:13 d2.evaluation.evaluator]: [0mInference done 4309/8355. 0.1172 s / img. ETA=0:08:04
[32m[04/20 17:31:18 d2.evaluation.evaluator]: [0mInference done 4351/8355. 0.1172 s / img. ETA=0:07:59
[32m[04/20 17:31:23 d2.evaluation.evaluator]: [0mInference done 4393/8355. 0.1172 s / img. ETA=0:07:54
[32m[04/20 17:31:28 d2.evaluation.evaluator]: [0mInference done 4435/8355. 0.1172 s / img. ETA=0:07:49
[32m[04/20 17:31:33 d2.evaluation.evaluator]: [0mInference done 4477/8355. 0.1172 s / img. ETA=0:07:44
[32m[04/20 17:31:38 d2.evaluation.evaluator]: [0mInference done 4519/8355. 0.1172 s / img. ETA=0:07:39
[32m[04/20 17:31:43 d2.evaluation.evaluator]: [0mInference done 4561/8355. 0.1172 s / img. ETA=0:07:34
[32m[04/20 17:31:48 d2.evaluation.evaluator]: [0mInference done 4603/8355. 0.1172 s / img. ETA=0:07:29
[32m[04/20 17:31:53 d2.evaluation.evaluator]: [0mInference done 4645/8355. 0.1173 s / img. ETA=0:07:24
[32m[04/20 17:31:58 d2.evaluation.evaluator]: [0mInference done 4687/8355. 0.1172 s / img. ETA=0:07:19
[32m[04/20 17:32:03 d2.evaluation.evaluator]: [0mInference done 4729/8355. 0.1172 s / img. ETA=0:07:14
[32m[04/20 17:32:08 d2.evaluation.evaluator]: [0mInference done 4771/8355. 0.1173 s / img. ETA=0:07:09
[32m[04/20 17:32:13 d2.evaluation.evaluator]: [0mInference done 4813/8355. 0.1173 s / img. ETA=0:07:04
[32m[04/20 17:32:18 d2.evaluation.evaluator]: [0mInference done 4855/8355. 0.1173 s / img. ETA=0:06:59
[32m[04/20 17:32:23 d2.evaluation.evaluator]: [0mInference done 4897/8355. 0.1173 s / img. ETA=0:06:54
[32m[04/20 17:32:28 d2.evaluation.evaluator]: [0mInference done 4939/8355. 0.1173 s / img. ETA=0:06:49
[32m[04/20 17:32:33 d2.evaluation.evaluator]: [0mInference done 4981/8355. 0.1173 s / img. ETA=0:06:44
[32m[04/20 17:32:39 d2.evaluation.evaluator]: [0mInference done 5023/8355. 0.1173 s / img. ETA=0:06:39
[32m[04/20 17:32:44 d2.evaluation.evaluator]: [0mInference done 5065/8355. 0.1173 s / img. ETA=0:06:34
[32m[04/20 17:32:49 d2.evaluation.evaluator]: [0mInference done 5107/8355. 0.1173 s / img. ETA=0:06:29
[32m[04/20 17:32:54 d2.evaluation.evaluator]: [0mInference done 5149/8355. 0.1173 s / img. ETA=0:06:24
[32m[04/20 17:32:59 d2.evaluation.evaluator]: [0mInference done 5191/8355. 0.1173 s / img. ETA=0:06:19
[32m[04/20 17:33:04 d2.evaluation.evaluator]: [0mInference done 5233/8355. 0.1173 s / img. ETA=0:06:14
[32m[04/20 17:33:09 d2.evaluation.evaluator]: [0mInference done 5275/8355. 0.1173 s / img. ETA=0:06:09
[32m[04/20 17:33:14 d2.evaluation.evaluator]: [0mInference done 5317/8355. 0.1173 s / img. ETA=0:06:04
[32m[04/20 17:33:19 d2.evaluation.evaluator]: [0mInference done 5359/8355. 0.1173 s / img. ETA=0:05:59
[32m[04/20 17:33:24 d2.evaluation.evaluator]: [0mInference done 5401/8355. 0.1173 s / img. ETA=0:05:54
[32m[04/20 17:33:29 d2.evaluation.evaluator]: [0mInference done 5443/8355. 0.1173 s / img. ETA=0:05:48
[32m[04/20 17:33:34 d2.evaluation.evaluator]: [0mInference done 5485/8355. 0.1173 s / img. ETA=0:05:43
[32m[04/20 17:33:39 d2.evaluation.evaluator]: [0mInference done 5527/8355. 0.1173 s / img. ETA=0:05:38
[32m[04/20 17:33:44 d2.evaluation.evaluator]: [0mInference done 5569/8355. 0.1173 s / img. ETA=0:05:33
[32m[04/20 17:33:49 d2.evaluation.evaluator]: [0mInference done 5611/8355. 0.1173 s / img. ETA=0:05:28
[32m[04/20 17:33:54 d2.evaluation.evaluator]: [0mInference done 5653/8355. 0.1174 s / img. ETA=0:05:23
[32m[04/20 17:33:59 d2.evaluation.evaluator]: [0mInference done 5695/8355. 0.1174 s / img. ETA=0:05:18
[32m[04/20 17:34:05 d2.evaluation.evaluator]: [0mInference done 5737/8355. 0.1174 s / img. ETA=0:05:13
[32m[04/20 17:34:10 d2.evaluation.evaluator]: [0mInference done 5779/8355. 0.1174 s / img. ETA=0:05:08
[32m[04/20 17:34:15 d2.evaluation.evaluator]: [0mInference done 5821/8355. 0.1174 s / img. ETA=0:05:03
[32m[04/20 17:34:20 d2.evaluation.evaluator]: [0mInference done 5863/8355. 0.1174 s / img. ETA=0:04:58
[32m[04/20 17:34:25 d2.evaluation.evaluator]: [0mInference done 5905/8355. 0.1174 s / img. ETA=0:04:53
[32m[04/20 17:34:30 d2.evaluation.evaluator]: [0mInference done 5947/8355. 0.1174 s / img. ETA=0:04:48
[32m[04/20 17:34:35 d2.evaluation.evaluator]: [0mInference done 5989/8355. 0.1174 s / img. ETA=0:04:43
[32m[04/20 17:34:40 d2.evaluation.evaluator]: [0mInference done 6031/8355. 0.1174 s / img. ETA=0:04:38
[32m[04/20 17:34:45 d2.evaluation.evaluator]: [0mInference done 6073/8355. 0.1174 s / img. ETA=0:04:33
[32m[04/20 17:34:50 d2.evaluation.evaluator]: [0mInference done 6115/8355. 0.1174 s / img. ETA=0:04:28
[32m[04/20 17:34:55 d2.evaluation.evaluator]: [0mInference done 6157/8355. 0.1174 s / img. ETA=0:04:23
[32m[04/20 17:35:00 d2.evaluation.evaluator]: [0mInference done 6199/8355. 0.1174 s / img. ETA=0:04:18
[32m[04/20 17:35:05 d2.evaluation.evaluator]: [0mInference done 6241/8355. 0.1174 s / img. ETA=0:04:13
[32m[04/20 17:35:10 d2.evaluation.evaluator]: [0mInference done 6283/8355. 0.1174 s / img. ETA=0:04:08
[32m[04/20 17:35:15 d2.evaluation.evaluator]: [0mInference done 6325/8355. 0.1174 s / img. ETA=0:04:03
[32m[04/20 17:35:20 d2.evaluation.evaluator]: [0mInference done 6367/8355. 0.1174 s / img. ETA=0:03:58
[32m[04/20 17:35:25 d2.evaluation.evaluator]: [0mInference done 6409/8355. 0.1174 s / img. ETA=0:03:53
[32m[04/20 17:35:30 d2.evaluation.evaluator]: [0mInference done 6451/8355. 0.1174 s / img. ETA=0:03:48
[32m[04/20 17:35:36 d2.evaluation.evaluator]: [0mInference done 6493/8355. 0.1174 s / img. ETA=0:03:43
[32m[04/20 17:35:41 d2.evaluation.evaluator]: [0mInference done 6535/8355. 0.1174 s / img. ETA=0:03:38
[32m[04/20 17:35:46 d2.evaluation.evaluator]: [0mInference done 6577/8355. 0.1174 s / img. ETA=0:03:33
[32m[04/20 17:35:51 d2.evaluation.evaluator]: [0mInference done 6619/8355. 0.1174 s / img. ETA=0:03:28
[32m[04/20 17:35:56 d2.evaluation.evaluator]: [0mInference done 6661/8355. 0.1174 s / img. ETA=0:03:23
[32m[04/20 17:36:01 d2.evaluation.evaluator]: [0mInference done 6704/8355. 0.1174 s / img. ETA=0:03:17
[32m[04/20 17:36:06 d2.evaluation.evaluator]: [0mInference done 6746/8355. 0.1174 s / img. ETA=0:03:12
[32m[04/20 17:36:11 d2.evaluation.evaluator]: [0mInference done 6789/8355. 0.1174 s / img. ETA=0:03:07
[32m[04/20 17:36:16 d2.evaluation.evaluator]: [0mInference done 6831/8355. 0.1174 s / img. ETA=0:03:02
[32m[04/20 17:36:21 d2.evaluation.evaluator]: [0mInference done 6873/8355. 0.1174 s / img. ETA=0:02:57
[32m[04/20 17:36:26 d2.evaluation.evaluator]: [0mInference done 6916/8355. 0.1174 s / img. ETA=0:02:52
[32m[04/20 17:36:31 d2.evaluation.evaluator]: [0mInference done 6958/8355. 0.1174 s / img. ETA=0:02:47
[32m[04/20 17:36:36 d2.evaluation.evaluator]: [0mInference done 7000/8355. 0.1174 s / img. ETA=0:02:42
[32m[04/20 17:36:41 d2.evaluation.evaluator]: [0mInference done 7042/8355. 0.1174 s / img. ETA=0:02:37
[32m[04/20 17:36:46 d2.evaluation.evaluator]: [0mInference done 7084/8355. 0.1174 s / img. ETA=0:02:32
[32m[04/20 17:36:51 d2.evaluation.evaluator]: [0mInference done 7126/8355. 0.1174 s / img. ETA=0:02:27
[32m[04/20 17:36:56 d2.evaluation.evaluator]: [0mInference done 7168/8355. 0.1174 s / img. ETA=0:02:22
[32m[04/20 17:37:01 d2.evaluation.evaluator]: [0mInference done 7210/8355. 0.1175 s / img. ETA=0:02:17
[32m[04/20 17:37:07 d2.evaluation.evaluator]: [0mInference done 7252/8355. 0.1175 s / img. ETA=0:02:12
[32m[04/20 17:37:12 d2.evaluation.evaluator]: [0mInference done 7293/8355. 0.1175 s / img. ETA=0:02:07
[32m[04/20 17:37:17 d2.evaluation.evaluator]: [0mInference done 7335/8355. 0.1175 s / img. ETA=0:02:02
[32m[04/20 17:37:22 d2.evaluation.evaluator]: [0mInference done 7377/8355. 0.1175 s / img. ETA=0:01:57
[32m[04/20 17:37:27 d2.evaluation.evaluator]: [0mInference done 7419/8355. 0.1175 s / img. ETA=0:01:52
[32m[04/20 17:37:32 d2.evaluation.evaluator]: [0mInference done 7461/8355. 0.1175 s / img. ETA=0:01:47
[32m[04/20 17:37:37 d2.evaluation.evaluator]: [0mInference done 7503/8355. 0.1175 s / img. ETA=0:01:42
[32m[04/20 17:37:42 d2.evaluation.evaluator]: [0mInference done 7545/8355. 0.1175 s / img. ETA=0:01:37
[32m[04/20 17:37:47 d2.evaluation.evaluator]: [0mInference done 7587/8355. 0.1175 s / img. ETA=0:01:32
[32m[04/20 17:37:52 d2.evaluation.evaluator]: [0mInference done 7629/8355. 0.1175 s / img. ETA=0:01:27
[32m[04/20 17:37:57 d2.evaluation.evaluator]: [0mInference done 7671/8355. 0.1175 s / img. ETA=0:01:22
[32m[04/20 17:38:02 d2.evaluation.evaluator]: [0mInference done 7713/8355. 0.1175 s / img. ETA=0:01:17
[32m[04/20 17:38:08 d2.evaluation.evaluator]: [0mInference done 7755/8355. 0.1175 s / img. ETA=0:01:12
[32m[04/20 17:38:13 d2.evaluation.evaluator]: [0mInference done 7797/8355. 0.1176 s / img. ETA=0:01:06
[32m[04/20 17:38:18 d2.evaluation.evaluator]: [0mInference done 7839/8355. 0.1176 s / img. ETA=0:01:01
[32m[04/20 17:38:23 d2.evaluation.evaluator]: [0mInference done 7881/8355. 0.1176 s / img. ETA=0:00:56
[32m[04/20 17:38:28 d2.evaluation.evaluator]: [0mInference done 7923/8355. 0.1176 s / img. ETA=0:00:51
[32m[04/20 17:38:33 d2.evaluation.evaluator]: [0mInference done 7965/8355. 0.1176 s / img. ETA=0:00:46
[32m[04/20 17:38:38 d2.evaluation.evaluator]: [0mInference done 8004/8355. 0.1176 s / img. ETA=0:00:42
[32m[04/20 17:38:43 d2.evaluation.evaluator]: [0mInference done 8046/8355. 0.1176 s / img. ETA=0:00:37
[32m[04/20 17:38:48 d2.evaluation.evaluator]: [0mInference done 8088/8355. 0.1176 s / img. ETA=0:00:32
[32m[04/20 17:38:53 d2.evaluation.evaluator]: [0mInference done 8130/8355. 0.1176 s / img. ETA=0:00:27
[32m[04/20 17:38:58 d2.evaluation.evaluator]: [0mInference done 8172/8355. 0.1176 s / img. ETA=0:00:21
[32m[04/20 17:39:03 d2.evaluation.evaluator]: [0mInference done 8214/8355. 0.1176 s / img. ETA=0:00:16
[32m[04/20 17:39:08 d2.evaluation.evaluator]: [0mInference done 8256/8355. 0.1176 s / img. ETA=0:00:11
[32m[04/20 17:39:13 d2.evaluation.evaluator]: [0mInference done 8298/8355. 0.1176 s / img. ETA=0:00:06
[32m[04/20 17:39:18 d2.evaluation.evaluator]: [0mInference done 8340/8355. 0.1176 s / img. ETA=0:00:01
[32m[04/20 17:39:20 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:42.684325 (0.120082 s / img per device, on 1 devices)
[32m[04/20 17:39:20 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:21 (0.117602 s / img per device, on 1 devices)
[32m[04/20 17:39:20 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 17:39:20 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 17:39:21 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=21.48s).
Accumulating evaluation results...
DONE (t=2.44s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.399
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.720
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.388
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.692
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.159
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.444
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.360
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.581
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.737
[32m[04/20 17:39:45 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.912 | 71.974 | 38.807 | 29.152 | 52.339 | 69.229 |
[32m[04/20 17:39:45 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 41.875 | bicycle       | 26.969 | car            | 50.891 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 17:39:46 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 17:39:46 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 17:39:46 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 17:39:48 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1177 s / img. ETA=0:02:29
[32m[04/20 17:39:53 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1178 s / img. ETA=0:02:24
[32m[04/20 17:39:58 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1180 s / img. ETA=0:02:19
[32m[04/20 17:40:03 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1179 s / img. ETA=0:02:14
[32m[04/20 17:40:08 d2.evaluation.evaluator]: [0mInference done 179/1257. 0.1181 s / img. ETA=0:02:09
[32m[04/20 17:40:13 d2.evaluation.evaluator]: [0mInference done 221/1257. 0.1179 s / img. ETA=0:02:04
[32m[04/20 17:40:18 d2.evaluation.evaluator]: [0mInference done 263/1257. 0.1180 s / img. ETA=0:01:59
[32m[04/20 17:40:23 d2.evaluation.evaluator]: [0mInference done 305/1257. 0.1180 s / img. ETA=0:01:54
[32m[04/20 17:40:28 d2.evaluation.evaluator]: [0mInference done 347/1257. 0.1180 s / img. ETA=0:01:49
[32m[04/20 17:40:33 d2.evaluation.evaluator]: [0mInference done 389/1257. 0.1180 s / img. ETA=0:01:44
[32m[04/20 17:40:38 d2.evaluation.evaluator]: [0mInference done 431/1257. 0.1180 s / img. ETA=0:01:39
[32m[04/20 17:40:43 d2.evaluation.evaluator]: [0mInference done 473/1257. 0.1180 s / img. ETA=0:01:34
[32m[04/20 17:40:48 d2.evaluation.evaluator]: [0mInference done 515/1257. 0.1179 s / img. ETA=0:01:29
[32m[04/20 17:40:54 d2.evaluation.evaluator]: [0mInference done 557/1257. 0.1180 s / img. ETA=0:01:24
[32m[04/20 17:40:59 d2.evaluation.evaluator]: [0mInference done 599/1257. 0.1180 s / img. ETA=0:01:19
[32m[04/20 17:41:04 d2.evaluation.evaluator]: [0mInference done 641/1257. 0.1180 s / img. ETA=0:01:14
[32m[04/20 17:41:09 d2.evaluation.evaluator]: [0mInference done 683/1257. 0.1180 s / img. ETA=0:01:09
[32m[04/20 17:41:14 d2.evaluation.evaluator]: [0mInference done 725/1257. 0.1180 s / img. ETA=0:01:04
[32m[04/20 17:41:19 d2.evaluation.evaluator]: [0mInference done 767/1257. 0.1180 s / img. ETA=0:00:59
[32m[04/20 17:41:24 d2.evaluation.evaluator]: [0mInference done 809/1257. 0.1180 s / img. ETA=0:00:53
[32m[04/20 17:41:29 d2.evaluation.evaluator]: [0mInference done 851/1257. 0.1180 s / img. ETA=0:00:48
[32m[04/20 17:41:34 d2.evaluation.evaluator]: [0mInference done 893/1257. 0.1181 s / img. ETA=0:00:43
[32m[04/20 17:41:39 d2.evaluation.evaluator]: [0mInference done 935/1257. 0.1180 s / img. ETA=0:00:38
[32m[04/20 17:41:44 d2.evaluation.evaluator]: [0mInference done 977/1257. 0.1180 s / img. ETA=0:00:33
[32m[04/20 17:41:49 d2.evaluation.evaluator]: [0mInference done 1019/1257. 0.1180 s / img. ETA=0:00:28
[32m[04/20 17:41:54 d2.evaluation.evaluator]: [0mInference done 1061/1257. 0.1180 s / img. ETA=0:00:23
[32m[04/20 17:41:59 d2.evaluation.evaluator]: [0mInference done 1103/1257. 0.1180 s / img. ETA=0:00:18
[32m[04/20 17:42:04 d2.evaluation.evaluator]: [0mInference done 1145/1257. 0.1180 s / img. ETA=0:00:13
[32m[04/20 17:42:09 d2.evaluation.evaluator]: [0mInference done 1187/1257. 0.1180 s / img. ETA=0:00:08
[32m[04/20 17:42:15 d2.evaluation.evaluator]: [0mInference done 1229/1257. 0.1180 s / img. ETA=0:00:03
[32m[04/20 17:42:18 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:30.933931 (0.120554 s / img per device, on 1 devices)
[32m[04/20 17:42:18 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:27 (0.118044 s / img per device, on 1 devices)
[32m[04/20 17:42:18 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 17:42:18 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 17:42:18 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.03s).
Accumulating evaluation results...
DONE (t=0.38s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.562
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.266
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.351
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.491
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.354
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.408
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.557
[32m[04/20 17:42:22 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 29.624 | 56.160 | 26.558 | 19.136 | 35.104 | 49.088 |
[32m[04/20 17:42:22 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 31.822 | bicycle       | 10.582 | car            | 46.468 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  20  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 17:42:22 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 17:42:23 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 17:42:23 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 17:42:23 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 17:42:23 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 17:42:23 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 17:42:23 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 17:42:44 d2.utils.events]: [0m eta: 0:16:42  iter: 19  total_loss: 0.564  loss_cls: 0.196  loss_box_reg: 0.306  loss_rpn_cls: 0.013  loss_rpn_loc: 0.058  time: 1.0221  data_time: 0.0242  lr: 0.000100  max_mem: 5406M
[32m[04/20 17:43:05 d2.utils.events]: [0m eta: 0:16:33  iter: 39  total_loss: 0.576  loss_cls: 0.194  loss_box_reg: 0.317  loss_rpn_cls: 0.015  loss_rpn_loc: 0.055  time: 1.0269  data_time: 0.0111  lr: 0.000200  max_mem: 5406M
[32m[04/20 17:43:25 d2.utils.events]: [0m eta: 0:16:22  iter: 59  total_loss: 0.533  loss_cls: 0.185  loss_box_reg: 0.297  loss_rpn_cls: 0.014  loss_rpn_loc: 0.044  time: 1.0306  data_time: 0.0102  lr: 0.000300  max_mem: 5406M
[32m[04/20 17:43:46 d2.utils.events]: [0m eta: 0:15:44  iter: 79  total_loss: 0.637  loss_cls: 0.201  loss_box_reg: 0.332  loss_rpn_cls: 0.015  loss_rpn_loc: 0.073  time: 1.0251  data_time: 0.0120  lr: 0.000400  max_mem: 5406M
[32m[04/20 17:44:07 d2.utils.events]: [0m eta: 0:15:38  iter: 99  total_loss: 0.554  loss_cls: 0.183  loss_box_reg: 0.317  loss_rpn_cls: 0.011  loss_rpn_loc: 0.046  time: 1.0295  data_time: 0.0116  lr: 0.000500  max_mem: 5406M
[32m[04/20 17:44:27 d2.utils.events]: [0m eta: 0:15:15  iter: 119  total_loss: 0.528  loss_cls: 0.173  loss_box_reg: 0.320  loss_rpn_cls: 0.014  loss_rpn_loc: 0.052  time: 1.0307  data_time: 0.0120  lr: 0.000599  max_mem: 5406M
[32m[04/20 17:44:49 d2.utils.events]: [0m eta: 0:14:56  iter: 139  total_loss: 0.538  loss_cls: 0.172  loss_box_reg: 0.308  loss_rpn_cls: 0.011  loss_rpn_loc: 0.042  time: 1.0340  data_time: 0.0113  lr: 0.000699  max_mem: 5406M
[32m[04/20 17:45:09 d2.utils.events]: [0m eta: 0:14:29  iter: 159  total_loss: 0.553  loss_cls: 0.180  loss_box_reg: 0.326  loss_rpn_cls: 0.012  loss_rpn_loc: 0.045  time: 1.0302  data_time: 0.0114  lr: 0.000799  max_mem: 5406M
[32m[04/20 17:45:30 d2.utils.events]: [0m eta: 0:14:11  iter: 179  total_loss: 0.530  loss_cls: 0.174  loss_box_reg: 0.300  loss_rpn_cls: 0.010  loss_rpn_loc: 0.045  time: 1.0317  data_time: 0.0113  lr: 0.000899  max_mem: 5406M
[32m[04/20 17:45:50 d2.utils.events]: [0m eta: 0:13:51  iter: 199  total_loss: 0.527  loss_cls: 0.168  loss_box_reg: 0.306  loss_rpn_cls: 0.011  loss_rpn_loc: 0.041  time: 1.0312  data_time: 0.0112  lr: 0.000999  max_mem: 5406M
[32m[04/20 17:46:11 d2.utils.events]: [0m eta: 0:13:32  iter: 219  total_loss: 0.540  loss_cls: 0.177  loss_box_reg: 0.306  loss_rpn_cls: 0.013  loss_rpn_loc: 0.049  time: 1.0328  data_time: 0.0112  lr: 0.001099  max_mem: 5406M
[32m[04/20 17:46:32 d2.utils.events]: [0m eta: 0:13:13  iter: 239  total_loss: 0.507  loss_cls: 0.165  loss_box_reg: 0.294  loss_rpn_cls: 0.011  loss_rpn_loc: 0.051  time: 1.0349  data_time: 0.0109  lr: 0.001199  max_mem: 5406M
[32m[04/20 17:46:54 d2.utils.events]: [0m eta: 0:12:54  iter: 259  total_loss: 0.587  loss_cls: 0.186  loss_box_reg: 0.336  loss_rpn_cls: 0.009  loss_rpn_loc: 0.040  time: 1.0366  data_time: 0.0114  lr: 0.001299  max_mem: 5406M
[32m[04/20 17:47:14 d2.utils.events]: [0m eta: 0:12:33  iter: 279  total_loss: 0.539  loss_cls: 0.172  loss_box_reg: 0.319  loss_rpn_cls: 0.011  loss_rpn_loc: 0.052  time: 1.0365  data_time: 0.0110  lr: 0.001399  max_mem: 5406M
[32m[04/20 17:47:35 d2.utils.events]: [0m eta: 0:12:12  iter: 299  total_loss: 0.619  loss_cls: 0.191  loss_box_reg: 0.320  loss_rpn_cls: 0.012  loss_rpn_loc: 0.065  time: 1.0368  data_time: 0.0107  lr: 0.001499  max_mem: 5406M
[32m[04/20 17:47:56 d2.utils.events]: [0m eta: 0:11:49  iter: 319  total_loss: 0.531  loss_cls: 0.177  loss_box_reg: 0.325  loss_rpn_cls: 0.014  loss_rpn_loc: 0.038  time: 1.0360  data_time: 0.0105  lr: 0.001598  max_mem: 5406M
[32m[04/20 17:48:16 d2.utils.events]: [0m eta: 0:11:27  iter: 339  total_loss: 0.630  loss_cls: 0.201  loss_box_reg: 0.364  loss_rpn_cls: 0.018  loss_rpn_loc: 0.052  time: 1.0357  data_time: 0.0106  lr: 0.001698  max_mem: 5406M
[32m[04/20 17:48:37 d2.utils.events]: [0m eta: 0:11:07  iter: 359  total_loss: 0.568  loss_cls: 0.180  loss_box_reg: 0.313  loss_rpn_cls: 0.009  loss_rpn_loc: 0.056  time: 1.0360  data_time: 0.0110  lr: 0.001798  max_mem: 5406M
[32m[04/20 17:48:58 d2.utils.events]: [0m eta: 0:10:47  iter: 379  total_loss: 0.494  loss_cls: 0.155  loss_box_reg: 0.273  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0365  data_time: 0.0117  lr: 0.001898  max_mem: 5406M
[32m[04/20 17:49:19 d2.utils.events]: [0m eta: 0:10:28  iter: 399  total_loss: 0.566  loss_cls: 0.175  loss_box_reg: 0.319  loss_rpn_cls: 0.011  loss_rpn_loc: 0.056  time: 1.0368  data_time: 0.0121  lr: 0.001998  max_mem: 5406M
[32m[04/20 17:49:39 d2.utils.events]: [0m eta: 0:10:06  iter: 419  total_loss: 0.624  loss_cls: 0.191  loss_box_reg: 0.356  loss_rpn_cls: 0.013  loss_rpn_loc: 0.055  time: 1.0359  data_time: 0.0112  lr: 0.002098  max_mem: 5406M
[32m[04/20 17:50:00 d2.utils.events]: [0m eta: 0:09:45  iter: 439  total_loss: 0.544  loss_cls: 0.168  loss_box_reg: 0.321  loss_rpn_cls: 0.010  loss_rpn_loc: 0.048  time: 1.0352  data_time: 0.0108  lr: 0.002198  max_mem: 5406M
[32m[04/20 17:50:21 d2.utils.events]: [0m eta: 0:09:25  iter: 459  total_loss: 0.552  loss_cls: 0.171  loss_box_reg: 0.320  loss_rpn_cls: 0.014  loss_rpn_loc: 0.054  time: 1.0354  data_time: 0.0121  lr: 0.002298  max_mem: 5406M
[32m[04/20 17:50:41 d2.utils.events]: [0m eta: 0:09:04  iter: 479  total_loss: 0.540  loss_cls: 0.170  loss_box_reg: 0.302  loss_rpn_cls: 0.017  loss_rpn_loc: 0.052  time: 1.0349  data_time: 0.0114  lr: 0.002398  max_mem: 5406M
[32m[04/20 17:51:03 d2.utils.events]: [0m eta: 0:08:44  iter: 499  total_loss: 0.531  loss_cls: 0.174  loss_box_reg: 0.292  loss_rpn_cls: 0.013  loss_rpn_loc: 0.046  time: 1.0360  data_time: 0.0107  lr: 0.002498  max_mem: 5406M
[32m[04/20 17:51:24 d2.utils.events]: [0m eta: 0:08:25  iter: 519  total_loss: 0.547  loss_cls: 0.160  loss_box_reg: 0.327  loss_rpn_cls: 0.010  loss_rpn_loc: 0.052  time: 1.0374  data_time: 0.0112  lr: 0.002597  max_mem: 5406M
[32m[04/20 17:51:45 d2.utils.events]: [0m eta: 0:08:04  iter: 539  total_loss: 0.658  loss_cls: 0.189  loss_box_reg: 0.370  loss_rpn_cls: 0.011  loss_rpn_loc: 0.054  time: 1.0374  data_time: 0.0106  lr: 0.002697  max_mem: 5406M
[32m[04/20 17:52:06 d2.utils.events]: [0m eta: 0:07:42  iter: 559  total_loss: 0.566  loss_cls: 0.180  loss_box_reg: 0.321  loss_rpn_cls: 0.012  loss_rpn_loc: 0.055  time: 1.0375  data_time: 0.0105  lr: 0.002797  max_mem: 5406M
[32m[04/20 17:52:27 d2.utils.events]: [0m eta: 0:07:22  iter: 579  total_loss: 0.619  loss_cls: 0.190  loss_box_reg: 0.355  loss_rpn_cls: 0.013  loss_rpn_loc: 0.051  time: 1.0376  data_time: 0.0114  lr: 0.002897  max_mem: 5406M
[32m[04/20 17:52:47 d2.utils.events]: [0m eta: 0:07:01  iter: 599  total_loss: 0.584  loss_cls: 0.188  loss_box_reg: 0.328  loss_rpn_cls: 0.013  loss_rpn_loc: 0.052  time: 1.0377  data_time: 0.0112  lr: 0.002997  max_mem: 5406M
[32m[04/20 17:53:08 d2.utils.events]: [0m eta: 0:06:40  iter: 619  total_loss: 0.535  loss_cls: 0.151  loss_box_reg: 0.305  loss_rpn_cls: 0.010  loss_rpn_loc: 0.048  time: 1.0375  data_time: 0.0113  lr: 0.003097  max_mem: 5406M
[32m[04/20 17:53:29 d2.utils.events]: [0m eta: 0:06:19  iter: 639  total_loss: 0.495  loss_cls: 0.162  loss_box_reg: 0.279  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0377  data_time: 0.0113  lr: 0.003197  max_mem: 5406M
[32m[04/20 17:53:49 d2.utils.events]: [0m eta: 0:05:57  iter: 659  total_loss: 0.554  loss_cls: 0.176  loss_box_reg: 0.329  loss_rpn_cls: 0.018  loss_rpn_loc: 0.048  time: 1.0370  data_time: 0.0104  lr: 0.003297  max_mem: 5406M
[32m[04/20 17:54:10 d2.utils.events]: [0m eta: 0:05:36  iter: 679  total_loss: 0.570  loss_cls: 0.170  loss_box_reg: 0.329  loss_rpn_cls: 0.008  loss_rpn_loc: 0.057  time: 1.0367  data_time: 0.0115  lr: 0.003397  max_mem: 5406M
[32m[04/20 17:54:31 d2.utils.events]: [0m eta: 0:05:15  iter: 699  total_loss: 0.600  loss_cls: 0.192  loss_box_reg: 0.348  loss_rpn_cls: 0.012  loss_rpn_loc: 0.049  time: 1.0364  data_time: 0.0118  lr: 0.003497  max_mem: 5406M
[32m[04/20 17:54:52 d2.utils.events]: [0m eta: 0:04:54  iter: 719  total_loss: 0.578  loss_cls: 0.188  loss_box_reg: 0.340  loss_rpn_cls: 0.012  loss_rpn_loc: 0.047  time: 1.0366  data_time: 0.0115  lr: 0.003596  max_mem: 5406M
[32m[04/20 17:55:12 d2.utils.events]: [0m eta: 0:04:33  iter: 739  total_loss: 0.649  loss_cls: 0.202  loss_box_reg: 0.367  loss_rpn_cls: 0.011  loss_rpn_loc: 0.064  time: 1.0367  data_time: 0.0109  lr: 0.003696  max_mem: 5406M
[32m[04/20 17:55:33 d2.utils.events]: [0m eta: 0:04:12  iter: 759  total_loss: 0.583  loss_cls: 0.180  loss_box_reg: 0.323  loss_rpn_cls: 0.011  loss_rpn_loc: 0.055  time: 1.0370  data_time: 0.0113  lr: 0.003796  max_mem: 5406M
[32m[04/20 17:55:54 d2.utils.events]: [0m eta: 0:03:51  iter: 779  total_loss: 0.629  loss_cls: 0.202  loss_box_reg: 0.345  loss_rpn_cls: 0.011  loss_rpn_loc: 0.051  time: 1.0372  data_time: 0.0111  lr: 0.003896  max_mem: 5406M
[32m[04/20 17:56:15 d2.utils.events]: [0m eta: 0:03:30  iter: 799  total_loss: 0.603  loss_cls: 0.200  loss_box_reg: 0.324  loss_rpn_cls: 0.014  loss_rpn_loc: 0.062  time: 1.0368  data_time: 0.0108  lr: 0.003996  max_mem: 5406M
[32m[04/20 17:56:35 d2.utils.events]: [0m eta: 0:03:09  iter: 819  total_loss: 0.564  loss_cls: 0.181  loss_box_reg: 0.323  loss_rpn_cls: 0.013  loss_rpn_loc: 0.061  time: 1.0358  data_time: 0.0114  lr: 0.004096  max_mem: 5406M
[32m[04/20 17:56:55 d2.utils.events]: [0m eta: 0:02:48  iter: 839  total_loss: 0.558  loss_cls: 0.181  loss_box_reg: 0.307  loss_rpn_cls: 0.015  loss_rpn_loc: 0.051  time: 1.0354  data_time: 0.0114  lr: 0.004196  max_mem: 5406M
[32m[04/20 17:57:16 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.570  loss_cls: 0.171  loss_box_reg: 0.320  loss_rpn_cls: 0.012  loss_rpn_loc: 0.057  time: 1.0353  data_time: 0.0109  lr: 0.004296  max_mem: 5406M
[32m[04/20 17:57:36 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.586  loss_cls: 0.182  loss_box_reg: 0.307  loss_rpn_cls: 0.014  loss_rpn_loc: 0.053  time: 1.0348  data_time: 0.0108  lr: 0.004396  max_mem: 5406M
[32m[04/20 17:57:57 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.617  loss_cls: 0.197  loss_box_reg: 0.356  loss_rpn_cls: 0.019  loss_rpn_loc: 0.057  time: 1.0349  data_time: 0.0107  lr: 0.004496  max_mem: 5406M
[32m[04/20 17:58:18 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.555  loss_cls: 0.172  loss_box_reg: 0.318  loss_rpn_cls: 0.016  loss_rpn_loc: 0.053  time: 1.0348  data_time: 0.0108  lr: 0.004595  max_mem: 5406M
[32m[04/20 17:58:38 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.498  loss_cls: 0.162  loss_box_reg: 0.297  loss_rpn_cls: 0.014  loss_rpn_loc: 0.043  time: 1.0345  data_time: 0.0121  lr: 0.004695  max_mem: 5406M
[32m[04/20 17:58:59 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.686  loss_cls: 0.216  loss_box_reg: 0.376  loss_rpn_cls: 0.013  loss_rpn_loc: 0.064  time: 1.0344  data_time: 0.0107  lr: 0.004795  max_mem: 5406M
[32m[04/20 17:59:19 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.611  loss_cls: 0.185  loss_box_reg: 0.344  loss_rpn_cls: 0.017  loss_rpn_loc: 0.061  time: 1.0339  data_time: 0.0107  lr: 0.004895  max_mem: 5406M
[5m[31mWARNING[0m [32m[04/20 17:59:43 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 17:59:43 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 17:59:43 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 17:59:43 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.587  loss_cls: 0.200  loss_box_reg: 0.314  loss_rpn_cls: 0.016  loss_rpn_loc: 0.057  time: 1.0338  data_time: 0.0111  lr: 0.004995  max_mem: 5406M
[32m[04/20 17:59:44 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:11 (1.0348 s / it)
[32m[04/20 17:59:44 d2.engine.hooks]: [0mTotal training time: 0:17:18 (0:00:06 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 17:59:46 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 17:59:46 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 17:59:47 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 17:59:48 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1182 s / img. ETA=0:16:43
[32m[04/20 17:59:53 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1175 s / img. ETA=0:16:33
[32m[04/20 17:59:58 d2.evaluation.evaluator]: [0mInference done 95/8355. 0.1172 s / img. ETA=0:16:26
[32m[04/20 18:00:03 d2.evaluation.evaluator]: [0mInference done 137/8355. 0.1172 s / img. ETA=0:16:21
[32m[04/20 18:00:08 d2.evaluation.evaluator]: [0mInference done 179/8355. 0.1171 s / img. ETA=0:16:16
[32m[04/20 18:00:13 d2.evaluation.evaluator]: [0mInference done 221/8355. 0.1172 s / img. ETA=0:16:12
[32m[04/20 18:00:18 d2.evaluation.evaluator]: [0mInference done 263/8355. 0.1172 s / img. ETA=0:16:06
[32m[04/20 18:00:23 d2.evaluation.evaluator]: [0mInference done 305/8355. 0.1173 s / img. ETA=0:16:02
[32m[04/20 18:00:28 d2.evaluation.evaluator]: [0mInference done 347/8355. 0.1173 s / img. ETA=0:15:57
[32m[04/20 18:00:33 d2.evaluation.evaluator]: [0mInference done 389/8355. 0.1174 s / img. ETA=0:15:53
[32m[04/20 18:00:38 d2.evaluation.evaluator]: [0mInference done 431/8355. 0.1173 s / img. ETA=0:15:48
[32m[04/20 18:00:43 d2.evaluation.evaluator]: [0mInference done 473/8355. 0.1173 s / img. ETA=0:15:42
[32m[04/20 18:00:48 d2.evaluation.evaluator]: [0mInference done 515/8355. 0.1173 s / img. ETA=0:15:37
[32m[04/20 18:00:53 d2.evaluation.evaluator]: [0mInference done 557/8355. 0.1173 s / img. ETA=0:15:32
[32m[04/20 18:00:58 d2.evaluation.evaluator]: [0mInference done 599/8355. 0.1173 s / img. ETA=0:15:28
[32m[04/20 18:01:03 d2.evaluation.evaluator]: [0mInference done 641/8355. 0.1173 s / img. ETA=0:15:22
[32m[04/20 18:01:09 d2.evaluation.evaluator]: [0mInference done 683/8355. 0.1173 s / img. ETA=0:15:18
[32m[04/20 18:01:14 d2.evaluation.evaluator]: [0mInference done 725/8355. 0.1173 s / img. ETA=0:15:13
[32m[04/20 18:01:19 d2.evaluation.evaluator]: [0mInference done 767/8355. 0.1173 s / img. ETA=0:15:08
[32m[04/20 18:01:24 d2.evaluation.evaluator]: [0mInference done 809/8355. 0.1173 s / img. ETA=0:15:03
[32m[04/20 18:01:29 d2.evaluation.evaluator]: [0mInference done 851/8355. 0.1173 s / img. ETA=0:14:58
[32m[04/20 18:01:34 d2.evaluation.evaluator]: [0mInference done 893/8355. 0.1173 s / img. ETA=0:14:54
[32m[04/20 18:01:39 d2.evaluation.evaluator]: [0mInference done 935/8355. 0.1174 s / img. ETA=0:14:49
[32m[04/20 18:01:44 d2.evaluation.evaluator]: [0mInference done 977/8355. 0.1174 s / img. ETA=0:14:44
[32m[04/20 18:01:49 d2.evaluation.evaluator]: [0mInference done 1019/8355. 0.1174 s / img. ETA=0:14:39
[32m[04/20 18:01:54 d2.evaluation.evaluator]: [0mInference done 1061/8355. 0.1174 s / img. ETA=0:14:34
[32m[04/20 18:01:59 d2.evaluation.evaluator]: [0mInference done 1103/8355. 0.1174 s / img. ETA=0:14:30
[32m[04/20 18:02:04 d2.evaluation.evaluator]: [0mInference done 1145/8355. 0.1174 s / img. ETA=0:14:25
[32m[04/20 18:02:09 d2.evaluation.evaluator]: [0mInference done 1187/8355. 0.1174 s / img. ETA=0:14:20
[32m[04/20 18:02:14 d2.evaluation.evaluator]: [0mInference done 1229/8355. 0.1174 s / img. ETA=0:14:15
[32m[04/20 18:02:19 d2.evaluation.evaluator]: [0mInference done 1271/8355. 0.1174 s / img. ETA=0:14:10
[32m[04/20 18:02:24 d2.evaluation.evaluator]: [0mInference done 1313/8355. 0.1174 s / img. ETA=0:14:05
[32m[04/20 18:02:29 d2.evaluation.evaluator]: [0mInference done 1355/8355. 0.1173 s / img. ETA=0:14:00
[32m[04/20 18:02:34 d2.evaluation.evaluator]: [0mInference done 1397/8355. 0.1173 s / img. ETA=0:13:55
[32m[04/20 18:02:39 d2.evaluation.evaluator]: [0mInference done 1439/8355. 0.1173 s / img. ETA=0:13:49
[32m[04/20 18:02:45 d2.evaluation.evaluator]: [0mInference done 1481/8355. 0.1173 s / img. ETA=0:13:44
[32m[04/20 18:02:50 d2.evaluation.evaluator]: [0mInference done 1523/8355. 0.1174 s / img. ETA=0:13:40
[32m[04/20 18:02:55 d2.evaluation.evaluator]: [0mInference done 1565/8355. 0.1174 s / img. ETA=0:13:35
[32m[04/20 18:03:00 d2.evaluation.evaluator]: [0mInference done 1607/8355. 0.1174 s / img. ETA=0:13:30
[32m[04/20 18:03:05 d2.evaluation.evaluator]: [0mInference done 1649/8355. 0.1174 s / img. ETA=0:13:25
[32m[04/20 18:03:10 d2.evaluation.evaluator]: [0mInference done 1691/8355. 0.1175 s / img. ETA=0:13:20
[32m[04/20 18:03:15 d2.evaluation.evaluator]: [0mInference done 1733/8355. 0.1175 s / img. ETA=0:13:15
[32m[04/20 18:03:20 d2.evaluation.evaluator]: [0mInference done 1775/8355. 0.1175 s / img. ETA=0:13:11
[32m[04/20 18:03:25 d2.evaluation.evaluator]: [0mInference done 1817/8355. 0.1176 s / img. ETA=0:13:06
[32m[04/20 18:03:30 d2.evaluation.evaluator]: [0mInference done 1859/8355. 0.1176 s / img. ETA=0:13:01
[32m[04/20 18:03:35 d2.evaluation.evaluator]: [0mInference done 1900/8355. 0.1176 s / img. ETA=0:12:56
[32m[04/20 18:03:41 d2.evaluation.evaluator]: [0mInference done 1942/8355. 0.1177 s / img. ETA=0:12:51
[32m[04/20 18:03:46 d2.evaluation.evaluator]: [0mInference done 1984/8355. 0.1177 s / img. ETA=0:12:46
[32m[04/20 18:03:51 d2.evaluation.evaluator]: [0mInference done 2026/8355. 0.1177 s / img. ETA=0:12:41
[32m[04/20 18:03:56 d2.evaluation.evaluator]: [0mInference done 2068/8355. 0.1177 s / img. ETA=0:12:36
[32m[04/20 18:04:01 d2.evaluation.evaluator]: [0mInference done 2110/8355. 0.1177 s / img. ETA=0:12:31
[32m[04/20 18:04:06 d2.evaluation.evaluator]: [0mInference done 2152/8355. 0.1177 s / img. ETA=0:12:27
[32m[04/20 18:04:11 d2.evaluation.evaluator]: [0mInference done 2193/8355. 0.1178 s / img. ETA=0:12:22
[32m[04/20 18:04:16 d2.evaluation.evaluator]: [0mInference done 2234/8355. 0.1178 s / img. ETA=0:12:17
[32m[04/20 18:04:21 d2.evaluation.evaluator]: [0mInference done 2275/8355. 0.1178 s / img. ETA=0:12:12
[32m[04/20 18:04:26 d2.evaluation.evaluator]: [0mInference done 2316/8355. 0.1179 s / img. ETA=0:12:08
[32m[04/20 18:04:31 d2.evaluation.evaluator]: [0mInference done 2358/8355. 0.1179 s / img. ETA=0:12:03
[32m[04/20 18:04:36 d2.evaluation.evaluator]: [0mInference done 2399/8355. 0.1179 s / img. ETA=0:11:58
[32m[04/20 18:04:41 d2.evaluation.evaluator]: [0mInference done 2440/8355. 0.1179 s / img. ETA=0:11:53
[32m[04/20 18:04:46 d2.evaluation.evaluator]: [0mInference done 2482/8355. 0.1180 s / img. ETA=0:11:48
[32m[04/20 18:04:51 d2.evaluation.evaluator]: [0mInference done 2524/8355. 0.1180 s / img. ETA=0:11:43
[32m[04/20 18:04:57 d2.evaluation.evaluator]: [0mInference done 2566/8355. 0.1180 s / img. ETA=0:11:38
[32m[04/20 18:05:02 d2.evaluation.evaluator]: [0mInference done 2608/8355. 0.1180 s / img. ETA=0:11:33
[32m[04/20 18:05:07 d2.evaluation.evaluator]: [0mInference done 2649/8355. 0.1180 s / img. ETA=0:11:28
[32m[04/20 18:05:12 d2.evaluation.evaluator]: [0mInference done 2691/8355. 0.1180 s / img. ETA=0:11:23
[32m[04/20 18:05:17 d2.evaluation.evaluator]: [0mInference done 2733/8355. 0.1180 s / img. ETA=0:11:18
[32m[04/20 18:05:22 d2.evaluation.evaluator]: [0mInference done 2775/8355. 0.1180 s / img. ETA=0:11:13
[32m[04/20 18:05:27 d2.evaluation.evaluator]: [0mInference done 2816/8355. 0.1180 s / img. ETA=0:11:09
[32m[04/20 18:05:32 d2.evaluation.evaluator]: [0mInference done 2857/8355. 0.1181 s / img. ETA=0:11:04
[32m[04/20 18:05:37 d2.evaluation.evaluator]: [0mInference done 2899/8355. 0.1181 s / img. ETA=0:10:59
[32m[04/20 18:05:42 d2.evaluation.evaluator]: [0mInference done 2941/8355. 0.1181 s / img. ETA=0:10:54
[32m[04/20 18:05:47 d2.evaluation.evaluator]: [0mInference done 2983/8355. 0.1181 s / img. ETA=0:10:49
[32m[04/20 18:05:52 d2.evaluation.evaluator]: [0mInference done 3025/8355. 0.1181 s / img. ETA=0:10:44
[32m[04/20 18:05:58 d2.evaluation.evaluator]: [0mInference done 3067/8355. 0.1181 s / img. ETA=0:10:39
[32m[04/20 18:06:03 d2.evaluation.evaluator]: [0mInference done 3108/8355. 0.1181 s / img. ETA=0:10:34
[32m[04/20 18:06:08 d2.evaluation.evaluator]: [0mInference done 3150/8355. 0.1181 s / img. ETA=0:10:29
[32m[04/20 18:06:13 d2.evaluation.evaluator]: [0mInference done 3192/8355. 0.1181 s / img. ETA=0:10:24
[32m[04/20 18:06:18 d2.evaluation.evaluator]: [0mInference done 3233/8355. 0.1182 s / img. ETA=0:10:19
[32m[04/20 18:06:23 d2.evaluation.evaluator]: [0mInference done 3274/8355. 0.1182 s / img. ETA=0:10:14
[32m[04/20 18:06:28 d2.evaluation.evaluator]: [0mInference done 3315/8355. 0.1182 s / img. ETA=0:10:09
[32m[04/20 18:06:33 d2.evaluation.evaluator]: [0mInference done 3356/8355. 0.1182 s / img. ETA=0:10:05
[32m[04/20 18:06:38 d2.evaluation.evaluator]: [0mInference done 3397/8355. 0.1182 s / img. ETA=0:10:00
[32m[04/20 18:06:43 d2.evaluation.evaluator]: [0mInference done 3438/8355. 0.1183 s / img. ETA=0:09:55
[32m[04/20 18:06:48 d2.evaluation.evaluator]: [0mInference done 3479/8355. 0.1183 s / img. ETA=0:09:50
[32m[04/20 18:06:53 d2.evaluation.evaluator]: [0mInference done 3520/8355. 0.1183 s / img. ETA=0:09:45
[32m[04/20 18:06:58 d2.evaluation.evaluator]: [0mInference done 3561/8355. 0.1183 s / img. ETA=0:09:40
[32m[04/20 18:07:03 d2.evaluation.evaluator]: [0mInference done 3602/8355. 0.1183 s / img. ETA=0:09:36
[32m[04/20 18:07:08 d2.evaluation.evaluator]: [0mInference done 3643/8355. 0.1183 s / img. ETA=0:09:31
[32m[04/20 18:07:13 d2.evaluation.evaluator]: [0mInference done 3684/8355. 0.1183 s / img. ETA=0:09:26
[32m[04/20 18:07:18 d2.evaluation.evaluator]: [0mInference done 3725/8355. 0.1184 s / img. ETA=0:09:21
[32m[04/20 18:07:23 d2.evaluation.evaluator]: [0mInference done 3767/8355. 0.1184 s / img. ETA=0:09:16
[32m[04/20 18:07:29 d2.evaluation.evaluator]: [0mInference done 3809/8355. 0.1184 s / img. ETA=0:09:11
[32m[04/20 18:07:34 d2.evaluation.evaluator]: [0mInference done 3851/8355. 0.1184 s / img. ETA=0:09:06
[32m[04/20 18:07:39 d2.evaluation.evaluator]: [0mInference done 3893/8355. 0.1184 s / img. ETA=0:09:00
[32m[04/20 18:07:44 d2.evaluation.evaluator]: [0mInference done 3935/8355. 0.1184 s / img. ETA=0:08:55
[32m[04/20 18:07:49 d2.evaluation.evaluator]: [0mInference done 3977/8355. 0.1184 s / img. ETA=0:08:50
[32m[04/20 18:07:54 d2.evaluation.evaluator]: [0mInference done 4019/8355. 0.1184 s / img. ETA=0:08:45
[32m[04/20 18:07:59 d2.evaluation.evaluator]: [0mInference done 4061/8355. 0.1184 s / img. ETA=0:08:40
[32m[04/20 18:08:04 d2.evaluation.evaluator]: [0mInference done 4103/8355. 0.1184 s / img. ETA=0:08:35
[32m[04/20 18:08:09 d2.evaluation.evaluator]: [0mInference done 4144/8355. 0.1184 s / img. ETA=0:08:30
[32m[04/20 18:08:14 d2.evaluation.evaluator]: [0mInference done 4186/8355. 0.1184 s / img. ETA=0:08:25
[32m[04/20 18:08:19 d2.evaluation.evaluator]: [0mInference done 4227/8355. 0.1184 s / img. ETA=0:08:20
[32m[04/20 18:08:24 d2.evaluation.evaluator]: [0mInference done 4269/8355. 0.1184 s / img. ETA=0:08:15
[32m[04/20 18:08:29 d2.evaluation.evaluator]: [0mInference done 4310/8355. 0.1184 s / img. ETA=0:08:10
[32m[04/20 18:08:34 d2.evaluation.evaluator]: [0mInference done 4352/8355. 0.1184 s / img. ETA=0:08:05
[32m[04/20 18:08:40 d2.evaluation.evaluator]: [0mInference done 4394/8355. 0.1184 s / img. ETA=0:08:00
[32m[04/20 18:08:45 d2.evaluation.evaluator]: [0mInference done 4436/8355. 0.1184 s / img. ETA=0:07:55
[32m[04/20 18:08:50 d2.evaluation.evaluator]: [0mInference done 4478/8355. 0.1184 s / img. ETA=0:07:50
[32m[04/20 18:08:55 d2.evaluation.evaluator]: [0mInference done 4519/8355. 0.1184 s / img. ETA=0:07:45
[32m[04/20 18:09:00 d2.evaluation.evaluator]: [0mInference done 4561/8355. 0.1184 s / img. ETA=0:07:40
[32m[04/20 18:09:05 d2.evaluation.evaluator]: [0mInference done 4603/8355. 0.1184 s / img. ETA=0:07:34
[32m[04/20 18:09:10 d2.evaluation.evaluator]: [0mInference done 4645/8355. 0.1184 s / img. ETA=0:07:29
[32m[04/20 18:09:15 d2.evaluation.evaluator]: [0mInference done 4686/8355. 0.1184 s / img. ETA=0:07:24
[32m[04/20 18:09:20 d2.evaluation.evaluator]: [0mInference done 4728/8355. 0.1184 s / img. ETA=0:07:19
[32m[04/20 18:09:25 d2.evaluation.evaluator]: [0mInference done 4770/8355. 0.1184 s / img. ETA=0:07:14
[32m[04/20 18:09:30 d2.evaluation.evaluator]: [0mInference done 4812/8355. 0.1184 s / img. ETA=0:07:09
[32m[04/20 18:09:35 d2.evaluation.evaluator]: [0mInference done 4854/8355. 0.1184 s / img. ETA=0:07:04
[32m[04/20 18:09:41 d2.evaluation.evaluator]: [0mInference done 4896/8355. 0.1184 s / img. ETA=0:06:59
[32m[04/20 18:09:46 d2.evaluation.evaluator]: [0mInference done 4938/8355. 0.1184 s / img. ETA=0:06:54
[32m[04/20 18:09:51 d2.evaluation.evaluator]: [0mInference done 4980/8355. 0.1184 s / img. ETA=0:06:49
[32m[04/20 18:09:56 d2.evaluation.evaluator]: [0mInference done 5022/8355. 0.1184 s / img. ETA=0:06:44
[32m[04/20 18:10:01 d2.evaluation.evaluator]: [0mInference done 5064/8355. 0.1184 s / img. ETA=0:06:39
[32m[04/20 18:10:06 d2.evaluation.evaluator]: [0mInference done 5106/8355. 0.1184 s / img. ETA=0:06:34
[32m[04/20 18:10:11 d2.evaluation.evaluator]: [0mInference done 5147/8355. 0.1184 s / img. ETA=0:06:29
[32m[04/20 18:10:16 d2.evaluation.evaluator]: [0mInference done 5188/8355. 0.1184 s / img. ETA=0:06:24
[32m[04/20 18:10:21 d2.evaluation.evaluator]: [0mInference done 5230/8355. 0.1184 s / img. ETA=0:06:19
[32m[04/20 18:10:26 d2.evaluation.evaluator]: [0mInference done 5271/8355. 0.1184 s / img. ETA=0:06:14
[32m[04/20 18:10:31 d2.evaluation.evaluator]: [0mInference done 5312/8355. 0.1184 s / img. ETA=0:06:09
[32m[04/20 18:10:36 d2.evaluation.evaluator]: [0mInference done 5353/8355. 0.1185 s / img. ETA=0:06:04
[32m[04/20 18:10:41 d2.evaluation.evaluator]: [0mInference done 5395/8355. 0.1185 s / img. ETA=0:05:59
[32m[04/20 18:10:46 d2.evaluation.evaluator]: [0mInference done 5437/8355. 0.1185 s / img. ETA=0:05:54
[32m[04/20 18:10:52 d2.evaluation.evaluator]: [0mInference done 5479/8355. 0.1185 s / img. ETA=0:05:48
[32m[04/20 18:10:57 d2.evaluation.evaluator]: [0mInference done 5520/8355. 0.1185 s / img. ETA=0:05:43
[32m[04/20 18:11:02 d2.evaluation.evaluator]: [0mInference done 5561/8355. 0.1185 s / img. ETA=0:05:39
[32m[04/20 18:11:07 d2.evaluation.evaluator]: [0mInference done 5603/8355. 0.1185 s / img. ETA=0:05:33
[32m[04/20 18:11:12 d2.evaluation.evaluator]: [0mInference done 5645/8355. 0.1185 s / img. ETA=0:05:28
[32m[04/20 18:11:17 d2.evaluation.evaluator]: [0mInference done 5686/8355. 0.1185 s / img. ETA=0:05:23
[32m[04/20 18:11:22 d2.evaluation.evaluator]: [0mInference done 5728/8355. 0.1185 s / img. ETA=0:05:18
[32m[04/20 18:11:27 d2.evaluation.evaluator]: [0mInference done 5769/8355. 0.1185 s / img. ETA=0:05:13
[32m[04/20 18:11:32 d2.evaluation.evaluator]: [0mInference done 5810/8355. 0.1185 s / img. ETA=0:05:08
[32m[04/20 18:11:37 d2.evaluation.evaluator]: [0mInference done 5851/8355. 0.1185 s / img. ETA=0:05:03
[32m[04/20 18:11:42 d2.evaluation.evaluator]: [0mInference done 5892/8355. 0.1185 s / img. ETA=0:04:58
[32m[04/20 18:11:47 d2.evaluation.evaluator]: [0mInference done 5933/8355. 0.1185 s / img. ETA=0:04:54
[32m[04/20 18:11:52 d2.evaluation.evaluator]: [0mInference done 5975/8355. 0.1185 s / img. ETA=0:04:48
[32m[04/20 18:11:57 d2.evaluation.evaluator]: [0mInference done 6016/8355. 0.1185 s / img. ETA=0:04:43
[32m[04/20 18:12:02 d2.evaluation.evaluator]: [0mInference done 6058/8355. 0.1185 s / img. ETA=0:04:38
[32m[04/20 18:12:07 d2.evaluation.evaluator]: [0mInference done 6099/8355. 0.1185 s / img. ETA=0:04:33
[32m[04/20 18:12:12 d2.evaluation.evaluator]: [0mInference done 6141/8355. 0.1185 s / img. ETA=0:04:28
[32m[04/20 18:12:17 d2.evaluation.evaluator]: [0mInference done 6182/8355. 0.1185 s / img. ETA=0:04:23
[32m[04/20 18:12:22 d2.evaluation.evaluator]: [0mInference done 6224/8355. 0.1185 s / img. ETA=0:04:18
[32m[04/20 18:12:27 d2.evaluation.evaluator]: [0mInference done 6266/8355. 0.1185 s / img. ETA=0:04:13
[32m[04/20 18:12:33 d2.evaluation.evaluator]: [0mInference done 6308/8355. 0.1185 s / img. ETA=0:04:08
[32m[04/20 18:12:38 d2.evaluation.evaluator]: [0mInference done 6350/8355. 0.1185 s / img. ETA=0:04:03
[32m[04/20 18:12:43 d2.evaluation.evaluator]: [0mInference done 6392/8355. 0.1185 s / img. ETA=0:03:58
[32m[04/20 18:12:48 d2.evaluation.evaluator]: [0mInference done 6434/8355. 0.1185 s / img. ETA=0:03:53
[32m[04/20 18:12:53 d2.evaluation.evaluator]: [0mInference done 6475/8355. 0.1185 s / img. ETA=0:03:48
[32m[04/20 18:12:58 d2.evaluation.evaluator]: [0mInference done 6517/8355. 0.1185 s / img. ETA=0:03:43
[32m[04/20 18:13:03 d2.evaluation.evaluator]: [0mInference done 6559/8355. 0.1185 s / img. ETA=0:03:38
[32m[04/20 18:13:08 d2.evaluation.evaluator]: [0mInference done 6601/8355. 0.1185 s / img. ETA=0:03:32
[32m[04/20 18:13:13 d2.evaluation.evaluator]: [0mInference done 6643/8355. 0.1185 s / img. ETA=0:03:27
[32m[04/20 18:13:18 d2.evaluation.evaluator]: [0mInference done 6685/8355. 0.1185 s / img. ETA=0:03:22
[32m[04/20 18:13:23 d2.evaluation.evaluator]: [0mInference done 6727/8355. 0.1185 s / img. ETA=0:03:17
[32m[04/20 18:13:28 d2.evaluation.evaluator]: [0mInference done 6769/8355. 0.1185 s / img. ETA=0:03:12
[32m[04/20 18:13:33 d2.evaluation.evaluator]: [0mInference done 6811/8355. 0.1185 s / img. ETA=0:03:07
[32m[04/20 18:13:39 d2.evaluation.evaluator]: [0mInference done 6853/8355. 0.1185 s / img. ETA=0:03:02
[32m[04/20 18:13:44 d2.evaluation.evaluator]: [0mInference done 6895/8355. 0.1185 s / img. ETA=0:02:57
[32m[04/20 18:13:49 d2.evaluation.evaluator]: [0mInference done 6937/8355. 0.1185 s / img. ETA=0:02:52
[32m[04/20 18:13:54 d2.evaluation.evaluator]: [0mInference done 6978/8355. 0.1185 s / img. ETA=0:02:47
[32m[04/20 18:13:59 d2.evaluation.evaluator]: [0mInference done 7020/8355. 0.1185 s / img. ETA=0:02:42
[32m[04/20 18:14:04 d2.evaluation.evaluator]: [0mInference done 7061/8355. 0.1185 s / img. ETA=0:02:37
[32m[04/20 18:14:09 d2.evaluation.evaluator]: [0mInference done 7102/8355. 0.1185 s / img. ETA=0:02:32
[32m[04/20 18:14:14 d2.evaluation.evaluator]: [0mInference done 7143/8355. 0.1186 s / img. ETA=0:02:27
[32m[04/20 18:14:19 d2.evaluation.evaluator]: [0mInference done 7184/8355. 0.1186 s / img. ETA=0:02:22
[32m[04/20 18:14:24 d2.evaluation.evaluator]: [0mInference done 7225/8355. 0.1186 s / img. ETA=0:02:17
[32m[04/20 18:14:29 d2.evaluation.evaluator]: [0mInference done 7266/8355. 0.1186 s / img. ETA=0:02:12
[32m[04/20 18:14:34 d2.evaluation.evaluator]: [0mInference done 7307/8355. 0.1186 s / img. ETA=0:02:07
[32m[04/20 18:14:39 d2.evaluation.evaluator]: [0mInference done 7348/8355. 0.1186 s / img. ETA=0:02:02
[32m[04/20 18:14:44 d2.evaluation.evaluator]: [0mInference done 7389/8355. 0.1186 s / img. ETA=0:01:57
[32m[04/20 18:14:49 d2.evaluation.evaluator]: [0mInference done 7430/8355. 0.1186 s / img. ETA=0:01:52
[32m[04/20 18:14:54 d2.evaluation.evaluator]: [0mInference done 7471/8355. 0.1186 s / img. ETA=0:01:47
[32m[04/20 18:14:59 d2.evaluation.evaluator]: [0mInference done 7512/8355. 0.1186 s / img. ETA=0:01:42
[32m[04/20 18:15:05 d2.evaluation.evaluator]: [0mInference done 7553/8355. 0.1186 s / img. ETA=0:01:37
[32m[04/20 18:15:10 d2.evaluation.evaluator]: [0mInference done 7594/8355. 0.1187 s / img. ETA=0:01:32
[32m[04/20 18:15:15 d2.evaluation.evaluator]: [0mInference done 7635/8355. 0.1187 s / img. ETA=0:01:27
[32m[04/20 18:15:20 d2.evaluation.evaluator]: [0mInference done 7676/8355. 0.1187 s / img. ETA=0:01:22
[32m[04/20 18:15:25 d2.evaluation.evaluator]: [0mInference done 7717/8355. 0.1187 s / img. ETA=0:01:17
[32m[04/20 18:15:30 d2.evaluation.evaluator]: [0mInference done 7758/8355. 0.1187 s / img. ETA=0:01:12
[32m[04/20 18:15:35 d2.evaluation.evaluator]: [0mInference done 7799/8355. 0.1187 s / img. ETA=0:01:07
[32m[04/20 18:15:40 d2.evaluation.evaluator]: [0mInference done 7840/8355. 0.1187 s / img. ETA=0:01:02
[32m[04/20 18:15:45 d2.evaluation.evaluator]: [0mInference done 7881/8355. 0.1187 s / img. ETA=0:00:57
[32m[04/20 18:15:50 d2.evaluation.evaluator]: [0mInference done 7922/8355. 0.1187 s / img. ETA=0:00:52
[32m[04/20 18:15:55 d2.evaluation.evaluator]: [0mInference done 7963/8355. 0.1187 s / img. ETA=0:00:47
[32m[04/20 18:16:00 d2.evaluation.evaluator]: [0mInference done 8004/8355. 0.1187 s / img. ETA=0:00:42
[32m[04/20 18:16:05 d2.evaluation.evaluator]: [0mInference done 8045/8355. 0.1187 s / img. ETA=0:00:37
[32m[04/20 18:16:10 d2.evaluation.evaluator]: [0mInference done 8086/8355. 0.1187 s / img. ETA=0:00:32
[32m[04/20 18:16:15 d2.evaluation.evaluator]: [0mInference done 8128/8355. 0.1187 s / img. ETA=0:00:27
[32m[04/20 18:16:20 d2.evaluation.evaluator]: [0mInference done 8170/8355. 0.1187 s / img. ETA=0:00:22
[32m[04/20 18:16:25 d2.evaluation.evaluator]: [0mInference done 8212/8355. 0.1187 s / img. ETA=0:00:17
[32m[04/20 18:16:31 d2.evaluation.evaluator]: [0mInference done 8254/8355. 0.1187 s / img. ETA=0:00:12
[32m[04/20 18:16:36 d2.evaluation.evaluator]: [0mInference done 8296/8355. 0.1187 s / img. ETA=0:00:07
[32m[04/20 18:16:41 d2.evaluation.evaluator]: [0mInference done 8337/8355. 0.1187 s / img. ETA=0:00:02
[32m[04/20 18:16:43 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:55.478919 (0.121614 s / img per device, on 1 devices)
[32m[04/20 18:16:43 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:31 (0.118733 s / img per device, on 1 devices)
[32m[04/20 18:16:43 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 18:16:43 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 18:16:44 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.09s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=31.88s).
Accumulating evaluation results...
DONE (t=3.34s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.414
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.759
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.399
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.304
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.547
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.689
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.463
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.378
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.730
[32m[04/20 18:17:19 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.379 | 75.917 | 39.870 | 30.389 | 54.705 | 68.854 |
[32m[04/20 18:17:19 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 40.927 | bicycle       | 31.253 | car            | 51.957 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 18:17:23 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 18:17:23 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 18:17:23 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 18:17:25 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1192 s / img. ETA=0:02:31
[32m[04/20 18:17:30 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1183 s / img. ETA=0:02:25
[32m[04/20 18:17:36 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1185 s / img. ETA=0:02:21
[32m[04/20 18:17:41 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1185 s / img. ETA=0:02:15
[32m[04/20 18:17:46 d2.evaluation.evaluator]: [0mInference done 179/1257. 0.1185 s / img. ETA=0:02:10
[32m[04/20 18:17:51 d2.evaluation.evaluator]: [0mInference done 220/1257. 0.1188 s / img. ETA=0:02:06
[32m[04/20 18:17:56 d2.evaluation.evaluator]: [0mInference done 261/1257. 0.1189 s / img. ETA=0:02:01
[32m[04/20 18:18:01 d2.evaluation.evaluator]: [0mInference done 303/1257. 0.1188 s / img. ETA=0:01:56
[32m[04/20 18:18:06 d2.evaluation.evaluator]: [0mInference done 344/1257. 0.1189 s / img. ETA=0:01:51
[32m[04/20 18:18:11 d2.evaluation.evaluator]: [0mInference done 385/1257. 0.1189 s / img. ETA=0:01:46
[32m[04/20 18:18:16 d2.evaluation.evaluator]: [0mInference done 427/1257. 0.1188 s / img. ETA=0:01:41
[32m[04/20 18:18:21 d2.evaluation.evaluator]: [0mInference done 468/1257. 0.1188 s / img. ETA=0:01:36
[32m[04/20 18:18:26 d2.evaluation.evaluator]: [0mInference done 509/1257. 0.1188 s / img. ETA=0:01:31
[32m[04/20 18:18:31 d2.evaluation.evaluator]: [0mInference done 550/1257. 0.1189 s / img. ETA=0:01:26
[32m[04/20 18:18:36 d2.evaluation.evaluator]: [0mInference done 591/1257. 0.1189 s / img. ETA=0:01:21
[32m[04/20 18:18:41 d2.evaluation.evaluator]: [0mInference done 632/1257. 0.1189 s / img. ETA=0:01:16
[32m[04/20 18:18:46 d2.evaluation.evaluator]: [0mInference done 674/1257. 0.1189 s / img. ETA=0:01:11
[32m[04/20 18:18:51 d2.evaluation.evaluator]: [0mInference done 715/1257. 0.1190 s / img. ETA=0:01:06
[32m[04/20 18:18:56 d2.evaluation.evaluator]: [0mInference done 757/1257. 0.1190 s / img. ETA=0:01:01
[32m[04/20 18:19:02 d2.evaluation.evaluator]: [0mInference done 799/1257. 0.1190 s / img. ETA=0:00:55
[32m[04/20 18:19:07 d2.evaluation.evaluator]: [0mInference done 840/1257. 0.1190 s / img. ETA=0:00:50
[32m[04/20 18:19:12 d2.evaluation.evaluator]: [0mInference done 881/1257. 0.1190 s / img. ETA=0:00:45
[32m[04/20 18:19:17 d2.evaluation.evaluator]: [0mInference done 922/1257. 0.1191 s / img. ETA=0:00:40
[32m[04/20 18:19:22 d2.evaluation.evaluator]: [0mInference done 964/1257. 0.1190 s / img. ETA=0:00:35
[32m[04/20 18:19:27 d2.evaluation.evaluator]: [0mInference done 1005/1257. 0.1190 s / img. ETA=0:00:30
[32m[04/20 18:19:32 d2.evaluation.evaluator]: [0mInference done 1046/1257. 0.1191 s / img. ETA=0:00:25
[32m[04/20 18:19:37 d2.evaluation.evaluator]: [0mInference done 1087/1257. 0.1191 s / img. ETA=0:00:20
[32m[04/20 18:19:42 d2.evaluation.evaluator]: [0mInference done 1128/1257. 0.1192 s / img. ETA=0:00:15
[32m[04/20 18:19:47 d2.evaluation.evaluator]: [0mInference done 1169/1257. 0.1192 s / img. ETA=0:00:10
[32m[04/20 18:19:52 d2.evaluation.evaluator]: [0mInference done 1210/1257. 0.1192 s / img. ETA=0:00:05
[32m[04/20 18:19:57 d2.evaluation.evaluator]: [0mInference done 1252/1257. 0.1192 s / img. ETA=0:00:00
[32m[04/20 18:19:58 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:33.166967 (0.122338 s / img per device, on 1 devices)
[32m[04/20 18:19:58 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:29 (0.119192 s / img per device, on 1 devices)
[32m[04/20 18:19:58 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 18:19:58 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 18:19:58 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=4.92s).
Accumulating evaluation results...
DONE (t=0.64s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.601
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.279
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.198
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.379
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.471
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.153
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.377
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.382
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.277
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.454
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.508
[32m[04/20 18:20:04 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 30.949 | 60.116 | 27.929 | 19.768 | 37.868 | 47.121 |
[32m[04/20 18:20:04 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 32.270 | bicycle       | 13.728 | car            | 46.848 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  21  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 18:20:05 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 18:20:05 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 18:20:05 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 18:20:06 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 18:20:06 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 18:20:06 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 18:20:08 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 18:20:30 d2.utils.events]: [0m eta: 0:17:00  iter: 19  total_loss: 0.617  loss_cls: 0.204  loss_box_reg: 0.341  loss_rpn_cls: 0.015  loss_rpn_loc: 0.043  time: 1.0375  data_time: 0.0658  lr: 0.000100  max_mem: 5406M
[32m[04/20 18:20:51 d2.utils.events]: [0m eta: 0:16:29  iter: 39  total_loss: 0.559  loss_cls: 0.183  loss_box_reg: 0.307  loss_rpn_cls: 0.013  loss_rpn_loc: 0.048  time: 1.0313  data_time: 0.0098  lr: 0.000200  max_mem: 5406M
[32m[04/20 18:21:12 d2.utils.events]: [0m eta: 0:16:11  iter: 59  total_loss: 0.595  loss_cls: 0.198  loss_box_reg: 0.339  loss_rpn_cls: 0.017  loss_rpn_loc: 0.048  time: 1.0306  data_time: 0.0109  lr: 0.000300  max_mem: 5406M
[32m[04/20 18:21:32 d2.utils.events]: [0m eta: 0:15:51  iter: 79  total_loss: 0.588  loss_cls: 0.180  loss_box_reg: 0.338  loss_rpn_cls: 0.012  loss_rpn_loc: 0.054  time: 1.0306  data_time: 0.0106  lr: 0.000400  max_mem: 5406M
[32m[04/20 18:21:53 d2.utils.events]: [0m eta: 0:15:34  iter: 99  total_loss: 0.601  loss_cls: 0.200  loss_box_reg: 0.330  loss_rpn_cls: 0.016  loss_rpn_loc: 0.050  time: 1.0314  data_time: 0.0106  lr: 0.000500  max_mem: 5406M
[32m[04/20 18:22:14 d2.utils.events]: [0m eta: 0:15:10  iter: 119  total_loss: 0.603  loss_cls: 0.189  loss_box_reg: 0.358  loss_rpn_cls: 0.013  loss_rpn_loc: 0.050  time: 1.0299  data_time: 0.0106  lr: 0.000599  max_mem: 5406M
[32m[04/20 18:22:34 d2.utils.events]: [0m eta: 0:14:50  iter: 139  total_loss: 0.590  loss_cls: 0.189  loss_box_reg: 0.330  loss_rpn_cls: 0.013  loss_rpn_loc: 0.045  time: 1.0312  data_time: 0.0106  lr: 0.000699  max_mem: 5406M
[32m[04/20 18:22:55 d2.utils.events]: [0m eta: 0:14:31  iter: 159  total_loss: 0.606  loss_cls: 0.193  loss_box_reg: 0.335  loss_rpn_cls: 0.015  loss_rpn_loc: 0.063  time: 1.0327  data_time: 0.0107  lr: 0.000799  max_mem: 5406M
[32m[04/20 18:23:16 d2.utils.events]: [0m eta: 0:14:12  iter: 179  total_loss: 0.563  loss_cls: 0.182  loss_box_reg: 0.303  loss_rpn_cls: 0.018  loss_rpn_loc: 0.055  time: 1.0334  data_time: 0.0109  lr: 0.000899  max_mem: 5406M
[32m[04/20 18:23:36 d2.utils.events]: [0m eta: 0:13:48  iter: 199  total_loss: 0.512  loss_cls: 0.163  loss_box_reg: 0.279  loss_rpn_cls: 0.015  loss_rpn_loc: 0.053  time: 1.0314  data_time: 0.0103  lr: 0.000999  max_mem: 5406M
[32m[04/20 18:23:57 d2.utils.events]: [0m eta: 0:13:25  iter: 219  total_loss: 0.449  loss_cls: 0.153  loss_box_reg: 0.260  loss_rpn_cls: 0.009  loss_rpn_loc: 0.040  time: 1.0302  data_time: 0.0106  lr: 0.001099  max_mem: 5406M
[32m[04/20 18:24:18 d2.utils.events]: [0m eta: 0:13:07  iter: 239  total_loss: 0.595  loss_cls: 0.190  loss_box_reg: 0.342  loss_rpn_cls: 0.015  loss_rpn_loc: 0.052  time: 1.0320  data_time: 0.0103  lr: 0.001199  max_mem: 5406M
[32m[04/20 18:24:39 d2.utils.events]: [0m eta: 0:12:46  iter: 259  total_loss: 0.561  loss_cls: 0.188  loss_box_reg: 0.327  loss_rpn_cls: 0.011  loss_rpn_loc: 0.049  time: 1.0325  data_time: 0.0099  lr: 0.001299  max_mem: 5406M
[32m[04/20 18:24:59 d2.utils.events]: [0m eta: 0:12:26  iter: 279  total_loss: 0.542  loss_cls: 0.164  loss_box_reg: 0.318  loss_rpn_cls: 0.009  loss_rpn_loc: 0.038  time: 1.0325  data_time: 0.0104  lr: 0.001399  max_mem: 5406M
[32m[04/20 18:25:21 d2.utils.events]: [0m eta: 0:12:05  iter: 299  total_loss: 0.552  loss_cls: 0.213  loss_box_reg: 0.306  loss_rpn_cls: 0.011  loss_rpn_loc: 0.050  time: 1.0337  data_time: 0.0099  lr: 0.001499  max_mem: 5406M
[32m[04/20 18:25:42 d2.utils.events]: [0m eta: 0:11:46  iter: 319  total_loss: 0.557  loss_cls: 0.172  loss_box_reg: 0.303  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0354  data_time: 0.0103  lr: 0.001598  max_mem: 5406M
[32m[04/20 18:26:03 d2.utils.events]: [0m eta: 0:11:25  iter: 339  total_loss: 0.568  loss_cls: 0.183  loss_box_reg: 0.320  loss_rpn_cls: 0.011  loss_rpn_loc: 0.045  time: 1.0355  data_time: 0.0098  lr: 0.001698  max_mem: 5406M
[32m[04/20 18:26:23 d2.utils.events]: [0m eta: 0:11:04  iter: 359  total_loss: 0.595  loss_cls: 0.180  loss_box_reg: 0.328  loss_rpn_cls: 0.009  loss_rpn_loc: 0.051  time: 1.0355  data_time: 0.0102  lr: 0.001798  max_mem: 5406M
[32m[04/20 18:26:44 d2.utils.events]: [0m eta: 0:10:42  iter: 379  total_loss: 0.595  loss_cls: 0.174  loss_box_reg: 0.324  loss_rpn_cls: 0.012  loss_rpn_loc: 0.064  time: 1.0346  data_time: 0.0103  lr: 0.001898  max_mem: 5406M
[32m[04/20 18:27:04 d2.utils.events]: [0m eta: 0:10:22  iter: 399  total_loss: 0.569  loss_cls: 0.175  loss_box_reg: 0.339  loss_rpn_cls: 0.011  loss_rpn_loc: 0.046  time: 1.0346  data_time: 0.0101  lr: 0.001998  max_mem: 5406M
[32m[04/20 18:27:26 d2.utils.events]: [0m eta: 0:10:01  iter: 419  total_loss: 0.551  loss_cls: 0.184  loss_box_reg: 0.321  loss_rpn_cls: 0.009  loss_rpn_loc: 0.057  time: 1.0354  data_time: 0.0109  lr: 0.002098  max_mem: 5406M
[32m[04/20 18:27:47 d2.utils.events]: [0m eta: 0:09:41  iter: 439  total_loss: 0.541  loss_cls: 0.153  loss_box_reg: 0.317  loss_rpn_cls: 0.010  loss_rpn_loc: 0.049  time: 1.0360  data_time: 0.0112  lr: 0.002198  max_mem: 5406M
[32m[04/20 18:28:07 d2.utils.events]: [0m eta: 0:09:20  iter: 459  total_loss: 0.603  loss_cls: 0.170  loss_box_reg: 0.342  loss_rpn_cls: 0.011  loss_rpn_loc: 0.051  time: 1.0356  data_time: 0.0100  lr: 0.002298  max_mem: 5406M
[32m[04/20 18:28:28 d2.utils.events]: [0m eta: 0:09:01  iter: 479  total_loss: 0.579  loss_cls: 0.198  loss_box_reg: 0.320  loss_rpn_cls: 0.013  loss_rpn_loc: 0.046  time: 1.0361  data_time: 0.0101  lr: 0.002398  max_mem: 5406M
[32m[04/20 18:28:49 d2.utils.events]: [0m eta: 0:08:39  iter: 499  total_loss: 0.560  loss_cls: 0.177  loss_box_reg: 0.314  loss_rpn_cls: 0.012  loss_rpn_loc: 0.055  time: 1.0358  data_time: 0.0112  lr: 0.002498  max_mem: 5406M
[32m[04/20 18:29:10 d2.utils.events]: [0m eta: 0:08:19  iter: 519  total_loss: 0.562  loss_cls: 0.180  loss_box_reg: 0.296  loss_rpn_cls: 0.010  loss_rpn_loc: 0.048  time: 1.0363  data_time: 0.0098  lr: 0.002597  max_mem: 5406M
[32m[04/20 18:29:31 d2.utils.events]: [0m eta: 0:08:01  iter: 539  total_loss: 0.606  loss_cls: 0.200  loss_box_reg: 0.336  loss_rpn_cls: 0.012  loss_rpn_loc: 0.056  time: 1.0372  data_time: 0.0103  lr: 0.002697  max_mem: 5406M
[32m[04/20 18:29:52 d2.utils.events]: [0m eta: 0:07:39  iter: 559  total_loss: 0.573  loss_cls: 0.172  loss_box_reg: 0.327  loss_rpn_cls: 0.015  loss_rpn_loc: 0.058  time: 1.0366  data_time: 0.0109  lr: 0.002797  max_mem: 5406M
[32m[04/20 18:30:12 d2.utils.events]: [0m eta: 0:07:19  iter: 579  total_loss: 0.531  loss_cls: 0.169  loss_box_reg: 0.316  loss_rpn_cls: 0.009  loss_rpn_loc: 0.040  time: 1.0367  data_time: 0.0099  lr: 0.002897  max_mem: 5406M
[32m[04/20 18:30:33 d2.utils.events]: [0m eta: 0:06:59  iter: 599  total_loss: 0.594  loss_cls: 0.191  loss_box_reg: 0.334  loss_rpn_cls: 0.010  loss_rpn_loc: 0.054  time: 1.0371  data_time: 0.0106  lr: 0.002997  max_mem: 5406M
[32m[04/20 18:30:54 d2.utils.events]: [0m eta: 0:06:37  iter: 619  total_loss: 0.601  loss_cls: 0.177  loss_box_reg: 0.347  loss_rpn_cls: 0.015  loss_rpn_loc: 0.062  time: 1.0371  data_time: 0.0105  lr: 0.003097  max_mem: 5406M
[32m[04/20 18:31:15 d2.utils.events]: [0m eta: 0:06:17  iter: 639  total_loss: 0.644  loss_cls: 0.203  loss_box_reg: 0.353  loss_rpn_cls: 0.011  loss_rpn_loc: 0.055  time: 1.0370  data_time: 0.0100  lr: 0.003197  max_mem: 5406M
[32m[04/20 18:31:36 d2.utils.events]: [0m eta: 0:05:56  iter: 659  total_loss: 0.651  loss_cls: 0.210  loss_box_reg: 0.371  loss_rpn_cls: 0.013  loss_rpn_loc: 0.060  time: 1.0368  data_time: 0.0109  lr: 0.003297  max_mem: 5406M
[32m[04/20 18:31:57 d2.utils.events]: [0m eta: 0:05:35  iter: 679  total_loss: 0.519  loss_cls: 0.169  loss_box_reg: 0.273  loss_rpn_cls: 0.011  loss_rpn_loc: 0.053  time: 1.0375  data_time: 0.0105  lr: 0.003397  max_mem: 5406M
[32m[04/20 18:32:18 d2.utils.events]: [0m eta: 0:05:15  iter: 699  total_loss: 0.540  loss_cls: 0.171  loss_box_reg: 0.313  loss_rpn_cls: 0.010  loss_rpn_loc: 0.035  time: 1.0379  data_time: 0.0102  lr: 0.003497  max_mem: 5406M
[32m[04/20 18:32:39 d2.utils.events]: [0m eta: 0:04:54  iter: 719  total_loss: 0.617  loss_cls: 0.207  loss_box_reg: 0.342  loss_rpn_cls: 0.013  loss_rpn_loc: 0.045  time: 1.0377  data_time: 0.0107  lr: 0.003596  max_mem: 5406M
[32m[04/20 18:32:59 d2.utils.events]: [0m eta: 0:04:32  iter: 739  total_loss: 0.556  loss_cls: 0.174  loss_box_reg: 0.324  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 1.0373  data_time: 0.0099  lr: 0.003696  max_mem: 5406M
[32m[04/20 18:33:20 d2.utils.events]: [0m eta: 0:04:11  iter: 759  total_loss: 0.547  loss_cls: 0.179  loss_box_reg: 0.314  loss_rpn_cls: 0.013  loss_rpn_loc: 0.054  time: 1.0373  data_time: 0.0102  lr: 0.003796  max_mem: 5406M
[32m[04/20 18:33:41 d2.utils.events]: [0m eta: 0:03:51  iter: 779  total_loss: 0.567  loss_cls: 0.178  loss_box_reg: 0.306  loss_rpn_cls: 0.011  loss_rpn_loc: 0.053  time: 1.0372  data_time: 0.0105  lr: 0.003896  max_mem: 5406M
[32m[04/20 18:34:01 d2.utils.events]: [0m eta: 0:03:29  iter: 799  total_loss: 0.664  loss_cls: 0.203  loss_box_reg: 0.372  loss_rpn_cls: 0.014  loss_rpn_loc: 0.063  time: 1.0367  data_time: 0.0100  lr: 0.003996  max_mem: 5406M
[32m[04/20 18:34:22 d2.utils.events]: [0m eta: 0:03:08  iter: 819  total_loss: 0.569  loss_cls: 0.172  loss_box_reg: 0.314  loss_rpn_cls: 0.011  loss_rpn_loc: 0.051  time: 1.0369  data_time: 0.0106  lr: 0.004096  max_mem: 5406M
[32m[04/20 18:34:43 d2.utils.events]: [0m eta: 0:02:48  iter: 839  total_loss: 0.623  loss_cls: 0.197  loss_box_reg: 0.337  loss_rpn_cls: 0.018  loss_rpn_loc: 0.059  time: 1.0372  data_time: 0.0097  lr: 0.004196  max_mem: 5406M
[32m[04/20 18:35:04 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.578  loss_cls: 0.177  loss_box_reg: 0.325  loss_rpn_cls: 0.015  loss_rpn_loc: 0.058  time: 1.0369  data_time: 0.0100  lr: 0.004296  max_mem: 5406M
[32m[04/20 18:35:24 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.637  loss_cls: 0.210  loss_box_reg: 0.368  loss_rpn_cls: 0.013  loss_rpn_loc: 0.056  time: 1.0370  data_time: 0.0105  lr: 0.004396  max_mem: 5406M
[32m[04/20 18:35:46 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.527  loss_cls: 0.175  loss_box_reg: 0.284  loss_rpn_cls: 0.013  loss_rpn_loc: 0.045  time: 1.0380  data_time: 0.0110  lr: 0.004496  max_mem: 5406M
[32m[04/20 18:36:06 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.512  loss_cls: 0.181  loss_box_reg: 0.289  loss_rpn_cls: 0.012  loss_rpn_loc: 0.048  time: 1.0371  data_time: 0.0097  lr: 0.004595  max_mem: 5406M
[32m[04/20 18:36:27 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.592  loss_cls: 0.199  loss_box_reg: 0.340  loss_rpn_cls: 0.015  loss_rpn_loc: 0.050  time: 1.0371  data_time: 0.0106  lr: 0.004695  max_mem: 5406M
[32m[04/20 18:36:48 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.583  loss_cls: 0.178  loss_box_reg: 0.322  loss_rpn_cls: 0.013  loss_rpn_loc: 0.052  time: 1.0372  data_time: 0.0103  lr: 0.004795  max_mem: 5406M
[32m[04/20 18:37:09 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.590  loss_cls: 0.192  loss_box_reg: 0.325  loss_rpn_cls: 0.015  loss_rpn_loc: 0.055  time: 1.0377  data_time: 0.0101  lr: 0.004895  max_mem: 5406M
[5m[31mWARNING[0m [32m[04/20 18:37:34 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 18:37:34 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 18:37:34 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 18:37:34 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.614  loss_cls: 0.198  loss_box_reg: 0.341  loss_rpn_cls: 0.016  loss_rpn_loc: 0.051  time: 1.0378  data_time: 0.0106  lr: 0.004995  max_mem: 5406M
[32m[04/20 18:37:35 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:15 (1.0389 s / it)
[32m[04/20 18:37:35 d2.engine.hooks]: [0mTotal training time: 0:17:23 (0:00:07 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 18:37:40 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 18:37:40 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 18:37:40 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 18:37:42 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1186 s / img. ETA=0:16:46
[32m[04/20 18:37:47 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1181 s / img. ETA=0:16:41
[32m[04/20 18:37:52 d2.evaluation.evaluator]: [0mInference done 95/8355. 0.1181 s / img. ETA=0:16:36
[32m[04/20 18:37:57 d2.evaluation.evaluator]: [0mInference done 137/8355. 0.1180 s / img. ETA=0:16:31
[32m[04/20 18:38:02 d2.evaluation.evaluator]: [0mInference done 179/8355. 0.1179 s / img. ETA=0:16:24
[32m[04/20 18:38:07 d2.evaluation.evaluator]: [0mInference done 221/8355. 0.1177 s / img. ETA=0:16:18
[32m[04/20 18:38:12 d2.evaluation.evaluator]: [0mInference done 263/8355. 0.1177 s / img. ETA=0:16:12
[32m[04/20 18:38:17 d2.evaluation.evaluator]: [0mInference done 305/8355. 0.1177 s / img. ETA=0:16:07
[32m[04/20 18:38:22 d2.evaluation.evaluator]: [0mInference done 347/8355. 0.1177 s / img. ETA=0:16:02
[32m[04/20 18:38:28 d2.evaluation.evaluator]: [0mInference done 389/8355. 0.1177 s / img. ETA=0:15:57
[32m[04/20 18:38:33 d2.evaluation.evaluator]: [0mInference done 431/8355. 0.1177 s / img. ETA=0:15:52
[32m[04/20 18:38:38 d2.evaluation.evaluator]: [0mInference done 473/8355. 0.1177 s / img. ETA=0:15:48
[32m[04/20 18:38:43 d2.evaluation.evaluator]: [0mInference done 515/8355. 0.1176 s / img. ETA=0:15:43
[32m[04/20 18:38:48 d2.evaluation.evaluator]: [0mInference done 557/8355. 0.1177 s / img. ETA=0:15:38
[32m[04/20 18:38:53 d2.evaluation.evaluator]: [0mInference done 599/8355. 0.1177 s / img. ETA=0:15:33
[32m[04/20 18:38:58 d2.evaluation.evaluator]: [0mInference done 641/8355. 0.1177 s / img. ETA=0:15:28
[32m[04/20 18:39:03 d2.evaluation.evaluator]: [0mInference done 683/8355. 0.1178 s / img. ETA=0:15:24
[32m[04/20 18:39:08 d2.evaluation.evaluator]: [0mInference done 724/8355. 0.1178 s / img. ETA=0:15:20
[32m[04/20 18:39:13 d2.evaluation.evaluator]: [0mInference done 766/8355. 0.1178 s / img. ETA=0:15:15
[32m[04/20 18:39:18 d2.evaluation.evaluator]: [0mInference done 808/8355. 0.1178 s / img. ETA=0:15:09
[32m[04/20 18:39:23 d2.evaluation.evaluator]: [0mInference done 850/8355. 0.1178 s / img. ETA=0:15:05
[32m[04/20 18:39:28 d2.evaluation.evaluator]: [0mInference done 892/8355. 0.1179 s / img. ETA=0:15:00
[32m[04/20 18:39:33 d2.evaluation.evaluator]: [0mInference done 934/8355. 0.1179 s / img. ETA=0:14:55
[32m[04/20 18:39:39 d2.evaluation.evaluator]: [0mInference done 976/8355. 0.1179 s / img. ETA=0:14:50
[32m[04/20 18:39:44 d2.evaluation.evaluator]: [0mInference done 1018/8355. 0.1180 s / img. ETA=0:14:46
[32m[04/20 18:39:49 d2.evaluation.evaluator]: [0mInference done 1060/8355. 0.1180 s / img. ETA=0:14:41
[32m[04/20 18:39:54 d2.evaluation.evaluator]: [0mInference done 1102/8355. 0.1180 s / img. ETA=0:14:36
[32m[04/20 18:39:59 d2.evaluation.evaluator]: [0mInference done 1144/8355. 0.1180 s / img. ETA=0:14:31
[32m[04/20 18:40:04 d2.evaluation.evaluator]: [0mInference done 1186/8355. 0.1180 s / img. ETA=0:14:25
[32m[04/20 18:40:09 d2.evaluation.evaluator]: [0mInference done 1228/8355. 0.1180 s / img. ETA=0:14:20
[32m[04/20 18:40:14 d2.evaluation.evaluator]: [0mInference done 1270/8355. 0.1180 s / img. ETA=0:14:15
[32m[04/20 18:40:19 d2.evaluation.evaluator]: [0mInference done 1312/8355. 0.1180 s / img. ETA=0:14:10
[32m[04/20 18:40:24 d2.evaluation.evaluator]: [0mInference done 1354/8355. 0.1180 s / img. ETA=0:14:05
[32m[04/20 18:40:29 d2.evaluation.evaluator]: [0mInference done 1396/8355. 0.1179 s / img. ETA=0:14:00
[32m[04/20 18:40:34 d2.evaluation.evaluator]: [0mInference done 1438/8355. 0.1179 s / img. ETA=0:13:54
[32m[04/20 18:40:39 d2.evaluation.evaluator]: [0mInference done 1480/8355. 0.1179 s / img. ETA=0:13:49
[32m[04/20 18:40:44 d2.evaluation.evaluator]: [0mInference done 1522/8355. 0.1179 s / img. ETA=0:13:44
[32m[04/20 18:40:49 d2.evaluation.evaluator]: [0mInference done 1563/8355. 0.1180 s / img. ETA=0:13:40
[32m[04/20 18:40:54 d2.evaluation.evaluator]: [0mInference done 1604/8355. 0.1180 s / img. ETA=0:13:35
[32m[04/20 18:41:00 d2.evaluation.evaluator]: [0mInference done 1645/8355. 0.1181 s / img. ETA=0:13:30
[32m[04/20 18:41:05 d2.evaluation.evaluator]: [0mInference done 1686/8355. 0.1181 s / img. ETA=0:13:26
[32m[04/20 18:41:10 d2.evaluation.evaluator]: [0mInference done 1728/8355. 0.1181 s / img. ETA=0:13:21
[32m[04/20 18:41:15 d2.evaluation.evaluator]: [0mInference done 1770/8355. 0.1181 s / img. ETA=0:13:16
[32m[04/20 18:41:20 d2.evaluation.evaluator]: [0mInference done 1812/8355. 0.1182 s / img. ETA=0:13:11
[32m[04/20 18:41:25 d2.evaluation.evaluator]: [0mInference done 1853/8355. 0.1182 s / img. ETA=0:13:06
[32m[04/20 18:41:30 d2.evaluation.evaluator]: [0mInference done 1894/8355. 0.1182 s / img. ETA=0:13:01
[32m[04/20 18:41:35 d2.evaluation.evaluator]: [0mInference done 1936/8355. 0.1182 s / img. ETA=0:12:56
[32m[04/20 18:41:40 d2.evaluation.evaluator]: [0mInference done 1978/8355. 0.1182 s / img. ETA=0:12:51
[32m[04/20 18:41:45 d2.evaluation.evaluator]: [0mInference done 2020/8355. 0.1183 s / img. ETA=0:12:46
[32m[04/20 18:41:50 d2.evaluation.evaluator]: [0mInference done 2062/8355. 0.1183 s / img. ETA=0:12:41
[32m[04/20 18:41:55 d2.evaluation.evaluator]: [0mInference done 2104/8355. 0.1183 s / img. ETA=0:12:36
[32m[04/20 18:42:00 d2.evaluation.evaluator]: [0mInference done 2146/8355. 0.1183 s / img. ETA=0:12:31
[32m[04/20 18:42:05 d2.evaluation.evaluator]: [0mInference done 2188/8355. 0.1183 s / img. ETA=0:12:26
[32m[04/20 18:42:11 d2.evaluation.evaluator]: [0mInference done 2230/8355. 0.1183 s / img. ETA=0:12:21
[32m[04/20 18:42:16 d2.evaluation.evaluator]: [0mInference done 2272/8355. 0.1183 s / img. ETA=0:12:16
[32m[04/20 18:42:21 d2.evaluation.evaluator]: [0mInference done 2314/8355. 0.1183 s / img. ETA=0:12:11
[32m[04/20 18:42:26 d2.evaluation.evaluator]: [0mInference done 2356/8355. 0.1183 s / img. ETA=0:12:05
[32m[04/20 18:42:31 d2.evaluation.evaluator]: [0mInference done 2398/8355. 0.1183 s / img. ETA=0:12:00
[32m[04/20 18:42:36 d2.evaluation.evaluator]: [0mInference done 2440/8355. 0.1183 s / img. ETA=0:11:55
[32m[04/20 18:42:41 d2.evaluation.evaluator]: [0mInference done 2481/8355. 0.1183 s / img. ETA=0:11:51
[32m[04/20 18:42:46 d2.evaluation.evaluator]: [0mInference done 2522/8355. 0.1183 s / img. ETA=0:11:46
[32m[04/20 18:42:51 d2.evaluation.evaluator]: [0mInference done 2563/8355. 0.1183 s / img. ETA=0:11:41
[32m[04/20 18:42:56 d2.evaluation.evaluator]: [0mInference done 2604/8355. 0.1184 s / img. ETA=0:11:36
[32m[04/20 18:43:01 d2.evaluation.evaluator]: [0mInference done 2645/8355. 0.1184 s / img. ETA=0:11:31
[32m[04/20 18:43:06 d2.evaluation.evaluator]: [0mInference done 2687/8355. 0.1184 s / img. ETA=0:11:26
[32m[04/20 18:43:11 d2.evaluation.evaluator]: [0mInference done 2728/8355. 0.1184 s / img. ETA=0:11:21
[32m[04/20 18:43:16 d2.evaluation.evaluator]: [0mInference done 2770/8355. 0.1184 s / img. ETA=0:11:16
[32m[04/20 18:43:21 d2.evaluation.evaluator]: [0mInference done 2811/8355. 0.1184 s / img. ETA=0:11:11
[32m[04/20 18:43:26 d2.evaluation.evaluator]: [0mInference done 2852/8355. 0.1185 s / img. ETA=0:11:07
[32m[04/20 18:43:32 d2.evaluation.evaluator]: [0mInference done 2894/8355. 0.1185 s / img. ETA=0:11:01
[32m[04/20 18:43:37 d2.evaluation.evaluator]: [0mInference done 2935/8355. 0.1185 s / img. ETA=0:10:57
[32m[04/20 18:43:42 d2.evaluation.evaluator]: [0mInference done 2976/8355. 0.1185 s / img. ETA=0:10:52
[32m[04/20 18:43:47 d2.evaluation.evaluator]: [0mInference done 3018/8355. 0.1185 s / img. ETA=0:10:47
[32m[04/20 18:43:52 d2.evaluation.evaluator]: [0mInference done 3060/8355. 0.1185 s / img. ETA=0:10:42
[32m[04/20 18:43:57 d2.evaluation.evaluator]: [0mInference done 3102/8355. 0.1185 s / img. ETA=0:10:36
[32m[04/20 18:44:02 d2.evaluation.evaluator]: [0mInference done 3144/8355. 0.1185 s / img. ETA=0:10:31
[32m[04/20 18:44:07 d2.evaluation.evaluator]: [0mInference done 3186/8355. 0.1185 s / img. ETA=0:10:26
[32m[04/20 18:44:12 d2.evaluation.evaluator]: [0mInference done 3228/8355. 0.1185 s / img. ETA=0:10:21
[32m[04/20 18:44:17 d2.evaluation.evaluator]: [0mInference done 3269/8355. 0.1185 s / img. ETA=0:10:16
[32m[04/20 18:44:22 d2.evaluation.evaluator]: [0mInference done 3311/8355. 0.1185 s / img. ETA=0:10:11
[32m[04/20 18:44:27 d2.evaluation.evaluator]: [0mInference done 3353/8355. 0.1185 s / img. ETA=0:10:06
[32m[04/20 18:44:32 d2.evaluation.evaluator]: [0mInference done 3395/8355. 0.1185 s / img. ETA=0:10:01
[32m[04/20 18:44:37 d2.evaluation.evaluator]: [0mInference done 3437/8355. 0.1185 s / img. ETA=0:09:56
[32m[04/20 18:44:42 d2.evaluation.evaluator]: [0mInference done 3478/8355. 0.1185 s / img. ETA=0:09:51
[32m[04/20 18:44:48 d2.evaluation.evaluator]: [0mInference done 3520/8355. 0.1185 s / img. ETA=0:09:46
[32m[04/20 18:44:53 d2.evaluation.evaluator]: [0mInference done 3562/8355. 0.1185 s / img. ETA=0:09:41
[32m[04/20 18:44:58 d2.evaluation.evaluator]: [0mInference done 3603/8355. 0.1185 s / img. ETA=0:09:36
[32m[04/20 18:45:03 d2.evaluation.evaluator]: [0mInference done 3644/8355. 0.1185 s / img. ETA=0:09:31
[32m[04/20 18:45:08 d2.evaluation.evaluator]: [0mInference done 3685/8355. 0.1185 s / img. ETA=0:09:26
[32m[04/20 18:45:13 d2.evaluation.evaluator]: [0mInference done 3727/8355. 0.1185 s / img. ETA=0:09:21
[32m[04/20 18:45:18 d2.evaluation.evaluator]: [0mInference done 3769/8355. 0.1185 s / img. ETA=0:09:16
[32m[04/20 18:45:23 d2.evaluation.evaluator]: [0mInference done 3811/8355. 0.1185 s / img. ETA=0:09:11
[32m[04/20 18:45:28 d2.evaluation.evaluator]: [0mInference done 3853/8355. 0.1185 s / img. ETA=0:09:06
[32m[04/20 18:45:33 d2.evaluation.evaluator]: [0mInference done 3895/8355. 0.1185 s / img. ETA=0:09:01
[32m[04/20 18:45:38 d2.evaluation.evaluator]: [0mInference done 3937/8355. 0.1185 s / img. ETA=0:08:55
[32m[04/20 18:45:43 d2.evaluation.evaluator]: [0mInference done 3979/8355. 0.1185 s / img. ETA=0:08:50
[32m[04/20 18:45:48 d2.evaluation.evaluator]: [0mInference done 4020/8355. 0.1185 s / img. ETA=0:08:45
[32m[04/20 18:45:54 d2.evaluation.evaluator]: [0mInference done 4062/8355. 0.1185 s / img. ETA=0:08:40
[32m[04/20 18:45:59 d2.evaluation.evaluator]: [0mInference done 4104/8355. 0.1185 s / img. ETA=0:08:35
[32m[04/20 18:46:04 d2.evaluation.evaluator]: [0mInference done 4146/8355. 0.1185 s / img. ETA=0:08:30
[32m[04/20 18:46:09 d2.evaluation.evaluator]: [0mInference done 4188/8355. 0.1185 s / img. ETA=0:08:25
[32m[04/20 18:46:14 d2.evaluation.evaluator]: [0mInference done 4230/8355. 0.1185 s / img. ETA=0:08:20
[32m[04/20 18:46:19 d2.evaluation.evaluator]: [0mInference done 4272/8355. 0.1185 s / img. ETA=0:08:15
[32m[04/20 18:46:24 d2.evaluation.evaluator]: [0mInference done 4313/8355. 0.1185 s / img. ETA=0:08:10
[32m[04/20 18:46:29 d2.evaluation.evaluator]: [0mInference done 4354/8355. 0.1185 s / img. ETA=0:08:05
[32m[04/20 18:46:34 d2.evaluation.evaluator]: [0mInference done 4396/8355. 0.1185 s / img. ETA=0:08:00
[32m[04/20 18:46:39 d2.evaluation.evaluator]: [0mInference done 4438/8355. 0.1185 s / img. ETA=0:07:55
[32m[04/20 18:46:44 d2.evaluation.evaluator]: [0mInference done 4480/8355. 0.1185 s / img. ETA=0:07:50
[32m[04/20 18:46:49 d2.evaluation.evaluator]: [0mInference done 4521/8355. 0.1185 s / img. ETA=0:07:45
[32m[04/20 18:46:54 d2.evaluation.evaluator]: [0mInference done 4562/8355. 0.1185 s / img. ETA=0:07:40
[32m[04/20 18:46:59 d2.evaluation.evaluator]: [0mInference done 4604/8355. 0.1185 s / img. ETA=0:07:35
[32m[04/20 18:47:04 d2.evaluation.evaluator]: [0mInference done 4645/8355. 0.1185 s / img. ETA=0:07:30
[32m[04/20 18:47:09 d2.evaluation.evaluator]: [0mInference done 4686/8355. 0.1185 s / img. ETA=0:07:25
[32m[04/20 18:47:14 d2.evaluation.evaluator]: [0mInference done 4727/8355. 0.1185 s / img. ETA=0:07:20
[32m[04/20 18:47:20 d2.evaluation.evaluator]: [0mInference done 4768/8355. 0.1185 s / img. ETA=0:07:15
[32m[04/20 18:47:25 d2.evaluation.evaluator]: [0mInference done 4809/8355. 0.1186 s / img. ETA=0:07:10
[32m[04/20 18:47:30 d2.evaluation.evaluator]: [0mInference done 4851/8355. 0.1186 s / img. ETA=0:07:05
[32m[04/20 18:47:35 d2.evaluation.evaluator]: [0mInference done 4893/8355. 0.1186 s / img. ETA=0:07:00
[32m[04/20 18:47:40 d2.evaluation.evaluator]: [0mInference done 4935/8355. 0.1185 s / img. ETA=0:06:55
[32m[04/20 18:47:45 d2.evaluation.evaluator]: [0mInference done 4977/8355. 0.1185 s / img. ETA=0:06:50
[32m[04/20 18:47:50 d2.evaluation.evaluator]: [0mInference done 5019/8355. 0.1185 s / img. ETA=0:06:44
[32m[04/20 18:47:55 d2.evaluation.evaluator]: [0mInference done 5060/8355. 0.1186 s / img. ETA=0:06:40
[32m[04/20 18:48:00 d2.evaluation.evaluator]: [0mInference done 5101/8355. 0.1186 s / img. ETA=0:06:35
[32m[04/20 18:48:05 d2.evaluation.evaluator]: [0mInference done 5142/8355. 0.1186 s / img. ETA=0:06:30
[32m[04/20 18:48:10 d2.evaluation.evaluator]: [0mInference done 5183/8355. 0.1186 s / img. ETA=0:06:25
[32m[04/20 18:48:15 d2.evaluation.evaluator]: [0mInference done 5224/8355. 0.1186 s / img. ETA=0:06:20
[32m[04/20 18:48:20 d2.evaluation.evaluator]: [0mInference done 5266/8355. 0.1186 s / img. ETA=0:06:15
[32m[04/20 18:48:25 d2.evaluation.evaluator]: [0mInference done 5307/8355. 0.1186 s / img. ETA=0:06:10
[32m[04/20 18:48:30 d2.evaluation.evaluator]: [0mInference done 5348/8355. 0.1186 s / img. ETA=0:06:05
[32m[04/20 18:48:35 d2.evaluation.evaluator]: [0mInference done 5390/8355. 0.1186 s / img. ETA=0:06:00
[32m[04/20 18:48:41 d2.evaluation.evaluator]: [0mInference done 5432/8355. 0.1186 s / img. ETA=0:05:55
[32m[04/20 18:48:46 d2.evaluation.evaluator]: [0mInference done 5474/8355. 0.1186 s / img. ETA=0:05:49
[32m[04/20 18:48:51 d2.evaluation.evaluator]: [0mInference done 5515/8355. 0.1186 s / img. ETA=0:05:44
[32m[04/20 18:48:56 d2.evaluation.evaluator]: [0mInference done 5557/8355. 0.1186 s / img. ETA=0:05:39
[32m[04/20 18:49:01 d2.evaluation.evaluator]: [0mInference done 5599/8355. 0.1186 s / img. ETA=0:05:34
[32m[04/20 18:49:06 d2.evaluation.evaluator]: [0mInference done 5640/8355. 0.1186 s / img. ETA=0:05:29
[32m[04/20 18:49:11 d2.evaluation.evaluator]: [0mInference done 5681/8355. 0.1186 s / img. ETA=0:05:24
[32m[04/20 18:49:16 d2.evaluation.evaluator]: [0mInference done 5722/8355. 0.1186 s / img. ETA=0:05:19
[32m[04/20 18:49:21 d2.evaluation.evaluator]: [0mInference done 5764/8355. 0.1186 s / img. ETA=0:05:14
[32m[04/20 18:49:26 d2.evaluation.evaluator]: [0mInference done 5806/8355. 0.1186 s / img. ETA=0:05:09
[32m[04/20 18:49:31 d2.evaluation.evaluator]: [0mInference done 5848/8355. 0.1186 s / img. ETA=0:05:04
[32m[04/20 18:49:36 d2.evaluation.evaluator]: [0mInference done 5890/8355. 0.1186 s / img. ETA=0:04:59
[32m[04/20 18:49:41 d2.evaluation.evaluator]: [0mInference done 5932/8355. 0.1186 s / img. ETA=0:04:54
[32m[04/20 18:49:47 d2.evaluation.evaluator]: [0mInference done 5974/8355. 0.1186 s / img. ETA=0:04:49
[32m[04/20 18:49:52 d2.evaluation.evaluator]: [0mInference done 6016/8355. 0.1186 s / img. ETA=0:04:44
[32m[04/20 18:49:57 d2.evaluation.evaluator]: [0mInference done 6057/8355. 0.1187 s / img. ETA=0:04:39
[32m[04/20 18:50:02 d2.evaluation.evaluator]: [0mInference done 6099/8355. 0.1187 s / img. ETA=0:04:34
[32m[04/20 18:50:07 d2.evaluation.evaluator]: [0mInference done 6141/8355. 0.1187 s / img. ETA=0:04:29
[32m[04/20 18:50:12 d2.evaluation.evaluator]: [0mInference done 6183/8355. 0.1187 s / img. ETA=0:04:23
[32m[04/20 18:50:17 d2.evaluation.evaluator]: [0mInference done 6224/8355. 0.1187 s / img. ETA=0:04:18
[32m[04/20 18:50:22 d2.evaluation.evaluator]: [0mInference done 6266/8355. 0.1187 s / img. ETA=0:04:13
[32m[04/20 18:50:27 d2.evaluation.evaluator]: [0mInference done 6308/8355. 0.1187 s / img. ETA=0:04:08
[32m[04/20 18:50:32 d2.evaluation.evaluator]: [0mInference done 6350/8355. 0.1187 s / img. ETA=0:04:03
[32m[04/20 18:50:37 d2.evaluation.evaluator]: [0mInference done 6392/8355. 0.1187 s / img. ETA=0:03:58
[32m[04/20 18:50:43 d2.evaluation.evaluator]: [0mInference done 6434/8355. 0.1187 s / img. ETA=0:03:53
[32m[04/20 18:50:48 d2.evaluation.evaluator]: [0mInference done 6476/8355. 0.1187 s / img. ETA=0:03:48
[32m[04/20 18:50:53 d2.evaluation.evaluator]: [0mInference done 6518/8355. 0.1187 s / img. ETA=0:03:43
[32m[04/20 18:50:58 d2.evaluation.evaluator]: [0mInference done 6560/8355. 0.1186 s / img. ETA=0:03:38
[32m[04/20 18:51:03 d2.evaluation.evaluator]: [0mInference done 6602/8355. 0.1186 s / img. ETA=0:03:32
[32m[04/20 18:51:08 d2.evaluation.evaluator]: [0mInference done 6644/8355. 0.1186 s / img. ETA=0:03:27
[32m[04/20 18:51:13 d2.evaluation.evaluator]: [0mInference done 6686/8355. 0.1186 s / img. ETA=0:03:22
[32m[04/20 18:51:18 d2.evaluation.evaluator]: [0mInference done 6728/8355. 0.1186 s / img. ETA=0:03:17
[32m[04/20 18:51:23 d2.evaluation.evaluator]: [0mInference done 6770/8355. 0.1186 s / img. ETA=0:03:12
[32m[04/20 18:51:28 d2.evaluation.evaluator]: [0mInference done 6812/8355. 0.1186 s / img. ETA=0:03:07
[32m[04/20 18:51:33 d2.evaluation.evaluator]: [0mInference done 6854/8355. 0.1186 s / img. ETA=0:03:02
[32m[04/20 18:51:38 d2.evaluation.evaluator]: [0mInference done 6896/8355. 0.1186 s / img. ETA=0:02:57
[32m[04/20 18:51:43 d2.evaluation.evaluator]: [0mInference done 6937/8355. 0.1186 s / img. ETA=0:02:52
[32m[04/20 18:51:48 d2.evaluation.evaluator]: [0mInference done 6978/8355. 0.1186 s / img. ETA=0:02:47
[32m[04/20 18:51:53 d2.evaluation.evaluator]: [0mInference done 7019/8355. 0.1186 s / img. ETA=0:02:42
[32m[04/20 18:51:58 d2.evaluation.evaluator]: [0mInference done 7060/8355. 0.1186 s / img. ETA=0:02:37
[32m[04/20 18:52:03 d2.evaluation.evaluator]: [0mInference done 7101/8355. 0.1186 s / img. ETA=0:02:32
[32m[04/20 18:52:08 d2.evaluation.evaluator]: [0mInference done 7142/8355. 0.1187 s / img. ETA=0:02:27
[32m[04/20 18:52:14 d2.evaluation.evaluator]: [0mInference done 7183/8355. 0.1187 s / img. ETA=0:02:22
[32m[04/20 18:52:19 d2.evaluation.evaluator]: [0mInference done 7224/8355. 0.1187 s / img. ETA=0:02:17
[32m[04/20 18:52:24 d2.evaluation.evaluator]: [0mInference done 7265/8355. 0.1187 s / img. ETA=0:02:12
[32m[04/20 18:52:29 d2.evaluation.evaluator]: [0mInference done 7306/8355. 0.1187 s / img. ETA=0:02:07
[32m[04/20 18:52:34 d2.evaluation.evaluator]: [0mInference done 7347/8355. 0.1187 s / img. ETA=0:02:02
[32m[04/20 18:52:39 d2.evaluation.evaluator]: [0mInference done 7388/8355. 0.1187 s / img. ETA=0:01:57
[32m[04/20 18:52:44 d2.evaluation.evaluator]: [0mInference done 7429/8355. 0.1187 s / img. ETA=0:01:52
[32m[04/20 18:52:49 d2.evaluation.evaluator]: [0mInference done 7470/8355. 0.1187 s / img. ETA=0:01:47
[32m[04/20 18:52:54 d2.evaluation.evaluator]: [0mInference done 7511/8355. 0.1187 s / img. ETA=0:01:42
[32m[04/20 18:52:59 d2.evaluation.evaluator]: [0mInference done 7552/8355. 0.1187 s / img. ETA=0:01:37
[32m[04/20 18:53:04 d2.evaluation.evaluator]: [0mInference done 7593/8355. 0.1187 s / img. ETA=0:01:32
[32m[04/20 18:53:09 d2.evaluation.evaluator]: [0mInference done 7634/8355. 0.1187 s / img. ETA=0:01:27
[32m[04/20 18:53:14 d2.evaluation.evaluator]: [0mInference done 7675/8355. 0.1188 s / img. ETA=0:01:22
[32m[04/20 18:53:19 d2.evaluation.evaluator]: [0mInference done 7717/8355. 0.1188 s / img. ETA=0:01:17
[32m[04/20 18:53:24 d2.evaluation.evaluator]: [0mInference done 7759/8355. 0.1188 s / img. ETA=0:01:12
[32m[04/20 18:53:29 d2.evaluation.evaluator]: [0mInference done 7800/8355. 0.1188 s / img. ETA=0:01:07
[32m[04/20 18:53:34 d2.evaluation.evaluator]: [0mInference done 7841/8355. 0.1188 s / img. ETA=0:01:02
[32m[04/20 18:53:39 d2.evaluation.evaluator]: [0mInference done 7882/8355. 0.1188 s / img. ETA=0:00:57
[32m[04/20 18:53:44 d2.evaluation.evaluator]: [0mInference done 7923/8355. 0.1188 s / img. ETA=0:00:52
[32m[04/20 18:53:50 d2.evaluation.evaluator]: [0mInference done 7964/8355. 0.1188 s / img. ETA=0:00:47
[32m[04/20 18:53:55 d2.evaluation.evaluator]: [0mInference done 8006/8355. 0.1188 s / img. ETA=0:00:42
[32m[04/20 18:54:00 d2.evaluation.evaluator]: [0mInference done 8048/8355. 0.1188 s / img. ETA=0:00:37
[32m[04/20 18:54:05 d2.evaluation.evaluator]: [0mInference done 8085/8355. 0.1188 s / img. ETA=0:00:32
[32m[04/20 18:54:10 d2.evaluation.evaluator]: [0mInference done 8119/8355. 0.1188 s / img. ETA=0:00:28
[32m[04/20 18:54:15 d2.evaluation.evaluator]: [0mInference done 8157/8355. 0.1188 s / img. ETA=0:00:24
[32m[04/20 18:54:20 d2.evaluation.evaluator]: [0mInference done 8191/8355. 0.1188 s / img. ETA=0:00:20
[32m[04/20 18:54:25 d2.evaluation.evaluator]: [0mInference done 8219/8355. 0.1188 s / img. ETA=0:00:16
[32m[04/20 18:54:30 d2.evaluation.evaluator]: [0mInference done 8255/8355. 0.1188 s / img. ETA=0:00:12
[32m[04/20 18:54:36 d2.evaluation.evaluator]: [0mInference done 8282/8355. 0.1188 s / img. ETA=0:00:08
[32m[04/20 18:54:41 d2.evaluation.evaluator]: [0mInference done 8306/8355. 0.1188 s / img. ETA=0:00:06
[32m[04/20 18:54:46 d2.evaluation.evaluator]: [0mInference done 8331/8355. 0.1188 s / img. ETA=0:00:02
[32m[04/20 18:54:52 d2.evaluation.evaluator]: [0mTotal inference time: 0:17:10.761368 (0.123444 s / img per device, on 1 devices)
[32m[04/20 18:54:52 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:31 (0.118756 s / img per device, on 1 devices)
[32m[04/20 18:54:52 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 18:54:52 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 18:54:53 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.80s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=21.15s).
Accumulating evaluation results...
DONE (t=2.60s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.388
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.718
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.366
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.273
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.695
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.156
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.432
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.336
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.586
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.743
[32m[04/20 18:55:19 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 38.774 | 71.816 | 36.618 | 27.331 | 52.262 | 69.456 |
[32m[04/20 18:55:19 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 38.983 | bicycle       | 29.572 | car            | 47.768 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 18:55:23 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 18:55:23 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 18:55:23 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 18:55:29 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1181 s / img. ETA=0:05:33
[32m[04/20 18:55:35 d2.evaluation.evaluator]: [0mInference done 27/1257. 0.1175 s / img. ETA=0:06:29
[32m[04/20 18:55:40 d2.evaluation.evaluator]: [0mInference done 47/1257. 0.1173 s / img. ETA=0:05:53
[32m[04/20 18:55:45 d2.evaluation.evaluator]: [0mInference done 65/1257. 0.1171 s / img. ETA=0:05:48
[32m[04/20 18:55:50 d2.evaluation.evaluator]: [0mInference done 90/1257. 0.1170 s / img. ETA=0:05:11
[32m[04/20 18:55:56 d2.evaluation.evaluator]: [0mInference done 108/1257. 0.1170 s / img. ETA=0:05:11
[32m[04/20 18:56:01 d2.evaluation.evaluator]: [0mInference done 130/1257. 0.1170 s / img. ETA=0:04:57
[32m[04/20 18:56:06 d2.evaluation.evaluator]: [0mInference done 145/1257. 0.1169 s / img. ETA=0:05:01
[32m[04/20 18:56:11 d2.evaluation.evaluator]: [0mInference done 175/1257. 0.1169 s / img. ETA=0:04:35
[32m[04/20 18:56:16 d2.evaluation.evaluator]: [0mInference done 207/1257. 0.1170 s / img. ETA=0:04:11
[32m[04/20 18:56:21 d2.evaluation.evaluator]: [0mInference done 240/1257. 0.1170 s / img. ETA=0:03:51
[32m[04/20 18:56:26 d2.evaluation.evaluator]: [0mInference done 277/1257. 0.1171 s / img. ETA=0:03:30
[32m[04/20 18:56:31 d2.evaluation.evaluator]: [0mInference done 316/1257. 0.1171 s / img. ETA=0:03:12
[32m[04/20 18:56:36 d2.evaluation.evaluator]: [0mInference done 355/1257. 0.1172 s / img. ETA=0:02:56
[32m[04/20 18:56:41 d2.evaluation.evaluator]: [0mInference done 389/1257. 0.1172 s / img. ETA=0:02:46
[32m[04/20 18:56:47 d2.evaluation.evaluator]: [0mInference done 420/1257. 0.1171 s / img. ETA=0:02:38
[32m[04/20 18:56:52 d2.evaluation.evaluator]: [0mInference done 439/1257. 0.1171 s / img. ETA=0:02:37
[32m[04/20 18:56:58 d2.evaluation.evaluator]: [0mInference done 450/1257. 0.1172 s / img. ETA=0:02:43
[32m[04/20 18:57:03 d2.evaluation.evaluator]: [0mInference done 462/1257. 0.1171 s / img. ETA=0:02:45
[32m[04/20 18:57:08 d2.evaluation.evaluator]: [0mInference done 492/1257. 0.1171 s / img. ETA=0:02:37
[32m[04/20 18:57:13 d2.evaluation.evaluator]: [0mInference done 505/1257. 0.1171 s / img. ETA=0:02:38
[32m[04/20 18:57:18 d2.evaluation.evaluator]: [0mInference done 527/1257. 0.1171 s / img. ETA=0:02:34
[32m[04/20 18:57:23 d2.evaluation.evaluator]: [0mInference done 546/1257. 0.1171 s / img. ETA=0:02:31
[32m[04/20 18:57:29 d2.evaluation.evaluator]: [0mInference done 577/1257. 0.1171 s / img. ETA=0:02:23
[32m[04/20 18:57:34 d2.evaluation.evaluator]: [0mInference done 610/1257. 0.1170 s / img. ETA=0:02:14
[32m[04/20 18:57:40 d2.evaluation.evaluator]: [0mInference done 635/1257. 0.1171 s / img. ETA=0:02:10
[32m[04/20 18:57:47 d2.evaluation.evaluator]: [0mInference done 656/1257. 0.1171 s / img. ETA=0:02:08
[32m[04/20 18:57:52 d2.evaluation.evaluator]: [0mInference done 683/1257. 0.1171 s / img. ETA=0:02:01
[32m[04/20 18:57:57 d2.evaluation.evaluator]: [0mInference done 719/1257. 0.1171 s / img. ETA=0:01:52
[32m[04/20 18:58:02 d2.evaluation.evaluator]: [0mInference done 752/1257. 0.1172 s / img. ETA=0:01:44
[32m[04/20 18:58:07 d2.evaluation.evaluator]: [0mInference done 791/1257. 0.1172 s / img. ETA=0:01:34
[32m[04/20 18:58:12 d2.evaluation.evaluator]: [0mInference done 833/1257. 0.1173 s / img. ETA=0:01:24
[32m[04/20 18:58:17 d2.evaluation.evaluator]: [0mInference done 871/1257. 0.1173 s / img. ETA=0:01:15
[32m[04/20 18:58:22 d2.evaluation.evaluator]: [0mInference done 910/1257. 0.1174 s / img. ETA=0:01:06
[32m[04/20 18:58:27 d2.evaluation.evaluator]: [0mInference done 952/1257. 0.1174 s / img. ETA=0:00:57
[32m[04/20 18:58:32 d2.evaluation.evaluator]: [0mInference done 992/1257. 0.1175 s / img. ETA=0:00:49
[32m[04/20 18:58:37 d2.evaluation.evaluator]: [0mInference done 1030/1257. 0.1175 s / img. ETA=0:00:42
[32m[04/20 18:58:43 d2.evaluation.evaluator]: [0mInference done 1072/1257. 0.1175 s / img. ETA=0:00:33
[32m[04/20 18:58:48 d2.evaluation.evaluator]: [0mInference done 1108/1257. 0.1175 s / img. ETA=0:00:26
[32m[04/20 18:58:53 d2.evaluation.evaluator]: [0mInference done 1142/1257. 0.1176 s / img. ETA=0:00:20
[32m[04/20 18:58:58 d2.evaluation.evaluator]: [0mInference done 1179/1257. 0.1176 s / img. ETA=0:00:13
[32m[04/20 18:59:03 d2.evaluation.evaluator]: [0mInference done 1212/1257. 0.1176 s / img. ETA=0:00:08
[32m[04/20 18:59:08 d2.evaluation.evaluator]: [0mInference done 1247/1257. 0.1176 s / img. ETA=0:00:01
[32m[04/20 18:59:10 d2.evaluation.evaluator]: [0mTotal inference time: 0:03:41.929666 (0.177260 s / img per device, on 1 devices)
[32m[04/20 18:59:10 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:27 (0.117578 s / img per device, on 1 devices)
[32m[04/20 18:59:10 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 18:59:10 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 18:59:10 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.78s).
Accumulating evaluation results...
DONE (t=0.36s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.293
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.570
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.258
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.178
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.356
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.478
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.151
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.351
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.245
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.421
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.537
[32m[04/20 18:59:13 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 29.328 | 57.003 | 25.798 | 17.773 | 35.581 | 47.796 |
[32m[04/20 18:59:13 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 29.811 | bicycle       | 13.761 | car            | 44.411 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  22  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 18:59:14 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[32m[04/20 18:59:16 d2.data.datasets.coco]: [0mLoading ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json takes 1.86 seconds.
[5m[31mWARNING[0m [32m[04/20 18:59:16 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 18:59:16 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 18:59:16 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 18:59:16 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 18:59:16 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 18:59:18 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 18:59:48 d2.utils.events]: [0m eta: 0:16:49  iter: 19  total_loss: 0.641  loss_cls: 0.196  loss_box_reg: 0.369  loss_rpn_cls: 0.015  loss_rpn_loc: 0.060  time: 1.0308  data_time: 0.1501  lr: 0.000100  max_mem: 5406M
[32m[04/20 19:00:09 d2.utils.events]: [0m eta: 0:17:01  iter: 39  total_loss: 0.605  loss_cls: 0.192  loss_box_reg: 0.326  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0505  data_time: 0.0446  lr: 0.000200  max_mem: 5406M
[32m[04/20 19:00:30 d2.utils.events]: [0m eta: 0:16:50  iter: 59  total_loss: 0.565  loss_cls: 0.175  loss_box_reg: 0.307  loss_rpn_cls: 0.012  loss_rpn_loc: 0.046  time: 1.0528  data_time: 0.0253  lr: 0.000300  max_mem: 5406M
[32m[04/20 19:00:51 d2.utils.events]: [0m eta: 0:16:19  iter: 79  total_loss: 0.600  loss_cls: 0.203  loss_box_reg: 0.332  loss_rpn_cls: 0.010  loss_rpn_loc: 0.059  time: 1.0446  data_time: 0.0246  lr: 0.000400  max_mem: 5406M
[32m[04/20 19:01:12 d2.utils.events]: [0m eta: 0:15:58  iter: 99  total_loss: 0.563  loss_cls: 0.170  loss_box_reg: 0.308  loss_rpn_cls: 0.010  loss_rpn_loc: 0.053  time: 1.0445  data_time: 0.0107  lr: 0.000500  max_mem: 5406M
[32m[04/20 19:01:33 d2.utils.events]: [0m eta: 0:15:36  iter: 119  total_loss: 0.545  loss_cls: 0.178  loss_box_reg: 0.321  loss_rpn_cls: 0.010  loss_rpn_loc: 0.043  time: 1.0431  data_time: 0.0095  lr: 0.000599  max_mem: 5406M
[32m[04/20 19:01:54 d2.utils.events]: [0m eta: 0:15:16  iter: 139  total_loss: 0.559  loss_cls: 0.177  loss_box_reg: 0.321  loss_rpn_cls: 0.014  loss_rpn_loc: 0.045  time: 1.0437  data_time: 0.0099  lr: 0.000699  max_mem: 5406M
[32m[04/20 19:02:15 d2.utils.events]: [0m eta: 0:14:54  iter: 159  total_loss: 0.579  loss_cls: 0.173  loss_box_reg: 0.328  loss_rpn_cls: 0.013  loss_rpn_loc: 0.049  time: 1.0423  data_time: 0.0100  lr: 0.000799  max_mem: 5406M
[32m[04/20 19:02:36 d2.utils.events]: [0m eta: 0:14:32  iter: 179  total_loss: 0.558  loss_cls: 0.176  loss_box_reg: 0.329  loss_rpn_cls: 0.010  loss_rpn_loc: 0.051  time: 1.0427  data_time: 0.0095  lr: 0.000899  max_mem: 5406M
[32m[04/20 19:02:56 d2.utils.events]: [0m eta: 0:14:10  iter: 199  total_loss: 0.552  loss_cls: 0.169  loss_box_reg: 0.311  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0410  data_time: 0.0096  lr: 0.000999  max_mem: 5406M
[32m[04/20 19:03:17 d2.utils.events]: [0m eta: 0:13:45  iter: 219  total_loss: 0.628  loss_cls: 0.207  loss_box_reg: 0.358  loss_rpn_cls: 0.015  loss_rpn_loc: 0.056  time: 1.0393  data_time: 0.0122  lr: 0.001099  max_mem: 5406M
[32m[04/20 19:03:37 d2.utils.events]: [0m eta: 0:13:23  iter: 239  total_loss: 0.574  loss_cls: 0.182  loss_box_reg: 0.329  loss_rpn_cls: 0.011  loss_rpn_loc: 0.062  time: 1.0373  data_time: 0.0096  lr: 0.001199  max_mem: 5406M
[32m[04/20 19:03:58 d2.utils.events]: [0m eta: 0:12:59  iter: 259  total_loss: 0.563  loss_cls: 0.190  loss_box_reg: 0.318  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0359  data_time: 0.0097  lr: 0.001299  max_mem: 5406M
[32m[04/20 19:04:19 d2.utils.events]: [0m eta: 0:12:35  iter: 279  total_loss: 0.542  loss_cls: 0.163  loss_box_reg: 0.302  loss_rpn_cls: 0.011  loss_rpn_loc: 0.044  time: 1.0356  data_time: 0.0097  lr: 0.001399  max_mem: 5406M
[32m[04/20 19:04:40 d2.utils.events]: [0m eta: 0:12:14  iter: 299  total_loss: 0.692  loss_cls: 0.222  loss_box_reg: 0.394  loss_rpn_cls: 0.013  loss_rpn_loc: 0.060  time: 1.0353  data_time: 0.0098  lr: 0.001499  max_mem: 5406M
[32m[04/20 19:05:01 d2.utils.events]: [0m eta: 0:11:55  iter: 319  total_loss: 0.616  loss_cls: 0.197  loss_box_reg: 0.356  loss_rpn_cls: 0.010  loss_rpn_loc: 0.055  time: 1.0371  data_time: 0.0097  lr: 0.001598  max_mem: 5406M
[32m[04/20 19:05:22 d2.utils.events]: [0m eta: 0:11:34  iter: 339  total_loss: 0.534  loss_cls: 0.175  loss_box_reg: 0.293  loss_rpn_cls: 0.012  loss_rpn_loc: 0.040  time: 1.0375  data_time: 0.0334  lr: 0.001698  max_mem: 5406M
[32m[04/20 19:05:43 d2.utils.events]: [0m eta: 0:11:11  iter: 359  total_loss: 0.498  loss_cls: 0.158  loss_box_reg: 0.287  loss_rpn_cls: 0.012  loss_rpn_loc: 0.045  time: 1.0369  data_time: 0.0115  lr: 0.001798  max_mem: 5406M
[32m[04/20 19:06:04 d2.utils.events]: [0m eta: 0:10:51  iter: 379  total_loss: 0.616  loss_cls: 0.211  loss_box_reg: 0.343  loss_rpn_cls: 0.013  loss_rpn_loc: 0.047  time: 1.0378  data_time: 0.0102  lr: 0.001898  max_mem: 5406M
[32m[04/20 19:06:25 d2.utils.events]: [0m eta: 0:10:30  iter: 399  total_loss: 0.550  loss_cls: 0.175  loss_box_reg: 0.315  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0379  data_time: 0.0104  lr: 0.001998  max_mem: 5406M
[32m[04/20 19:06:46 d2.utils.events]: [0m eta: 0:10:09  iter: 419  total_loss: 0.582  loss_cls: 0.178  loss_box_reg: 0.340  loss_rpn_cls: 0.012  loss_rpn_loc: 0.049  time: 1.0380  data_time: 0.0107  lr: 0.002098  max_mem: 5406M
[32m[04/20 19:07:06 d2.utils.events]: [0m eta: 0:09:47  iter: 439  total_loss: 0.601  loss_cls: 0.185  loss_box_reg: 0.331  loss_rpn_cls: 0.011  loss_rpn_loc: 0.061  time: 1.0371  data_time: 0.0100  lr: 0.002198  max_mem: 5406M
[32m[04/20 19:07:27 d2.utils.events]: [0m eta: 0:09:26  iter: 459  total_loss: 0.534  loss_cls: 0.172  loss_box_reg: 0.301  loss_rpn_cls: 0.012  loss_rpn_loc: 0.046  time: 1.0367  data_time: 0.0100  lr: 0.002298  max_mem: 5406M
[32m[04/20 19:07:48 d2.utils.events]: [0m eta: 0:09:06  iter: 479  total_loss: 0.558  loss_cls: 0.166  loss_box_reg: 0.297  loss_rpn_cls: 0.010  loss_rpn_loc: 0.053  time: 1.0373  data_time: 0.0111  lr: 0.002398  max_mem: 5406M
[32m[04/20 19:08:10 d2.utils.events]: [0m eta: 0:08:47  iter: 499  total_loss: 0.557  loss_cls: 0.176  loss_box_reg: 0.302  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 1.0388  data_time: 0.0105  lr: 0.002498  max_mem: 5406M
[32m[04/20 19:08:30 d2.utils.events]: [0m eta: 0:08:26  iter: 519  total_loss: 0.574  loss_cls: 0.174  loss_box_reg: 0.328  loss_rpn_cls: 0.014  loss_rpn_loc: 0.056  time: 1.0388  data_time: 0.0101  lr: 0.002597  max_mem: 5406M
[32m[04/20 19:08:50 d2.utils.events]: [0m eta: 0:08:03  iter: 539  total_loss: 0.555  loss_cls: 0.174  loss_box_reg: 0.311  loss_rpn_cls: 0.011  loss_rpn_loc: 0.044  time: 1.0370  data_time: 0.0101  lr: 0.002697  max_mem: 5406M
[32m[04/20 19:09:11 d2.utils.events]: [0m eta: 0:07:43  iter: 559  total_loss: 0.565  loss_cls: 0.183  loss_box_reg: 0.321  loss_rpn_cls: 0.010  loss_rpn_loc: 0.045  time: 1.0376  data_time: 0.0104  lr: 0.002797  max_mem: 5406M
[32m[04/20 19:09:32 d2.utils.events]: [0m eta: 0:07:21  iter: 579  total_loss: 0.558  loss_cls: 0.178  loss_box_reg: 0.328  loss_rpn_cls: 0.009  loss_rpn_loc: 0.047  time: 1.0369  data_time: 0.0100  lr: 0.002897  max_mem: 5406M
[32m[04/20 19:09:52 d2.utils.events]: [0m eta: 0:06:59  iter: 599  total_loss: 0.592  loss_cls: 0.182  loss_box_reg: 0.339  loss_rpn_cls: 0.014  loss_rpn_loc: 0.057  time: 1.0350  data_time: 0.0095  lr: 0.002997  max_mem: 5406M
[32m[04/20 19:10:12 d2.utils.events]: [0m eta: 0:06:38  iter: 619  total_loss: 0.650  loss_cls: 0.208  loss_box_reg: 0.367  loss_rpn_cls: 0.011  loss_rpn_loc: 0.063  time: 1.0342  data_time: 0.0100  lr: 0.003097  max_mem: 5406M
[32m[04/20 19:10:32 d2.utils.events]: [0m eta: 0:06:17  iter: 639  total_loss: 0.552  loss_cls: 0.184  loss_box_reg: 0.321  loss_rpn_cls: 0.011  loss_rpn_loc: 0.059  time: 1.0333  data_time: 0.0101  lr: 0.003197  max_mem: 5406M
[32m[04/20 19:10:53 d2.utils.events]: [0m eta: 0:05:56  iter: 659  total_loss: 0.606  loss_cls: 0.194  loss_box_reg: 0.341  loss_rpn_cls: 0.015  loss_rpn_loc: 0.044  time: 1.0336  data_time: 0.0100  lr: 0.003297  max_mem: 5406M
[32m[04/20 19:11:14 d2.utils.events]: [0m eta: 0:05:35  iter: 679  total_loss: 0.623  loss_cls: 0.193  loss_box_reg: 0.356  loss_rpn_cls: 0.014  loss_rpn_loc: 0.052  time: 1.0340  data_time: 0.0098  lr: 0.003397  max_mem: 5406M
[32m[04/20 19:11:34 d2.utils.events]: [0m eta: 0:05:14  iter: 699  total_loss: 0.555  loss_cls: 0.180  loss_box_reg: 0.315  loss_rpn_cls: 0.011  loss_rpn_loc: 0.043  time: 1.0336  data_time: 0.0098  lr: 0.003497  max_mem: 5406M
[32m[04/20 19:11:55 d2.utils.events]: [0m eta: 0:04:53  iter: 719  total_loss: 0.562  loss_cls: 0.177  loss_box_reg: 0.318  loss_rpn_cls: 0.012  loss_rpn_loc: 0.045  time: 1.0337  data_time: 0.0100  lr: 0.003596  max_mem: 5406M
[32m[04/20 19:12:16 d2.utils.events]: [0m eta: 0:04:32  iter: 739  total_loss: 0.576  loss_cls: 0.185  loss_box_reg: 0.322  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 1.0335  data_time: 0.0103  lr: 0.003696  max_mem: 5406M
[32m[04/20 19:12:37 d2.utils.events]: [0m eta: 0:04:11  iter: 759  total_loss: 0.616  loss_cls: 0.203  loss_box_reg: 0.346  loss_rpn_cls: 0.016  loss_rpn_loc: 0.062  time: 1.0337  data_time: 0.0103  lr: 0.003796  max_mem: 5406M
[32m[04/20 19:12:57 d2.utils.events]: [0m eta: 0:03:50  iter: 779  total_loss: 0.553  loss_cls: 0.170  loss_box_reg: 0.309  loss_rpn_cls: 0.011  loss_rpn_loc: 0.052  time: 1.0337  data_time: 0.0099  lr: 0.003896  max_mem: 5406M
[32m[04/20 19:13:18 d2.utils.events]: [0m eta: 0:03:29  iter: 799  total_loss: 0.633  loss_cls: 0.179  loss_box_reg: 0.356  loss_rpn_cls: 0.011  loss_rpn_loc: 0.067  time: 1.0336  data_time: 0.0099  lr: 0.003996  max_mem: 5406M
[32m[04/20 19:13:39 d2.utils.events]: [0m eta: 0:03:09  iter: 819  total_loss: 0.537  loss_cls: 0.161  loss_box_reg: 0.307  loss_rpn_cls: 0.010  loss_rpn_loc: 0.049  time: 1.0339  data_time: 0.0097  lr: 0.004096  max_mem: 5406M
[32m[04/20 19:13:59 d2.utils.events]: [0m eta: 0:02:48  iter: 839  total_loss: 0.556  loss_cls: 0.185  loss_box_reg: 0.309  loss_rpn_cls: 0.009  loss_rpn_loc: 0.048  time: 1.0333  data_time: 0.0097  lr: 0.004196  max_mem: 5406M
[32m[04/20 19:14:20 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.564  loss_cls: 0.169  loss_box_reg: 0.322  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 1.0334  data_time: 0.0099  lr: 0.004296  max_mem: 5406M
[32m[04/20 19:14:41 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.582  loss_cls: 0.180  loss_box_reg: 0.325  loss_rpn_cls: 0.014  loss_rpn_loc: 0.065  time: 1.0333  data_time: 0.0101  lr: 0.004396  max_mem: 5406M
[32m[04/20 19:15:02 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.537  loss_cls: 0.157  loss_box_reg: 0.309  loss_rpn_cls: 0.012  loss_rpn_loc: 0.046  time: 1.0335  data_time: 0.0098  lr: 0.004496  max_mem: 5406M
[32m[04/20 19:15:23 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.593  loss_cls: 0.196  loss_box_reg: 0.351  loss_rpn_cls: 0.011  loss_rpn_loc: 0.061  time: 1.0335  data_time: 0.0164  lr: 0.004595  max_mem: 5406M
[32m[04/20 19:15:44 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.580  loss_cls: 0.185  loss_box_reg: 0.338  loss_rpn_cls: 0.012  loss_rpn_loc: 0.043  time: 1.0335  data_time: 0.0099  lr: 0.004695  max_mem: 5406M
[32m[04/20 19:16:04 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.581  loss_cls: 0.186  loss_box_reg: 0.313  loss_rpn_cls: 0.011  loss_rpn_loc: 0.054  time: 1.0336  data_time: 0.0103  lr: 0.004795  max_mem: 5406M
[32m[04/20 19:16:25 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.585  loss_cls: 0.182  loss_box_reg: 0.336  loss_rpn_cls: 0.013  loss_rpn_loc: 0.047  time: 1.0339  data_time: 0.0095  lr: 0.004895  max_mem: 5406M
[5m[31mWARNING[0m [32m[04/20 19:16:54 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 19:16:54 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 19:16:54 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 19:16:54 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.609  loss_cls: 0.201  loss_box_reg: 0.340  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0339  data_time: 0.0094  lr: 0.004995  max_mem: 5406M
[32m[04/20 19:16:59 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:11 (1.0349 s / it)
[32m[04/20 19:16:59 d2.engine.hooks]: [0mTotal training time: 0:17:30 (0:00:18 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 19:17:02 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 19:17:02 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 19:17:02 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 19:17:05 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1164 s / img. ETA=0:16:25
[32m[04/20 19:17:10 d2.evaluation.evaluator]: [0mInference done 51/8355. 0.1170 s / img. ETA=0:17:12
[32m[04/20 19:17:15 d2.evaluation.evaluator]: [0mInference done 89/8355. 0.1170 s / img. ETA=0:17:37
[32m[04/20 19:17:20 d2.evaluation.evaluator]: [0mInference done 131/8355. 0.1170 s / img. ETA=0:17:18
[32m[04/20 19:17:25 d2.evaluation.evaluator]: [0mInference done 165/8355. 0.1170 s / img. ETA=0:17:53
[32m[04/20 19:17:30 d2.evaluation.evaluator]: [0mInference done 206/8355. 0.1171 s / img. ETA=0:17:34
[32m[04/20 19:17:35 d2.evaluation.evaluator]: [0mInference done 248/8355. 0.1172 s / img. ETA=0:17:16
[32m[04/20 19:17:40 d2.evaluation.evaluator]: [0mInference done 290/8355. 0.1172 s / img. ETA=0:17:02
[32m[04/20 19:17:45 d2.evaluation.evaluator]: [0mInference done 331/8355. 0.1172 s / img. ETA=0:16:55
[32m[04/20 19:17:50 d2.evaluation.evaluator]: [0mInference done 373/8355. 0.1172 s / img. ETA=0:16:43
[32m[04/20 19:17:55 d2.evaluation.evaluator]: [0mInference done 415/8355. 0.1173 s / img. ETA=0:16:34
[32m[04/20 19:18:00 d2.evaluation.evaluator]: [0mInference done 453/8355. 0.1174 s / img. ETA=0:16:34
[32m[04/20 19:18:05 d2.evaluation.evaluator]: [0mInference done 495/8355. 0.1174 s / img. ETA=0:16:25
[32m[04/20 19:18:11 d2.evaluation.evaluator]: [0mInference done 531/8355. 0.1173 s / img. ETA=0:16:35
[32m[04/20 19:18:16 d2.evaluation.evaluator]: [0mInference done 555/8355. 0.1173 s / img. ETA=0:17:00
[32m[04/20 19:18:21 d2.evaluation.evaluator]: [0mInference done 580/8355. 0.1173 s / img. ETA=0:17:21
[32m[04/20 19:18:26 d2.evaluation.evaluator]: [0mInference done 620/8355. 0.1173 s / img. ETA=0:17:11
[32m[04/20 19:18:31 d2.evaluation.evaluator]: [0mInference done 662/8355. 0.1173 s / img. ETA=0:16:59
[32m[04/20 19:18:36 d2.evaluation.evaluator]: [0mInference done 704/8355. 0.1173 s / img. ETA=0:16:48
[32m[04/20 19:18:41 d2.evaluation.evaluator]: [0mInference done 746/8355. 0.1173 s / img. ETA=0:16:38
[32m[04/20 19:18:46 d2.evaluation.evaluator]: [0mInference done 788/8355. 0.1173 s / img. ETA=0:16:27
[32m[04/20 19:18:51 d2.evaluation.evaluator]: [0mInference done 830/8355. 0.1174 s / img. ETA=0:16:19
[32m[04/20 19:18:56 d2.evaluation.evaluator]: [0mInference done 872/8355. 0.1174 s / img. ETA=0:16:10
[32m[04/20 19:19:01 d2.evaluation.evaluator]: [0mInference done 914/8355. 0.1174 s / img. ETA=0:16:02
[32m[04/20 19:19:07 d2.evaluation.evaluator]: [0mInference done 956/8355. 0.1174 s / img. ETA=0:15:53
[32m[04/20 19:19:12 d2.evaluation.evaluator]: [0mInference done 993/8355. 0.1174 s / img. ETA=0:15:52
[32m[04/20 19:19:17 d2.evaluation.evaluator]: [0mInference done 1032/8355. 0.1174 s / img. ETA=0:15:47
[32m[04/20 19:19:22 d2.evaluation.evaluator]: [0mInference done 1074/8355. 0.1174 s / img. ETA=0:15:39
[32m[04/20 19:19:27 d2.evaluation.evaluator]: [0mInference done 1116/8355. 0.1174 s / img. ETA=0:15:31
[32m[04/20 19:19:32 d2.evaluation.evaluator]: [0mInference done 1158/8355. 0.1174 s / img. ETA=0:15:23
[32m[04/20 19:19:37 d2.evaluation.evaluator]: [0mInference done 1200/8355. 0.1174 s / img. ETA=0:15:16
[32m[04/20 19:19:42 d2.evaluation.evaluator]: [0mInference done 1242/8355. 0.1175 s / img. ETA=0:15:08
[32m[04/20 19:19:47 d2.evaluation.evaluator]: [0mInference done 1283/8355. 0.1175 s / img. ETA=0:15:02
[32m[04/20 19:19:52 d2.evaluation.evaluator]: [0mInference done 1325/8355. 0.1175 s / img. ETA=0:14:55
[32m[04/20 19:19:57 d2.evaluation.evaluator]: [0mInference done 1366/8355. 0.1174 s / img. ETA=0:14:49
[32m[04/20 19:20:02 d2.evaluation.evaluator]: [0mInference done 1408/8355. 0.1174 s / img. ETA=0:14:43
[32m[04/20 19:20:07 d2.evaluation.evaluator]: [0mInference done 1450/8355. 0.1174 s / img. ETA=0:14:36
[32m[04/20 19:20:12 d2.evaluation.evaluator]: [0mInference done 1492/8355. 0.1175 s / img. ETA=0:14:29
[32m[04/20 19:20:17 d2.evaluation.evaluator]: [0mInference done 1534/8355. 0.1175 s / img. ETA=0:14:23
[32m[04/20 19:20:23 d2.evaluation.evaluator]: [0mInference done 1576/8355. 0.1175 s / img. ETA=0:14:17
[32m[04/20 19:20:28 d2.evaluation.evaluator]: [0mInference done 1617/8355. 0.1176 s / img. ETA=0:14:11
[32m[04/20 19:20:33 d2.evaluation.evaluator]: [0mInference done 1654/8355. 0.1176 s / img. ETA=0:14:07
[32m[04/20 19:20:38 d2.evaluation.evaluator]: [0mInference done 1695/8355. 0.1177 s / img. ETA=0:14:02
[32m[04/20 19:20:43 d2.evaluation.evaluator]: [0mInference done 1737/8355. 0.1177 s / img. ETA=0:13:56
[32m[04/20 19:20:48 d2.evaluation.evaluator]: [0mInference done 1779/8355. 0.1177 s / img. ETA=0:13:49
[32m[04/20 19:20:53 d2.evaluation.evaluator]: [0mInference done 1819/8355. 0.1177 s / img. ETA=0:13:44
[32m[04/20 19:20:58 d2.evaluation.evaluator]: [0mInference done 1861/8355. 0.1177 s / img. ETA=0:13:38
[32m[04/20 19:21:03 d2.evaluation.evaluator]: [0mInference done 1903/8355. 0.1178 s / img. ETA=0:13:32
[32m[04/20 19:21:08 d2.evaluation.evaluator]: [0mInference done 1944/8355. 0.1178 s / img. ETA=0:13:27
[32m[04/20 19:21:13 d2.evaluation.evaluator]: [0mInference done 1985/8355. 0.1178 s / img. ETA=0:13:21
[32m[04/20 19:21:18 d2.evaluation.evaluator]: [0mInference done 2027/8355. 0.1179 s / img. ETA=0:13:15
[32m[04/20 19:21:23 d2.evaluation.evaluator]: [0mInference done 2067/8355. 0.1179 s / img. ETA=0:13:10
[32m[04/20 19:21:28 d2.evaluation.evaluator]: [0mInference done 2109/8355. 0.1178 s / img. ETA=0:13:04
[32m[04/20 19:21:33 d2.evaluation.evaluator]: [0mInference done 2151/8355. 0.1178 s / img. ETA=0:12:59
[32m[04/20 19:21:39 d2.evaluation.evaluator]: [0mInference done 2193/8355. 0.1179 s / img. ETA=0:12:53
[32m[04/20 19:21:44 d2.evaluation.evaluator]: [0mInference done 2230/8355. 0.1179 s / img. ETA=0:12:49
[32m[04/20 19:21:49 d2.evaluation.evaluator]: [0mInference done 2270/8355. 0.1179 s / img. ETA=0:12:44
[32m[04/20 19:21:54 d2.evaluation.evaluator]: [0mInference done 2298/8355. 0.1179 s / img. ETA=0:12:45
[32m[04/20 19:21:59 d2.evaluation.evaluator]: [0mInference done 2338/8355. 0.1179 s / img. ETA=0:12:39
[32m[04/20 19:22:04 d2.evaluation.evaluator]: [0mInference done 2378/8355. 0.1179 s / img. ETA=0:12:34
[32m[04/20 19:22:09 d2.evaluation.evaluator]: [0mInference done 2413/8355. 0.1179 s / img. ETA=0:12:32
[32m[04/20 19:22:14 d2.evaluation.evaluator]: [0mInference done 2454/8355. 0.1179 s / img. ETA=0:12:27
[32m[04/20 19:22:19 d2.evaluation.evaluator]: [0mInference done 2485/8355. 0.1179 s / img. ETA=0:12:26
[32m[04/20 19:22:24 d2.evaluation.evaluator]: [0mInference done 2523/8355. 0.1179 s / img. ETA=0:12:22
[32m[04/20 19:22:30 d2.evaluation.evaluator]: [0mInference done 2562/8355. 0.1179 s / img. ETA=0:12:17
[32m[04/20 19:22:35 d2.evaluation.evaluator]: [0mInference done 2604/8355. 0.1179 s / img. ETA=0:12:11
[32m[04/20 19:22:40 d2.evaluation.evaluator]: [0mInference done 2646/8355. 0.1179 s / img. ETA=0:12:05
[32m[04/20 19:22:45 d2.evaluation.evaluator]: [0mInference done 2687/8355. 0.1180 s / img. ETA=0:12:00
[32m[04/20 19:22:50 d2.evaluation.evaluator]: [0mInference done 2726/8355. 0.1180 s / img. ETA=0:11:55
[32m[04/20 19:22:55 d2.evaluation.evaluator]: [0mInference done 2756/8355. 0.1180 s / img. ETA=0:11:53
[32m[04/20 19:23:00 d2.evaluation.evaluator]: [0mInference done 2794/8355. 0.1180 s / img. ETA=0:11:49
[32m[04/20 19:23:05 d2.evaluation.evaluator]: [0mInference done 2832/8355. 0.1180 s / img. ETA=0:11:45
[32m[04/20 19:23:10 d2.evaluation.evaluator]: [0mInference done 2854/8355. 0.1180 s / img. ETA=0:11:47
[32m[04/20 19:23:16 d2.evaluation.evaluator]: [0mInference done 2889/8355. 0.1180 s / img. ETA=0:11:44
[32m[04/20 19:23:21 d2.evaluation.evaluator]: [0mInference done 2918/8355. 0.1180 s / img. ETA=0:11:43
[32m[04/20 19:23:26 d2.evaluation.evaluator]: [0mInference done 2958/8355. 0.1180 s / img. ETA=0:11:38
[32m[04/20 19:23:31 d2.evaluation.evaluator]: [0mInference done 2992/8355. 0.1180 s / img. ETA=0:11:35
[32m[04/20 19:23:36 d2.evaluation.evaluator]: [0mInference done 3021/8355. 0.1180 s / img. ETA=0:11:33
[32m[04/20 19:23:42 d2.evaluation.evaluator]: [0mInference done 3048/8355. 0.1180 s / img. ETA=0:11:33
[32m[04/20 19:23:47 d2.evaluation.evaluator]: [0mInference done 3074/8355. 0.1180 s / img. ETA=0:11:32
[32m[04/20 19:23:52 d2.evaluation.evaluator]: [0mInference done 3116/8355. 0.1180 s / img. ETA=0:11:26
[32m[04/20 19:23:57 d2.evaluation.evaluator]: [0mInference done 3157/8355. 0.1180 s / img. ETA=0:11:20
[32m[04/20 19:24:02 d2.evaluation.evaluator]: [0mInference done 3199/8355. 0.1180 s / img. ETA=0:11:14
[32m[04/20 19:24:07 d2.evaluation.evaluator]: [0mInference done 3241/8355. 0.1180 s / img. ETA=0:11:08
[32m[04/20 19:24:12 d2.evaluation.evaluator]: [0mInference done 3283/8355. 0.1180 s / img. ETA=0:11:02
[32m[04/20 19:24:17 d2.evaluation.evaluator]: [0mInference done 3325/8355. 0.1180 s / img. ETA=0:10:55
[32m[04/20 19:24:22 d2.evaluation.evaluator]: [0mInference done 3367/8355. 0.1180 s / img. ETA=0:10:49
[32m[04/20 19:24:27 d2.evaluation.evaluator]: [0mInference done 3409/8355. 0.1180 s / img. ETA=0:10:43
[32m[04/20 19:24:32 d2.evaluation.evaluator]: [0mInference done 3451/8355. 0.1180 s / img. ETA=0:10:37
[32m[04/20 19:24:37 d2.evaluation.evaluator]: [0mInference done 3492/8355. 0.1180 s / img. ETA=0:10:32
[32m[04/20 19:24:42 d2.evaluation.evaluator]: [0mInference done 3534/8355. 0.1180 s / img. ETA=0:10:26
[32m[04/20 19:24:47 d2.evaluation.evaluator]: [0mInference done 3576/8355. 0.1180 s / img. ETA=0:10:20
[32m[04/20 19:24:52 d2.evaluation.evaluator]: [0mInference done 3617/8355. 0.1180 s / img. ETA=0:10:14
[32m[04/20 19:24:57 d2.evaluation.evaluator]: [0mInference done 3658/8355. 0.1180 s / img. ETA=0:10:08
[32m[04/20 19:25:02 d2.evaluation.evaluator]: [0mInference done 3699/8355. 0.1181 s / img. ETA=0:10:03
[32m[04/20 19:25:08 d2.evaluation.evaluator]: [0mInference done 3741/8355. 0.1181 s / img. ETA=0:09:57
[32m[04/20 19:25:13 d2.evaluation.evaluator]: [0mInference done 3783/8355. 0.1181 s / img. ETA=0:09:51
[32m[04/20 19:25:18 d2.evaluation.evaluator]: [0mInference done 3825/8355. 0.1181 s / img. ETA=0:09:45
[32m[04/20 19:25:23 d2.evaluation.evaluator]: [0mInference done 3867/8355. 0.1181 s / img. ETA=0:09:39
[32m[04/20 19:25:28 d2.evaluation.evaluator]: [0mInference done 3909/8355. 0.1181 s / img. ETA=0:09:33
[32m[04/20 19:25:33 d2.evaluation.evaluator]: [0mInference done 3950/8355. 0.1181 s / img. ETA=0:09:28
[32m[04/20 19:25:38 d2.evaluation.evaluator]: [0mInference done 3992/8355. 0.1181 s / img. ETA=0:09:22
[32m[04/20 19:25:43 d2.evaluation.evaluator]: [0mInference done 4033/8355. 0.1181 s / img. ETA=0:09:16
[32m[04/20 19:25:48 d2.evaluation.evaluator]: [0mInference done 4075/8355. 0.1181 s / img. ETA=0:09:11
[32m[04/20 19:25:53 d2.evaluation.evaluator]: [0mInference done 4117/8355. 0.1181 s / img. ETA=0:09:05
[32m[04/20 19:25:58 d2.evaluation.evaluator]: [0mInference done 4158/8355. 0.1181 s / img. ETA=0:08:59
[32m[04/20 19:26:03 d2.evaluation.evaluator]: [0mInference done 4199/8355. 0.1181 s / img. ETA=0:08:54
[32m[04/20 19:26:08 d2.evaluation.evaluator]: [0mInference done 4241/8355. 0.1181 s / img. ETA=0:08:48
[32m[04/20 19:26:13 d2.evaluation.evaluator]: [0mInference done 4283/8355. 0.1181 s / img. ETA=0:08:42
[32m[04/20 19:26:18 d2.evaluation.evaluator]: [0mInference done 4324/8355. 0.1181 s / img. ETA=0:08:37
[32m[04/20 19:26:23 d2.evaluation.evaluator]: [0mInference done 4366/8355. 0.1181 s / img. ETA=0:08:31
[32m[04/20 19:26:29 d2.evaluation.evaluator]: [0mInference done 4408/8355. 0.1181 s / img. ETA=0:08:26
[32m[04/20 19:26:34 d2.evaluation.evaluator]: [0mInference done 4450/8355. 0.1181 s / img. ETA=0:08:20
[32m[04/20 19:26:39 d2.evaluation.evaluator]: [0mInference done 4492/8355. 0.1181 s / img. ETA=0:08:14
[32m[04/20 19:26:44 d2.evaluation.evaluator]: [0mInference done 4534/8355. 0.1181 s / img. ETA=0:08:09
[32m[04/20 19:26:49 d2.evaluation.evaluator]: [0mInference done 4576/8355. 0.1181 s / img. ETA=0:08:03
[32m[04/20 19:26:54 d2.evaluation.evaluator]: [0mInference done 4618/8355. 0.1182 s / img. ETA=0:07:58
[32m[04/20 19:26:59 d2.evaluation.evaluator]: [0mInference done 4660/8355. 0.1182 s / img. ETA=0:07:52
[32m[04/20 19:27:04 d2.evaluation.evaluator]: [0mInference done 4702/8355. 0.1182 s / img. ETA=0:07:46
[32m[04/20 19:27:09 d2.evaluation.evaluator]: [0mInference done 4744/8355. 0.1182 s / img. ETA=0:07:41
[32m[04/20 19:27:14 d2.evaluation.evaluator]: [0mInference done 4785/8355. 0.1182 s / img. ETA=0:07:35
[32m[04/20 19:27:19 d2.evaluation.evaluator]: [0mInference done 4826/8355. 0.1182 s / img. ETA=0:07:30
[32m[04/20 19:27:24 d2.evaluation.evaluator]: [0mInference done 4867/8355. 0.1182 s / img. ETA=0:07:25
[32m[04/20 19:27:29 d2.evaluation.evaluator]: [0mInference done 4908/8355. 0.1182 s / img. ETA=0:07:19
[32m[04/20 19:27:34 d2.evaluation.evaluator]: [0mInference done 4949/8355. 0.1182 s / img. ETA=0:07:14
[32m[04/20 19:27:40 d2.evaluation.evaluator]: [0mInference done 4991/8355. 0.1182 s / img. ETA=0:07:08
[32m[04/20 19:27:45 d2.evaluation.evaluator]: [0mInference done 5032/8355. 0.1182 s / img. ETA=0:07:03
[32m[04/20 19:27:50 d2.evaluation.evaluator]: [0mInference done 5073/8355. 0.1182 s / img. ETA=0:06:58
[32m[04/20 19:27:55 d2.evaluation.evaluator]: [0mInference done 5114/8355. 0.1182 s / img. ETA=0:06:52
[32m[04/20 19:28:00 d2.evaluation.evaluator]: [0mInference done 5155/8355. 0.1182 s / img. ETA=0:06:47
[32m[04/20 19:28:05 d2.evaluation.evaluator]: [0mInference done 5196/8355. 0.1183 s / img. ETA=0:06:42
[32m[04/20 19:28:10 d2.evaluation.evaluator]: [0mInference done 5238/8355. 0.1183 s / img. ETA=0:06:36
[32m[04/20 19:28:15 d2.evaluation.evaluator]: [0mInference done 5280/8355. 0.1183 s / img. ETA=0:06:31
[32m[04/20 19:28:20 d2.evaluation.evaluator]: [0mInference done 5321/8355. 0.1183 s / img. ETA=0:06:25
[32m[04/20 19:28:25 d2.evaluation.evaluator]: [0mInference done 5363/8355. 0.1183 s / img. ETA=0:06:20
[32m[04/20 19:28:30 d2.evaluation.evaluator]: [0mInference done 5404/8355. 0.1183 s / img. ETA=0:06:15
[32m[04/20 19:28:35 d2.evaluation.evaluator]: [0mInference done 5446/8355. 0.1183 s / img. ETA=0:06:09
[32m[04/20 19:28:40 d2.evaluation.evaluator]: [0mInference done 5488/8355. 0.1183 s / img. ETA=0:06:04
[32m[04/20 19:28:45 d2.evaluation.evaluator]: [0mInference done 5530/8355. 0.1183 s / img. ETA=0:05:58
[32m[04/20 19:28:50 d2.evaluation.evaluator]: [0mInference done 5572/8355. 0.1183 s / img. ETA=0:05:53
[32m[04/20 19:28:56 d2.evaluation.evaluator]: [0mInference done 5614/8355. 0.1183 s / img. ETA=0:05:47
[32m[04/20 19:29:01 d2.evaluation.evaluator]: [0mInference done 5656/8355. 0.1183 s / img. ETA=0:05:42
[32m[04/20 19:29:06 d2.evaluation.evaluator]: [0mInference done 5698/8355. 0.1183 s / img. ETA=0:05:36
[32m[04/20 19:29:11 d2.evaluation.evaluator]: [0mInference done 5740/8355. 0.1183 s / img. ETA=0:05:31
[32m[04/20 19:29:16 d2.evaluation.evaluator]: [0mInference done 5782/8355. 0.1183 s / img. ETA=0:05:26
[32m[04/20 19:29:21 d2.evaluation.evaluator]: [0mInference done 5824/8355. 0.1183 s / img. ETA=0:05:20
[32m[04/20 19:29:26 d2.evaluation.evaluator]: [0mInference done 5865/8355. 0.1183 s / img. ETA=0:05:15
[32m[04/20 19:29:31 d2.evaluation.evaluator]: [0mInference done 5907/8355. 0.1183 s / img. ETA=0:05:09
[32m[04/20 19:29:36 d2.evaluation.evaluator]: [0mInference done 5948/8355. 0.1183 s / img. ETA=0:05:04
[32m[04/20 19:29:41 d2.evaluation.evaluator]: [0mInference done 5990/8355. 0.1183 s / img. ETA=0:04:59
[32m[04/20 19:29:46 d2.evaluation.evaluator]: [0mInference done 6032/8355. 0.1183 s / img. ETA=0:04:53
[32m[04/20 19:29:51 d2.evaluation.evaluator]: [0mInference done 6074/8355. 0.1183 s / img. ETA=0:04:48
[32m[04/20 19:29:57 d2.evaluation.evaluator]: [0mInference done 6116/8355. 0.1183 s / img. ETA=0:04:43
[32m[04/20 19:30:02 d2.evaluation.evaluator]: [0mInference done 6158/8355. 0.1183 s / img. ETA=0:04:37
[32m[04/20 19:30:07 d2.evaluation.evaluator]: [0mInference done 6200/8355. 0.1183 s / img. ETA=0:04:32
[32m[04/20 19:30:12 d2.evaluation.evaluator]: [0mInference done 6242/8355. 0.1183 s / img. ETA=0:04:26
[32m[04/20 19:30:17 d2.evaluation.evaluator]: [0mInference done 6284/8355. 0.1183 s / img. ETA=0:04:21
[32m[04/20 19:30:22 d2.evaluation.evaluator]: [0mInference done 6326/8355. 0.1183 s / img. ETA=0:04:16
[32m[04/20 19:30:27 d2.evaluation.evaluator]: [0mInference done 6368/8355. 0.1183 s / img. ETA=0:04:10
[32m[04/20 19:30:32 d2.evaluation.evaluator]: [0mInference done 6410/8355. 0.1183 s / img. ETA=0:04:05
[32m[04/20 19:30:37 d2.evaluation.evaluator]: [0mInference done 6452/8355. 0.1183 s / img. ETA=0:04:00
[32m[04/20 19:30:42 d2.evaluation.evaluator]: [0mInference done 6494/8355. 0.1183 s / img. ETA=0:03:54
[32m[04/20 19:30:47 d2.evaluation.evaluator]: [0mInference done 6536/8355. 0.1183 s / img. ETA=0:03:49
[32m[04/20 19:30:52 d2.evaluation.evaluator]: [0mInference done 6578/8355. 0.1183 s / img. ETA=0:03:43
[32m[04/20 19:30:57 d2.evaluation.evaluator]: [0mInference done 6620/8355. 0.1183 s / img. ETA=0:03:38
[32m[04/20 19:31:03 d2.evaluation.evaluator]: [0mInference done 6662/8355. 0.1183 s / img. ETA=0:03:33
[32m[04/20 19:31:08 d2.evaluation.evaluator]: [0mInference done 6704/8355. 0.1183 s / img. ETA=0:03:27
[32m[04/20 19:31:13 d2.evaluation.evaluator]: [0mInference done 6746/8355. 0.1183 s / img. ETA=0:03:22
[32m[04/20 19:31:18 d2.evaluation.evaluator]: [0mInference done 6788/8355. 0.1183 s / img. ETA=0:03:17
[32m[04/20 19:31:23 d2.evaluation.evaluator]: [0mInference done 6830/8355. 0.1183 s / img. ETA=0:03:11
[32m[04/20 19:31:28 d2.evaluation.evaluator]: [0mInference done 6872/8355. 0.1183 s / img. ETA=0:03:06
[32m[04/20 19:31:33 d2.evaluation.evaluator]: [0mInference done 6914/8355. 0.1183 s / img. ETA=0:03:01
[32m[04/20 19:31:38 d2.evaluation.evaluator]: [0mInference done 6956/8355. 0.1183 s / img. ETA=0:02:55
[32m[04/20 19:31:43 d2.evaluation.evaluator]: [0mInference done 6997/8355. 0.1183 s / img. ETA=0:02:50
[32m[04/20 19:31:48 d2.evaluation.evaluator]: [0mInference done 7039/8355. 0.1183 s / img. ETA=0:02:45
[32m[04/20 19:31:53 d2.evaluation.evaluator]: [0mInference done 7080/8355. 0.1183 s / img. ETA=0:02:40
[32m[04/20 19:31:58 d2.evaluation.evaluator]: [0mInference done 7121/8355. 0.1183 s / img. ETA=0:02:35
[32m[04/20 19:32:03 d2.evaluation.evaluator]: [0mInference done 7162/8355. 0.1183 s / img. ETA=0:02:29
[32m[04/20 19:32:08 d2.evaluation.evaluator]: [0mInference done 7204/8355. 0.1183 s / img. ETA=0:02:24
[32m[04/20 19:32:13 d2.evaluation.evaluator]: [0mInference done 7245/8355. 0.1184 s / img. ETA=0:02:19
[32m[04/20 19:32:18 d2.evaluation.evaluator]: [0mInference done 7286/8355. 0.1184 s / img. ETA=0:02:14
[32m[04/20 19:32:23 d2.evaluation.evaluator]: [0mInference done 7327/8355. 0.1184 s / img. ETA=0:02:09
[32m[04/20 19:32:28 d2.evaluation.evaluator]: [0mInference done 7368/8355. 0.1184 s / img. ETA=0:02:03
[32m[04/20 19:32:33 d2.evaluation.evaluator]: [0mInference done 7409/8355. 0.1184 s / img. ETA=0:01:58
[32m[04/20 19:32:38 d2.evaluation.evaluator]: [0mInference done 7450/8355. 0.1184 s / img. ETA=0:01:53
[32m[04/20 19:32:43 d2.evaluation.evaluator]: [0mInference done 7491/8355. 0.1184 s / img. ETA=0:01:48
[32m[04/20 19:32:48 d2.evaluation.evaluator]: [0mInference done 7532/8355. 0.1184 s / img. ETA=0:01:43
[32m[04/20 19:32:53 d2.evaluation.evaluator]: [0mInference done 7573/8355. 0.1184 s / img. ETA=0:01:38
[32m[04/20 19:32:58 d2.evaluation.evaluator]: [0mInference done 7614/8355. 0.1184 s / img. ETA=0:01:32
[32m[04/20 19:33:03 d2.evaluation.evaluator]: [0mInference done 7655/8355. 0.1184 s / img. ETA=0:01:27
[32m[04/20 19:33:09 d2.evaluation.evaluator]: [0mInference done 7696/8355. 0.1184 s / img. ETA=0:01:22
[32m[04/20 19:33:14 d2.evaluation.evaluator]: [0mInference done 7737/8355. 0.1184 s / img. ETA=0:01:17
[32m[04/20 19:33:19 d2.evaluation.evaluator]: [0mInference done 7778/8355. 0.1184 s / img. ETA=0:01:12
[32m[04/20 19:33:24 d2.evaluation.evaluator]: [0mInference done 7819/8355. 0.1185 s / img. ETA=0:01:07
[32m[04/20 19:33:29 d2.evaluation.evaluator]: [0mInference done 7860/8355. 0.1185 s / img. ETA=0:01:02
[32m[04/20 19:33:34 d2.evaluation.evaluator]: [0mInference done 7901/8355. 0.1185 s / img. ETA=0:00:56
[32m[04/20 19:33:39 d2.evaluation.evaluator]: [0mInference done 7942/8355. 0.1185 s / img. ETA=0:00:51
[32m[04/20 19:33:44 d2.evaluation.evaluator]: [0mInference done 7983/8355. 0.1185 s / img. ETA=0:00:46
[32m[04/20 19:33:49 d2.evaluation.evaluator]: [0mInference done 8024/8355. 0.1185 s / img. ETA=0:00:41
[32m[04/20 19:33:54 d2.evaluation.evaluator]: [0mInference done 8065/8355. 0.1185 s / img. ETA=0:00:36
[32m[04/20 19:33:59 d2.evaluation.evaluator]: [0mInference done 8107/8355. 0.1185 s / img. ETA=0:00:31
[32m[04/20 19:34:04 d2.evaluation.evaluator]: [0mInference done 8149/8355. 0.1185 s / img. ETA=0:00:25
[32m[04/20 19:34:09 d2.evaluation.evaluator]: [0mInference done 8191/8355. 0.1185 s / img. ETA=0:00:20
[32m[04/20 19:34:14 d2.evaluation.evaluator]: [0mInference done 8233/8355. 0.1185 s / img. ETA=0:00:15
[32m[04/20 19:34:19 d2.evaluation.evaluator]: [0mInference done 8275/8355. 0.1185 s / img. ETA=0:00:10
[32m[04/20 19:34:24 d2.evaluation.evaluator]: [0mInference done 8317/8355. 0.1185 s / img. ETA=0:00:04
[32m[04/20 19:34:29 d2.evaluation.evaluator]: [0mTotal inference time: 0:17:24.832442 (0.125130 s / img per device, on 1 devices)
[32m[04/20 19:34:29 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:29 (0.118466 s / img per device, on 1 devices)
[32m[04/20 19:34:29 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 19:34:29 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 19:34:29 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.53s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=30.37s).
Accumulating evaluation results...
DONE (t=3.86s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.406
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.752
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.380
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.293
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.536
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.159
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.451
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.373
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.705
[32m[04/20 19:35:04 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.606 | 75.192 | 38.041 | 29.293 | 53.632 | 66.631 |
[32m[04/20 19:35:04 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 41.075 | bicycle       | 30.323 | car            | 50.421 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 19:35:06 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 19:35:06 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 19:35:06 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 19:35:08 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1188 s / img. ETA=0:02:31
[32m[04/20 19:35:13 d2.evaluation.evaluator]: [0mInference done 52/1257. 0.1189 s / img. ETA=0:02:26
[32m[04/20 19:35:18 d2.evaluation.evaluator]: [0mInference done 93/1257. 0.1189 s / img. ETA=0:02:22
[32m[04/20 19:35:23 d2.evaluation.evaluator]: [0mInference done 135/1257. 0.1188 s / img. ETA=0:02:16
[32m[04/20 19:35:28 d2.evaluation.evaluator]: [0mInference done 177/1257. 0.1186 s / img. ETA=0:02:11
[32m[04/20 19:35:33 d2.evaluation.evaluator]: [0mInference done 219/1257. 0.1186 s / img. ETA=0:02:06
[32m[04/20 19:35:38 d2.evaluation.evaluator]: [0mInference done 260/1257. 0.1187 s / img. ETA=0:02:01
[32m[04/20 19:35:43 d2.evaluation.evaluator]: [0mInference done 301/1257. 0.1189 s / img. ETA=0:01:56
[32m[04/20 19:35:48 d2.evaluation.evaluator]: [0mInference done 343/1257. 0.1188 s / img. ETA=0:01:51
[32m[04/20 19:35:53 d2.evaluation.evaluator]: [0mInference done 385/1257. 0.1188 s / img. ETA=0:01:46
[32m[04/20 19:35:58 d2.evaluation.evaluator]: [0mInference done 427/1257. 0.1188 s / img. ETA=0:01:41
[32m[04/20 19:36:04 d2.evaluation.evaluator]: [0mInference done 469/1257. 0.1188 s / img. ETA=0:01:35
[32m[04/20 19:36:09 d2.evaluation.evaluator]: [0mInference done 510/1257. 0.1188 s / img. ETA=0:01:30
[32m[04/20 19:36:14 d2.evaluation.evaluator]: [0mInference done 551/1257. 0.1189 s / img. ETA=0:01:26
[32m[04/20 19:36:19 d2.evaluation.evaluator]: [0mInference done 592/1257. 0.1190 s / img. ETA=0:01:21
[32m[04/20 19:36:24 d2.evaluation.evaluator]: [0mInference done 633/1257. 0.1190 s / img. ETA=0:01:16
[32m[04/20 19:36:29 d2.evaluation.evaluator]: [0mInference done 674/1257. 0.1190 s / img. ETA=0:01:11
[32m[04/20 19:36:34 d2.evaluation.evaluator]: [0mInference done 715/1257. 0.1191 s / img. ETA=0:01:06
[32m[04/20 19:36:39 d2.evaluation.evaluator]: [0mInference done 757/1257. 0.1191 s / img. ETA=0:01:01
[32m[04/20 19:36:44 d2.evaluation.evaluator]: [0mInference done 799/1257. 0.1190 s / img. ETA=0:00:55
[32m[04/20 19:36:49 d2.evaluation.evaluator]: [0mInference done 841/1257. 0.1191 s / img. ETA=0:00:50
[32m[04/20 19:36:54 d2.evaluation.evaluator]: [0mInference done 882/1257. 0.1191 s / img. ETA=0:00:45
[32m[04/20 19:36:59 d2.evaluation.evaluator]: [0mInference done 924/1257. 0.1190 s / img. ETA=0:00:40
[32m[04/20 19:37:04 d2.evaluation.evaluator]: [0mInference done 966/1257. 0.1190 s / img. ETA=0:00:35
[32m[04/20 19:37:09 d2.evaluation.evaluator]: [0mInference done 1007/1257. 0.1191 s / img. ETA=0:00:30
[32m[04/20 19:37:14 d2.evaluation.evaluator]: [0mInference done 1049/1257. 0.1190 s / img. ETA=0:00:25
[32m[04/20 19:37:19 d2.evaluation.evaluator]: [0mInference done 1091/1257. 0.1190 s / img. ETA=0:00:20
[32m[04/20 19:37:24 d2.evaluation.evaluator]: [0mInference done 1132/1257. 0.1191 s / img. ETA=0:00:15
[32m[04/20 19:37:29 d2.evaluation.evaluator]: [0mInference done 1173/1257. 0.1191 s / img. ETA=0:00:10
[32m[04/20 19:37:35 d2.evaluation.evaluator]: [0mInference done 1214/1257. 0.1191 s / img. ETA=0:00:05
[32m[04/20 19:37:40 d2.evaluation.evaluator]: [0mInference done 1256/1257. 0.1191 s / img. ETA=0:00:00
[32m[04/20 19:37:40 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:32.743553 (0.122000 s / img per device, on 1 devices)
[32m[04/20 19:37:40 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:29 (0.119062 s / img per device, on 1 devices)
[32m[04/20 19:37:40 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 19:37:40 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 19:37:40 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=4.55s).
Accumulating evaluation results...
DONE (t=0.62s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.580
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.258
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.457
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.146
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.271
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.417
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.525
[32m[04/20 19:37:45 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 29.551 | 57.952 | 25.818 | 18.934 | 35.696 | 45.705 |
[32m[04/20 19:37:45 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 30.315 | bicycle       | 11.805 | car            | 46.534 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  23  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 19:37:46 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 19:37:46 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 19:37:46 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 19:37:47 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 19:37:47 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 19:37:47 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 19:37:47 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 19:38:07 d2.utils.events]: [0m eta: 0:16:33  iter: 19  total_loss: 0.610  loss_cls: 0.185  loss_box_reg: 0.333  loss_rpn_cls: 0.015  loss_rpn_loc: 0.057  time: 1.0073  data_time: 0.0340  lr: 0.000100  max_mem: 5406M
[32m[04/20 19:38:28 d2.utils.events]: [0m eta: 0:16:14  iter: 39  total_loss: 0.592  loss_cls: 0.195  loss_box_reg: 0.326  loss_rpn_cls: 0.017  loss_rpn_loc: 0.048  time: 1.0108  data_time: 0.0106  lr: 0.000200  max_mem: 5406M
[32m[04/20 19:38:48 d2.utils.events]: [0m eta: 0:15:58  iter: 59  total_loss: 0.645  loss_cls: 0.194  loss_box_reg: 0.365  loss_rpn_cls: 0.012  loss_rpn_loc: 0.053  time: 1.0115  data_time: 0.0124  lr: 0.000300  max_mem: 5406M
[32m[04/20 19:39:08 d2.utils.events]: [0m eta: 0:15:40  iter: 79  total_loss: 0.559  loss_cls: 0.190  loss_box_reg: 0.320  loss_rpn_cls: 0.014  loss_rpn_loc: 0.044  time: 1.0148  data_time: 0.0107  lr: 0.000400  max_mem: 5406M
[32m[04/20 19:39:29 d2.utils.events]: [0m eta: 0:15:19  iter: 99  total_loss: 0.624  loss_cls: 0.200  loss_box_reg: 0.360  loss_rpn_cls: 0.013  loss_rpn_loc: 0.058  time: 1.0137  data_time: 0.0105  lr: 0.000500  max_mem: 5406M
[32m[04/20 19:39:50 d2.utils.events]: [0m eta: 0:15:03  iter: 119  total_loss: 0.512  loss_cls: 0.162  loss_box_reg: 0.295  loss_rpn_cls: 0.009  loss_rpn_loc: 0.043  time: 1.0224  data_time: 0.0124  lr: 0.000599  max_mem: 5406M
[32m[04/20 19:40:11 d2.utils.events]: [0m eta: 0:14:43  iter: 139  total_loss: 0.579  loss_cls: 0.186  loss_box_reg: 0.323  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 1.0249  data_time: 0.0112  lr: 0.000699  max_mem: 5406M
[32m[04/20 19:40:32 d2.utils.events]: [0m eta: 0:14:29  iter: 159  total_loss: 0.572  loss_cls: 0.176  loss_box_reg: 0.323  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 1.0270  data_time: 0.0110  lr: 0.000799  max_mem: 5406M
[32m[04/20 19:40:53 d2.utils.events]: [0m eta: 0:14:19  iter: 179  total_loss: 0.540  loss_cls: 0.166  loss_box_reg: 0.304  loss_rpn_cls: 0.015  loss_rpn_loc: 0.040  time: 1.0291  data_time: 0.0113  lr: 0.000899  max_mem: 5406M
[32m[04/20 19:41:14 d2.utils.events]: [0m eta: 0:14:02  iter: 199  total_loss: 0.565  loss_cls: 0.181  loss_box_reg: 0.329  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 1.0312  data_time: 0.0114  lr: 0.000999  max_mem: 5406M
[32m[04/20 19:41:35 d2.utils.events]: [0m eta: 0:13:41  iter: 219  total_loss: 0.660  loss_cls: 0.222  loss_box_reg: 0.359  loss_rpn_cls: 0.013  loss_rpn_loc: 0.057  time: 1.0322  data_time: 0.0106  lr: 0.001099  max_mem: 5406M
[32m[04/20 19:41:55 d2.utils.events]: [0m eta: 0:13:18  iter: 239  total_loss: 0.558  loss_cls: 0.169  loss_box_reg: 0.312  loss_rpn_cls: 0.009  loss_rpn_loc: 0.051  time: 1.0319  data_time: 0.0116  lr: 0.001199  max_mem: 5406M
[32m[04/20 19:42:16 d2.utils.events]: [0m eta: 0:12:58  iter: 259  total_loss: 0.529  loss_cls: 0.168  loss_box_reg: 0.316  loss_rpn_cls: 0.010  loss_rpn_loc: 0.046  time: 1.0338  data_time: 0.0107  lr: 0.001299  max_mem: 5406M
[32m[04/20 19:42:37 d2.utils.events]: [0m eta: 0:12:36  iter: 279  total_loss: 0.613  loss_cls: 0.197  loss_box_reg: 0.345  loss_rpn_cls: 0.013  loss_rpn_loc: 0.046  time: 1.0338  data_time: 0.0102  lr: 0.001399  max_mem: 5406M
[32m[04/20 19:42:58 d2.utils.events]: [0m eta: 0:12:12  iter: 299  total_loss: 0.557  loss_cls: 0.149  loss_box_reg: 0.334  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 1.0327  data_time: 0.0107  lr: 0.001499  max_mem: 5406M
[32m[04/20 19:43:18 d2.utils.events]: [0m eta: 0:11:50  iter: 319  total_loss: 0.523  loss_cls: 0.178  loss_box_reg: 0.301  loss_rpn_cls: 0.013  loss_rpn_loc: 0.046  time: 1.0324  data_time: 0.0113  lr: 0.001598  max_mem: 5406M
[32m[04/20 19:43:39 d2.utils.events]: [0m eta: 0:11:29  iter: 339  total_loss: 0.560  loss_cls: 0.181  loss_box_reg: 0.326  loss_rpn_cls: 0.010  loss_rpn_loc: 0.049  time: 1.0319  data_time: 0.0111  lr: 0.001698  max_mem: 5406M
[32m[04/20 19:43:59 d2.utils.events]: [0m eta: 0:11:08  iter: 359  total_loss: 0.599  loss_cls: 0.192  loss_box_reg: 0.340  loss_rpn_cls: 0.013  loss_rpn_loc: 0.057  time: 1.0309  data_time: 0.0112  lr: 0.001798  max_mem: 5406M
[32m[04/20 19:44:20 d2.utils.events]: [0m eta: 0:10:47  iter: 379  total_loss: 0.620  loss_cls: 0.186  loss_box_reg: 0.346  loss_rpn_cls: 0.013  loss_rpn_loc: 0.054  time: 1.0304  data_time: 0.0124  lr: 0.001898  max_mem: 5406M
[32m[04/20 19:44:40 d2.utils.events]: [0m eta: 0:10:25  iter: 399  total_loss: 0.507  loss_cls: 0.156  loss_box_reg: 0.285  loss_rpn_cls: 0.008  loss_rpn_loc: 0.045  time: 1.0304  data_time: 0.0111  lr: 0.001998  max_mem: 5406M
[32m[04/20 19:45:01 d2.utils.events]: [0m eta: 0:10:03  iter: 419  total_loss: 0.537  loss_cls: 0.171  loss_box_reg: 0.304  loss_rpn_cls: 0.010  loss_rpn_loc: 0.056  time: 1.0298  data_time: 0.0122  lr: 0.002098  max_mem: 5406M
[32m[04/20 19:45:22 d2.utils.events]: [0m eta: 0:09:43  iter: 439  total_loss: 0.557  loss_cls: 0.174  loss_box_reg: 0.315  loss_rpn_cls: 0.009  loss_rpn_loc: 0.054  time: 1.0306  data_time: 0.0109  lr: 0.002198  max_mem: 5406M
[32m[04/20 19:45:42 d2.utils.events]: [0m eta: 0:09:24  iter: 459  total_loss: 0.552  loss_cls: 0.167  loss_box_reg: 0.317  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 1.0312  data_time: 0.0111  lr: 0.002298  max_mem: 5406M
[32m[04/20 19:46:03 d2.utils.events]: [0m eta: 0:09:03  iter: 479  total_loss: 0.548  loss_cls: 0.183  loss_box_reg: 0.319  loss_rpn_cls: 0.011  loss_rpn_loc: 0.046  time: 1.0316  data_time: 0.0109  lr: 0.002398  max_mem: 5406M
[32m[04/20 19:46:24 d2.utils.events]: [0m eta: 0:08:42  iter: 499  total_loss: 0.525  loss_cls: 0.169  loss_box_reg: 0.304  loss_rpn_cls: 0.011  loss_rpn_loc: 0.041  time: 1.0320  data_time: 0.0115  lr: 0.002498  max_mem: 5406M
[32m[04/20 19:46:45 d2.utils.events]: [0m eta: 0:08:21  iter: 519  total_loss: 0.516  loss_cls: 0.174  loss_box_reg: 0.291  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0314  data_time: 0.0110  lr: 0.002597  max_mem: 5406M
[32m[04/20 19:47:05 d2.utils.events]: [0m eta: 0:07:58  iter: 539  total_loss: 0.485  loss_cls: 0.156  loss_box_reg: 0.290  loss_rpn_cls: 0.011  loss_rpn_loc: 0.046  time: 1.0306  data_time: 0.0103  lr: 0.002697  max_mem: 5406M
[32m[04/20 19:47:26 d2.utils.events]: [0m eta: 0:07:38  iter: 559  total_loss: 0.593  loss_cls: 0.180  loss_box_reg: 0.327  loss_rpn_cls: 0.009  loss_rpn_loc: 0.055  time: 1.0307  data_time: 0.0104  lr: 0.002797  max_mem: 5406M
[32m[04/20 19:47:46 d2.utils.events]: [0m eta: 0:07:17  iter: 579  total_loss: 0.556  loss_cls: 0.173  loss_box_reg: 0.309  loss_rpn_cls: 0.013  loss_rpn_loc: 0.060  time: 1.0307  data_time: 0.0103  lr: 0.002897  max_mem: 5406M
[32m[04/20 19:48:07 d2.utils.events]: [0m eta: 0:06:56  iter: 599  total_loss: 0.595  loss_cls: 0.184  loss_box_reg: 0.326  loss_rpn_cls: 0.014  loss_rpn_loc: 0.067  time: 1.0304  data_time: 0.0098  lr: 0.002997  max_mem: 5406M
[32m[04/20 19:48:28 d2.utils.events]: [0m eta: 0:06:36  iter: 619  total_loss: 0.598  loss_cls: 0.175  loss_box_reg: 0.347  loss_rpn_cls: 0.011  loss_rpn_loc: 0.050  time: 1.0311  data_time: 0.0120  lr: 0.003097  max_mem: 5406M
[32m[04/20 19:48:48 d2.utils.events]: [0m eta: 0:06:15  iter: 639  total_loss: 0.558  loss_cls: 0.169  loss_box_reg: 0.316  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0308  data_time: 0.0113  lr: 0.003197  max_mem: 5406M
[32m[04/20 19:49:09 d2.utils.events]: [0m eta: 0:05:54  iter: 659  total_loss: 0.576  loss_cls: 0.194  loss_box_reg: 0.325  loss_rpn_cls: 0.013  loss_rpn_loc: 0.050  time: 1.0308  data_time: 0.0102  lr: 0.003297  max_mem: 5406M
[32m[04/20 19:49:30 d2.utils.events]: [0m eta: 0:05:33  iter: 679  total_loss: 0.612  loss_cls: 0.198  loss_box_reg: 0.346  loss_rpn_cls: 0.009  loss_rpn_loc: 0.054  time: 1.0309  data_time: 0.0110  lr: 0.003397  max_mem: 5406M
[32m[04/20 19:49:51 d2.utils.events]: [0m eta: 0:05:13  iter: 699  total_loss: 0.575  loss_cls: 0.185  loss_box_reg: 0.326  loss_rpn_cls: 0.014  loss_rpn_loc: 0.046  time: 1.0319  data_time: 0.0116  lr: 0.003497  max_mem: 5406M
[32m[04/20 19:50:12 d2.utils.events]: [0m eta: 0:04:53  iter: 719  total_loss: 0.646  loss_cls: 0.207  loss_box_reg: 0.356  loss_rpn_cls: 0.014  loss_rpn_loc: 0.069  time: 1.0327  data_time: 0.0118  lr: 0.003596  max_mem: 5406M
[32m[04/20 19:50:33 d2.utils.events]: [0m eta: 0:04:32  iter: 739  total_loss: 0.614  loss_cls: 0.187  loss_box_reg: 0.347  loss_rpn_cls: 0.013  loss_rpn_loc: 0.067  time: 1.0334  data_time: 0.0121  lr: 0.003696  max_mem: 5406M
[32m[04/20 19:50:55 d2.utils.events]: [0m eta: 0:04:12  iter: 759  total_loss: 0.543  loss_cls: 0.161  loss_box_reg: 0.311  loss_rpn_cls: 0.011  loss_rpn_loc: 0.044  time: 1.0339  data_time: 0.0112  lr: 0.003796  max_mem: 5406M
[32m[04/20 19:51:16 d2.utils.events]: [0m eta: 0:03:51  iter: 779  total_loss: 0.587  loss_cls: 0.178  loss_box_reg: 0.341  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 1.0345  data_time: 0.0110  lr: 0.003896  max_mem: 5406M
[32m[04/20 19:51:36 d2.utils.events]: [0m eta: 0:03:30  iter: 799  total_loss: 0.590  loss_cls: 0.188  loss_box_reg: 0.340  loss_rpn_cls: 0.014  loss_rpn_loc: 0.046  time: 1.0343  data_time: 0.0110  lr: 0.003996  max_mem: 5406M
[32m[04/20 19:51:57 d2.utils.events]: [0m eta: 0:03:09  iter: 819  total_loss: 0.622  loss_cls: 0.191  loss_box_reg: 0.346  loss_rpn_cls: 0.015  loss_rpn_loc: 0.060  time: 1.0337  data_time: 0.0106  lr: 0.004096  max_mem: 5406M
[32m[04/20 19:52:17 d2.utils.events]: [0m eta: 0:02:48  iter: 839  total_loss: 0.577  loss_cls: 0.187  loss_box_reg: 0.318  loss_rpn_cls: 0.016  loss_rpn_loc: 0.057  time: 1.0337  data_time: 0.0102  lr: 0.004196  max_mem: 5406M
[32m[04/20 19:52:38 d2.utils.events]: [0m eta: 0:02:27  iter: 859  total_loss: 0.578  loss_cls: 0.183  loss_box_reg: 0.335  loss_rpn_cls: 0.013  loss_rpn_loc: 0.051  time: 1.0339  data_time: 0.0109  lr: 0.004296  max_mem: 5406M
[32m[04/20 19:52:59 d2.utils.events]: [0m eta: 0:02:06  iter: 879  total_loss: 0.568  loss_cls: 0.196  loss_box_reg: 0.305  loss_rpn_cls: 0.014  loss_rpn_loc: 0.056  time: 1.0342  data_time: 0.0107  lr: 0.004396  max_mem: 5406M
[32m[04/20 19:53:20 d2.utils.events]: [0m eta: 0:01:45  iter: 899  total_loss: 0.584  loss_cls: 0.187  loss_box_reg: 0.319  loss_rpn_cls: 0.010  loss_rpn_loc: 0.051  time: 1.0338  data_time: 0.0103  lr: 0.004496  max_mem: 5406M
[32m[04/20 19:53:40 d2.utils.events]: [0m eta: 0:01:24  iter: 919  total_loss: 0.663  loss_cls: 0.208  loss_box_reg: 0.356  loss_rpn_cls: 0.016  loss_rpn_loc: 0.052  time: 1.0339  data_time: 0.0106  lr: 0.004595  max_mem: 5406M
[32m[04/20 19:54:01 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.524  loss_cls: 0.178  loss_box_reg: 0.303  loss_rpn_cls: 0.017  loss_rpn_loc: 0.057  time: 1.0340  data_time: 0.0106  lr: 0.004695  max_mem: 5406M
[32m[04/20 19:54:21 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.577  loss_cls: 0.174  loss_box_reg: 0.304  loss_rpn_cls: 0.013  loss_rpn_loc: 0.050  time: 1.0332  data_time: 0.0107  lr: 0.004795  max_mem: 5406M
[32m[04/20 19:54:41 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.539  loss_cls: 0.168  loss_box_reg: 0.306  loss_rpn_cls: 0.013  loss_rpn_loc: 0.054  time: 1.0325  data_time: 0.0117  lr: 0.004895  max_mem: 5406M
[5m[31mWARNING[0m [32m[04/20 19:55:05 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 19:55:05 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 19:55:05 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 19:55:05 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.584  loss_cls: 0.184  loss_box_reg: 0.328  loss_rpn_cls: 0.013  loss_rpn_loc: 0.062  time: 1.0323  data_time: 0.0106  lr: 0.004995  max_mem: 5406M
[32m[04/20 19:55:07 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:10 (1.0333 s / it)
[32m[04/20 19:55:07 d2.engine.hooks]: [0mTotal training time: 0:17:17 (0:00:07 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 19:55:10 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 19:55:10 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 19:55:11 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 19:55:12 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1175 s / img. ETA=0:16:40
[32m[04/20 19:55:17 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1178 s / img. ETA=0:16:40
[32m[04/20 19:55:23 d2.evaluation.evaluator]: [0mInference done 95/8355. 0.1178 s / img. ETA=0:16:36
[32m[04/20 19:55:28 d2.evaluation.evaluator]: [0mInference done 137/8355. 0.1178 s / img. ETA=0:16:31
[32m[04/20 19:55:33 d2.evaluation.evaluator]: [0mInference done 179/8355. 0.1175 s / img. ETA=0:16:23
[32m[04/20 19:55:38 d2.evaluation.evaluator]: [0mInference done 221/8355. 0.1174 s / img. ETA=0:16:16
[32m[04/20 19:55:43 d2.evaluation.evaluator]: [0mInference done 264/8355. 0.1172 s / img. ETA=0:16:09
[32m[04/20 19:55:48 d2.evaluation.evaluator]: [0mInference done 306/8355. 0.1173 s / img. ETA=0:16:05
[32m[04/20 19:55:53 d2.evaluation.evaluator]: [0mInference done 348/8355. 0.1174 s / img. ETA=0:16:01
[32m[04/20 19:55:58 d2.evaluation.evaluator]: [0mInference done 390/8355. 0.1174 s / img. ETA=0:15:56
[32m[04/20 19:56:03 d2.evaluation.evaluator]: [0mInference done 432/8355. 0.1175 s / img. ETA=0:15:51
[32m[04/20 19:56:08 d2.evaluation.evaluator]: [0mInference done 474/8355. 0.1175 s / img. ETA=0:15:46
[32m[04/20 19:56:13 d2.evaluation.evaluator]: [0mInference done 516/8355. 0.1175 s / img. ETA=0:15:41
[32m[04/20 19:56:18 d2.evaluation.evaluator]: [0mInference done 558/8355. 0.1175 s / img. ETA=0:15:36
[32m[04/20 19:56:23 d2.evaluation.evaluator]: [0mInference done 600/8355. 0.1174 s / img. ETA=0:15:31
[32m[04/20 19:56:28 d2.evaluation.evaluator]: [0mInference done 642/8355. 0.1174 s / img. ETA=0:15:26
[32m[04/20 19:56:33 d2.evaluation.evaluator]: [0mInference done 684/8355. 0.1174 s / img. ETA=0:15:21
[32m[04/20 19:56:38 d2.evaluation.evaluator]: [0mInference done 727/8355. 0.1174 s / img. ETA=0:15:15
[32m[04/20 19:56:43 d2.evaluation.evaluator]: [0mInference done 769/8355. 0.1174 s / img. ETA=0:15:10
[32m[04/20 19:56:48 d2.evaluation.evaluator]: [0mInference done 811/8355. 0.1174 s / img. ETA=0:15:05
[32m[04/20 19:56:54 d2.evaluation.evaluator]: [0mInference done 853/8355. 0.1174 s / img. ETA=0:15:00
[32m[04/20 19:56:59 d2.evaluation.evaluator]: [0mInference done 895/8355. 0.1174 s / img. ETA=0:14:55
[32m[04/20 19:57:04 d2.evaluation.evaluator]: [0mInference done 937/8355. 0.1175 s / img. ETA=0:14:51
[32m[04/20 19:57:09 d2.evaluation.evaluator]: [0mInference done 979/8355. 0.1175 s / img. ETA=0:14:46
[32m[04/20 19:57:14 d2.evaluation.evaluator]: [0mInference done 1021/8355. 0.1175 s / img. ETA=0:14:41
[32m[04/20 19:57:19 d2.evaluation.evaluator]: [0mInference done 1063/8355. 0.1175 s / img. ETA=0:14:36
[32m[04/20 19:57:24 d2.evaluation.evaluator]: [0mInference done 1105/8355. 0.1175 s / img. ETA=0:14:31
[32m[04/20 19:57:29 d2.evaluation.evaluator]: [0mInference done 1147/8355. 0.1175 s / img. ETA=0:14:26
[32m[04/20 19:57:34 d2.evaluation.evaluator]: [0mInference done 1189/8355. 0.1175 s / img. ETA=0:14:21
[32m[04/20 19:57:39 d2.evaluation.evaluator]: [0mInference done 1231/8355. 0.1175 s / img. ETA=0:14:16
[32m[04/20 19:57:44 d2.evaluation.evaluator]: [0mInference done 1273/8355. 0.1175 s / img. ETA=0:14:11
[32m[04/20 19:57:49 d2.evaluation.evaluator]: [0mInference done 1315/8355. 0.1175 s / img. ETA=0:14:05
[32m[04/20 19:57:54 d2.evaluation.evaluator]: [0mInference done 1358/8355. 0.1174 s / img. ETA=0:14:00
[32m[04/20 19:57:59 d2.evaluation.evaluator]: [0mInference done 1401/8355. 0.1174 s / img. ETA=0:13:54
[32m[04/20 19:58:04 d2.evaluation.evaluator]: [0mInference done 1444/8355. 0.1174 s / img. ETA=0:13:49
[32m[04/20 19:58:09 d2.evaluation.evaluator]: [0mInference done 1486/8355. 0.1174 s / img. ETA=0:13:44
[32m[04/20 19:58:14 d2.evaluation.evaluator]: [0mInference done 1528/8355. 0.1174 s / img. ETA=0:13:39
[32m[04/20 19:58:20 d2.evaluation.evaluator]: [0mInference done 1570/8355. 0.1174 s / img. ETA=0:13:34
[32m[04/20 19:58:25 d2.evaluation.evaluator]: [0mInference done 1612/8355. 0.1174 s / img. ETA=0:13:29
[32m[04/20 19:58:30 d2.evaluation.evaluator]: [0mInference done 1654/8355. 0.1175 s / img. ETA=0:13:24
[32m[04/20 19:58:35 d2.evaluation.evaluator]: [0mInference done 1696/8355. 0.1175 s / img. ETA=0:13:19
[32m[04/20 19:58:40 d2.evaluation.evaluator]: [0mInference done 1738/8355. 0.1175 s / img. ETA=0:13:14
[32m[04/20 19:58:45 d2.evaluation.evaluator]: [0mInference done 1780/8355. 0.1175 s / img. ETA=0:13:09
[32m[04/20 19:58:50 d2.evaluation.evaluator]: [0mInference done 1822/8355. 0.1175 s / img. ETA=0:13:04
[32m[04/20 19:58:55 d2.evaluation.evaluator]: [0mInference done 1864/8355. 0.1175 s / img. ETA=0:12:59
[32m[04/20 19:59:00 d2.evaluation.evaluator]: [0mInference done 1906/8355. 0.1175 s / img. ETA=0:12:54
[32m[04/20 19:59:05 d2.evaluation.evaluator]: [0mInference done 1948/8355. 0.1175 s / img. ETA=0:12:49
[32m[04/20 19:59:10 d2.evaluation.evaluator]: [0mInference done 1990/8355. 0.1175 s / img. ETA=0:12:44
[32m[04/20 19:59:15 d2.evaluation.evaluator]: [0mInference done 2032/8355. 0.1175 s / img. ETA=0:12:39
[32m[04/20 19:59:20 d2.evaluation.evaluator]: [0mInference done 2074/8355. 0.1175 s / img. ETA=0:12:33
[32m[04/20 19:59:25 d2.evaluation.evaluator]: [0mInference done 2116/8355. 0.1175 s / img. ETA=0:12:28
[32m[04/20 19:59:30 d2.evaluation.evaluator]: [0mInference done 2158/8355. 0.1175 s / img. ETA=0:12:23
[32m[04/20 19:59:35 d2.evaluation.evaluator]: [0mInference done 2200/8355. 0.1175 s / img. ETA=0:12:18
[32m[04/20 19:59:40 d2.evaluation.evaluator]: [0mInference done 2242/8355. 0.1175 s / img. ETA=0:12:13
[32m[04/20 19:59:45 d2.evaluation.evaluator]: [0mInference done 2284/8355. 0.1175 s / img. ETA=0:12:08
[32m[04/20 19:59:50 d2.evaluation.evaluator]: [0mInference done 2326/8355. 0.1175 s / img. ETA=0:12:03
[32m[04/20 19:59:55 d2.evaluation.evaluator]: [0mInference done 2368/8355. 0.1175 s / img. ETA=0:11:58
[32m[04/20 20:00:00 d2.evaluation.evaluator]: [0mInference done 2410/8355. 0.1175 s / img. ETA=0:11:53
[32m[04/20 20:00:05 d2.evaluation.evaluator]: [0mInference done 2452/8355. 0.1175 s / img. ETA=0:11:48
[32m[04/20 20:00:10 d2.evaluation.evaluator]: [0mInference done 2494/8355. 0.1175 s / img. ETA=0:11:43
[32m[04/20 20:00:15 d2.evaluation.evaluator]: [0mInference done 2536/8355. 0.1175 s / img. ETA=0:11:38
[32m[04/20 20:00:21 d2.evaluation.evaluator]: [0mInference done 2578/8355. 0.1175 s / img. ETA=0:11:33
[32m[04/20 20:00:26 d2.evaluation.evaluator]: [0mInference done 2620/8355. 0.1175 s / img. ETA=0:11:28
[32m[04/20 20:00:31 d2.evaluation.evaluator]: [0mInference done 2662/8355. 0.1175 s / img. ETA=0:11:23
[32m[04/20 20:00:36 d2.evaluation.evaluator]: [0mInference done 2704/8355. 0.1176 s / img. ETA=0:11:18
[32m[04/20 20:00:41 d2.evaluation.evaluator]: [0mInference done 2746/8355. 0.1175 s / img. ETA=0:11:13
[32m[04/20 20:00:46 d2.evaluation.evaluator]: [0mInference done 2788/8355. 0.1176 s / img. ETA=0:11:08
[32m[04/20 20:00:51 d2.evaluation.evaluator]: [0mInference done 2830/8355. 0.1176 s / img. ETA=0:11:03
[32m[04/20 20:00:56 d2.evaluation.evaluator]: [0mInference done 2872/8355. 0.1176 s / img. ETA=0:10:58
[32m[04/20 20:01:01 d2.evaluation.evaluator]: [0mInference done 2914/8355. 0.1176 s / img. ETA=0:10:53
[32m[04/20 20:01:06 d2.evaluation.evaluator]: [0mInference done 2956/8355. 0.1176 s / img. ETA=0:10:48
[32m[04/20 20:01:11 d2.evaluation.evaluator]: [0mInference done 2998/8355. 0.1176 s / img. ETA=0:10:43
[32m[04/20 20:01:16 d2.evaluation.evaluator]: [0mInference done 3040/8355. 0.1176 s / img. ETA=0:10:38
[32m[04/20 20:01:21 d2.evaluation.evaluator]: [0mInference done 3082/8355. 0.1176 s / img. ETA=0:10:33
[32m[04/20 20:01:26 d2.evaluation.evaluator]: [0mInference done 3124/8355. 0.1176 s / img. ETA=0:10:28
[32m[04/20 20:01:31 d2.evaluation.evaluator]: [0mInference done 3166/8355. 0.1176 s / img. ETA=0:10:23
[32m[04/20 20:01:36 d2.evaluation.evaluator]: [0mInference done 3208/8355. 0.1176 s / img. ETA=0:10:18
[32m[04/20 20:01:42 d2.evaluation.evaluator]: [0mInference done 3250/8355. 0.1176 s / img. ETA=0:10:13
[32m[04/20 20:01:47 d2.evaluation.evaluator]: [0mInference done 3292/8355. 0.1176 s / img. ETA=0:10:08
[32m[04/20 20:01:52 d2.evaluation.evaluator]: [0mInference done 3334/8355. 0.1176 s / img. ETA=0:10:03
[32m[04/20 20:01:57 d2.evaluation.evaluator]: [0mInference done 3376/8355. 0.1176 s / img. ETA=0:09:58
[32m[04/20 20:02:02 d2.evaluation.evaluator]: [0mInference done 3418/8355. 0.1176 s / img. ETA=0:09:53
[32m[04/20 20:02:07 d2.evaluation.evaluator]: [0mInference done 3460/8355. 0.1176 s / img. ETA=0:09:48
[32m[04/20 20:02:12 d2.evaluation.evaluator]: [0mInference done 3502/8355. 0.1176 s / img. ETA=0:09:42
[32m[04/20 20:02:17 d2.evaluation.evaluator]: [0mInference done 3544/8355. 0.1176 s / img. ETA=0:09:37
[32m[04/20 20:02:22 d2.evaluation.evaluator]: [0mInference done 3586/8355. 0.1176 s / img. ETA=0:09:32
[32m[04/20 20:02:27 d2.evaluation.evaluator]: [0mInference done 3628/8355. 0.1176 s / img. ETA=0:09:27
[32m[04/20 20:02:32 d2.evaluation.evaluator]: [0mInference done 3670/8355. 0.1176 s / img. ETA=0:09:22
[32m[04/20 20:02:37 d2.evaluation.evaluator]: [0mInference done 3712/8355. 0.1176 s / img. ETA=0:09:17
[32m[04/20 20:02:42 d2.evaluation.evaluator]: [0mInference done 3754/8355. 0.1176 s / img. ETA=0:09:12
[32m[04/20 20:02:47 d2.evaluation.evaluator]: [0mInference done 3796/8355. 0.1176 s / img. ETA=0:09:07
[32m[04/20 20:02:52 d2.evaluation.evaluator]: [0mInference done 3838/8355. 0.1176 s / img. ETA=0:09:02
[32m[04/20 20:02:57 d2.evaluation.evaluator]: [0mInference done 3880/8355. 0.1176 s / img. ETA=0:08:57
[32m[04/20 20:03:02 d2.evaluation.evaluator]: [0mInference done 3923/8355. 0.1175 s / img. ETA=0:08:52
[32m[04/20 20:03:07 d2.evaluation.evaluator]: [0mInference done 3965/8355. 0.1175 s / img. ETA=0:08:47
[32m[04/20 20:03:12 d2.evaluation.evaluator]: [0mInference done 4007/8355. 0.1175 s / img. ETA=0:08:41
[32m[04/20 20:03:17 d2.evaluation.evaluator]: [0mInference done 4049/8355. 0.1175 s / img. ETA=0:08:36
[32m[04/20 20:03:22 d2.evaluation.evaluator]: [0mInference done 4091/8355. 0.1175 s / img. ETA=0:08:31
[32m[04/20 20:03:27 d2.evaluation.evaluator]: [0mInference done 4133/8355. 0.1175 s / img. ETA=0:08:26
[32m[04/20 20:03:32 d2.evaluation.evaluator]: [0mInference done 4175/8355. 0.1175 s / img. ETA=0:08:21
[32m[04/20 20:03:37 d2.evaluation.evaluator]: [0mInference done 4217/8355. 0.1175 s / img. ETA=0:08:16
[32m[04/20 20:03:42 d2.evaluation.evaluator]: [0mInference done 4259/8355. 0.1175 s / img. ETA=0:08:11
[32m[04/20 20:03:47 d2.evaluation.evaluator]: [0mInference done 4301/8355. 0.1175 s / img. ETA=0:08:06
[32m[04/20 20:03:52 d2.evaluation.evaluator]: [0mInference done 4343/8355. 0.1175 s / img. ETA=0:08:01
[32m[04/20 20:03:57 d2.evaluation.evaluator]: [0mInference done 4385/8355. 0.1175 s / img. ETA=0:07:56
[32m[04/20 20:04:03 d2.evaluation.evaluator]: [0mInference done 4427/8355. 0.1175 s / img. ETA=0:07:51
[32m[04/20 20:04:08 d2.evaluation.evaluator]: [0mInference done 4469/8355. 0.1175 s / img. ETA=0:07:46
[32m[04/20 20:04:13 d2.evaluation.evaluator]: [0mInference done 4511/8355. 0.1175 s / img. ETA=0:07:41
[32m[04/20 20:04:18 d2.evaluation.evaluator]: [0mInference done 4553/8355. 0.1175 s / img. ETA=0:07:36
[32m[04/20 20:04:23 d2.evaluation.evaluator]: [0mInference done 4595/8355. 0.1175 s / img. ETA=0:07:31
[32m[04/20 20:04:28 d2.evaluation.evaluator]: [0mInference done 4637/8355. 0.1175 s / img. ETA=0:07:26
[32m[04/20 20:04:33 d2.evaluation.evaluator]: [0mInference done 4679/8355. 0.1175 s / img. ETA=0:07:21
[32m[04/20 20:04:38 d2.evaluation.evaluator]: [0mInference done 4721/8355. 0.1175 s / img. ETA=0:07:16
[32m[04/20 20:04:43 d2.evaluation.evaluator]: [0mInference done 4763/8355. 0.1175 s / img. ETA=0:07:11
[32m[04/20 20:04:48 d2.evaluation.evaluator]: [0mInference done 4805/8355. 0.1175 s / img. ETA=0:07:06
[32m[04/20 20:04:53 d2.evaluation.evaluator]: [0mInference done 4847/8355. 0.1175 s / img. ETA=0:07:01
[32m[04/20 20:04:58 d2.evaluation.evaluator]: [0mInference done 4889/8355. 0.1175 s / img. ETA=0:06:56
[32m[04/20 20:05:03 d2.evaluation.evaluator]: [0mInference done 4931/8355. 0.1175 s / img. ETA=0:06:51
[32m[04/20 20:05:08 d2.evaluation.evaluator]: [0mInference done 4973/8355. 0.1175 s / img. ETA=0:06:46
[32m[04/20 20:05:13 d2.evaluation.evaluator]: [0mInference done 5015/8355. 0.1175 s / img. ETA=0:06:41
[32m[04/20 20:05:18 d2.evaluation.evaluator]: [0mInference done 5057/8355. 0.1175 s / img. ETA=0:06:35
[32m[04/20 20:05:23 d2.evaluation.evaluator]: [0mInference done 5099/8355. 0.1175 s / img. ETA=0:06:30
[32m[04/20 20:05:28 d2.evaluation.evaluator]: [0mInference done 5141/8355. 0.1175 s / img. ETA=0:06:25
[32m[04/20 20:05:34 d2.evaluation.evaluator]: [0mInference done 5183/8355. 0.1176 s / img. ETA=0:06:20
[32m[04/20 20:05:39 d2.evaluation.evaluator]: [0mInference done 5225/8355. 0.1176 s / img. ETA=0:06:15
[32m[04/20 20:05:44 d2.evaluation.evaluator]: [0mInference done 5266/8355. 0.1176 s / img. ETA=0:06:11
[32m[04/20 20:05:49 d2.evaluation.evaluator]: [0mInference done 5308/8355. 0.1176 s / img. ETA=0:06:06
[32m[04/20 20:05:54 d2.evaluation.evaluator]: [0mInference done 5350/8355. 0.1176 s / img. ETA=0:06:00
[32m[04/20 20:05:59 d2.evaluation.evaluator]: [0mInference done 5392/8355. 0.1176 s / img. ETA=0:05:55
[32m[04/20 20:06:04 d2.evaluation.evaluator]: [0mInference done 5434/8355. 0.1176 s / img. ETA=0:05:50
[32m[04/20 20:06:09 d2.evaluation.evaluator]: [0mInference done 5476/8355. 0.1176 s / img. ETA=0:05:45
[32m[04/20 20:06:14 d2.evaluation.evaluator]: [0mInference done 5518/8355. 0.1176 s / img. ETA=0:05:40
[32m[04/20 20:06:19 d2.evaluation.evaluator]: [0mInference done 5560/8355. 0.1176 s / img. ETA=0:05:35
[32m[04/20 20:06:24 d2.evaluation.evaluator]: [0mInference done 5602/8355. 0.1176 s / img. ETA=0:05:30
[32m[04/20 20:06:29 d2.evaluation.evaluator]: [0mInference done 5644/8355. 0.1176 s / img. ETA=0:05:25
[32m[04/20 20:06:34 d2.evaluation.evaluator]: [0mInference done 5686/8355. 0.1176 s / img. ETA=0:05:20
[32m[04/20 20:06:39 d2.evaluation.evaluator]: [0mInference done 5728/8355. 0.1176 s / img. ETA=0:05:15
[32m[04/20 20:06:44 d2.evaluation.evaluator]: [0mInference done 5770/8355. 0.1176 s / img. ETA=0:05:10
[32m[04/20 20:06:49 d2.evaluation.evaluator]: [0mInference done 5812/8355. 0.1176 s / img. ETA=0:05:05
[32m[04/20 20:06:54 d2.evaluation.evaluator]: [0mInference done 5854/8355. 0.1176 s / img. ETA=0:05:00
[32m[04/20 20:06:59 d2.evaluation.evaluator]: [0mInference done 5896/8355. 0.1176 s / img. ETA=0:04:55
[32m[04/20 20:07:04 d2.evaluation.evaluator]: [0mInference done 5938/8355. 0.1176 s / img. ETA=0:04:50
[32m[04/20 20:07:09 d2.evaluation.evaluator]: [0mInference done 5977/8355. 0.1176 s / img. ETA=0:04:45
[32m[04/20 20:07:15 d2.evaluation.evaluator]: [0mInference done 6019/8355. 0.1177 s / img. ETA=0:04:40
[32m[04/20 20:07:20 d2.evaluation.evaluator]: [0mInference done 6061/8355. 0.1177 s / img. ETA=0:04:35
[32m[04/20 20:07:25 d2.evaluation.evaluator]: [0mInference done 6103/8355. 0.1177 s / img. ETA=0:04:30
[32m[04/20 20:07:30 d2.evaluation.evaluator]: [0mInference done 6145/8355. 0.1177 s / img. ETA=0:04:25
[32m[04/20 20:07:35 d2.evaluation.evaluator]: [0mInference done 6187/8355. 0.1177 s / img. ETA=0:04:20
[32m[04/20 20:07:40 d2.evaluation.evaluator]: [0mInference done 6229/8355. 0.1177 s / img. ETA=0:04:15
[32m[04/20 20:07:45 d2.evaluation.evaluator]: [0mInference done 6271/8355. 0.1177 s / img. ETA=0:04:10
[32m[04/20 20:07:50 d2.evaluation.evaluator]: [0mInference done 6312/8355. 0.1177 s / img. ETA=0:04:05
[32m[04/20 20:07:55 d2.evaluation.evaluator]: [0mInference done 6354/8355. 0.1177 s / img. ETA=0:04:00
[32m[04/20 20:08:00 d2.evaluation.evaluator]: [0mInference done 6396/8355. 0.1177 s / img. ETA=0:03:55
[32m[04/20 20:08:05 d2.evaluation.evaluator]: [0mInference done 6438/8355. 0.1177 s / img. ETA=0:03:50
[32m[04/20 20:08:10 d2.evaluation.evaluator]: [0mInference done 6480/8355. 0.1177 s / img. ETA=0:03:45
[32m[04/20 20:08:15 d2.evaluation.evaluator]: [0mInference done 6522/8355. 0.1177 s / img. ETA=0:03:40
[32m[04/20 20:08:20 d2.evaluation.evaluator]: [0mInference done 6564/8355. 0.1177 s / img. ETA=0:03:35
[32m[04/20 20:08:25 d2.evaluation.evaluator]: [0mInference done 6606/8355. 0.1177 s / img. ETA=0:03:30
[32m[04/20 20:08:30 d2.evaluation.evaluator]: [0mInference done 6648/8355. 0.1177 s / img. ETA=0:03:25
[32m[04/20 20:08:35 d2.evaluation.evaluator]: [0mInference done 6691/8355. 0.1177 s / img. ETA=0:03:20
[32m[04/20 20:08:40 d2.evaluation.evaluator]: [0mInference done 6733/8355. 0.1177 s / img. ETA=0:03:14
[32m[04/20 20:08:46 d2.evaluation.evaluator]: [0mInference done 6776/8355. 0.1176 s / img. ETA=0:03:09
[32m[04/20 20:08:51 d2.evaluation.evaluator]: [0mInference done 6818/8355. 0.1176 s / img. ETA=0:03:04
[32m[04/20 20:08:56 d2.evaluation.evaluator]: [0mInference done 6860/8355. 0.1176 s / img. ETA=0:02:59
[32m[04/20 20:09:01 d2.evaluation.evaluator]: [0mInference done 6902/8355. 0.1176 s / img. ETA=0:02:54
[32m[04/20 20:09:06 d2.evaluation.evaluator]: [0mInference done 6944/8355. 0.1176 s / img. ETA=0:02:49
[32m[04/20 20:09:11 d2.evaluation.evaluator]: [0mInference done 6986/8355. 0.1176 s / img. ETA=0:02:44
[32m[04/20 20:09:16 d2.evaluation.evaluator]: [0mInference done 7028/8355. 0.1176 s / img. ETA=0:02:39
[32m[04/20 20:09:21 d2.evaluation.evaluator]: [0mInference done 7070/8355. 0.1177 s / img. ETA=0:02:34
[32m[04/20 20:09:26 d2.evaluation.evaluator]: [0mInference done 7112/8355. 0.1177 s / img. ETA=0:02:29
[32m[04/20 20:09:31 d2.evaluation.evaluator]: [0mInference done 7153/8355. 0.1177 s / img. ETA=0:02:24
[32m[04/20 20:09:36 d2.evaluation.evaluator]: [0mInference done 7194/8355. 0.1177 s / img. ETA=0:02:19
[32m[04/20 20:09:41 d2.evaluation.evaluator]: [0mInference done 7235/8355. 0.1177 s / img. ETA=0:02:14
[32m[04/20 20:09:46 d2.evaluation.evaluator]: [0mInference done 7276/8355. 0.1177 s / img. ETA=0:02:09
[32m[04/20 20:09:51 d2.evaluation.evaluator]: [0mInference done 7318/8355. 0.1177 s / img. ETA=0:02:04
[32m[04/20 20:09:56 d2.evaluation.evaluator]: [0mInference done 7360/8355. 0.1177 s / img. ETA=0:01:59
[32m[04/20 20:10:01 d2.evaluation.evaluator]: [0mInference done 7402/8355. 0.1177 s / img. ETA=0:01:54
[32m[04/20 20:10:07 d2.evaluation.evaluator]: [0mInference done 7444/8355. 0.1177 s / img. ETA=0:01:49
[32m[04/20 20:10:12 d2.evaluation.evaluator]: [0mInference done 7486/8355. 0.1177 s / img. ETA=0:01:44
[32m[04/20 20:10:17 d2.evaluation.evaluator]: [0mInference done 7527/8355. 0.1177 s / img. ETA=0:01:39
[32m[04/20 20:10:22 d2.evaluation.evaluator]: [0mInference done 7569/8355. 0.1177 s / img. ETA=0:01:34
[32m[04/20 20:10:27 d2.evaluation.evaluator]: [0mInference done 7611/8355. 0.1178 s / img. ETA=0:01:29
[32m[04/20 20:10:32 d2.evaluation.evaluator]: [0mInference done 7653/8355. 0.1178 s / img. ETA=0:01:24
[32m[04/20 20:10:37 d2.evaluation.evaluator]: [0mInference done 7695/8355. 0.1178 s / img. ETA=0:01:19
[32m[04/20 20:10:42 d2.evaluation.evaluator]: [0mInference done 7737/8355. 0.1178 s / img. ETA=0:01:14
[32m[04/20 20:10:47 d2.evaluation.evaluator]: [0mInference done 7779/8355. 0.1178 s / img. ETA=0:01:09
[32m[04/20 20:10:52 d2.evaluation.evaluator]: [0mInference done 7821/8355. 0.1178 s / img. ETA=0:01:04
[32m[04/20 20:10:57 d2.evaluation.evaluator]: [0mInference done 7863/8355. 0.1178 s / img. ETA=0:00:59
[32m[04/20 20:11:02 d2.evaluation.evaluator]: [0mInference done 7905/8355. 0.1178 s / img. ETA=0:00:54
[32m[04/20 20:11:08 d2.evaluation.evaluator]: [0mInference done 7947/8355. 0.1178 s / img. ETA=0:00:49
[32m[04/20 20:11:13 d2.evaluation.evaluator]: [0mInference done 7989/8355. 0.1178 s / img. ETA=0:00:44
[32m[04/20 20:11:18 d2.evaluation.evaluator]: [0mInference done 8031/8355. 0.1178 s / img. ETA=0:00:38
[32m[04/20 20:11:23 d2.evaluation.evaluator]: [0mInference done 8073/8355. 0.1178 s / img. ETA=0:00:33
[32m[04/20 20:11:28 d2.evaluation.evaluator]: [0mInference done 8115/8355. 0.1178 s / img. ETA=0:00:28
[32m[04/20 20:11:33 d2.evaluation.evaluator]: [0mInference done 8157/8355. 0.1178 s / img. ETA=0:00:23
[32m[04/20 20:11:38 d2.evaluation.evaluator]: [0mInference done 8199/8355. 0.1178 s / img. ETA=0:00:18
[32m[04/20 20:11:43 d2.evaluation.evaluator]: [0mInference done 8241/8355. 0.1178 s / img. ETA=0:00:13
[32m[04/20 20:11:48 d2.evaluation.evaluator]: [0mInference done 8283/8355. 0.1178 s / img. ETA=0:00:08
[32m[04/20 20:11:53 d2.evaluation.evaluator]: [0mInference done 8324/8355. 0.1178 s / img. ETA=0:00:03
[32m[04/20 20:11:57 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:45.056085 (0.120366 s / img per device, on 1 devices)
[32m[04/20 20:11:57 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:23 (0.117783 s / img per device, on 1 devices)
[32m[04/20 20:11:57 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 20:11:57 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 20:11:57 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.09s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=35.40s).
Accumulating evaluation results...
DONE (t=3.98s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.411
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.769
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.376
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.309
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.529
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.468
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.399
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.714
[32m[04/20 20:12:37 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.139 | 76.893 | 37.598 | 30.940 | 52.948 | 66.447 |
[32m[04/20 20:12:37 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 40.427 | bicycle       | 30.093 | car            | 52.896 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 20:12:39 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 20:12:39 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 20:12:39 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 20:12:41 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1182 s / img. ETA=0:02:29
[32m[04/20 20:12:46 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1177 s / img. ETA=0:02:24
[32m[04/20 20:12:51 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1179 s / img. ETA=0:02:19
[32m[04/20 20:12:56 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1179 s / img. ETA=0:02:14
[32m[04/20 20:13:01 d2.evaluation.evaluator]: [0mInference done 179/1257. 0.1176 s / img. ETA=0:02:09
[32m[04/20 20:13:06 d2.evaluation.evaluator]: [0mInference done 221/1257. 0.1177 s / img. ETA=0:02:04
[32m[04/20 20:13:11 d2.evaluation.evaluator]: [0mInference done 263/1257. 0.1178 s / img. ETA=0:01:59
[32m[04/20 20:13:16 d2.evaluation.evaluator]: [0mInference done 305/1257. 0.1178 s / img. ETA=0:01:54
[32m[04/20 20:13:21 d2.evaluation.evaluator]: [0mInference done 347/1257. 0.1179 s / img. ETA=0:01:49
[32m[04/20 20:13:26 d2.evaluation.evaluator]: [0mInference done 389/1257. 0.1179 s / img. ETA=0:01:44
[32m[04/20 20:13:31 d2.evaluation.evaluator]: [0mInference done 431/1257. 0.1179 s / img. ETA=0:01:39
[32m[04/20 20:13:36 d2.evaluation.evaluator]: [0mInference done 473/1257. 0.1180 s / img. ETA=0:01:34
[32m[04/20 20:13:41 d2.evaluation.evaluator]: [0mInference done 515/1257. 0.1180 s / img. ETA=0:01:29
[32m[04/20 20:13:46 d2.evaluation.evaluator]: [0mInference done 557/1257. 0.1181 s / img. ETA=0:01:24
[32m[04/20 20:13:52 d2.evaluation.evaluator]: [0mInference done 599/1257. 0.1181 s / img. ETA=0:01:19
[32m[04/20 20:13:57 d2.evaluation.evaluator]: [0mInference done 641/1257. 0.1181 s / img. ETA=0:01:14
[32m[04/20 20:14:02 d2.evaluation.evaluator]: [0mInference done 683/1257. 0.1182 s / img. ETA=0:01:09
[32m[04/20 20:14:07 d2.evaluation.evaluator]: [0mInference done 724/1257. 0.1182 s / img. ETA=0:01:04
[32m[04/20 20:14:12 d2.evaluation.evaluator]: [0mInference done 766/1257. 0.1182 s / img. ETA=0:00:59
[32m[04/20 20:14:17 d2.evaluation.evaluator]: [0mInference done 808/1257. 0.1182 s / img. ETA=0:00:54
[32m[04/20 20:14:22 d2.evaluation.evaluator]: [0mInference done 850/1257. 0.1183 s / img. ETA=0:00:49
[32m[04/20 20:14:27 d2.evaluation.evaluator]: [0mInference done 892/1257. 0.1183 s / img. ETA=0:00:44
[32m[04/20 20:14:32 d2.evaluation.evaluator]: [0mInference done 934/1257. 0.1183 s / img. ETA=0:00:39
[32m[04/20 20:14:37 d2.evaluation.evaluator]: [0mInference done 976/1257. 0.1183 s / img. ETA=0:00:34
[32m[04/20 20:14:42 d2.evaluation.evaluator]: [0mInference done 1018/1257. 0.1183 s / img. ETA=0:00:28
[32m[04/20 20:14:47 d2.evaluation.evaluator]: [0mInference done 1060/1257. 0.1183 s / img. ETA=0:00:23
[32m[04/20 20:14:53 d2.evaluation.evaluator]: [0mInference done 1102/1257. 0.1183 s / img. ETA=0:00:18
[32m[04/20 20:14:58 d2.evaluation.evaluator]: [0mInference done 1144/1257. 0.1183 s / img. ETA=0:00:13
[32m[04/20 20:15:03 d2.evaluation.evaluator]: [0mInference done 1186/1257. 0.1183 s / img. ETA=0:00:08
[32m[04/20 20:15:08 d2.evaluation.evaluator]: [0mInference done 1228/1257. 0.1183 s / img. ETA=0:00:03
[32m[04/20 20:15:11 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:31.402726 (0.120929 s / img per device, on 1 devices)
[32m[04/20 20:15:11 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:28 (0.118240 s / img per device, on 1 devices)
[32m[04/20 20:15:11 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 20:15:11 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 20:15:11 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.40s).
Accumulating evaluation results...
DONE (t=0.42s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.282
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.568
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.231
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.332
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.411
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.147
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.361
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.289
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.477
[32m[04/20 20:15:15 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 28.242 | 56.824 | 23.062 | 19.667 | 33.175 | 41.058 |
[32m[04/20 20:15:15 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 26.078 | bicycle       | 11.173 | car            | 47.475 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  24  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 20:15:16 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 20:15:17 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 20:15:17 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 20:15:18 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 20:15:18 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 20:15:18 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 20:15:18 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 20:15:39 d2.utils.events]: [0m eta: 0:17:05  iter: 19  total_loss: 0.562  loss_cls: 0.186  loss_box_reg: 0.306  loss_rpn_cls: 0.014  loss_rpn_loc: 0.050  time: 1.0298  data_time: 0.0292  lr: 0.000100  max_mem: 5406M
[32m[04/20 20:15:59 d2.utils.events]: [0m eta: 0:16:49  iter: 39  total_loss: 0.609  loss_cls: 0.204  loss_box_reg: 0.335  loss_rpn_cls: 0.011  loss_rpn_loc: 0.061  time: 1.0342  data_time: 0.0110  lr: 0.000200  max_mem: 5406M
[32m[04/20 20:16:20 d2.utils.events]: [0m eta: 0:16:22  iter: 59  total_loss: 0.617  loss_cls: 0.194  loss_box_reg: 0.356  loss_rpn_cls: 0.014  loss_rpn_loc: 0.068  time: 1.0327  data_time: 0.0105  lr: 0.000300  max_mem: 5406M
[32m[04/20 20:16:41 d2.utils.events]: [0m eta: 0:16:02  iter: 79  total_loss: 0.584  loss_cls: 0.195  loss_box_reg: 0.341  loss_rpn_cls: 0.012  loss_rpn_loc: 0.061  time: 1.0345  data_time: 0.0105  lr: 0.000400  max_mem: 5406M
[32m[04/20 20:17:01 d2.utils.events]: [0m eta: 0:15:26  iter: 99  total_loss: 0.542  loss_cls: 0.175  loss_box_reg: 0.317  loss_rpn_cls: 0.012  loss_rpn_loc: 0.044  time: 1.0280  data_time: 0.0110  lr: 0.000500  max_mem: 5406M
[32m[04/20 20:17:21 d2.utils.events]: [0m eta: 0:15:05  iter: 119  total_loss: 0.542  loss_cls: 0.182  loss_box_reg: 0.303  loss_rpn_cls: 0.011  loss_rpn_loc: 0.061  time: 1.0272  data_time: 0.0102  lr: 0.000599  max_mem: 5406M
[32m[04/20 20:17:42 d2.utils.events]: [0m eta: 0:14:44  iter: 139  total_loss: 0.578  loss_cls: 0.182  loss_box_reg: 0.348  loss_rpn_cls: 0.013  loss_rpn_loc: 0.043  time: 1.0284  data_time: 0.0106  lr: 0.000699  max_mem: 5406M
[32m[04/20 20:18:03 d2.utils.events]: [0m eta: 0:14:25  iter: 159  total_loss: 0.525  loss_cls: 0.177  loss_box_reg: 0.300  loss_rpn_cls: 0.011  loss_rpn_loc: 0.051  time: 1.0294  data_time: 0.0106  lr: 0.000799  max_mem: 5406M
[32m[04/20 20:18:23 d2.utils.events]: [0m eta: 0:14:02  iter: 179  total_loss: 0.536  loss_cls: 0.155  loss_box_reg: 0.301  loss_rpn_cls: 0.011  loss_rpn_loc: 0.059  time: 1.0254  data_time: 0.0105  lr: 0.000899  max_mem: 5406M
[32m[04/20 20:18:43 d2.utils.events]: [0m eta: 0:13:40  iter: 199  total_loss: 0.555  loss_cls: 0.178  loss_box_reg: 0.310  loss_rpn_cls: 0.010  loss_rpn_loc: 0.058  time: 1.0252  data_time: 0.0108  lr: 0.000999  max_mem: 5406M
[32m[04/20 20:19:04 d2.utils.events]: [0m eta: 0:13:20  iter: 219  total_loss: 0.533  loss_cls: 0.165  loss_box_reg: 0.300  loss_rpn_cls: 0.013  loss_rpn_loc: 0.055  time: 1.0250  data_time: 0.0113  lr: 0.001099  max_mem: 5406M
[32m[04/20 20:19:24 d2.utils.events]: [0m eta: 0:12:59  iter: 239  total_loss: 0.590  loss_cls: 0.180  loss_box_reg: 0.345  loss_rpn_cls: 0.012  loss_rpn_loc: 0.060  time: 1.0234  data_time: 0.0118  lr: 0.001199  max_mem: 5406M
[32m[04/20 20:19:45 d2.utils.events]: [0m eta: 0:12:39  iter: 259  total_loss: 0.536  loss_cls: 0.166  loss_box_reg: 0.317  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 1.0242  data_time: 0.0120  lr: 0.001299  max_mem: 5406M
[32m[04/20 20:20:06 d2.utils.events]: [0m eta: 0:12:21  iter: 279  total_loss: 0.534  loss_cls: 0.159  loss_box_reg: 0.294  loss_rpn_cls: 0.011  loss_rpn_loc: 0.056  time: 1.0265  data_time: 0.0104  lr: 0.001399  max_mem: 5406M
[32m[04/20 20:20:27 d2.utils.events]: [0m eta: 0:12:01  iter: 299  total_loss: 0.621  loss_cls: 0.188  loss_box_reg: 0.357  loss_rpn_cls: 0.010  loss_rpn_loc: 0.049  time: 1.0270  data_time: 0.0107  lr: 0.001499  max_mem: 5406M
[32m[04/20 20:20:47 d2.utils.events]: [0m eta: 0:11:40  iter: 319  total_loss: 0.522  loss_cls: 0.159  loss_box_reg: 0.304  loss_rpn_cls: 0.009  loss_rpn_loc: 0.050  time: 1.0268  data_time: 0.0118  lr: 0.001598  max_mem: 5406M
[32m[04/20 20:21:08 d2.utils.events]: [0m eta: 0:11:20  iter: 339  total_loss: 0.526  loss_cls: 0.172  loss_box_reg: 0.310  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 1.0273  data_time: 0.0108  lr: 0.001698  max_mem: 5406M
[32m[04/20 20:21:28 d2.utils.events]: [0m eta: 0:10:59  iter: 359  total_loss: 0.574  loss_cls: 0.178  loss_box_reg: 0.320  loss_rpn_cls: 0.011  loss_rpn_loc: 0.057  time: 1.0264  data_time: 0.0112  lr: 0.001798  max_mem: 5406M
[32m[04/20 20:21:49 d2.utils.events]: [0m eta: 0:10:39  iter: 379  total_loss: 0.585  loss_cls: 0.177  loss_box_reg: 0.340  loss_rpn_cls: 0.009  loss_rpn_loc: 0.045  time: 1.0277  data_time: 0.0102  lr: 0.001898  max_mem: 5406M
[32m[04/20 20:22:10 d2.utils.events]: [0m eta: 0:10:19  iter: 399  total_loss: 0.587  loss_cls: 0.187  loss_box_reg: 0.338  loss_rpn_cls: 0.012  loss_rpn_loc: 0.051  time: 1.0289  data_time: 0.0110  lr: 0.001998  max_mem: 5406M
[32m[04/20 20:22:31 d2.utils.events]: [0m eta: 0:09:58  iter: 419  total_loss: 0.553  loss_cls: 0.175  loss_box_reg: 0.326  loss_rpn_cls: 0.013  loss_rpn_loc: 0.043  time: 1.0285  data_time: 0.0102  lr: 0.002098  max_mem: 5406M
[32m[04/20 20:22:52 d2.utils.events]: [0m eta: 0:09:38  iter: 439  total_loss: 0.524  loss_cls: 0.163  loss_box_reg: 0.293  loss_rpn_cls: 0.008  loss_rpn_loc: 0.043  time: 1.0297  data_time: 0.0116  lr: 0.002198  max_mem: 5406M
[32m[04/20 20:23:13 d2.utils.events]: [0m eta: 0:09:18  iter: 459  total_loss: 0.529  loss_cls: 0.165  loss_box_reg: 0.300  loss_rpn_cls: 0.011  loss_rpn_loc: 0.045  time: 1.0297  data_time: 0.0114  lr: 0.002298  max_mem: 5406M
[32m[04/20 20:23:33 d2.utils.events]: [0m eta: 0:08:57  iter: 479  total_loss: 0.559  loss_cls: 0.181  loss_box_reg: 0.331  loss_rpn_cls: 0.011  loss_rpn_loc: 0.045  time: 1.0295  data_time: 0.0108  lr: 0.002398  max_mem: 5406M
[32m[04/20 20:23:54 d2.utils.events]: [0m eta: 0:08:36  iter: 499  total_loss: 0.612  loss_cls: 0.185  loss_box_reg: 0.361  loss_rpn_cls: 0.010  loss_rpn_loc: 0.052  time: 1.0300  data_time: 0.0113  lr: 0.002498  max_mem: 5406M
[32m[04/20 20:24:15 d2.utils.events]: [0m eta: 0:08:16  iter: 519  total_loss: 0.571  loss_cls: 0.172  loss_box_reg: 0.333  loss_rpn_cls: 0.012  loss_rpn_loc: 0.049  time: 1.0313  data_time: 0.0119  lr: 0.002597  max_mem: 5406M
[32m[04/20 20:24:36 d2.utils.events]: [0m eta: 0:07:55  iter: 539  total_loss: 0.547  loss_cls: 0.179  loss_box_reg: 0.304  loss_rpn_cls: 0.010  loss_rpn_loc: 0.064  time: 1.0307  data_time: 0.0109  lr: 0.002697  max_mem: 5406M
[32m[04/20 20:24:56 d2.utils.events]: [0m eta: 0:07:35  iter: 559  total_loss: 0.534  loss_cls: 0.175  loss_box_reg: 0.302  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0303  data_time: 0.0106  lr: 0.002797  max_mem: 5406M
[32m[04/20 20:25:17 d2.utils.events]: [0m eta: 0:07:15  iter: 579  total_loss: 0.614  loss_cls: 0.195  loss_box_reg: 0.326  loss_rpn_cls: 0.015  loss_rpn_loc: 0.050  time: 1.0313  data_time: 0.0104  lr: 0.002897  max_mem: 5406M
[32m[04/20 20:25:38 d2.utils.events]: [0m eta: 0:06:54  iter: 599  total_loss: 0.522  loss_cls: 0.173  loss_box_reg: 0.293  loss_rpn_cls: 0.011  loss_rpn_loc: 0.039  time: 1.0313  data_time: 0.0105  lr: 0.002997  max_mem: 5406M
[32m[04/20 20:25:59 d2.utils.events]: [0m eta: 0:06:33  iter: 619  total_loss: 0.501  loss_cls: 0.151  loss_box_reg: 0.271  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0310  data_time: 0.0106  lr: 0.003097  max_mem: 5406M
[32m[04/20 20:26:19 d2.utils.events]: [0m eta: 0:06:13  iter: 639  total_loss: 0.588  loss_cls: 0.181  loss_box_reg: 0.350  loss_rpn_cls: 0.012  loss_rpn_loc: 0.052  time: 1.0307  data_time: 0.0106  lr: 0.003197  max_mem: 5406M
[32m[04/20 20:26:40 d2.utils.events]: [0m eta: 0:05:52  iter: 659  total_loss: 0.549  loss_cls: 0.189  loss_box_reg: 0.341  loss_rpn_cls: 0.011  loss_rpn_loc: 0.045  time: 1.0310  data_time: 0.0102  lr: 0.003297  max_mem: 5406M
[32m[04/20 20:27:01 d2.utils.events]: [0m eta: 0:05:31  iter: 679  total_loss: 0.538  loss_cls: 0.170  loss_box_reg: 0.314  loss_rpn_cls: 0.014  loss_rpn_loc: 0.045  time: 1.0313  data_time: 0.0106  lr: 0.003397  max_mem: 5406M
[32m[04/20 20:27:22 d2.utils.events]: [0m eta: 0:05:12  iter: 699  total_loss: 0.570  loss_cls: 0.165  loss_box_reg: 0.310  loss_rpn_cls: 0.014  loss_rpn_loc: 0.062  time: 1.0316  data_time: 0.0114  lr: 0.003497  max_mem: 5406M
[32m[04/20 20:27:42 d2.utils.events]: [0m eta: 0:04:50  iter: 719  total_loss: 0.563  loss_cls: 0.180  loss_box_reg: 0.315  loss_rpn_cls: 0.015  loss_rpn_loc: 0.056  time: 1.0310  data_time: 0.0102  lr: 0.003596  max_mem: 5406M
[32m[04/20 20:28:03 d2.utils.events]: [0m eta: 0:04:30  iter: 739  total_loss: 0.623  loss_cls: 0.192  loss_box_reg: 0.346  loss_rpn_cls: 0.014  loss_rpn_loc: 0.055  time: 1.0309  data_time: 0.0105  lr: 0.003696  max_mem: 5406M
[32m[04/20 20:28:23 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.545  loss_cls: 0.167  loss_box_reg: 0.309  loss_rpn_cls: 0.012  loss_rpn_loc: 0.044  time: 1.0301  data_time: 0.0105  lr: 0.003796  max_mem: 5406M
[32m[04/20 20:28:43 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.612  loss_cls: 0.179  loss_box_reg: 0.357  loss_rpn_cls: 0.012  loss_rpn_loc: 0.057  time: 1.0302  data_time: 0.0113  lr: 0.003896  max_mem: 5406M
[32m[04/20 20:29:04 d2.utils.events]: [0m eta: 0:03:27  iter: 799  total_loss: 0.570  loss_cls: 0.184  loss_box_reg: 0.316  loss_rpn_cls: 0.012  loss_rpn_loc: 0.044  time: 1.0298  data_time: 0.0115  lr: 0.003996  max_mem: 5406M
[32m[04/20 20:29:24 d2.utils.events]: [0m eta: 0:03:06  iter: 819  total_loss: 0.671  loss_cls: 0.219  loss_box_reg: 0.378  loss_rpn_cls: 0.016  loss_rpn_loc: 0.064  time: 1.0296  data_time: 0.0106  lr: 0.004096  max_mem: 5406M
[32m[04/20 20:29:45 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.547  loss_cls: 0.168  loss_box_reg: 0.305  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 1.0296  data_time: 0.0106  lr: 0.004196  max_mem: 5406M
[32m[04/20 20:30:06 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.553  loss_cls: 0.173  loss_box_reg: 0.309  loss_rpn_cls: 0.014  loss_rpn_loc: 0.053  time: 1.0298  data_time: 0.0096  lr: 0.004296  max_mem: 5406M
[32m[04/20 20:30:26 d2.utils.events]: [0m eta: 0:02:04  iter: 879  total_loss: 0.612  loss_cls: 0.196  loss_box_reg: 0.338  loss_rpn_cls: 0.010  loss_rpn_loc: 0.048  time: 1.0298  data_time: 0.0121  lr: 0.004396  max_mem: 5406M
[32m[04/20 20:30:47 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.593  loss_cls: 0.197  loss_box_reg: 0.326  loss_rpn_cls: 0.014  loss_rpn_loc: 0.053  time: 1.0301  data_time: 0.0101  lr: 0.004496  max_mem: 5406M
[32m[04/20 20:31:08 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.602  loss_cls: 0.199  loss_box_reg: 0.319  loss_rpn_cls: 0.015  loss_rpn_loc: 0.060  time: 1.0300  data_time: 0.0118  lr: 0.004595  max_mem: 5406M
[32m[04/20 20:31:28 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.593  loss_cls: 0.188  loss_box_reg: 0.334  loss_rpn_cls: 0.013  loss_rpn_loc: 0.049  time: 1.0298  data_time: 0.0108  lr: 0.004695  max_mem: 5406M
[32m[04/20 20:31:49 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.517  loss_cls: 0.150  loss_box_reg: 0.287  loss_rpn_cls: 0.013  loss_rpn_loc: 0.045  time: 1.0301  data_time: 0.0111  lr: 0.004795  max_mem: 5406M
[32m[04/20 20:32:10 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.626  loss_cls: 0.187  loss_box_reg: 0.354  loss_rpn_cls: 0.016  loss_rpn_loc: 0.060  time: 1.0299  data_time: 0.0104  lr: 0.004895  max_mem: 5406M
[5m[31mWARNING[0m [32m[04/20 20:32:34 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 20:32:34 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 20:32:34 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 20:32:34 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.533  loss_cls: 0.175  loss_box_reg: 0.270  loss_rpn_cls: 0.011  loss_rpn_loc: 0.052  time: 1.0299  data_time: 0.0104  lr: 0.004995  max_mem: 5406M
[32m[04/20 20:32:35 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:07 (1.0309 s / it)
[32m[04/20 20:32:35 d2.engine.hooks]: [0mTotal training time: 0:17:15 (0:00:07 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 20:32:37 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 20:32:37 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 20:32:38 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 20:32:39 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1175 s / img. ETA=0:16:37
[32m[04/20 20:32:44 d2.evaluation.evaluator]: [0mInference done 53/8355. 0.1169 s / img. ETA=0:16:29
[32m[04/20 20:32:49 d2.evaluation.evaluator]: [0mInference done 96/8355. 0.1165 s / img. ETA=0:16:21
[32m[04/20 20:32:54 d2.evaluation.evaluator]: [0mInference done 138/8355. 0.1167 s / img. ETA=0:16:19
[32m[04/20 20:33:00 d2.evaluation.evaluator]: [0mInference done 181/8355. 0.1166 s / img. ETA=0:16:13
[32m[04/20 20:33:05 d2.evaluation.evaluator]: [0mInference done 223/8355. 0.1166 s / img. ETA=0:16:08
[32m[04/20 20:33:10 d2.evaluation.evaluator]: [0mInference done 265/8355. 0.1167 s / img. ETA=0:16:04
[32m[04/20 20:33:15 d2.evaluation.evaluator]: [0mInference done 307/8355. 0.1168 s / img. ETA=0:16:00
[32m[04/20 20:33:20 d2.evaluation.evaluator]: [0mInference done 349/8355. 0.1169 s / img. ETA=0:15:56
[32m[04/20 20:33:25 d2.evaluation.evaluator]: [0mInference done 391/8355. 0.1170 s / img. ETA=0:15:52
[32m[04/20 20:33:30 d2.evaluation.evaluator]: [0mInference done 434/8355. 0.1170 s / img. ETA=0:15:47
[32m[04/20 20:33:35 d2.evaluation.evaluator]: [0mInference done 476/8355. 0.1170 s / img. ETA=0:15:41
[32m[04/20 20:33:40 d2.evaluation.evaluator]: [0mInference done 518/8355. 0.1169 s / img. ETA=0:15:36
[32m[04/20 20:33:45 d2.evaluation.evaluator]: [0mInference done 560/8355. 0.1169 s / img. ETA=0:15:31
[32m[04/20 20:33:50 d2.evaluation.evaluator]: [0mInference done 602/8355. 0.1169 s / img. ETA=0:15:26
[32m[04/20 20:33:55 d2.evaluation.evaluator]: [0mInference done 645/8355. 0.1169 s / img. ETA=0:15:20
[32m[04/20 20:34:00 d2.evaluation.evaluator]: [0mInference done 687/8355. 0.1169 s / img. ETA=0:15:15
[32m[04/20 20:34:05 d2.evaluation.evaluator]: [0mInference done 729/8355. 0.1169 s / img. ETA=0:15:10
[32m[04/20 20:34:10 d2.evaluation.evaluator]: [0mInference done 772/8355. 0.1169 s / img. ETA=0:15:04
[32m[04/20 20:34:15 d2.evaluation.evaluator]: [0mInference done 814/8355. 0.1169 s / img. ETA=0:15:00
[32m[04/20 20:34:20 d2.evaluation.evaluator]: [0mInference done 856/8355. 0.1169 s / img. ETA=0:14:55
[32m[04/20 20:34:25 d2.evaluation.evaluator]: [0mInference done 898/8355. 0.1170 s / img. ETA=0:14:51
[32m[04/20 20:34:30 d2.evaluation.evaluator]: [0mInference done 940/8355. 0.1170 s / img. ETA=0:14:46
[32m[04/20 20:34:35 d2.evaluation.evaluator]: [0mInference done 983/8355. 0.1170 s / img. ETA=0:14:41
[32m[04/20 20:34:40 d2.evaluation.evaluator]: [0mInference done 1025/8355. 0.1170 s / img. ETA=0:14:36
[32m[04/20 20:34:46 d2.evaluation.evaluator]: [0mInference done 1068/8355. 0.1169 s / img. ETA=0:14:30
[32m[04/20 20:34:51 d2.evaluation.evaluator]: [0mInference done 1111/8355. 0.1169 s / img. ETA=0:14:25
[32m[04/20 20:34:56 d2.evaluation.evaluator]: [0mInference done 1154/8355. 0.1169 s / img. ETA=0:14:19
[32m[04/20 20:35:01 d2.evaluation.evaluator]: [0mInference done 1197/8355. 0.1169 s / img. ETA=0:14:14
[32m[04/20 20:35:06 d2.evaluation.evaluator]: [0mInference done 1240/8355. 0.1168 s / img. ETA=0:14:09
[32m[04/20 20:35:11 d2.evaluation.evaluator]: [0mInference done 1283/8355. 0.1168 s / img. ETA=0:14:03
[32m[04/20 20:35:16 d2.evaluation.evaluator]: [0mInference done 1326/8355. 0.1168 s / img. ETA=0:13:58
[32m[04/20 20:35:21 d2.evaluation.evaluator]: [0mInference done 1369/8355. 0.1168 s / img. ETA=0:13:53
[32m[04/20 20:35:26 d2.evaluation.evaluator]: [0mInference done 1412/8355. 0.1168 s / img. ETA=0:13:47
[32m[04/20 20:35:31 d2.evaluation.evaluator]: [0mInference done 1455/8355. 0.1167 s / img. ETA=0:13:42
[32m[04/20 20:35:36 d2.evaluation.evaluator]: [0mInference done 1497/8355. 0.1168 s / img. ETA=0:13:37
[32m[04/20 20:35:42 d2.evaluation.evaluator]: [0mInference done 1539/8355. 0.1168 s / img. ETA=0:13:33
[32m[04/20 20:35:47 d2.evaluation.evaluator]: [0mInference done 1581/8355. 0.1169 s / img. ETA=0:13:28
[32m[04/20 20:35:52 d2.evaluation.evaluator]: [0mInference done 1623/8355. 0.1169 s / img. ETA=0:13:23
[32m[04/20 20:35:57 d2.evaluation.evaluator]: [0mInference done 1665/8355. 0.1169 s / img. ETA=0:13:18
[32m[04/20 20:36:02 d2.evaluation.evaluator]: [0mInference done 1707/8355. 0.1170 s / img. ETA=0:13:13
[32m[04/20 20:36:07 d2.evaluation.evaluator]: [0mInference done 1749/8355. 0.1170 s / img. ETA=0:13:09
[32m[04/20 20:36:12 d2.evaluation.evaluator]: [0mInference done 1791/8355. 0.1170 s / img. ETA=0:13:04
[32m[04/20 20:36:17 d2.evaluation.evaluator]: [0mInference done 1833/8355. 0.1170 s / img. ETA=0:12:59
[32m[04/20 20:36:22 d2.evaluation.evaluator]: [0mInference done 1875/8355. 0.1171 s / img. ETA=0:12:54
[32m[04/20 20:36:27 d2.evaluation.evaluator]: [0mInference done 1917/8355. 0.1171 s / img. ETA=0:12:49
[32m[04/20 20:36:32 d2.evaluation.evaluator]: [0mInference done 1959/8355. 0.1171 s / img. ETA=0:12:44
[32m[04/20 20:36:37 d2.evaluation.evaluator]: [0mInference done 2001/8355. 0.1171 s / img. ETA=0:12:39
[32m[04/20 20:36:42 d2.evaluation.evaluator]: [0mInference done 2043/8355. 0.1171 s / img. ETA=0:12:34
[32m[04/20 20:36:47 d2.evaluation.evaluator]: [0mInference done 2085/8355. 0.1171 s / img. ETA=0:12:29
[32m[04/20 20:36:52 d2.evaluation.evaluator]: [0mInference done 2127/8355. 0.1171 s / img. ETA=0:12:24
[32m[04/20 20:36:57 d2.evaluation.evaluator]: [0mInference done 2169/8355. 0.1171 s / img. ETA=0:12:19
[32m[04/20 20:37:02 d2.evaluation.evaluator]: [0mInference done 2211/8355. 0.1171 s / img. ETA=0:12:14
[32m[04/20 20:37:07 d2.evaluation.evaluator]: [0mInference done 2253/8355. 0.1172 s / img. ETA=0:12:09
[32m[04/20 20:37:12 d2.evaluation.evaluator]: [0mInference done 2295/8355. 0.1172 s / img. ETA=0:12:04
[32m[04/20 20:37:18 d2.evaluation.evaluator]: [0mInference done 2337/8355. 0.1172 s / img. ETA=0:11:59
[32m[04/20 20:37:23 d2.evaluation.evaluator]: [0mInference done 2379/8355. 0.1172 s / img. ETA=0:11:55
[32m[04/20 20:37:28 d2.evaluation.evaluator]: [0mInference done 2421/8355. 0.1172 s / img. ETA=0:11:50
[32m[04/20 20:37:33 d2.evaluation.evaluator]: [0mInference done 2463/8355. 0.1172 s / img. ETA=0:11:45
[32m[04/20 20:37:38 d2.evaluation.evaluator]: [0mInference done 2505/8355. 0.1172 s / img. ETA=0:11:40
[32m[04/20 20:37:43 d2.evaluation.evaluator]: [0mInference done 2547/8355. 0.1173 s / img. ETA=0:11:35
[32m[04/20 20:37:48 d2.evaluation.evaluator]: [0mInference done 2589/8355. 0.1173 s / img. ETA=0:11:30
[32m[04/20 20:37:53 d2.evaluation.evaluator]: [0mInference done 2631/8355. 0.1173 s / img. ETA=0:11:25
[32m[04/20 20:37:58 d2.evaluation.evaluator]: [0mInference done 2673/8355. 0.1173 s / img. ETA=0:11:20
[32m[04/20 20:38:03 d2.evaluation.evaluator]: [0mInference done 2715/8355. 0.1173 s / img. ETA=0:11:15
[32m[04/20 20:38:08 d2.evaluation.evaluator]: [0mInference done 2757/8355. 0.1173 s / img. ETA=0:11:10
[32m[04/20 20:38:13 d2.evaluation.evaluator]: [0mInference done 2799/8355. 0.1173 s / img. ETA=0:11:05
[32m[04/20 20:38:18 d2.evaluation.evaluator]: [0mInference done 2841/8355. 0.1173 s / img. ETA=0:11:00
[32m[04/20 20:38:23 d2.evaluation.evaluator]: [0mInference done 2883/8355. 0.1174 s / img. ETA=0:10:55
[32m[04/20 20:38:28 d2.evaluation.evaluator]: [0mInference done 2925/8355. 0.1174 s / img. ETA=0:10:50
[32m[04/20 20:38:33 d2.evaluation.evaluator]: [0mInference done 2967/8355. 0.1174 s / img. ETA=0:10:45
[32m[04/20 20:38:38 d2.evaluation.evaluator]: [0mInference done 3009/8355. 0.1174 s / img. ETA=0:10:40
[32m[04/20 20:38:43 d2.evaluation.evaluator]: [0mInference done 3051/8355. 0.1174 s / img. ETA=0:10:35
[32m[04/20 20:38:49 d2.evaluation.evaluator]: [0mInference done 3093/8355. 0.1174 s / img. ETA=0:10:30
[32m[04/20 20:38:54 d2.evaluation.evaluator]: [0mInference done 3135/8355. 0.1174 s / img. ETA=0:10:25
[32m[04/20 20:38:59 d2.evaluation.evaluator]: [0mInference done 3178/8355. 0.1174 s / img. ETA=0:10:20
[32m[04/20 20:39:04 d2.evaluation.evaluator]: [0mInference done 3221/8355. 0.1174 s / img. ETA=0:10:14
[32m[04/20 20:39:09 d2.evaluation.evaluator]: [0mInference done 3263/8355. 0.1174 s / img. ETA=0:10:09
[32m[04/20 20:39:14 d2.evaluation.evaluator]: [0mInference done 3305/8355. 0.1174 s / img. ETA=0:10:04
[32m[04/20 20:39:19 d2.evaluation.evaluator]: [0mInference done 3347/8355. 0.1174 s / img. ETA=0:09:59
[32m[04/20 20:39:24 d2.evaluation.evaluator]: [0mInference done 3389/8355. 0.1174 s / img. ETA=0:09:54
[32m[04/20 20:39:29 d2.evaluation.evaluator]: [0mInference done 3431/8355. 0.1174 s / img. ETA=0:09:49
[32m[04/20 20:39:34 d2.evaluation.evaluator]: [0mInference done 3473/8355. 0.1174 s / img. ETA=0:09:44
[32m[04/20 20:39:39 d2.evaluation.evaluator]: [0mInference done 3515/8355. 0.1174 s / img. ETA=0:09:39
[32m[04/20 20:39:44 d2.evaluation.evaluator]: [0mInference done 3557/8355. 0.1174 s / img. ETA=0:09:34
[32m[04/20 20:39:49 d2.evaluation.evaluator]: [0mInference done 3599/8355. 0.1174 s / img. ETA=0:09:29
[32m[04/20 20:39:54 d2.evaluation.evaluator]: [0mInference done 3641/8355. 0.1174 s / img. ETA=0:09:24
[32m[04/20 20:39:59 d2.evaluation.evaluator]: [0mInference done 3683/8355. 0.1174 s / img. ETA=0:09:19
[32m[04/20 20:40:04 d2.evaluation.evaluator]: [0mInference done 3726/8355. 0.1174 s / img. ETA=0:09:14
[32m[04/20 20:40:09 d2.evaluation.evaluator]: [0mInference done 3768/8355. 0.1174 s / img. ETA=0:09:09
[32m[04/20 20:40:15 d2.evaluation.evaluator]: [0mInference done 3810/8355. 0.1174 s / img. ETA=0:09:04
[32m[04/20 20:40:20 d2.evaluation.evaluator]: [0mInference done 3852/8355. 0.1174 s / img. ETA=0:08:59
[32m[04/20 20:40:25 d2.evaluation.evaluator]: [0mInference done 3894/8355. 0.1174 s / img. ETA=0:08:54
[32m[04/20 20:40:30 d2.evaluation.evaluator]: [0mInference done 3936/8355. 0.1174 s / img. ETA=0:08:49
[32m[04/20 20:40:35 d2.evaluation.evaluator]: [0mInference done 3978/8355. 0.1174 s / img. ETA=0:08:44
[32m[04/20 20:40:40 d2.evaluation.evaluator]: [0mInference done 4020/8355. 0.1174 s / img. ETA=0:08:39
[32m[04/20 20:40:45 d2.evaluation.evaluator]: [0mInference done 4062/8355. 0.1174 s / img. ETA=0:08:34
[32m[04/20 20:40:50 d2.evaluation.evaluator]: [0mInference done 4104/8355. 0.1174 s / img. ETA=0:08:29
[32m[04/20 20:40:55 d2.evaluation.evaluator]: [0mInference done 4146/8355. 0.1174 s / img. ETA=0:08:24
[32m[04/20 20:41:00 d2.evaluation.evaluator]: [0mInference done 4188/8355. 0.1174 s / img. ETA=0:08:19
[32m[04/20 20:41:05 d2.evaluation.evaluator]: [0mInference done 4230/8355. 0.1174 s / img. ETA=0:08:14
[32m[04/20 20:41:10 d2.evaluation.evaluator]: [0mInference done 4272/8355. 0.1174 s / img. ETA=0:08:09
[32m[04/20 20:41:15 d2.evaluation.evaluator]: [0mInference done 4314/8355. 0.1174 s / img. ETA=0:08:04
[32m[04/20 20:41:20 d2.evaluation.evaluator]: [0mInference done 4356/8355. 0.1174 s / img. ETA=0:07:59
[32m[04/20 20:41:25 d2.evaluation.evaluator]: [0mInference done 4398/8355. 0.1174 s / img. ETA=0:07:54
[32m[04/20 20:41:30 d2.evaluation.evaluator]: [0mInference done 4440/8355. 0.1174 s / img. ETA=0:07:49
[32m[04/20 20:41:35 d2.evaluation.evaluator]: [0mInference done 4482/8355. 0.1174 s / img. ETA=0:07:44
[32m[04/20 20:41:40 d2.evaluation.evaluator]: [0mInference done 4524/8355. 0.1174 s / img. ETA=0:07:39
[32m[04/20 20:41:45 d2.evaluation.evaluator]: [0mInference done 4566/8355. 0.1174 s / img. ETA=0:07:34
[32m[04/20 20:41:50 d2.evaluation.evaluator]: [0mInference done 4608/8355. 0.1174 s / img. ETA=0:07:29
[32m[04/20 20:41:55 d2.evaluation.evaluator]: [0mInference done 4650/8355. 0.1174 s / img. ETA=0:07:24
[32m[04/20 20:42:00 d2.evaluation.evaluator]: [0mInference done 4692/8355. 0.1175 s / img. ETA=0:07:19
[32m[04/20 20:42:06 d2.evaluation.evaluator]: [0mInference done 4734/8355. 0.1175 s / img. ETA=0:07:14
[32m[04/20 20:42:11 d2.evaluation.evaluator]: [0mInference done 4776/8355. 0.1175 s / img. ETA=0:07:09
[32m[04/20 20:42:16 d2.evaluation.evaluator]: [0mInference done 4818/8355. 0.1175 s / img. ETA=0:07:04
[32m[04/20 20:42:21 d2.evaluation.evaluator]: [0mInference done 4860/8355. 0.1175 s / img. ETA=0:06:59
[32m[04/20 20:42:26 d2.evaluation.evaluator]: [0mInference done 4902/8355. 0.1175 s / img. ETA=0:06:54
[32m[04/20 20:42:31 d2.evaluation.evaluator]: [0mInference done 4944/8355. 0.1175 s / img. ETA=0:06:48
[32m[04/20 20:42:36 d2.evaluation.evaluator]: [0mInference done 4986/8355. 0.1175 s / img. ETA=0:06:43
[32m[04/20 20:42:41 d2.evaluation.evaluator]: [0mInference done 5028/8355. 0.1175 s / img. ETA=0:06:38
[32m[04/20 20:42:46 d2.evaluation.evaluator]: [0mInference done 5067/8355. 0.1176 s / img. ETA=0:06:34
[32m[04/20 20:42:51 d2.evaluation.evaluator]: [0mInference done 5109/8355. 0.1176 s / img. ETA=0:06:29
[32m[04/20 20:42:56 d2.evaluation.evaluator]: [0mInference done 5151/8355. 0.1176 s / img. ETA=0:06:24
[32m[04/20 20:43:01 d2.evaluation.evaluator]: [0mInference done 5193/8355. 0.1176 s / img. ETA=0:06:19
[32m[04/20 20:43:06 d2.evaluation.evaluator]: [0mInference done 5235/8355. 0.1176 s / img. ETA=0:06:14
[32m[04/20 20:43:11 d2.evaluation.evaluator]: [0mInference done 5277/8355. 0.1176 s / img. ETA=0:06:09
[32m[04/20 20:43:16 d2.evaluation.evaluator]: [0mInference done 5319/8355. 0.1176 s / img. ETA=0:06:04
[32m[04/20 20:43:21 d2.evaluation.evaluator]: [0mInference done 5361/8355. 0.1176 s / img. ETA=0:05:59
[32m[04/20 20:43:26 d2.evaluation.evaluator]: [0mInference done 5403/8355. 0.1176 s / img. ETA=0:05:54
[32m[04/20 20:43:32 d2.evaluation.evaluator]: [0mInference done 5445/8355. 0.1176 s / img. ETA=0:05:49
[32m[04/20 20:43:37 d2.evaluation.evaluator]: [0mInference done 5487/8355. 0.1176 s / img. ETA=0:05:44
[32m[04/20 20:43:42 d2.evaluation.evaluator]: [0mInference done 5529/8355. 0.1176 s / img. ETA=0:05:39
[32m[04/20 20:43:47 d2.evaluation.evaluator]: [0mInference done 5571/8355. 0.1176 s / img. ETA=0:05:34
[32m[04/20 20:43:52 d2.evaluation.evaluator]: [0mInference done 5613/8355. 0.1176 s / img. ETA=0:05:29
[32m[04/20 20:43:57 d2.evaluation.evaluator]: [0mInference done 5655/8355. 0.1176 s / img. ETA=0:05:24
[32m[04/20 20:44:02 d2.evaluation.evaluator]: [0mInference done 5697/8355. 0.1176 s / img. ETA=0:05:19
[32m[04/20 20:44:07 d2.evaluation.evaluator]: [0mInference done 5739/8355. 0.1176 s / img. ETA=0:05:13
[32m[04/20 20:44:12 d2.evaluation.evaluator]: [0mInference done 5781/8355. 0.1176 s / img. ETA=0:05:08
[32m[04/20 20:44:17 d2.evaluation.evaluator]: [0mInference done 5823/8355. 0.1176 s / img. ETA=0:05:03
[32m[04/20 20:44:22 d2.evaluation.evaluator]: [0mInference done 5865/8355. 0.1176 s / img. ETA=0:04:58
[32m[04/20 20:44:27 d2.evaluation.evaluator]: [0mInference done 5907/8355. 0.1176 s / img. ETA=0:04:53
[32m[04/20 20:44:32 d2.evaluation.evaluator]: [0mInference done 5949/8355. 0.1176 s / img. ETA=0:04:48
[32m[04/20 20:44:37 d2.evaluation.evaluator]: [0mInference done 5991/8355. 0.1176 s / img. ETA=0:04:43
[32m[04/20 20:44:42 d2.evaluation.evaluator]: [0mInference done 6033/8355. 0.1176 s / img. ETA=0:04:38
[32m[04/20 20:44:47 d2.evaluation.evaluator]: [0mInference done 6075/8355. 0.1177 s / img. ETA=0:04:33
[32m[04/20 20:44:52 d2.evaluation.evaluator]: [0mInference done 6117/8355. 0.1177 s / img. ETA=0:04:28
[32m[04/20 20:44:57 d2.evaluation.evaluator]: [0mInference done 6159/8355. 0.1177 s / img. ETA=0:04:23
[32m[04/20 20:45:03 d2.evaluation.evaluator]: [0mInference done 6201/8355. 0.1177 s / img. ETA=0:04:18
[32m[04/20 20:45:08 d2.evaluation.evaluator]: [0mInference done 6243/8355. 0.1177 s / img. ETA=0:04:13
[32m[04/20 20:45:13 d2.evaluation.evaluator]: [0mInference done 6285/8355. 0.1177 s / img. ETA=0:04:08
[32m[04/20 20:45:18 d2.evaluation.evaluator]: [0mInference done 6326/8355. 0.1177 s / img. ETA=0:04:03
[32m[04/20 20:45:23 d2.evaluation.evaluator]: [0mInference done 6368/8355. 0.1177 s / img. ETA=0:03:58
[32m[04/20 20:45:28 d2.evaluation.evaluator]: [0mInference done 6410/8355. 0.1177 s / img. ETA=0:03:53
[32m[04/20 20:45:33 d2.evaluation.evaluator]: [0mInference done 6452/8355. 0.1177 s / img. ETA=0:03:48
[32m[04/20 20:45:38 d2.evaluation.evaluator]: [0mInference done 6494/8355. 0.1177 s / img. ETA=0:03:43
[32m[04/20 20:45:43 d2.evaluation.evaluator]: [0mInference done 6536/8355. 0.1177 s / img. ETA=0:03:38
[32m[04/20 20:45:48 d2.evaluation.evaluator]: [0mInference done 6578/8355. 0.1177 s / img. ETA=0:03:33
[32m[04/20 20:45:53 d2.evaluation.evaluator]: [0mInference done 6620/8355. 0.1177 s / img. ETA=0:03:28
[32m[04/20 20:45:58 d2.evaluation.evaluator]: [0mInference done 6662/8355. 0.1177 s / img. ETA=0:03:23
[32m[04/20 20:46:03 d2.evaluation.evaluator]: [0mInference done 6704/8355. 0.1177 s / img. ETA=0:03:18
[32m[04/20 20:46:08 d2.evaluation.evaluator]: [0mInference done 6746/8355. 0.1177 s / img. ETA=0:03:13
[32m[04/20 20:46:13 d2.evaluation.evaluator]: [0mInference done 6788/8355. 0.1177 s / img. ETA=0:03:08
[32m[04/20 20:46:18 d2.evaluation.evaluator]: [0mInference done 6830/8355. 0.1177 s / img. ETA=0:03:03
[32m[04/20 20:46:24 d2.evaluation.evaluator]: [0mInference done 6872/8355. 0.1177 s / img. ETA=0:02:58
[32m[04/20 20:46:29 d2.evaluation.evaluator]: [0mInference done 6914/8355. 0.1177 s / img. ETA=0:02:53
[32m[04/20 20:46:34 d2.evaluation.evaluator]: [0mInference done 6956/8355. 0.1177 s / img. ETA=0:02:48
[32m[04/20 20:46:39 d2.evaluation.evaluator]: [0mInference done 6998/8355. 0.1177 s / img. ETA=0:02:43
[32m[04/20 20:46:44 d2.evaluation.evaluator]: [0mInference done 7040/8355. 0.1177 s / img. ETA=0:02:37
[32m[04/20 20:46:49 d2.evaluation.evaluator]: [0mInference done 7082/8355. 0.1177 s / img. ETA=0:02:32
[32m[04/20 20:46:54 d2.evaluation.evaluator]: [0mInference done 7124/8355. 0.1177 s / img. ETA=0:02:27
[32m[04/20 20:46:59 d2.evaluation.evaluator]: [0mInference done 7166/8355. 0.1177 s / img. ETA=0:02:22
[32m[04/20 20:47:04 d2.evaluation.evaluator]: [0mInference done 7207/8355. 0.1177 s / img. ETA=0:02:17
[32m[04/20 20:47:09 d2.evaluation.evaluator]: [0mInference done 7248/8355. 0.1178 s / img. ETA=0:02:13
[32m[04/20 20:47:14 d2.evaluation.evaluator]: [0mInference done 7290/8355. 0.1178 s / img. ETA=0:02:07
[32m[04/20 20:47:19 d2.evaluation.evaluator]: [0mInference done 7332/8355. 0.1178 s / img. ETA=0:02:02
[32m[04/20 20:47:24 d2.evaluation.evaluator]: [0mInference done 7374/8355. 0.1178 s / img. ETA=0:01:57
[32m[04/20 20:47:29 d2.evaluation.evaluator]: [0mInference done 7415/8355. 0.1178 s / img. ETA=0:01:53
[32m[04/20 20:47:34 d2.evaluation.evaluator]: [0mInference done 7457/8355. 0.1178 s / img. ETA=0:01:47
[32m[04/20 20:47:40 d2.evaluation.evaluator]: [0mInference done 7499/8355. 0.1178 s / img. ETA=0:01:42
[32m[04/20 20:47:45 d2.evaluation.evaluator]: [0mInference done 7541/8355. 0.1178 s / img. ETA=0:01:37
[32m[04/20 20:47:50 d2.evaluation.evaluator]: [0mInference done 7583/8355. 0.1178 s / img. ETA=0:01:32
[32m[04/20 20:47:55 d2.evaluation.evaluator]: [0mInference done 7624/8355. 0.1178 s / img. ETA=0:01:27
[32m[04/20 20:48:00 d2.evaluation.evaluator]: [0mInference done 7666/8355. 0.1178 s / img. ETA=0:01:22
[32m[04/20 20:48:05 d2.evaluation.evaluator]: [0mInference done 7707/8355. 0.1178 s / img. ETA=0:01:17
[32m[04/20 20:48:10 d2.evaluation.evaluator]: [0mInference done 7749/8355. 0.1178 s / img. ETA=0:01:12
[32m[04/20 20:48:15 d2.evaluation.evaluator]: [0mInference done 7791/8355. 0.1178 s / img. ETA=0:01:07
[32m[04/20 20:48:20 d2.evaluation.evaluator]: [0mInference done 7833/8355. 0.1178 s / img. ETA=0:01:02
[32m[04/20 20:48:25 d2.evaluation.evaluator]: [0mInference done 7875/8355. 0.1178 s / img. ETA=0:00:57
[32m[04/20 20:48:30 d2.evaluation.evaluator]: [0mInference done 7917/8355. 0.1179 s / img. ETA=0:00:52
[32m[04/20 20:48:35 d2.evaluation.evaluator]: [0mInference done 7959/8355. 0.1179 s / img. ETA=0:00:47
[32m[04/20 20:48:40 d2.evaluation.evaluator]: [0mInference done 8001/8355. 0.1179 s / img. ETA=0:00:42
[32m[04/20 20:48:45 d2.evaluation.evaluator]: [0mInference done 8043/8355. 0.1179 s / img. ETA=0:00:37
[32m[04/20 20:48:50 d2.evaluation.evaluator]: [0mInference done 8085/8355. 0.1179 s / img. ETA=0:00:32
[32m[04/20 20:48:55 d2.evaluation.evaluator]: [0mInference done 8127/8355. 0.1179 s / img. ETA=0:00:27
[32m[04/20 20:49:00 d2.evaluation.evaluator]: [0mInference done 8169/8355. 0.1178 s / img. ETA=0:00:22
[32m[04/20 20:49:05 d2.evaluation.evaluator]: [0mInference done 8211/8355. 0.1178 s / img. ETA=0:00:17
[32m[04/20 20:49:11 d2.evaluation.evaluator]: [0mInference done 8253/8355. 0.1178 s / img. ETA=0:00:12
[32m[04/20 20:49:16 d2.evaluation.evaluator]: [0mInference done 8295/8355. 0.1178 s / img. ETA=0:00:07
[32m[04/20 20:49:21 d2.evaluation.evaluator]: [0mInference done 8337/8355. 0.1178 s / img. ETA=0:00:02
[32m[04/20 20:49:23 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:44.317559 (0.120278 s / img per device, on 1 devices)
[32m[04/20 20:49:23 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:24 (0.117850 s / img per device, on 1 devices)
[32m[04/20 20:49:23 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 20:49:23 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 20:49:23 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=34.52s).
Accumulating evaluation results...
DONE (t=3.55s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.417
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.758
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.406
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.313
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.546
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.164
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.466
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.483
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.389
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.712
[32m[04/20 20:50:02 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.716 | 75.794 | 40.626 | 31.317 | 54.565 | 67.366 |
[32m[04/20 20:50:02 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 41.621 | bicycle       | 30.796 | car            | 52.730 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 20:50:03 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 20:50:03 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 20:50:03 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 20:50:05 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1187 s / img. ETA=0:02:31
[32m[04/20 20:50:10 d2.evaluation.evaluator]: [0mInference done 53/1257. 0.1177 s / img. ETA=0:02:24
[32m[04/20 20:50:15 d2.evaluation.evaluator]: [0mInference done 95/1257. 0.1179 s / img. ETA=0:02:19
[32m[04/20 20:50:20 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1180 s / img. ETA=0:02:14
[32m[04/20 20:50:25 d2.evaluation.evaluator]: [0mInference done 179/1257. 0.1180 s / img. ETA=0:02:09
[32m[04/20 20:50:30 d2.evaluation.evaluator]: [0mInference done 221/1257. 0.1179 s / img. ETA=0:02:04
[32m[04/20 20:50:35 d2.evaluation.evaluator]: [0mInference done 263/1257. 0.1180 s / img. ETA=0:01:59
[32m[04/20 20:50:40 d2.evaluation.evaluator]: [0mInference done 305/1257. 0.1181 s / img. ETA=0:01:54
[32m[04/20 20:50:45 d2.evaluation.evaluator]: [0mInference done 347/1257. 0.1181 s / img. ETA=0:01:49
[32m[04/20 20:50:50 d2.evaluation.evaluator]: [0mInference done 389/1257. 0.1181 s / img. ETA=0:01:44
[32m[04/20 20:50:55 d2.evaluation.evaluator]: [0mInference done 431/1257. 0.1181 s / img. ETA=0:01:39
[32m[04/20 20:51:00 d2.evaluation.evaluator]: [0mInference done 473/1257. 0.1182 s / img. ETA=0:01:34
[32m[04/20 20:51:05 d2.evaluation.evaluator]: [0mInference done 515/1257. 0.1182 s / img. ETA=0:01:29
[32m[04/20 20:51:10 d2.evaluation.evaluator]: [0mInference done 557/1257. 0.1182 s / img. ETA=0:01:24
[32m[04/20 20:51:16 d2.evaluation.evaluator]: [0mInference done 599/1257. 0.1183 s / img. ETA=0:01:19
[32m[04/20 20:51:21 d2.evaluation.evaluator]: [0mInference done 641/1257. 0.1183 s / img. ETA=0:01:14
[32m[04/20 20:51:26 d2.evaluation.evaluator]: [0mInference done 683/1257. 0.1183 s / img. ETA=0:01:09
[32m[04/20 20:51:31 d2.evaluation.evaluator]: [0mInference done 724/1257. 0.1183 s / img. ETA=0:01:04
[32m[04/20 20:51:36 d2.evaluation.evaluator]: [0mInference done 766/1257. 0.1183 s / img. ETA=0:00:59
[32m[04/20 20:51:41 d2.evaluation.evaluator]: [0mInference done 808/1257. 0.1183 s / img. ETA=0:00:54
[32m[04/20 20:51:46 d2.evaluation.evaluator]: [0mInference done 850/1257. 0.1184 s / img. ETA=0:00:49
[32m[04/20 20:51:51 d2.evaluation.evaluator]: [0mInference done 892/1257. 0.1184 s / img. ETA=0:00:44
[32m[04/20 20:51:56 d2.evaluation.evaluator]: [0mInference done 934/1257. 0.1183 s / img. ETA=0:00:39
[32m[04/20 20:52:01 d2.evaluation.evaluator]: [0mInference done 976/1257. 0.1183 s / img. ETA=0:00:33
[32m[04/20 20:52:06 d2.evaluation.evaluator]: [0mInference done 1018/1257. 0.1184 s / img. ETA=0:00:28
[32m[04/20 20:52:11 d2.evaluation.evaluator]: [0mInference done 1060/1257. 0.1183 s / img. ETA=0:00:23
[32m[04/20 20:52:16 d2.evaluation.evaluator]: [0mInference done 1102/1257. 0.1184 s / img. ETA=0:00:18
[32m[04/20 20:52:22 d2.evaluation.evaluator]: [0mInference done 1144/1257. 0.1184 s / img. ETA=0:00:13
[32m[04/20 20:52:27 d2.evaluation.evaluator]: [0mInference done 1186/1257. 0.1184 s / img. ETA=0:00:08
[32m[04/20 20:52:32 d2.evaluation.evaluator]: [0mInference done 1228/1257. 0.1184 s / img. ETA=0:00:03
[32m[04/20 20:52:35 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:31.518551 (0.121021 s / img per device, on 1 devices)
[32m[04/20 20:52:35 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:28 (0.118382 s / img per device, on 1 devices)
[32m[04/20 20:52:35 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 20:52:35 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 20:52:35 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.11s).
Accumulating evaluation results...
DONE (t=0.67s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.583
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.273
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.365
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.483
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.132
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.263
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.428
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.512
[32m[04/20 20:52:39 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 30.200 | 58.310 | 27.349 | 19.450 | 36.475 | 48.321 |
[32m[04/20 20:52:39 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP    | category       | AP     |
|:--------------|:-------|:--------------|:------|:---------------|:-------|
| person        | 34.887 | bicycle       | 8.329 | car            | 47.385 |
| motorcycle    | nan    | airplane      | nan   | bus            | nan    |
| train         | nan    | truck         | nan   | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan   | stop sign      | nan    |
| parking meter | nan    | bench         | nan   | bird           | nan    |
| cat           | nan    | dog           | nan   | horse          | nan    |
| sheep         | nan    | cow           | nan   | elephant       | nan    |
| bear          | nan    | zebra         | nan   | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan   | handbag        | nan    |
| tie           | nan    | suitcase      | nan   | frisbee        | nan    |
| skis          | nan    | snowboard     | nan   | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan   | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan   | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan   | cup            | nan    |
| fork          | nan    | knife         | nan   | spoon          | nan    |
| bowl          | nan    | banana        | nan   | apple          | nan    |
| sandwich      | nan    | orange        | nan   | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan   | pizza          | nan    |
| donut         | nan    | cake          | nan   | chair          | nan    |
| couch         | nan    | potted plant  | nan   | bed            | nan    |
| dining table  | nan    | toilet        | nan   | tv             | nan    |
| laptop        | nan    | mouse         | nan   | remote         | nan    |
| keyboard      | nan    | cell phone    | nan   | microwave      | nan    |
| oven          | nan    | bike          | nan   | hydrant        | nan    |
| motor         | nan    | rider         | nan   | light          | nan    |
| sign          | nan    | motor vehicle | nan   | human face     | nan    |
| hair drier    | nan    | license plate | nan   |                |        |
============== The  25  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 20:52:40 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 20:52:40 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 20:52:40 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 20:52:41 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 20:52:41 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 20:52:41 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 20:52:41 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 20:53:02 d2.utils.events]: [0m eta: 0:17:46  iter: 19  total_loss: 0.613  loss_cls: 0.190  loss_box_reg: 0.352  loss_rpn_cls: 0.011  loss_rpn_loc: 0.059  time: 1.0573  data_time: 0.0294  lr: 0.000100  max_mem: 5406M
[32m[04/20 20:53:23 d2.utils.events]: [0m eta: 0:17:03  iter: 39  total_loss: 0.549  loss_cls: 0.180  loss_box_reg: 0.320  loss_rpn_cls: 0.016  loss_rpn_loc: 0.037  time: 1.0465  data_time: 0.0109  lr: 0.000200  max_mem: 5406M
[32m[04/20 20:53:43 d2.utils.events]: [0m eta: 0:16:31  iter: 59  total_loss: 0.597  loss_cls: 0.180  loss_box_reg: 0.313  loss_rpn_cls: 0.012  loss_rpn_loc: 0.061  time: 1.0354  data_time: 0.0109  lr: 0.000300  max_mem: 5406M
[32m[04/20 20:54:04 d2.utils.events]: [0m eta: 0:15:51  iter: 79  total_loss: 0.524  loss_cls: 0.158  loss_box_reg: 0.307  loss_rpn_cls: 0.009  loss_rpn_loc: 0.052  time: 1.0282  data_time: 0.0120  lr: 0.000400  max_mem: 5406M
[32m[04/20 20:54:24 d2.utils.events]: [0m eta: 0:15:26  iter: 99  total_loss: 0.563  loss_cls: 0.185  loss_box_reg: 0.327  loss_rpn_cls: 0.010  loss_rpn_loc: 0.051  time: 1.0240  data_time: 0.0122  lr: 0.000500  max_mem: 5406M
[32m[04/20 20:54:44 d2.utils.events]: [0m eta: 0:15:04  iter: 119  total_loss: 0.546  loss_cls: 0.169  loss_box_reg: 0.314  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0239  data_time: 0.0109  lr: 0.000599  max_mem: 5406M
[32m[04/20 20:55:05 d2.utils.events]: [0m eta: 0:14:44  iter: 139  total_loss: 0.550  loss_cls: 0.175  loss_box_reg: 0.298  loss_rpn_cls: 0.010  loss_rpn_loc: 0.043  time: 1.0252  data_time: 0.0112  lr: 0.000699  max_mem: 5406M
[32m[04/20 20:55:26 d2.utils.events]: [0m eta: 0:14:25  iter: 159  total_loss: 0.521  loss_cls: 0.165  loss_box_reg: 0.295  loss_rpn_cls: 0.009  loss_rpn_loc: 0.037  time: 1.0276  data_time: 0.0114  lr: 0.000799  max_mem: 5406M
[32m[04/20 20:55:46 d2.utils.events]: [0m eta: 0:14:02  iter: 179  total_loss: 0.498  loss_cls: 0.157  loss_box_reg: 0.290  loss_rpn_cls: 0.011  loss_rpn_loc: 0.042  time: 1.0270  data_time: 0.0112  lr: 0.000899  max_mem: 5406M
[32m[04/20 20:56:07 d2.utils.events]: [0m eta: 0:13:42  iter: 199  total_loss: 0.563  loss_cls: 0.169  loss_box_reg: 0.320  loss_rpn_cls: 0.009  loss_rpn_loc: 0.047  time: 1.0273  data_time: 0.0119  lr: 0.000999  max_mem: 5406M
[32m[04/20 20:56:28 d2.utils.events]: [0m eta: 0:13:25  iter: 219  total_loss: 0.563  loss_cls: 0.165  loss_box_reg: 0.315  loss_rpn_cls: 0.011  loss_rpn_loc: 0.060  time: 1.0281  data_time: 0.0106  lr: 0.001099  max_mem: 5406M
[32m[04/20 20:56:48 d2.utils.events]: [0m eta: 0:13:04  iter: 239  total_loss: 0.581  loss_cls: 0.182  loss_box_reg: 0.334  loss_rpn_cls: 0.012  loss_rpn_loc: 0.046  time: 1.0279  data_time: 0.0118  lr: 0.001199  max_mem: 5406M
[32m[04/20 20:57:09 d2.utils.events]: [0m eta: 0:12:44  iter: 259  total_loss: 0.578  loss_cls: 0.179  loss_box_reg: 0.319  loss_rpn_cls: 0.011  loss_rpn_loc: 0.041  time: 1.0291  data_time: 0.0104  lr: 0.001299  max_mem: 5406M
[32m[04/20 20:57:30 d2.utils.events]: [0m eta: 0:12:25  iter: 279  total_loss: 0.525  loss_cls: 0.164  loss_box_reg: 0.294  loss_rpn_cls: 0.010  loss_rpn_loc: 0.045  time: 1.0303  data_time: 0.0109  lr: 0.001399  max_mem: 5406M
[32m[04/20 20:57:51 d2.utils.events]: [0m eta: 0:12:03  iter: 299  total_loss: 0.508  loss_cls: 0.153  loss_box_reg: 0.295  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 1.0299  data_time: 0.0109  lr: 0.001499  max_mem: 5406M
[32m[04/20 20:58:12 d2.utils.events]: [0m eta: 0:11:44  iter: 319  total_loss: 0.476  loss_cls: 0.142  loss_box_reg: 0.276  loss_rpn_cls: 0.010  loss_rpn_loc: 0.039  time: 1.0318  data_time: 0.0108  lr: 0.001598  max_mem: 5406M
[32m[04/20 20:58:32 d2.utils.events]: [0m eta: 0:11:22  iter: 339  total_loss: 0.524  loss_cls: 0.162  loss_box_reg: 0.306  loss_rpn_cls: 0.010  loss_rpn_loc: 0.041  time: 1.0305  data_time: 0.0118  lr: 0.001698  max_mem: 5406M
[32m[04/20 20:58:53 d2.utils.events]: [0m eta: 0:11:02  iter: 359  total_loss: 0.635  loss_cls: 0.195  loss_box_reg: 0.357  loss_rpn_cls: 0.010  loss_rpn_loc: 0.052  time: 1.0309  data_time: 0.0117  lr: 0.001798  max_mem: 5406M
[32m[04/20 20:59:14 d2.utils.events]: [0m eta: 0:10:42  iter: 379  total_loss: 0.526  loss_cls: 0.168  loss_box_reg: 0.312  loss_rpn_cls: 0.009  loss_rpn_loc: 0.039  time: 1.0314  data_time: 0.0117  lr: 0.001898  max_mem: 5406M
[32m[04/20 20:59:35 d2.utils.events]: [0m eta: 0:10:21  iter: 399  total_loss: 0.564  loss_cls: 0.170  loss_box_reg: 0.307  loss_rpn_cls: 0.010  loss_rpn_loc: 0.048  time: 1.0317  data_time: 0.0113  lr: 0.001998  max_mem: 5406M
[32m[04/20 20:59:55 d2.utils.events]: [0m eta: 0:10:00  iter: 419  total_loss: 0.525  loss_cls: 0.173  loss_box_reg: 0.308  loss_rpn_cls: 0.011  loss_rpn_loc: 0.045  time: 1.0312  data_time: 0.0102  lr: 0.002098  max_mem: 5406M
[32m[04/20 21:00:16 d2.utils.events]: [0m eta: 0:09:39  iter: 439  total_loss: 0.544  loss_cls: 0.171  loss_box_reg: 0.321  loss_rpn_cls: 0.009  loss_rpn_loc: 0.048  time: 1.0307  data_time: 0.0117  lr: 0.002198  max_mem: 5406M
[32m[04/20 21:00:37 d2.utils.events]: [0m eta: 0:09:19  iter: 459  total_loss: 0.626  loss_cls: 0.184  loss_box_reg: 0.353  loss_rpn_cls: 0.014  loss_rpn_loc: 0.051  time: 1.0312  data_time: 0.0107  lr: 0.002298  max_mem: 5406M
[32m[04/20 21:00:58 d2.utils.events]: [0m eta: 0:08:59  iter: 479  total_loss: 0.517  loss_cls: 0.163  loss_box_reg: 0.305  loss_rpn_cls: 0.012  loss_rpn_loc: 0.049  time: 1.0322  data_time: 0.0112  lr: 0.002398  max_mem: 5406M
[32m[04/20 21:01:18 d2.utils.events]: [0m eta: 0:08:38  iter: 499  total_loss: 0.524  loss_cls: 0.166  loss_box_reg: 0.310  loss_rpn_cls: 0.012  loss_rpn_loc: 0.050  time: 1.0321  data_time: 0.0111  lr: 0.002498  max_mem: 5406M
[32m[04/20 21:01:39 d2.utils.events]: [0m eta: 0:08:17  iter: 519  total_loss: 0.537  loss_cls: 0.173  loss_box_reg: 0.310  loss_rpn_cls: 0.011  loss_rpn_loc: 0.050  time: 1.0322  data_time: 0.0104  lr: 0.002597  max_mem: 5406M
[32m[04/20 21:02:00 d2.utils.events]: [0m eta: 0:07:57  iter: 539  total_loss: 0.540  loss_cls: 0.178  loss_box_reg: 0.309  loss_rpn_cls: 0.014  loss_rpn_loc: 0.042  time: 1.0327  data_time: 0.0115  lr: 0.002697  max_mem: 5406M
[32m[04/20 21:02:20 d2.utils.events]: [0m eta: 0:07:35  iter: 559  total_loss: 0.637  loss_cls: 0.190  loss_box_reg: 0.360  loss_rpn_cls: 0.013  loss_rpn_loc: 0.052  time: 1.0313  data_time: 0.0117  lr: 0.002797  max_mem: 5406M
[32m[04/20 21:02:42 d2.utils.events]: [0m eta: 0:07:15  iter: 579  total_loss: 0.506  loss_cls: 0.155  loss_box_reg: 0.283  loss_rpn_cls: 0.013  loss_rpn_loc: 0.038  time: 1.0323  data_time: 0.0102  lr: 0.002897  max_mem: 5406M
[32m[04/20 21:03:02 d2.utils.events]: [0m eta: 0:06:55  iter: 599  total_loss: 0.565  loss_cls: 0.170  loss_box_reg: 0.322  loss_rpn_cls: 0.009  loss_rpn_loc: 0.053  time: 1.0325  data_time: 0.0103  lr: 0.002997  max_mem: 5406M
[32m[04/20 21:03:23 d2.utils.events]: [0m eta: 0:06:34  iter: 619  total_loss: 0.542  loss_cls: 0.167  loss_box_reg: 0.329  loss_rpn_cls: 0.010  loss_rpn_loc: 0.042  time: 1.0320  data_time: 0.0108  lr: 0.003097  max_mem: 5406M
[32m[04/20 21:03:43 d2.utils.events]: [0m eta: 0:06:13  iter: 639  total_loss: 0.545  loss_cls: 0.175  loss_box_reg: 0.309  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 1.0315  data_time: 0.0104  lr: 0.003197  max_mem: 5406M
[32m[04/20 21:04:03 d2.utils.events]: [0m eta: 0:05:52  iter: 659  total_loss: 0.559  loss_cls: 0.192  loss_box_reg: 0.309  loss_rpn_cls: 0.011  loss_rpn_loc: 0.050  time: 1.0311  data_time: 0.0101  lr: 0.003297  max_mem: 5406M
[32m[04/20 21:04:25 d2.utils.events]: [0m eta: 0:05:32  iter: 679  total_loss: 0.492  loss_cls: 0.152  loss_box_reg: 0.266  loss_rpn_cls: 0.009  loss_rpn_loc: 0.042  time: 1.0317  data_time: 0.0102  lr: 0.003397  max_mem: 5406M
[32m[04/20 21:04:46 d2.utils.events]: [0m eta: 0:05:11  iter: 699  total_loss: 0.614  loss_cls: 0.181  loss_box_reg: 0.350  loss_rpn_cls: 0.011  loss_rpn_loc: 0.050  time: 1.0318  data_time: 0.0102  lr: 0.003497  max_mem: 5406M
[32m[04/20 21:05:06 d2.utils.events]: [0m eta: 0:04:50  iter: 719  total_loss: 0.612  loss_cls: 0.187  loss_box_reg: 0.334  loss_rpn_cls: 0.013  loss_rpn_loc: 0.062  time: 1.0312  data_time: 0.0107  lr: 0.003596  max_mem: 5406M
[32m[04/20 21:05:27 d2.utils.events]: [0m eta: 0:04:29  iter: 739  total_loss: 0.573  loss_cls: 0.182  loss_box_reg: 0.315  loss_rpn_cls: 0.014  loss_rpn_loc: 0.063  time: 1.0317  data_time: 0.0122  lr: 0.003696  max_mem: 5406M
[32m[04/20 21:05:47 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.563  loss_cls: 0.178  loss_box_reg: 0.332  loss_rpn_cls: 0.011  loss_rpn_loc: 0.056  time: 1.0316  data_time: 0.0105  lr: 0.003796  max_mem: 5406M
[32m[04/20 21:06:08 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.515  loss_cls: 0.178  loss_box_reg: 0.283  loss_rpn_cls: 0.010  loss_rpn_loc: 0.040  time: 1.0319  data_time: 0.0113  lr: 0.003896  max_mem: 5406M
[32m[04/20 21:06:29 d2.utils.events]: [0m eta: 0:03:27  iter: 799  total_loss: 0.591  loss_cls: 0.190  loss_box_reg: 0.318  loss_rpn_cls: 0.014  loss_rpn_loc: 0.048  time: 1.0318  data_time: 0.0109  lr: 0.003996  max_mem: 5406M
[32m[04/20 21:06:50 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.557  loss_cls: 0.167  loss_box_reg: 0.331  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 1.0323  data_time: 0.0115  lr: 0.004096  max_mem: 5406M
[32m[04/20 21:07:11 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.524  loss_cls: 0.168  loss_box_reg: 0.288  loss_rpn_cls: 0.010  loss_rpn_loc: 0.051  time: 1.0324  data_time: 0.0110  lr: 0.004196  max_mem: 5406M
[32m[04/20 21:07:32 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.637  loss_cls: 0.205  loss_box_reg: 0.364  loss_rpn_cls: 0.011  loss_rpn_loc: 0.050  time: 1.0326  data_time: 0.0110  lr: 0.004296  max_mem: 5406M
[32m[04/20 21:07:52 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.476  loss_cls: 0.158  loss_box_reg: 0.272  loss_rpn_cls: 0.010  loss_rpn_loc: 0.044  time: 1.0323  data_time: 0.0102  lr: 0.004396  max_mem: 5406M
[32m[04/20 21:08:13 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.525  loss_cls: 0.167  loss_box_reg: 0.284  loss_rpn_cls: 0.011  loss_rpn_loc: 0.049  time: 1.0323  data_time: 0.0098  lr: 0.004496  max_mem: 5406M
[32m[04/20 21:08:34 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.604  loss_cls: 0.184  loss_box_reg: 0.332  loss_rpn_cls: 0.014  loss_rpn_loc: 0.048  time: 1.0329  data_time: 0.0096  lr: 0.004595  max_mem: 5406M
[32m[04/20 21:08:55 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.579  loss_cls: 0.177  loss_box_reg: 0.320  loss_rpn_cls: 0.011  loss_rpn_loc: 0.058  time: 1.0328  data_time: 0.0096  lr: 0.004695  max_mem: 5406M
[32m[04/20 21:09:15 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.588  loss_cls: 0.187  loss_box_reg: 0.342  loss_rpn_cls: 0.015  loss_rpn_loc: 0.049  time: 1.0328  data_time: 0.0097  lr: 0.004795  max_mem: 5406M
[32m[04/20 21:09:36 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.587  loss_cls: 0.176  loss_box_reg: 0.335  loss_rpn_cls: 0.014  loss_rpn_loc: 0.048  time: 1.0327  data_time: 0.0094  lr: 0.004895  max_mem: 5406M
[5m[31mWARNING[0m [32m[04/20 21:09:59 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 21:09:59 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 21:10:00 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 21:10:00 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.564  loss_cls: 0.179  loss_box_reg: 0.308  loss_rpn_cls: 0.010  loss_rpn_loc: 0.046  time: 1.0327  data_time: 0.0096  lr: 0.004995  max_mem: 5406M
[32m[04/20 21:10:01 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:10 (1.0338 s / it)
[32m[04/20 21:10:01 d2.engine.hooks]: [0mTotal training time: 0:17:17 (0:00:06 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 21:10:03 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 21:10:03 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 21:10:03 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 21:10:04 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1164 s / img. ETA=0:16:25
[32m[04/20 21:10:10 d2.evaluation.evaluator]: [0mInference done 54/8355. 0.1163 s / img. ETA=0:16:22
[32m[04/20 21:10:15 d2.evaluation.evaluator]: [0mInference done 97/8355. 0.1161 s / img. ETA=0:16:15
[32m[04/20 21:10:20 d2.evaluation.evaluator]: [0mInference done 140/8355. 0.1160 s / img. ETA=0:16:09
[32m[04/20 21:10:25 d2.evaluation.evaluator]: [0mInference done 183/8355. 0.1159 s / img. ETA=0:16:03
[32m[04/20 21:10:30 d2.evaluation.evaluator]: [0mInference done 226/8355. 0.1159 s / img. ETA=0:15:59
[32m[04/20 21:10:35 d2.evaluation.evaluator]: [0mInference done 269/8355. 0.1159 s / img. ETA=0:15:54
[32m[04/20 21:10:40 d2.evaluation.evaluator]: [0mInference done 312/8355. 0.1160 s / img. ETA=0:15:50
[32m[04/20 21:10:45 d2.evaluation.evaluator]: [0mInference done 355/8355. 0.1161 s / img. ETA=0:15:45
[32m[04/20 21:10:50 d2.evaluation.evaluator]: [0mInference done 397/8355. 0.1161 s / img. ETA=0:15:41
[32m[04/20 21:10:55 d2.evaluation.evaluator]: [0mInference done 440/8355. 0.1162 s / img. ETA=0:15:37
[32m[04/20 21:11:00 d2.evaluation.evaluator]: [0mInference done 483/8355. 0.1162 s / img. ETA=0:15:31
[32m[04/20 21:11:05 d2.evaluation.evaluator]: [0mInference done 526/8355. 0.1161 s / img. ETA=0:15:26
[32m[04/20 21:11:11 d2.evaluation.evaluator]: [0mInference done 569/8355. 0.1161 s / img. ETA=0:15:21
[32m[04/20 21:11:16 d2.evaluation.evaluator]: [0mInference done 612/8355. 0.1161 s / img. ETA=0:15:16
[32m[04/20 21:11:21 d2.evaluation.evaluator]: [0mInference done 655/8355. 0.1162 s / img. ETA=0:15:11
[32m[04/20 21:11:26 d2.evaluation.evaluator]: [0mInference done 698/8355. 0.1162 s / img. ETA=0:15:06
[32m[04/20 21:11:31 d2.evaluation.evaluator]: [0mInference done 741/8355. 0.1162 s / img. ETA=0:15:01
[32m[04/20 21:11:36 d2.evaluation.evaluator]: [0mInference done 784/8355. 0.1162 s / img. ETA=0:14:56
[32m[04/20 21:11:41 d2.evaluation.evaluator]: [0mInference done 827/8355. 0.1162 s / img. ETA=0:14:51
[32m[04/20 21:11:46 d2.evaluation.evaluator]: [0mInference done 870/8355. 0.1162 s / img. ETA=0:14:46
[32m[04/20 21:11:51 d2.evaluation.evaluator]: [0mInference done 912/8355. 0.1162 s / img. ETA=0:14:42
[32m[04/20 21:11:56 d2.evaluation.evaluator]: [0mInference done 955/8355. 0.1162 s / img. ETA=0:14:37
[32m[04/20 21:12:01 d2.evaluation.evaluator]: [0mInference done 998/8355. 0.1162 s / img. ETA=0:14:31
[32m[04/20 21:12:07 d2.evaluation.evaluator]: [0mInference done 1041/8355. 0.1162 s / img. ETA=0:14:26
[32m[04/20 21:12:12 d2.evaluation.evaluator]: [0mInference done 1084/8355. 0.1162 s / img. ETA=0:14:21
[32m[04/20 21:12:17 d2.evaluation.evaluator]: [0mInference done 1127/8355. 0.1162 s / img. ETA=0:14:16
[32m[04/20 21:12:22 d2.evaluation.evaluator]: [0mInference done 1170/8355. 0.1162 s / img. ETA=0:14:11
[32m[04/20 21:12:27 d2.evaluation.evaluator]: [0mInference done 1213/8355. 0.1162 s / img. ETA=0:14:06
[32m[04/20 21:12:32 d2.evaluation.evaluator]: [0mInference done 1256/8355. 0.1162 s / img. ETA=0:14:00
[32m[04/20 21:12:37 d2.evaluation.evaluator]: [0mInference done 1299/8355. 0.1162 s / img. ETA=0:13:55
[32m[04/20 21:12:42 d2.evaluation.evaluator]: [0mInference done 1342/8355. 0.1162 s / img. ETA=0:13:50
[32m[04/20 21:12:47 d2.evaluation.evaluator]: [0mInference done 1385/8355. 0.1162 s / img. ETA=0:13:45
[32m[04/20 21:12:52 d2.evaluation.evaluator]: [0mInference done 1428/8355. 0.1161 s / img. ETA=0:13:40
[32m[04/20 21:12:57 d2.evaluation.evaluator]: [0mInference done 1471/8355. 0.1161 s / img. ETA=0:13:35
[32m[04/20 21:13:02 d2.evaluation.evaluator]: [0mInference done 1513/8355. 0.1162 s / img. ETA=0:13:30
[32m[04/20 21:13:07 d2.evaluation.evaluator]: [0mInference done 1555/8355. 0.1162 s / img. ETA=0:13:25
[32m[04/20 21:13:12 d2.evaluation.evaluator]: [0mInference done 1597/8355. 0.1163 s / img. ETA=0:13:21
[32m[04/20 21:13:18 d2.evaluation.evaluator]: [0mInference done 1639/8355. 0.1163 s / img. ETA=0:13:16
[32m[04/20 21:13:23 d2.evaluation.evaluator]: [0mInference done 1681/8355. 0.1163 s / img. ETA=0:13:11
[32m[04/20 21:13:28 d2.evaluation.evaluator]: [0mInference done 1723/8355. 0.1164 s / img. ETA=0:13:07
[32m[04/20 21:13:33 d2.evaluation.evaluator]: [0mInference done 1765/8355. 0.1164 s / img. ETA=0:13:02
[32m[04/20 21:13:38 d2.evaluation.evaluator]: [0mInference done 1807/8355. 0.1164 s / img. ETA=0:12:57
[32m[04/20 21:13:43 d2.evaluation.evaluator]: [0mInference done 1849/8355. 0.1165 s / img. ETA=0:12:52
[32m[04/20 21:13:48 d2.evaluation.evaluator]: [0mInference done 1889/8355. 0.1166 s / img. ETA=0:12:49
[32m[04/20 21:13:53 d2.evaluation.evaluator]: [0mInference done 1931/8355. 0.1166 s / img. ETA=0:12:44
[32m[04/20 21:13:58 d2.evaluation.evaluator]: [0mInference done 1973/8355. 0.1166 s / img. ETA=0:12:39
[32m[04/20 21:14:03 d2.evaluation.evaluator]: [0mInference done 2015/8355. 0.1167 s / img. ETA=0:12:34
[32m[04/20 21:14:08 d2.evaluation.evaluator]: [0mInference done 2057/8355. 0.1167 s / img. ETA=0:12:29
[32m[04/20 21:14:13 d2.evaluation.evaluator]: [0mInference done 2099/8355. 0.1167 s / img. ETA=0:12:24
[32m[04/20 21:14:18 d2.evaluation.evaluator]: [0mInference done 2142/8355. 0.1167 s / img. ETA=0:12:19
[32m[04/20 21:14:23 d2.evaluation.evaluator]: [0mInference done 2184/8355. 0.1167 s / img. ETA=0:12:14
[32m[04/20 21:14:28 d2.evaluation.evaluator]: [0mInference done 2227/8355. 0.1167 s / img. ETA=0:12:09
[32m[04/20 21:14:33 d2.evaluation.evaluator]: [0mInference done 2269/8355. 0.1167 s / img. ETA=0:12:04
[32m[04/20 21:14:38 d2.evaluation.evaluator]: [0mInference done 2311/8355. 0.1167 s / img. ETA=0:11:59
[32m[04/20 21:14:43 d2.evaluation.evaluator]: [0mInference done 2354/8355. 0.1167 s / img. ETA=0:11:54
[32m[04/20 21:14:48 d2.evaluation.evaluator]: [0mInference done 2396/8355. 0.1167 s / img. ETA=0:11:49
[32m[04/20 21:14:53 d2.evaluation.evaluator]: [0mInference done 2438/8355. 0.1167 s / img. ETA=0:11:44
[32m[04/20 21:14:58 d2.evaluation.evaluator]: [0mInference done 2481/8355. 0.1167 s / img. ETA=0:11:39
[32m[04/20 21:15:03 d2.evaluation.evaluator]: [0mInference done 2523/8355. 0.1167 s / img. ETA=0:11:34
[32m[04/20 21:15:08 d2.evaluation.evaluator]: [0mInference done 2565/8355. 0.1167 s / img. ETA=0:11:29
[32m[04/20 21:15:13 d2.evaluation.evaluator]: [0mInference done 2607/8355. 0.1167 s / img. ETA=0:11:24
[32m[04/20 21:15:18 d2.evaluation.evaluator]: [0mInference done 2649/8355. 0.1167 s / img. ETA=0:11:19
[32m[04/20 21:15:23 d2.evaluation.evaluator]: [0mInference done 2691/8355. 0.1167 s / img. ETA=0:11:14
[32m[04/20 21:15:28 d2.evaluation.evaluator]: [0mInference done 2733/8355. 0.1167 s / img. ETA=0:11:09
[32m[04/20 21:15:33 d2.evaluation.evaluator]: [0mInference done 2775/8355. 0.1167 s / img. ETA=0:11:04
[32m[04/20 21:15:39 d2.evaluation.evaluator]: [0mInference done 2817/8355. 0.1168 s / img. ETA=0:10:59
[32m[04/20 21:15:44 d2.evaluation.evaluator]: [0mInference done 2859/8355. 0.1168 s / img. ETA=0:10:54
[32m[04/20 21:15:49 d2.evaluation.evaluator]: [0mInference done 2901/8355. 0.1168 s / img. ETA=0:10:49
[32m[04/20 21:15:54 d2.evaluation.evaluator]: [0mInference done 2943/8355. 0.1168 s / img. ETA=0:10:44
[32m[04/20 21:15:59 d2.evaluation.evaluator]: [0mInference done 2985/8355. 0.1168 s / img. ETA=0:10:39
[32m[04/20 21:16:04 d2.evaluation.evaluator]: [0mInference done 3028/8355. 0.1168 s / img. ETA=0:10:34
[32m[04/20 21:16:09 d2.evaluation.evaluator]: [0mInference done 3070/8355. 0.1168 s / img. ETA=0:10:29
[32m[04/20 21:16:14 d2.evaluation.evaluator]: [0mInference done 3112/8355. 0.1168 s / img. ETA=0:10:24
[32m[04/20 21:16:19 d2.evaluation.evaluator]: [0mInference done 3155/8355. 0.1168 s / img. ETA=0:10:19
[32m[04/20 21:16:24 d2.evaluation.evaluator]: [0mInference done 3198/8355. 0.1168 s / img. ETA=0:10:14
[32m[04/20 21:16:29 d2.evaluation.evaluator]: [0mInference done 3241/8355. 0.1168 s / img. ETA=0:10:08
[32m[04/20 21:16:34 d2.evaluation.evaluator]: [0mInference done 3283/8355. 0.1168 s / img. ETA=0:10:03
[32m[04/20 21:16:39 d2.evaluation.evaluator]: [0mInference done 3326/8355. 0.1168 s / img. ETA=0:09:58
[32m[04/20 21:16:44 d2.evaluation.evaluator]: [0mInference done 3369/8355. 0.1168 s / img. ETA=0:09:53
[32m[04/20 21:16:49 d2.evaluation.evaluator]: [0mInference done 3412/8355. 0.1168 s / img. ETA=0:09:48
[32m[04/20 21:16:54 d2.evaluation.evaluator]: [0mInference done 3455/8355. 0.1168 s / img. ETA=0:09:43
[32m[04/20 21:16:59 d2.evaluation.evaluator]: [0mInference done 3497/8355. 0.1168 s / img. ETA=0:09:38
[32m[04/20 21:17:05 d2.evaluation.evaluator]: [0mInference done 3540/8355. 0.1168 s / img. ETA=0:09:33
[32m[04/20 21:17:10 d2.evaluation.evaluator]: [0mInference done 3583/8355. 0.1168 s / img. ETA=0:09:28
[32m[04/20 21:17:15 d2.evaluation.evaluator]: [0mInference done 3625/8355. 0.1168 s / img. ETA=0:09:23
[32m[04/20 21:17:20 d2.evaluation.evaluator]: [0mInference done 3667/8355. 0.1168 s / img. ETA=0:09:18
[32m[04/20 21:17:25 d2.evaluation.evaluator]: [0mInference done 3709/8355. 0.1168 s / img. ETA=0:09:13
[32m[04/20 21:17:30 d2.evaluation.evaluator]: [0mInference done 3752/8355. 0.1168 s / img. ETA=0:09:08
[32m[04/20 21:17:35 d2.evaluation.evaluator]: [0mInference done 3794/8355. 0.1168 s / img. ETA=0:09:03
[32m[04/20 21:17:40 d2.evaluation.evaluator]: [0mInference done 3836/8355. 0.1168 s / img. ETA=0:08:58
[32m[04/20 21:17:45 d2.evaluation.evaluator]: [0mInference done 3879/8355. 0.1168 s / img. ETA=0:08:52
[32m[04/20 21:17:50 d2.evaluation.evaluator]: [0mInference done 3921/8355. 0.1168 s / img. ETA=0:08:47
[32m[04/20 21:17:55 d2.evaluation.evaluator]: [0mInference done 3964/8355. 0.1168 s / img. ETA=0:08:42
[32m[04/20 21:18:00 d2.evaluation.evaluator]: [0mInference done 4006/8355. 0.1168 s / img. ETA=0:08:37
[32m[04/20 21:18:05 d2.evaluation.evaluator]: [0mInference done 4048/8355. 0.1168 s / img. ETA=0:08:32
[32m[04/20 21:18:10 d2.evaluation.evaluator]: [0mInference done 4090/8355. 0.1168 s / img. ETA=0:08:27
[32m[04/20 21:18:15 d2.evaluation.evaluator]: [0mInference done 4132/8355. 0.1168 s / img. ETA=0:08:22
[32m[04/20 21:18:20 d2.evaluation.evaluator]: [0mInference done 4174/8355. 0.1168 s / img. ETA=0:08:17
[32m[04/20 21:18:25 d2.evaluation.evaluator]: [0mInference done 4216/8355. 0.1169 s / img. ETA=0:08:13
[32m[04/20 21:18:30 d2.evaluation.evaluator]: [0mInference done 4258/8355. 0.1169 s / img. ETA=0:08:08
[32m[04/20 21:18:35 d2.evaluation.evaluator]: [0mInference done 4300/8355. 0.1169 s / img. ETA=0:08:03
[32m[04/20 21:18:40 d2.evaluation.evaluator]: [0mInference done 4342/8355. 0.1169 s / img. ETA=0:07:58
[32m[04/20 21:18:45 d2.evaluation.evaluator]: [0mInference done 4384/8355. 0.1169 s / img. ETA=0:07:53
[32m[04/20 21:18:50 d2.evaluation.evaluator]: [0mInference done 4426/8355. 0.1169 s / img. ETA=0:07:48
[32m[04/20 21:18:55 d2.evaluation.evaluator]: [0mInference done 4468/8355. 0.1169 s / img. ETA=0:07:43
[32m[04/20 21:19:01 d2.evaluation.evaluator]: [0mInference done 4510/8355. 0.1169 s / img. ETA=0:07:38
[32m[04/20 21:19:06 d2.evaluation.evaluator]: [0mInference done 4552/8355. 0.1169 s / img. ETA=0:07:33
[32m[04/20 21:19:11 d2.evaluation.evaluator]: [0mInference done 4594/8355. 0.1169 s / img. ETA=0:07:28
[32m[04/20 21:19:16 d2.evaluation.evaluator]: [0mInference done 4636/8355. 0.1169 s / img. ETA=0:07:23
[32m[04/20 21:19:21 d2.evaluation.evaluator]: [0mInference done 4678/8355. 0.1169 s / img. ETA=0:07:18
[32m[04/20 21:19:26 d2.evaluation.evaluator]: [0mInference done 4720/8355. 0.1169 s / img. ETA=0:07:13
[32m[04/20 21:19:31 d2.evaluation.evaluator]: [0mInference done 4762/8355. 0.1169 s / img. ETA=0:07:08
[32m[04/20 21:19:36 d2.evaluation.evaluator]: [0mInference done 4804/8355. 0.1169 s / img. ETA=0:07:03
[32m[04/20 21:19:41 d2.evaluation.evaluator]: [0mInference done 4846/8355. 0.1169 s / img. ETA=0:06:58
[32m[04/20 21:19:46 d2.evaluation.evaluator]: [0mInference done 4888/8355. 0.1169 s / img. ETA=0:06:53
[32m[04/20 21:19:51 d2.evaluation.evaluator]: [0mInference done 4930/8355. 0.1169 s / img. ETA=0:06:48
[32m[04/20 21:19:56 d2.evaluation.evaluator]: [0mInference done 4972/8355. 0.1169 s / img. ETA=0:06:43
[32m[04/20 21:20:01 d2.evaluation.evaluator]: [0mInference done 5014/8355. 0.1169 s / img. ETA=0:06:38
[32m[04/20 21:20:06 d2.evaluation.evaluator]: [0mInference done 5056/8355. 0.1169 s / img. ETA=0:06:33
[32m[04/20 21:20:11 d2.evaluation.evaluator]: [0mInference done 5098/8355. 0.1170 s / img. ETA=0:06:28
[32m[04/20 21:20:16 d2.evaluation.evaluator]: [0mInference done 5140/8355. 0.1170 s / img. ETA=0:06:23
[32m[04/20 21:20:21 d2.evaluation.evaluator]: [0mInference done 5182/8355. 0.1170 s / img. ETA=0:06:18
[32m[04/20 21:20:26 d2.evaluation.evaluator]: [0mInference done 5224/8355. 0.1170 s / img. ETA=0:06:13
[32m[04/20 21:20:31 d2.evaluation.evaluator]: [0mInference done 5266/8355. 0.1170 s / img. ETA=0:06:08
[32m[04/20 21:20:36 d2.evaluation.evaluator]: [0mInference done 5308/8355. 0.1170 s / img. ETA=0:06:03
[32m[04/20 21:20:41 d2.evaluation.evaluator]: [0mInference done 5350/8355. 0.1170 s / img. ETA=0:05:58
[32m[04/20 21:20:46 d2.evaluation.evaluator]: [0mInference done 5392/8355. 0.1170 s / img. ETA=0:05:53
[32m[04/20 21:20:51 d2.evaluation.evaluator]: [0mInference done 5434/8355. 0.1170 s / img. ETA=0:05:48
[32m[04/20 21:20:56 d2.evaluation.evaluator]: [0mInference done 5476/8355. 0.1170 s / img. ETA=0:05:43
[32m[04/20 21:21:01 d2.evaluation.evaluator]: [0mInference done 5518/8355. 0.1170 s / img. ETA=0:05:38
[32m[04/20 21:21:06 d2.evaluation.evaluator]: [0mInference done 5560/8355. 0.1170 s / img. ETA=0:05:33
[32m[04/20 21:21:11 d2.evaluation.evaluator]: [0mInference done 5603/8355. 0.1170 s / img. ETA=0:05:28
[32m[04/20 21:21:16 d2.evaluation.evaluator]: [0mInference done 5645/8355. 0.1170 s / img. ETA=0:05:23
[32m[04/20 21:21:22 d2.evaluation.evaluator]: [0mInference done 5687/8355. 0.1170 s / img. ETA=0:05:18
[32m[04/20 21:21:27 d2.evaluation.evaluator]: [0mInference done 5729/8355. 0.1170 s / img. ETA=0:05:13
[32m[04/20 21:21:32 d2.evaluation.evaluator]: [0mInference done 5771/8355. 0.1170 s / img. ETA=0:05:08
[32m[04/20 21:21:37 d2.evaluation.evaluator]: [0mInference done 5813/8355. 0.1170 s / img. ETA=0:05:03
[32m[04/20 21:21:42 d2.evaluation.evaluator]: [0mInference done 5855/8355. 0.1170 s / img. ETA=0:04:58
[32m[04/20 21:21:47 d2.evaluation.evaluator]: [0mInference done 5897/8355. 0.1170 s / img. ETA=0:04:53
[32m[04/20 21:21:52 d2.evaluation.evaluator]: [0mInference done 5939/8355. 0.1170 s / img. ETA=0:04:48
[32m[04/20 21:21:57 d2.evaluation.evaluator]: [0mInference done 5981/8355. 0.1170 s / img. ETA=0:04:43
[32m[04/20 21:22:02 d2.evaluation.evaluator]: [0mInference done 6023/8355. 0.1170 s / img. ETA=0:04:38
[32m[04/20 21:22:07 d2.evaluation.evaluator]: [0mInference done 6064/8355. 0.1171 s / img. ETA=0:04:33
[32m[04/20 21:22:12 d2.evaluation.evaluator]: [0mInference done 6106/8355. 0.1171 s / img. ETA=0:04:28
[32m[04/20 21:22:17 d2.evaluation.evaluator]: [0mInference done 6148/8355. 0.1171 s / img. ETA=0:04:23
[32m[04/20 21:22:22 d2.evaluation.evaluator]: [0mInference done 6190/8355. 0.1171 s / img. ETA=0:04:18
[32m[04/20 21:22:27 d2.evaluation.evaluator]: [0mInference done 6232/8355. 0.1171 s / img. ETA=0:04:13
[32m[04/20 21:22:32 d2.evaluation.evaluator]: [0mInference done 6274/8355. 0.1171 s / img. ETA=0:04:08
[32m[04/20 21:22:37 d2.evaluation.evaluator]: [0mInference done 6315/8355. 0.1171 s / img. ETA=0:04:03
[32m[04/20 21:22:42 d2.evaluation.evaluator]: [0mInference done 6357/8355. 0.1171 s / img. ETA=0:03:58
[32m[04/20 21:22:48 d2.evaluation.evaluator]: [0mInference done 6399/8355. 0.1171 s / img. ETA=0:03:53
[32m[04/20 21:22:53 d2.evaluation.evaluator]: [0mInference done 6441/8355. 0.1171 s / img. ETA=0:03:48
[32m[04/20 21:22:58 d2.evaluation.evaluator]: [0mInference done 6483/8355. 0.1171 s / img. ETA=0:03:43
[32m[04/20 21:23:03 d2.evaluation.evaluator]: [0mInference done 6525/8355. 0.1171 s / img. ETA=0:03:38
[32m[04/20 21:23:08 d2.evaluation.evaluator]: [0mInference done 6567/8355. 0.1171 s / img. ETA=0:03:33
[32m[04/20 21:23:13 d2.evaluation.evaluator]: [0mInference done 6609/8355. 0.1171 s / img. ETA=0:03:28
[32m[04/20 21:23:18 d2.evaluation.evaluator]: [0mInference done 6651/8355. 0.1171 s / img. ETA=0:03:23
[32m[04/20 21:23:23 d2.evaluation.evaluator]: [0mInference done 6693/8355. 0.1171 s / img. ETA=0:03:18
[32m[04/20 21:23:28 d2.evaluation.evaluator]: [0mInference done 6735/8355. 0.1171 s / img. ETA=0:03:13
[32m[04/20 21:23:33 d2.evaluation.evaluator]: [0mInference done 6778/8355. 0.1171 s / img. ETA=0:03:08
[32m[04/20 21:23:38 d2.evaluation.evaluator]: [0mInference done 6820/8355. 0.1171 s / img. ETA=0:03:03
[32m[04/20 21:23:43 d2.evaluation.evaluator]: [0mInference done 6862/8355. 0.1171 s / img. ETA=0:02:58
[32m[04/20 21:23:48 d2.evaluation.evaluator]: [0mInference done 6904/8355. 0.1171 s / img. ETA=0:02:53
[32m[04/20 21:23:53 d2.evaluation.evaluator]: [0mInference done 6946/8355. 0.1171 s / img. ETA=0:02:48
[32m[04/20 21:23:58 d2.evaluation.evaluator]: [0mInference done 6988/8355. 0.1171 s / img. ETA=0:02:43
[32m[04/20 21:24:03 d2.evaluation.evaluator]: [0mInference done 7030/8355. 0.1171 s / img. ETA=0:02:38
[32m[04/20 21:24:08 d2.evaluation.evaluator]: [0mInference done 7072/8355. 0.1171 s / img. ETA=0:02:33
[32m[04/20 21:24:13 d2.evaluation.evaluator]: [0mInference done 7114/8355. 0.1171 s / img. ETA=0:02:28
[32m[04/20 21:24:18 d2.evaluation.evaluator]: [0mInference done 7156/8355. 0.1172 s / img. ETA=0:02:23
[32m[04/20 21:24:23 d2.evaluation.evaluator]: [0mInference done 7198/8355. 0.1172 s / img. ETA=0:02:18
[32m[04/20 21:24:28 d2.evaluation.evaluator]: [0mInference done 7240/8355. 0.1172 s / img. ETA=0:02:13
[32m[04/20 21:24:33 d2.evaluation.evaluator]: [0mInference done 7282/8355. 0.1172 s / img. ETA=0:02:08
[32m[04/20 21:24:39 d2.evaluation.evaluator]: [0mInference done 7324/8355. 0.1172 s / img. ETA=0:02:03
[32m[04/20 21:24:44 d2.evaluation.evaluator]: [0mInference done 7365/8355. 0.1172 s / img. ETA=0:01:58
[32m[04/20 21:24:49 d2.evaluation.evaluator]: [0mInference done 7407/8355. 0.1172 s / img. ETA=0:01:53
[32m[04/20 21:24:54 d2.evaluation.evaluator]: [0mInference done 7449/8355. 0.1172 s / img. ETA=0:01:48
[32m[04/20 21:24:59 d2.evaluation.evaluator]: [0mInference done 7491/8355. 0.1172 s / img. ETA=0:01:43
[32m[04/20 21:25:04 d2.evaluation.evaluator]: [0mInference done 7533/8355. 0.1172 s / img. ETA=0:01:38
[32m[04/20 21:25:09 d2.evaluation.evaluator]: [0mInference done 7575/8355. 0.1172 s / img. ETA=0:01:33
[32m[04/20 21:25:14 d2.evaluation.evaluator]: [0mInference done 7617/8355. 0.1172 s / img. ETA=0:01:28
[32m[04/20 21:25:19 d2.evaluation.evaluator]: [0mInference done 7659/8355. 0.1172 s / img. ETA=0:01:23
[32m[04/20 21:25:24 d2.evaluation.evaluator]: [0mInference done 7701/8355. 0.1172 s / img. ETA=0:01:18
[32m[04/20 21:25:29 d2.evaluation.evaluator]: [0mInference done 7743/8355. 0.1172 s / img. ETA=0:01:13
[32m[04/20 21:25:34 d2.evaluation.evaluator]: [0mInference done 7785/8355. 0.1172 s / img. ETA=0:01:08
[32m[04/20 21:25:39 d2.evaluation.evaluator]: [0mInference done 7827/8355. 0.1172 s / img. ETA=0:01:03
[32m[04/20 21:25:44 d2.evaluation.evaluator]: [0mInference done 7869/8355. 0.1172 s / img. ETA=0:00:58
[32m[04/20 21:25:49 d2.evaluation.evaluator]: [0mInference done 7911/8355. 0.1172 s / img. ETA=0:00:53
[32m[04/20 21:25:54 d2.evaluation.evaluator]: [0mInference done 7953/8355. 0.1172 s / img. ETA=0:00:48
[32m[04/20 21:25:59 d2.evaluation.evaluator]: [0mInference done 7995/8355. 0.1173 s / img. ETA=0:00:43
[32m[04/20 21:26:04 d2.evaluation.evaluator]: [0mInference done 8037/8355. 0.1173 s / img. ETA=0:00:38
[32m[04/20 21:26:09 d2.evaluation.evaluator]: [0mInference done 8079/8355. 0.1172 s / img. ETA=0:00:33
[32m[04/20 21:26:15 d2.evaluation.evaluator]: [0mInference done 8122/8355. 0.1172 s / img. ETA=0:00:27
[32m[04/20 21:26:20 d2.evaluation.evaluator]: [0mInference done 8165/8355. 0.1172 s / img. ETA=0:00:22
[32m[04/20 21:26:25 d2.evaluation.evaluator]: [0mInference done 8207/8355. 0.1172 s / img. ETA=0:00:17
[32m[04/20 21:26:30 d2.evaluation.evaluator]: [0mInference done 8249/8355. 0.1172 s / img. ETA=0:00:12
[32m[04/20 21:26:35 d2.evaluation.evaluator]: [0mInference done 8291/8355. 0.1172 s / img. ETA=0:00:07
[32m[04/20 21:26:40 d2.evaluation.evaluator]: [0mInference done 8333/8355. 0.1172 s / img. ETA=0:00:02
[32m[04/20 21:26:43 d2.evaluation.evaluator]: [0mTotal inference time: 0:16:38.779731 (0.119614 s / img per device, on 1 devices)
[32m[04/20 21:26:43 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:19 (0.117250 s / img per device, on 1 devices)
[32m[04/20 21:26:43 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 21:26:43 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 21:26:43 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=19.86s).
Accumulating evaluation results...
DONE (t=2.18s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.419
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.768
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.403
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.309
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.554
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.685
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.167
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.468
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.380
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.724
[32m[04/20 21:27:05 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.875 | 76.834 | 40.266 | 30.947 | 55.364 | 68.496 |
[32m[04/20 21:27:05 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 42.447 | bicycle       | 33.150 | car            | 50.029 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    |               |        |                |        |
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 21:27:06 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 21:27:06 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 21:27:06 d2.evaluation.evaluator]: [0mStart inference on 1257 images
[32m[04/20 21:27:08 d2.evaluation.evaluator]: [0mInference done 11/1257. 0.1170 s / img. ETA=0:02:28
[32m[04/20 21:27:13 d2.evaluation.evaluator]: [0mInference done 54/1257. 0.1166 s / img. ETA=0:02:22
[32m[04/20 21:27:18 d2.evaluation.evaluator]: [0mInference done 96/1257. 0.1169 s / img. ETA=0:02:18
[32m[04/20 21:27:23 d2.evaluation.evaluator]: [0mInference done 137/1257. 0.1183 s / img. ETA=0:02:14
[32m[04/20 21:27:28 d2.evaluation.evaluator]: [0mInference done 180/1257. 0.1180 s / img. ETA=0:02:09
[32m[04/20 21:27:33 d2.evaluation.evaluator]: [0mInference done 223/1257. 0.1177 s / img. ETA=0:02:03
[32m[04/20 21:27:38 d2.evaluation.evaluator]: [0mInference done 265/1257. 0.1176 s / img. ETA=0:01:58
[32m[04/20 21:27:44 d2.evaluation.evaluator]: [0mInference done 308/1257. 0.1175 s / img. ETA=0:01:53
[32m[04/20 21:27:49 d2.evaluation.evaluator]: [0mInference done 351/1257. 0.1174 s / img. ETA=0:01:48
[32m[04/20 21:27:54 d2.evaluation.evaluator]: [0mInference done 394/1257. 0.1173 s / img. ETA=0:01:43
[32m[04/20 21:27:59 d2.evaluation.evaluator]: [0mInference done 436/1257. 0.1173 s / img. ETA=0:01:38
[32m[04/20 21:28:04 d2.evaluation.evaluator]: [0mInference done 478/1257. 0.1173 s / img. ETA=0:01:33
[32m[04/20 21:28:09 d2.evaluation.evaluator]: [0mInference done 520/1257. 0.1174 s / img. ETA=0:01:28
[32m[04/20 21:28:14 d2.evaluation.evaluator]: [0mInference done 562/1257. 0.1174 s / img. ETA=0:01:23
[32m[04/20 21:28:19 d2.evaluation.evaluator]: [0mInference done 604/1257. 0.1175 s / img. ETA=0:01:18
[32m[04/20 21:28:24 d2.evaluation.evaluator]: [0mInference done 646/1257. 0.1175 s / img. ETA=0:01:13
[32m[04/20 21:28:29 d2.evaluation.evaluator]: [0mInference done 688/1257. 0.1175 s / img. ETA=0:01:08
[32m[04/20 21:28:34 d2.evaluation.evaluator]: [0mInference done 730/1257. 0.1175 s / img. ETA=0:01:03
[32m[04/20 21:28:39 d2.evaluation.evaluator]: [0mInference done 773/1257. 0.1174 s / img. ETA=0:00:57
[32m[04/20 21:28:44 d2.evaluation.evaluator]: [0mInference done 815/1257. 0.1175 s / img. ETA=0:00:52
[32m[04/20 21:28:49 d2.evaluation.evaluator]: [0mInference done 857/1257. 0.1175 s / img. ETA=0:00:47
[32m[04/20 21:28:54 d2.evaluation.evaluator]: [0mInference done 899/1257. 0.1175 s / img. ETA=0:00:42
[32m[04/20 21:28:59 d2.evaluation.evaluator]: [0mInference done 941/1257. 0.1175 s / img. ETA=0:00:37
[32m[04/20 21:29:04 d2.evaluation.evaluator]: [0mInference done 983/1257. 0.1175 s / img. ETA=0:00:32
[32m[04/20 21:29:09 d2.evaluation.evaluator]: [0mInference done 1025/1257. 0.1175 s / img. ETA=0:00:27
[32m[04/20 21:29:14 d2.evaluation.evaluator]: [0mInference done 1067/1257. 0.1175 s / img. ETA=0:00:22
[32m[04/20 21:29:20 d2.evaluation.evaluator]: [0mInference done 1109/1257. 0.1175 s / img. ETA=0:00:17
[32m[04/20 21:29:25 d2.evaluation.evaluator]: [0mInference done 1151/1257. 0.1175 s / img. ETA=0:00:12
[32m[04/20 21:29:30 d2.evaluation.evaluator]: [0mInference done 1193/1257. 0.1175 s / img. ETA=0:00:07
[32m[04/20 21:29:35 d2.evaluation.evaluator]: [0mInference done 1235/1257. 0.1175 s / img. ETA=0:00:02
[32m[04/20 21:29:37 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:29.995961 (0.119805 s / img per device, on 1 devices)
[32m[04/20 21:29:37 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:27 (0.117477 s / img per device, on 1 devices)
[32m[04/20 21:29:37 d2.evaluation.FLIR_evaluation]: [0mPreparing results for COCO format ...
[32m[04/20 21:29:37 d2.evaluation.FLIR_evaluation]: [0mSaving results to output_6_channel/coco_instances_results.json
[32m[04/20 21:29:37 d2.evaluation.FLIR_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.81s).
Accumulating evaluation results...
DONE (t=0.36s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.592
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.267
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.374
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.152
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.257
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.451
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.536
[32m[04/20 21:29:41 d2.evaluation.FLIR_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 30.249 | 59.248 | 26.708 | 18.646 | 37.390 | 49.715 |
[32m[04/20 21:29:41 d2.evaluation.FLIR_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category      | AP     | category       | AP     |
|:--------------|:-------|:--------------|:-------|:---------------|:-------|
| person        | 32.873 | bicycle       | 13.371 | car            | 44.503 |
| motorcycle    | nan    | airplane      | nan    | bus            | nan    |
| train         | nan    | truck         | nan    | boat           | nan    |
| traffic light | nan    | fire hydrant  | nan    | stop sign      | nan    |
| parking meter | nan    | bench         | nan    | bird           | nan    |
| cat           | nan    | dog           | nan    | horse          | nan    |
| sheep         | nan    | cow           | nan    | elephant       | nan    |
| bear          | nan    | zebra         | nan    | giraffe        | nan    |
| backpack      | nan    | umbrella      | nan    | handbag        | nan    |
| tie           | nan    | suitcase      | nan    | frisbee        | nan    |
| skis          | nan    | snowboard     | nan    | sports ball    | nan    |
| kite          | nan    | baseball bat  | nan    | baseball glove | nan    |
| skateboard    | nan    | surfboard     | nan    | tennis racket  | nan    |
| bottle        | nan    | wine glass    | nan    | cup            | nan    |
| fork          | nan    | knife         | nan    | spoon          | nan    |
| bowl          | nan    | banana        | nan    | apple          | nan    |
| sandwich      | nan    | orange        | nan    | broccoli       | nan    |
| carrot        | nan    | hot dog       | nan    | pizza          | nan    |
| donut         | nan    | cake          | nan    | chair          | nan    |
| couch         | nan    | potted plant  | nan    | bed            | nan    |
| dining table  | nan    | toilet        | nan    | tv             | nan    |
| laptop        | nan    | mouse         | nan    | remote         | nan    |
| keyboard      | nan    | cell phone    | nan    | microwave      | nan    |
| oven          | nan    | bike          | nan    | hydrant        | nan    |
| motor         | nan    | rider         | nan    | light          | nan    |
| sign          | nan    | motor vehicle | nan    | human face     | nan    |
| hair drier    | nan    | license plate | nan    |                |        |
============== The  26  *  1000  iterations ============
3 channel input
Require gradient = False for the first several layers of ResNet
[32m[04/20 21:29:41 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
[5m[31mWARNING[0m [32m[04/20 21:29:42 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 21:29:42 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 21:29:42 d2.data.build]: [0mRemoved 890 images with no usable annotations. 7465 images left.
[32m[04/20 21:29:42 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[04/20 21:29:42 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[04/20 21:29:43 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[04/20 21:30:03 d2.utils.events]: [0m eta: 0:16:20  iter: 19  total_loss: 0.627  loss_cls: 0.206  loss_box_reg: 0.352  loss_rpn_cls: 0.014  loss_rpn_loc: 0.055  time: 1.0065  data_time: 0.0337  lr: 0.000100  max_mem: 5406M
[32m[04/20 21:30:24 d2.utils.events]: [0m eta: 0:16:10  iter: 39  total_loss: 0.563  loss_cls: 0.176  loss_box_reg: 0.312  loss_rpn_cls: 0.009  loss_rpn_loc: 0.054  time: 1.0173  data_time: 0.0118  lr: 0.000200  max_mem: 5406M
[32m[04/20 21:30:45 d2.utils.events]: [0m eta: 0:16:22  iter: 59  total_loss: 0.631  loss_cls: 0.188  loss_box_reg: 0.344  loss_rpn_cls: 0.014  loss_rpn_loc: 0.062  time: 1.0287  data_time: 0.0106  lr: 0.000300  max_mem: 5406M
[32m[04/20 21:31:05 d2.utils.events]: [0m eta: 0:15:44  iter: 79  total_loss: 0.559  loss_cls: 0.172  loss_box_reg: 0.321  loss_rpn_cls: 0.012  loss_rpn_loc: 0.051  time: 1.0235  data_time: 0.0112  lr: 0.000400  max_mem: 5406M
[32m[04/20 21:31:25 d2.utils.events]: [0m eta: 0:15:23  iter: 99  total_loss: 0.567  loss_cls: 0.177  loss_box_reg: 0.328  loss_rpn_cls: 0.010  loss_rpn_loc: 0.052  time: 1.0239  data_time: 0.0116  lr: 0.000500  max_mem: 5406M
[32m[04/20 21:31:46 d2.utils.events]: [0m eta: 0:15:05  iter: 119  total_loss: 0.446  loss_cls: 0.145  loss_box_reg: 0.248  loss_rpn_cls: 0.008  loss_rpn_loc: 0.031  time: 1.0277  data_time: 0.0115  lr: 0.000599  max_mem: 5406M
[32m[04/20 21:32:07 d2.utils.events]: [0m eta: 0:14:45  iter: 139  total_loss: 0.551  loss_cls: 0.181  loss_box_reg: 0.317  loss_rpn_cls: 0.012  loss_rpn_loc: 0.059  time: 1.0280  data_time: 0.0113  lr: 0.000699  max_mem: 5406M
[32m[04/20 21:32:28 d2.utils.events]: [0m eta: 0:14:28  iter: 159  total_loss: 0.494  loss_cls: 0.170  loss_box_reg: 0.282  loss_rpn_cls: 0.008  loss_rpn_loc: 0.037  time: 1.0296  data_time: 0.0129  lr: 0.000799  max_mem: 5406M
[32m[04/20 21:32:48 d2.utils.events]: [0m eta: 0:14:05  iter: 179  total_loss: 0.585  loss_cls: 0.187  loss_box_reg: 0.332  loss_rpn_cls: 0.014  loss_rpn_loc: 0.058  time: 1.0293  data_time: 0.0107  lr: 0.000899  max_mem: 5406M
[32m[04/20 21:33:09 d2.utils.events]: [0m eta: 0:13:46  iter: 199  total_loss: 0.574  loss_cls: 0.181  loss_box_reg: 0.326  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 1.0312  data_time: 0.0129  lr: 0.000999  max_mem: 5406M
[32m[04/20 21:33:30 d2.utils.events]: [0m eta: 0:13:29  iter: 219  total_loss: 0.508  loss_cls: 0.154  loss_box_reg: 0.300  loss_rpn_cls: 0.008  loss_rpn_loc: 0.040  time: 1.0327  data_time: 0.0102  lr: 0.001099  max_mem: 5406M
[32m[04/20 21:33:51 d2.utils.events]: [0m eta: 0:13:07  iter: 239  total_loss: 0.481  loss_cls: 0.150  loss_box_reg: 0.271  loss_rpn_cls: 0.008  loss_rpn_loc: 0.037  time: 1.0316  data_time: 0.0118  lr: 0.001199  max_mem: 5406M
[32m[04/20 21:34:12 d2.utils.events]: [0m eta: 0:12:48  iter: 259  total_loss: 0.551  loss_cls: 0.184  loss_box_reg: 0.309  loss_rpn_cls: 0.008  loss_rpn_loc: 0.051  time: 1.0317  data_time: 0.0114  lr: 0.001299  max_mem: 5406M
[32m[04/20 21:34:32 d2.utils.events]: [0m eta: 0:12:26  iter: 279  total_loss: 0.561  loss_cls: 0.174  loss_box_reg: 0.311  loss_rpn_cls: 0.008  loss_rpn_loc: 0.055  time: 1.0312  data_time: 0.0100  lr: 0.001399  max_mem: 5406M
[32m[04/20 21:34:53 d2.utils.events]: [0m eta: 0:12:04  iter: 299  total_loss: 0.519  loss_cls: 0.162  loss_box_reg: 0.296  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0313  data_time: 0.0105  lr: 0.001499  max_mem: 5406M
[32m[04/20 21:35:14 d2.utils.events]: [0m eta: 0:11:45  iter: 319  total_loss: 0.571  loss_cls: 0.169  loss_box_reg: 0.311  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 1.0313  data_time: 0.0111  lr: 0.001598  max_mem: 5406M
[32m[04/20 21:35:34 d2.utils.events]: [0m eta: 0:11:25  iter: 339  total_loss: 0.550  loss_cls: 0.181  loss_box_reg: 0.334  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 1.0321  data_time: 0.0111  lr: 0.001698  max_mem: 5406M
[32m[04/20 21:35:55 d2.utils.events]: [0m eta: 0:11:03  iter: 359  total_loss: 0.534  loss_cls: 0.159  loss_box_reg: 0.316  loss_rpn_cls: 0.007  loss_rpn_loc: 0.051  time: 1.0311  data_time: 0.0101  lr: 0.001798  max_mem: 5406M
[32m[04/20 21:36:16 d2.utils.events]: [0m eta: 0:10:45  iter: 379  total_loss: 0.542  loss_cls: 0.178  loss_box_reg: 0.300  loss_rpn_cls: 0.013  loss_rpn_loc: 0.052  time: 1.0317  data_time: 0.0111  lr: 0.001898  max_mem: 5406M
[32m[04/20 21:36:36 d2.utils.events]: [0m eta: 0:10:22  iter: 399  total_loss: 0.537  loss_cls: 0.166  loss_box_reg: 0.308  loss_rpn_cls: 0.009  loss_rpn_loc: 0.052  time: 1.0311  data_time: 0.0108  lr: 0.001998  max_mem: 5406M
[32m[04/20 21:36:57 d2.utils.events]: [0m eta: 0:10:02  iter: 419  total_loss: 0.591  loss_cls: 0.180  loss_box_reg: 0.322  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 1.0304  data_time: 0.0118  lr: 0.002098  max_mem: 5406M
[32m[04/20 21:37:17 d2.utils.events]: [0m eta: 0:09:41  iter: 439  total_loss: 0.564  loss_cls: 0.184  loss_box_reg: 0.307  loss_rpn_cls: 0.010  loss_rpn_loc: 0.052  time: 1.0306  data_time: 0.0117  lr: 0.002198  max_mem: 5406M
[32m[04/20 21:37:38 d2.utils.events]: [0m eta: 0:09:20  iter: 459  total_loss: 0.542  loss_cls: 0.169  loss_box_reg: 0.306  loss_rpn_cls: 0.010  loss_rpn_loc: 0.048  time: 1.0315  data_time: 0.0112  lr: 0.002298  max_mem: 5406M
[32m[04/20 21:37:59 d2.utils.events]: [0m eta: 0:08:59  iter: 479  total_loss: 0.610  loss_cls: 0.184  loss_box_reg: 0.343  loss_rpn_cls: 0.008  loss_rpn_loc: 0.051  time: 1.0306  data_time: 0.0100  lr: 0.002398  max_mem: 5406M
[32m[04/20 21:38:19 d2.utils.events]: [0m eta: 0:08:38  iter: 499  total_loss: 0.541  loss_cls: 0.165  loss_box_reg: 0.320  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 1.0309  data_time: 0.0109  lr: 0.002498  max_mem: 5406M
[32m[04/20 21:38:40 d2.utils.events]: [0m eta: 0:08:18  iter: 519  total_loss: 0.583  loss_cls: 0.171  loss_box_reg: 0.307  loss_rpn_cls: 0.012  loss_rpn_loc: 0.051  time: 1.0311  data_time: 0.0114  lr: 0.002597  max_mem: 5406M
[32m[04/20 21:39:01 d2.utils.events]: [0m eta: 0:07:57  iter: 539  total_loss: 0.625  loss_cls: 0.177  loss_box_reg: 0.339  loss_rpn_cls: 0.013  loss_rpn_loc: 0.053  time: 1.0308  data_time: 0.0106  lr: 0.002697  max_mem: 5406M
[32m[04/20 21:39:21 d2.utils.events]: [0m eta: 0:07:36  iter: 559  total_loss: 0.563  loss_cls: 0.180  loss_box_reg: 0.315  loss_rpn_cls: 0.010  loss_rpn_loc: 0.056  time: 1.0302  data_time: 0.0114  lr: 0.002797  max_mem: 5406M
[32m[04/20 21:39:41 d2.utils.events]: [0m eta: 0:07:14  iter: 579  total_loss: 0.583  loss_cls: 0.175  loss_box_reg: 0.317  loss_rpn_cls: 0.008  loss_rpn_loc: 0.052  time: 1.0294  data_time: 0.0109  lr: 0.002897  max_mem: 5406M
[32m[04/20 21:40:02 d2.utils.events]: [0m eta: 0:06:54  iter: 599  total_loss: 0.510  loss_cls: 0.161  loss_box_reg: 0.303  loss_rpn_cls: 0.009  loss_rpn_loc: 0.039  time: 1.0295  data_time: 0.0116  lr: 0.002997  max_mem: 5406M
[32m[04/20 21:40:23 d2.utils.events]: [0m eta: 0:06:34  iter: 619  total_loss: 0.552  loss_cls: 0.168  loss_box_reg: 0.299  loss_rpn_cls: 0.007  loss_rpn_loc: 0.044  time: 1.0304  data_time: 0.0107  lr: 0.003097  max_mem: 5406M
[32m[04/20 21:40:44 d2.utils.events]: [0m eta: 0:06:13  iter: 639  total_loss: 0.621  loss_cls: 0.198  loss_box_reg: 0.353  loss_rpn_cls: 0.011  loss_rpn_loc: 0.055  time: 1.0308  data_time: 0.0110  lr: 0.003197  max_mem: 5406M
[32m[04/20 21:41:05 d2.utils.events]: [0m eta: 0:05:53  iter: 659  total_loss: 0.533  loss_cls: 0.175  loss_box_reg: 0.311  loss_rpn_cls: 0.010  loss_rpn_loc: 0.045  time: 1.0308  data_time: 0.0108  lr: 0.003297  max_mem: 5406M
[32m[04/20 21:41:25 d2.utils.events]: [0m eta: 0:05:32  iter: 679  total_loss: 0.492  loss_cls: 0.151  loss_box_reg: 0.286  loss_rpn_cls: 0.012  loss_rpn_loc: 0.042  time: 1.0308  data_time: 0.0105  lr: 0.003397  max_mem: 5406M
[32m[04/20 21:41:46 d2.utils.events]: [0m eta: 0:05:11  iter: 699  total_loss: 0.486  loss_cls: 0.150  loss_box_reg: 0.304  loss_rpn_cls: 0.011  loss_rpn_loc: 0.034  time: 1.0303  data_time: 0.0109  lr: 0.003497  max_mem: 5406M
[32m[04/20 21:42:07 d2.utils.events]: [0m eta: 0:04:50  iter: 719  total_loss: 0.556  loss_cls: 0.172  loss_box_reg: 0.309  loss_rpn_cls: 0.011  loss_rpn_loc: 0.055  time: 1.0307  data_time: 0.0107  lr: 0.003596  max_mem: 5406M
[32m[04/20 21:42:27 d2.utils.events]: [0m eta: 0:04:30  iter: 739  total_loss: 0.531  loss_cls: 0.163  loss_box_reg: 0.309  loss_rpn_cls: 0.009  loss_rpn_loc: 0.052  time: 1.0309  data_time: 0.0113  lr: 0.003696  max_mem: 5406M
[32m[04/20 21:42:48 d2.utils.events]: [0m eta: 0:04:09  iter: 759  total_loss: 0.601  loss_cls: 0.187  loss_box_reg: 0.314  loss_rpn_cls: 0.011  loss_rpn_loc: 0.060  time: 1.0307  data_time: 0.0109  lr: 0.003796  max_mem: 5406M
[32m[04/20 21:43:08 d2.utils.events]: [0m eta: 0:03:48  iter: 779  total_loss: 0.630  loss_cls: 0.201  loss_box_reg: 0.363  loss_rpn_cls: 0.014  loss_rpn_loc: 0.058  time: 1.0303  data_time: 0.0114  lr: 0.003896  max_mem: 5406M
[32m[04/20 21:43:29 d2.utils.events]: [0m eta: 0:03:27  iter: 799  total_loss: 0.507  loss_cls: 0.163  loss_box_reg: 0.308  loss_rpn_cls: 0.011  loss_rpn_loc: 0.044  time: 1.0300  data_time: 0.0103  lr: 0.003996  max_mem: 5406M
[32m[04/20 21:43:50 d2.utils.events]: [0m eta: 0:03:07  iter: 819  total_loss: 0.646  loss_cls: 0.194  loss_box_reg: 0.349  loss_rpn_cls: 0.010  loss_rpn_loc: 0.059  time: 1.0301  data_time: 0.0106  lr: 0.004096  max_mem: 5406M
[32m[04/20 21:44:10 d2.utils.events]: [0m eta: 0:02:46  iter: 839  total_loss: 0.554  loss_cls: 0.179  loss_box_reg: 0.312  loss_rpn_cls: 0.010  loss_rpn_loc: 0.043  time: 1.0301  data_time: 0.0104  lr: 0.004196  max_mem: 5406M
[32m[04/20 21:44:31 d2.utils.events]: [0m eta: 0:02:25  iter: 859  total_loss: 0.602  loss_cls: 0.194  loss_box_reg: 0.345  loss_rpn_cls: 0.012  loss_rpn_loc: 0.047  time: 1.0298  data_time: 0.0104  lr: 0.004296  max_mem: 5406M
[32m[04/20 21:44:52 d2.utils.events]: [0m eta: 0:02:05  iter: 879  total_loss: 0.630  loss_cls: 0.197  loss_box_reg: 0.348  loss_rpn_cls: 0.012  loss_rpn_loc: 0.056  time: 1.0303  data_time: 0.0115  lr: 0.004396  max_mem: 5406M
[32m[04/20 21:45:13 d2.utils.events]: [0m eta: 0:01:44  iter: 899  total_loss: 0.632  loss_cls: 0.203  loss_box_reg: 0.354  loss_rpn_cls: 0.016  loss_rpn_loc: 0.049  time: 1.0306  data_time: 0.0111  lr: 0.004496  max_mem: 5406M
[32m[04/20 21:45:33 d2.utils.events]: [0m eta: 0:01:23  iter: 919  total_loss: 0.609  loss_cls: 0.191  loss_box_reg: 0.333  loss_rpn_cls: 0.012  loss_rpn_loc: 0.058  time: 1.0307  data_time: 0.0100  lr: 0.004595  max_mem: 5406M
[32m[04/20 21:45:54 d2.utils.events]: [0m eta: 0:01:03  iter: 939  total_loss: 0.563  loss_cls: 0.179  loss_box_reg: 0.329  loss_rpn_cls: 0.015  loss_rpn_loc: 0.058  time: 1.0308  data_time: 0.0109  lr: 0.004695  max_mem: 5406M
[32m[04/20 21:46:14 d2.utils.events]: [0m eta: 0:00:42  iter: 959  total_loss: 0.562  loss_cls: 0.180  loss_box_reg: 0.313  loss_rpn_cls: 0.011  loss_rpn_loc: 0.052  time: 1.0305  data_time: 0.0104  lr: 0.004795  max_mem: 5406M
[32m[04/20 21:46:35 d2.utils.events]: [0m eta: 0:00:21  iter: 979  total_loss: 0.648  loss_cls: 0.205  loss_box_reg: 0.354  loss_rpn_cls: 0.017  loss_rpn_loc: 0.067  time: 1.0307  data_time: 0.0117  lr: 0.004895  max_mem: 5406M
[5m[31mWARNING[0m [32m[04/20 21:46:59 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 21:46:59 d2.data.datasets.coco]: [0mLoaded 1257 images in COCO format from ../../../Datasets/FLIR/val/thermal_annotations_4_channel_no_dogs.json
[5m[31mWARNING[0m [32m[04/20 21:46:59 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[04/20 21:46:59 d2.utils.events]: [0m eta: 0:00:01  iter: 999  total_loss: 0.548  loss_cls: 0.169  loss_box_reg: 0.300  loss_rpn_cls: 0.012  loss_rpn_loc: 0.041  time: 1.0304  data_time: 0.0105  lr: 0.004995  max_mem: 5406M
[32m[04/20 21:47:01 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:17:08 (1.0315 s / it)
[32m[04/20 21:47:01 d2.engine.hooks]: [0mTotal training time: 0:17:15 (0:00:07 on hooks)
3 channel input
Require gradient = False for the first several layers of ResNet
[5m[31mWARNING[0m [32m[04/20 21:47:03 d2.data.datasets.coco]: [0m
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[32m[04/20 21:47:03 d2.data.datasets.coco]: [0mLoaded 8355 images in COCO format from ../../../Datasets/FLIR/train/thermal_annotations_4_channel_no_dogs.json
[32m[04/20 21:47:04 d2.evaluation.evaluator]: [0mStart inference on 8355 images
[32m[04/20 21:47:05 d2.evaluation.evaluator]: [0mInference done 11/8355. 0.1176 s / img. ETA=0:16:39
[32m[04/20 21:47:10 d2.evaluation.evaluator]: [0mInference done 54/8355. 0.1167 s / img. ETA=0:16:28
[32m[04/20 21:47:15 d2.evaluation.evaluator]: [0mInference done 97/8355. 0.1166 s / img. ETA=0:16:22
[32m[04/20 21:47:20 d2.evaluation.evaluator]: [0mInference done 139/8355. 0.1167 s / img. ETA=0:16:18
[32m[04/20 21:47:25 d2.evaluation.evaluator]: [0mInference done 181/8355. 0.1168 s / img. ETA=0:16:14
[32m[04/20 21:47:30 d2.evaluation.evaluator]: [0mInference done 223/8355. 0.1168 s / img. ETA=0:16:09
[32m[04/20 21:47:36 d2.evaluation.evaluator]: [0mInference done 266/8355. 0.1167 s / img. ETA=0:16:03
[32m[04/20 21:47:41 d2.evaluation.evaluator]: [0mInference done 308/8355. 0.1167 s / img. ETA=0:15:58
[32m[04/20 21:47:46 d2.evaluation.evaluator]: [0mInference done 351/8355. 0.1167 s / img. ETA=0:15:53
[32m[04/20 21:47:51 d2.evaluation.evaluator]: [0mInference done 393/8355. 0.1167 s / img. ETA=0:15:48
[32m[04/20 21:47:56 d2.evaluation.evaluator]: [0mInference done 435/8355. 0.1168 s / img. ETA=0:15:44
[32m[04/20 21:48:01 d2.evaluation.evaluator]: [0mInference done 477/8355. 0.1168 s / img. ETA=0:15:39
[32m[04/20 21:48:06 d2.evaluation.evaluator]: [0mInference done 520/8355. 0.1167 s / img. ETA=0:15:33
[32m[04/20 21:48:11 d2.evaluation.evaluator]: [0mInference done 563/8355. 0.1167 s / img. ETA=0:15:28
[32m[04/20 21:48:16 d2.evaluation.evaluator]: [0mInference done 605/8355. 0.1167 s / img. ETA=0:15:23
[32m[04/20 21:48:21 d2.evaluation.evaluator]: [0mInference done 647/8355. 0.1167 s / img. ETA=0:15:18
[32m[04/20 21:48:26 d2.evaluation.evaluator]: [0mInference done 689/8355. 0.1168 s / img. ETA=0:15:13
[32m[04/20 21:48:31 d2.evaluation.evaluator]: [0mInference done 731/8355. 0.1168 s / img. ETA=0:15:08
[32m[04/20 21:48:36 d2.evaluation.evaluator]: [0mInference done 774/8355. 0.1168 s / img. ETA=0:15:03
[32m[04/20 21:48:41 d2.evaluation.evaluator]: [0mInference done 816/8355. 0.1168 s / img. ETA=0:14:58
[32m[04/20 21:48:46 d2.evaluation.evaluator]: [0mInference done 858/8355. 0.1168 s / img. ETA=0:14:53
[32m[04/20 21:48:51 d2.evaluation.evaluator]: [0mInference done 900/8355. 0.1169 s / img. ETA=0:14:49
[32m[04/20 21:48:56 d2.evaluation.evaluator]: [0mInference done 942/8355. 0.1169 s / img. ETA=0:14:44
[32m[04/20 21:49:01 d2.evaluation.evaluator]: [0mInference done 985/8355. 0.1168 s / img. ETA=0:14:38
[32m[04/20 21:49:06 d2.evaluation.evaluator]: [0mInference done 1027/8355. 0.1169 s / img. ETA=0:14:33
[32m[04/20 21:49:11 d2.evaluation.evaluator]: [0mInference done 1070/8355. 0.1168 s / img. ETA=0:14:28
[32m[04/20 21:49:16 d2.evaluation.evaluator]: [0mInference done 1112/8355. 0.1168 s / img. ETA=0:14:23
[32m[04/20 21:49:22 d2.evaluation.evaluator]: [0mInference done 1155/8355. 0.1168 s / img. ETA=0:14:18
[32m[04/20 21:49:27 d2.evaluation.evaluator]: [0mInference done 1198/8355. 0.1168 s / img. ETA=0:14:13
[32m[04/20 21:49:32 d2.evaluation.evaluator]: [0mInference done 1241/8355. 0.1168 s / img. ETA=0:14:07
[32m[04/20 21:49:37 d2.evaluation.evaluator]: [0mInference done 1284/8355. 0.1168 s / img. ETA=0:14:02
[32m[04/20 21:49:42 d2.evaluation.evaluator]: [0mInference done 1327/8355. 0.1168 s / img. ETA=0:13:57
[32m[04/20 21:49:47 d2.evaluation.evaluator]: [0mInference done 1370/8355. 0.1168 s / img. ETA=0:13:52
[32m[04/20 21:49:52 d2.evaluation.evaluator]: [0mInference done 1413/8355. 0.1167 s / img. ETA=0:13:46
[32m[04/20 21:49:57 d2.evaluation.evaluator]: [0mInference done 1456/8355. 0.1167 s / img. ETA=0:13:41
[32m[04/20 21:50:02 d2.evaluation.evaluator]: [0mInference done 1498/8355. 0.1168 s / img. ETA=0:13:36
[32m[04/20 21:50:07 d2.evaluation.evaluator]: [0mInference done 1540/8355. 0.1168 s / img. ETA=0:13:32
[32m[04/20 21:50:12 d2.evaluation.evaluator]: [0mInference done 1582/8355. 0.1168 s / img. ETA=0:13:27
[32m[04/20 21:50:18 d2.evaluation.evaluator]: [0mInference done 1624/8355. 0.1169 s / img. ETA=0:13:22
[32m[04/20 21:50:23 d2.evaluation.evaluator]: [0mInference done 1666/8355. 0.1169 s / img. ETA=0:13:17
[32m[04/20 21:50:28 d2.evaluation.evaluator]: [0mInference done 1708/8355. 0.1169 s / img. ETA=0:13:12
[32m[04/20 21:50:33 d2.evaluation.evaluator]: [0mInference done 1750/8355. 0.1169 s / img. ETA=0:13:08
[32m[04/20 21:50:38 d2.evaluation.evaluator]: [0mInference done 1792/8355. 0.1170 s / img. ETA=0:13:03
[32m[04/20 21:50:43 d2.evaluation.evaluator]: [0mInference done 1834/8355. 0.1170 s / img. ETA=0:12:58
[32m[04/20 21:50:48 d2.evaluation.evaluator]: [0mInference done 1876/8355. 0.1170 s / img. ETA=0:12:53
[32m[04/20 21:50:53 d2.evaluation.evaluator]: [0mInference done 1918/8355. 0.1170 s / img. ETA=0:12:48
[32m[04/20 21:50:58 d2.evaluation.evaluator]: [0mInference done 1960/8355. 0.1170 s / img. ETA=0:12:43
[32m[04/20 21:51:03 d2.evaluation.evaluator]: [0mInference done 2002/8355. 0.1170 s / img. ETA=0:12:38
[32m[04/20 21:51:08 d2.evaluation.evaluator]: [0mInference done 2044/8355. 0.1170 s / img. ETA=0:12:33
[32m[04/20 21:51:13 d2.evaluation.evaluator]: [0mInference done 2086/8355. 0.1170 s / img. ETA=0:12:28
[32m[04/20 21:51:18 d2.evaluation.evaluator]: [0mInference done 2128/8355. 0.1170 s / img. ETA=0:12:23
[32m[04/20 21:51:23 d2.evaluation.evaluator]: [0mInference done 2170/8355. 0.1171 s / img. ETA=0:12:18
[32m[04/20 21:51:28 d2.evaluation.evaluator]: [0mInference done 2212/8355. 0.1171 s / img. ETA=0:12:13
[32m[04/20 21:51:33 d2.evaluation.evaluator]: [0mInference done 2254/8355. 0.1171 s / img. ETA=0:12:09
[32m[04/20 21:51:38 d2.evaluation.evaluator]: [0mInference done 2296/8355. 0.1171 s / img. ETA=0:12:04
[32m[04/20 21:51:43 d2.evaluation.evaluator]: [0mInference done 2338/8355. 0.1171 s / img. ETA=0:11:59
[32m[04/20 21:51:48 d2.evaluation.evaluator]: [0mInference done 2380/8355. 0.1171 s / img. ETA=0:11:54
[32m[04/20 21:51:53 d2.evaluation.evaluator]: [0mInference done 2421/8355. 0.1172 s / img. ETA=0:11:49
[32m[04/20 21:51:59 d2.evaluation.evaluator]: [0mInference done 2463/8355. 0.1172 s / img. ETA=0:11:44
[32m[04/20 21:52:04 d2.evaluation.evaluator]: [0mInference done 2505/8355. 0.1172 s / img. ETA=0:11:39
[32m[04/20 21:52:09 d2.evaluation.evaluator]: [0mInference done 2547/8355. 0.1172 s / img. ETA=0:11:35
[32m[04/20 21:52:14 d2.evaluation.evaluator]: [0mInference done 2589/8355. 0.1172 s / img. ETA=0:11:30
[32m[04/20 21:52:19 d2.evaluation.evaluator]: [0mInference done 2631/8355. 0.1172 s / img. ETA=0:11:25
[32m[04/20 21:52:24 d2.evaluation.evaluator]: [0mInference done 2673/8355. 0.1172 s / img. ETA=0:11:20
[32m[04/20 21:52:29 d2.evaluation.evaluator]: [0mInference done 2715/8355. 0.1173 s / img. ETA=0:11:15
[32m[04/20 21:52:34 d2.evaluation.evaluator]: [0mInference done 2757/8355. 0.1173 s / img. ETA=0:11:10
[32m[04/20 21:52:39 d2.evaluation.evaluator]: [0mInference done 2799/8355. 0.1173 s / img. ETA=0:11:05
[32m[04/20 21:52:44 d2.evaluation.evaluator]: [0mInference done 2841/8355. 0.1173 s / img. ETA=0:11:00
[32m[04/20 21:52:49 d2.evaluation.evaluator]: [0mInference done 2883/8355. 0.1173 s / img. ETA=0:10:55
[32m[04/20 21:52:54 d2.evaluation.evaluator]: [0mInference done 2925/8355. 0.1173 s / img. ETA=0:10:50
[32m[04/20 21:52:59 d2.evaluation.evaluator]: [0mInference done 2967/8355. 0.1173 s / img. ETA=0:10:45
[32m[04/20 21:53:04 d2.evaluation.evaluator]: [0mInference done 3009/8355. 0.1173 s / img. ETA=0:10:40
[32m[04/20 21:53:09 d2.evaluation.evaluator]: [0mInference done 3051/8355. 0.1173 s / img. ETA=0:10:35
[32m[04/20 21:53:14 d2.evaluation.evaluator]: [0mInference done 3093/8355. 0.1173 s / img. ETA=0:10:30
[32m[04/20 21:53:19 d2.evaluation.evaluator]: [0mInference done 3135/8355. 0.1173 s / img. ETA=0:10:25
[32m[04/20 21:53:24 d2.evaluation.evaluator]: [0mInference done 3178/8355. 0.1173 s / img. ETA=0:10:20
[32m[04/20 21:53:29 d2.evaluation.evaluator]: [0mInference done 3220/8355. 0.1173 s / img. ETA=0:10:15
[32m[04/20 21:53:35 d2.evaluation.evaluator]: [0mInference done 3262/8355. 0.1173 s / img. ETA=0:10:09
[32m[04/20 21:53:40 d2.evaluation.evaluator]: [0mInference done 3304/8355. 0.1173 s / img. ETA=0:10:04
[32m[04/20 21:53:45 d2.evaluation.evaluator]: [0mInference done 3346/8355. 0.1173 s / img. ETA=0:09:59
[32m[04/20 21:53:50 d2.evaluation.evaluator]: [0mInference done 3388/8355. 0.1173 s / img. ETA=0:09:54
[32m[04/20 21:53:55 d2.evaluation.evaluator]: [0mInference done 3430/8355. 0.1173 s / img. ETA=0:09:49
[32m[04/20 21:54:00 d2.evaluation.evaluator]: [0mInference done 3472/8355. 0.1173 s / img. ETA=0:09:44
[32m[04/20 21:54:05 d2.evaluation.evaluator]: [0mInference done 3514/8355. 0.1173 s / img. ETA=0:09:39
[32m[04/20 21:54:10 d2.evaluation.evaluator]: [0mInference done 3556/8355. 0.1173 s / img. ETA=0:09:34
[32m[04/20 21:54:15 d2.evaluation.evaluator]: [0mInference done 3598/8355. 0.1173 s / img. ETA=0:09:29
[32m[04/20 21:54:20 d2.evaluation.evaluator]: [0mInference done 3640/8355. 0.1173 s / img. ETA=0:09:24
[32m[04/20 21:54:25 d2.evaluation.evaluator]: [0mInference done 3682/8355. 0.1173 s / img. ETA=0:09:19
[32m[04/20 21:54:30 d2.evaluation.evaluator]: [0mInference done 3724/8355. 0.1173 s / img. ETA=0:09:14
[32m[04/20 21:54:35 d2.evaluation.evaluator]: [0mInference done 3766/8355. 0.1173 s / img. ETA=0:09:09
[32m[04/20 21:54:40 d2.evaluation.evaluator]: [0mInference done 3808/8355. 0.1173 s / img. ETA=0:09:04
[32m[04/20 21:54:45 d2.evaluation.evaluator]: [0mInference done 3850/8355. 0.1173 s / img. ETA=0:08:59
[32m[04/20 21:54:50 d2.evaluation.evaluator]: [0mInference done 3892/8355. 0.1173 s / img. ETA=0:08:54
[32m[04/20 21:54:55 d2.evaluation.evaluator]: [0mInference done 3934/8355. 0.1173 s / img. ETA=0:08:49
[32m[04/20 21:55:00 d2.evaluation.evaluator]: [0mInference done 3977/8355. 0.1173 s / img. ETA=0:08:44
[32m[04/20 21:55:05 d2.evaluation.evaluator]: [0mInference done 4019/8355. 0.1173 s / img. ETA=0:08:39
[32m[04/20 21:55:10 d2.evaluation.evaluator]: [0mInference done 4061/8355. 0.1173 s / img. ETA=0:08:34
[32m[04/20 21:55:15 d2.evaluation.evaluator]: [0mInference done 4103/8355. 0.1173 s / img. ETA=0:08:29
[32m[04/20 21:55:20 d2.evaluation.evaluator]: [0mInference done 4145/8355. 0.1173 s / img. ETA=0:08:24
[32m[04/20 21:55:25 d2.evaluation.evaluator]: [0mInference done 4187/8355. 0.1174 s / img. ETA=0:08:19
[32m[04/20 21:55:30 d2.evaluation.evaluator]: [0mInference done 4229/8355. 0.1173 s / img. ETA=0:08:14
[32m[04/20 21:55:36 d2.evaluation.evaluator]: [0mInference done 4271/8355. 0.1173 s / img. ETA=0:08:09
[32m[04/20 21:55:41 d2.evaluation.evaluator]: [0mInference done 4313/8355. 0.1173 s / img. ETA=0:08:04
[32m[04/20 21:55:46 d2.evaluation.evaluator]: [0mInference done 4355/8355. 0.1173 s / img. ETA=0:07:59
[32m[04/20 21:55:51 d2.evaluation.evaluator]: [0mInference done 4397/8355. 0.1173 s / img. ETA=0:07:54
[32m[04/20 21:55:56 d2.evaluation.evaluator]: [0mInference done 4439/8355. 0.1173 s / img. ETA=0:07:49
[32m[04/20 21:56:01 d2.evaluation.evaluator]: [0mInference done 4481/8355. 0.1174 s / img. ETA=0:07:44
[32m[04/20 21:56:06 d2.evaluation.evaluator]: [0mInference done 4523/8355. 0.1174 s / img. ETA=0:07:39
[32m[04/20 21:56:11 d2.evaluation.evaluator]: [0mInference done 4565/8355. 0.1174 s / img. ETA=0:07:34
[32m[04/20 21:56:16 d2.evaluation.evaluator]: [0mInference done 4607/8355. 0.1174 s / img. ETA=0:07:29
[32m[04/20 21:56:21 d2.evaluation.evaluator]: [0mInference done 4649/8355. 0.1174 s / img. ETA=0:07:24
[32m[04/20 21:56:26 d2.evaluation.evaluator]: [0mInference done 4691/8355. 0.1174 s / img. ETA=0:07:19
[32m[04/20 21:56:31 d2.evaluation.evaluator]: [0mInference done 4733/8355. 0.1174 s / img. ETA=0:07:14
[32m[04/20 21:56:36 d2.evaluation.evaluator]: [0mInference done 4775/8355. 0.1174 s / img. ETA=0:07:09
[32m[04/20 21:56:41 d2.evaluation.evaluator]: [0mInference done 4817/8355. 0.1174 s / img. ETA=0:07:04
[32m[04/20 21:56:46 d2.evaluation.evaluator]: [0mInference done 4859/8355. 0.1174 s / img. ETA=0:06:59
[32m[04/20 21:56:51 d2.evaluation.evaluator]: [0mInference done 4901/8355. 0.1174 s / img. ETA=0:06:54
[32m[04/20 21:56:56 d2.evaluation.evaluator]: [0mInference done 4943/8355. 0.1174 s / img. ETA=0:06:48
[32m[04/20 21:57:01 d2.evaluation.evaluator]: [0mInference done 4985/8355. 0.1174 s / img. ETA=0:06:43
[32m[04/20 21:57:06 d2.evaluation.evaluator]: [0mInference done 5027/8355. 0.1174 s / img. ETA=0:06:38
[32m[04/20 21:57:11 d2.evaluation.evaluator]: [0mInference done 5069/8355. 0.1174 s / img. ETA=0:06:33
[32m[04/20 21:57:17 d2.evaluation.evaluator]: [0mInference done 5111/8355. 0.1174 s / img. ETA=0:06:28
[32m[04/20 21:57:22 d2.evaluation.evaluator]: [0mInference done 5153/8355. 0.1174 s / img. ETA=0:06:23
[32m[04/20 21:57:27 d2.evaluation.evaluator]: [0mInference done 5195/8355. 0.1174 s / img. ETA=0:06:18
[32m[04/20 21:57:32 d2.evaluation.evaluator]: [0mInference done 5237/8355. 0.1174 s / img. ETA=0:06:13
[32m[04/20 21:57:37 d2.evaluation.evaluator]: [0mInference done 5279/8355. 0.1174 s / img. ETA=0:06:08
[32m[04/20 21:57:42 d2.evaluation.evaluator]: [0mInference done 5321/8355. 0.1174 s / img. ETA=0:06:03
[32m[04/20 21:57:47 d2.evaluation.evaluator]: [0mInference done 5363/8355. 0.1175 s / img. ETA=0:05:58
[32m[04/20 21:57:52 d2.evaluation.evaluator]: [0mInference done 5405/8355. 0.1175 s / img. ETA=0:05:53
[32m[04/20 21:57:57 d2.evaluation.evaluator]: [0mInference done 5447/8355. 0.1175 s / img. ETA=0:05:48
[32m[04/20 21:58:02 d2.evaluation.evaluator]: [0mInference done 5489/8355. 0.1175 s / img. ETA=0:05:43
[32m[04/20 21:58:07 d2.evaluation.evaluator]: [0mInference done 5531/8355. 0.1175 s / img. ETA=0:05:38
[32m[04/20 21:58:12 d2.evaluation.evaluator]: [0mInference done 5573/8355. 0.1175 s / img. ETA=0:05:33
[32m[04/20 21:58:17 d2.evaluation.evaluator]: [0mInference done 5615/8355. 0.1175 s / img. ETA=0:05:28
[32m[04/20 21:58:22 d2.evaluation.evaluator]: [0mInference done 5657/8355. 0.1175 s / img. ETA=0:05:23
[32m[04/20 21:58:28 d2.evaluation.evaluator]: [0mInference done 5699/8355. 0.1175 s / img. ETA=0:05:18
[32m[04/20 21:58:33 d2.evaluation.evaluator]: [0mInference done 5741/8355. 0.1175 s / img. ETA=0:05:13
[32m[04/20 21:58:38 d2.evaluation.evaluator]: [0mInference done 5783/8355. 0.1175 s / img. ETA=0:05:08
[32m[04/20 21:58:43 d2.evaluation.evaluator]: [0mInference done 5825/8355. 0.1175 s / img. ETA=0:05:03
[32m[04/20 21:58:48 d2.evaluation.evaluator]: [0mInference done 5867/8355. 0.1175 s / img. ETA=0:04:58
[32m[04/20 21:58:53 d2.evaluation.evaluator]: [0mInference done 5909/8355. 0.1175 s / img. ETA=0:04:53
[32m[04/20 21:58:58 d2.evaluation.evaluator]: [0mInference done 5951/8355. 0.1175 s / img. ETA=0:04:48
[32m[04/20 21:59:03 d2.evaluation.evaluator]: [0mInference done 5993/8355. 0.1175 s / img. ETA=0:04:43
[32m[04/20 21:59:08 d2.evaluation.evaluator]: [0mInference done 6035/8355. 0.1175 s / img. ETA=0:04:38
[32m[04/20 21:59:13 d2.evaluation.evaluator]: [0mInference done 6077/8355. 0.1175 s / img. ETA=0:04:33
[32m[04/20 21:59:18 d2.evaluation.evaluator]: [0mInference done 6119/8355. 0.1175 s / img. ETA=0:04:28
[32m[04/20 21:59:23 d2.evaluation.evaluator]: [0mInference done 6161/8355. 0.1176 s / img. ETA=0:04:23
[32m[04/20 21:59:28 d2.evaluation.evaluator]: [0mInference done 6203/8355. 0.1176 s / img. ETA=0:04:18
[32m[04/20 21:59:33 d2.evaluation.evaluator]: [0mInference done 6245/8355. 0.1176 s / img. ETA=0:04:13
[32m[04/20 21:59:38 d2.evaluation.evaluator]: [0mInference done 6287/8355. 0.1176 s / img. ETA=0:04:08
[32m[04/20 21:59:44 d2.evaluation.evaluator]: [0mInference done 6329/8355. 0.1176 s / img. ETA=0:04:03
[32m[04/20 21:59:49 d2.evaluation.evaluator]: [0mInference done 6371/8355. 0.1176 s / img. ETA=0:03:58
[32m[04/20 21:59:54 d2.evaluation.evaluator]: [0mInference done 6413/8355. 0.1176 s / img. ETA=0:03:53
[32m[04/20 21:59:59 d2.evaluation.evaluator]: [0mInference done 6455/8355. 0.1176 s / img. ETA=0:03:48
[32m[04/20 22:00:04 d2.evaluation.evaluator]: [0mInference done 6497/8355. 0.1176 s / img. ETA=0:03:43
[32m[04/20 22:00:09 d2.evaluation.evaluator]: [0mInference done 6539/8355. 0.1176 s / img. ETA=0:03:37
[32m[04/20 22:00:14 d2.evaluation.evaluator]: [0mInference done 6581/8355. 0.1176 s / img. ETA=0:03:32
[32m[04/20 22:00:19 d2.evaluation.evaluator]: [0mInference done 6623/8355. 0.1176 s / img. ETA=0:03:27
[32m[04/20 22:00:24 d2.evaluation.evaluator]: [0mInference done 6665/8355. 0.1176 s / img. ETA=0:03:22
[32m[04/20 22:00:29 d2.evaluation.evaluator]: [0mInference done 6708/8355. 0.1176 s / img. ETA=0:03:17
[32m[04/20 22:00:34 d2.evaluation.evaluator]: [0mInference done 6750/8355. 0.1176 s / img. ETA=0:03:12
[32m[04/20 22:00:39 d2.evaluation.evaluator]: [0mInference done 6792/8355. 0.1176 s / img. ETA=0:03:07
[32m[04/20 22:00:44 d2.evaluation.evaluator]: [0mInference done 6834/8355. 0.1176 s / img. ETA=0:03:02
[32m[04/20 22:00:49 d2.evaluation.evaluator]: [0mInference done 6876/8355. 0.1176 s / img. ETA=0:02:57
[32m[04/20 22:00:54 d2.evaluation.evaluator]: [0mInference done 6918/8355. 0.1176 s / img. ETA=0:02:52
[32m[04/20 22:00:59 d2.evaluation.evaluator]: [0mInference done 6960/8355. 0.1176 s / img. ETA=0:02:47
[32m[04/20 22:01:04 d2.evaluation.evaluator]: [0mInference done 7002/8355. 0.1176 s / img. ETA=0:02:42
[32m[04/20 22:01:09 d2.evaluation.evaluator]: [0mInference done 7044/8355. 0.1176 s / img. ETA=0:02:37
